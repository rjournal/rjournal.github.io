% Encoding: ISO-8859-1

@article{Bilogur2018,
  doi = {10.21105/joss.00547},
  url = {https://doi.org/10.21105/joss.00547},
  year = {2018},
  publisher = {The Open Journal},
  volume = {3},
  number = {22},
  pages = {547},
  author = {Aleksey Bilogur},
  title = {Missingno: a missing data visualization suite},
  journal = {Journal of Open Source Software}
}

@Article{dempster_etal_1977,
  Title                    = {Maximum likelihood from incomplete data via the EM algorithm},
  Author                   = {Dempster, Arthur P and Laird, Nan M and Rubin, Donald B},
  Journal                  = {Journal of the Royal Statistical Society: Series B (Methodological)},
  Volume                   = {39},
  Number                   = {1},
  Pages                    = {1--22},
  Year                     = {1977},
  Publisher                = {Wiley Online Library},
  Doi                      = {10.1111/j.2517-6161.1977.tb01600.x},

  Abstract                 = {A broadly applicable algorithm for computing maximum likelihood
  estimates from incomplete data is presented at various levels of generality. Theory showing
  the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many
  examples are sketched, including missing value situations, applications to grouped, censored
  or truncated data, finite mixture models, variance component estimation, hyperparameter
  estimation, iteratively reweighted least squares and factor analysis.},

  Keywords                 = {maximum likelihood; incomplete data; em algorithm; posterior mode},
  Owner                    = {imke},
  Timestamp                = {2019.04.01}
}

@book{rubin2004multiple,
  title={Multiple imputation for nonresponse in surveys},
  author={Rubin, Donald B},
  volume={81},
  year={2004},
  publisher={John Wiley \& Sons}
}

@Manual{R,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2020},
    url = {https://www.R-project.org/}
}


@BOOK{Carpenter2012,
  title     = "Multiple Imputation and its Application",
  author    = "Carpenter, James and Kenward, Michael",
  publisher = "John Wiley \& Sons",
  month     =  dec,
  year      =  2012,
  language  = "en"
}

 @Article{mice,
    title = {{mice}: Multivariate Imputation by Chained Equations in R},
    author = {Stef {van Buuren} and Karin Groothuis-Oudshoorn},
    journal = {Journal of Statistical Software},
    year = {2011},
    volume = {45},
    number = {3},
    pages = {1--67},
    url = {http://www.jstatsoft.org/v45/i03/},
  }


@BOOK{VanBuuren2012,
  title     = "Flexible Imputation of Missing Data, Second Edition",
  author    = "van Buuren, Stef",
  publisher = "CRC Press",
  year      =  2018,
  language  = "en"
}

@BOOK{Little2002,
  title     = "Statistical Analysis with Missing Data",
  author    = "Little, Roderick J A and Rubin, Donald B",
  publisher = "Wiley",
  edition   = "2nd ed.",
  month     =  sep,
  year      =  2002,
  address   = "New York ; Chichester",
  language  = "en"
}

@ARTICLE{Schafer2002,
  title    = "Missing data: our view of the state of the art",
  author   = "Schafer, Joseph L and Graham, John W",
  journal  = "Psychological methods",
  volume   =  7,
  number   =  2,
  pages    = "147--177",
  month    =  jun,
  year     =  2002,
  language = "en"
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@Article{mi,
  title = {Opening Windows to the Black Box},
  author = {Andrew Gelman and Jennifer Hill},
  journal = {Journal of Statistical Software},
  year = {2011},
  volume = {40},
}

@Article{amelia,
  title = {{Amelia II}: A Program for Missing Data},
  author = {James Honaker and Gary King and Matthew Blackwell},
  journal = {Journal of Statistical Software},
  year = {2011},
  volume = {45},
  number = {7},
  pages = {1--47},
  url = {http://www.jstatsoft.org/v45/i07/},
}

@Manual{naniar,
  title = {naniar: Data Structures, Summaries, and Visualisations for Missing Data},
  author = {Nicholas Tierney and Di Cook and Miles McBain and Colin Fay},
  year = {2021}, 
  note = {R package version 0.6.1},
  url = {https://CRAN.R-project.org/package=naniar},
}

@Article{VIM,
  title = {Imputation with the {R} Package {VIM}},
  author = {Alexander Kowarik and Matthias Templ},
  journal = {Journal of Statistical Software},
  year = {2016},
  volume = {74},
  number = {7},
  pages = {1--16},
  doi = {10.18637/jss.v074.i07},
}

@ARTICLE{Cheng2015,
  title   = "Visually Exploring Missing Values in Multivariable Data Using a
             Graphical User Interface",
  author  = "Cheng, Xiaoyue and Cook, Dianne and Hofmann, Heike",
  journal = "Journal of statistical software",
  volume  =  68,
  number  =  1,
  pages   = "1--23",
  year    =  2015
}

@misc{dua_2019,
author = "Dua, Dheeru and Graff, Casey",
year = "2019",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" 
}

@InProceedings{gondara_wang_2018,
  Title                    = {MIDA: Multiple Imputation using Denoising Autoencoders},
  Author                   = {Gondara, L. and Wang, K.},
  Booktitle                = {Proceedings of the 22nd Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2018)},
  Series                   = {Lecture Notes in Computer Science},
  Year                     = {2018},
  Editor                   = {Phung, D. and Tseng, V. and Webb, G. and Ho, B. and Ganji, M. and Rashidi, L.},

  Pages                    = {260-272},
  Publisher                = {Springer International Publishing},

  Eventdate                = {2018-06-03/2018-06-06},
  ISBN                     = {3319930404},

  Abstract                 = {Missing data is a significant problem impacting all domains. State-of-the-art framework for minimizing missing data bias is multiple imputation, for which the choice of an imputation model remains nontrivial. We propose a multiple imputation model based on overcomplete deep denoising autoencoders. Our proposed model is capable of handling different data types, missingness patterns, missingness proportions and distributions. Evaluation on several real life datasets show our proposed model significantly outperforms current state-of-the-art methods under varying conditions while simultaneously improving end of the line analytics.},
  Doi                      = {10.1007/978-3-319-93040-4_21},
  Url                      = {https://arxiv.org/abs/1705.02737},
  Keywords                 = {Multiple imputation; denoising autoencoders; DAE},
  Owner                    = {imke},
  Timestamp                = {2018.11.08},
  Topics                   = {multiple imputation; deep learning}
}

@Article{Josse2016,
  title = {{missMDA}: A Package for Handling Missing Values in Multivariate Data Analysis},
  author = {Julie Josse and Fran\c{c}ois Husson},
  journal = {Journal of Statistical Software},
  year = {2016},
  volume = {70},
  number = {1},
  pages = {1--31},
  doi = {10.18637/jss.v070.i01},
}

@Article{josse_etal_2019,
  Title                    = {On the consistency of supervised learning with missing values},
  Author                   = {Josse, Julie and Prost, Nicolas and Scornet, Erwan and Varoquaux, Ga{\"e}l},
  Journal                  = {arXiv preprint},
  archivePrefix            = {arXiv},
  eprint                   = {1902.06931},
  primaryClass             = {stat.ML},
  Year                     = {2019},
  Url                      = {https://arxiv.org/abs/1902.06931},

  Abstract                 = {In many application settings, the data are plagued with missing features. These hinder data analysis. An abundant literature addresses missing values in an inferential framework, where the aim is to estimate parameters and their variance from incomplete tables. Here, we consider supervised-learning settings where the objective is to best predict a target when missing values appear in both training and test sets. We analyze which missing-values strategies lead to good prediction. We show the consistency of two approaches to estimating the prediction function. The most striking one shows that the widely-used mean imputation prior to learning method is consistent when missing values are not informative. This is in contrast with inferential settings as mean imputation is known to have serious drawbacks in terms of deformation of the joint and marginal distribution of the data. That such a simple approach can be consistent has important consequences in practice. This result holds asymptotically when the learning algorithm is consistent in itself. We contribute additional analysis on decision trees as they can naturally tackle empirical risk minimization with missing values. This is due to their ability to handle the half-discrete nature of variables with missing values. After comparing theoretically and empirically different missing-values strategies in trees, we recommend using the missing incorporated in attributes method as it can handle both non-informative and informative missing values.},
  Keywords                 = {Imputation; decision trees; expectation maximization},
  Owner                    = {imke},
  Timestamp                = {2019.03.17},
  Topics                   = {random trees; random forests}
}

@Misc{Murray2015,
  title = {Multiple Imputation of Missing Categorical and Continuous Values via Bayesian Mixture Models with Local Dependence},
  author = {Jared S Murray and Jerome P Reiter},
  year = {2015},
  eprint = {arXiv:1410.0438},
  url = {http://arxiv.org/abs/1410.0438},
}

@Article{zhu_etal_2019,
  Title                    = {High-dimensional principal component analysis with heterogeneous missingness},
  Author                   = {Zhu, Ziwei and Wang, Tengyao and Samworth, Richard J},
  Journal                  = {arXiv preprint},
  Year                     = {2019},

  Archiveprefix            = {arXiv},
  Arxivid                  = {1906.12125},
  Url                      = {https://arxiv.org/abs/1906.12125},

  Abstract                 = {We study the problem of high-dimensional Principal Component Analysis (PCA) with missing observations. In simple, homogeneous missingness settings with a noise level of constant order, we show that an existing inverse-probability weighted (IPW) estimator of the leading principal components can (nearly) attain the minimax optimal rate of convergence. However, deeper investigation reveals both that, particularly in more realistic settings where the missingness mechanism is heterogeneous, the empirical performance of the IPW estimator can be unsatisfactory, and moreover that, in the noiseless case, it fails to provide exact recovery of the principal components. Our main contribution, then, is to introduce a new method for high-dimensional PCA, called `primePCA', that is designed to cope with situations where observations may be missing in a heterogeneous manner. Starting from the IPW estimator, primePCA iteratively projects the observed entries of the data matrix onto the column space of our current estimate to impute the missing entries, and then updates our estimate by computing the leading right singular space of the imputed data matrix. It turns out that the interaction between the heterogeneity of missingness and the low-dimensional structure is crucial in determining the feasibility of the problem. We therefore introduce an incoherence condition on the principal components and prove that in the noiseless case, the error of primePCA converges to zero at a geometric rate when the signal strength is not too small. An important feature of our theoretical guarantees is that they depend on average, as opposed to worst-case, properties of the missingness mechanism. Our numerical studies on both simulated and real data reveal that primePCA exhibits very encouraging performance across a wide range of scenarios.},

  Keywords                 = {missing values; heterogeneous missingness; incoherence; principal component analysis; inverse propensity weighting},
  Owner                    = {imke},
  Timestamp                = {2019.07.05},
  Topics                   = {factorial data analysis; imputation; causal inference}
}

@Book{xie_etal_bCWRM2017,
  title     = {blogdown: Creating Websites with R Markdow},
  publisher = {Chapman and Hall/CRC},
  year      = {2017},
  author    = {Xie, Yihui and Presmanes Hill, Alison and Thomas, Amber},
  editor    = {Boca Raton, FL, USA},
  series    = {The R Series},
  isbn      = {978-0815363729},
  owner     = {nathalie},
  timestamp = {2019.08.07},
}

@Comment{jabref-meta: databaseType:bibtex;}

@article{stekhoven2012missforest,
  title={MissForest—non-parametric missing value imputation for mixed-type data},
  author={Stekhoven, Daniel J and B{\"u}hlmann, Peter},
  journal={Bioinformatics},
  volume={28},
  number={1},
  pages={112--118},
  year={2012},
  publisher={Oxford University Press}
}

@article{hastie2015matrix,
  title={Matrix completion and low-rank SVD via fast alternating least squares},
  author={Hastie, Trevor and Mazumder, Rahul and Lee, Jason D and Zadeh, Reza},
  journal={The Journal of Machine Learning Research},
  volume={16},
  number={1},
  pages={3367--3402},
  year={2015},
  publisher={JMLR. org}
}

@article{josse2016missmda,
  title={missMDA: a package for handling missing values in multivariate data analysis},
  author={Josse, Julie and Husson, Fran{\c{c}}ois and others},
  journal={Journal of Statistical Software},
  volume={70},
  number={1},
  pages={1--31},
  year={2016},
  publisher={Foundation for Open Access Statistics}
}

@article{jiang2020logistic,
  title={Logistic regression with missing covariates—Parameter estimation, model selection and prediction within a joint-modeling framework},
  author={Jiang, Wei and Josse, Julie and Lavielle, Marc and Group, TraumaBase},
  journal={Computational Statistics \& Data Analysis},
  volume={145},
  pages={106907},
  year={2020},
  publisher={Elsevier}
}


@article{rubin_B1976,
  title={Inference and missing data},
  author={Rubin, Donald B},
  journal={Biometrika},
  volume={63},
  number={3},
  pages={581--592},
  year={1976},
  publisher={Oxford University Press}
}

@article{josse_reiter_2018,
  title={Introduction to the special section on missing data},
  author={Josse, Julie and Reiter, Jerome P},
  journal={Statistical Science},
  volume={33},
  number={2},
  pages={139--141},
  year={2018},
  publisher={Institute of Mathematical Statistics}
}

@book{enders_AMDA2010,
  title={Applied missing data analysis},
  author={Enders, Craig K},
  year={2010},
  publisher={Guilford press}
}

@article{Tierney2018,
  title={Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations},
  author={Tierney, Nicholas J and Cook, Dianne H},
  journal={arXiv preprint arXiv:1809.02264},
  year={2018}
}

@inproceedings{mattei2019miwae,
  title={MIWAE: Deep generative modelling and imputation of incomplete data sets},
  author={Mattei, Pierre-Alexandre and Frellsen, Jes},
  booktitle={International Conference on Machine Learning},
  pages={4413--4423},
  year={2019},
  organization={PMLR}
}


@inproceedings{muzellec2020missing,
  title={Missing Data Imputation using Optimal Transport},
  author={Muzellec, Boris and Josse, Julie and Boyer, Claire and Cuturi, Marco},
  booktitle={International Conference on Machine Learning},
  pages={7130--7140},
  year={2020},
  organization={PMLR}
}


@article{abiri2019establishing,
  title={Establishing strong imputation performance of a denoising autoencoder in a wide range of missing data problems},
  author={Abiri, Najmeh and Linse, Bj{\"o}rn and Ed{\'e}n, Patrik and Ohlsson, Mattias},
  journal={Neurocomputing},
  volume={365},
  pages={137--146},
  year={2019},
  publisher={Elsevier}
}

@article{twala2008good,
  title={Good methods for coping with missing data in decision trees},
  author={Twala, BETH and Jones, MC and Hand, David J},
  journal={Pattern Recognition Letters},
  volume={29},
  number={7},
  pages={950--956},
  year={2008},
  publisher={Elsevier}
}

@article{seaman2013meant,
  title={What is meant by" missing at random"?},
  author={Seaman, Shaun and Galati, John and Jackson, Dan and Carlin, John},
  journal={Statistical Science},
  pages={257--268},
  year={2013},
  publisher={JSTOR}
}

@article{pedregosa2011scikit,
  title={Scikit-learn: Machine learning in Python},
  author={Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others},
  journal={the Journal of machine Learning research},
  volume={12},
  pages={2825--2830},
  year={2011},
  publisher={JMLR. org}
}

@book{python,
 author = {Van Rossum, Guido and Drake, Fred L.},
 title = {Python 3 Reference Manual},
 year = {2009},
 isbn = {1441412697},
 publisher = {CreateSpace},
 address = {Scotts Valley, CA}
}

@book{stata,
 author = {{StataCorp.}},
 year = {2019},
 title = {Stata Statistical Software: Release 16},
 address = {College Station, TX}, 
 publisher = {StataCorp LLC.}
}

@article{ihaka_1998,
  title={R: Past and future history},
  author={Ihaka, Ross},
  journal={Computing Science and Statistics},
  volume={392396},
  year={1998},
  publisher={Citeseer}
}

@inproceedings{Bennett2007,
  title={The netflix prize},
  author={Bennett, James and Lanning, Stan and others},
  booktitle={Proceedings of KDD cup and workshop},
  volume={2007},
  pages={35},
  year={2007},
  organization={Citeseer}
}

@article{Makridakis2018,
  title={The M4 Competition: Results, findings, conclusion and way forward},
  author={Makridakis, Spyros and Spiliotis, Evangelos and Assimakopoulos, Vassilios},
  journal={International Journal of Forecasting},
  volume={34},
  number={4},
  pages={802--808},
  year={2018},
  publisher={Elsevier}
}

@article{zhu2019high,
  title={High-dimensional principal component analysis with heterogeneous missingness},
  author={Zhu, Ziwei and Wang, Tengyao and Samworth, Richard J},
  journal={arXiv preprint arXiv:1906.12125},
  year={2019}
}

@inproceedings{datawig,
 author = {Biessmann, Felix and Salinas, David and Schelter, Sebastian and Schmidt, Philipp and Lange, Dustin},
 title = {"Deep" Learning for Missing Value Imputationin Tables with Non-Numerical Data},
 booktitle = {Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
 series = {CIKM '18},
 year = {2018},
 isbn = {978-1-4503-6014-2},
 location = {Torino, Italy},
 pages = {2017--2025},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/3269206.3272005},
 doi = {10.1145/3269206.3272005},
 keywords = {data cleaning, missing value imputation}}
 
@article{breiman_2001,
  title={Random forests},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={45},
  number={1},
  pages={5--32},
  year={2001},
  publisher={Springer}
}

@Article{moritz_2017,
  title = {{imputeTS: Time Series Missing Value Imputation in R}},
  author = {Steffen Moritz and Thomas Bartz-Beielstein},
  journal = {{The R Journal}},
  volume = {9},
  number = {1},
  pages = {207--218},
  year = {2017},
  doi = {10.32614/RJ-2017-009},
}

@Article{Mayer2020,
    Author = {Imke Mayer and Erik Sverdrup and Tobias Gauss and Jean-Denis Moyer and Stefan Wager and Julie Josse},
    Title = {Doubly robust treatment effect estimation with missing attributes},
    Journal = {Ann. Appl. Statist.},
    FJournal = {Annals of Applied Statistics},
    Year = {2020},
    Volume = {14},
    Number = {3},
    Pages = {1409-1431},
    ISSN = {1932-6157},
    DOI = {10.1214/20-AOAS1356},
    SICI = {1932-6157(2020)14:3<1409:DRTEEW>2.0.CO;2-E},
}

@inproceedings{yoon2018gain,
  title={Gain: Missing data imputation using generative adversarial nets},
  author={Yoon, Jinsung and Jordon, James and Schaar, Mihaela},
  booktitle={International Conference on Machine Learning},
  pages={5689--5698},
  year={2018},
  organization={PMLR}
}


@article{delyon1999convergence,
  title={Convergence of a stochastic approximation version of the EM algorithm},
  author={Delyon, Bernard and Lavielle, Marc and Moulines, Eric and others},
  journal={The Annals of Statistics},
  volume={27},
  number={1},
  pages={94--128},
  year={1999},
  publisher={Institute of Mathematical Statistics}
}

@article{sportisse2021handling,
  title={Handling heterogeneous and MNAR missing data in statistical learning frameworks: imputation based on low-rank models, online linear regression with SGD, and model-based clustering},
  author={Sportisse, Aude},
  year={2021},
  school={Sorbonne University}
}

@book{little2019statistical,
  title={Statistical analysis with missing data},
  author={Little, Roderick JA and Rubin, Donald B},
  volume={793},
  year={2019},
  publisher={John Wiley \& Sons}
}

@article{le2008factominer,
  title={FactoMineR: an R package for multivariate analysis},
  author={L{\^e}, S{\'e}bastien and Josse, Julie and Husson, Fran{\c{c}}ois},
  journal={Journal of statistical software},
  volume={25},
  pages={1--18},
  year={2008}
}