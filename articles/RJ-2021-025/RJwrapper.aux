\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{abbrvnat}
\citation{michie1994machine}
\citation{lim2000comparison,dettling2004bagboosting,hand2006classifier}
\citation{fan2008high,bickel2008}
\citation{catch}
\citation{DSDA}
\citation{ROAD}
\citation{Clemmensen}
\citation{hastie1994flexible}
\citation{Mai2015ssda}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}{\normalfont  \fontseries  {b}\selectfont  TULIP}: A Toolbox for Linear Discriminant Analysis with Penalties}{134}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction}{134}{section.2.1}\protected@file@percent }
\newlabel{sec:intro}{{2.1}{134}{Introduction}{section.2.1}{}}
\@writefile{brf}{\backcite{michie1994machine}{{134}{2.1}{section.2.1}}}
\@writefile{brf}{\backcite{lim2000comparison}{{134}{2.1}{section.2.1}}}
\@writefile{brf}{\backcite{dettling2004bagboosting}{{134}{2.1}{section.2.1}}}
\@writefile{brf}{\backcite{hand2006classifier}{{134}{2.1}{section.2.1}}}
\@writefile{brf}{\backcite{fan2008high}{{134}{2.1}{section.2.1}}}
\@writefile{brf}{\backcite{bickel2008}{{134}{2.1}{section.2.1}}}
\@writefile{brf}{\backcite{catch}{{134}{2.1}{section.2.1}}}
\@writefile{brf}{\backcite{DSDA}{{134}{1}{Item.1}}}
\@writefile{brf}{\backcite{ROAD}{{134}{2}{Item.2}}}
\@writefile{brf}{\backcite{Clemmensen}{{134}{3}{Item.3}}}
\@writefile{brf}{\backcite{hastie1994flexible}{{134}{3}{Item.3}}}
\citation{MSDA}
\citation{yuan2006model}
\citation{catch}
\citation{TULIP}
\citation{MSDA}
\citation{sparseLDA}
\citation{fan2008high,Tibshirani2002,Trendafilov2007,ROAD,wu2009sparse,cai2011constrained,Shao2011,Clemmensen,witten,Xu2015,Niu2015}
\citation{Zhou2013,KoldaBader09Tensor,chi2012tensors,liu2017characterizing,CMDA,STDA,Zhong2015,Zeng2015}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of model settings between models. SOS was originally proposed to deal with both binary and multiclass problems, but we focus on binary problems in the package. Model SeLDA stands for Semi-parametric linear discriminant analysis, which is introduced in Section\nobreakspace  {}\ref {Sec: SeLDA}. Model TDA/CATCH represents tensor discriminant analysis and covariate-adjusted tensor in high-dimensions, which are illustrated in Section\nobreakspace  {}\ref {Sec: CATCH} and \ref {catchmodel}. }}{135}{table.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:model}{{1}{135}{Comparison of model settings between models. SOS was originally proposed to deal with both binary and multiclass problems, but we focus on binary problems in the package. Model SeLDA stands for Semi-parametric linear discriminant analysis, which is introduced in Section~\ref {Sec: SeLDA}. Model TDA/CATCH represents tensor discriminant analysis and covariate-adjusted tensor in high-dimensions, which are illustrated in Section~\ref {Sec: CATCH} and \ref {catchmodel}}{table.caption.2}{}}
\@writefile{brf}{\backcite{Mai2015ssda}{{135}{4}{Item.4}}}
\@writefile{brf}{\backcite{MSDA}{{135}{5}{Item.5}}}
\@writefile{brf}{\backcite{yuan2006model}{{135}{5}{Item.5}}}
\@writefile{brf}{\backcite{catch}{{135}{6}{Item.6}}}
\@writefile{brf}{\backcite{TULIP}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{MSDA}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{sparseLDA}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{fan2008high}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{Tibshirani2002}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{Trendafilov2007}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{ROAD}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{wu2009sparse}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{cai2011constrained}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{Shao2011}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{Clemmensen}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{witten}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{Xu2015}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{Niu2015}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{Zhou2013}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{KoldaBader09Tensor}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{chi2012tensors}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{liu2017characterizing}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{CMDA}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{STDA}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{Zhong2015}{{135}{2.1}{table.caption.2}}}
\@writefile{brf}{\backcite{Zeng2015}{{135}{2.1}{table.caption.2}}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Discriminant analysis models and Bayes rules}{135}{section.2.2}\protected@file@percent }
\newlabel{Sec: models}{{2.2}{135}{Discriminant analysis models and Bayes rules}{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Bayes rule for classification}{135}{subsection.2.2.1}\protected@file@percent }
\citation{FHT01}
\citation{jiang2015quda,fan2015quadro,LiandShao2015,Sun2015}
\citation{catch}
\@writefile{brf}{\backcite{FHT01}{{136}{2.2.1}{equation.2.2.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}The linear discriminant analysis model (LDA)}{136}{subsection.2.2.2}\protected@file@percent }
\newlabel{Sec: LDA}{{2.2.2}{136}{The linear discriminant analysis model (LDA)}{subsection.2.2.2}{}}
\newlabel{LDA}{{2}{136}{The linear discriminant analysis model (LDA)}{equation.2.2.2}{}}
\newlabel{ldabayes}{{3}{136}{The linear discriminant analysis model (LDA)}{equation.2.2.3}{}}
\@writefile{brf}{\backcite{jiang2015quda}{{136}{2.2.2}{equation.2.2.3}}}
\@writefile{brf}{\backcite{fan2015quadro}{{136}{2.2.2}{equation.2.2.3}}}
\@writefile{brf}{\backcite{LiandShao2015}{{136}{2.2.2}{equation.2.2.3}}}
\@writefile{brf}{\backcite{Sun2015}{{136}{2.2.2}{equation.2.2.3}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Covariates adjustment}{136}{subsection.2.2.3}\protected@file@percent }
\newlabel{Sec:CA}{{2.2.3}{136}{Covariates adjustment}{subsection.2.2.3}{}}
\newlabel{CALDA.eq1}{{4}{136}{Covariates adjustment}{equation.2.2.4}{}}
\newlabel{CALDA.eq2}{{5}{136}{Covariates adjustment}{equation.2.2.5}{}}
\citation{Lin2003}
\citation{wellner1997,HNW14,SemiCov}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  Graphical illustration of the direct and indirect effects. The direct effect of covariate $\mathbf  {U}$ on $Y$ follows classical discriminant analysis model measured by $\{\boldsymbol  {\gamma }_2,\ldots  ,\boldsymbol  {\gamma }_K\}$. Meanwhile, $\mathbf  {U}$ also affects class label through affecting $\mathbf  {X}$. Therefore we have $\setbox \z@ \hbox {\mathsurround \z@ $\textstyle Y$}\mathaccent "0362{Y}=f(\mathbf  {X}, \mathbf  {U})$. }}{137}{figure.caption.3}\protected@file@percent }
\newlabel{fig:covariate}{{1}{137}{Graphical illustration of the direct and indirect effects. The direct effect of covariate $\mbU $ on $Y$ follows classical discriminant analysis model measured by $\{\bolgamma _2,\ldots ,\bolgamma _K\}$. Meanwhile, $\mbU $ also affects class label through affecting $\mbX $. Therefore we have $\widehat {Y}=f(\mbX , \mbU )$}{figure.caption.3}{}}
\@writefile{brf}{\backcite{catch}{{137}{2.2.3}{equation.2.2.5}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}The semiparametric LDA model}{137}{subsection.2.2.4}\protected@file@percent }
\newlabel{Sec: SeLDA}{{2.2.4}{137}{The semiparametric LDA model}{subsection.2.2.4}{}}
\@writefile{brf}{\backcite{Lin2003}{{137}{2.2.4}{subsection.2.2.4}}}
\newlabel{sesda}{{7}{137}{The semiparametric LDA model}{equation.2.2.7}{}}
\newlabel{sesda.h}{{8}{137}{The semiparametric LDA model}{equation.2.2.8}{}}
\citation{KoldaBader09Tensor}
\citation{catch}
\citation{catch}
\@writefile{brf}{\backcite{wellner1997}{{138}{2.2.4}{equation.2.2.8}}}
\@writefile{brf}{\backcite{HNW14}{{138}{2.2.4}{equation.2.2.8}}}
\@writefile{brf}{\backcite{SemiCov}{{138}{2.2.4}{equation.2.2.8}}}
\newlabel{seldabayes}{{9}{138}{The semiparametric LDA model}{equation.2.2.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Tensor discriminant analysis (TDA) and covariate adjustment}{138}{subsection.2.2.5}\protected@file@percent }
\newlabel{Sec: CATCH}{{2.2.5}{138}{Tensor discriminant analysis (TDA) and covariate adjustment}{subsection.2.2.5}{}}
\@writefile{brf}{\backcite{KoldaBader09Tensor}{{138}{2.2.5}{subsection.2.2.5}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Tucker decomposition of tensor $\mathbf  {A}$.}}{138}{figure.caption.4}\protected@file@percent }
\newlabel{fig:tucker}{{2}{138}{Tucker decomposition of tensor $\mbA $}{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Tensor normal distribution.}}{138}{figure.caption.4}\protected@file@percent }
\newlabel{fig:tn}{{3}{138}{Tensor normal distribution}{figure.caption.4}{}}
\newlabel{tda}{{10}{138}{Tensor discriminant analysis (TDA) and covariate adjustment}{equation.2.2.10}{}}
\@writefile{brf}{\backcite{catch}{{138}{2.2.5}{equation.2.2.10}}}
\newlabel{bayestda}{{11}{138}{Tensor discriminant analysis (TDA) and covariate adjustment}{equation.2.2.11}{}}
\@writefile{brf}{\backcite{catch}{{138}{2.2.5}{equation.2.2.11}}}
\citation{Tibshirani1996}
\citation{ROAD}
\citation{wu2009sparse}
\newlabel{bayescatch}{{14}{139}{Tensor discriminant analysis (TDA) and covariate adjustment}{equation.2.2.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Methods}{139}{section.2.3}\protected@file@percent }
\newlabel{sec:para}{{2.3}{139}{Methods}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Direct sparse discriminant analysis (DSDA)}{139}{subsection.2.3.1}\protected@file@percent }
\newlabel{dsda}{{15}{139}{Direct sparse discriminant analysis (DSDA)}{equation.2.3.15}{}}
\@writefile{brf}{\backcite{Tibshirani1996}{{139}{2.3.1}{equation.2.3.15}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Regularized optimal affine discriminant (ROAD)}{139}{subsection.2.3.2}\protected@file@percent }
\@writefile{brf}{\backcite{ROAD}{{139}{2.3.2}{subsection.2.3.2}}}
\newlabel{ROAD}{{16}{139}{Regularized optimal affine discriminant (ROAD)}{equation.2.3.16}{}}
\@writefile{brf}{\backcite{wu2009sparse}{{139}{2.3.2}{equation.2.3.17}}}
\citation{Mai2013note}
\citation{Clemmensen}
\citation{Mai2013note}
\citation{Mai2015ssda}
\newlabel{ROAD.opt}{{18}{140}{Regularized optimal affine discriminant (ROAD)}{equation.2.3.18}{}}
\@writefile{brf}{\backcite{Mai2013note}{{140}{2.3.2}{equation.2.3.18}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Sparse optimal scoring (SOS) in binary problems}{140}{subsection.2.3.3}\protected@file@percent }
\@writefile{brf}{\backcite{Clemmensen}{{140}{2.3.3}{subsection.2.3.3}}}
\newlabel{SOS}{{19}{140}{Sparse optimal scoring (SOS) in binary problems}{equation.2.3.19}{}}
\@writefile{brf}{\backcite{Mai2013note}{{140}{2.3.3}{equation.2.3.19}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Semiparametric sparse discriminant analysis (SeSDA)}{140}{subsection.2.3.4}\protected@file@percent }
\newlabel{Sec: SeSDA}{{2.3.4}{140}{Semiparametric sparse discriminant analysis (SeSDA)}{subsection.2.3.4}{}}
\@writefile{brf}{\backcite{Mai2015ssda}{{140}{2.3.4}{subsection.2.3.4}}}
\citation{yuan2006model}
\citation{MSDA}
\newlabel{alg:MSDA}{{1}{141}{Algorithm for MSDA}{algorithm.1}{}}
\newlabel{algmsdaupdate}{{25}{141}{Multiclass sparse discriminant analysis (MSDA)}{equation.2.3.25}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces  Algorithm for MSDA}}{141}{algorithm.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Multiclass sparse discriminant analysis (MSDA)}{141}{subsection.2.3.5}\protected@file@percent }
\newlabel{msdamodel}{{2.3.5}{141}{Multiclass sparse discriminant analysis (MSDA)}{subsection.2.3.5}{}}
\@writefile{brf}{\backcite{yuan2006model}{{141}{2.3.5}{equation.2.3.22}}}
\newlabel{MSDA}{{23}{141}{Multiclass sparse discriminant analysis (MSDA)}{equation.2.3.23}{}}
\@writefile{brf}{\backcite{MSDA}{{141}{2.3.5}{equation.2.3.23}}}
\citation{catch}
\newlabel{algMmsdaupdate}{{26}{142}{Multiclass sparse discriminant analysis (MSDA)}{equation.2.3.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.6}Covariate-adjusted tensor classification in high dimensions (CATCH)}{142}{subsection.2.3.6}\protected@file@percent }
\newlabel{catchmodel}{{2.3.6}{142}{Covariate-adjusted tensor classification in high dimensions (CATCH)}{subsection.2.3.6}{}}
\@writefile{brf}{\backcite{catch}{{142}{2.3.6}{subsection.2.3.6}}}
\newlabel{TLDA-formula}{{27}{142}{Covariate-adjusted tensor classification in high dimensions (CATCH)}{equation.2.3.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.7}Covariates adjustment}{142}{subsection.2.3.7}\protected@file@percent }
\newlabel{sec:covlam}{{2.3.7}{142}{Covariates adjustment}{subsection.2.3.7}{}}
\newlabel{alpha.MLE1}{{29}{142}{Covariates adjustment}{equation.2.3.29}{}}
\citation{MASS}
\citation{Matrix}
\citation{tensr}
\citation{glmnet}
\citation{Burczynski2006}
\citation{MSDA}
\citation{Zhong2015}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Method description and major parameters. Penalty parameter $\lambda $ controls the size of $\ell _1$-penalty. Parameter \code  {dfmax} limits the maximum number of non-zero variables. Parameter \code  {model} specifies the version of implementation for MSDA.}}{143}{table.caption.5}\protected@file@percent }
\newlabel{tab:modelsum}{{2}{143}{Method description and major parameters. Penalty parameter $\lambda $ controls the size of $\ell _1$-penalty. Parameter \code {dfmax} limits the maximum number of non-zero variables. Parameter \code {model} specifies the version of implementation for MSDA}{table.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.8}Selection of the tuning parameter}{143}{subsection.2.3.8}\protected@file@percent }
\newlabel{sec:tune}{{2.3.8}{143}{Selection of the tuning parameter}{subsection.2.3.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Using the R package}{143}{section.2.4}\protected@file@percent }
\newlabel{sec: usage}{{2.4}{143}{Using the R package}{section.2.4}{}}
\@writefile{brf}{\backcite{MASS}{{143}{2.4}{section.2.4}}}
\@writefile{brf}{\backcite{Matrix}{{143}{2.4}{section.2.4}}}
\@writefile{brf}{\backcite{tensr}{{143}{2.4}{section.2.4}}}
\@writefile{brf}{\backcite{glmnet}{{143}{2.4}{section.2.4}}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Data set dat.vec. Variables type and dimension are listed.}}{144}{table.caption.6}\protected@file@percent }
\newlabel{tab:datvec}{{3}{144}{Data set dat.vec. Variables type and dimension are listed}{table.caption.6}{}}
\@writefile{brf}{\backcite{Burczynski2006}{{144}{2.4}{table.caption.6}}}
\@writefile{brf}{\backcite{MSDA}{{144}{2.4}{table.caption.6}}}
\@writefile{brf}{\backcite{Zhong2015}{{144}{2.4}{table.caption.6}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Core functions}{144}{subsection.2.4.1}\protected@file@percent }
\newlabel{sec:core}{{2.4.1}{144}{Core functions}{subsection.2.4.1}{}}
\citation{ROAD}
\citation{Clemmensen}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Solution path of five selected variables in a DSDA model. Five trends correspond to the parameter values of five elements given different parameter $\lambda $ values. }}{145}{figure.caption.7}\protected@file@percent }
\newlabel{fig:dsdasp}{{4}{145}{Solution path of five selected variables in a DSDA model. Five trends correspond to the parameter values of five elements given different parameter $\lambda $ values}{figure.caption.7}{}}
\@writefile{brf}{\backcite{ROAD}{{145}{2.4.1}{figure.caption.8}}}
\@writefile{brf}{\backcite{Clemmensen}{{145}{2.4.1}{figure.caption.8}}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The distribution of the 1st variable in simulated data set among two classes before transformation and after transformation. The top row is before transformation. The second row is after pooled transformation. The bottom row is after na\"{i}ve transformation.}}{146}{figure.caption.8}\protected@file@percent }
\newlabel{fig:sesda}{{5}{146}{The distribution of the 1st variable in simulated data set among two classes before transformation and after transformation. The top row is before transformation. The second row is after pooled transformation. The bottom row is after na\"{i}ve transformation}{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Parameters in ROAD vs. Parameters in DSDA. Notice that the parameters in DSDA are double those of SOS.}}{146}{figure.caption.9}\protected@file@percent }
\newlabel{fig:param}{{6}{146}{Parameters in ROAD vs. Parameters in DSDA. Notice that the parameters in DSDA are double those of SOS}{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The GDS data projected onto the two principle components of $\mathbf  {X}\boldsymbol  {\beta }$. Three classes are separated.}}{147}{figure.caption.10}\protected@file@percent }
\newlabel{fig:msdagds}{{7}{147}{The GDS data projected onto the two principle components of $\mbX \bolbeta $. Three classes are separated}{figure.caption.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Data set dat.ten. Variables type and dimension are listed.}}{147}{table.caption.11}\protected@file@percent }
\newlabel{tab:datten}{{4}{147}{Data set dat.ten. Variables type and dimension are listed}{table.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Other functions}{148}{subsection.2.4.2}\protected@file@percent }
\newlabel{Sec:otherfun}{{2.4.2}{148}{Other functions}{subsection.2.4.2}{}}
\citation{ADHD}
\citation{Clemmensen}
\citation{glmnet}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces ADHD classification. Average error rates based on 100 replicates and running time of 20 replicates are reported.}}{149}{table.caption.12}\protected@file@percent }
\newlabel{tab: adhd}{{5}{149}{ADHD classification. Average error rates based on 100 replicates and running time of 20 replicates are reported}{table.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Real data example}{149}{section.2.5}\protected@file@percent }
\newlabel{sec: data}{{2.5}{149}{Real data example}{section.2.5}{}}
\@writefile{brf}{\backcite{ADHD}{{149}{2.5}{section.2.5}}}
\@writefile{brf}{\backcite{Clemmensen}{{149}{2.5}{section.2.5}}}
\@writefile{brf}{\backcite{glmnet}{{149}{2.5}{section.2.5}}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Discussion}{150}{section.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {.1}Appendices}{150}{section.Alph0.1}\protected@file@percent }
\newlabel{sec:appendix}{{.1}{150}{Appendices}{section.Alph0.1}{}}
\@writefile{toc}{\contentsline {section}{Appendices}{150}{section.Alph0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Tensor notation}{150}{subsection.Alph0.1.1}\protected@file@percent }
\newlabel{Append.A}{{A}{150}{Tensor notation}{subsection.Alph0.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Simulation code}{150}{subsection.Alph0.1.2}\protected@file@percent }
\bibdata{pan-mai-zhang}
\bibcite{Matrix}{{1}{2016}{{Bates and Maechler}}{{}}}
\bibcite{ADHD}{{2}{2017}{{Bellec et~al.}}{{Bellec, Chu, Chouinard-Decorte, Benhajali, Margulies, and Craddock}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C}Estimation of covariance matrices in the TDA/CATCH model}{151}{subsection.Alph0.1.3}\protected@file@percent }
\newlabel{Appendix.C}{{C}{151}{Estimation of covariance matrices in the TDA/CATCH model}{subsection.Alph0.1.3}{}}
\newlabel{sigma.hat}{{30}{151}{Estimation of covariance matrices in the TDA/CATCH model}{equation.Alph0.1.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D}Definition of F-test statistic}{151}{subsection.Alph0.1.4}\protected@file@percent }
\bibcite{bickel2008}{{3}{2008}{{Bickel and Levina}}{{}}}
\bibcite{Burczynski2006}{{4}{2006}{{Burczynski et~al.}}{{Burczynski, Peterson, Twine, A~Zuberek, J~Brodeur, Casciotti, Maganti, S~Reddy, Strahs, Immermann, Spinelli, Schwertschlag, M~Slager, M~Cotreau, and J~Dorner}}}
\bibcite{cai2011constrained}{{5}{2011}{{Cai et~al.}}{{Cai, Liu, and Luo}}}
\bibcite{chi2012tensors}{{6}{2012}{{Chi and Kolda}}{{}}}
\bibcite{sparseLDA}{{7}{2016}{{Clemmensen and Kuhn}}{{}}}
\bibcite{Clemmensen}{{8}{2011}{{Clemmensen et~al.}}{{Clemmensen, Hastie, Witten, and Ersb{\o }ll}}}
\bibcite{dettling2004bagboosting}{{9}{2004}{{Dettling}}{{}}}
\bibcite{fan2008high}{{10}{2008}{{Fan and Fan}}{{}}}
\bibcite{ROAD}{{11}{2012}{{Fan et~al.}}{{Fan, Feng, and Tong}}}
\bibcite{fan2015quadro}{{12}{2015}{{Fan et~al.}}{{Fan, Ke, Liu, and Xia}}}
\bibcite{FHT01}{{13}{2001}{{Friedman et~al.}}{{Friedman, Hastie, and Tibshirani}}}
\bibcite{glmnet}{{14}{2010}{{Friedman et~al.}}{{Friedman, Hastie, and Tibshirani}}}
\bibcite{tensr}{{15}{2016}{{Gerard and Hoff}}{{}}}
\bibcite{hand2006classifier}{{16}{2006}{{Hand}}{{}}}
\bibcite{hastie1994flexible}{{17}{1994}{{Hastie et~al.}}{{Hastie, Tibshirani, and Buja}}}
\bibcite{HNW14}{{18}{2014}{{Hoff et~al.}}{{Hoff, Niu, and Wellner}}}
\bibcite{jiang2015quda}{{19}{2015}{{Jiang et~al.}}{{Jiang, Wang, and Leng}}}
\bibcite{wellner1997}{{20}{1997}{{Klaassen and Wellner}}{{}}}
\bibcite{KoldaBader09Tensor}{{21}{2009}{{Kolda and Bader}}{{}}}
\bibcite{STDA}{{22}{2013}{{Lai et~al.}}{{Lai, Xu, Yang, Tang, and Zhang}}}
\bibcite{CMDA}{{23}{2014}{{Li and Schonfeld}}{{}}}
\bibcite{LiandShao2015}{{24}{2015}{{Li and Shao}}{{}}}
\bibcite{lim2000comparison}{{25}{2000}{{Lim et~al.}}{{Lim, Loh, and Shih}}}
\bibcite{Lin2003}{{26}{2003}{{Lin and Jeon}}{{}}}
\bibcite{SemiCov}{{27}{2009}{{Liu et~al.}}{{Liu, Lafferty, and Wasserman}}}
\bibcite{liu2017characterizing}{{28}{2017}{{Liu et~al.}}{{Liu, Yuan, and Zhao}}}
\bibcite{Mai2013note}{{29}{2013}{{Mai and Zou}}{{}}}
\bibcite{Mai2015ssda}{{30}{2015}{{Mai and Zou}}{{}}}
\bibcite{DSDA}{{31}{2012}{{Mai et~al.}}{{Mai, Zou, and Yuan}}}
\bibcite{MSDA}{{32}{2015}{{Mai et~al.}}{{Mai, Yang, and Zou}}}
\bibcite{michie1994machine}{{33}{1994}{{Michie et~al.}}{{Michie, Spiegelhalter, and Taylor}}}
\bibcite{Niu2015}{{34}{2015}{{Niu et~al.}}{{Niu, Hao, and Dong}}}
\bibcite{catch}{{35}{2019}{{Pan et~al.}}{{Pan, Mai, and Zhang}}}
\bibcite{TULIP}{{36}{2021}{{Pan et~al.}}{{Pan, Mai, and Zhang}}}
\bibcite{Shao2011}{{37}{2011}{{Shao et~al.}}{{Shao, Wang, Deng, and Wang}}}
\bibcite{Sun2015}{{38}{2015}{{Sun and Zhao}}{{}}}
\bibcite{Tibshirani1996}{{39}{1996}{{Tibshirani}}{{}}}
\bibcite{Tibshirani2002}{{40}{2002}{{Tibshirani et~al.}}{{Tibshirani, Hastie, Narasimhan, and Chu}}}
\bibcite{Trendafilov2007}{{41}{2007}{{Trendafilov and Jolliffe}}{{}}}
\bibcite{MASS}{{42}{2002}{{Venables and Ripley}}{{}}}
\bibcite{witten}{{43}{2011}{{Witten and Tibshirani}}{{}}}
\bibcite{wu2009sparse}{{44}{2009}{{Wu et~al.}}{{Wu, Zhang, Wang, Christiani, and Lin}}}
\bibcite{Xu2015}{{45}{2015}{{Xu et~al.}}{{Xu, Zhu, Zhu, and Li}}}
\bibcite{yuan2006model}{{46}{2006}{{Yuan and Lin}}{{}}}
\bibcite{Zeng2015}{{47}{2015}{{Zeng et~al.}}{{Zeng, Wu, Senhadji, and Shu}}}
\bibcite{Zhong2015}{{48}{2015}{{Zhong and Suslick}}{{}}}
\bibcite{Zhou2013}{{49}{2013}{{Zhou et~al.}}{{Zhou, Li, and Zhu}}}
\ttl@finishall
\gdef \@abspage@last{21}
