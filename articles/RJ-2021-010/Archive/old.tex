

\begin{comment}
 \section{Forward-backward scan for parameter estimation}
 \label{s3:scan}
 This section briefly discusses a novel forward-backward scan algorithm, proposed in \cite{kawaguchi2019scalable}, that reduces the computational complexity associated with parameter estimation from $O(n^2)$ to $O(n)$. Commonly-used optimization routines generally require the calculation of the log-pseudo likelihood (\ref{eq3:lpp}), the score function
 \begin{align}
\label{eq3:psh_score}
\dot{l}_j(\bbeta) = & \sum_{i=1}^n I(\delta_i\ep_i = 1) z_{ij} - \sum_{i = 1}^n I(\delta_i\ep_i = 1) \frac{ \sum_{k \in R_i} z_{kj} \tilde{w}_{ik}  \exp(\eta_k)}{\sum_{k \in R_i} \tilde{w}_{ik} \exp(\eta_k)}, 
\end{align}
and, in some cases, the Hessian diagonals
\begin{align}
\label{eq3:psh_hess}
\ddot{l}_{jj}(\bbeta) = & \sum_{i=1}^n I(\delta_i\ep_i = 1) \left[ \frac{ \sum_{k \in R_i} z_{kj}^2 \tilde{w}_{ik}  \exp(\eta_k)}{\sum_{k \in R_i} \tilde{w}_{ik} \exp(\eta_k)} -  \left\{ \frac{ \sum_{k \in R_i} z_{kj} \tilde{w}_{ik}  \exp(\eta_k)}{\sum_{k \in R_i} \tilde{w}_{ik} \exp(\eta_k)} \right\}^2 \right], 
\end{align}
where  $$\tilde{w}_{ik} = \hat{w}_k(X_i) = \hat{G}(X_i) / \hat{G}(X_i \mmin X_k), \quad k \in R_i,$$ 
$R_i = \{y:(X_y \geq X_i) \cup (X_y \leq X_i \cap \epsilon_y =  2)\}$ and
$\eta_k = \mathbf{z}_k^\prime\bbeta$ for use within cyclic coordinate descent. {\color{blue} Despite $\eta$ and $\hat{G}(X)$ being fixed quantities within the calculation of (\ref{eq3:lpp}), (\ref{eq3:psh_score}), and (\ref{eq3:psh_hess}), directly evaluating these quantities using the above formulas will require $O(n^2)$ operations due to the structure of the risk set within the double summation, and will be computationally taxing for large $n$.} Below we will show how to calculate the double summation linearly using a forward-backward scan algorithm, that allows us to compute (\ref{eq3:lpp}), (\ref{eq3:psh_score}), and (\ref{eq3:psh_hess}) in $O(n)$ time.

Before proceeding with the algorithm, we first define what we mean by a forward and backward scan. A forward (prefix) scan maps $\{a_1, a_2, \ldots, a_n\} \mapsto \{a_1, a_1 + a_2, \ldots, \sum_{i=1}^n a_i\}$; whereas a backward (prefix) scan maps to $\{\sum_{i=1}^n a_i, \sum_{i=2}^n a_i, \ldots, a_1\}$. 
First, note that $R_i$ partitions into two disjoint subsets: $R_i(1) = \{y:X_y \geq X_i\}$ and $R_i(2) = \{y:(X_y \leq X_i \cap \epsilon_y =  2) \}$. Here $R_i(1)$ is the set of observations that have an observed event time after $X_i$ and $R_i(2)$ is the set of observations that have observed the competing event before time $X_i$. Further, $\tilde{w}_{ik} = 1$ if $k \in R_i(1)$ and $\tilde{w}_{ik} = \hat{G}(X_i) / \hat{G}(X_k),$ if $k \in R_i(2)$. Since $R_i(1)$ and $R_i(2)$ are disjoint, we can write the double summation of, for example, the score function (\ref{eq3:psh_score}) as
\begin{align}
\label{eq3:psh_score2}
\sum_{i = 1}^n I(\delta_i\ep_i = 1) \frac{ \sum_{k \in R_i(1)} z_{kj} \exp(\eta_k) +   \hat{G}(X_i)\sum_{k \in R_i(2)} z_{kj} \exp(\eta_k) / \hat{G}(X_k)}{\sum_{k \in R_i(1)} \exp(\eta_k) +  \hat{G}(X_i) \sum_{k \in R_i(2)} \exp(\eta_k) / \hat{G}(X_k)}. 
\end{align}
We will first tackle the denominator term $\sum_{k \in R_i(1)} \exp(\eta_k) +  \hat{G}(X_i) \sum_{k \in R_i(2)} \exp(\eta_k) / \hat{G}(X_k)$.
If we arrange the observed event times in decreasing order, we see that  $\sum_{k \in R_i(1)} \exp(\eta_k)$ is a series of cumulative sums. For example, given $X_i > X_{i'}$, the set $R_{i'}(1)$  consists of the observations from $R_i(1)$ and  the set of observations $\{y: X_y \in [X_{i'}, X_{i})\}$, therefore $\sum_{k \in R_{i'}(1)} \exp(\eta_k) = \sum_{k \in R_i(1)}  \exp(\eta_k) + \sum_{k \in \{y: X_y \in [X_{i'}, X_{i})\}} \exp(\eta_k)$ and  thus calculating $\sum_{k \in R_i(1)} \exp(\eta_k)$ for all $i = 1, \ldots, n$ requires $O(n)$ calculations in total. However, $ \hat{G}(X_i) \sum_{k \in R_i(2)} \exp(\eta_k) / \hat{G}(X_k)$ does not monotonically increase as the event times decrease. Instead, we observe that $ \hat{G}(X_i) \sum_{k \in R_i(2)} \exp(\eta_k) / \hat{G}(X_k)$  is a series of cumulative sums as the event times increase. Thus calculating the denominator term will requires two scans: one forward scan going forward from largest observed event time to smallest to calculate $\sum_{k \in R_i(1)} \exp(\eta_k) $ and one backward scan from smallest observed event time to largest to calculate $ \hat{G}(X_i) \sum_{k \in R_i(2)} \exp(\eta_k) / \hat{G}(X_k)$. Likewise, we calculate both $\sum_{k \in R_i} z_{kj} \exp(\eta_k)$ and $\sum_{k \in R_i} z_{kj}^2 \exp(\eta_k)$ in linear time since the terms $z_{kj}$ and $z_{kj}^2$ are multiplicative constants that do not affect the cumulative structures of the summations. As a consequence, the ratio in the double summation is available in $O(n)$ time.

Furthermore, the outer summation of subjects who observe the event of interest is also a cumulative sum since, provided that $X_i > X_{i'}$ and both $\delta_i = 1$ and $\delta_{i'} = 1$,
\begin{align}
\sum_{l = 1}^{i} I(\delta_{l} \ep_l = 1) \frac{ \sum_{k \in R_l} z_{kj} \exp(\eta_k)}{\sum_{k \in R_l} \exp(\eta_k)} & = \sum_{l = 1}^{i'} I(\delta_{l}\ep_l = 1) \frac{ \sum_{k \in R_l} z_{kj} \exp(\eta_k)}{\sum_{k \in R_l} \exp(\eta_k)} \\
&  + I(\delta_{i}\ep_i = 1) \frac{ \sum_{k \in R_{i}} z_{kj} \exp(\eta_k)}{\sum_{k \in R_{i}} \exp(\eta_k)} , 
\end{align}
that also only requires $O(n)$ calculations since the ratios are precomputed in $O(n)$ calculations and thus the score function (\ref{eq3:psh_score}) can be calculated in linear time. Similarly, both the log-pseudo likelihood (\ref{eq3:lpp}) and the diagonal elements of the Hessian (\ref{eq3:psh_hess}) are also calculated linearly. We refer readers to \cite{kawaguchi2019scalable} for a thorough disucssion.
\end{comment}