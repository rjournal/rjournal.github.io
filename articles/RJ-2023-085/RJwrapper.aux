\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{abbrvnat}
\citation{sacks1989design}
\citation{bayarri2007computer}
\citation{kennedy2001bayesian}
\citation{bayarri2007computer,higdon2008computer,paulo2012calibration,chang2016calibrating,chang2022ice}
\citation{arendt2012quantification}
\citation{gu2018sgasp}
\citation{williamson2013history}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}RobustCalibration: Robust Calibration of Computer Models in R}{83}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction}{83}{section.2.1}\protected@file@percent }
\@writefile{brf}{\backcite{sacks1989design}{{83}{2.1}{section.2.1}}}
\@writefile{brf}{\backcite{bayarri2007computer}{{83}{2.1}{section.2.1}}}
\newlabel{equ:calibration_no_discrepancy}{{1}{83}{Introduction}{equation.2.1.1}{}}
\newlabel{equ:calibration_discrepancy}{{2}{83}{Introduction}{equation.2.1.2}{}}
\@writefile{brf}{\backcite{kennedy2001bayesian}{{83}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{bayarri2007computer}{{83}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{higdon2008computer}{{83}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{paulo2012calibration}{{83}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{chang2016calibrating}{{83}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{chang2022ice}{{83}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{arendt2012quantification}{{83}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{gu2018sgasp}{{83}{2.1}{equation.2.1.2}}}
\citation{tuo2015efficient,wong2017frequentist}
\citation{plumlee2017bayesian}
\citation{roustant2012dicekriging}
\citation{macdonald2015gpfit}
\citation{gu2018robustgasp}
\citation{hankin2005introducing}
\citation{palomo2015save}
\citation{carmassi2018calico}
\citation{wickham2011ggplot2}
\citation{kennedy2001bayesian}
\citation{gu2018robustgasp}
\citation{anderson2019magma}
\citation{ma2022multifidelity}
\@writefile{brf}{\backcite{williamson2013history}{{84}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{tuo2015efficient}{{84}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{wong2017frequentist}{{84}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{plumlee2017bayesian}{{84}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{roustant2012dicekriging}{{84}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{macdonald2015gpfit}{{84}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{gu2018robustgasp}{{84}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{hankin2005introducing}{{84}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{palomo2015save}{{84}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{carmassi2018calico}{{84}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{wickham2011ggplot2}{{84}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{kennedy2001bayesian}{{84}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{gu2018robustgasp}{{84}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{anderson2019magma}{{84}{2.1}{equation.2.1.2}}}
\@writefile{brf}{\backcite{ma2022multifidelity}{{84}{2.1}{equation.2.1.2}}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}An overview of \href  {https://CRAN.R-project.org/package=RobustCalibration}{{\normalfont  \fontseries  {b}\selectfont  RobustCalibration}}}{84}{section.2.2}\protected@file@percent }
\citation{anderson2019magma}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Schematic overview of the \href  {https://CRAN.R-project.org/package=RobustCalibration}{{\normalfont  \fontseries  {b}\selectfont  RobustCalibration}} package. The left panel compares the expected predictive accuracy and calibration accuracy by different calibration methods. The \code  {calibration} and \code  {calibration\_MS} in the right panel are two main functions for parameter estimation for observations from single and multiple sources, respectively. The arguments of these functions are given in blue boxes. The object classes \code  {calibration} and \code  {calibration\_MS} (orange boxes) can be supplied in \code  {predict.rcalibration} and \code  {predict\_MS.rcalibration\_MS} functions for making predictions. }}{85}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:schematic_graph}{{1}{85}{Schematic overview of the \CRANpkg {RobustCalibration} package. The left panel compares the expected predictive accuracy and calibration accuracy by different calibration methods. The \code {calibration} and \code {calibration\_MS} in the right panel are two main functions for parameter estimation for observations from single and multiple sources, respectively. The arguments of these functions are given in blue boxes. The object classes \code {calibration} and \code {calibration\_MS} (orange boxes) can be supplied in \code {predict.rcalibration} and \code {predict\_MS.rcalibration\_MS} functions for making predictions}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Main functions}{85}{subsection.2.2.1}\protected@file@percent }
\@writefile{brf}{\backcite{anderson2019magma}{{85}{2.2.1}{subsection.2.2.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}The rcalibration function}{85}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}The predict.rcalibration function}{86}{subsection.2.2.3}\protected@file@percent }
\citation{liu1989limited}
\citation{nloptr2014}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}The rcalibration\_MS function and the predict\_MS.rcalibration\_MS function}{87}{subsection.2.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Methods and examples}{87}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}No-discrepancy calibration}{87}{subsection.2.3.1}\protected@file@percent }
\@writefile{brf}{\backcite{liu1989limited}{{87}{2.3.1}{subsection.2.3.1}}}
\@writefile{brf}{\backcite{nloptr2014}{{87}{2.3.1}{subsection.2.3.1}}}
\citation{bayarri2007framework}
\citation{bayarri2007framework}
\newlabel{equ:post}{{3}{88}{No-discrepancy calibration}{equation.2.3.3}{}}
\@writefile{brf}{\backcite{bayarri2007framework}{{88}{2.3.1}{equation.2.3.3}}}
\@writefile{brf}{\backcite{bayarri2007framework}{{88}{2.3.1}{equation.2.3.3}}}
\citation{bayarri2007framework}
\citation{bayarri2007framework}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Gaussian stochastic process models of discrepancy functions}{89}{subsection.2.3.2}\protected@file@percent }
\newlabel{equ:MLE_GaSP}{{4}{89}{Gaussian stochastic process models of discrepancy functions}{equation.2.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Predictions and posterior samples by the \href  {https://CRAN.R-project.org/package=RobustCalibration}{{\normalfont  \fontseries  {b}\selectfont  RobustCalibration}} package for the example introduced in \cite  {bayarri2007framework}. In the left and middle panels, the unknown reality is graphed as black curves, and field observations that contain with 3 replicates at each observable input are plotted as black {dots}. In the left panel, predictions of reality based on calibrated computer model with trend by GaSP, S-GaSP and no-discrepancy calibration are graphed as light blue, blue and red curves, respectively. `CM' denotes the computer model and the shaded area is the $95\%$ posterior predictive interval by the no-discrepancy calibration. In the middle panel, predictions based on the calibrated computer model, discrepancy, and the trend by GaSP and S-GaSP are graphed as light blue and blue curves, respectively. The shaded area is the $95\%$ predictive interval by the GaSP calibration. After burn-in posterior samples of calibration parameter $\theta $ and mean parameter $\theta _m$ are plotted in the right panel. }}{90}{figure.caption.3}\protected@file@percent }
\@writefile{brf}{\backcite{bayarri2007framework}{{90}{2}{figure.caption.3}}}
\newlabel{fig:bayarri_2007}{{2}{90}{Predictions and posterior samples by the \CRANpkg {RobustCalibration} package for the example introduced in \cite {bayarri2007framework}. In the left and middle panels, the unknown reality is graphed as black curves, and field observations that contain with 3 replicates at each observable input are plotted as black {dots}. In the left panel, predictions of reality based on calibrated computer model with trend by GaSP, S-GaSP and no-discrepancy calibration are graphed as light blue, blue and red curves, respectively. `CM' denotes the computer model and the shaded area is the $95\%$ posterior predictive interval by the no-discrepancy calibration. In the middle panel, predictions based on the calibrated computer model, discrepancy, and the trend by GaSP and S-GaSP are graphed as light blue and blue curves, respectively. The shaded area is the $95\%$ predictive interval by the GaSP calibration. After burn-in posterior samples of calibration parameter $\theta $ and mean parameter $\theta _m$ are plotted in the right panel}{figure.caption.3}{}}
\newlabel{equ:predict_dist_gasp}{{5}{90}{Gaussian stochastic process models of discrepancy functions}{equation.2.3.5}{}}
\newlabel{equ:post}{{6}{90}{Gaussian stochastic process models of discrepancy functions}{equation.2.3.6}{}}
\citation{gu2019jointly}
\citation{bayarri2007framework}
\citation{gu2018sgasp}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Kernel functions implemented in \href  {https://CRAN.R-project.org/package=RobustCalibration}{{\normalfont  \fontseries  {b}\selectfont  RobustCalibration}}. For any $\mathbf  x_a, \mathbf  x_b \in \mathcal  X$, denote $\mathbf  d=\mathbf  x_a-\mathbf  x_d=(d_1,...,d_{p_x})^T$. For any kernel $K$, the discretized scaled kernel $K_{Z_d}(\mathbf  x_a,\mathbf  x_b )$ with discretization points on observed points $\mathbf  x_1,..., \mathbf  x_n$ is implemented in the S-GaSP calibration, where $ {\mathbf  R}_z:=\mathbf  R+n\mathbf  I_n / \lambda _z $, and $\mathbf  r(\mathbf  x)=(K(\mathbf  x, \mathbf  x_1),...,K(\mathbf  x, \mathbf  x_n))^T$ for any $\mathbf  x$. }}{91}{table.caption.4}\protected@file@percent }
\newlabel{tab:kernel}{{1}{91}{Kernel functions implemented in \CRANpkg {RobustCalibration}. For any $\mathbf x_a, \mathbf x_b \in \mathcal X$, denote $\mathbf d=\mathbf x_a-\mathbf x_d=(d_1,...,d_{p_x})^T$. For any kernel $K$, the discretized scaled kernel $K_{Z_d}(\mathbf x_a,\mathbf x_b )$ with discretization points on observed points $\mathbf x_1,..., \mathbf x_n$ is implemented in the S-GaSP calibration, where $ {\mathbf R}_z:=\mathbf R+n\mathbf I_n / \lambda _z $, and $\mathbf r(\mathbf x)=(K(\mathbf x, \mathbf x_1),...,K(\mathbf x, \mathbf x_n))^T$ for any $\mathbf x$}{table.caption.4}{}}
\@writefile{brf}{\backcite{gu2019jointly}{{91}{2.3.2}{equation.2.3.6}}}
\@writefile{brf}{\backcite{bayarri2007framework}{{91}{2.3.2}{equation.2.3.6}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Scaled Gaussian stochastic process models of discrepancy functions}{91}{subsection.2.3.3}\protected@file@percent }
\@writefile{brf}{\backcite{gu2018sgasp}{{91}{2.3.3}{subsection.2.3.3}}}
\citation{gu2022theoretical}
\citation{gu2018sgasp}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Predictive accuracy and uncertainty assessment. The RMSE of the out-of-sample prediction based on the calibrated computer model (CM) and trend are shown in the second column. The predictive RMSE by the summation of the calibrated computer model, trend and discrepancy is given in the third column. The proportion of the held-out reality covered in the $95\%$ predictive interval, and average lengths of predictive intervals are given in the last two columns, respectively. }}{92}{table.caption.5}\protected@file@percent }
\newlabel{tab:prediction_bayarri_2007}{{2}{92}{Predictive accuracy and uncertainty assessment. The RMSE of the out-of-sample prediction based on the calibrated computer model (CM) and trend are shown in the second column. The predictive RMSE by the summation of the calibrated computer model, trend and discrepancy is given in the third column. The proportion of the held-out reality covered in the $95\%$ predictive interval, and average lengths of predictive intervals are given in the last two columns, respectively}{table.caption.5}{}}
\newlabel{equ:delta_z_d}{{7}{92}{Scaled Gaussian stochastic process models of discrepancy functions}{equation.2.3.7}{}}
\newlabel{equ:p_Z_d}{{8}{92}{Scaled Gaussian stochastic process models of discrepancy functions}{equation.2.3.8}{}}
\newlabel{equ:g_Z_d}{{9}{92}{Scaled Gaussian stochastic process models of discrepancy functions}{equation.2.3.9}{}}
\@writefile{brf}{\backcite{gu2022theoretical}{{92}{2.3.3}{equation.2.3.9}}}
\@writefile{brf}{\backcite{gu2018sgasp}{{92}{2.3.3}{equation.2.3.9}}}
\newlabel{equ:sigma_2_K_z_d}{{10}{92}{Scaled Gaussian stochastic process models of discrepancy functions}{equation.2.3.10}{}}
\newlabel{equ:R_z}{{11}{92}{Scaled Gaussian stochastic process models of discrepancy functions}{equation.2.3.11}{}}
\citation{bayarri2007framework}
\citation{lorenz1996predictability}
\citation{maclean2020surrogate,brajard2020combining}
\newlabel{equ:MLE_SGaSP}{{12}{93}{Scaled Gaussian stochastic process models of discrepancy functions}{equation.2.3.12}{}}
\@writefile{brf}{\backcite{bayarri2007framework}{{93}{2.3.3}{equation.2.3.12}}}
\@writefile{brf}{\backcite{lorenz1996predictability}{{93}{2.3.3}{equation.2.3.12}}}
\@writefile{brf}{\backcite{maclean2020surrogate}{{93}{2.3.3}{equation.2.3.13}}}
\@writefile{brf}{\backcite{brajard2020combining}{{93}{2.3.3}{equation.2.3.13}}}
\newlabel{equ:no_discrepancy}{{14}{93}{Scaled Gaussian stochastic process models of discrepancy functions}{equation.2.3.14}{}}
\newlabel{equ:with_discrepancy}{{15}{93}{Scaled Gaussian stochastic process models of discrepancy functions}{equation.2.3.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The reality and full observations of Lorenz-96 system in Scenario 1 are plotted in the upper left panel and upper middle panel, respectively, where the black circles are the $5\%$ observations used for model calibration. Posterior samples of calibration parameters of different calibration methods are plotted in the upper right panel. The lower panels give the difference between the reality and calibrated computer model of all latent states. }}{94}{figure.caption.6}\protected@file@percent }
\newlabel{fig:lorenz_96}{{3}{94}{The reality and full observations of Lorenz-96 system in Scenario 1 are plotted in the upper left panel and upper middle panel, respectively, where the black circles are the $5\%$ observations used for model calibration. Posterior samples of calibration parameters of different calibration methods are plotted in the upper right panel. The lower panels give the difference between the reality and calibrated computer model of all latent states}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Calibration with repeated experiments}{94}{subsection.2.3.4}\protected@file@percent }
\newlabel{equ:lik_replicates}{{16}{94}{Calibration with repeated experiments}{equation.2.3.16}{}}
\citation{simakov2019modernizing}
\citation{anderson2019magma}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The reality of the discrepancy-included Lorenz-96 system (Scenario 2) is plotted in the upper left panel. The simulated observations are plotted in the upper middle panel, where the $5\%$ of the observations plotted as black circles are used in model calibration. Posterior samples of calibration parameters of different calibration methods are plotted in the upper right panel. The lower panels show the differences between the reality and the predictive mean of all latent states. }}{95}{figure.caption.7}\protected@file@percent }
\newlabel{fig:lorenz_96_discrepancy}{{4}{95}{The reality of the discrepancy-included Lorenz-96 system (Scenario 2) is plotted in the upper left panel. The simulated observations are plotted in the upper middle panel, where the $5\%$ of the observations plotted as black circles are used in model calibration. Posterior samples of calibration parameters of different calibration methods are plotted in the upper right panel. The lower panels show the differences between the reality and the predictive mean of all latent states}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Statistical emulators}{95}{subsection.2.3.5}\protected@file@percent }
\citation{santner2003design}
\citation{roustant2012dicekriging}
\citation{macdonald2015gpfit}
\citation{gu2018robustgasp}
\citation{palomo2015save,carmassi2018calico}
\citation{higdon2008computer,ma2022multifidelity,li2022efficient,fang2022reliable}
\citation{gu2019jointly}
\citation{bayarri2007framework,liu2009modularization}
\citation{box1956application}
\citation{box1956application}
\citation{soetaert2010solving}
\citation{box1956application}
\@writefile{brf}{\backcite{simakov2019modernizing}{{96}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{anderson2019magma}{{96}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{santner2003design}{{96}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{roustant2012dicekriging}{{96}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{macdonald2015gpfit}{{96}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{gu2018robustgasp}{{96}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{palomo2015save}{{96}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{carmassi2018calico}{{96}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{higdon2008computer}{{96}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{ma2022multifidelity}{{96}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{li2022efficient}{{96}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{fang2022reliable}{{96}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{gu2019jointly}{{96}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{bayarri2007framework}{{96}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{liu2009modularization}{{96}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{box1956application}{{96}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{box1956application}{{96}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{soetaert2010solving}{{96}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{box1956application}{{96}{2.3.5}{subsection.2.3.5}}}
\citation{anderson2019magma}
\citation{Zebker1997,agram2015noise}
\citation{gu2022calibration}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Comparison between the Bayesian model calibration based on the numerical solver and the PP-GaSP emulator of the computer model. In the left panel, the green solid curve is the predictive mean from the calibrated computer model and the discrepancy function, and the {blue} dashed curves are predictions from the calibrated computer model alone, both of which call the numerical solver for each posterior sample. The same result based on the emulator is plotted as the {green} curves. The black dots are field observations and the shaded area is the $95\%$ predictive interval of the reality by the approach that uses the PP-GaSP emulator. In the right panel, posterior samples based on the numerical solver and the PP-GaSP emulator are denoted by the {blue} dots and {green} dots, respectively. }}{98}{figure.caption.8}\protected@file@percent }
\newlabel{fig:box_model}{{5}{98}{Comparison between the Bayesian model calibration based on the numerical solver and the PP-GaSP emulator of the computer model. In the left panel, the green solid curve is the predictive mean from the calibrated computer model and the discrepancy function, and the {blue} dashed curves are predictions from the calibrated computer model alone, both of which call the numerical solver for each posterior sample. The same result based on the emulator is plotted as the {green} curves. The black dots are field observations and the shaded area is the $95\%$ predictive interval of the reality by the approach that uses the PP-GaSP emulator. In the right panel, posterior samples based on the numerical solver and the PP-GaSP emulator are denoted by the {blue} dots and {green} dots, respectively}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.6}Calibration with multiple sources of observations}{98}{subsection.2.3.6}\protected@file@percent }
\@writefile{brf}{\backcite{anderson2019magma}{{98}{2.3.6}{subsection.2.3.6}}}
\@writefile{brf}{\backcite{Zebker1997}{{98}{2.3.6}{subsection.2.3.6}}}
\@writefile{brf}{\backcite{agram2015noise}{{98}{2.3.6}{subsection.2.3.6}}}
\@writefile{brf}{\backcite{gu2022calibration}{{98}{2.3.6}{subsection.2.3.6}}}
\newlabel{equ:measurement_bias}{{17}{98}{Calibration with multiple sources of observations}{equation.2.3.17}{}}
\newlabel{equ:multi_calibration_measurement_bias}{{18}{98}{Calibration with multiple sources of observations}{equation.2.3.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Comparison between modeling individual data and aggregated data for simulation from Equation (\ref {equ:multi_calibration_measurement_bias}). The upper left and right panels give the reality and model discrepancy, whereas the lower two panels give the measurement bias for the first two sources. The estimation results from GaSP, S-GaSP, GaSP Stack and S-GaSP calibration are plotted as red, blue, pink and cyan curves. The observations from the first two sources are graphed as the triangles and dots in the upper left panel. }}{99}{figure.caption.9}\protected@file@percent }
\newlabel{fig:multicalibration_eg}{{6}{99}{Comparison between modeling individual data and aggregated data for simulation from Equation (\ref {equ:multi_calibration_measurement_bias}). The upper left and right panels give the reality and model discrepancy, whereas the lower two panels give the measurement bias for the first two sources. The estimation results from GaSP, S-GaSP, GaSP Stack and S-GaSP calibration are plotted as red, blue, pink and cyan curves. The observations from the first two sources are graphed as the triangles and dots in the upper left panel}{figure.caption.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces The RMSE of the reality, discrepancy and measurement bias, where the smaller number indicates a smaller error. For measurement bias, we average the RMSE for each source of data. }}{100}{table.caption.10}\protected@file@percent }
\newlabel{tab:prediction_multicalibration}{{3}{100}{The RMSE of the reality, discrepancy and measurement bias, where the smaller number indicates a smaller error. For measurement bias, we average the RMSE for each source of data}{table.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Concluding remarks}{100}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Appendix}{100}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Auxiliary facts}{100}{subsection.2.5.1}\protected@file@percent }
\newlabel{item:derivative_1}{{1}{100}{Auxiliary facts}{Item.1}{}}
\citation{nloptr2014}
\newlabel{item:derivative_2}{{3}{101}{Auxiliary facts}{Item.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Likelihood functions and posterior distributions}{101}{subsection.2.5.2}\protected@file@percent }
\newlabel{equ:PL_GP}{{19}{101}{Likelihood functions and posterior distributions}{equation.2.5.19}{}}
\@writefile{brf}{\backcite{nloptr2014}{{101}{2.5.2}{equation.2.5.19}}}
\citation{gu2019jointly}
\citation{gu2019jointly}
\bibdata{gu.bib}
\bibcite{agram2015noise}{{1}{2015}{{Agram and Simons}}{{}}}
\bibcite{anderson2019magma}{{2}{2019}{{Anderson et~al.}}{{Anderson, Johanson, Patrick, Gu, Segall, Poland, Montgomery-Brown, and Miklius}}}
\bibcite{arendt2012quantification}{{3}{2012}{{Arendt et~al.}}{{Arendt, Apley, and Chen}}}
\bibcite{bayarri2007computer}{{4}{2007{a}}{{Bayarri et~al.}}{{Bayarri, Berger, Cafeo, Garcia-Donato, Liu, Palomo, Parthasarathy, Paulo, Sacks, and Walsh}}}
\@writefile{brf}{\backcite{gu2019jointly}{{102}{2.5.2}{equation.2.5.19}}}
\@writefile{brf}{\backcite{gu2019jointly}{{102}{2.5.2}{equation.2.5.19}}}
\bibcite{bayarri2007framework}{{5}{2007{b}}{{Bayarri et~al.}}{{Bayarri, Berger, Paulo, Sacks, Cafeo, Cavendish, Lin, and Tu}}}
\bibcite{box1956application}{{6}{1956}{{Box and Coutie}}{{}}}
\bibcite{brajard2020combining}{{7}{2020}{{Brajard et~al.}}{{Brajard, Carrassi, Bocquet, and Bertino}}}
\bibcite{carmassi2018calico}{{8}{2018}{{Carmassi et~al.}}{{Carmassi, Barbillon, Chiodetti, Keller, and Parent}}}
\bibcite{chang2016calibrating}{{9}{2016}{{Chang et~al.}}{{Chang, Haran, Applegate, and Pollard}}}
\bibcite{chang2022ice}{{10}{2022}{{Chang et~al.}}{{Chang, Konomi, Karagiannis, Guan, and Haran}}}
\bibcite{fang2022reliable}{{11}{2022}{{Fang et~al.}}{{Fang, Gu, and Wu}}}
\bibcite{gu2019jointly}{{12}{2019}{{Gu}}{{}}}
\bibcite{gu2018sgasp}{{13}{2018}{{Gu and Wang}}{{}}}
\bibcite{gu2018robustgasp}{{14}{2019}{{Gu et~al.}}{{Gu, Palomo, and Berger}}}
\bibcite{gu2022theoretical}{{15}{2022}{{Gu et~al.}}{{Gu, Xie, and Wang}}}
\bibcite{gu2022calibration}{{16}{2023}{{Gu et~al.}}{{Gu, Anderson, and McPhillips}}}
\bibcite{hankin2005introducing}{{17}{2005}{{Hankin}}{{}}}
\bibcite{higdon2008computer}{{18}{2008}{{Higdon et~al.}}{{Higdon, Gattiker, Williams, and Rightley}}}
\bibcite{kennedy2001bayesian}{{19}{2001}{{Kennedy and O'Hagan}}{{}}}
\bibcite{li2022efficient}{{20}{2022}{{Li et~al.}}{{Li, Zhou, Sebastian, Wu, and Gu}}}
\bibcite{liu1989limited}{{21}{1989}{{Liu and Nocedal}}{{}}}
\bibcite{liu2009modularization}{{22}{2009}{{Liu et~al.}}{{Liu, Bayarri, and Berger}}}
\bibcite{lorenz1996predictability}{{23}{1996}{{Lorenz}}{{}}}
\bibcite{ma2022multifidelity}{{24}{2022}{{Ma et~al.}}{{Ma, Karagiannis, Konomi, Asher, Toro, and Cox}}}
\bibcite{macdonald2015gpfit}{{25}{2015}{{MacDonald et~al.}}{{MacDonald, Ranjan, Chipman, et~al.}}}
\bibcite{maclean2020surrogate}{{26}{2020}{{Maclean and Spiller}}{{}}}
\bibcite{palomo2015save}{{27}{2015}{{Palomo et~al.}}{{Palomo, Paulo, Garc{\'\i }a-Donato, et~al.}}}
\bibcite{paulo2012calibration}{{28}{2012}{{Paulo et~al.}}{{Paulo, Garc{\'\i }a-Donato, and Palomo}}}
\bibcite{plumlee2017bayesian}{{29}{2017}{{Plumlee}}{{}}}
\bibcite{roustant2012dicekriging}{{30}{2012}{{Roustant et~al.}}{{Roustant, Ginsbourger, and Deville}}}
\bibcite{sacks1989design}{{31}{1989}{{Sacks et~al.}}{{Sacks, Welch, Mitchell, Wynn, et~al.}}}
\bibcite{santner2003design}{{32}{2003}{{Santner et~al.}}{{Santner, Williams, and Notz}}}
\bibcite{simakov2019modernizing}{{33}{2019}{{Simakov et~al.}}{{Simakov, Jones-Ivey, Akhavan-Safaei, Aghakhani, Jones, and Patra}}}
\bibcite{soetaert2010solving}{{34}{2010}{{Soetaert et~al.}}{{Soetaert, Petzoldt, and Setzer}}}
\bibcite{tuo2015efficient}{{35}{2015}{{Tuo and Wu}}{{}}}
\bibcite{wickham2011ggplot2}{{36}{2011}{{Wickham}}{{}}}
\bibcite{williamson2013history}{{37}{2013}{{Williamson et~al.}}{{Williamson, Goldstein, Allison, Blaker, Challenor, Jackson, and Yamazaki}}}
\bibcite{wong2017frequentist}{{38}{2017}{{Wong et~al.}}{{Wong, Storlie, and Lee}}}
\bibcite{nloptr2014}{{39}{2014}{{Ypma}}{{}}}
\bibcite{Zebker1997}{{40}{1997}{{Zebker et~al.}}{{Zebker, Rosen, and Hensley}}}
\ttl@finishall
\gdef \@abspage@last{22}
