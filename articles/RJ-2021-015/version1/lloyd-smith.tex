% !TeX root = RJwrapper.tex
\title{Multiple Discrete-Continuous Extreme Value Model Estimation and
Simulation in R: The rmdcev Package}
\author{by Patrick Lloyd-Smith}

\maketitle

\abstract{%
This paper introduces the package \pkg{rmdcev} in R for estimation and
simulation of multiple-discrete continuous extreme value (MDCEV) models
with individual heterogeneity.The models supported by \pkg{rmdcev} are
the MDCEV model, the latent class MDCEV model, and the random parameters
MDCEV model. The models are fit using maximum likelihood estimation or
Bayesian estimation. The \pkg{rmdcev} package also implements demand
forecasting and welfare calculation for policy simulation. The purpose
of this paper is to describe the MDCEV estimation and simulation
framework and to demonstrate the functionalities of \pkg{rmdcev} using
real datasets.
}

% Any extra LaTeX you need in the preamble

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Individual choice contexts are often characterized by both extensive
(i.e.~what alternative to choose) and intensive (i.e.~how much of an
alternative to consume) margins \citep{bhatmultiple2008}. These multiple
discrete-continuous choice situations are pervasive, arising in
transportation, marketing, health, and decisions regarding environmental
resources \citep{bhatmultiple2014}. The multiple-discrete continuous
extreme value (MDCEV) demand model, also commonly called Kuhn-Tucker
(KT) models in economics, is often employed to analyze these MDC
situations and substantial progress has been made in improving these
econometric modeling structures
\citep{vonhaefenkuhn-tucker2005, bhatmultiple2014}. Despite the large
potential applications for MDCEV models, there remains a gap between
this potential and actual examples of these models being used. One of
the reasons cited for the lack of widespread use of MDCEV models is that
estimating and simulating these models is challenging. The explanations
of methods used to work with these models are spread across many papers
and few user friendly software tools are available. The purpose of this
paper is to present a unified account for MDCEV estimation and
simulation alongside computer code.

This paper presents an overview of the R package \pkg{rmdcev} which can
estimate and simulate MDCEV models with discrete or continuous
unobserved individual heterogeneity. Incoporating preference
heterogeneity has been an important advancement in choice modeling.
Unobserved preference heterogeneity can be accomodated assuming
continuous distributions using random parameters or a latent class (LC)
specification assuming a discrete distribution where people can be
divided into distinct segments. Within each segment, the LC
specification assumes preference homogeneity. The models in \pkg{rmdcev}
can be fit using maximum likelihood estimation or Bayesian estimation.
The \pkg{rmdcev} package also implements demand forecasting and welfare
calculation for policy simulation. \pkg{rmdcev} is available from the
Comprehensive R Archive Network (CRAN) at
\url{https://CRAN.R-project.org/package=rmdcev}.

While there are several R packages available to estimate discrete choice
data such as \pkg{mlogit} \citep{mlogit2019} and \pkg{gmnl}
\citep{sarriasmultinomial2017}\footnote{\citet{sarriasmultinomial2017}
  provides a good overview of the different R packages available to
  estimate discrete choice models}, there are less options for users
interested in estimating and simulating MDCEV models. In addition to
\pkg{rmdcev}, the
\href{http://www.apollochoicemodelling.com/}{\pkg{apollo}} package
developed by Stephane Hess and David Palma at the Choice Modelling
Centre in Leeds provides a flexible modelling platform for estimating
MDCEV models and simulating demand behaviour \citep{hessapollo2019}.
\pkg{apollo} estimates a full suite of choice models including discrete
choice models and is thus more comprehensive then \pkg{rmdcev}. The main
differences for MDCEV modeling between the two packages is that
\pkg{rmdcev} 1) provides functions for calculating welfare implications
of policy scenarios, 2) uses the Stan program \citep{carpenterstan2017}
for Bayesian estimation and thus the user has access to specialized
postestimation commands, and 3) is primarily coded in C++ and thus
around 20 times faster.

The paper first introduces the conceptual framework underlying MDCEV
models and the connection to economic theory and welfare measures.
Section \protect\hyperlink{models}{2} also describes the various
empirical specifications for MDCEV models. Section
\protect\hyperlink{rmdcev}{3} introduces the \pkg{rmdcev} package
focusing first on estimation before moving on to discuss how to conduct
welfare and demand simulations. Section
\protect\hyperlink{conclusions}{4} provides conclusions of the paper.

\hypertarget{models}{%
\section{Models}\label{models}}

\hypertarget{conceptual-framework}{%
\subsection{Conceptual framework}\label{conceptual-framework}}

This section describes the underlying conceptual framework for MDCEV
models. Each individual \(i\) maximizes utility through the choice of
the numeraire or outside good (\(x_{i1}\)) and the non-numeraire
alternatives (\(x_{ik}\)) subject to a monetary budget constraint. We
assume there is a numeraire good (i.e.~essential Hicksian composite
good) which is always consumed and has a price of one. The individual's
maximization problem is

\begin{equation}
\max_{x_{ik}, x_{i1}} U(x_{ik}, x_{i1}) \;\;\; s.t. \;\;\;y = \sum\limits^K_{k=2}p_{ik} x_{ik} + x_{i1}, \;\; x_{ik} \geq 0,\;\; k = 2,...,K  
\end{equation}

\noindent where \(x_{ik}\) is the consumption level for alternative
\(k\), \(x_{i1}\) is consumption of the numeraire, \(y\) is annual
income, and \(p_{ik}\) is the unit price of alternative \(k\).

The resulting first-order KT conditions that implicitly define the
solution to the optimal consumption bundles of \(x_{ik}\) and \(x_{i1}\)
are

\begin{align}
\label{eq:kt_conditions}
\begin{split}
 \frac{U_{x_{ik}}}{U_{x_{i1}}} & \leq p_{ik},\; \; k = 1,....K , \\
  x_{ik}\left[\frac{U_{x_{ik}}}{U_{x_{i1}}} - p_{ik} \right] & = 0,\; \; k = 1,....K.
  \end{split}
\end{align}

For alternatives with positive consumption levels, the marginal rate of
substitution between these alternatives and the numeraire good is equal
to the price of the alternative. For unconsumed alternatives, the
marginal rate of substitution between these alternatives and the
numeraire good is less than the price of the alternatives. For the rest
of the paper, we drop the subscript \(i\) for notational simplicity.

These first-order conditions can be used to derive Marshallian and
Hicksian demands and welfare measures. We assume that alternatives have
non-price attribute \(q_{k}\) and the vector of \(k\) prices and
attributes is denoted as \(p\) and \(q\). The Hicksian compensating
surplus (\(CS^H\)) for a change in price and quality from baseline
levels \(p^0\) and \(q^0\) to new `policy' levels \(p^1\) and \(q^1\) is
defined explicitly using an expenditure function

\begin{equation}
\label{eq:welfare}
CS^H = y - e(p^1, q^1, \bar{U}, \theta, \varepsilon)
\end{equation}

\noindent where \(\theta\) is the vector of structural parameters
(\(\psi_k, \alpha_k, \gamma_k\)), \(\varepsilon\) is a vector or matrix
of unobserved heterogeneity, and
\(\bar{U} = V(p^0, q^0, y, \theta, \varepsilon)\) and represents
baseline utility.

\hypertarget{multiple-discrete-continuous-extreme-value-model-mdcev}{%
\subsection{Multiple discrete-continuous extreme value model
(MDCEV)}\label{multiple-discrete-continuous-extreme-value-model-mdcev}}

The \pkg{rmdcev} package implements the random utility specification as
introduced by \citet{bhatmultiple2008}. The model specifications
included in \pkg{rmdcev} always assume an outside good (i.e.~the
numeraire good that is always consumed by every individual). The general
utility function is specified as

\begin{equation}
U(x_k, x_1) = \sum_{k=2}^{K} \frac{\gamma_k}{\alpha_k}\psi_k \left[ \left( \frac{x_k}{\gamma_k} + 1 \right)^{\alpha_k} - 1 \right] + \frac{\psi_1}{\alpha_1}x_1^{\alpha_1} \label{utilkt}
\end{equation}

\noindent where \(\gamma_k > 0\), \(\psi_k > 0\) and \(\alpha_k \leq 1\)
for all \(k\) are required for this specification to be consistent with
the properties of a utility function \citep{bhatmultiple2008}.
\citet{bhatmultiple2008} provides a detailed overview of the parameter
interpretation and in brief

\begin{itemize}
\tightlist
\item
  The \(\psi_k\) parameters represent the marginal utility of consuming
  alternative \(k\) at the point of zero consumption (i.e.~baseline
  marginal utility).
\item
  The \(\gamma_k\) parameters are translation parameters that allow for
  corner solutions (i.e.~zero consumption levels for alternatives) and
  also influence satiation. The lower the value of \(\gamma_k\), the
  greater the satiation effect in consuming \(x_k\).
\item
  The \(\alpha_k\) parameters control the rate of diminishing marginal
  utility of additional consumption. If \(\alpha_k\) equal to one, then
  there is no satiation effects (i.e.~constant marginal utility).
\end{itemize}

The `random utility' element of the model is introduced into the
baseline utility through a random error term as

\begin{equation}
\label{eq:psi}
\psi_k=\psi(z_k,\varepsilon_k)= exp(\beta'z_k+\varepsilon_k)
\end{equation}

\noindent where \(z_k\) is a set of variables that can include
alternative-specific attributes and individual-specific characteristics,
and \(\varepsilon_k\) is an error term that allows for the utility
function to be random over the population. We assume an extreme value
distribution that is independently distributed across alternatives for
\(\varepsilon_k\) with an associated scale parameter of \(\sigma\). For
identification, we specify \(\psi_1= e^{\varepsilon_1}\).

To ensure the estimated utility function corresponds to economic theory
we specify \(\gamma_k = exp(\gamma_k)\) such that \(\gamma_k > 0\) and
\(\alpha_k = exp(\alpha_k)/(1 + exp(\alpha_k))\) such that
\(0 < \alpha_k < 1\). Weak complementarity, which is required for
deriving unique welfare measures \citep{malerenvironment1974}, is
imposed in this specification by adding and subtracting one in the
non-numeraire part of the utility function.

While the most general form of the MDCEV model includes \(\psi_k\),
\(\gamma_k\), and \(\alpha_k\) parameters for each alternative, Bhat
(2008) discusses the identification concerns regarding estimating
separate \(\gamma_k\) and \(\alpha_k\) parameters for each non-numeraire
alternative. Typically only a subset of these parameters can be
identified and there are three common utility function specifications:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\alpha\)-profile: set all \(\gamma_k\) parameters to 1.
\end{enumerate}

\begin{equation}
\label{eq:alpha}
U(x_k, x_1) = \sum_{k=2}^{K} \frac{1}{\alpha_k}exp(\beta'z_k+\varepsilon_k) \left[ \left( x_k + 1 \right)^{\alpha_k} - 1 \right] + \frac{exp(\varepsilon_1)}{\alpha_1}x_1^{\alpha_1}
\end{equation}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \(\gamma\)-profile: set all non-numeraire \(\alpha_k\) parameters to
  0.
\end{enumerate}

\begin{equation}
\label{eq:gamma}
U(x_k, x_1) = \sum_{k=2}^{K} \gamma_k exp(\beta'z_k+\varepsilon_k) \ln\left( \frac{x_k}{\gamma_k} + 1 \right) + \frac{exp(\varepsilon_1)}{\alpha_1}x_1^{\alpha_1}
\end{equation}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  hybrid-profile: set all \(\alpha_k=\alpha_1=\alpha\).
\end{enumerate}

\begin{equation}
\label{eq:hybrid}
U(x_k, x_1) = \sum_{k=2}^{K} \frac{\gamma_k}{\alpha} exp(\beta'z_k+\varepsilon_k) \left[ \left( \frac{x_k}{\gamma_k} + 1 \right)^{\alpha} - 1 \right] + \frac{exp(\varepsilon_1)}{\alpha}x_1^{\alpha}
\end{equation}

The likelihood function representing the model probability of the
consumption pattern where \(M\) alternatives are chosen can be expressed
as \citet{bhatmultiple2008}

\begin{equation}
\label{eq:ll_base}
P(x^{*}_1,x^{*}_2...x^{*}_M,0,...,0) = \frac{1}{\sigma^{M-1}} \left(\prod_{m=1}^M c_m \right)\left(\sum_{m=1}^M \frac{p_m}{c_m} \right) \left( \ \frac{\prod_{m=1}^M e^{V_m/\sigma}}{ \left( \sum_{k=1}^J e^{V_k/\sigma} \right)^M }\right)(M-1)!
\end{equation}

\noindent where \(\sigma\) is the scale parameter and
\(c_m = \frac{1-\alpha_m}{x_m+ \gamma_m}\). The \(V\) expression depend
on what model specification is used:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(\alpha\)-profle:
  \(V_k = \beta' z_k + (\alpha_k-1)\ln\left( x_k + 1 \right) - \ln \left(p_k\right)\)
  for \(k \geq 2\), and \(V_1 = (\alpha_1-1)\ln(x_1)\).
\item
  \(\gamma\)-profle:
  \(V_k = \beta' z_k - \ln\left( \frac{x_k}{\gamma_k} + 1 \right) - \ln \left(p_k\right)\)
  for \(k \geq 2\), and \(V_1 = (\alpha_1-1)\ln(x_1)\).
\item
  hybrid-profile:
  \(V_k = \beta' z_k + (\alpha-1)\ln\left( \frac{x_k}{\gamma_k} + 1 \right) - \ln \left(p_k\right)\)
  for \(k \geq 2\), and \(V_1 = (\alpha-1)\ln(x_1)\).
\end{enumerate}

In these specifications, the parameters
(\(\beta, \alpha_k , \gamma_k, \sigma\)) are structural parameters that
are assumed to be equal across the population which simplifies
estimation. However, this fixed MDCEV specification is quite restrictive
as it imposes that all individuals have the same tastes for altenatives
(i.e.~preference homeogeneity). This assumption is relaxed in the next
two specifications.

\hypertarget{latent-class-lc-mdcev-models}{%
\subsection{Latent class (LC-MDCEV)
models}\label{latent-class-lc-mdcev-models}}

The latent class version of the MDCEV assumes that an individual belongs
to a finite mixture of \(S\) segments each indexed by \(s\)
(\(s=1,2,...S\)) \citep{sobhanilatent2013, kuriyamalatent2010}. We do
not observe which segment an individual belongs to but we can attribute
a probability \(\pi_{is}\) that individual \(i\) is a member of segment
\(s\). We impose that \(0 \leq \pi_{is} \leq 1\) and
\(\sum^S_{s=1} \pi_{is} = 1\) through the use of the logit link function
as

\begin{equation}
\pi_{is} = \frac{exp(\delta_s'w_i)}{\sum^S_{s=1}exp(\delta_s'w_i)}
\end{equation}

\noindent where \(w_i\) is a vector of individual characteristics and
\(\delta_s\) is a vector of coefficients to be estimated. The
\(\delta_s\) coefficients determine how the individual characteristics
affect the membership of individual \(i\) in segment \(s\). For
identification, the \(\delta_1\) coefficients for the first segment are
set to zero.

The likelihood function can be written as

\begin{equation}
P = \prod_{i} \pi_{is}P_{is}
\end{equation}

where \(P_{is}\) has the same form as Equation (\ref{eq:ll_base}) but is
now class specific.

\hypertarget{random-parameters-rp-mdcev-models}{%
\subsection{Random parameters (RP-MDCEV)
models}\label{random-parameters-rp-mdcev-models}}

The random parameter specification of the MDCEV model assumes that the
structural parameters \(\theta = (\beta, \alpha_k , \gamma_k)\) are not
neccesarily fixed but have an assumed distribution
\citep{bhatmultiple2008}. In \pkg{rmdcev}, parameters are distributed
multivariate normal with a mean \(\bar{\theta}\) and variance covariance
matrix \(\sum_{\theta}\) \citep{vonhaefenkuhn-tucker2005}. This
structure allows for continuous preference heterogeneity and accomodates
more fleixlbe correlation patterns between alternatives in a simlar
fashion to the mixed logit model in discrete choice models. The
\(\sigma\) scale parameter is always assumed to be a fixed parameter.

The most flexible model specification is to estimate the full variance
covariance matrix and if there are \(Q\) parameters in \(\theta\) then
there are \(Q(Q+1)/2\) unique variance covariance parameters to estimate
in the correlated RP-MDCEV specification. An alternative is to assume
the off-diagonal parameters are zero and estimate uncorrelated random
parameters by estimating the \(Q\) diagonal elements of
\(\sum_{\theta}\). If all elements of \(\sum_{\theta}\) are assumed to
be zero, the model collapses to the fixed MDCEV structure.

\hypertarget{a-note-on-bayesian-versus-classical-maximum-likelihood-estimation}{%
\subsection{A note on Bayesian versus classical maximum likelihood
estimation}\label{a-note-on-bayesian-versus-classical-maximum-likelihood-estimation}}

The MDCEV model without unobserved heterogeneity can be estimated using
Bayesian or classical maximum likelihood techniques. The LC-MDCEV model
can only be estimated using classical maximum likelihood techniques as
Bayesian approaches are challenged by the `label switching' problem. The
RP-MDCEV models can only be estimated using Bayesian techniques as
random parameter models require simulated maximum likelihood estimators
and these are not implemented in \pkg{rmdcev} at this time.

While there are philosphical differences between Bayesian and classical
maximum likelihood techniques to estimating models, the Bernstein-von
Mises theorem suggests that the Bayesian posterior distribution are
asymptotically equivalent to maximum likelihood estimates if the data
generating process has been correctly specified
\citep{traindiscrete2003}.

\hypertarget{rmdcev}{%
\section{The rmdcev package}\label{rmdcev}}

\hypertarget{data-format}{%
\subsection{Data format}\label{data-format}}

The \pkg{rmdcev} uses \code{mdcev.data} function for handling multiple
discrete-continuous data while ensuring the data is in the correct
format and is suitable for estimation. The \pkg{rmdcev} package accepts
data in ``long'' format (i.e.~one row per available non-numeraire
alternative for each individual). There is no row for the numeraire
good. If there are \(I\) individuals and \(J\) non-numeraire
alternatives, then the data frame should have \(IxJ\) rows.

To illustrate the data, we can load the recreation data included with
the \pkg{rmdcev} package. This data is from the Canadian Nature Survey
and includes choices for number of days spent recreating in 17 different
outdoor activities for 2,000 people \citep{federal20122014}.

\begin{Schunk}
\begin{Sinput}
data(data_rec, package = "rmdcev")
\end{Sinput}
\end{Schunk}

Each recreation activity is characterized by the daily costs of
participation for each individual. In additional to the recreation
behaviour and prices, the data includes information on three individual
characteristics: university (a dummy variable if the person has
completed a university degree), ageindex (a person's age divided by the
average age in sample), and urban (a dummy variable if a person lives in
an urban area). Additional details on the data and price construction
are provided in \citet{lloydsmitheconomics2019}. We can summarize the
average consumption and price levels for each alternative as:

\begin{Schunk}
\begin{Sinput}
data_rec %>%
    group_by(alt) %>%
    summarise(mean_quant = mean(quant),
                  mean_price = mean(price))
\end{Sinput}
\begin{Soutput}
#> # A tibble: 17 x 3
#>    alt            mean_quant mean_price
#>    <chr>               <dbl>      <dbl>
#>  1 beach               6.54        53.2
#>  2 birding            14.4         44.0
#>  3 camping             2.51        61.4
#>  4 cycling             9.47        46.0
#>  5 fish                3.34        86.2
#>  6 garden             21.6         38.3
#>  7 golf                4.03       134. 
#>  8 hiking             41.4         37.5
#>  9 hunt_birds          0.486      111. 
#> 10 hunt_large          0.948      184. 
#> 11 hunt_trap           0.629       95.3
#> 12 hunt_waterfowl      0.208      160. 
#> 13 motor_land          3.70       123. 
#> 14 motor_water         2.84       140. 
#> 15 photo               8.64        67.1
#> 16 ski_cross           2.64        32.7
#> 17 ski_down            1.21       151.
\end{Soutput}
\end{Schunk}

The data can be transformed into the structure for MDCEV estimation
using the \code{mdcev.data} function:

\begin{Schunk}
\begin{Sinput}
data_mdcev <- mdcev.data(data_rec,
                       id.var = "id",
                       alt.var = "alt",
                       choice = "quant")
\end{Sinput}
\begin{Soutput}
#> Checking data...
\end{Soutput}
\begin{Soutput}
#> Data is good
\end{Soutput}
\end{Schunk}

The \code{id.var} argument indicates what varible uniquely identifies
individuals in the data set, \code{alt.var} indicates the variable
containing the variable that identifies the non-numeraire alternatives,
and \code{choice} indicates the level of consumption made by the
individuals. Two other optional arguments of \code{mdcev.data} are
\code{price} and \code{income} indicating the individual-specific price
levels for each alternative, and the income level for each individual.
These two arguments only need to be explicitly specified if they are not
labelled price and income. Additional variables containing information
for alternative-specific attributes and individual characteristics can
also be included. Data must be arranged by id and then alternative.

The \code{mdcev.data} function also checks to ensure the data has the
necessary variables, and that all individuals spend positive amounts on
the numeraire good. If an individual does not have positive expenditures
on the numeraire good, an error message is given.

\hypertarget{mdcev-estimation}{%
\subsection{MDCEV estimation}\label{mdcev-estimation}}

\hypertarget{a-general-overview-of-mdcev}{%
\subsubsection{A general overview of
mdcev}\label{a-general-overview-of-mdcev}}

All the various MDCEV model specifications are estimated using the
\code{mdcev} function.

\begin{Schunk}
\begin{Sinput}
args(mdcev)
\end{Sinput}
\begin{Soutput}
#> function (formula = NULL, data, weights = NULL, model = c("alpha", 
#>     "gamma", "hybrid", "hybrid0"), n_classes = 1, fixed_scale1 = 0, 
#>     trunc_data = 0, seed = "123", max_iterations = 2000, initial.parameters = NULL, 
#>     algorithm = c("MLE", "Bayes"), flat_priors = NULL, print_iterations = TRUE, 
#>     hessian = TRUE, prior_psi_sd = 10, prior_gamma_sd = 10, prior_alpha_sd = 0.5, 
#>     prior_scale_sd = 1, prior_delta_sd = 10, gamma_fixed = 0, 
#>     alpha_fixed = 0, std_errors = "mvn", n_draws = 50, keep_loglik = 0, 
#>     random_parameters = "fixed", show_stan_warnings = TRUE, n_iterations = 200, 
#>     n_chains = 4, n_cores = 4, max_tree_depth = 10, adapt_delta = 0.8, 
#>     lkj_shape_prior = 4, ...) 
#> NULL
\end{Soutput}
\end{Schunk}

The main arguments are briefly explained below:

\begin{itemize}
\tightlist
\item
  \textbackslash code\{formula**: Formula for the model to be estimated.
  The formula is divided in two parts, separated by the symbol \code{|}.
  The first part is reserved for the \(z_k\) variables in \(\psi\) as in
  Equation (\ref{eq:psi}). These can include alternative-specific and
  individual-specific variables. Interaction terms between variables can
  be included using the normal \pkg{formula} syntax of \code{z1:z2}.
  This is particularly useful for creating interaction terms to
  incorporate observed preference heterogeneity for alternative-specific
  variables and individual-specific characteristics. The second part
  corresponds for individual-specific characteristics that enter in the
  probability assignment in models with latent classes. This formula is
  based on the R package \pkg{formula} \citep{zeileisextended2010}. The
  formula will automatically include a constant but a constant can be
  omitted if -1 is used in the formula.
\end{itemize}

\begin{Schunk}
\begin{Sinput}
formula = ~ z1 + z2 + z3
\end{Sinput}
\end{Schunk}

\begin{itemize}
\item
  \code{data} The (\(IxJ\)) data to be used in estimation as described
  above.
\item
  \code{weights} An optional vector of sampling or frequency weights.
\item
  \code{model} A string indicating which model specification to
  estimate. The four options are presented below:

  \begin{itemize}
  \tightlist
  \item
    ``alpha'': \(\alpha\)-profile with all \(\gamma_k\) parameters fixed
    equal to 1 (Equation (\ref{eq:alpha})).
  \item
    ``gamma'': \(\gamma\)-profile with one estimated \(\alpha_1\) and
    all non-numeraire \(\alpha_k\) parameters equal to 0 (Equation
    (\ref{eq:gamma})).
  \item
    ``hybrid'': hybrid-profile with a single estimated \(\alpha\)
    parameter (i.e.~\(\alpha_1 = \alpha_k = \alpha\)) (Equation
    (\ref{eq:hybrid})).
  \item
    ``hybrid0'': hybrid-profile with all \(\alpha\) parameters fixed
    equal to 1e-3 (Equation (\ref{eq:hybrid})).
  \end{itemize}
\item
  \code{n\_classes} The number of latent classes. Note that the LC model
  is automatically estimated as long as the prespecified number of
  classes is set greater than 1.
\item
  \code{fixed\_scale1} Whether to fix the scale parameter at 1.
\item
  \code{trunc\_data} Whether the estimation should be adjusted for
  truncation. This option should be used if data was only collected from
  people that consume at least one non-numeraire alternative. For
  example, if a intercept survey collected recreation data at a park
  then people that did not visit the park are not included in the data.
\item
  \code{seed} Random seed.
\item
  \code{algorithm} Either ``Bayes'' for Bayesian estimation or ``MLE''
  for maximum likelihood estimation. The MLE algorithm uses the
  Limited-memory BFGS which approximates the
  Broyden--Fletcher--Goldfarb--Shanno (BFGS) algorithm but uses less
  computer memory.
\item
  \code{flat\_priors} indicator if completely uninformative priors
  should be specified. If using MLE, the optimizing function will then
  be equal to log-likelihood. Defaults to 1 if MLE used and 0 if Bayes
  used.
\item
  \code{print\_iterations} Whether to print itermediate iteration
  information or not.
\item
  \code{std\_errors} Compute standard errors using the delta method
  (``deltamethod'') or multivariate normal draws (``mvn'').
\item
  \code{n\_draws} The number of multivariate normal draws for standard
  error calculations. Default is 50.
\item
  \code{initial.parameters} Specify initial parameters instead of
  starting at random.
\end{itemize}

\hypertarget{estimating-mdcev-using-maximum-likelihood-techniques}{%
\subsubsection{Estimating MDCEV using maximum likelihood
techniques}\label{estimating-mdcev-using-maximum-likelihood-techniques}}

We estimate a MDCEV model using the \textbf{Recreation} data where we
include activity-specific constants in \(\psi\). We exclude the constant
by including \code{-1} as below.

\begin{Schunk}
\begin{Sinput}
data_model <- mdcev.data(data_rec, subset = id < 201,
                       id.var = "id",
                       alt.var = "alt",
                       choice = "quant")  
\end{Sinput}
\begin{Soutput}
#> Checking data...
\end{Soutput}
\begin{Soutput}
#> Data is good
\end{Soutput}
\begin{Sinput}
formula <- ~ alt - 1
\end{Sinput}
\end{Schunk}

We specify the hybrid model specification where a single \(\alpha\) is
estimated for the numeraire and non-numeraire alternatives by setting
\code{model = "hybrid"}. We use maximum likelihood estimation by setting
\code{algorithm = "MLE"}. Standard errors can be calculated using the
delta method using the \code{std\_errors} option as shown below. For
these examples we are going to use a subset of 200 individuals from the
data.

The syntax for the model is the following:

\begin{Schunk}
\begin{Sinput}
mdcev_mle <- mdcev(formula,
                  data = data_model,
                  model = "hybrid",
                  algorithm = "MLE",
                  std_errors = "deltamethod",
                  print_iterations = FALSE)
\end{Sinput}
\begin{Soutput}
#> Using MLE to estimate MDCEV
\end{Soutput}
\end{Schunk}

Setting \code{print\_iterations = TRUE} will print out intermediate
iteration results as the model converges.

The output of the function can be accessed by calling summary.

\begin{Schunk}
\begin{Sinput}
summary(mdcev_mle)
\end{Sinput}
\begin{Soutput}
#> Model run using rmdcev for R, version 1.1.1 
#> Estimation method                : MLE
#> Model type                       : hybrid specification
#> Number of classes                : 1
#> Number of individuals            : 200
#> Number of non-numeraire alts     : 17
#> Estimated parameters             : 36
#> LL                               : -5152.76
#> AIC                              : 10377.51
#> BIC                              : 10496.25
#> Standard errors calculated using : Delta method
#> Exit of MLE                      : successful convergence
#> Time taken (hh:mm:ss)            : 00:00:0.8
#> 
#> Average consumption of non-numeraire alternatives:
#>     1     2     3     4     5     6     7     8     9    10    11    12    13 
#>  6.70 12.75  2.60  7.89  4.00 23.18  5.42 41.62  0.58  1.03  0.80  0.24  5.92 
#>    14    15    16    17 
#>  3.53 11.00  3.12  1.86 
#> 
#> Parameter estimates --------------------------------  
#>                    Estimate Std.err z.stat
#> psi_beach            -4.971   0.630  -7.89
#> psi_birding          -5.726   0.649  -8.82
#> psi_camping          -5.509   0.649  -8.49
#> psi_cycling          -5.432   0.647  -8.40
#> psi_fish             -5.133   0.648  -7.92
#> psi_garden           -5.008   0.614  -8.16
#> psi_golf             -4.418   0.653  -6.77
#> psi_hiking           -4.943   0.608  -8.13
#> psi_hunt_birds       -6.038   0.709  -8.52
#> psi_hunt_large       -5.231   0.688  -7.60
#> psi_hunt_trap        -6.279   0.718  -8.75
#> psi_hunt_waterfowl   -5.926   0.751  -7.89
#> psi_motor_land       -4.862   0.664  -7.32
#> psi_motor_water      -4.504   0.651  -6.92
#> psi_photo            -4.959   0.635  -7.81
#> psi_ski_cross        -6.134   0.661  -9.28
#> psi_ski_down         -4.773   0.675  -7.07
#> gamma1                5.736   1.061   5.41
#> gamma2               13.964   3.388   4.12
#> gamma3                5.293   1.136   4.66
#> gamma4               11.089   2.302   4.82
#> gamma5                8.241   1.754   4.70
#> gamma6               11.428   1.986   5.75
#> gamma7                7.117   1.668   4.27
#> gamma8               10.154   1.952   5.20
#> gamma9                6.810   2.808   2.43
#> gamma10               9.293   2.874   3.23
#> gamma11               8.794   4.210   2.09
#> gamma12               5.569   3.202   1.74
#> gamma13              11.011   2.929   3.76
#> gamma14               7.565   1.731   4.37
#> gamma15               9.832   1.946   5.05
#> gamma16               6.932   1.725   4.02
#> gamma17               6.259   1.798   3.48
#> alpha1                0.210   0.085   2.47
#> scale                 0.632   0.038  16.64
#> Note: Alpha parameter is equal for all alternatives.
\end{Soutput}
\end{Schunk}

The summary includes overall model and estimation information and the
parameter estimates.

In the next example, we estimate the \(\alpha\)-profile of the utility
function by changing the model argument to \code{"alpha"}.

\begin{Schunk}
\begin{Sinput}
mdcev_mle <- mdcev(formula,
                    data = data_model,
                    model = "alpha",
                    algorithm = "MLE",
                    std_error = "deltamethod",
                    print_iterations = FALSE)
\end{Sinput}
\end{Schunk}

\begin{Schunk}
\begin{Sinput}
summary(mdcev_mle)
\end{Sinput}
\begin{Soutput}
#> Model run using rmdcev for R, version 1.1.1 
#> Estimation method                : MLE
#> Model type                       : alpha specification
#> Number of classes                : 1
#> Number of individuals            : 200
#> Number of non-numeraire alts     : 17
#> Estimated parameters             : 36
#> LL                               : -5356.72
#> AIC                              : 10785.44
#> BIC                              : 10904.18
#> Standard errors calculated using : Delta method
#> Exit of MLE                      : successful convergence
#> Time taken (hh:mm:ss)            : 00:00:0.94
#> 
#> Average consumption of non-numeraire alternatives:
#>     1     2     3     4     5     6     7     8     9    10    11    12    13 
#>  6.70 12.75  2.60  7.89  4.00 23.18  5.42 41.62  0.58  1.03  0.80  0.24  5.92 
#>    14    15    16    17 
#>  3.53 11.00  3.12  1.86 
#> 
#> Parameter estimates --------------------------------  
#>                    Estimate Std.err z.stat
#> psi_beach            -1.562   0.685  -2.28
#> psi_birding          -2.366   0.695  -3.40
#> psi_camping          -2.131   0.695  -3.07
#> psi_cycling          -2.052   0.694  -2.96
#> psi_fish             -1.752   0.694  -2.52
#> psi_garden           -1.566   0.676  -2.32
#> psi_golf             -1.055   0.696  -1.52
#> psi_hiking           -1.401   0.674  -2.08
#> psi_hunt_birds       -2.685   0.731  -3.67
#> psi_hunt_large       -1.866   0.716  -2.61
#> psi_hunt_trap        -2.924   0.736  -3.97
#> psi_hunt_waterfowl   -2.559   0.762  -3.36
#> psi_motor_land       -1.514   0.703  -2.15
#> psi_motor_water      -1.148   0.694  -1.65
#> psi_photo            -1.578   0.689  -2.29
#> psi_ski_cross        -2.777   0.700  -3.97
#> psi_ski_down         -1.405   0.710  -1.98
#> alpha1                0.517   0.058   8.92
#> alpha2                0.590   0.041  14.38
#> alpha3                0.715   0.039  18.34
#> alpha4                0.590   0.050  11.80
#> alpha5                0.695   0.040  17.38
#> alpha6                0.654   0.044  14.85
#> alpha7                0.646   0.031  20.83
#> alpha8                0.663   0.046  14.40
#> alpha9                0.590   0.031  19.02
#> alpha10               0.658   0.091   7.23
#> alpha11               0.695   0.069  10.08
#> alpha12               0.705   0.095   7.42
#> alpha13               0.647   0.134   4.83
#> alpha14               0.718   0.049  14.64
#> alpha15               0.657   0.048  13.69
#> alpha16               0.676   0.037  18.27
#> alpha17               0.654   0.052  12.58
#> alpha18               0.653   0.061  10.71
#> scale                 0.616   0.036  17.11
#> Note: All non-numeraire gamma's fixed to 1.
\end{Soutput}
\end{Schunk}

The parameter estimates are quite different from the previous model as
all the non-numeraire \(\gamma\) parameters are fixed at 1 and
alternative-specific \(\alpha_k\) parameters are estimated.

The \(\gamma\)-profile version of the model can be estimated by changing
the model to \code{"gamma"} as the next example demonstrates.

\begin{Schunk}
\begin{Sinput}
mdcev_mle <- mdcev(formula,
                    data = data_model,
                    model = "gamma",
                    algorithm = "MLE",
                    std_error = "deltamethod",
                    print_iterations = FALSE)
\end{Sinput}
\end{Schunk}

\begin{Schunk}
\begin{Sinput}
summary(mdcev_mle)
\end{Sinput}
\begin{Soutput}
#> Model run using rmdcev for R, version 1.1.1 
#> Estimation method                : MLE
#> Model type                       : gamma specification
#> Number of classes                : 1
#> Number of individuals            : 200
#> Number of non-numeraire alts     : 17
#> Estimated parameters             : 36
#> LL                               : -5124.06
#> AIC                              : 10320.12
#> BIC                              : 10438.86
#> Standard errors calculated using : Delta method
#> Exit of MLE                      : successful convergence
#> Time taken (hh:mm:ss)            : 00:00:0.61
#> 
#> Average consumption of non-numeraire alternatives:
#>     1     2     3     4     5     6     7     8     9    10    11    12    13 
#>  6.70 12.75  2.60  7.89  4.00 23.18  5.42 41.62  0.58  1.03  0.80  0.24  5.92 
#>    14    15    16    17 
#>  3.53 11.00  3.12  1.86 
#> 
#> Parameter estimates --------------------------------  
#>                    Estimate Std.err z.stat
#> psi_beach            -0.797   0.674  -1.18
#> psi_birding          -1.546   0.679  -2.28
#> psi_camping          -1.322   0.680  -1.94
#> psi_cycling          -1.244   0.679  -1.83
#> psi_fish             -0.946   0.679  -1.39
#> psi_garden           -0.858   0.669  -1.28
#> psi_golf             -0.232   0.680  -0.34
#> psi_hiking           -0.819   0.668  -1.23
#> psi_hunt_birds       -1.822   0.706  -2.58
#> psi_hunt_large       -1.023   0.695  -1.47
#> psi_hunt_trap        -2.070   0.710  -2.91
#> psi_hunt_waterfowl   -1.686   0.732  -2.30
#> psi_motor_land       -0.670   0.684  -0.98
#> psi_motor_water      -0.327   0.679  -0.48
#> psi_photo            -0.779   0.676  -1.15
#> psi_ski_cross        -1.947   0.682  -2.86
#> psi_ski_down         -0.563   0.690  -0.82
#> gamma1                8.692   1.466   5.93
#> gamma2               22.213   4.929   4.51
#> gamma3                7.541   1.486   5.07
#> gamma4               16.174   3.125   5.18
#> gamma5               11.760   2.273   5.17
#> gamma6               18.236   2.819   6.47
#> gamma7               10.943   2.372   4.61
#> gamma8               17.383   2.872   6.05
#> gamma9                9.575   3.661   2.62
#> gamma10              12.490   3.581   3.49
#> gamma11              12.575   5.614   2.24
#> gamma12               7.831   4.235   1.85
#> gamma13              16.191   4.006   4.04
#> gamma14              11.158   2.341   4.77
#> gamma15              14.469   2.646   5.47
#> gamma16              10.284   2.376   4.33
#> gamma17               9.059   2.415   3.75
#> alpha1                0.596   0.058  10.27
#> scale                 0.611   0.028  21.81
#> Note: All non-numeraire alpha's fixed to 0.
\end{Soutput}
\end{Schunk}

The same number of parameters are estimated in all three models and the
log-likelihood is highest for the \(\gamma\)-profile specification.

\hypertarget{estimating-mdcev-using-bayesian-techniques}{%
\subsubsection{Estimating MDCEV using Bayesian
techniques}\label{estimating-mdcev-using-bayesian-techniques}}

The exact same models can be fit using Bayesian estimation by changing
the algorithm call to \code{"Bayes"}. Bayesian estimation is implemented
using the Stan programming language \citep{carpenterstan2017}. The
Bayesian framework requires careful choice of priors for the parameters.
All priors are assumed to follow a normal distribution with a fixed mean
and the user can change the standard deviation through these options in
the mdcev function.

\begin{itemize}
\tightlist
\item
  \code{prior\_psi\_sd} standard deviation for normal prior with mean 0.
\item
  \code{prior\_gamma\_sd} standard deviation for normal prior with mean
  0.
\item
  \code{prior\_alpha\_sd} standard deviation for normal prior with mean
  0.5.
\item
  \code{prior\_scale\_sd} standard deviation for normal prior with mean
  1.
\end{itemize}

There are also a number of further options for Bayesian estimation. For
example, the number of iterations (n\_iterations), number of chains
(n\_chains), and number of cores (n\_cores) for parallel implementation
of the chains can also be chosen. The full set of options for Bayesian
estimation are presented below.

\begin{itemize}
\item
  \code{random\_parameters} The form of the covariance matrix for the
  parameters. Options are

  \begin{itemize}
  \tightlist
  \item
    `fixed' for no random parameters,
  \item
    'uncorr for uncorrelated random parameters, and
  \item
    `corr' for correlated random parameters.
  \end{itemize}
\item
  \code{n\_iterations} The number of iterations in Bayesian estimation.
\item
  \code{n\_chains} The number of chains in Bayesian estimation.
\item
  \code{n\_cores} The number of cores to use in Bayesian estimation. Can
  set using options(mc.cores = parallel::detectCores()).
\item
  \code{max\_tree\_depth}
  \url{http://mc-stan.org/misc/warnings.html\#maximum-treedepth-exceeded}
\item
  \code{adapt\_delta}
  \url{http://mc-stan.org/misc/warnings.html\#divergent-transitions-after-warmup}
\item
  \code{lkj\_shape\_prior} Prior for Cholesky matrix for correlated
  random parameters
\end{itemize}

In this example, we estimate the hybrid0 specification using Bayesian
techniques. We set the number of iterations to 200 and use 4 independent
chains.

\begin{Schunk}
\begin{Sinput}
mdcev_bayes <- mdcev(formula,
                        data = data_model,
                        model = "hybrid0",
                        algorithm = "Bayes",
                        n_iterations = 200,
                        n_chains = 4,
                        print_iterations = FALSE)
\end{Sinput}
\end{Schunk}

The output of the function can be accessed by calling summary.

\begin{Schunk}
\begin{Sinput}
    summary(mdcev_bayes)
\end{Sinput}
\begin{Soutput}
#> Model run using rmdcev for R, version 1.1.1 
#> Estimation method                : Bayes
#> Model type                       : hybrid0 specification
#> Number of classes                : 1
#> Number of individuals            : 200
#> Number of non-numeraire alts     : 17
#> Estimated parameters             : 35
#> LL                               : -5174.12
#> Number of chains                 : 4
#> Number of warmup draws per chain : 100
#> Total post-warmup sample         : 400
#> Time taken (hh:mm:ss)            : 00:00:31.92
#> 
#> Average consumption of non-numeraire alternatives:
#>     1     2     3     4     5     6     7     8     9    10    11    12    13 
#>  6.70 12.75  2.60  7.89  4.00 23.18  5.42 41.62  0.58  1.03  0.80  0.24  5.92 
#>    14    15    16    17 
#>  3.53 11.00  3.12  1.86 
#> 
#> Parameter estimates --------------------------------  
#>                    Estimate Std.err z.stat n_eff Rhat
#> psi_beach            -7.263   0.112 -64.62   420 1.01
#> psi_birding          -8.097   0.117 -69.16   464 1.00
#> psi_camping          -7.887   0.129 -61.24   430 1.00
#> psi_cycling          -7.791   0.122 -64.04   423 1.00
#> psi_fish             -7.508   0.129 -58.03   383 1.01
#> psi_garden           -7.220   0.095 -75.66   479 1.00
#> psi_golf             -6.811   0.126 -54.01   392 1.00
#> psi_hiking           -7.111   0.109 -64.97   586 1.00
#> psi_hunt_birds       -8.622   0.228 -37.79   420 1.00
#> psi_hunt_large       -7.752   0.193 -40.27   481 0.99
#> psi_hunt_trap        -8.900   0.271 -32.84   411 1.00
#> psi_hunt_waterfowl   -8.657   0.323 -26.79   284 1.00
#> psi_motor_land       -7.300   0.150 -48.82   453 1.00
#> psi_motor_water      -6.882   0.127 -54.20   610 0.99
#> psi_photo            -7.269   0.108 -67.13   566 1.00
#> psi_ski_cross        -8.557   0.135 -63.42   411 1.01
#> psi_ski_down         -7.255   0.149 -48.55   478 1.00
#> gamma1                6.376   1.094   5.83   842 1.00
#> gamma2               14.873   3.343   4.45   684 0.99
#> gamma3                6.023   1.154   5.22   638 0.99
#> gamma4               11.941   2.364   5.05   821 0.99
#> gamma5                9.238   1.760   5.25   842 1.00
#> gamma6               12.569   1.746   7.20   507 0.99
#> gamma7                8.098   1.946   4.16   557 1.00
#> gamma8               11.798   1.824   6.47   584 0.99
#> gamma9                8.204   2.836   2.89   305 1.00
#> gamma10              10.142   2.914   3.48   352 1.01
#> gamma11              10.104   3.860   2.62   250 0.99
#> gamma12               7.155   3.480   2.06   113 1.01
#> gamma13              11.860   2.665   4.45   474 0.99
#> gamma14               8.398   1.765   4.76   532 1.00
#> gamma15              10.933   1.986   5.50   851 0.99
#> gamma16               7.731   1.819   4.25   530 1.00
#> gamma17               7.377   2.211   3.34   416 0.99
#> scale                 0.769   0.030  25.89   247 1.00
#> Note: All alpha parameters fixed to 1e-3. 
#> Note from Rstan: 'For each parameter, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence, Rhat=1)'
\end{Soutput}
\end{Schunk}

One benefit of using the Bayesian approach is that we can take advantage
of the postestimation commands, interactive diagnostics, and posterior
analysis in \pkg{rstan},
\href{https://mc-stan.org/bayesplot/}{\pkg{bayesplot}}
\citep{gabrybayesplot2019}, and
\href{http://mc-stan.org/shinystan/}{\pkg{shinystan}}
\citep{muthuser2018}. For example, the effective sample size reports the
estimated number of independent draws from the posterior distribution
for each parameter \citep{stan2019}. The interested reader is refered to
these packages for additional details.

\hypertarget{estimating-lc-mdcev-models}{%
\subsubsection{Estimating LC-MDCEV
models}\label{estimating-lc-mdcev-models}}

In this example, we estimate a LC-MDCEV model using the
\textbf{Recreation} data. We set the number of classes equal to 2 and we
use data on 500 individuals. We would like to include the
\code{university}, \code{ageindex}, and \code{urban} in the membership
equation and we include them in the \code{formula} interface. Note that
we need to include at least a constant in the formula. The LC model is
automatically estimated as long as the prespecified number of classes
(\code{n\_classes}) is set greater than 1.

\begin{Schunk}
\begin{Sinput}
data_model <- mdcev.data(data_rec, subset = id < 501,
                       id.var = "id",
                       alt.var = "alt",
                       choice = "quant")  

formula <- ~ alt - 1 | university + ageindex + urban

mdcev_lc <- mdcev(formula,
                  data = data_model,
                  n_classes = 2,
                  model = "hybrid0",
                  algorithm = "MLE",
                  print_iterations = FALSE)
\end{Sinput}
\end{Schunk}

\begin{Schunk}
\begin{Sinput}
summary(mdcev_lc)
\end{Sinput}
\begin{Soutput}
#> Model run using rmdcev for R, version 1.1.1 
#> Estimation method                : MLE
#> Model type                       : hybrid0 specification
#> Number of classes                : 2
#> Number of individuals            : 500
#> Number of non-numeraire alts     : 17
#> Estimated parameters             : 74
#> LL                               : -12033.48
#> AIC                              : 24214.97
#> BIC                              : 24526.85
#> Standard errors calculated using : 50 MVN draws
#> Exit of MLE                      : successful convergence
#> Time taken (hh:mm:ss)            : 00:00:6.31
#> 
#> Average consumption of non-numeraire alternatives:
#>     1     2     3     4     5     6     7     8     9    10    11    12    13 
#>  6.47 12.27  2.33  9.03  3.84 21.97  4.44 39.52  0.64  1.14  0.84  0.27  4.48 
#>    14    15    16    17 
#>  3.03  9.20  2.36  1.49 
#> 
#> 
#> Class average probabilities:
#> class1 class2 
#>   0.32   0.68 
#> Parameter estimates --------------------------------  
#>                           Estimate Std.err z.stat
#> class1.psi_beach            -6.265   0.159 -39.32
#> class2.psi_beach            -7.669   0.095 -80.66
#> class1.psi_birding          -8.268   0.143 -57.72
#> class2.psi_birding          -8.173   0.102 -79.93
#> class1.psi_camping          -7.300   0.150 -48.53
#> class2.psi_camping          -8.226   0.142 -58.09
#> class1.psi_cycling          -7.301   0.136 -53.64
#> class2.psi_cycling          -8.103   0.099 -82.01
#> class1.psi_fish             -7.816   0.171 -45.59
#> class2.psi_fish             -7.382   0.115 -64.37
#> class1.psi_garden           -7.290   0.128 -56.76
#> class2.psi_garden           -7.309   0.074 -98.74
#> class1.psi_golf             -7.047   0.165 -42.83
#> class2.psi_golf             -6.866   0.110 -62.62
#> class1.psi_hiking           -6.250   0.226 -27.66
#> class2.psi_hiking           -7.363   0.089 -82.71
#> class1.psi_hunt_birds       -9.480   0.513 -18.48
#> class2.psi_hunt_birds       -7.973   0.132 -60.49
#> class1.psi_hunt_large       -9.235   0.490 -18.83
#> class2.psi_hunt_large       -7.347   0.143 -51.27
#> class1.psi_hunt_trap       -10.243   0.538 -19.03
#> class2.psi_hunt_trap        -8.548   0.185 -46.09
#> class1.psi_hunt_waterfowl   -9.204   0.452 -20.36
#> class2.psi_hunt_waterfowl   -8.093   0.179 -45.31
#> class1.psi_motor_land       -7.233   0.165 -43.94
#> class2.psi_motor_land       -7.130   0.108 -66.13
#> class1.psi_motor_water      -6.875   0.161 -42.73
#> class2.psi_motor_water      -6.980   0.144 -48.53
#> class1.psi_photo            -7.002   0.137 -51.15
#> class2.psi_photo            -7.460   0.082 -90.68
#> class1.psi_ski_cross        -8.327   0.125 -66.48
#> class2.psi_ski_cross        -8.733   0.146 -59.62
#> class1.psi_ski_down         -6.578   0.193 -34.11
#> class2.psi_ski_down         -7.647   0.167 -45.86
#> class1.gamma1                2.276   0.426   5.34
#> class2.gamma1               14.303   2.874   4.98
#> class1.gamma2                4.849   1.367   3.55
#> class2.gamma2               40.858  11.152   3.66
#> class1.gamma3                3.313   0.501   6.61
#> class2.gamma3               11.593   2.741   4.23
#> class1.gamma4                8.312   1.697   4.90
#> class2.gamma4               26.291   5.793   4.54
#> class1.gamma5                5.641   1.702   3.31
#> class2.gamma5               12.442   2.254   5.52
#> class1.gamma6                5.946   1.436   4.14
#> class2.gamma6               22.582   3.090   7.31
#> class1.gamma7                8.277   2.274   3.64
#> class2.gamma7               11.972   2.046   5.85
#> class1.gamma8                2.857   0.787   3.63
#> class2.gamma8               26.743   4.768   5.61
#> class1.gamma9                2.196   1.629   1.35
#> class2.gamma9                7.858   2.032   3.87
#> class1.gamma10               9.522   6.810   1.40
#> class2.gamma10              12.169   1.946   6.25
#> class1.gamma11              49.078  76.955   0.64
#> class2.gamma11              12.589   3.994   3.15
#> class1.gamma12               4.081   2.768   1.47
#> class2.gamma12              10.663   3.887   2.74
#> class1.gamma13               3.703   0.739   5.01
#> class2.gamma13              22.136   4.089   5.41
#> class1.gamma14               3.032   0.717   4.23
#> class2.gamma14              14.005   2.463   5.69
#> class1.gamma15               7.067   1.376   5.14
#> class2.gamma15              15.005   2.502   6.00
#> class1.gamma16               4.590   1.230   3.73
#> class2.gamma16              12.807   3.058   4.19
#> class1.gamma17               4.775   1.233   3.87
#> class2.gamma17               8.577   2.895   2.96
#> class1.scale                 0.800   0.035  22.74
#> class2.scale                 0.653   0.030  22.08
#> class2.(Intercept)          -2.474   0.744  -3.33
#> class2.university           -1.374   0.300  -4.57
#> class2.ageindex              4.068   0.616   6.61
#> class2.urban                 0.139   0.576   0.24
#> Note: All alpha parameters fixed to 1e-3. 
#> Note: The membership equation parameters for class 1 are normalized to 0.
\end{Soutput}
\end{Schunk}

In this LC example, we assume that there are two types of people that
have different preferences for recreation. The probability of class
assignment depends on unobserved factors and the three sociodemographic
factors included in the membership equation. The summary output reports
the average class probabiliies as being 32\% for class 1 and 68\% for
class 2. The \(\psi\) parameters across classes are similar although
there are some noticable differences. The \(\gamma\) parameters, on the
other hand, show that satiation between classes is quite different
between the classes. To assist speed and convergence issues,
\pkg{rmdcev} uses the results of the MDCEV model as starting values when
estimating the LC-MDCEV model. The MDCEV model output can be accessed
from \code{mdcev\_lc[["mdcev\_fit"]]} object for comparison.

\hypertarget{estimating-rp-mdcev-models}{%
\subsubsection{Estimating RP-MDCEV
models}\label{estimating-rp-mdcev-models}}

Random parameter models require defining and parameterizing the variance
covariance matrix. For uncorrelated random parameters, the diagonal
elements of the variance covariance matrix are estimated and the
off-diagonal elements are assumed to be zero. For correlated random
parameters, the variance covariance matrix is fully estimated and can be
parameterized in many ways. The \pkg{rmdcev} package defines the
variance covariance matrix in terms of Cholesky factors of the
correlation matrix and a vector of standard deviations for numerical
stability. Thus the variance covariance matrix is specified as

\begin{equation}
\sum = diag(\tau) \; x \; LL^T \; x \; diag(\tau)
\end{equation}

where \(\tau\) is a vector of standard deviations, and \(L\) is the
cholesky factors of the correlation matrix.

In this example, we estimate an uncorrelated random parameters MDCEV
model using \pkg{rmdcev}. We set the argument
\code{random\_parameters = "uncorr"} to indicate that uncorrelated
random parameters will be estimated. All random parameters follow a
normal distribution. We change the \code{formula} specification to only
include a single constant term for all non-numeraire alternatives. The
scale parameter is fixed at 1 using \code{fixed\_scale1 = 1}.

\begin{Schunk}
\begin{Sinput}
data_model <- mdcev.data(data_rec, subset = id < 201,
                       id.var = "id",
                       alt.var = "alt",
                       choice = "quant") 

mdcev_rp <- mdcev(formula = ~ 1,
                    data = data_model,
                    model = "hybrid0",
                    algorithm = "Bayes",
                    n_chains = 4,
                    fixed_scale1 = 1,
                    n_iterations = 200,
                    random_parameters = "uncorr",
                    print_iterations = FALSE)
\end{Sinput}
\end{Schunk}

\begin{Schunk}
\begin{Sinput}
summary(mdcev_rp)
\end{Sinput}
\begin{Soutput}
#> Model run using rmdcev for R, version 1.1.1 
#> Estimation method                : Bayes
#> Model type                       : hybrid0 specification
#> Number of classes                : 1
#> Number of individuals            : 200
#> Number of non-numeraire alts     : 17
#> Estimated parameters             : 36
#> LL                               : -5352.95
#> Random parameters                : uncorrelated random parameters
#> Number of chains                 : 4
#> Number of warmup draws per chain : 100
#> Total post-warmup sample         : 400
#> Time taken (hh:mm:ss)            : 00:01:2.11
#> 
#> Average consumption of non-numeraire alternatives:
#>     1     2     3     4     5     6     7     8     9    10    11    12    13 
#>  6.70 12.75  2.60  7.89  4.00 23.18  5.42 41.62  0.58  1.03  0.80  0.24  5.92 
#>    14    15    16    17 
#>  3.53 11.00  3.12  1.86 
#> 
#> Parameter estimates --------------------------------  
#>                    Estimate Std.err z.stat n_eff Rhat
#> psi_(Intercept)      -7.923   0.096 -82.39   383 1.00
#> gamma1                5.576   0.831   6.71   518 1.01
#> gamma2                8.274   2.181   3.79   438 1.00
#> gamma3                3.842   0.792   4.85   501 0.99
#> gamma4                8.049   1.593   5.05   464 1.00
#> gamma5                7.182   1.436   5.00   445 1.01
#> gamma6               12.604   1.779   7.08   398 1.00
#> gamma7                6.606   1.588   4.16   456 1.00
#> gamma8               15.074   2.061   7.32   401 1.00
#> gamma9                4.286   2.116   2.03   517 1.00
#> gamma10               7.380   2.472   2.99   318 1.01
#> gamma11               5.899   3.427   1.72   444 1.00
#> gamma12               4.886   7.198   0.68   620 0.99
#> gamma13               8.734   2.548   3.43   503 0.99
#> gamma14               6.866   1.862   3.69   428 1.00
#> gamma15               9.144   1.932   4.73   493 1.00
#> gamma16               3.313   0.922   3.59   354 1.01
#> gamma17               5.051   1.523   3.32   382 0.99
#> sd.psi_(Intercept)    0.322   0.166   1.94   143 1.01
#> sd.gamma1             1.278   0.242   5.28   454 1.00
#> sd.gamma2             1.923   0.690   2.79   144 1.02
#> sd.gamma3             1.244   0.228   5.45   554 1.00
#> sd.gamma4             1.303   0.256   5.08   460 0.99
#> sd.gamma5             1.283   0.249   5.15   520 1.00
#> sd.gamma6             1.275   0.228   5.60   351 1.00
#> sd.gamma7             1.601   0.496   3.23   269 1.01
#> sd.gamma8             1.371   0.292   4.69   252 1.01
#> sd.gamma9             1.738   0.814   2.14   458 1.00
#> sd.gamma10            1.406   0.403   3.49   729 1.00
#> sd.gamma11            2.314   1.595   1.45   433 1.00
#> sd.gamma12            2.605   2.871   0.91   528 1.00
#> sd.gamma13            1.547   0.553   2.80   345 1.00
#> sd.gamma14            1.393   0.373   3.73   371 1.00
#> sd.gamma15            1.294   0.283   4.57   484 1.00
#> sd.gamma16            1.457   0.438   3.33   304 1.02
#> sd.gamma17            1.528   0.521   2.93   303 1.00
#> Note: Scale parameter fixed to 1. 
#> Note: All alpha parameters fixed to 1e-3. 
#> Note from Rstan: 'For each parameter, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence, Rhat=1)'
\end{Soutput}
\end{Schunk}

The results show the means of the random parameters followed by the
estimated standard deviations. The standard deviations that are
estimated to be different from zero suggest there is heterogeneity in
preference parameters. The correlated random parameters specification
can be estimated by setting \code{random\_parameters = "corr"}.

\hypertarget{simulating-mdcev-demand-and-welfare-scenarios}{%
\subsection{Simulating MDCEV demand and welfare
scenarios}\label{simulating-mdcev-demand-and-welfare-scenarios}}

The \pkg{rmdcev} package includes simulation functions for calculating
welfare measures and forecasting demand under alternative policy
scenaros. The overall approach used for simulation is first introduced
and then code examples are given.

\hypertarget{overview-of-simulation-steps}{%
\subsubsection{Overview of simulation
steps}\label{overview-of-simulation-steps}}

Once the model parameters are estimated, there are two steps to
simulation in MDCEV models. In the first step we draw simulated values
for the unobserved heterogeneity term (\(\varepsilon\)) using Monte
Carlo techniques. The second step uses these error draws, the previously
estimated model parameters, and the underlying data to calculate
Marshallian demands for forecasting or Hicksian demands for welfare
analysis. These two steps are described below.

\textbf{Step 1: simulating unobervered heterogeneity}

Monte Carlo simulation techniques can be employed to draw simulated
values of the unobserved heterogeneity (\(\varepsilon\)) using either
unconditional or conditional draws.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Unconditional error draws: draw from the entire distribution of
  unobserved heterogeneity using the following formula
\end{enumerate}

\begin{equation}
\varepsilon_{k} = -log(-log(draw(0,1))) * \sigma
\end{equation}

where \(draw(0,1)\) is a draw between 0 and 1 and \(\sigma\) is the
scale parameter. \pkg{rmdcev} allows errors to be drawn using uniform
draws or the Modified Latin Hypercube Sampling algorithm
\citep{hesson2006}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Conditional error draws: draw errors terms to reflect behaviour and
  dependent on whether alternative is consumed or not
  \citep{vonhaefenincorporating2003, vonhaefenestimation2004}:
\end{enumerate}

\begin{itemize}
\tightlist
\item
  If \(x_k>0\), set \(\varepsilon_k = (V_1 - V_k)/ \sigma\) where
  \(V_1\) and \(V_k\) depend on the model specification as detailed
  above.
\item
  If \(x_k=0\), \(\varepsilon_k < (V_1 - V_k)/ \sigma\) and simulate
  \(\varepsilon_k\) from the truncated type I extreme value distribution
  such that
\end{itemize}

\begin{equation}
\varepsilon_k = -log(-log(draw(0, 1) * exp(-exp(\frac{V_1 - V_k}{\sigma})))) * \sigma
\end{equation}

In the conditional error draw approach, we normalize
\(\varepsilon_1=0\).

The main differences between these two error draw approaches is that in
the conditional approach, we draw errors such that the model perfectly
predicts the observed consumption patterns in the baseline state
\citep{vonhaefenkuhn-tucker2005}. Thus the conditional approach uses
observed behaviour by individuals to characterize unobserved
heterogeneity. If the model correctly specifies the data generating
process, the sample means of the conditional and unconditional
approaches should converge in expectation. Another difference between
the two approaches is that the unconditional approach uses more
computation time. The reason for the relative slowness of the
unconditional approach is the need to calculate consumption patterns in
the baseline state as well as simulate the entire distribution of
unobserved heterogeneity.

\textbf{Step 2: Calculating welfare measures and demand forecasts}

With the error draws in hand, the second step is to simulate demand or
welfare changes. Compared to welfare measures in discrete choice models,
welfare calculation in MDCEV models is more challenging because of the
two Kuhn-Tucker conditions in Equation (\ref{eq:kt_conditions}). For a
given policy scenario, a priori, we do not know which alternatives have
a positive or zero consumption level. \pkg{rmdcev} implements the
\citet{pinjaricomputationally2011} efficient demand forecasting routine
for simulating demand behaviour which relies on calculting Marshallian
demands. For welfare calculations, we need to calculate the expenditure
function in Equation (\ref{eq:welfare}) which relies on Hicksian
demands. These are calculated using the approach described by
\citet{lloydsmithnew2018}. The demand and welfare simulation approaches
share a lot of commonalities and thus only the approach used for welfare
calculations are fully described in the appendix. The specific steps for
demand simulation is explained in-depth in
\citet{pinjaricomputationally2011} and the interested reader is
encouraged to read Section 4 of the paper for the exact details.

\hypertarget{welfare-analysis}{%
\subsubsection{Welfare analysis}\label{welfare-analysis}}

In \pkg{rmdcev}, the functions for welfare and demand simulation have
been divided into 3 steps to allow users to parallelize operations as
desired.

\hypertarget{define-policy-scenarios}{%
\subparagraph{1. Define policy
scenarios}\label{define-policy-scenarios}}

In the first step, we define the number of alternative policy scenarios
to use in simulation and then specify changes to the \(\psi\) variables
and prices of alternatives. The CreateBlankPolicies function has been
created to easily set-up the required lists for the simulation. These
policies can then be manually edited according to the specific policy
scenario. For prices, \pkg{rmdcev} is set up to accept additive changes
in prices that impact all individuals the same. For the \(\psi\)
variable changes, the package is set up to accept any new values for
these variables. Depending on the number of individuals and number of
policies, the generated policies list can be quite large. If the user is
only interested in assessing price changes, then you can use
\code{price\_change\_only = TRUE} which ensures duplicate \(\psi\) data
is not created.

In this example, we are interested in two separate policies. The first
policy increases the costs of all recreation activities by \$1 and the
second policy increases the cost of all four hunting activities by \$10.
The policy set-up for these two scenarios is demonstrated below.

\begin{Schunk}
\begin{Sinput}
nalts <- mdcev_mle$stan_data[["J"]]
npols <- 2

policies<-  CreateBlankPolicies(npols = npols,
                                nalts = nalts,
                                mdcev_mle$stan_data[["dat_psi"]],
                                price_change_only = TRUE)

policies$price_p[[1]] <- c(0, rep(1, nalts))
policies$price_p[[2]][10:13] <- rep(10, 4)
\end{Sinput}
\end{Schunk}

For policy scenarios that involve changes in the \(\psi\) variables, the
user can change the \code{dat\_psi} list of the \code{policies} object.
For example, the following code will increase the value of the third
variable by 20\% in policy scenario 1.

\begin{Schunk}
\begin{Sinput}
policies$dat_psi[[1]][3] <- policies$dat_psi[[1]][3]*1.2
\end{Sinput}
\end{Schunk}

\hypertarget{prepare-simulation-data}{%
\subparagraph{2. Prepare simulation
data}\label{prepare-simulation-data}}

The second step is to combine the parameter estimates, data, and policy
scenarios into a data format for simulation. The PrepareSimulationData
function uses the model fit and the user defined policy scenarios to
create this specific data format. This function separates the output
into individual-specific data (df\_indiv), data common to all
individuals (df\_common), and simulation options (sim\_options).

\begin{Schunk}
\begin{Sinput}
df_sim <- PrepareSimulationData(mdcev_mle, policies)
\end{Sinput}
\end{Schunk}

\hypertarget{simulate-mdcev-model}{%
\subparagraph{3. Simulate MDCEV model}\label{simulate-mdcev-model}}

The third step is to simulate the policy scenario using the formatted
data and the \code{mdcev.sim} function. The specific steps for the
simulation algorithms are described in Appendix A. The user chooses the
type of error draws (unconditional or conditional as described above),
the number of error draws, and whether to simulate the demand or welfare
changes.

\begin{Schunk}
\begin{Sinput}
welfare <- mdcev.sim(df_sim$df_indiv,
                     df_common = df_sim$df_common,
                     sim_options = df_sim$sim_options,
                     cond_err = 1,
                     nerrs = 15,
                     sim_type = "welfare")
\end{Sinput}
\begin{Soutput}
#> Using general approach to simulation
\end{Soutput}
\begin{Soutput}
#> Simulating welfare...
\end{Soutput}
\begin{Soutput}
#> 
#> 1.80e+05simulations finished in1.04minutes.(2884per second)
\end{Soutput}
\begin{Sinput}
summary(welfare)
\end{Sinput}
\begin{Soutput}
#> # A tibble: 2 x 5
#>   policy    mean std.dev `ci_lo2.5%` `ci_hi97.5%`
#>   <chr>    <dbl>   <dbl>       <dbl>        <dbl>
#> 1 policy1 -129.   0.0793      -129.        -129. 
#> 2 policy2  -22.6  0.310        -23.0        -21.9
\end{Soutput}
\end{Schunk}

The output of the \code{mdcev.sim} for welfare analysis is an object of
class \code{mdcev.sim} which contains a list of matrices where each
element of the list is for an individual and the matrix consists of rows
for each policy scenario and columns for each parameter simulation.

The summary function computes summary statistics across all individuals.
For example, the average welfare change for a \$1 daily increase in all
recreation costs is -\$129.

The reason these last two steps are separate is to allow users to
parallelize the simulation step as the last step can be computationally
intensive. The number of simulations is a multiplicative function of the
number of individuals, number of policies, number of parameter estimate
simulations, and the number of error draws (\(I\) x \(npols\) x
\(nsims\) x \(nerrs\)). Even for modestly sized data, the total number
of simulations can easily reach well into the millions or billions. All
simulations are conducted at the individual level which allows the user
to easily parallelize the mdcev.sim function using the \pkg{parallel}
package or similar packages.

\hypertarget{demand-forecasting}{%
\subsubsection{Demand forecasting}\label{demand-forecasting}}

This section demonstrates the demand forecasting capabilities of
\pkg{rmdcev}. Please refer to the previous section for an overview of
the three steps to simulation.

\begin{Schunk}
\begin{Sinput}
policies <- CreateBlankPolicies(npols = 2,
                                nalts = mdcev_mle$stan_data[["J"]],
                                mdcev_mle$stan_data[["dat_psi"]],
                                price_change_only = TRUE)

policies$price_p[[1]] <- c(0, rep(1, nalts))
policies$price_p[[2]][10:13] <- rep(10, 4)
df_sim <- PrepareSimulationData(mdcev_mle, policies)

demand <- mdcev.sim(df_sim$df_indiv,
                        df_common = df_sim$df_common,
                        sim_options = df_sim$sim_options,
                        cond_err = 1,
                        nerrs = 20,
                        sim_type = "demand")
\end{Sinput}
\begin{Soutput}
#> Using general approach to simulation
\end{Soutput}
\begin{Soutput}
#> Simulating demand...
\end{Soutput}
\begin{Soutput}
#> 
#> 4.32e+06simulations finished in0.57minutes.(126058per second)
\end{Soutput}
\begin{Sinput}
summary(demand)
\end{Sinput}
\begin{Soutput}
#> # A tibble: 36 x 6
#> # Groups:   policy [2]
#>    policy    alt     mean std.dev `ci_lo2.5%` `ci_hi97.5%`
#>    <chr>   <int>    <dbl>   <dbl>       <dbl>        <dbl>
#>  1 policy1     0 68912.      4.62    68905.      68920.   
#>  2 policy1     1     6.45    0.02        6.41        6.47 
#>  3 policy1     2    12       0.04       11.9        12.0  
#>  4 policy1     3     2.41    0.04        2.33        2.46 
#>  5 policy1     4     7.61    0.03        7.56        7.65 
#>  6 policy1     5     3.84    0.02        3.79        3.87 
#>  7 policy1     6    22.0     0.05       21.9        22.1  
#>  8 policy1     7     5.34    0.01        5.32        5.34 
#>  9 policy1     8    39.1     0.06       39.0        39.2  
#> 10 policy1     9     0.56    0           0.56        0.570
#> # ... with 26 more rows
\end{Soutput}
\end{Schunk}

The output of the demand simulation a \code{mdcev.sim} object with a
list of \(I\) elements, one for each individual. Within each element
there are nsim lists each containing a matrix of demands. The rows of
the matrix are for each policy scenario and the columns represent each
alternative. The summary function computes summary statistics.

\hypertarget{conclusions}{%
\section{Conclusions}\label{conclusions}}

The \pkg{rmdcev} package implements the multiple discrete-continuous
extreme value model with heterogeneity that can be continuous
(i.e.~random parameters) or discrete (i.e.~latent classes). Models can
be estimated using maximum likelihood or Bayesian techniques. This paper
demonstrates the use of the pacakage to estimate several model
specifications and to derive demand forecasts and welfare implications
of policy scenarios. To my knowledge, there is no other available
statistical package that can estimate welfare implications of policy
scenarios using MDCEV models. I hope that the publication of
\pkg{rmdcev} will make MDCEV modeling available to a wider audience.

\hypertarget{appendix-a-specific-steps-for-simulating-mdcev-models}{%
\section*{Appendix A: Specific steps for simulating MDCEV
models}\label{appendix-a-specific-steps-for-simulating-mdcev-models}}
\addcontentsline{toc}{section}{Appendix A: Specific steps for simulating
MDCEV models}

There are two alogrithms that differ depending on the MDCEV model
specification. If a single \(\alpha\) parameter is estimated (i.e.~model
= ``hybrid'' or ``hybrid0''), then we can use the hybrid approach to
welfare simulation. If there are heterogenous \(\alpha\) parameters,
then we can use the general approach to welfare simulation. The hybrid
approach is less computationally intensive and provides an exact
analytical solution but the general approach can be used with all
utility specifications. The specific steps for both algorithms are
described below. Additional details are provided in
\citet{lloydsmithnew2018}.

\textbf{Steps in algorithm for hybrid-profile utility specifications}

\textbf{Step 0}: Assume that only the numeraire alternative is chosen
and let the number of chosen alternatives equal one (M=1).

\textbf{Step 1}: Using the data, model parameters, and either
conditional or unconditional simulated error term draws, calculate the
price-normalized baseline utility values (\(\psi_k/p_k\)) for all
alternatives. Sort the \(K\) alternatives in the descending order of
their price-normalized baseline utility values. Note that the numeraire
alternative is in the first place. Go to step 2.

\textbf{Step 2}: Compute the value of \(\lambda^E\) using the following
equation:

\begin{equation}
\frac{1}{\lambda^E} = \left[ \frac{\alpha \bar{U} + \sum_{m=2}^{M} \gamma_m \psi_m} {\sum_{m=2}^{M} \gamma_m \psi_m \left( \frac{p_m}{\psi_m} \right)^\frac{\alpha}{\alpha-1} + \psi_1 \left(\frac{p_1}{\psi_1} \right)^\frac{\alpha}{\alpha-1}} \right] ^\frac{\alpha-1}{\alpha}
\end{equation}

Go to step 3.

\textbf{Step 3}: If
\(\frac{1}{\lambda^E} > \frac{\psi_{M+1}}{p_{M+1}}\), go to step 4. Else
if \(\frac{1}{\lambda^E} < \frac{\psi_{M+1}}{p_{M+1}}\), set
\(M = M + 1\). If \(M < K\), go back to step 2. If \(M = K\), go to step
4.

\textbf{Step 4}: Compute the optimal Hicksian consumption levels for the
first \(I\) alternatives in the above descending order using the
following equations

\begin{align}
\label{eq:optimal_x}
x_1 &=   \left( \frac{p_1}{\lambda^E \psi_1} \right)^\frac{1}{\alpha_1-1}\text{, and} \\
x_m &=   \left[ \left( \frac{p_m}{\lambda^E \psi_m} \right)^\frac{1}{\alpha_m-1}-1 \right]\gamma_m, \; \; \text{if} \; \; x_m > 0.
\end{align}

Set the remaining alternative consumption levels to zero and stop.

\textbf{Steps in algorithm for general utility specifications}

\begin{verbatim}
In this context, there is no closed-form expressions for $\lambda^E$ and we need to conduct a numerical bisection routine. Let $\hat{\lambda^E}$ and $\hat{U}$ be estimates of $\lambda^E$ and $U$ and let $tol_{\lambda}$ and $tol_{U}$ be the tolerance levels for estimating $\lambda^E$ and $U$ that can be arbitrarily small. The algorithm works as follows:
\end{verbatim}

\textbf{Step 0}: Assume that only the numeraire is chosen and let the
number of chosen alternatives equal one (M=1).

\textbf{Step 1}: Using the data, model parameters, and either
conditional or unconditional simulated error term draws, calculate the
price-normalized baseline utility values (\(\psi_k/p_k\)) for all
alternatives. Sort the \(K\) alternatives in the descending order of
their price-normalized baseline utility values. Note that the numeraire
is in the first place. Go to step 2.

\textbf{Step 2}: Let
\(\frac{1}{\hat{\lambda^E}} = \frac{\psi_{M+1}}{p_{M+1}}\) and
substitute \(\hat{\lambda^E}\) into the following quation to obtain an
estimate of \(\hat{U}\).

\begin{align}
\bar{U}=\sum_{M=2}^{M} \frac{\gamma_m}{\alpha_m}\psi_m \left[ \left( \frac{p_m}{\lambda^E \psi_m} \right)^\frac{\alpha_m}{\alpha_m-1} - 1 \right] + \frac{\psi_1}{\alpha_1}\left(\frac{p_1}{\lambda^E \psi_1} \right)^\frac{\alpha_1}{\alpha_1-1}.
\end{align}

\textbf{Step 3}: If \(\hat{U} < \bar{U}\), go to step 4. Else, if
\(\hat{U} \geq \bar{U}\), set
\(\frac{1}{\lambda_l^E}= \frac{\psi_{M+1}}{p_{M+1}}\) and
\(\frac{1}{\lambda_u^E}= \frac{\psi_{M}}{p_{M}}\). Go to step 5.

\textbf{Step 4}: Set \(M=M+1\). If \(M<K\), go to step 2. Else if
\(M=K\), set \(\frac{1}{\lambda_l^E}= 0\) and
\(\frac{1}{\lambda_u^E}= \frac{\psi_{K}}{p_{K}}\). Go to step 5.

\textbf{Step 5}: Let \(\hat{\lambda^E}= (\lambda_l^E+\lambda_u^E)/2\)
and substitute \(\hat{\lambda^E}\) into the equation of step 2 to obtain
an estimate of \(\hat{U}\). Go to step 6.

\textbf{Step 6}: If \(|\lambda_l^E-\lambda_u^E| \leq \; tol_{\lambda}\)
or \(|\hat{U}-\bar{U}| \leq \; tol_{U}\), go to step 7. Else if
\(\hat{U}<\bar{U}\), update \(\lambda^E_u= (\lambda_l^E+\lambda_u^E)/2\)
and go to step 5. Else if \(\hat{U}>\bar{U}\), update
\(\lambda^E_l= (\lambda_l^E+\lambda_u^E)/2\) and go to step 5.

\textbf{Step 7}: Compute the optimal Hicksian consumption levels for the
first \(M\) alternatives in the above descending order using Equation
(\ref{eq:optimal_x}). Set the remaining alternative consumption levels
to zero and stop.

\bibliography{lloyd-smith}


\address{%
Patrick Lloyd-Smith\\
University of Saskatchewan\\
Department of Agricultural and Resource Economics Room 3D34, Agriculture
Building 51 Campus Drive Saskatoon, SK S7N 5A8 Canada\\
}
\email{patrick.lloydsmith@usask.ca}

