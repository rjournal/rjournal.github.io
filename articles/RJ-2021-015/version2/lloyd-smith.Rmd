---
title: "Kuhn-Tucker and Multiple Discrete-Continuous Extreme Value Model Estimation and Simulation in R: The rmdcev Package"
author:
  - name: Patrick Lloyd-Smith
    affiliation: University of Saskatchewan
    address: >
      Department of Agricultural and Resource Economics
      Room 3D34, Agriculture Building
      51 Campus Drive  
      Saskatoon, SK S7N 5A8 Canada
    email: \email{patrick.lloydsmith@usask.ca}
    url: https://plloydsmith.github.io/
abstract: >
 This paper introduces the package \pkg{rmdcev} in R for estimation and simulation of Kuhn-Tucker demand models with individual heterogeneity. The models supported by \pkg{rmdcev} are the multiple-discrete continuous extreme value (MDCEV) model and Kuhn-Tucker specification common in the environmental economics literature on recreation demand. Latent class and random parameters specifications can be implemented and the models are fit using maximum likelihood estimation or Bayesian estimation. The \pkg{rmdcev} package also implements demand forecasting and welfare calculation for policy simulation. The purpose of this paper is to describe the model estimation and simulation framework and to demonstrate the functionalities of \pkg{rmdcev} using real datasets.
output:
  rticles::rjournal_article:
    includes:
      in_header: preamble.tex
---

```{r setup, include = TRUE, echo = FALSE, message = FALSE, warning = FALSE, eval = TRUE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

# Load packages
library(rmdcev)
#knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
#opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

# Introduction

Individual choice contexts are often characterized by both extensive (i.e. what alternative to choose) and intensive (i.e. how much of an alternative to consume) margins \citep{bhatmultiple2008}. These multiple discrete-continuous (MDC) choice situations are pervasive, arising in transportation, marketing, health, and decisions regarding environmental resources \citep{bhatmultiple2014}. The Kuhn-Tucker (KT) modelling framework is often employed to analyze these MDC situations and substantial progress has been made in improving these econometric modeling structures \citep{vonhaefenkuhn-tucker2005, bhatmultiple2014}. Despite the large potential applications for KT models, there remains a gap between this potential and actual examples of these models being used. One of the reasons cited for the lack of widespread use of KT models is that estimating and simulating these models is challenging. The explanations of methods used to work with these models are spread across many papers and few user friendly software tools are available. The purpose of this paper is to present a unified account for KT estimation and simulation alongside computer code for easy and efficient implementation.

This paper presents an overview of the R package \pkg{rmdcev} which can estimate and simulate KT demand models with discrete or continuous unobserved individual heterogeneity.^[This paper uses version 1.2.0 of the \pkg{rmdcev} package.] The common starting point for all KT models is the individual's constrained optimization problem and exploiting the resulting KT first order conditions in estimation. The most popular empirical KT modelling framework is the multiple-discrete continuous extreme value (MDCEV) model as first introduced by Bhat (2008). A separate stream of literature in the environmental economics on recreation demand has developed a closely related set of models and use the term KT to describe the models. In this paper, we use KT to describe the general modelling framework, MDCEV to describe the Bhat (2008) specifications, and KT-EE to describe the environmental economics literature KT specification \citep{vonhaefenestimation2004}. One of the main differences between the MDCEV and KT-EE frameworks is how alternative-specific attributes enter the utility function, a point we describe in the paper. 

Incorporating preference heterogeneity has been an important advancement in choice modeling. Both the MDCEV and KT-EE specifications can be estimated to incorporate unobserved preference heterogeneity by assuming continuous distributions using random parameters or using a latent class (LC) specification assuming a discrete distribution where people can be divided into distinct segments. The models in \pkg{rmdcev} can be fit using maximum likelihood estimation or Bayesian estimation. Besides estimation, the \pkg{rmdcev} package also implements demand forecasting and welfare calculation for policy simulation. The two main functions in the \pkg{rmdcev} are \code{mdcev} used to estimate all model specifications and \code{mdcev.sim} used to simulate both demand and welfare implications. \pkg{rmdcev} is available from the Comprehensive R Archive Network (CRAN) at https://CRAN.R-project.org/package=rmdcev as well as from GitHub at https://github.com/plloydsmith/rmdcev.

While there are several R packages available to estimate discrete choice data such as \pkg{apollo} \citep{hessapollo2019}, \pkg{mlogit} \citep{mlogit2019}, and \pkg{gmnl} \citep{sarriasmultinomial2017}^[ \citet{sarriasmultinomial2017} provides a good overview of the different R packages available to estimate discrete choice models], there are limited options for users interested in estimating and simulating KT models. In addition to \pkg{rmdcev}, the [\pkg{apollo}](http://www.apollochoicemodelling.com/) package developed by Stephane Hess and David Palma at the Choice Modelling Centre in Leeds provides a flexible modelling platform for estimating MDCEV models and simulating demand behaviour \citep{hessapollo2019}. \pkg{apollo} estimates a full suite of choice models including discrete choice models and is thus more comprehensive and flexible than \pkg{rmdcev}. The main advantages for KT modeling in using the \pkg{rmdcev} is that it 1) provides functions for calculating welfare implications of policy scenarios, 2) allows the estimation and simulation of the KT formulation used in environmental economics \citep{vonhaefenkuhn-tucker2005}, 3) uses the Stan program \citep{carpenterstan2017} for Bayesian estimation and thus the user has access to specialized postestimation commands, and 4) is primarily coded in C++ and thus around 20 times faster. The main limitations \pkg{rmdcev} compared to \pkg{apollo} is that it 1) only estimates model specifications with an outside good that is always consumed whereas \pkg{apollo} can estimate models without an outside good, 2) users have more control over which particular parameters are fixed at their starting values and which are allowed to be random parameters, and 3) \pkg{apollo} allows users to estimate the multiple discrete continuous nested extreme value model and LC-random parameter MDCEV specifications.

The paper first introduces the conceptual framework underlying KT models and the connection to economic theory and welfare measures. Section [2](#models) also describes the various empirical specifications for KT models. Section [3](#rmdcev) introduces the \pkg{rmdcev} package focusing first on estimation before moving on to discuss how to conduct welfare and demand simulations. Section [4](#conclusions) provides conclusions of the paper.

# Models {#models}

## Conceptual framework

This section describes the underlying conceptual framework for KT models. Each individual $i$ maximizes utility through the choice of the numeraire or outside good ($x_{i1}$) and the non-numeraire alternatives ($x_{ik}$) subject to a monetary or non-monetary budget constraint. We assume there is a numeraire good (i.e. essential Hicksian composite good) which is always consumed and has a price of one. The individual's maximization problem is

\begin{align}
\begin{split}
 & \max_{x_{ik}, x_{i1}} U(x_{ik}, x_{i1}) \\
& s.t. \;\;\;y_i = \sum\limits^K_{k=2}p_{ik} x_{ik} + x_{i1}, \;\; x_{ik} \geq 0,\;\; k = 2,...,K,
  \end{split}
\end{align}

\noindent
where $x_{ik}$ is the consumption level for alternative $k$, $x_{i1}$ is consumption of the numeraire, $y_i$ is any arbitrary budget amount (e.g. annual income), and $p_{ik}$ is the unit price of alternative $k$.

The resulting first-order KT conditions that implicitly define the solution to the optimal consumption bundles of $x_{ik}$ and $x_{i1}$ are

\begin{align}
\label{eq:kt_conditions}
\begin{split}
 \frac{U_{x_{ik}}}{U_{x_{i1}}} & \leq p_{ik},\; \; k = 1,....K , \\
  x_{ik}\left[\frac{U_{x_{ik}}}{U_{x_{i1}}} - p_{ik} \right] & = 0,\; \; k = 1,....K.
  \end{split}
\end{align}

For alternatives with positive consumption levels, the marginal rate of substitution between these alternatives and the numeraire good is equal to the price of the alternative. For unconsumed alternatives, the marginal rate of substitution between these alternatives and the numeraire good is less than the price of the alternatives. For the rest of the paper, we drop the subscript $i$ for notational simplicity.

These first-order conditions can be used to derive Marshallian and Hicksian demands and welfare measures \citep{vonhaefenkuhn-tucker2005}. We assume that alternatives have non-price attribute $q_{k}$ and the vector of $k$ prices and attributes is denoted as $p$ and $q$. The Hicksian compensating surplus ($CS^H$) for a change in price and quality from baseline levels $p^0$ and $q^0$ to new 'policy' levels $p^1$ and $q^1$ is defined explicitly using an expenditure function

\begin{equation}
\label{eq:welfare}
CS^H = y - e(p^1, q^1, \bar{U}, \theta, \varepsilon),
\end{equation}

\noindent
where $\theta$ is the vector of structural parameters ($\psi_k, \alpha_k, \gamma_k$), $\varepsilon$ is a vector or matrix of unobserved heterogeneity, and $\bar{U} = V(p^0, q^0, y, \theta, \varepsilon)$ and represents baseline utility.

## Multiple discrete-continuous extreme value model (MDCEV)

The \pkg{rmdcev} package implements the random utility specification of the MDCEV as introduced by \citet{bhatmultiple2008}. The model specifications included in \pkg{rmdcev} always assume an outside good (i.e. the numeraire good that is always consumed by every individual). The general utility function is specified as

\begin{equation}
U(x_k, x_1) = \sum_{k=2}^{K} \frac{\gamma_k}{\alpha_k}\psi_k \left[ \left( \frac{x_k}{\gamma_k} + 1 \right)^{\alpha_k} - 1 \right] + \frac{\psi_1}{\alpha_1}x_1^{\alpha_1} \label{utilkt},
\end{equation}

\noindent
where $\gamma_k > 0$, $\psi_k > 0$ and $\alpha_k \leq 1$ for all $k$ are required for this specification to be consistent with the properties of a utility function \citep{bhatmultiple2008}. \citet{bhatmultiple2008} provides a detailed overview of the parameter interpretation and in brief

- The $\psi_k$ parameters represent the marginal utility of consuming alternative $k$ at the point of zero consumption (i.e. baseline marginal utility).
- The $\gamma_k$ parameters are translation parameters that allow for corner solutions (i.e. zero consumption levels for alternatives) and also influence satiation. The lower the value of $\gamma_k$, the greater the satiation effect in consuming $x_k$.
- The $\alpha_k$ parameters control the rate of diminishing marginal utility of additional consumption. If $\alpha_k$ equal to one, then there is no satiation effects (i.e. constant marginal utility).

The 'random utility' element of the model is introduced into the baseline utility through a random error term as

\begin{equation}
\label{eq:psi}
\psi_k=\psi(z_k,\varepsilon_k)= exp(\beta'z_k+\varepsilon_k),
\end{equation}

\noindent
where $z_k$ is a set of variables that can include alternative-specific attributes and individual-specific characteristics, and $\varepsilon_k$ is an error term that allows for the utility function to be random over the population. We assume an extreme value distribution that is independently distributed across alternatives for $\varepsilon_k$ with an associated scale parameter of $\sigma$. For identification, we specify $\psi_1= e^{\varepsilon_1}$.

To ensure the estimated utility function corresponds to economic theory we specify $\gamma_k = exp(\gamma^*_k)$ such that $\gamma_k > 0$ and $\alpha_k = exp(\alpha^*_k)/(1 + exp(\alpha^*_k))$ such that $0 < \alpha_k < 1$. $\gamma^*_k$ and $\alpha^*_k$ are estimated in the package and $\gamma_k$ and $\alpha_k$ are reported to the user. Similarly, we specify $\sigma = exp(\sigma^*)$. Weak complementarity, which is required for deriving unique welfare measures \citep{malerenvironment1974}, is imposed in this specification by adding and subtracting one in the non-numeraire part of the utility function.

While the most general form of the MDCEV model includes $\psi_k$, $\gamma_k$, and $\alpha_k$ parameters for each alternative, Bhat (2008) discusses the identification concerns regarding estimating separate $\gamma_k$ and $\alpha_k$ parameters for each non-numeraire alternative. Typically only a subset of these parameters can be identified and there are three common utility function specifications:

1. $\alpha$-profile: set all $\gamma_k$ parameters to 1.

\begin{equation}
\label{eq:alpha}
U(x_k, x_1) = \sum_{k=2}^{K} \frac{1}{\alpha_k}exp(\beta'z_k+\varepsilon_k) \left[ \left( x_k + 1 \right)^{\alpha_k} - 1 \right] + \frac{exp(\varepsilon_1)}{\alpha_1}x_1^{\alpha_1}.
\end{equation}

2. $\gamma$-profile: set all non-numeraire $\alpha_k$ parameters to 0.

\begin{equation}
\label{eq:gamma}
U(x_k, x_1) = \sum_{k=2}^{K} \gamma_k exp(\beta'z_k+\varepsilon_k) \ln\left( \frac{x_k}{\gamma_k} + 1 \right) + \frac{exp(\varepsilon_1)}{\alpha_1}x_1^{\alpha_1}.
\end{equation}

\begin{equation}
\label{eq:gamma}
U(x_k, x_1) = \sum_{k=2}^{K} exp(\beta'z_k+\varepsilon_k) \ln\left( \phi_k x_k + \gamma_k \right) + \frac{1}{\alpha_1}x_1^{\alpha_1}.
\end{equation}

3. hybrid-profile: set all $\alpha_k=\alpha_1=\alpha$.

\begin{equation}
\label{eq:hybrid}
U(x_k, x_1) = \sum_{k=2}^{K} \frac{\gamma_k}{\alpha} exp(\beta'z_k+\varepsilon_k) \left[ \left( \frac{x_k}{\gamma_k} + 1 \right)^{\alpha} - 1 \right] + \frac{exp(\varepsilon_1)}{\alpha}x_1^{\alpha}.
\end{equation}

The likelihood function representing the model probability of the consumption pattern where $M$ alternatives are chosen can be expressed as \citet{bhatmultiple2008}

\begin{equation}
\label{eq:ll_base}
P(x^{*}_1,x^{*}_2...x^{*}_M,0,...,0) = \frac{1}{\sigma^{M-1}} \left(\prod_{m=1}^M c_m \right)\left(\sum_{m=1}^M \frac{p_m}{c_m} \right) \left( \ \frac{\prod_{m=1}^M e^{V_m/\sigma}}{ \left( \sum_{k=1}^J e^{V_k/\sigma} \right)^M }\right)(M-1)!,
\end{equation}

\noindent
where $\sigma$ is the scale parameter and $c_m = \frac{1-\alpha_m}{x_m+ \gamma_m}$. The $V$ expression depend on what model specification is used:

1. $\alpha$-profile: $V_k = \beta' z_k + (\alpha_k-1)\ln\left( x_k + 1 \right) - \ln \left(p_k\right)$ for $k \geq 2$, and $V_1 = (\alpha_1-1)\ln(x_1)$.

2. $\gamma$-profile: $V_k = \beta' z_k - \ln\left( \frac{x_k}{\gamma_k} + 1 \right) - \ln \left(p_k\right)$ for $k \geq 2$, and $V_1 = (\alpha_1-1)\ln(x_1)$.

3. hybrid-profile: $V_k = \beta' z_k + (\alpha-1)\ln\left( \frac{x_k}{\gamma_k} + 1 \right) - \ln \left(p_k\right)$ for $k \geq 2$, and $V_1 = (\alpha-1)\ln(x_1)$.

## Kuhn-Tucker model specifications in Environmental Economics (KT-EE)

The \pkg{rmdcev} package also implements the KT-EE specification \citep{vonhaefenkuhn-tucker2005}. The utility function in this specification is similar to the $\gamma$-profile of the MDCEV specification introduced above and is

\begin{equation}
U(x_k, x_1) = \sum_{k=2}^{K}\psi_k \ln \left(\phi_kx_k + \gamma_k \right) + \frac{1}{\alpha_1}x_1^{\alpha_1}, 
\label{eq:util_kt_ee}
\end{equation}

\noindent
where $\phi_k >0$.^[The environmental economics literature uses slightly different notation as typically $\theta$ is used for $\gamma$, $\mu$ is used for $\sigma$, and $\rho$ for $\alpha_1$. We change the notation slightly for consistency with the MDCEV model specifications.] 

An important difference between this KT formulation and the MDCEV models is the way weak complementary is imposed. In this KT formulation, weak complementarity is imposed by only including alternative-specific attributes in the $\phi_k$ parameter and not the $\psi_k$ parameter.^[See \citet{herrigeswhats2004} for more discussion on this point.]

In this formulation, the estimating first-order conditions can be written as

\begin{equation}
\varepsilon_k \leq \frac{1}{\sigma}\left( -\beta' s + \ln(\frac{p_k}{\phi_k}) + \ln(\phi_k x_k + \gamma_k) + (\alpha_1 - 1)\ln (y - p_k * x_k) \right ), \; \; \forall k,
\label{eq:kt_g}
\end{equation}

and the resulting likelihood function as

\begin{equation}
P(x) = |J| \prod_k \left[exp(-g_k(.))/ \sigma \right]^{1(x_k>0)} exp[-exp(-g_k(.))],
\label{eq:ll_kt_ee}
\end{equation}

where $|J|$ is the determinant of the Jacobian of transformation, $g_k(.)$ is the right hand side of Equation (\ref{eq:kt_g}), and $1(x_k>0)$ is equal to one if $x_k$ is positive and equal to zero if $x_k$ is zero \citep{vonhaefenkuhn-tucker2005}. In previous implementations, the KT formulation used the computationally intensive numerical gradient approach to the calculation of the determinant of the Jacobian of transformation \citep{vonhaefenkuhn-tucker2005}. 

The \pkg{rmdcev} package uses the compact structure of the determinant of the Jacobian as derived by Bhat (2008) and defined as

\begin{equation}
|J| = \frac{(1-\alpha_1)}{x_1} \left[ \prod_m \frac{\phi_m}{\phi_m * x_m + \gamma_m} \right] \left[ {x_1}{(1-\alpha_1)} + \sum_m \frac{(\phi_m * x_m + \gamma_m)* p_m}{\phi_m} \right],
\end{equation}

where $m$ denotes non-numeraire alternatives with positive consumption levels. Using this analytical gradient approach has the benefit of substantially speeding up estimation by around 70% relative to the numerical gradient approach.

In both the MDCEV and KT-EE specifications described above, the parameters ($\beta, \alpha_k , \gamma_k, \phi_k, \sigma$) are structural parameters that are assumed to be equal across the population which simplifies estimation. However, these fixed parameter specification is quite restrictive as they can only incorporate preference heterogeneity through interaction terms with observed individual characteristics. Without these interaction terms, the fixed specifications impose the assumption that all individuals have the same tastes for alternatives (i.e. preference homogeneity). This assumption is relaxed in the next two specifications which are able to accommodate both observed and unobserved preference heterogeneity.

## Latent class (LC-KT) models

The latent class version of the KT model assumes that an individual belongs to a finite mixture of $S$ segments each indexed by $s$ ($s=1,2,...S$) \citep{sobhanilatent2013, kuriyamalatent2010}.  Within each segment, the LC specification assumes preference homogeneity. We do not observe which segment an individual belongs to but we can attribute a probability $\pi_{is}$ that individual $i$ is a member of segment $s$. We impose that $0 \leq \pi_{is} \leq 1$ and $\sum^S_{s=1} \pi_{is} = 1$ through the use of the logit link function as

\begin{equation}
\pi_{is} = \frac{exp(\delta_s'w_i)}{\sum^S_{s=1}exp(\delta_s'w_i)},
\end{equation}

\noindent
where $w_i$ is a vector of individual characteristics and $\delta_s$ is a vector of coefficients to be estimated. The $\delta_s$ coefficients determine how the individual characteristics affect the membership of individual $i$ in segment $s$. For identification, the $\delta_1$ coefficients for the first segment are set to zero.

The likelihood function can be written as

\begin{equation}
P = \prod_{i} \pi_{is}P_{is},
\end{equation}

where $P_{is}$ has the same form as Equations (\ref{eq:ll_base}) and Equations (\ref{eq:ll_kt_ee}) but is now class specific.

## Random parameters (RP-LC) models

The random parameter specification of the LC models assumes that the structural parameters $\theta =  (\beta, \alpha_k , \gamma_k)$ are not necessarily fixed but have an assumed distribution \citep{bhatmultiple2008}. In \pkg{rmdcev}, parameters are distributed multivariate normal with a mean $\bar{\theta}$ and variance covariance matrix $\sum_{\theta}$ \citep{vonhaefenkuhn-tucker2005}. This structure allows for continuous preference heterogeneity and accommodates more flexible correlation patterns between alternatives in a similar fashion to the mixed logit model in discrete choice models. The $\sigma$ scale parameter is always assumed to be a fixed parameter.

The most flexible model specification is to estimate the full variance covariance matrix and if there are $Q$ parameters in $\theta$ then there are $Q(Q+1)/2$ unique variance covariance parameters to estimate in the correlated RP-MDCEV specification. An alternative is to assume the off-diagonal parameters are zero and estimate uncorrelated random parameters by estimating the $Q$ diagonal elements of $\sum_{\theta}$. If all elements of $\sum_{\theta}$ are assumed to be zero, the model collapses to the fixed KT structures.

## A note on Bayesian versus classical maximum likelihood estimation

The KT model without unobserved heterogeneity can be estimated using Bayesian or classical maximum likelihood techniques. The LC-KT model can only be estimated using classical maximum likelihood techniques as Bayesian approaches are challenged by the 'label switching' problem \citep{jasra2005}. The RP-KT models can only be estimated using Bayesian techniques as random parameter models require simulated maximum likelihood estimators and these are not implemented in \pkg{rmdcev} at this time.

While there are philosophical differences between Bayesian and classical maximum likelihood techniques to estimating models, the Bernstein-von Mises theorem suggests that the Bayesian posterior distribution are asymptotically equivalent to maximum likelihood estimates if the data generating process has been correctly specified \citep{traindiscrete2003}.


# The rmdcev package {#rmdcev}

## Data format

The \pkg{rmdcev} uses \code{mdcev.data} function for handling multiple discrete-continuous data while ensuring the data is in the correct format and is suitable for estimation. The \pkg{rmdcev} package accepts data in "long" format (i.e. one row per available non-numeraire alternative for each individual). There is no row for the numeraire (i.e. outside) good. If there are $I$ individuals and $J$ non-numeraire alternatives, then the data frame should have $IxJ$ rows.  

To illustrate the suitable form of the data, we can load the recreation data included with the \pkg{rmdcev} package. This data is from the Canadian Nature Survey and includes choices for number of days spent recreating in 17 different outdoor activities for 2,000 people \citep{federal20122014}.

```{r, echo=T, data}
data(data_rec, package = "rmdcev")
```

Each recreation activity is characterized by the daily costs of participation for each individual. In addition to the recreation behaviour and prices, the data includes information on three individual characteristics: university (a dummy variable if the person has completed a university degree), ageindex (a person's age divided by the average age in sample), and urban (a dummy variable if a person lives in an urban area). Additional details on the data and price construction are provided in \citet{lloydsmitheconomics2020}. We can summarize the average consumption and price levels for each alternative as:

```{r, echo=T, summary}
aggregate(cbind(quant, price) ~ alt, data = data_rec, FUN = mean )
```

The data can be transformed into the structure for MDCEV estimation using the \code{mdcev.data} function:

```{r, echo=T, mdcev.data_test}
data_mdcev <- mdcev.data(data_rec,
					   id.var = "id",
					   alt.var = "alt",
					   choice = "quant")
```

The \code{id.var} argument indicates what variable uniquely identifies individuals in the data set, \code{alt.var} indicates the variable that identifies the non-numeraire alternatives, and \code{choice} indicates the level of consumption made by the individuals. Two other optional arguments of \code{mdcev.data} are \code{price} and \code{income} indicating the individual-specific price levels for each alternative, and the income level for each individual. These two arguments only need to be explicitly specified if they are not labeled price and income. Alternative-specific attributes and individual-specific characteristics can be included as additional columns and do not need to be specified in \code{mdcev.data}.

The \code{mdcev.data} function also checks to ensure the data has the necessary variables, and that all individuals spend positive amounts on the numeraire good. If an individual does not have positive expenditures on the numeraire good, an error message is given.

## KT estimation

###	A general overview of mdcev

The \pkg{rmdcev}

All the various KT model specifications are estimated using the \code{mdcev} function.

```{r, echo=T, mdcev}
args(mdcev)
```

The main arguments are briefly explained below:

- \code{formula}: Formula for the model to be estimated as described in Section {#formula}.

- \code{data} The ($IxJ$) data to be used in estimation as described above.

- \code{weights} An optional vector of sampling or frequency weights.

- \code{model} A string indicating which model specification to estimate. The four options are presented below:
	+ "alpha": $\alpha$-profile with all $\gamma_k$ parameters fixed equal to 1 (Equation (\ref{eq:alpha})).
	+ "gamma": $\gamma$-profile with one estimated $\alpha_1$ and all non-numeraire $\alpha_k$ parameters equal to 0 (Equation (\ref{eq:gamma})).
	+ "hybrid": hybrid-profile with a single estimated $\alpha$ parameter (i.e. $\alpha_1 = \alpha_k = \alpha$) (Equation (\ref{eq:hybrid})).
	+ "hybrid0": hybrid-profile with all $\alpha$ parameters fixed equal to 1e-3 (Equation (\ref{eq:hybrid})).
	+ "kt_ee": Environmental economics version of KT model (Equation (\ref{eq:util_kt_ee})).
	
- \code{n\_classes} The number of latent classes. Note that the LC model is automatically estimated as long as the prespecified number of classes is set greater than 1.

- \code{gamma\_ascs} Indicator to include alternative-specific gammas parameters.
- \code{psi\_ascs} Whether to include alternative-specific psi parameters. The first alternative is used as the reference category. Only specify to 1 for MDCEV models.

- \code{fixed\_scale1} Whether to fix the scale parameter at 1.

- \code{trunc\_data} Whether the estimation should be adjusted for truncation of non-numeraire alternatives. This option is useful if the data only includes individuals with positive non-numeraire consumption levels such as recreation data collected on-site. To account for the truncation of consumption, the likelihood is normalized by one minus the likelihood of observing zero consumption for all non-numeraire alternatives (i.e. likelihood of positive consumption) following Englin, Boxall and Watson (1998) and von Haefen (2003).

- \code{seed} Random seed.

- \code{algorithm} Either "Bayes" for Bayesian estimation or "MLE" for maximum likelihood estimation. The MLE algorithm uses the Limited-memory BFGS which approximates the Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm but uses less computer memory.

- \code{flat\_priors} indicator if completely uninformative priors should be specified. Defaults to 1 if MLE used and 0 if Bayes used. If using MLE and set flat_priors = 0, penalized MLE is used and the optimizing objective is augmented with the priors.

- \code{print\_iterations} Whether to print intermediate iteration information or not.

- \code{std\_errors} Compute standard errors using the delta method ("deltamethod") or multivariate normal draws ("mvn"). The default is "deltamethod". Note that mvn parameter draws should be used to incorporate parameter uncertainty for demand and welfare simulation. For maximum likelihood estimation only.

- \code{n\_draws} The number of multivariate normal draws for standard error calculations if "mvn" is specified.

- \code{initial.parameters} The default for fixed and random parameter specifications is to use random starting values. For LC models, the default is to use slightly adjusted MLE point estimates from the single class model. Initial parameter values should be included in a named list. For example, the LC "hybrid" specification initial parameters can be specified as:
 initial.parameters = list(psi = array(0, dim = c(K, num_psi)),
                             gamma = array(1, dim = c(K, num_alt)),
                             alpha = array(0.5, dim = c(K, 1)),
                             scale = array(1, dim = c(K)))
 where K is the number of classes (i.e. K = 1 is used for single class models), num_psi is number of psi parameters, and num_alt is number of non-numeraire alternatives.

## Formula format {#formula}

The formula is used to incorporate alternative-specific variables and individual-specific characteristics into the $\psi_k$ parameters, the membership equation of the LC-KT models, and $\phi_k$ parameters for the KT-EE specification. By default, alternative-specific constants (ASCs) for all non-numeraire alternatives are included in the $\psi_k$ and $\gamma_k$ parameters. For the $\psi_k$, the first ASC is fixed at 0 due to identification concerns. They can be omitted using the \code{psi\_ascs = 0} and \code{gamma\_ascs = 0} arguments. Furthermore, the $\gamma_k$, $\alpha_k$, and $\sigma$ parameters cannot include alternative- or individual specific variables besides ASCs.

The formula is divided in three parts, separated by the symbol \code{|} and is based on the R package \pkg{Formula} \citep{zeileisextended2010}. The first part is reserved for the $z_k$ variables in $\psi_k$ as in Equation (\ref{eq:psi}), excluding ASCs. These can include alternative-specific and individual-specific variables. Interaction terms between variables can be included using the normal \pkg{Formula} syntax of \code{z1:z2}. This is particularly useful for creating interaction terms to incorporate observed preference heterogeneity for alternative-specific variables and individual-specific characteristics. 

For a model with only ASCs in $\psi_k$, the formula can be specified as

```{r, echo=T}
f1 = ~ 0
```

We can add individual-specific variables to the $\psi_k$ parameters as follows

```{r, echo=T}
f2 = ~ university + ageindex
```

Alternative-specific variables such as \code{z1} and \code{z2} can be included in the same way such as

```{r, echo=T}
f2 = ~ z1 + z2
```

The second part corresponds to individual-specific characteristics that enter in the probability assignment in models with latent classes. The formula will automatically include a constant in the membership equation but this can be omitted if \code{-1} is used in the formula. For example, a LC model with no alternative-specific variables in the $psi_k$ parameters and \code{university}, \code{ageindex} and a constant determine the class membership can be specified as

```{r, echo=T}
f3 = ~ 0 | university + ageindex
```

The third part is reserved for the $q_k$ variables included in the $\phi_k$ parameters in the KT-EE model specification ( Equation \ref{eq:util_kt_ee})) as in Equation (\ref{eq:phi}). For example, if there was an alternative-specific variable named 'q1', it can be included as below

```{r, echo=T}
f4 = ~ 0 | 0 | q1
```

### Estimating KT using maximum likelihood techniques

We estimate a KT model by first calling \code{mdcev.data} on the **Recreation** data. For these examples we are going to use a subset of 200 individuals from the data.

```{r, echo=T, set_data}
data_model <- mdcev.data(data_rec, subset = id <= 200,
					   id.var = "id",
					   alt.var = "alt",
					   choice = "quant")  
```

We might think that older people prefer gardening to other activities and so we can include an interaction term between the activity \code{garden} and the variable \code{ageindex}. There are no alternative-specific variables besides constant terms to include in $\psi$ and therefore the formula can be specified as  

```{r, echo=T}
data_model$age_garden = ifelse(data_model$alt == "garden",
							   data_model$ageindex,0)
f5 = ~ age_garden
```

We specify the $\gamma$-profile of the MDCEV model specification where a single $\alpha_1$ is estimated for the numeraire alternative and all non-numeraire alternatives are fixed at zero by setting \code{model = "gamma"}. We use maximum likelihood estimation by setting \code{algorithm = "MLE"}.

The syntax for the model is the following:

```{r, echo=T, estimation_mdcev_gamma}
mdcev_mle <- mdcev(~ age_garden,
                  data = data_model,
                  model = "gamma",
                  algorithm = "MLE",
                  print_iterations = FALSE)
```

Setting \code{print\_iterations = TRUE} will print out intermediate iteration results as the model converges.

The output of the function can be accessed by calling summary.

```{r, echo=T,summary_mdcev_gamma}
summary(mdcev_mle)
```

The summary includes overall model and estimation information and the parameter estimates. All parameters have been transformed to their original form.^[$\gamma_k = exp(\gamma^*_k)$, $\alpha_1 = exp(\alpha^*_1)/(1 + exp(\alpha^*_1))$, and $\sigma = exp(\sigma^*)$, where $\gamma^*_k$, $\alpha^*_1$, and $\sigma^*$ are estimated but the transformed parameters are returned to users.] Interpreting the parameter estimates of KT models directly is challenging due to the non-linearities implied by the utility function and the partial confounding of $\alpha_k$ and $\gamma_k$ parameters (see Bhat (2008) for a in-depth discussion). Examining the $\psi_k$ parameters first which represent the marginal utility when consumption is zero, we can see that relative to the beach recreation activity (i.e. the omitted reference category), hunting and trapping and cross country skiing have the largest negative ASCs suggesting these activities are less preferred starting from zero consumption levels. The interaction parameter between age and gardening is positive and significant suggesting that older people gain a higher utility from gardening compared to younger people. Because all non-numeraire $\alpha$ parameters are fixed at zero, the $\gamma_k$ parameters can be interpreted as capturing satiation and these satiation effects are lowest for the activities with the highest $\gamma_k$ parameter values such as birding, cycling, and motorized land vehicles. The $\alpha_1$ is estimated to be less than 1 which also implies satiation in the numeraire good. \citet{bhatmultiple2008, lloyd-smithdecoupling2019} provide empirical applications of this model.

In the next example, we estimate the $\alpha$-profile of the MDCEV utility function by changing the model argument to \code{"alpha"}.

```{r, estimation_mdcev_alpha, message = FALSE, warning = FALSE}
mdcev_mle <- mdcev(~ age_garden,
                   data = data_model,
                   model = "alpha",
                   algorithm = "MLE",
                   print_iterations = FALSE)
```

```{r, echo=T, echo=T,summary_mdcev_alpha}
summary(mdcev_mle)
```

Estimating alternative-specific $\alpha_k$ parameters and fixing all the non-numeraire $\gamma$ parameters at 1, allows us to see the heterogeneity in $\alpha_k$ parameters across recreation activities.

The hybrid model specification of the MDCEV model where a single $\alpha$ is estimated for the numeraire and non-numeraire alternatives can be estimated by setting \code{model = "hybrid"} as the next example demonstrates.

```{r, echo=T, estimation_mdcev_hybrid}
mdcev_mle <- mdcev(~ age_garden,
                  data = data_model,
                  model = "hybrid",
                  algorithm = "MLE",
                  print_iterations = FALSE)
```

```{r,  echo=T,summary_mdcev_hybrid}
summary(mdcev_mle)
```

The same number of parameters are estimated in all three models and the log-likelihood is highest for the $\gamma$-profile specification. The ease of estimating different MDCEV model specifications can be used to compare models quickly and help the analyst pick their preferred specification for each empirical application.

We can also estimate the KT-EE specification by changing the formula call and the model call to \code{"kt\_ee"}.

```{r, estimation_mdcev_kt, message = FALSE, warning = FALSE}
kt_mle <- mdcev(~ age_garden | 0 | 0,
                   data = data_model,
                   model = "kt_ee",
                   algorithm = "MLE",
                   print_iterations = FALSE)
```

```{r,  echo=T,summary_mdcev_kt}
summary(kt_mle)
```

This model does not include ASCs in the $psi_k$ parameters due to concerns about weak complementarity.

### Estimating KT using Bayesian techniques

The exact same models can be fit using Bayesian estimation by changing the algorithm call to \code{"Bayes"}. Bayesian estimation is implemented using the Stan programming language \citep{carpenterstan2017}. The Bayesian framework requires careful choice of priors for the parameters, especially in data sparse contexts. The specific prior distributions for the fixed parameter specifications is presented below.  The user has the ability to change the standard deviation and shape of these priors through these options in the \code{mdcev} function:

- \code{prior\_psi\_sd} standard deviation for normal prior with mean 0.
- \code{prior\_phi\_sd} standard deviation for normal prior with mean 0.
- \code{prior\_gamma\_sd} standard deviation for half-normal prior with mean 1.
- \code{prior\_alpha\_shape} shape parameter for beta distribution.
- \code{prior\_scale\_sd} standard deviation for half-normal prior with mean 0.

For the random parameter model specifications, the priors for the means of all random parameters follow a normal distribution with mean 0 on the unconstrained space.

There are also a number of further options for Bayesian estimation. For example, the number of iterations (n\_iterations), number of chains (n\_chains), and number of cores (n\_cores) for parallel implementation of the chains can also be chosen. The full set of options for Bayesian estimation are presented below.

- \code{random\_parameters} The form of the covariance matrix for the parameters. Options are
	+ 'fixed' for no random parameters,
	+ 'uncorr for uncorrelated random parameters, or
	+ 'corr' for correlated random parameters.

- \code{n\_iterations} The number of iterations to use in Bayesian estimation. The default is for the number of iterations to be split evenly between warmup and posterior draws. The number of warmup draws can be directly controlled using the warmup argument (see rstan::sampling)

- \code{n\_chains} The number of independent Markov chains in Bayesian estimation.

- \code{n\_cores} The number of cores used to execute the Markov chains in parallel in Bayesian estimation. Can set using options(mc.cores = parallel::detectCores()).

- \code{max\_tree\_depth} http://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded

- \code{adapt\_delta} http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup

- \code{lkj\_shape\_prior} Prior for Cholesky matrix for correlated random parameters.

In this example, we estimate the $\gamma$-profile of the MDCEV specification using Bayesian techniques. We set the number of iterations to 200 and use 4 independent chains across 4 cores.

```{r,eval=T, echo=T, estimation_mdcev_bayes, message = FALSE, warning = FALSE}
mdcev_bayes <- mdcev(~ age_garden,
                        data = data_model,
                        model = "gamma",
                        algorithm = "Bayes",
                        n_iterations = 200,
                        n_chains = 4,
						n_cores = 4,
                        print_iterations = FALSE)
```

The output of the function can be accessed by calling \code{summary}.

```{r,eval=T, echo=T, summary_mdcev_bayes}
	summary(mdcev_bayes)
```

Comparing these parameter values to the maximum likelihood estimates of the $\gamma$-profile MDCEV specification, the values are quite similar. As the data set is rather small with only 200 individuals, the priors play a role in reducing the estimates closer to 1 for the $\gamma_k$, but this role will lessen in larger data applications.

One benefit of using the Bayesian approach is that one can take advantage of the postestimation commands, interactive diagnostics, and posterior analysis in \pkg{rstan}, [\pkg{bayesplot}](https://mc-stan.org/bayesplot/) \citep{gabrybayesplot2019}, and [\pkg{shinystan}](http://mc-stan.org/shinystan/) \citep{muthuser2018}. For example, the effective sample size reports the estimated number of independent draws from the posterior distribution for each parameter \citep{stan2019}. The interested reader is referred to these packages for additional details.

### Estimating LC-KT models

In this example, we estimate a LC-KT model using the **Recreation** data. We set the number of classes equal to 2 and we use data on 500 individuals. We would like to include the \code{university}, \code{ageindex}, and \code{urban} in the membership equation and we include them in the \code{formula} interface. The constant for the membership equation is included automatically. The LC model is automatically estimated as long as the prespecified number of classes (\code{n\_classes}) is set greater than 1. The scale parameters are fixed at 1 using \code{fixed\_scale1 = 1}.

```{r, estimation_mdcev_lc, message = FALSE, warning = FALSE}

data_model <- mdcev.data(data_rec, subset = id <= 500,
					   id.var = "id",
					   alt.var = "alt",
					   choice = "quant")  

mdcev_lc <- mdcev(~ 0 | university + ageindex + urban,
                  data = data_model,
                  n_classes = 2,
                  model = "gamma",
				  fixed_scale1 = 1,
                  algorithm = "MLE",
                  print_iterations = FALSE)
```

```{r, summary_mdcev_lc}
summary(mdcev_lc)
```

In this LC example, we assume that there are two types of people that have different preferences for recreation. The probability of class assignment depends on unobserved factors and the three sociodemographic factors included in the membership equation with only \code{urban} having a statistically significant effect on class probability. People living in urban areas are less likely to be in class 2. The summary output reports the average class probabilities as being 32% for class 1 and 68% for class 2. The $\psi$ parameters across classes are similar although there are some noticeable differences such as the hunting and trapping preferences. The $\gamma$ parameters, on the other hand, show that satiation between classes is quite different. \citet{sobhanilatent2013, kuriyamalatent2010} provide empirical applications of these models.

If \code{initial.parameter} are not provided, the default is to use slightly adjusted parameter estimates of the MDCEV model as starting values when estimating the LC-MDCEV model to assist speed and convergence issues.^[In particular, the estimated $\psi_k$ and $\gamma_k$ parameters from the MDCEV model are randomly adjusted by 0.02.] The MDCEV model output can be accessed from \code{mdcev\_lc[["mdcev\_fit"]]} object for comparison.

### Estimating RP-KT models

Random parameter models require defining and parameterizing the variance covariance matrix. For uncorrelated random parameters, the diagonal elements of the variance covariance matrix are estimated and the off-diagonal elements are assumed to be zero. For correlated random parameters, the variance covariance matrix is fully estimated and can be parameterized in many ways. The \pkg{rmdcev} package defines the variance covariance matrix in terms of Cholesky factors of the correlation matrix and a vector of standard deviations for numerical stability. Thus the variance covariance matrix is specified as

\begin{equation}
\sum = diag(\tau) \; x \; LL^T \; x \; diag(\tau),
\end{equation}

where $\tau$ is a vector of standard deviations, and $L$ is the cholesky factors of the correlation matrix.

In this example, we estimate an uncorrelated random parameters $\gamma$-specification of the MDCEV model without any $\psi_k$ parameters. We set the argument \code{random\_parameters = "uncorr"} to indicate that uncorrelated random parameters will be estimated. As noted earlier, all random parameters follow a normal distribution. We change the \code{psi\_ascs = 0} to omit the ASCs in the $\psi_k$ parameters.

```{r,eval=T, echo=T, estimation_mdcev_rp, message = FALSE, warning = FALSE}
data_model <- mdcev.data(data_rec, subset = id <= 200,
					   id.var = "id",
					   alt.var = "alt",
					   choice = "quant") 

mdcev_rp <- mdcev(~ 0,
					data = data_model,
					model = "gamma",
					algorithm = "Bayes",
					n_chains = 4,
					psi_ascs = 0,
					fixed_scale1 = 1,
					n_iterations = 200,
					random_parameters = "uncorr",
					print_iterations = FALSE)
```

```{r, eval=T, summary_mdcev_rp}
summary(mdcev_rp)
```

The results show the means of the random parameters followed by the estimated standard deviations. The standard deviations that are estimated to be different from zero suggest there is heterogeneity in preference parameters. The correlated random parameters specification can be estimated by setting \code{random\_parameters = "corr"}. \citet{bhathousehold2006} provide an empirical application of this type of model.

### Computational and estimation issues

KT models are notoriously tricky to estimate relative to standard discrete choice models. This section provides some guidance for estimating these models and common convergence issues:

- **Starting values:** Model parameter estimates can be sensitive to starting values, especially the more complex LC-KT specification. Users should use several different initial parameter values for model estimation to ensure robust results and a global maxima is found rather than a local maxima. The default behaviour for LC-KT models is to use KT parameters as starting values. In practice the author has found this to be quite effective at finding global maxima. However, users are encouraged to use random starting values as a robustness check.

- **Identification issues:** Depending on the model specification and included variables the model may not be properly identified. If you receive an error such as \code{Error in chol.default(-H) : the leading minor of order 9 is not positive definite}, this usually suggests an identification issue. Users should double check all variables included in the model are appropriate. One solution is to start with a simpler model first and then slowly add variables to help locate any problematic variables.

- **Parameter estimates near boundaries:** Interpret models with parameter estimates that are near the boundaries (e.g. $\alpha$ close to 1) with caution. Users are recommended to re-estimate the model with starting values far from this boundary.

- **Bayesian estimation**: For models estimated using Bayesian estimation, users should consult the \pkg{rstan} User Guide for additional guidance on model estimation options and postestimation checks \citep{stan2019}. Additional information is available by typing \code{help(rstan)}.

## Simulating KT demand and welfare scenarios

The \pkg{rmdcev} package includes simulation functions for calculating welfare measures and forecasting demand under alternative policy scenarios. The overall approach used for simulation is first introduced and then code examples are given.

### Overview of simulation steps

Once the model parameters are estimated, there are two steps to simulation in KT models. In the first step we draw simulated values for the unobserved heterogeneity term ($\varepsilon$) using Monte Carlo techniques. The second step uses these error draws, the previously estimated model parameters, and the underlying data to calculate Marshallian demands for forecasting or Hicksian demands for welfare analysis. These two steps are described below.

**Step 1: simulating unobserved heterogeneity**

Monte Carlo simulation techniques can be employed to draw simulated values of the unobserved heterogeneity ($\varepsilon$) using either unconditional or conditional draws.

1. Unconditional error draws: draw from the entire distribution of unobserved heterogeneity using the following formula

\begin{equation}
\varepsilon_{k} = -log(-log(draw(0,1))) * \sigma,
\end{equation}

where $draw(0,1)$ is a draw between 0 and 1 and $\sigma$ is the scale parameter. \pkg{rmdcev} allows errors to be drawn using uniform draws or the Modified Latin Hypercube Sampling algorithm \citep{hesson2006}.

2. Conditional error draws: draw errors terms to reflect behaviour and dependent on whether alternative is consumed or not \citep{vonhaefenincorporating2003, vonhaefenestimation2004}:

- If $x_k>0$, set $\varepsilon_k = (V_1 - V_k)/ \sigma$ for the MDCEV specifications  where $V_1$ and $V_k$ depend on the model specification as detailed above. If using the environmental economics KT model specification ("kt_ee"), set $\varepsilon_k = g_k(.)$ from Equation (\ref{eq:kt_g}).
- If $x_k=0$, $\varepsilon_k < (V_1 - V_k)/ \sigma$ and simulate $\varepsilon_k$ from the truncated type I extreme value distribution such that

\begin{equation}
\varepsilon_k = -log(-log(draw(0, 1) * exp(-exp(\frac{V_1 - V_k}{\sigma})))) * \sigma \; \mbox{for the MDCEV specifications, or}
\varepsilon_k = -log(-log(draw(0, 1) * exp(-exp(-g_k(.))))) * \sigma \: \mbox{for the KT-EE specification.}
\end{equation}

In the conditional error draw approach, we normalize $\varepsilon_1=0$.

The main differences between these two error draw approaches is that in the conditional approach, errors are drawn such that the model perfectly predicts the observed consumption patterns in the baseline state  \citep{vonhaefenkuhn-tucker2005}. The conditional approach uses observed behaviour by individuals to characterize unobserved heterogeneity and can be useful for scenario simulation as the baseline matches observed behavior. This is especially true if poor in-sample behavioral predictions is found using the unconditional approach \citep{vonhaefenincorporating2003}. The unconditional approach draws all errors based on distributional assumptions and is necessary for out-of-sample forecasting. If the model correctly specifies the data generating process, the sample means of the conditional and unconditional approaches should converge in expectation. Another difference between the two approaches is that the unconditional approach uses more computation time as there is a need to calculate consumption patterns in the baseline state as well as simulate the entire distribution of unobserved heterogeneity.

\citep{vonhaefenincorporating2003}

**Step 2: Calculating welfare measures and demand forecasts**

With the error draws in hand, the second step is to simulate demand or welfare changes. Compared to welfare measures in discrete choice models, welfare calculation in KT models is more challenging because of the two KT conditions in Equation (\ref{eq:kt_conditions}). For a given policy scenario, a priori, we do not know which alternatives have a positive or zero consumption level. \pkg{rmdcev} implements the \citet{pinjaricomputationally2011} efficient demand forecasting routine for simulating demand behaviour for MDCEV models which relies on calculating Marshallian demands. For welfare calculations, we need to calculate the expenditure function in Equation (\ref{eq:welfare}) which relies on Hicksian demands. These are calculated using the approach described by \citet{lloydsmithnew2018} and the \pkg{rmdcev} extends these approaches to the environmental economics KT model specifications. The demand and welfare simulation approaches share a lot of commonalities and thus only the approach used for welfare calculations are fully described in the appendix. The specific steps for demand simulation is explained in-depth in \citet{pinjaricomputationally2011} and the interested reader is encouraged to read Section 4 of the paper for the exact details.

### Welfare analysis

In \pkg{rmdcev}, the functions for welfare and demand simulation have been divided into 3 steps to allow users to parallelize operations as necessary.

We first estimate the model using \code{mdcev} and we set \code{std\_errors = "mvn"} to generate multivariate normal draws.

```{r, sim_mdcev_welfare_estimate}
mdcev_mle <- mdcev(~0,
                  data = data_model,
                  model = "hybrid",
                  algorithm = "MLE",
				  std_errors = "mvn",
                  print_iterations = FALSE)
```

##### 1. Define policy scenarios

In the first step, we define the number of alternative policy scenarios to use in simulation and then specify changes to the $\psi$ variables and prices of alternatives. The CreateBlankPolicies function has been created to easily set-up the required lists for the simulation. These policies can then be manually edited according to the specific policy scenario. For prices, \pkg{rmdcev} is set up to accept additive changes in prices that impact all individuals the same. For the $\psi$ and $\phi$ variable changes, the package is set up to accept any new values for these variables. Depending on the number of individuals and number of policies, the generated policies list can be quite large. If the user is only interested in assessing price changes, then you can use \code{price\_change\_only = TRUE} which ensures duplicate $\psi$ and $\phi$ data is not created.

In this example, we are interested in two separate policies. The first policy increases the costs of all recreation activities by \$1 and the second policy increases the cost of all four hunting activities by \$10. The policy set-up for these two scenarios is demonstrated below.

```{r, sim_mdcev_welfare_policy}
nalts <- mdcev_mle$stan_data[["J"]]
npols <- 2

policies<-  CreateBlankPolicies(npols = npols,
								model = mdcev_mle,
								price_change_only = TRUE)

policies$price_p[[1]] <- c(0, rep(1, nalts))
policies$price_p[[2]][10:13] <- rep(10, 4)
```

For policy scenarios that involve changes in the $\psi$ or $\phi$ variables, the user can change the \code{dat\_psi} or \code{dat\_phi} list of the \code{policies} object. For example, the following code will increase the value of the third $\psi$ variable by 20\% in policy scenario 1.

```{r, sim_mdcev_welfare_policy_psi}

policies$dat_psi[[1]][3] <- policies$dat_psi[[1]][3]*1.2
```

##### 2. Prepare simulation data

The second step is to combine the parameter estimates, data, and policy scenarios into a data format for simulation. The \code{PrepareSimulationData} function uses the model fit and the user defined policy scenarios to create this specific data format. This function separates the output into individual-specific data (\code{df\_indiv}), data common to all individuals (\code{df\_common}), and simulation options (\code{sim\_options}).

```{r, sim_mdcev_welfare_prepare}
df_sim <- PrepareSimulationData(mdcev_mle, policies)
```

##### 3. Simulate MDCEV model

The third step is to simulate the policy scenario using the formatted data and the \code{mdcev.sim} function. The specific steps for the simulation algorithms are described in Appendix A. The user chooses the type of error draws (unconditional or conditional as described above), the number of error draws, and whether to simulate the demand or welfare changes.


```{r, eval=T, sim_mdcev_welfare}
welfare <- mdcev.sim(df_sim$df_indiv,
					 df_common = df_sim$df_common,
					 sim_options = df_sim$sim_options,
					 cond_err = 1,
					 nerrs = 25,
					 sim_type = "welfare")
summary(welfare)
```

The output of the \code{mdcev.sim} for welfare analysis is an object of class \code{mdcev.sim} which contains a list of matrices where each element of the list is for an individual and the matrix consists of rows for each policy scenario and columns for each parameter simulation.

The summary function computes summary statistics across all individuals. For example, the average welfare change for a \$1 daily increase in all recreation costs is -\$125.

The reason these last two steps are separate is to allow users to parallelize the simulation step as the last step can be computationally intensive. The number of simulations is a multiplicative function of the number of individuals, number of policies, number of parameter estimate simulations, and the number of error draws ($I$ x $npols$ x $nsims$ x $nerrs$). Even for modestly sized data, the total number of simulations can easily reach well into the millions or billions. All simulations are conducted at the individual level which allows the user to easily parallelize the \code{mdcev.sim} function using the \pkg{parallel} package or similar packages.

### Demand forecasting

This section demonstrates the demand forecasting capabilities of \pkg{rmdcev}. Please refer to the previous section for an overview of the three steps to simulation.

```{r, eval=T, sim_mdcev_demand}
policies <-	CreateBlankPolicies(npols = 2, model = mdcev_mle)

policies$price_p[[1]] <- c(0, rep(1, nalts))
policies$price_p[[2]][10:13] <- rep(10, 4)

df_sim <- PrepareSimulationData(mdcev_mle, policies)

demand <- mdcev.sim(df_sim$df_indiv,
						df_common = df_sim$df_common,
						sim_options = df_sim$sim_options,
					 	cond_err = 1,
						nerrs = 25,
						sim_type = "demand")
summary(demand)
```

The output of the demand simulation a \code{mdcev.sim} object with a list of $I$ elements, one for each individual. Within each element there are nsim lists each containing a matrix of demands. The rows of the matrix are for each policy scenario and the columns represent each alternative. The summary function computes summary statistics.

## Generating simulated data

The \pkg{rmdcev} package has the capability to simulate KT data. Simulated KT data can be easily created for model assessment and Monte Carlo analysis using the \code{GenerateMDCEVData} function. The following example will generate a simulated data set with 1,000 individuals, 10 non-numeraire alternatives, and particular parameter values.

```{r, eval=T, sim_mdcev_data}
model = "gamma" 
nobs = 1000
nalts = 10
sim.data <- GenerateMDCEVData(model = model, 
							  nobs = nobs, 
							  nalts = nalts,
							  psi_j_parms = c(-5, 0.5, 2), # alternative-specific variables
							  psi_i_parms = c(-1.5, 3, -2, 1, 2), # individual-specific variables
							  gamma_parms = stats::runif(nalts, 1, 10),
							  alpha_parms = 0.5,
							  scale_parms = 1)
```

Next, we can estimate the model using maximum likelihood techniques to recover the parameter estimates.

```{r, fake_estimate, message = FALSE, warning = FALSE}
mdcev_mle <- mdcev(formula = ~ b1 + b2 + b3 + b4 + b5 + b6 + b7 + b8,
        				   data = sim.data$data,
        				   model = model,
						   psi_ascs = 0,
        				   algorithm = "MLE",
        				   print_iterations = FALSE)
```

# Conclusions {#conclusions}

The \pkg{rmdcev} package implements several Kuhn-Tucker model specifications including MDCEV with heterogeneity that can be continuous (i.e. random parameters) or discrete (i.e. latent classes). Models can be estimated using maximum likelihood or Bayesian techniques. This paper demonstrates the use of the package to estimate several model specifications and to derive demand forecasts and welfare implications of policy scenarios. To my knowledge, there is no other available statistical package that can estimate welfare implications of policy scenarios using MDCEV models. I hope that the publication of \pkg{rmdcev} will make KT modeling available to a wider audience.


# Appendix A: Specific steps for simulating KT models {-}

Welfare and demand simulation follow similar approaches and this section details the welfare simulation approach. There are two algorithms that differ depending on the model specification. If a single $\alpha$ parameter is estimated (i.e. model = "hybrid" or "hybrid0"), then we can use the hybrid approach to welfare simulation. If there are heterogeneous $\alpha$ parameters (i.e. model = "gamma", "alpha", or "kt_ee"), then we can use the general approach to welfare simulation. The hybrid approach is less computationally intensive and provides an exact analytical solution but the general approach can be used with all utility specifications. The specific steps for both algorithms are described below. Additional details are provided in \citet{lloydsmithnew2018}.

**Steps in algorithm for hybrid-profile MDCEV utility specifications**

**Step 0**: Assume that only the numeraire alternative is chosen and let the number of chosen alternatives equal one (M=1).

**Step 1**: Using the data, model parameters, and either conditional or unconditional simulated error term draws, calculate the price-normalized baseline utility values ($\psi_k/p_k$) for all alternatives. Sort the $K$ alternatives in the descending order of their price-normalized baseline utility values. Note that the numeraire alternative is in the first place. Go to step 2.

**Step 2**: Compute the value of $\lambda^E$ using the following equation:

\begin{equation}
\frac{1}{\lambda^E} = \left[ \frac{\alpha \bar{U} + \sum_{m=2}^{M} \gamma_m \psi_m} {\sum_{m=2}^{M} \gamma_m \psi_m \left( \frac{p_m}{\psi_m} \right)^\frac{\alpha}{\alpha-1} + \psi_1 \left(\frac{p_1}{\psi_1} \right)^\frac{\alpha}{\alpha-1}} \right] ^\frac{\alpha-1}{\alpha}.
\end{equation}

Go to step 3.

**Step 3**: If $\frac{1}{\lambda^E} > \frac{\psi_{M+1}}{p_{M+1}}$, go to step 4. Else if $\frac{1}{\lambda^E} < \frac{\psi_{M+1}}{p_{M+1}}$, set $M = M + 1$. If $M < K$, go back to step 2. If $M = K$, go to step 4.

**Step 4**: Compute the optimal Hicksian consumption levels for the first $I$ alternatives in the above descending order using the following equations

\begin{align}
\label{eq:optimal_x}
x_1 &=   \left( \frac{p_1}{\lambda^E \psi_1} \right)^\frac{1}{\alpha_1-1}\text{, and} \\
x_m &=   \left[ \left( \frac{p_m}{\lambda^E \psi_m} \right)^\frac{1}{\alpha_m-1}-1 \right]\gamma_m, \; \; \text{if} \; \; x_m > 0.
\end{align}

Set the remaining alternative consumption levels to zero and stop.

**Steps in algorithm for general utility specifications**

In this context, there is no closed-form expressions for $\lambda^E$ and we need to conduct a numerical bisection routine. The following routine describes the approach for the MDCEV utility specifications. The approach used for the KT-EE specification is omitted due to space, but the overall strategy is the same with the only differences being the definitions for utility functions and optimal demands. Let $\hat{\lambda^E}$ and $\hat{U}$ be estimates of $\lambda^E$ and $U$ and let $tol_{\lambda}$ and $tol_{U}$ be the tolerance levels for estimating $\lambda^E$ and $U$ that can be arbitrarily small. The algorithm works as follows:

**Step 0**: Assume that only the numeraire is chosen and let the number of chosen alternatives equal one (M=1).

**Step 1**: Using the data, model parameters, and either conditional or unconditional simulated error term draws, calculate the price-normalized baseline utility values ($\psi_k/p_k$) for all alternatives. Sort the $K$ alternatives in the descending order of their price-normalized baseline utility values. Note that the numeraire is in the first place. Go to step 2.

**Step 2**: Let $\frac{1}{\hat{\lambda^E}} = \frac{\psi_{M+1}}{p_{M+1}}$ and substitute $\hat{\lambda^E}$ into the following equation to obtain an estimate of $\hat{U}$.

\begin{align}
\bar{U}=\sum_{M=2}^{M} \frac{\gamma_m}{\alpha_m}\psi_m \left[ \left( \frac{p_m}{\lambda^E \psi_m} \right)^\frac{\alpha_m}{\alpha_m-1} - 1 \right] + \frac{\psi_1}{\alpha_1}\left(\frac{p_1}{\lambda^E \psi_1} \right)^\frac{\alpha_1}{\alpha_1-1}.
\end{align}

**Step 3**: If $\hat{U} < \bar{U}$, go to step 4. Else, if $\hat{U} \geq \bar{U}$, set $\frac{1}{\lambda_l^E}= \frac{\psi_{M+1}}{p_{M+1}}$ and $\frac{1}{\lambda_u^E}= \frac{\psi_{M}}{p_{M}}$. Go to step 5.

**Step 4**: Set $M=M+1$. If $M<K$, go to step 2. Else if $M=K$, set $\frac{1}{\lambda_l^E}= 0$ and $\frac{1}{\lambda_u^E}= \frac{\psi_{K}}{p_{K}}$. Go to step 5.

**Step 5**: Let $\hat{\lambda^E}= (\lambda_l^E+\lambda_u^E)/2$ and substitute $\hat{\lambda^E}$ into the equation of step 2 to obtain an estimate of $\hat{U}$. Go to step 6.

**Step 6**: If $|\lambda_l^E-\lambda_u^E| \leq \; tol_{\lambda}$ or $|\hat{U}-\bar{U}| \leq \; tol_{U}$, go to step 7. Else if $\hat{U}<\bar{U}$, update $\lambda^E_u= (\lambda_l^E+\lambda_u^E)/2$ and go to step 5. Else if $\hat{U}>\bar{U}$, update $\lambda^E_l= (\lambda_l^E+\lambda_u^E)/2$ and go to step 5.

**Step 7**: Compute the optimal Hicksian consumption levels for the first $M$ alternatives in the above descending order using Equation (\ref{eq:optimal_x}). Set the remaining alternative consumption levels to zero and stop.

\bibliography{lloyd-smith}
