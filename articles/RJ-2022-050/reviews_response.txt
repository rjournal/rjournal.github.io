We thank the reviewers for the time and effort they have put into
these reviews.

From 1-review-2.txt
>  The manuscript 'Tidy Data Neatly Resolves Mass-Spectrometry's Ragged
>  Arrays' by Kumler and Ingalls describes the `RaMS` package to handle
>  raw mass spectrometry (MS). The package's functionality includes
>  parsing the open community-developed XML-based raw MS data and
>  returning the data as a list of long/tidy tables to allow users to
>  then use general-purpose data science packages to analyse and
>  visualise their data. The authors then perform a short benchmarking
>  experiment against the `MSnbase` on-disk and in-memory backends,
>  comparing times and memory requirements to load, subset and plot
>  data.
>  The manuscript is well written, clearly describing the rationale
>  behind the `RaMS` package development, it's usage and main use
>  cases, and provides a honest comparison to `MSnbase`. 
This is an accurate summary.

>  I have three comments below, that I would find interesting to hear
>  from by the authors.
>
>  Tidy MS data analysis:
>  The authors rightly emphasise the success and advantages of tidy
>  data and tidy data analysis, as defined in the tidyverse packages. I
>  find however that their definition if tidy analysis, limiting these
>  principles to tables, to be too restrictive. Tidy data analysis
>  principles can be applied to any type of data (such as arbitrary S4
>  classes) - the requirement being that the tidy functions read and
>  return that same class to allow users to reason along the chain of
>  commands. The two following code chunks, the first one handling a
>  long table and the second one handling a dedicated MS class, are
>  both tidy:
>  df |>
>  filter(level == 1)
>  filter(rt > 600 & rt < 900)
>  ms |>
>  filterMsLevel(1) |>
>  filterRt(c(600, 900))
>  The result of the second code chunk could then easily be coerced to
>  a table for plotting (for example with `ggplot2`).
>  As noted by the authors themselves, both table and dedicated S4
>  classes designs are valuable, addressing different use cases and
>  visions. I just feel that the authors fail to generalise the tidy
>  principles beyond the long/tidy table format.
This is a reasonable request for expansion, but we intentionally limit 
our definition of "tidy" to the principles established in the Wickham
2014 reference to best align with contemporary usage. Internet searches 
for "tidy data" return the Wickham definition much more frequently than
the "read and return same class" definition proposed by the reviewer. We
believe that including an additional discussion of this new "tidy"
definition will add more confusion than clarity to the manuscript.

>  Scalability:
>  The authors mention that their main use case is to explicitly not
>  require/rely on all MS data, which wouldn't scale with RaMS's ragged
>  data memory requirements. They also argue for using on-disk
>  representations, for instance by storing them as SQLite files. This
>  is indeed an excellent solution for very large data (that is also
>  being used by other MS packages - see below) and illustrated for a
>  single file in the paper. This approach will lead to a costly
>  initial overhead for multiple large files that would need to be
>  serially loaded in memory by `RaMS` and then added (again one by
>  one) to the database. Could the authors elaborate on this and
>  provide specific guidance/code as to how to handle such a case.
This is an understandable concern given the package's emphasis on small
subsets of data for visualization and preliminary exploration. However,
any such SQL database will require the same overhead of reading files
into memory prior to export into the database - we know of no method for
directly converting mzML files into databases without using computer
memory. We will also note that multiple files *can* be written to the 
database simultaneously - in fact, the only limit on the number of
simultaneously writable files is the size of the computer memory itself 
because the file name is one of the columns produced by RaMS. For databases 
larger than the computer's available memory, files can be read in several at
a time (up to available RAM) and then combined with existing database
functions such as DBI::dbAppendTable(). The "RaMS-and-friends" vignette has
been expanded to demonstrate this both ways, first by writing out multiple
files that fit in memory simultaneously, then by appending an additional
file to an existing table in the data base.

>  The `Spectra` package:
>  The authors used `MSnbase` as a reference in their benchmark and
>  discussions. For reference, I would like to point them to the
>  `Spectra` package (by the same team of developers), part of the R
>  for Mass Spectrometry initiative, that offers some considerable
>  improvements compared to `MSnbase`.
This was a helpful comment, and a direct comparison to the Spectra package
has now been added. 

>  Minor detail:
>  - the capitalisation of M*S*nbase and *R*-based is incorrect in the
>    Gatto et al. reference.
Capitalization is now fixed in this reference and others, thank you 
for pointing this out!


From 1-review-3.txt
>  Review of "Tidy Data Neatly Resolves Mass-Spectrometry's Ragged 
>  Arrays" by Kumler & Ingalls
>
>  The paper is well-written, organized, and polished.
>  The only thing I would suggest that the authors consider adding is 
>  a discussion of an alternative data structure.  This structure would 
>  be matrix-like and have the retention times in rows and *all* the 
>  observed masses in columns (as a result, there would be a lot of 
>  zeros, since many masses will be limited to particular retention 
>  times).  This matrix could easily be used to create either EIC plots 
>  in base graphics by plotting columns, or TIC plots by plotting rows 
>  -- what could be simpler?  Now, knowing full well that many (most?) 
>  users these days stay away base graphics, I'd consider this option to 
>  be a "straw man" argument -- an argument that is be raised only to 
>  knock it down. But I think the authors should consider a few sentences, 
>  possibly in a footnote, about it's pros and cons.  To be clear, this 
>  is a suggestion, I can't make demands!  But it does seem to fit in a 
>  paper discussing the best way to store MS data.
We appreciate this suggestion for additional discussion, but believe that
the premise is flawed because m/z values are functionally continuous
after instrumental error, as mentioned in the second paragraph of the
"Why isn’t it already easier to access mass-spectrometry data?" section.
This means that there are an infinite number of possible masses and a 
matrix constructed with a column for every observed mass would mean that
each column theoretically has only a single value in it. In reality,
rounding of masses in the Fourier transform means that each column has
about 10 values instead of 1, but these are essentially spurious and are
no more closely related to the true value than those in nearby columns.
Perhaps when the mass of a molecule can be measured exactly it will be
possible to implement this approach, but we believe that it should be
left out of the manuscript in its current form.

>  Regarding the package itself, even though there is basically just one 
>  user-facing function, I would like to see the addition of a 
>  RaMS-package.Rd file so that users can type ??RaMS in the console and 
>  quickly get to the package index (because without it, one has to know 
>  or find ahead of time the names of the functions in the package).  This 
>  is just a nice thing for users.
This was an excellent suggestion and has been implemented, thank you!

>  The main function, grabMSdata, is well-thought-out, well-documented and 
>  user friendly.  The use of data.table is a good choice for speed, and 
>  the authors have cleverly enhanced the integration of data.table to the 
>  user's advantage.  The authors have also (necessarily) written the 
>  function to capture only the needed portion of very large files.
>  The package includes two very helpful vignettes, which I am sure users 
>  will appreciate.
The package now includes a total of four vignettes since the manuscript
was first submitted.

>  The authors are diplomatic and humble in several places where they 
>  describe how RaMS can be used alongside long-standing packages for MS 
>  processing, but I think there is a high likelihood that RaMS will 
>  quickly become users' go-to package for basic exploration.
>  In my experience as a reviewer and associate editor, this paper is in 
>  great shape and other than a couple of small suggestions, is ready to go.  
>  It is certainly a worthy project, as it presents a distinctly different 
>  way of storing and handling MS data compared to other approaches (and one 
>  which is more user friendly).
Thank you!

