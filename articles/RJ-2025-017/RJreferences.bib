@misc{gqlasso,
      title={Quantile Predictions for Equity Premium using Penalized Quantile Regression with Consistent Variable Selection across Multiple Quantiles}, 
      author={Shaobo Li and Ben Sherwood},
      year={2025},
      eprint={2505.16019},
      archivePrefix={arXiv},
      primaryClass={stat.ME},
      url={https://arxiv.org/abs/2505.16019}, 
}

@article{mestatp,
  title = {Asymptotic properties of concave L1-norm group penalties},
  journal={Statistics \& Probability Letters},
  volume = {157},
  pages={108631},
  year={2020},
  author = {Ben Sherwood and Aaron J. Molstad and Sumanta Singha},
	doi = {https://doi.org/10.1016/j.spl.2019.108631},
url = {https://www.sciencedirect.com/science/article/pii/S0167715219302779}
}

@article{WEN2023,
title = {Feature-splitting algorithms for ultrahigh dimensional quantile regression},
journal = {Journal of Econometrics},
year = {2023},
author = {Jiawei Wen and Songshan Yang and Christina Dan Wang and Yifan Jiang and Runze Li},
keywords = {ADMM, Penalized quantile regression, Parallel computing, Sample-splitting algorithm},
abstract = {This paper is concerned with computational issues related to penalized quantile regression (PQR) with ultrahigh dimensional predictors. Various algorithms have been developed for PQR, but they become ineffective and/or infeasible in the presence of ultrahigh dimensional predictors due to the storage and scalability limitations. The variable updating schema of the feature-splitting algorithm that directly applies the ordinary alternating direction method of multiplier (ADMM) to ultrahigh dimensional PQR may make the algorithm fail to converge. To tackle this hurdle, we propose an efficient and parallelizable algorithm for ultrahigh dimensional PQR based on the three-block ADMM. The compatibility of the proposed algorithm with parallel computing alleviates the storage and scalability limitations of a single machine in the large-scale data processing. We establish the rate of convergence of the newly proposed algorithm. In addition, Monte Carlo simulations are conducted to compare the finite sample performance of the proposed algorithm with that of other existing algorithms. The numerical comparison implies that the proposed algorithm significantly outperforms the existing ones. We further illustrate the proposed algorithm via an empirical analysis of a real-world data set.}
}

@article{qrbic,
 abstract = {Bayesian information criterion (BIC) is known to identify the true model consistently as long as the predictor dimension is finite. Recently, its moderate modifications have been shown to be consistent in model selection even when the number of variables diverges. Those works have been done mostly in mean regression, but rarely in quantile regression. The best-known results about BIC for quantile regression are for linear models with a fixed number of variables. In this article, we investigate how BIC can be adapted to high-dimensional linear quantile regression and show that a modified BIC is consistent in model selection when the number of variables diverges as the sample size increases. We also discuss how it can be used for choosing the regularization parameters of penalized approaches that are designed to conduct variable selection and shrinkage estimation simultaneously. Moreover, we extend the results to structured nonparametric quantile models with a diverging number of covariates. We illustrate our theoretical results via some simulated examples and a real data analysis on human eye disease. Supplementary materials for this article are available online.},
 author = {Eun Ryung Lee and Hohsuk Noh and Byeong U. Park},
 journal = {Journal of the American Statistical Association},
 number = {505},
 pages = {216--229},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Model Selection via Bayesian Information Criterion for Quantile Regression Models},
 volume = {109},
 year = {2014},
 URL = {https://www.jstor.org/stable/24247149},
doi = {10.1080/01621459.2013.836975}
}

@article{sparseGroup,
author = { Noah   Simon  and  Jerome   Friedman  and  Trevor   Hastie  and  Robert   Tibshirani },
title = {A Sparse-Group Lasso},
journal = {Journal of Computational and Graphical Statistics},
volume = {22},
number = {2},
pages = {231-245},
year  = {2013},
publisher = {Taylor & Francis},
doi = {10.1080/10618600.2012.681250},
URL = {https://doi.org/10.1080/10618600.2012.681250},
eprint = {https://doi.org/10.1080/10618600.2012.681250}
}

@Article{penBiLevel,
	author = {Patrick Breheny and Jian Huang},
	title = {Penalized methods for bi-level variable selection},
	journal = {Statistics and its Interface},
	volume = {2},
	year = {2009},
	pages = {369-380}, 
	doi ={10.4310/SII.2009.v2.n3.a10},
	URL = {https://doi.org/10.4310/SII.2009.v2.n3.a10}
}

@article{admm_nan_qr,
author = {Yu, Liqun and Lin, Nan},
title = {ADMM for Penalized Quantile Regression in Big Data},
journal = {International Statistical Review},
volume = {85},
number = {3},
pages = {494-518},
year = {2017}
}

@article{barro,
author = { Roger   Koenker  and  Jos? A. F.   Machado },
title = {Goodness of Fit and Related Inference Processes for Quantile Regression},
journal = {Journal of the American Statistical Association},
volume = {94},
number = {448},
pages = {1296-1310},
year  = {1999},
publisher = {Taylor & Francis},
URL = {http://www.jstor.org/stable/2669943},
doi = {10.2307/2669943}
}


@article{lan_admm,
author = {Liqun Yu and Nan Lin and Lan Wang},
title = {A Parallel Algorithm for Large-Scale Nonconvex Penalized Quantile Regression},
journal = {Journal of Computational and Graphical Statistics},
volume = {26},
number = {4},
pages = {935-939},
year  = {2017},
publisher = {Taylor & Francis}
}

@article{scadAlg,
author = {Patrick Breheny and Jian Huang},
title = {Coordinate descent algorithms for nonconvex penalized regression, with applications to biological feature selection},
volume = {5},
journal = {The Annals of Applied Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {232 -- 253},
year={2011}, 
doi = {10.1214/10-AOAS388},
URL = {https://doi.org/10.1214/10-AOAS388}
}

@Article{br,
	author = {I. Barrodale and F.D.K. Roberts},
	title = {Solution of an Overdetermined System of Equations in the $\ell_1$ Norm.},
	journal = {Communications of the ACM},
	pages = {319-320},
	volume ={17},
	issue ={6},
	year = {1974},
	doi = {10.1145/355616.36102},
	URL = {https://doi.org/10.1145/355616.36102}
}

@Article{qr_lasso,
	author = {Alexandre Belloni and Victor Chernozhukov},
	title = {L1-Penalized quantile regression in high-dimensional sparse models},
	journal = {Ann. Statist.},
	year = {2011},
	volume = {39},
	number = {1},
	pages = {82-130},
	doi={10.1214/10-AOS827},
	URL={https://doi.org/10.1214/10-AOS827}
}

@Article{meatspec,
	author = {Claus Borggaard and Hans Henrik Thodberg},
	title = {Optimal minimal neural interpretation of spectra},
	journal = {Analytical Chemistry},
	year = {1992},
	volume = {64},
	number = {5},
	pages = {545-551}
}
	

@Manual{grpreg,
  author = {Patrick Breheny and Yaohui Zeng},
  title = {grpreg: Regularization Paths for Regression Models with Grouped Covariates 3.1-2},
  year  = {2017},
	note = {R package version 3.3.1}
}


@book{devoreLorentz,
  author = {Ronald A. Devore and George G. Lorentz},
  publisher = {Cambridge University Press},
  title = {Constructive Approximation},
  year = {2005}
}


@book{cb,
  author = {George Casella and Roger L. Berger},
  publisher = {Duxbury Advanced Series},
  title = {Statistical Inference},
  year = {2002}
}

@InProceedings{deBoor,
	author = {de Boor, Carl},
	title = {Splines as linear combinations of B-splines.},
	booktitle = {Approximation Theory II},
	pages = {1-47},
	year = {1976},
	organization = {Academic Press (New York)}
}	

@Article{deZerom,
	author = {De Gooijer, Jan G. and Dawit Zerom},
	title = {On additive conditional quantiles with high-dimensional covariates},
	journal = {J. Amer. Statist. Assoc. },
	issue = {461},
	volume = {98},
	year = {2003},
	pages = {135-146}
}

@Manual{grppenalty,
    title = {grppenalty: Concave 1-norm and 2-norm group penalty in linear and logistic
regression},
    author = {Dingfeng Jiang},
    year = {2014},
    note = {R package version 2.1-0}
  }

@Article{fanLi,
	author = {Jianqing Fan and Runze Li},
	year = {2001}, 
	title = {Variable selection via nonconcave penalized likelihood and its oracle properties}, 
	fjournal = {J. Amer. Statist. Assoc. }, 
	journal = {J. Amer. Statist. Assoc.},
	volume = {96}, 
	pages = {1348-1360},
	number = {456},
	doi = {10.1198/016214501753382273},
	URL = {https://doi.org/10.1198/016214501753382273}
}

@Article{fanLv,
	author = {Jianqing Fan and Jinchi Lv},
	year = {2011},
	title = {Nonconcave penalized likelihood with NP-dimensionality},
	journal = {IEEE Transactions on Information Theory},
	volume = {57},
	number = {8},
	pages = {5467-5484}
}

@Article{fanPeng,
	author = {Jianqing Fan and Heng Peng},
	title = {Nonconcave penalized likelihood with a diverging number of parameters},
	journal = {Ann. Statist.},
	volume = {32},
	number = {3},
	pages = {928-961},
	year = {2004}
}

@book{farawaybook,
  added-at = {2009-10-28T04:42:52.000+0100},
  author = {Julian Faraway},
  publisher = {CRC Press},
  title = {{Extending the Linear Model with R: Generalized Linear, Mixed Effects and Nonparametric Regression Models}},
  year = {2006}
}


@misc{farawaypkg,
  author = {Julian Faraway},
  title = {faraway: Functions and Datasets for Books by Julian Faraway 1.0.7},
  year  = {2016}
}

@article{MARS,
	author = {Jerome H. Friedman},
	title = {Multivariate adaptive regression splines},
	year = {1991},
	volume = {19},
	number = {1},
	pages = {1-141},
	journal = {Ann. Statist.}
}

@Article{admm_hui,
	author = {Yuwen Gu and Jun Fan and Lingchen Kong and Shiqian Ma and Hui Zou},
	title = {ADMM for High-Dimensional Sparse Penalized Quantile Regression},
  journal = {Technometrics},
  volume = {60},  
  number = {3},
  pages = {319-331},
  year  = {2018}
}


@Article{heShao,
	author = {Xuming He and Qi-Man Shao},
	title = {On Parameters of Increasing Dimensions},
	year = {2000},
	volume = {73},
	pages = {120-135},
	journal = {J. Multivariate Anal.}
}

@Article{heShi94,
	author = {Xuming He and Peide Shi},
	title = {Convergence rate of B-spline estimators of nonparametric conditional quantile functions},
	year = {1994},
	volume = {3},
	issue = {3-4},
	pages = {299-308},
	journal = {Journal of Nonparametric Statistics}
}

@Article{heShi96,
	author = {Xuming He and Peide Shi},
	year = {1996}, 
	title = {Bivariate tensor-product B-splines in a partly linear model},
	journal = {J. Multivariate Anal.}, 
	volume = {58},
	number = {2},
	pages = {162-181}
}

@Article{heSemiLong,
	author = {Xuming He and Zhong-Yi Zhu and Wing-Kam Fung},
	year = {2002},
	volume = {89},
	number = {3},
	pages = {579-590},
	journal = {Biometrika},
	title = {Estimation in semiparametric model for longitudinal data with unspecified dependence structure}
}



@Article{qr_screen,
	author = {Xuming He and Lan Wang and Hyokyoung Grace Hong},
	title = {Quantile-adaptive model-free nonlinear feature screening for high-dimensional heterogeneous data},
	year = {2013},
	volume = {41},
	journal = {Ann. Statist.},
	number = {1},
	pages = {342-369}
}
	
@Article{horLee,
	author = {Joel L. Horowitz and Sokbae Lee},
	title = {Nonparametric estimation of additive quantile regression model},
	year = {2005},
	volume = {100},
	number = {472},
	pages = {1238-1249},
	journal = {J. Amer. Statist. Assoc. }
}

@Article{jz_huang_1998,
	author = {Jianhua Z. Huang},
	title = {Projection estimation in multiple regression with application to functional ANOVA models},
	journal = {Ann. Statist.},
	year = {1998},
	volume = {26},
	number = {1},
	pages = {242-272}
}

@Article{jz_huang_1998_b,
	author = {Jianhua Z. Huang},
	title = {Functional ANOVA models for generalized regression},
	journal = {J. Multivariate Anal.},
	year = {1998},
	volume = {67},
	issue = {1},
	pages = {49-71}
}

@article{groupReview,
	author = {Jian Huang and Patrick Breheny and Shuangge Ma},
	journal = {Statistical Science},
	year = {2012},
	pages = {481-499},
	volume = {27},
	number = {4},
	title = {A selective review of group selection in high-dimensional models},
	doi = {10.1214/12-STS392},
URL = {https://doi.org/10.1214/12-STS392}
}

@Article{brehenyglasso,
    author = {Patrick Breheny and Jian Huang},
    title = {Group descent algorithms for nonconvex penalized linear
      and logistic regression models with grouped predictors},
    journal = {Stat. Comput.},
    year = {2015},
    volume = {25},
    pages = {173-187},
		doi = {10.1007/s11222-013-9424-2},
		URL = {https://doi.org/10.1007/s11222-013-9424-2}
  }

@article{huang2010,
	author = {Jian Huang and Joel L. Horowitz and Fengrong Wei},
	title = {Variable Selection in nonparametric additive models},
	year = {2010},
	volume = {38},
	number = {4},
	pages = {2282-2313},
	journal = {Ann. Statist.}
}

@article{huber1964,
	author = "Huber, Peter J.",
	fjournal = "Annals of Mathematical Statistics",
	journal = "Ann. Math. Statist.",
	month = "03",
	number = "1",
	pages = "73--101",
	publisher = "The Institute of Mathematical Statistics",
	title = "Robust Estimation of a Location Parameter",
	volume = "35",
	year = "1964",
	doi = {10.1214/aoms/1177703732},
URL = {https://doi.org/10.1214/aoms/1177703732}
}


@article{huber1973,
author = "Huber, Peter J.",
fjournal = "Annals of Statistics",
journal = "Ann. Statist.",
month = "09",
number = "5",
pages = "799--821",
publisher = "The Institute of Mathematical Statistics",
title = "Robust Regression: Asymptotics, Conjectures and Monte Carlo",
volume = "1",
year = "1973"
}



@article{concavel1,
	title  = {Concave 1-norm group selection},
	author = {Dingfeng Jiang and Jian Huang},
	year = {2015},
	volume = {16},
	number = {2},
	pages = {252-267},
	journal = {Biostatistics}
}



	

@InProceedings{kasap_16,
	author = {Ozge Yucel Kasap and Nevzat Ekmekci and Utku Gorkem Ketenci},
	title = {Combining Logisitc Regression Analysis and Association Rule Mining via MLR Algorithm},
	booktitle = {ICSEA 2016 The Eleventh International Conference on Software Engineering Advances},
	pages = {154-159},
	year = {2016},
	organization = {IARA}
}

@Unpublished{qr_group_lasso,
	author = {Kengo Kato},
	title = {Group Lasso for high dimensional sparse quantile regression models},
	pages = {1-37},
	year = {2012},
	url = {https://arxiv.org/pdf/1103.1458},
	month = {March}
}

@Article{varyCoefQR,
	author = {Mi-Ok Kim},
	title = {Quantile regression with varying coefficients},
	year = {2007},
	volume = {35},
	number = {1},
	pages = {92-108},
	journal = {Ann. Statist.}
}

@Article{scadHD,
	author = {Yongdai Kim and Hosik Choi and Hee-Seok Oh},
	title = {Smoothly clipped absolute deviation on high dimensions},
	year = {2008},
	volume = {103},
	number = {484},
	pages = {165-1673},
	journal = {J. Amer. Statist. Assoc. }
}

@Article{knightId,
	author={Keith Knight},
	journal={Ann. Statist.},
	year = {1998},
	volume = {26},
	number = {2},
	pages = {755-770},
	title = {Limiting distributions for $L_1$ regression estimators under general conditions}
}

@book{qrBook,
  author = {Roger Koenker},
  publisher = {Cambridge University Press},
  title = {Quantile Regression},
  year = {2005}
}
	
@Article{koenAdd,
	author = {Roger Koenker},
	title = {Additive models for quantile regression: model selection and confidence bandaids},
	year = {2011},
	volume = {25},
	year = {3},
	journal = {Brazilian Journal of Probability and Statistics},
	pages = {239-262}
}

@article{origQR,
 ISSN = {00129682, 14680262},
 URL = {http://www.jstor.org/stable/1913643},
 abstract = {A simple minimization problem yielding the ordinary sample quantiles in the location model is shown to generalize naturally to the linear model generating a new class of statistics we term "regression quantiles." The estimator which minimizes the sum of absolute residuals is an important special case. Some equivariance properties and the joint asymptotic distribution of regression quantiles are established. These results permit a natural generalization of the linear model of certain well-known robust estimators of location. Estimators are suggested, which have comparable efficiency to least squares for Gaussian linear models while substantially out-performing the least-squares estimator over a wide class of non-Gaussian error distributions.},
 author = {Roger Koenker and Gilbert Bassett},
 journal = {Econometrica},
 number = {1},
 pages = {33--50},
 publisher = {[Wiley, Econometric Society]},
 title = {Regression Quantiles},
 urldate = {2025-05-20},
 volume = {46},
 year = {1978},
doi = {10.2307/1913643}
}

@Article{crq1,
	author = {Roger W. Koenker and Vasco D'Orey},
	title = {Computing Regression Quantiles},
	volume = {36},
	number = {3},
	year = {1987},
	pages = {383-393},
	fjournal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
	journal = {J. R. Stat. Soc. Ser. C. Appl. Stat.},
	URL = {https://www.jstor.org/stable/2347802},
	doi = {10.2307/2347802}
}

@Article{crq2,
	author = {Roger Koenker and Vasco D'Orey},
	title = {A Remark on Algorithm AS 229: Computing Dual Regression Quantiles and Regression Rank Score},
	volume = {43},
	number = {2},
	pages = {410-414},
	fjournal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
	journal = {J. R. Stat. Soc. Ser. C. Appl. Stat.},
	year = {1994},
	URL = {http://www.jstor.org/stable/2986030},
	doi = {10.2307/2986030}
}

@Article{mleScad,
	author = {Sunghoon Kwon and Yongdai Kim},
	title = {Large sample properties of the SCAD-penalized maximum likelihood estimation on high dimensions},
	volume = {22},
	year = {2012},
	pages = {629-653},
	journal = {Statistica Sinica}
}


@Article{MARS,
	author = {Lewis, P. A. W. and Stevens, J. G.},
	title = {Nonlinear modeling of time series using multivariate adaptive regression splines (MARS)},
	journal = {J. Amer. Statist. Assoc.},
	year = {1991},
	volume = {86},
	number = {416},
	pages = {864-877}
}

@Article{qr_anova,
	author = {Chen-Yen Lin and Howard Bondell and Hao Helen Zhang and Hui Zou},
	title = {Variable selection for nonparametric quantile regression via smoothing spline analysis of variance},
	journal = {Stat},
	year = {2013},
	volume = {2},
	pages = {255-268}
}

@Article{cosso,
	author = {Yi Lin and Hao Helen Zhang},
	title = {Component selection and smoothing in multivariate nonparametric regression},
	journal = {Ann. Statist.},
	volume = {34},
	number = {5},
	pages = {2272-2297},
	year = {2006}
}


@article{lv2018,
author = "Lv, Shaogao and Lin, Huazhen and Lian, Heng and Huang, Jian",
fjournal = "Annals of Statistics",
journal = "Ann. Statist.",
month = "04",
number = "2",
pages = "781--813",
publisher = "The Institute of Mathematical Statistics",
title = "Oracle inequalities for sparse additive quantile regression in reproducing kernel Hilbert space",
volume = "46",
year = "2018"
}



@Article{marra2011,
	author = {Giampiero Marra and Simon N. Wood},
	title = {Practical variable selection for generalized additive models},
	journal = {Computational Statistics and Data Analysis},
	year = {2011},
	pages = {2372-2387},
}

@Article{cdqr_smooth,
	author = {Abdallah Mkhadri and Mohamed Ouhourane and Karim Oualkacha},
	title = {A coordinate descent algorithm for computing penalized smooth quantile regression},
	fjournal = {Statistics and Computing},
	journal = {Stat. Comput.},
	year = {2017},
	volume = {27},
	pages = {865-883},
	number = {4}
}

@Article{meier2009,	
	author = {Lukas Meier and van de Geer, Sara and Peter B{\"u}hlmann},
	title = {High-dimensional additive modeling},
	year = {2009},
	volume = {37},
	number = {6B},
	pages = {3779-3821},
	journal = {Ann. Statist.}
}

@Article{negahban2012,
author = {Sahand N. Negahban and others},
title = {A Unified Framework for High-Dimensional Analysis fo $M$-Estimators with Decomposable Regualrizers},
fjournal = {Statistical Science},
journal = {Statist. Sci.},
year = {2012},
volume = {27},
number = {4},
pages = {538-557}
}


@Article{qr_cd,
	author = {Bo Peng and Lan Wang},
	title = {An iterative coordinate descent algorithm for high-dimensional nonconvex penalized quantile regression},
	fjournal = {Journal of Computational and Graphical Statistics},
	journal = {J. Comput. Graph. Statist.},
	volume = {24},
	number = {3},
	pages = {676-694},
	year = {2015},
	doi = {10.1080/10618600.2014.913516},
	URL = {https://doi.org/10.1080/10618600.2014.913516},
	eprint = {https://doi.org/10.1080/10618600.2014.913516}
}

@Article{rosenthal1970,
	author = {Haskell P. Rosenthal},
	title = {On the subspaces of $L^p$ ($p>2)$ spanned by sequences of independent random variables.},
	journal = {Israel Journal of Mathematics},
	volume = {8},
	number = {3},
	pages = {273-303},
	year = {1970}
}

@Article{rosenthal1972,
	author = {Haskell P. Rosenthal},
	title = {On the span in $L^p$ of sequences of independent random variables (II).},
	journal = {Berkely Symposium on Mathematical Statistics and Probability},
	volume = {2},
	year = {1972},
	pages = {149-167}
}

@book{schumaker,
  author = {Larry L. Schumaker},
  publisher = {Wiley, New York},
  title = {Spline Functions: Basic Theory},
  year = {1981}
}

@Article{qr_miss_part_lin,
	author = {Ben Sherwood},
	title = {Variable selection for additive partial linear quantile regression with missing covariates},
	volume = {152},
	year = {2016},
	pages = {206-223},
	journal = {J. Multivariate Anal.}
}

@misc{rqPen,
  author = {Ben Sherwood and Adam Maidman},
  title = {rqPen: Penalized Quantile Regression 2.0},
  year  = {2017}
}

@Article{qr_hd_part_lin, 
	author = {Ben Sherwood and Lan Wang},
	year = {2016},
	title = {Partially linear additive quantile regression in ultra-high dimension},
	volume = {44},
	number = {1},
	pages = {288-317},
	journal = {Ann. Statist.}
}



@Article{stone82,
	author = {Charles J. Stone},
	title = {Optimal global rates of convergence for nonparametric regression},
	journal = {Ann. Statist.},
	volume = {10},
	number = {4},
	pages = {1040-1053},
	year = {1982}
}

@Article{stone85,
	author = {Charles J. Stone},
	title = {Additive regression and other nonparametric models},
	journal = {Ann. Statist.},
	volume = {13},
	number = {2},
	pages = {689-705},
	year = {1985}
}

@Article{stone86,
	author = {Charles J. Stone},
	title = {The dimensionality reduction principle for generalized additive models},
	journal = {Ann. Statist.},
	volume = {14},
	number = {2},
	pages = {590-606},
	year = {1986}
}

@Article{nonparaQR,
	author = {Ichiro Takeuchi and Quoc V. Le and Tim Sears and Alexander J. Smola},
	title = {Nonparametric quantile estimation},
	journal = {Journal of Machine Learning Research},
	year = {2006},
	volume = {7},
	pages = {1231-1264}
}

@Article{dc,
	author = {Pham Dinh Tao and Le Thi Hoai An},
	title = {Convex analysis approach to d.c. programming: Theory, algorithms and applications},
	journal = {Acta Mathematica Vietnamica},
	year = {1997},
	volume = {22},
	number = {1},
	pages = {289–355}
}

@book{vanDerVaart,
  author = {A.W. van der Vaart},
  publisher = {Cambridge University Press},
  title = {Asymptotic Statistics},
  year = {1998}
}

@book{vanWellner,
  author = {Aad W. van der Vaart and Jon A. Wellner},
  publisher = {Cambridge University Press},
  title = {Weak Convergence and Empirical Processes: With Applications to Statistics},
  year = {1996}
}

@book{banachBook,
  author = {M. Ledoux and M. Talagrand},
  publisher = {Springer-Verlag},
  title = {Probability in Banach Spaces},
  year = {1991}
}
	

@Article{quantRegPartVary,
	author = {Huixia Judy Wang and Zhongyi Zhu and Jianhui Zhou},
	title = {Quantile regression in partially linear varying coefficient models},
	journal = {Ann. Statist.},
	year = {2009},
	volume = {37},
	number = {6B},
	pages = {3841-3866}
}
	
@Article{lan_scad,
	author = {Lan Wang and Yichao Wu and Runze Li},
	title = {Quantile regression of analyzing heterogeneity in ultra-high dimension},
	year = {2012},
	volume = {107},
	number = {497},
	pages = {214-222},
	journal = {J. Amer. Statist. Assoc. },
	URL ={https://doi.org/10.1080/01621459.2012.656014},
	doi = {10.1080/01621459.2012.656014}
}



@Article{gen_add,	
	author = {Li Wang and Lan Xue and Annie Qu and Hua Liang},
	title = {Estimation and model selection in generalized additive partial linear models for correlated data with diverging number of covariates},
	year = {2014},
	volume = {42},
	number = {2},
	pages = {592-624},
	journal = {Ann. Statist.}
}

@Article{sbks,
	author = {Li Wang and Lijian Yang},
	title = {Spline-backfitted kernel smoothing of nonlinear additive autoregression model},
	year = {2007},
	volume = {35},
	number = {6},
	pages = {2474-2503},
	journal = {Ann. Statist.}
}

@Article{grSCAD,
	author= {Lifeng Wang and Guang Chen and Hongzhe Li},
	title ={Group SCAD regression analysis for microarray time course gene expression data},
	year = {2007},
	volume = {23},
	number = {12},
	pages = {1486-1494},
	journal = {Bioinformatics},
	doi = {10.1093/bioinformatics/btm125},
    url = {https://doi.org/10.1093/bioinformatics/btm125},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/23/12/1486/49814406/bioinformatics\_23\_12\_1486.pdf}	
}
	
@Article{quantGrowth,
	author = {Ying Wei and Anneli Pere and Roger Koenker and Xuming He},
	title = {Quantile regression methods for reference growth charts},
	year = {2006},
	volume = {25},
	issue = {8},
	pages = {1369-1382},
	journal = {Statistics in Medicine}
}


@Article{welsh89,
	author = {A.H. Welsh},
	title = {On M-Processes and M-Estimation},
	year = {1989},
	volume = {17},
	number = {1},
	pages = {337-361},
	journal = {Ann. Statist.}
}

@Article{scad_qr,
	author = {Yicaho Wu and Yufeng Liu},
	title = {Variable selection in quantile regression},
	year = {2009},
	volume = {19},
	number = {2},
	pages = {801-817},
	fjournal = {Statistica Sinica},
	journal = {Statist. Sinica}
}

@Article{xue2009,	
	author = {Lan Xue},
	title = {Consistent variable selection in additive models},
	year = {2009},
	volume = {19},
	pages = {1281-1296},
	journal = {Statistica Sinica}
}

@article{xueYang2006,
	author = {Lan Xue and Lijian Yang},
	title = {Additive coefficient modeling via polynomial spline},
	year = {2006},
	volume = {16},
	number = {4},
	pages = {1423-1446},
	journal = {Statistica Sinica}
}

@misc{unCon,
  
  
  author = {Man, Rebeka and Pan, Xiaoou and Tan, Kean Ming and Zhou, Wen-Xin},
  
  keywords = {Methodology (stat.ME), Computation (stat.CO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {A Unified Algorithm for Penalized Convolution Smoothed Quantile Regression},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}




@article{huber_cd,
	author = {Congrui Yi and Jian Huang},
	title = {Semismooth Newton Coordinate Descent Algorithm for Elastic-Net Penalized Huber Loss Regression and Quantile Regression},
fjournal = {Journal of Computational and Graphical Statistics},
journal ={J. Comput. Graph. Statist.},
volume = {26},
number = {3},
pages = {547-557},
year  = {2017},
URL = {https://doi.org/10.1080/10618600.2016.1256816},
doi = {10.1080/10618600.2016.1256816}
}



@article{admmQR,
	author = {Liqun Yu and Nan Lin and Lan Wang},
	title = {A parallel algorithm for large-scale nonconvex penalized quantile regression},
	year = {\noop{3001}in press},
	journal = {Journal of Computational and Graphical Statistics}
}

@Article{mcp, 
	author = {Cun-Hui Zhang},
	title = {Nearly unbiased variable selection under minimax concave penalty},
	year = {2010},
	volume = {38},
	number = {2},
	pages = {894-942},
	journal = {Ann. Statist.},
	doi={10.1214/09-AOS729},
	URL={https://doi.org/10.1214/09-AOS729}
}


@Article{zhang2006,
	author = {Hao Helen Zhang and Yi Lin},
	title = {Component selection and smoothing for nonparametric regression in exponential families},
	journal = {Statistica Sinica},
	volume = {16},
	pages = {1021-1041},
	year = {2006}
}

@Article{zhang2004,
	author = {Hao Helen Zhang and Grace Wahba and Yi Lin and Meta Voelker and Michael Ferris and Ronald Klein and Barbara Klein},
	title = {Variable selection and model building via likelihood basis pursuit},
	year = {2004},
	journal = {J. Amer. Statist. Assoc. },
	volume = {99},
	number = {467},
	pages = {659-672}
}


@Article{zhaoLian,
	author = {Kaifeng Zhao and Heng Lian},
	title = {Variable selection in additive quantile regression using nonconcave penalty},
	year = {2016},
	volume = {50},
	number = {6},
	pages = {1276-1289},
	journal = {Statistics}
}

@Article{modelConsLasso,
	author = {Peng Zhao and Bin Yu},
	title = {On model selection consistency of Lasso},
	journal = {Journal of Machine Learning Research},
	year = {2006},
	volume = {7},
	pages = {2541-2563}
}

@Article{adaptiveLasso,
	author = {Hui Zou},
	title = {The adaptive Lasso and its oracle properties},
	journal = {J. Amer. Statist. Assoc. },
	year = {2006},
	volume = {101},
	number = {476},
	pages = {1418-1429},
	doi={10.1198/016214506000000735},
	URL={https://doi.org/10.1198/016214506000000735}
}

@Article{lla,
	author = {Hui Zou and Runze Li},
	journal = {Ann. Statist.},
	volume = {36},
	number = {4},
	year = {2008},
	pages = {1509-1533},
	title = {One-step sparse estimates in nonconcave penalized likelihood models},
	doi = {10.1214/009053607000000802},
	URL = {https://doi.org/10.1214/009053607000000802}
}


@Article{peng10,
author = {Jie Peng and Ji Zhu and Anna Beramaschi and Wonshik Han and Dong-Young Noh and Jonathan R. Pollac and Pei Wang},
title = {Regularized Multivariate Regression for Identifying Master Predictors with Application to Integrative Genomics Study of Breast Cancer},
journal = {Annals of Applied Statistics},
year = {2010},
volume = {4},
number = {1},
pages = {53-77}
}


@Article{kim_09,
author = {Seyoung Kim and Kyung-Ah Sohn and Eric P. Xing},
title = {A Multivariate Regression Approach to Association Analysis of a Quantitative Trait Network},
journal = {Bioinformatics},
year = {2009},
volume = {25},
number = {12},
pages = {i204-i212}
}




@Unpublished{price17,
author = {Bradley S. Price and Charles J. Geyer and Adam J. Rothman},
title = {Automatic Response Category Combination in Multinomial Logistic Regression},
note = {https://arxiv.org/abs/1705.03594},
month = {May},
year = {2017}
}



@article{witten14,
author = {Daniela M. Witten and Ali Shojaie and Fan Zhang},
title = {The Cluster Elastic Net for High-Dimensional Regression With Unknown Variable Grouping},
journal = {Technometrics},
volume = {56},
number = {1},
pages = {112-122},
year = {2014}
}



@ARTICLE{zou05,
    author = {Hui Zou and Trevor Hastie},
    title = {Regularization and variable selection via the Elastic Net},
	  journal = {J. R. Stat. Soc. Ser. B. Stat. Methodol.},
    year = {2005},
    volume = {67},
    pages = {301--320},
		doi={10.1111/j.1467-9868.2005.00503.x},
		URL={https://doi.org/10.1111/j.1467-9868.2005.00503.x}
}

@Article{breiman97,
author = {Leo Breiman and Jerome H. Friedman},
title = {Predicting Multivariate Responses in Multiple Linear Regression},
journal = {J. R. Stat. Soc. Ser. B. Stat. Methodol.},
year = {1997},
volume = {59},
number = {1},
pages = {3-54}
}

@Article{li2015,
author = {Yanming Li and Bin Nan and Ji Zhu},
title = {Multivariate Sparse Group Lasso for Multivariate Multiple Linear Regression with Arbitrary Group Sparsity},
journal = {Biometrics},
year = {2015},
volume = {71},
pages = {354-363}
}

@Article{rothman2010,
author = {Adam J. Rothman and Elizaveta Levina and Ji Zhu },
title = {Sparse Multivariate Regression with Covariance Estimation},
journal = {Journal of Computational and Graphical Statistics},
year = {2010},
volume = {19},
number = {4},
pages = {947-962}
}

@Article{zhou14,
author = {Hua Zhou and Lexin Li},
title = {Regularized Matrix Regression},
journal = {J. R. Stat. Soc. Ser. B. Stat. Methodol.},
year = {2014},
volume = {76},
pages = {463-483}
}

@Article{friedman2008,
author = {Jerome Friedman and Trevor Hastie and Robert Tibshirani},
title = {Regularized Paths for Genearlized Linear Models via Coordinate Descent},
journal = {Journal of Statistial Softwawre},
year = {2008},
volume = {33},
number = {1}
}

@Article{rinaldo2009,
author = {Alessandro Rinaldo},
title = {Properties and Refinements of the Fused Lasso},
journal = {Ann. Statist.},
year = {2009},
volume = {37},
number = {5B},
pages = {2597--3097}
}


@Article{hoefling2010,
author = {Holger Hoefling},
title = {A Path Algorithm for the Fused Lasso Signal Approximator},
journal = {Journal of Computational and Graphical Statistics},
year = {2010},
volume = {19},
number = {4},
pages = {984--1006}
}


@TECHREPORT{friedman2007,
    author = {Jerome Friedman and Trevor Hastie and Holger Höfling and Robert Tibshirani},
    title = {Pathwise coordinate optimization},
    institution = {Stanford University},
    year = {2007}
}

@TECHREPORT{hjortPollard,
    author = {Nils Lid Hjort and David Pollard},
    title = {Asymptotics for minimisers of convex processes},
    institution = {University of Oslo and Yale University},
    year = {1993}
}


@INPROCEEDINGS{liu2010,
    author = {Jun Liu and Lei Yuan and Jieping Ye},
    title = {An efficient algorithm for a class of fused lasso problems},
    booktitle = {In ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
    year = {2010}
}

@ARTICLE{tibs05,
    author = {Robert Tibshirani and Michael Saunders and Saharon Rosset and Ji Zhu and Keith Knight},
    title = {Sparsity and smoothness via the fused lasso},
    journal = {J. R. Stat. Soc. Ser. B. Stat. Methodol.},
    year = {2005},
    pages = {91--108}
}



@Unpublished{liu2017,
author = {Hanzhong Liu and Jinzhu Jia},
title = {On $\ell_2$ Error Bounds of the Elastic Net when $p>>n$},
year = {2017}
}




@Article{lasso, 
	author = {Robert Tibshirani},
	title  = {Regression Shrinkage and Selection via the Lasso},
	journal = {J. R. Stat. Soc. Ser. B. Stat. Methodol.},
	year = {1996},
	pages = {267-288},
	volume = {58}, 
	number = {1},
	URL = {http://www.jstor.org/stable/2346178},
	doi = {10.1111/j.2517-6161.1996.tb02080.x}
}

@Article{ridge,
	author = {Arthur E. Hoerl and Robert W. Kennard},
	title = {Ridge Regression: Biased Estimation for Nonorthogonal Problems},
	journal = {Technometrics},
	year = {1970}, 
	pages = {55-67},
	volume = {12},
	number = {1}
}

@Article{buhlmanCluster,
	author = {Peter B{\"u}hlmann and Philipp R{\"u}timann and Sara van de Greer and Cun-Hui Zhang},
	title = {Correlated variables in regression: Clustering and sparse estimation},
	journal = {J. Statist. Planng Inf},
	year = {2013},
	pages = {1835-1858},
	volume = {143},
	number = {11}
}

@Article{yuan2007,
	author = {Ming Yuan and Yi Lin},
	title = {Model selection and estimation in regression with grouped variables},
	journal = {J. R. Stat. Soc. Ser. B. Stat. Methodol.},
	year = {2005},
	pages = {49-67},
	volume = {68},
	number = {1}, 
	URL = {https://doi.org/10.1111/j.1467-9868.2005.00532.x},
	doi = {10.1111/j.1467-9868.2005.00532.x}
}

@Article{sprem,
	author = {Qiang Sun and Hongtu Zhu and Yufeng Liu and Joseph G. Ibrahim},
	title = {SPReM: Sparse Projection Regression Model for High-Dimensional Linear Regression},
	journal = {J. Am. Statist. Ass},
	year = {2015},
	pages = {289-302},
	volume = {110},
	number = {509}
}

@Article{cook2015,
	author = {R. Dennis Cook and Xin Zhang},
	title = {Foundations for Envelope Models and Methods},
	journal = {J. Am. Statist. Ass},
	year = {2015},
	pages = {599-611},
	volume = {110},
	number = {510}
}

@Article{cook2010,
	author = {R. Dennis Cook and Bing Li and Francesca Chiaromonte},
	title = {Envelope Models for Parsimonious and Efficient Multivariate Linear Regression (with discussion)},
	journal = {Statistica Sinica},
	year = {2010},
	pages = {927-1010},
	volume = {20}
}

@Article{molstad,
	author = {Aaron J. Molstad and Adam J. Rothman},
	title = {Indirect multivariate response linear regression},
	journal = {Biometrika},
	year = {2016},
	volume = {3},
	number = {103},
	pages = {595-607}
}

@Article{lee2012,
	author = {Wonyul Lee and Yufeng Liu},
	title = {Simultaneous multiple response regression and inverse covariance matrix estimation via penalized Gaussian maximum likelihood},
	journal = {J. Multivariate Anal.},
	year = {2012},
	volume = {111},
	pages = {241-255}
}

@Article{bickel2009,
	author = {Peter J. Bickel and Ya'acov Ritov and Alexandre B. Tsybakov},
	title = {Simultaneous Analysis of Lasso and Dantzig Selector},
	journal = {Ann. Statist.},
	year = {2009},
	volume = {37},
	number = {4},
	pages = {1705-1732}
}


@Article{lassoTypeRecovery,
	author = {Nicolai Meinshausen and Bin Yu},
	title = {Lasso-Type Recovery of Sparse Representations for High-Dimensional Data},
	journal = {Ann. Statist.},
	year = {2009},
	volume = {37},
	number = {1},
	pages = {246-270}
}


@Article{dantzig,
	author = {Emmanuel Candes and Terence Tao},
	title = {The Dantzig selector: statistical estimation when $p$ is much larger than $n$},
	journal = {Ann. Statist.},
	year = {2007}, 
	volume = {35},
	number = {6},
	pages = {2313-2351}
}


@Article{oracleLasso,
		author = {Sara van de Geer and Peter B{\"u}hlmann},
		title = {On the conditions used to prove oracle results for the Lasso},
		journal = {Electronic Journal of Statistics},
		volume = {3},
		year = {2009},
		pages = {1360-1392}
}

@Article{genomicData,
		author = {H Votavova and M Dostalova Merkerova and K Fejglova and A Vasikova and Z Krejcik and A Pastorkova and N Tabashidze and J Topinka and M Veleminsky Jr. and R.J. Sram and R Brdicka},
		title = {Transcriptome alterations in maternal and fetal cells induced by tobacco smoke},
		journal = {Placenta},
		volume = {32},
		year = {2011},
		pages = {763-770}
}

@Article{turan,
	author = {Nahid Turan and Mohamed F Ghalwash and Sunita Katari and Christos Coutifaris and Zoran Obradovic and Carmen Sapienza},
	title = {DNA methylation differences at growth related genes correlate with birth weight: a molecular signature linked to developmental origins of adult disease?},
	journal = {BMC Medical Genomics},
	volume = {5},
	year = {2012},
	number = {10},
	pages = {1-21}
}

@Article{nigerianBirthWt,
	author = {Abubakar A. Panti and Bissala A. Ekele and Emmanuel I. Nwobodo and Ahmed Yakubu},
	title = {The relationship between the weight of the placenta and birth weight of the neonate in a Nigerian Hospital},
	journal = {Nigerian Medical Journal},
	volume = {53},
	year = {2012},
	number = {2},
	pages = {80-84}
}

@Article{linearPlaBrth,
	author = {R A. Molteni and S J. Stys and F C. Battaglia},
	title = {Relationship of fetal and placental weight in human beings: fetal/placental weight ratios at various gestational ages and birth weight distributions},
	journal = {The Journal of Reproductive Medicine},
	volume = {21},
	issue = {5},
	year = {1978},
	pages = {327-334}
}

@Article{fetalGrowth,
	author = {M Thame and C Osmond and F Bennett and R Wilks and T Forrester},
	title = {Fetal growth is directly related to maternal anthropometry and placental volume},
	journal = {European Journal of Clinical Nutrition},
	volume = {58},
	issue = {6},
	year = {2004},
	pages = {894-900}
}




@Article{highcostpatients,
	author = {A Maidman and L Wang},
	title = {New Semiparametric Method for Predicting High-Cost Patients},
	journal = {Biometrics},
	year = {\noop{3001}in press}
}

@article{zhou2018,
author = "Zhou, Wen-Xin and others",
fjournal = "Annals of Statistics",
journal = "Ann. Statist.",
month = "10",
number = "5",
pages = "1904--1931",
publisher = "The Institute of Mathematical Statistics",
title = "A new perspective on robust $M$-estimation: Finite sample theory and applications to dependence-adjusted multiple testing",
volume = "46",
year = "2018"
}



@article{sun2020,
author = {Qiang Sun and Wen-Xin Zhou and Jianqing Fan},
title = {Adaptive Huber Regression},
journal = {J. Amer. Statist. Assoc. },
volume = {115},
number = {529},
pages = {254-265},
year  = {2020},
publisher = {Taylor & Francis}
}



@article{jrssbHuber,
author = {Fan, Jianqing and Li, Quefeng and Wang, Yuyan},
title = {Estimation of high dimensional mean regression in the absence of symmetry and light tail assumptions},
fjournal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
journal = {J. R. Stat. Soc. Ser. B. Stat. Methodol.},
volume = {79},
number = {1},
pages = {247-265},
keywords = {High dimension, Huber loss, M-estimator, Optimal rate, Robust regularization},
year = {2017}
}

@article{expectile,
 author = {Whitney K. Newey and James L. Powell},
 journal = {Econometrica},
 number = {4},
 pages = {819--847},
 publisher = {[Wiley, Econometric Society]},
 title = {Asymmetric Least Squares Estimation and Testing},
 volume = {55},
 year = {1987}
}

@article{portnoy1997,
author = "Portnoy, Stephen and Koenker, Roger",
fjournal = "Statistical Science",
journal = "Statist. Sci.",
month = "11",
number = "4",
pages = "279--300",
publisher = "The Institute of Mathematical Statistics",
title = "The Gaussian hare and the Laplacian tortoise: computability of squared-error versus absolute-error estimators",
volume = "12",
year = "1997",
doi = {10.1214/ss/1030037960},
URL = {https://doi.org/10.1214/ss/1030037960}
}




@article{medLasso,
	title = "Simultaneous estimation and variable selection in median regression using Lasso-type penalty",
	author  = "Jinfeng Xu and Zhiliang Ying",
	year = "2010",
	pages = "487--514",
	volume = "62",
	fjournal = "Annals of the Institute of Statistical Mathematics",
	journal = "Ann. Inst. Statist. Math."
}

@article{lee2012Smooth,
	author = "Lee, Yoonkyung and MacEachern, Steven N. and Jung, Yoonsuh",
	fjournal = "Statistical Science",
	journal = "Statist. Sci.",
	month = "08",
	number = "3",
	pages = "350--372",
	publisher = "The Institute of Mathematical Statistics",
	title = "Regularization of Case-Specific Parameters for Robustness and Efficiency",
	volume = "27",
	year = "2012"
}



@article{glassoLogistic,
	author = {Meier, Lukas and Van De Geer, Sara and Bühlmann, Peter},
	title = {The group lasso for logistic regression},
	fjournal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	journal = {J. R. Stat. Soc. Ser. B. Stat. Methodol.},
	volume = {70},
	number = {1},
	pages = {53-71},
	keywords = {Categorical data, Co-ordinate descent algorithm, DNA splice site, Group variable selection, High dimensional generalized linear model, Penalized likelihood},

	abstract = {Summary.  The group lasso is an extension of the lasso to do variable selection on (predefined) groups of variables in linear regression models. The estimates have the attractive property of being invariant under groupwise orthogonal reparameterizations. We extend the group lasso to logistic regression models and present an efficient algorithm, that is especially suitable for high dimensional problems, which can also be applied to generalized linear models to solve the corresponding convex optimization problem. The group lasso estimator for logistic regression is shown to be statistically consistent even if the number of predictors is much larger than sample size but with sparse true underlying structure. We further use a two-stage procedure which aims for sparser models than the group lasso, leading to improved prediction performance for some cases. Moreover, owing to the two-stage nature, the estimates can be constructed to be hierarchical. The methods are used on simulated and real data sets about splice site detection in DNA sequences.},
	year = {2008}
}


@article{huangZhang2010,
author = "Huang, Junzhou and Zhang, Tong",
fjournal = "Annals of Statistics",
journal = "Ann. Statist.",
month = "08",
number = "4",
pages = "1978--2004",
publisher = "The Institute of Mathematical Statistics",
title = "The benefit of group sparsity",
volume = "38",
year = "2010"
}


@article{huberGlassoBio,
	author = "Li-Zhi Liu and Fang-Xiang Wu and Wen-Jun Zhang",
	title = "A group LASSO-based method for robustly inferring gene regulatory networks from multiple time-course datasets",
	fjournal = "BMC Systems Biology",
	journal = "BMC Syst. Biol.",
	year = "2014",
	volume = "8",
	pages = "1--12"
}

@Article{Ciuperca2019,
	author={Ciuperca, Gabriela},
	title={Adaptive group LASSO selection in quantile models},
	journal={Statist. Papers},
	year={2019},
	month={Feb},
	day={01},
	volume={60},
	number={1},
	pages={173-197},
	abstract={The paper considers a linear model with grouped explanatory variables. If the model errors are not with zero mean and bounded variance or if model contains outliers, then the least squares framework is not appropriate. Thus, the quantile regression is an interesting alternative. In order to automatically select the relevant variable groups, we propose and study here the adaptive group LASSO quantile estimator. We establish the sparsity and asymptotic normality of the proposed estimator in two cases: fixed number and divergent number of variable groups. Numerical study by Monte Carlo simulations confirms the theoretical results and illustrates the performance of the proposed estimator.}
}


@Article{Yang2015,
author={Yang, Yi
and Zou, Hui},
title={A fast unified algorithm for solving group-lasso penalize learning problems},
fjournal={Statistics and Computing},
journal={Stat. Comput.},
year={2015},
month={Nov},
day={01},
volume={25},
number={6},
pages={1129-1141},
abstract={This paper concerns a class of group-lasso learning problems where the objective function is the sum of an empirical loss and the group-lasso penalty. For a class of loss function satisfying a quadratic majorization condition, we derive a unified algorithm called groupwise-majorization-descent (GMD) for efficiently computing the solution paths of the corresponding group-lasso penalized learning problem. GMD allows for general design matrices, without requiring the predictors to be group-wise orthonormal. As illustration examples, we develop concrete algorithms for solving the group-lasso penalized least squares and several group-lasso penalized large margin classifiers. These group-lasso models have been implemented in an R package gglasso publicly available from the Comprehensive R Archive Network (CRAN) at http://cran.r-project.org/web/packages/gglasso. On simulated and real data, gglasso consistently outperforms the existing software for computing the group-lasso that implements either the classical groupwise descent algorithm or Nesterov's method.},
URL = {https://doi.org/10.1007/s11222-014-9498-5},
doi = {10.1007/s11222-014-9498-5}
}






@article{JSSv060i05,
   author = {Roger Koenker and Ivan Mizera},
   title = {Convex Optimization in {R}},
   journal = {J. Stat. Softw.},
   volume = {60},
   number = {5},
   year = {2014},
   keywords = {},
   abstract = {Convex optimization now plays an essential role in many facets of statistics. We briefly survey some recent developments and describe some implementations of these methods in R . Applications of linear and quadratic programming are introduced including quantile regression, the Huber M-estimator and various penalized regression methods. Applications to additively separable convex problems subject to linear equality and inequality constraints such as nonparametric density estimation and maximum likelihood estimation of general nonparametric mixture models are described, as are several cone programming problems. We focus throughout primarily on implementations in the R  environment that rely on solution methods linked to R, like MOSEK  by the package Rmosek. Code is provided in R  to illustrate several of these problems. Other applications are available in the R package REBayes, dealing with empirical Bayes estimation of nonparametric mixture models.},
   pages = {1--23},
	 url={https://www.jstatsoft.org/index.php/jss/article/view/v060i05},
 doi={10.18637/jss.v060.i05}
}


@article{lounici2011,
author = "Lounici, Karim and others",
fjournal = "Annals of Statistics",
journal = "Ann. Statist.",
month = "08",
number = "4",
pages = "2164--2204",
publisher = "The Institute of Mathematical Statistics",
title = "Oracle inequalities and optimal inference under group sparsity",
volume = "39",
year = "2011"
}



@article{highdConv,
author = {Tan, Kean Ming and Wang, Lan and Zhou, Wen-Xin},
title = {High-dimensional quantile regression: Convolution smoothing and concave regularization},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
volume = {84},
number = {1},
pages = {205-233},
keywords = {concave regularization, convolution, minimum signal strength, oracle property, quantile regression},
abstract = {Abstract L1-penalized quantile regression (QR) is widely used for analysing high-dimensional data with heterogeneity. It is now recognized that the ???1-penalty introduces non-negligible estimation bias, while a proper use of concave regularization may lead to estimators with refined convergence rates and oracle properties as the signal strengthens. Although folded concave penalized M-estimation with strongly convex loss functions have been well studied, the extant literature on QR is relatively silent. The main difficulty is that the quantile loss is piecewise linear: it is non-smooth and has curvature concentrated at a single point. To overcome the lack of smoothness and strong convexity, we propose and study a convolution-type smoothed QR with iteratively reweighted ???1-regularization. The resulting smoothed empirical loss is twice continuously differentiable and (provably) locally strongly convex with high probability. We show that the iteratively reweighted ???1-penalized smoothed QR estimator, after a few iterations, achieves the optimal rate of convergence, and moreover, the oracle rate and the strong oracle property under an almost necessary and sufficient minimum signal strength condition. Extensive numerical studies corroborate our theoretical results.},
year = {2022},
doi = {https://doi.org/10.1111/rssb.12485},
url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12485},
eprint = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssb.12485}
}


@article{lowdConv,
title = {Smoothed quantile regression with large-scale inference},
journal = {Journal of Econometrics},
volume = {232},
number = {2},
pages = {367-388},
year = {2023},
author = {Xuming He and Xiaoou Pan and Kean Ming Tan and Wen-Xin Zhou},
keywords = {Bahadur-Kiefer representation, Convolution, Quantile regression, Multiplier bootstrap, Non-asymptotic statistics},
abstract = {Quantile regression is a powerful tool for learning the relationship between a response variable and a multivariate predictor while exploring heterogeneous effects. This paper focuses on statistical inference for quantile regression in the "increasing dimension" regime. We provide a comprehensive analysis of a convolution smoothed approach that achieves adequate approximation to computation and inference for quantile regression. This method, which we refer to as conquer, turns the non-differentiable check function into a twice-differentiable, convex and locally strongly convex surrogate, which admits fast and scalable gradient-based algorithms to perform optimization, and multiplier bootstrap for statistical inference. Theoretically, we establish explicit non-asymptotic bounds on estimation and Bahadur-Kiefer linearization errors, from which we show that the asymptotic normality of the conquer estimator holds under a weaker requirement on dimensionality than needed for conventional quantile regression. The validity of multiplier bootstrap is also provided. Numerical studies confirm conquer as a practical and reliable approach to large-scale inference for quantile regression. Software implementing the methodology is available in the R package conquer.},
doi = {https://doi.org/10.1016/j.jeconom.2021.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S0304407621001950}
}

@Article{SherwoodLi2022,
author={Sherwood, Ben
and Li, Shaobo},
title={Quantile regression feature selection and estimation with grouped variables using Huber approximation},
journal={Statistics and Computing},
year={2022},
month={Sep},
day={11},
volume={32},
number={5},
pages={75},
abstract={This paper considers model selection and estimation for quantile regression with a known group structure in the predictors. For the median case the model is estimated by minimizing a penalized objective function with Huber loss and the group lasso penalty. While, for other quantiles an M-quantile approach, an asymmetric version of Huber loss, is used which approximates the standard quantile loss function. This approximation allows for efficient implementation of algorithms which rely on a differentiable loss function. Rates of convergence are provided which demonstrate the potential advantages of using the group penalty and that bias from the Huber-type approximation vanishes asymptotically. An efficient algorithm is discussed, which provides fast and accurate estimation for quantile regression models. Simulation and empirical results are provided to demonstrate the effectiveness of the proposed algorithm and support the theoretical results.},
doi = {10.1007/s11222-022-10135-w},
URL = {https://doi.org/10.1007/s11222-022-10135-w}
}

% Shaobo added
@article{friedman2009glmnet,
  title = {Regularization Paths for Generalized Linear Models via Coordinate Descent},
  author = {Jerome Friedman and Trevor Hastie and Robert Tibshirani},
  fjournal = {Journal of Statistical Software},
	journal = {J. Stat. Softw.},
  year = {2010},
  volume = {33},
  number = {1},
  pages = {1--22},
	url={https://www.jstatsoft.org/index.php/jss/article/view/v033i01},
  doi={10.18637/jss.v033.i01}
}


@article{hunter2004tutorial,
  title={A tutorial on MM algorithms},
  author={Hunter, David R and Lange, Kenneth},
  fjournal={The American Statistician},
	journal = {Amer. Statist.},
  volume={58},
  number={1},
  pages={30--37},
  year={2004},
  publisher={Taylor \& Francis}
}

@article{tibshirani2012strong,
  title={Strong rules for discarding predictors in lasso-type problems},
  author={Tibshirani, Robert and others},
  fjournal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	journal={J. R. Stat. Soc. Ser. B. Stat. Methodol.},
  volume={74},
  number={2},
  pages={245--266},
  year={2012},
  publisher={Wiley Online Library},
	doi = {10.1111/j.1467-9868.2011.01004.x},
	url = {https://doi.org/10.1111/j.1467-9868.2011.01004.x},
  eprint = {https://academic.oup.com/jrsssb/article-pdf/74/2/245/49513900/jrsssb\_74\_2\_245.pdf}
}


@article{wu2010mm,
  title={The {MM} alternative to {EM}},
  author={Wu, Tong Tong and Lange, Kenneth and others},
  fjournal={Statistical Science},
	journal={Statist. Sci.},
  volume={25},
  number={4},
  pages={492--505},
  year={2010},
  publisher={Institute of Mathematical Statistics}
}

@Manual{hqreg,
    title = {hqreg: Regularization Paths for Lasso or Elastic-Net Penalized Huber Loss Regression and Quantile Regression},
    author = {Congrui Yi},
    year = {2017},
    note = {R package version 1.4}
  }


@Manual{AmesR,
    title = {AmesHousing: The Ames Iowa Housing Data},
    author = {Max Kuhn},
    year = {2020},
    note = {R package version 0.0.4}
  }

@article{de2011ames,
  title={Ames, {I}owa: Alternative to the Boston housing data as an end of semester regression project},
  author={De Cock, Dean},
  journal={J. Stat. Educ.},
  volume={19},
  number={3},
  year={2011},
  publisher={Taylor \& Francis},
	doi = {10.1080/10691898.2011.11889627},
	URL = {https://doi.org/10.1080/10691898.2011.11889627},
	eprint = {https://doi.org/10.1080/10691898.2011.11889627}
}

@article{heteroIdQR,
author = {Mingqiu Wang and Xiaoning Kang and Jiajuan Liang and Kun Wang and Yuanshan Wu},
title = {Heteroscedasticity identification and variable selection via multiple quantile regression},
journal = {Journal of Statistical Computation and Simulation},
volume = {94},
number = {2},
pages = {297-314},
year = {2024},
publisher = {Taylor & Francis},
URL={https://doi.org/10.1080/00949655.2023.2243533},
doi={10.1080/00949655.2023.2243533}
}

@article{validQRInf,
author = {Alexandre Belloni, Victor Chernozhukov and Kengo Kato},
title = {Valid Post-Selection Inference in High-Dimensional Approximately Sparse Quantile Regression Models},
journal = {Journal of the American Statistical Association},
volume = {114},
number = {526},
pages = {749--758},
year = {2019},
doi = {10.1080/01621459.2018.1442339},
URL = {https://doi.org/10.1080/01621459.2018.1442339},
eprint = {https://doi.org/10.1080/01621459.2018.1442339}
}

@article{ciHypHDQR,
  author  = {Yibo Yan and Xiaozhou Wang and Riquan Zhang},
  title   = {Confidence Intervals and Hypothesis Testing for High-dimensional Quantile Regression: Convolution Smoothing and Debiasing},
  journal = {Journal of Machine Learning Research},
  year    = {2023},
  volume  = {24},
  number  = {245},
  pages   = {1--49},
  url     = {http://jmlr.org/papers/v24/22-1217.html}
}

,
publisher = {ASA Website},
doi = {10.1080/01621459.2018.1442339},


URL = { 
    
        https://doi.org/10.1080/01621459.2018.1442339
    
    

},
eprint = { 
    
        https://doi.org/10.1080/01621459.2018.1442339
    
    

}

@article{hdCensQR,
author = {Qi Zheng and Limin Peng and Xuming He},
title = {{High dimensional censored quantile regression}},
volume = {46},
journal = {The Annals of Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {308 -- 343},
keywords = {censored quantile regression, High dimensional survival data, varying covariate effects},
year = {2018},
doi={10.1214/17-AOS1551},
URL={https://doi.org/10.1214/17-AOS1551}
}

@article{effCenQR,
author = {Sze Ming Lee, Tony Sit and Gongjun Xu},
title = {Efficient Estimation for Censored Quantile Regression},
journal = {Journal of the American Statistical Association},
volume = {118},
number = {544},
pages = {2762--2775},
year = {2023},
doi = {10.1080/01621459.2022.2078331},
URL = {https://doi.org/10.1080/01621459.2022.2078331},
eprint = {https://doi.org/10.1080/01621459.2022.2078331}
}


@article{quantileCount,
 ISSN = {01621459},
 URL = {http://www.jstor.org/stable/27590667},
 abstract = {This article studies the estimation of conditional quantiles of counts. Given the discreteness of the data, some smoothness must be artificially imposed on the problem. We show that it is possible to smooth the data in a way that allows inference to be performed using standard quantile regression techniques. The performance and implementation of the estimators are illustrated by simulations and an application.},
 author = {José A. F. Machado and J. M. C. Santos Silva},
 journal = {Journal of the American Statistical Association},
 number = {472},
 pages = {1226--1237},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Quantiles for Counts},
 urldate = {2024-09-12},
 volume = {100},
 year = {2005},
URL={https://doi.org/10.1198/016214505000000330},
doi={10.1198/016214505000000330}
}

@article{qrDist,
author = {Stanislav Volgushev and Shih-Kang Chao and Guang Cheng},
title = {{Distributed inference for quantile regression processes}},
volume = {47},
journal = {The Annals of Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {1634 -- 1662},
keywords = {B-spline estimation, conditional distribution function, distributed computing, divide-and-conquer, quantile regression process},
year = {2019},
doi={10.1214/18-AOS1730},
URL={https://doi.org/10.1214/18-AOS1730}
}

@article{quantGrowthVito,
author = {Vito M.R. Muggeo and Federico Torretta and Paul H. C. Eilers and Mariangela Sciandra and Massimo Attanasio},
title ={Multiple smoothing parameters selection in additive regression quantiles},
journal = {Statistical Modelling},
volume = {21},
number = {5},
pages = {428-448},
year = {2021}
}


@ARTICLE{quantCurveNoCross,
  title    = {Estimating growth charts via nonparametric quantile regression: a
              practical framework with application in ecology},
  author   = {Muggeo, Vito M R and Sciandra, Mariangela and Tomasello, Agostino
              and Calvo, Sebastiano},
  journal  = {Environmental and Ecological Statistics},
  volume   =  {20},
  number   =  {4},
  pages    = {519-531},
  year     =  {2013}
}
