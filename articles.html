<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />
  <link rel="alternate" type="application/rss+xml" href="https://journal.r-project.org/articles.xml" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { color: #00769e; background-color: #f1f3f5; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #00769e; } /* Normal */
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #657422; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #00769e; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #00769e; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #00769e; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #5e5e5e; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>


  <!--radix_placeholder_meta_tags-->
  <title>All articles</title>

  <meta property="description" itemprop="description" content="All articles accepted into the R Journal."/>

  <link rel="icon" type="image/vnd.microsoft.icon" href="resources/favicon.ico"/>


  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="All articles"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="All articles accepted into the R Journal."/>
  <meta property="og:locale" content="en_US"/>
  <meta property="og:site_name" content="The R Journal"/>

  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="All articles"/>
  <meta property="twitter:description" content="All articles accepted into the R Journal."/>

  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","listing"]}},"value":[{"type":"character","attributes":{},"value":["All articles"]},{"type":"character","attributes":{},"value":["All articles accepted into the R Journal.\n"]},{"type":"character","attributes":{},"value":["articles"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  <!--radix_placeholder_navigation_in_header-->
  <meta name="distill:offset" content=""/>

  <script type="application/javascript">

    window.headroom_prevent_pin = false;

    window.document.addEventListener("DOMContentLoaded", function (event) {

      // initialize headroom for banner
      var header = $('header').get(0);
      var headerHeight = header.offsetHeight;
      var headroom = new Headroom(header, {
        tolerance: 5,
        onPin : function() {
          if (window.headroom_prevent_pin) {
            window.headroom_prevent_pin = false;
            headroom.unpin();
          }
        }
      });
      headroom.init();
      if(window.location.hash)
        headroom.unpin();
      $(header).addClass('headroom--transition');

      // offset scroll location for banner on hash change
      // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
      window.addEventListener("hashchange", function(event) {
        window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
      });

      // responsive menu
      $('.distill-site-header').each(function(i, val) {
        var topnav = $(this);
        var toggle = topnav.find('.nav-toggle');
        toggle.on('click', function() {
          topnav.toggleClass('responsive');
        });
      });

      // nav dropdowns
      $('.nav-dropbtn').click(function(e) {
        $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
        $(this).parent().siblings('.nav-dropdown')
           .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
      });
      $("body").click(function(e){
        $('.nav-dropdown-content').removeClass('nav-dropdown-active');
      });
      $(".nav-dropdown").click(function(e){
        e.stopPropagation();
      });
    });
  </script>

  <style type="text/css">

  /* Theme (user-documented overrideables for nav appearance) */

  .distill-site-nav {
    color: rgba(255, 255, 255, 0.8);
    background-color: #0F2E3D;
    font-size: 15px;
    font-weight: 300;
  }

  .distill-site-nav a {
    color: inherit;
    text-decoration: none;
  }

  .distill-site-nav a:hover {
    color: white;
  }

  @media print {
    .distill-site-nav {
      display: none;
    }
  }

  .distill-site-header {

  }

  .distill-site-footer {

  }


  /* Site Header */

  .distill-site-header {
    width: 100%;
    box-sizing: border-box;
    z-index: 3;
  }

  .distill-site-header .nav-left {
    display: inline-block;
    margin-left: 8px;
  }

  @media screen and (max-width: 768px) {
    .distill-site-header .nav-left {
      margin-left: 0;
    }
  }


  .distill-site-header .nav-right {
    float: right;
    margin-right: 8px;
  }

  .distill-site-header a,
  .distill-site-header .title {
    display: inline-block;
    text-align: center;
    padding: 14px 10px 14px 10px;
  }

  .distill-site-header .title {
    font-size: 18px;
    min-width: 150px;
  }

  .distill-site-header .logo {
    padding: 0;
  }

  .distill-site-header .logo img {
    display: none;
    max-height: 20px;
    width: auto;
    margin-bottom: -4px;
  }

  .distill-site-header .nav-image img {
    max-height: 18px;
    width: auto;
    display: inline-block;
    margin-bottom: -3px;
  }



  @media screen and (min-width: 1000px) {
    .distill-site-header .logo img {
      display: inline-block;
    }
    .distill-site-header .nav-left {
      margin-left: 20px;
    }
    .distill-site-header .nav-right {
      margin-right: 20px;
    }
    .distill-site-header .title {
      padding-left: 12px;
    }
  }


  .distill-site-header .nav-toggle {
    display: none;
  }

  .nav-dropdown {
    display: inline-block;
    position: relative;
  }

  .nav-dropdown .nav-dropbtn {
    border: none;
    outline: none;
    color: rgba(255, 255, 255, 0.8);
    padding: 16px 10px;
    background-color: transparent;
    font-family: inherit;
    font-size: inherit;
    font-weight: inherit;
    margin: 0;
    margin-top: 1px;
    z-index: 2;
  }

  .nav-dropdown-content {
    display: none;
    position: absolute;
    background-color: white;
    min-width: 200px;
    border: 1px solid rgba(0,0,0,0.15);
    border-radius: 4px;
    box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
    z-index: 1;
    margin-top: 2px;
    white-space: nowrap;
    padding-top: 4px;
    padding-bottom: 4px;
  }

  .nav-dropdown-content hr {
    margin-top: 4px;
    margin-bottom: 4px;
    border: none;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }

  .nav-dropdown-active {
    display: block;
  }

  .nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
    color: black;
    padding: 6px 24px;
    text-decoration: none;
    display: block;
    text-align: left;
  }

  .nav-dropdown-content .nav-dropdown-header {
    display: block;
    padding: 5px 24px;
    padding-bottom: 0;
    text-transform: uppercase;
    font-size: 14px;
    color: #999999;
    white-space: nowrap;
  }

  .nav-dropdown:hover .nav-dropbtn {
    color: white;
  }

  .nav-dropdown-content a:hover {
    background-color: #ddd;
    color: black;
  }

  .nav-right .nav-dropdown-content {
    margin-left: -45%;
    right: 0;
  }

  @media screen and (max-width: 768px) {
    .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
    .distill-site-header a.nav-toggle {
      float: right;
      display: block;
    }
    .distill-site-header .title {
      margin-left: 0;
    }
    .distill-site-header .nav-right {
      margin-right: 0;
    }
    .distill-site-header {
      overflow: hidden;
    }
    .nav-right .nav-dropdown-content {
      margin-left: 0;
    }
  }


  @media screen and (max-width: 768px) {
    .distill-site-header.responsive {position: relative; min-height: 500px; }
    .distill-site-header.responsive a.nav-toggle {
      position: absolute;
      right: 0;
      top: 0;
    }
    .distill-site-header.responsive a,
    .distill-site-header.responsive .nav-dropdown {
      display: block;
      text-align: left;
    }
    .distill-site-header.responsive .nav-left,
    .distill-site-header.responsive .nav-right {
      width: 100%;
    }
    .distill-site-header.responsive .nav-dropdown {float: none;}
    .distill-site-header.responsive .nav-dropdown-content {position: relative;}
    .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
      display: block;
      width: 100%;
      text-align: left;
    }
  }

  /* Site Footer */

  .distill-site-footer {
    width: 100%;
    overflow: hidden;
    box-sizing: border-box;
    z-index: 3;
    margin-top: 30px;
    padding-top: 30px;
    padding-bottom: 30px;
    text-align: center;
  }

  /* Headroom */

  d-title {
    padding-top: 6rem;
  }

  @media print {
    d-title {
      padding-top: 4rem;
    }
  }

  .headroom {
    z-index: 1000;
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
  }

  .headroom--transition {
    transition: all .4s ease-in-out;
  }

  .headroom--unpinned {
    top: -100px;
  }

  .headroom--pinned {
    top: 0;
  }

  /* adjust viewport for navbar height */
  /* helps vertically center bootstrap (non-distill) content */
  .min-vh-100 {
    min-height: calc(100vh - 100px) !important;
  }

  </style>

  <script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
  <link href="site_libs/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"/>
  <link href="site_libs/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"/>
  <script src="site_libs/headroom-0.9.4/headroom.min.js"></script>
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

  <style type="text/css">

  body {
    background-color: white;
  }

  .pandoc-table {
    width: 100%;
  }

  .pandoc-table>caption {
    margin-bottom: 10px;
  }

  .pandoc-table th:not([align]) {
    text-align: left;
  }

  .pagedtable-footer {
    font-size: 15px;
  }

  d-byline .byline {
    grid-template-columns: 2fr 2fr;
  }

  d-byline .byline h3 {
    margin-block-start: 1.5em;
  }

  d-byline .byline .authors-affiliations h3 {
    margin-block-start: 0.5em;
  }

  .authors-affiliations .orcid-id {
    width: 16px;
    height:16px;
    margin-left: 4px;
    margin-right: 4px;
    vertical-align: middle;
    padding-bottom: 2px;
  }

  d-title .dt-tags {
    margin-top: 1em;
    grid-column: text;
  }

  .dt-tags .dt-tag {
    text-decoration: none;
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0em 0.4em;
    margin-right: 0.5em;
    margin-bottom: 0.4em;
    font-size: 70%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  d-article table.gt_table td,
  d-article table.gt_table th {
    border-bottom: none;
    font-size: 100%;
  }

  .html-widget {
    margin-bottom: 2.0em;
  }

  .l-screen-inset {
    padding-right: 16px;
  }

  .l-screen .caption {
    margin-left: 10px;
  }

  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .shaded-content {
    background: white;
  }

  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }

  .hidden {
    display: none !important;
  }

  hr.section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    margin: 0px;
  }


  d-byline {
    border-top: none;
  }

  d-article {
    padding-top: 2.5rem;
    padding-bottom: 30px;
    border-top: none;
  }

  d-appendix {
    padding-top: 30px;
  }

  d-article>p>img {
    width: 100%;
  }

  d-article h2 {
    margin: 1rem 0 1.5rem 0;
  }

  d-article h3 {
    margin-top: 1.5rem;
  }

  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }

  /* Tweak code blocks */

  d-article div.sourceCode code,
  d-article pre code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: auto;
  }

  d-article div.sourceCode {
    background-color: white;
  }

  d-article div.sourceCode pre {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }

  d-article pre {
    font-size: 12px;
    color: black;
    background: none;
    margin-top: 0;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  d-article pre a {
    border-bottom: none;
  }

  d-article pre a:hover {
    border-bottom: none;
    text-decoration: underline;
  }

  d-article details {
    grid-column: text;
    margin-bottom: 0.8em;
  }

  @media(min-width: 768px) {

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: visible !important;
  }

  d-article div.sourceCode pre {
    padding-left: 18px;
    font-size: 14px;
  }

  /* tweak for Pandoc numbered line within distill */
  d-article pre.numberSource code > span {
      left: -2em;
  }

  d-article pre {
    font-size: 14px;
  }

  }

  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  /* CSS for d-contents */

  .d-contents {
    grid-column: text;
    color: rgba(0,0,0,0.8);
    font-size: 0.9em;
    padding-bottom: 1em;
    margin-bottom: 1em;
    padding-bottom: 0.5em;
    margin-bottom: 1em;
    padding-left: 0.25em;
    justify-self: start;
  }

  @media(min-width: 1000px) {
    .d-contents.d-contents-float {
      height: 0;
      grid-column-start: 1;
      grid-column-end: 4;
      justify-self: center;
      padding-right: 3em;
      padding-left: 2em;
    }
  }

  .d-contents nav h3 {
    font-size: 18px;
    margin-top: 0;
    margin-bottom: 1em;
  }

  .d-contents li {
    list-style-type: none
  }

  .d-contents nav > ul {
    padding-left: 0;
  }

  .d-contents ul {
    padding-left: 1em
  }

  .d-contents nav ul li {
    margin-top: 0.6em;
    margin-bottom: 0.2em;
  }

  .d-contents nav a {
    font-size: 13px;
    border-bottom: none;
    text-decoration: none
    color: rgba(0, 0, 0, 0.8);
  }

  .d-contents nav a:hover {
    text-decoration: underline solid rgba(0, 0, 0, 0.6)
  }

  .d-contents nav > ul > li > a {
    font-weight: 600;
  }

  .d-contents nav > ul > li > ul {
    font-weight: inherit;
  }

  .d-contents nav > ul > li > ul > li {
    margin-top: 0.2em;
  }


  .d-contents nav ul {
    margin-top: 0;
    margin-bottom: 0.25em;
  }

  .d-article-with-toc h2:nth-child(2) {
    margin-top: 0;
  }


  /* Figure */

  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }

  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }

  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }

  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }

  /* Citations */

  d-article .citation {
    color: inherit;
    cursor: inherit;
  }

  div.hanging-indent{
    margin-left: 1em; text-indent: -1em;
  }

  /* Citation hover box */

  .tippy-box[data-theme~=light-border] {
    background-color: rgba(250, 250, 250, 0.95);
  }

  .tippy-content > p {
    margin-bottom: 0;
    padding: 2px;
  }


  /* Tweak 1000px media break to show more text */

  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }

    .grid {
      grid-column-gap: 16px;
    }

    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }

  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }

    .grid {
      grid-column-gap: 32px;
    }
  }


  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */

  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  /* Include appendix styles here so they can be overridden */

  d-appendix {
    contain: layout style;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-top: 60px;
    margin-bottom: 0;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    color: rgba(0,0,0,0.5);
    padding-top: 60px;
    padding-bottom: 48px;
  }

  d-appendix h3 {
    grid-column: page-start / text-start;
    font-size: 15px;
    font-weight: 500;
    margin-top: 1em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.65);
  }

  d-appendix h3 + * {
    margin-top: 1em;
  }

  d-appendix ol {
    padding: 0 0 0 15px;
  }

  @media (min-width: 768px) {
    d-appendix ol {
      padding: 0 0 0 30px;
      margin-left: -30px;
    }
  }

  d-appendix li {
    margin-bottom: 1em;
  }

  d-appendix a {
    color: rgba(0, 0, 0, 0.6);
  }

  d-appendix > * {
    grid-column: text;
  }

  d-appendix > d-footnote-list,
  d-appendix > d-citation-list,
  d-appendix > distill-appendix {
    grid-column: screen;
  }

  /* Include footnote styles here so they can be overridden */

  d-footnote-list {
    contain: layout style;
  }

  d-footnote-list > * {
    grid-column: text;
  }

  d-footnote-list a.footnote-backlink {
    color: rgba(0,0,0,0.3);
    padding-left: 0.5em;
  }



  /* Anchor.js */

  .anchorjs-link {
    /*transition: all .25s linear; */
    text-decoration: none;
    border-bottom: none;
  }
  *:hover > .anchorjs-link {
    margin-left: -1.125em !important;
    text-decoration: none;
    border-bottom: none;
  }

  /* Social footer */

  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }

  .disqus-comments {
    margin-right: 30px;
  }

  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }

  #disqus_thread {
    margin-top: 30px;
  }

  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }

  .article-sharing a:hover {
    border-bottom: none;
  }

  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }

  .subscribe p {
    margin-bottom: 0.5em;
  }


  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }


  .sidebar-section.custom {
    font-size: 12px;
    line-height: 1.6em;
  }

  .custom p {
    margin-bottom: 0.5em;
  }

  /* Styles for listing layout (hide title) */
  .layout-listing d-title, .layout-listing .d-title {
    display: none;
  }

  /* Styles for posts lists (not auto-injected) */


  .posts-with-sidebar {
    padding-left: 45px;
    padding-right: 45px;
  }

  .posts-list .description h2,
  .posts-list .description p {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  }

  .posts-list .description h2 {
    font-weight: 700;
    border-bottom: none;
    padding-bottom: 0;
  }

  .posts-list h2.post-tag {
    border-bottom: 1px solid rgba(0, 0, 0, 0.2);
    padding-bottom: 12px;
  }
  .posts-list {
    margin-top: 60px;
    margin-bottom: 24px;
  }

  .posts-list .post-preview {
    text-decoration: none;
    overflow: hidden;
    display: block;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
    padding: 24px 0;
  }

  .post-preview-last {
    border-bottom: none !important;
  }

  .posts-list .posts-list-caption {
    grid-column: screen;
    font-weight: 400;
  }

  .posts-list .post-preview h2 {
    margin: 0 0 6px 0;
    line-height: 1.2em;
    font-style: normal;
    font-size: 24px;
  }

  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.4em;
    font-size: 16px;
  }

  .posts-list .post-preview .thumbnail {
    box-sizing: border-box;
    margin-bottom: 24px;
    position: relative;
    max-width: 500px;
  }
  .posts-list .post-preview img {
    width: 100%;
    display: block;
  }

  .posts-list .metadata {
    font-size: 12px;
    line-height: 1.4em;
    margin-bottom: 18px;
  }

  .posts-list .metadata > * {
    display: inline-block;
  }

  .posts-list .metadata .publishedDate {
    margin-right: 2em;
  }

  .posts-list .metadata .dt-authors {
    display: block;
    margin-top: 0.3em;
    margin-right: 2em;
  }

  .posts-list .dt-tags {
    display: block;
    line-height: 1em;
  }

  .posts-list .dt-tags .dt-tag {
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0.3em 0.4em;
    margin-right: 0.2em;
    margin-bottom: 0.4em;
    font-size: 60%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  .posts-list img {
    opacity: 1;
  }

  .posts-list img[data-src] {
    opacity: 0;
  }

  .posts-more {
    clear: both;
  }


  .posts-sidebar {
    font-size: 16px;
  }

  .posts-sidebar h3 {
    font-size: 16px;
    margin-top: 0;
    margin-bottom: 0.5em;
    font-weight: 400;
    text-transform: uppercase;
  }

  .sidebar-section {
    margin-bottom: 30px;
  }

  .categories ul {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }

  .categories li {
    color: rgba(0, 0, 0, 0.8);
    margin-bottom: 0;
  }

  .categories li>a {
    border-bottom: none;
  }

  .categories li>a:hover {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  }

  .categories .active {
    font-weight: 600;
  }

  .categories .category-count {
    color: rgba(0, 0, 0, 0.4);
  }


  @media(min-width: 768px) {
    .posts-list .post-preview h2 {
      font-size: 26px;
    }
    .posts-list .post-preview .thumbnail {
      float: right;
      width: 30%;
      margin-bottom: 0;
    }
    .posts-list .post-preview .description {
      float: left;
      width: 45%;
    }
    .posts-list .post-preview .metadata {
      float: left;
      width: 20%;
      margin-top: 8px;
    }
    .posts-list .post-preview p {
      margin: 0 0 12px 0;
      line-height: 1.5em;
      font-size: 16px;
    }
    .posts-with-sidebar .posts-list {
      float: left;
      width: 75%;
    }
    .posts-with-sidebar .posts-sidebar {
      float: right;
      width: 20%;
      margin-top: 60px;
      padding-top: 24px;
      padding-bottom: 24px;
    }
  }


  /* Improve display for browsers without grid (IE/Edge <= 15) */

  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }

  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }

  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }

  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }

  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }

  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }

  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }


  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }

  .downlevel .footnotes ol {
    padding-left: 13px;
  }

  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }

  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }

  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }

  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  .downlevel .posts-list .post-preview {
    color: inherit;
  }



  </style>

  <script type="application/javascript">

  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }

  // show body when load is complete
  function on_load_complete() {

    // add anchors
    if (window.anchors) {
      window.anchors.options.placement = 'left';
      window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
    }


    // set body to visible
    document.body.style.visibility = 'visible';

    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }

    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }

  function init_distill() {

    init_common();

    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);

    // create d-title
    $('.d-title').changeElementType('d-title');

    // separator
    var separator = '<hr class="section-separator" style="clear: both"/>';
    // prepend separator above appendix
    $('.d-byline').before(separator);
    $('.d-article').before(separator);

    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);

    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();

    // move posts container into article
    $('.posts-container').appendTo($('d-article'));

    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');

    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;

    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();

    // move refs into #references-listing
    $('#references-listing').replaceWith($('#refs'));

    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-contents a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });

    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');

    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {

      // capture layout
      var layout = $(this).attr('data-layout');

      // apply layout to markdown level block elements
      var elements = $(this).children().not('details, div.sourceCode, pre, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });


      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });

    // remove code block used to force  highlighting css
    $('.distill-force-highlighting-css').parent().remove();

    // remove empty line numbers inserted by pandoc when using a
    // custom syntax highlighting theme, except when numbering line
    // in code chunk
    $('pre:not(.numberLines) code.sourceCode a:empty').remove();

    // load distill framework
    load_distill_framework();

    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {

      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;

      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');

      // article with toc class
      $('.d-contents').parent().addClass('d-article-with-toc');

      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

      // add orcid ids
      $('.authors-affiliations').find('.author').each(function(i, el) {
        var orcid_id = front_matter.authors[i].orcidID;
        var author_name = front_matter.authors[i].author
        if (orcid_id) {
          var a = $('<a></a>');
          a.attr('href', 'https://orcid.org/' + orcid_id);
          var img = $('<img></img>');
          img.addClass('orcid-id');
          img.attr('alt', author_name ? 'ORCID ID for ' + author_name : 'ORCID ID');
          img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
          a.append(img);
          $(this).append(a);
        }
      });

      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }

      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");

      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }

       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }

      // remove d-appendix and d-footnote-list local styles
      $('d-appendix > style:first-child').remove();
      $('d-footnote-list > style:first-child').remove();

      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();

      // hoverable references
      $('span.citation[data-cites]').each(function() {
        const citeChild = $(this).children()[0]
        // Do not process if @xyz has been used without escaping and without bibliography activated
        // https://github.com/rstudio/distill/issues/466
        if (citeChild === undefined) return true

        if (citeChild.nodeName == "D-FOOTNOTE") {
          var fn = citeChild
          $(this).html(fn.shadowRoot.querySelector("sup"))
          $(this).id = fn.id
          fn.remove()
        }
        var refs = $(this).attr('data-cites').split(" ");
        var refHtml = refs.map(function(ref) {
          // Could use CSS.escape too here, we insure backward compatibility in navigator
          return "<p>" + $('div[id="ref-' + ref + '"]').html() + "</p>";
        }).join("\n");
        window.tippy(this, {
          allowHTML: true,
          content: refHtml,
          maxWidth: 500,
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        });
      });

      // fix footnotes in tables (#411)
      // replacing broken distill.pub feature
      $('table d-footnote').each(function() {
        // we replace internal showAtNode methode which is triggered when hovering a footnote
        this.hoverBox.showAtNode = function(node) {
          // ported from https://github.com/distillpub/template/pull/105/files
          calcOffset = function(elem) {
              let x = elem.offsetLeft;
              let y = elem.offsetTop;
              // Traverse upwards until an `absolute` element is found or `elem`
              // becomes null.
              while (elem = elem.offsetParent && elem.style.position != 'absolute') {
                  x += elem.offsetLeft;
                  y += elem.offsetTop;
              }

              return { left: x, top: y };
          }
          // https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement/offsetTop
          const bbox = node.getBoundingClientRect();
          const offset = calcOffset(node);
          this.show([offset.left + bbox.width, offset.top + bbox.height]);
        }
      })

      // clear polling timer
      clearInterval(tid);

      // show body now that everything is ready
      on_load_complete();
    }

    var tid = setInterval(distill_post_process, 50);
    distill_post_process();

  }

  function init_downlevel() {

    init_common();

     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));

    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;

    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();

    // remove toc
    $('.d-contents').remove();

    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });


    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);

    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();

    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });

    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));

    $('body').addClass('downlevel');

    on_load_complete();
  }


  function init_common() {

    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};

        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });

        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);

    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});

    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      // ignore leaflet img layers (#106)
      figures = figures.filter(':not(img[class*="leaflet"])')
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });

      }
    });

    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });

    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace(/^index[.]html/, "./"));
      });
    }

    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');

    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");

    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();

    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }

  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });

  </script>

  <style type="text/css">
  /* base variables */

  /* Edit the CSS properties in this file to create a custom
     Distill theme. Only edit values in the right column
     for each row; values shown are the CSS defaults.
     To return any property to the default,
     you may set its value to: unset
     All rows must end with a semi-colon.                      */

  /* Optional: embed custom fonts here with `@import`          */
  /* This must remain at the top of this file.                 */



  html {
    /*-- Main font sizes --*/
    --title-size:      50px;
    --body-size:       1.06rem;
    --code-size:       14px;
    --aside-size:      12px;
    --fig-cap-size:    13px;
    /*-- Main font colors --*/
    --title-color:     #000000;
    --header-color:    rgba(0, 0, 0, 0.8);
    --body-color:      rgba(0, 0, 0, 0.8);
    --aside-color:     rgba(0, 0, 0, 0.6);
    --fig-cap-color:   rgba(0, 0, 0, 0.6);
    /*-- Specify custom fonts ~~~ must be imported above   --*/
    --heading-font:    sans-serif;
    --mono-font:       monospace;
    --body-font:       sans-serif;
    --navbar-font:     sans-serif;  /* websites + blogs only */
  }

  /*-- ARTICLE METADATA --*/
  d-byline {
    --heading-size:    0.6rem;
    --heading-color:   rgba(0, 0, 0, 0.5);
    --body-size:       0.8rem;
    --body-color:      rgba(0, 0, 0, 0.8);
  }

  /*-- ARTICLE TABLE OF CONTENTS --*/
  .d-contents {
    --heading-size:    18px;
    --contents-size:   13px;
  }

  /*-- ARTICLE APPENDIX --*/
  d-appendix {
    --heading-size:    15px;
    --heading-color:   rgba(0, 0, 0, 0.65);
    --text-size:       0.8em;
    --text-color:      rgba(0, 0, 0, 0.5);
  }

  /*-- WEBSITE HEADER + FOOTER --*/
  /* These properties only apply to Distill sites and blogs  */

  .distill-site-header {
    --title-size:       18px;
    --text-color:       rgba(255, 255, 255, 0.8);
    --text-size:        15px;
    --hover-color:      white;
    --bkgd-color:       #0F2E3D;
  }

  .distill-site-footer {
    --text-color:       rgba(255, 255, 255, 0.8);
    --text-size:        15px;
    --hover-color:      white;
    --bkgd-color:       #0F2E3D;
  }

  /*-- Additional custom styles --*/
  /* Add any additional CSS rules below                      */
  </style>
  <style type="text/css">
  /* base variables */

  /* Edit the CSS properties in this file to create a custom
     Distill theme. Only edit values in the right column
     for each row; values shown are the CSS defaults.
     To return any property to the default,
     you may set its value to: unset
     All rows must end with a semi-colon.                      */

  /* Optional: embed custom fonts here with `@import`          */
  /* This must remain at the top of this file.                 */



  html {
    /*-- Main font sizes --*/
    --title-size:      50px;
    --body-size:       1.06rem;
    --code-size:       14px;
    --aside-size:      12px;
    --fig-cap-size:    13px;
    /*-- Main font colors --*/
    --title-color:     #000000;
    --header-color:    rgba(0, 0, 0, 0.8);
    --body-color:      rgba(0, 0, 0, 0.8);
    --aside-color:     rgba(0, 0, 0, 0.6);
    --fig-cap-color:   rgba(0, 0, 0, 0.6);
    /*-- Specify custom fonts ~~~ must be imported above   --*/
    --heading-font:    sans-serif;
    --mono-font:       monospace;
    --body-font:       sans-serif;
    --navbar-font:     sans-serif;  /* websites + blogs only */
  }

  /*-- ARTICLE METADATA --*/
  d-byline {
    --heading-size:    0.6rem;
    --heading-color:   rgba(0, 0, 0, 0.5);
    --body-size:       0.8rem;
    --body-color:      rgba(0, 0, 0, 0.8);
  }

  /*-- ARTICLE TABLE OF CONTENTS --*/
  .d-contents {
    --heading-size:    18px;
    --contents-size:   13px;
  }

  /*-- ARTICLE APPENDIX --*/
  d-appendix {
    --heading-size:    15px;
    --heading-color:   rgba(0, 0, 0, 0.65);
    --text-size:       0.8em;
    --text-color:      rgba(0, 0, 0, 0.7);
  }

  /*-- WEBSITE HEADER + FOOTER --*/
  /* These properties only apply to Distill sites and blogs  */

  .distill-site-header {
    --title-size:       18px;
    --text-color:       rgba(0, 0, 0, 0.8);
    --text-size:        15px;
    --hover-color:      black;
    --bkgd-color:       #ffffff;
  }

  .distill-site-footer {
    --text-color:       rgba(0, 0, 0, 0.8);
    --text-size:        15px;
    --hover-color:      black;
    --bkgd-color:       #fafafa;
  }

  /*-- Additional custom styles --*/
  /* Add any additional CSS rules below                      */

  .nav-right > a {
    text-transform: uppercase;
  }

  d-title h1, d-title p, d-title figure,
  d-abstract p, d-abstract b {
    grid-column: page;
  }

  .rj-blue {
    color: #2467bb;
  }

  ul li {
    line-height: 1.6;
    margin-top: 0em;
    margin-bottom: 0em;
  }</style>
  <style type="text/css">
  /* base style */

  /* FONT FAMILIES */

  :root {
    --heading-default: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    --mono-default: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    --body-default: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  }

  body,
  .posts-list .post-preview p,
  .posts-list .description p {
    font-family: var(--body-font), var(--body-default);
  }

  h1, h2, h3, h4, h5, h6,
  .posts-list .post-preview h2,
  .posts-list .description h2 {
    font-family: var(--heading-font), var(--heading-default);
  }

  d-article div.sourceCode code,
  d-article pre code {
    font-family: var(--mono-font), var(--mono-default);
  }


  /*-- TITLE --*/
  d-title h1,
  .posts-list > h1 {
    color: var(--title-color, black);
  }

  d-title h1 {
    font-size: var(--title-size, 50px);
  }

  /*-- HEADERS --*/
  d-article h1,
  d-article h2,
  d-article h3,
  d-article h4,
  d-article h5,
  d-article h6 {
    color: var(--header-color, rgba(0, 0, 0, 0.8));
  }

  /*-- BODY --*/
  d-article > p,  /* only text inside of <p> tags */
  d-article > ul, /* lists */
  d-article > ol {
    color: var(--body-color, rgba(0, 0, 0, 0.8));
    font-size: var(--body-size, 1.06rem);
  }


  /*-- CODE --*/
  d-article div.sourceCode code,
  d-article pre code {
    font-size: var(--code-size, 14px);
  }

  /*-- ASIDE --*/
  d-article aside {
    font-size: var(--aside-size, 12px);
    color: var(--aside-color, rgba(0, 0, 0, 0.6));
  }

  /*-- FIGURE CAPTIONS --*/
  figure .caption,
  figure figcaption,
  .figure .caption {
    font-size: var(--fig-cap-size, 13px);
    color: var(--fig-cap-color, rgba(0, 0, 0, 0.6));
  }

  /*-- METADATA --*/
  d-byline h3 {
    font-size: var(--heading-size, 0.6rem);
    color: var(--heading-color, rgba(0, 0, 0, 0.5));
  }

  d-byline {
    font-size: var(--body-size, 0.8rem);
    color: var(--body-color, rgba(0, 0, 0, 0.8));
  }

  d-byline a,
  d-article d-byline a {
    color: var(--body-color, rgba(0, 0, 0, 0.8));
  }

  /*-- TABLE OF CONTENTS --*/
  .d-contents nav h3 {
    font-size: var(--heading-size, 18px);
  }

  .d-contents nav a {
    font-size: var(--contents-size, 13px);
  }

  /*-- APPENDIX --*/
  d-appendix h3 {
    font-size: var(--heading-size, 15px);
    color: var(--heading-color, rgba(0, 0, 0, 0.65));
  }

  d-appendix {
    font-size: var(--text-size, 0.8em);
    color: var(--text-color, rgba(0, 0, 0, 0.5));
  }

  d-appendix d-footnote-list a.footnote-backlink {
    color: var(--text-color, rgba(0, 0, 0, 0.5));
  }

  /*-- WEBSITE HEADER + FOOTER --*/
  .distill-site-header .title {
    font-size: var(--title-size, 18px);
    font-family: var(--navbar-font), var(--heading-default);
  }

  .distill-site-header a,
  .nav-dropdown .nav-dropbtn {
    font-family: var(--navbar-font), var(--heading-default);
  }

  .nav-dropdown .nav-dropbtn {
    color: var(--text-color, rgba(255, 255, 255, 0.8));
    font-size: var(--text-size, 15px);
  }

  .distill-site-header a:hover,
  .nav-dropdown:hover .nav-dropbtn {
    color: var(--hover-color, white);
  }

  .distill-site-header {
    font-size: var(--text-size, 15px);
    color: var(--text-color, rgba(255, 255, 255, 0.8));
    background-color: var(--bkgd-color, #0F2E3D);
  }

  .distill-site-footer {
    font-size: var(--text-size, 15px);
    color: var(--text-color, rgba(255, 255, 255, 0.8));
    background-color: var(--bkgd-color, #0F2E3D);
  }

  .distill-site-footer a:hover {
    color: var(--hover-color, white);
  }</style>
  <!--/radix_placeholder_distill-->
  <script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
  <script src="site_libs/popper-2.6.0/popper.min.js"></script>
  <link href="site_libs/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="site_libs/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="site_libs/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="site_libs/anchor-4.2.2/anchor.min.js"></script>
  <script src="site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body class="layout-listing">

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"All articles","description":"All articles accepted into the R Journal.","authors":[]}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<a class="logo" href="index.html">
<img src="resources/rlogo.png" alt="Logo"/>
</a>
<a href="index.html" class="title">The R Journal</a>
</div>
<div class="nav-right">
<a href="index.html">Home</a>
<a href="issues/2024-4">Current</a>
<a href="issues.html">Issues</a>
<a href="news.html">News</a>
<a href="submissions.html">Submit</a>
<a href="editors.html">Editorial board</a>
<a href="articles.xml">
<i class="fa fa-rss" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->
<!--radix_placeholder_article_listing-->


<script type="application/javascript">

function init_posts_list() {

  function load_image(img) {
    var src = $(img).attr('data-src');
    if (src) {
      $(img).attr('src', src);
      $(img).on("load", function() {
        img.removeAttribute('data-src');
      });
    }
  }

  function set_posts_visible(posts, visible) {
    if (visible) {

      // show bottom border by default
      $(posts).removeClass('post-preview-last');

      // apply limits if need be
      var max_posts = 25;
      var apply_limits = $('.posts-container').hasClass('posts-apply-limit');
      if (apply_limits && posts.length > max_posts) {
        posts = $(posts).slice(0, max_posts);
      } else {
        $('.posts-more a').addClass('hidden');
      }

      // apply last style
      $(posts.slice(-1)[0]).addClass('post-preview-last');

      $(posts).removeClass('hidden');
      $(posts).find('img[data-src]').each(function(i, img) {
        load_image(img);
      });
    } else {
      $(posts).addClass('hidden');
    }
  }

  function apply_hash_filter() {

    // clear active state
    $('.categories .active').removeClass('active');

    // mark all posts invisible to start
    set_posts_visible($('.posts-list').children('a'), false);

    // if we have a hash filter
    if (window.location.hash && window.location.hash.startsWith("#category:")) {

      // mark posts that match the category visible
      var page_category = window.location.hash.replace(/^#category:/, "");
      page_category = decodeURIComponent(page_category)
      var posts = $('.post-metadata').map(function(idx, script) {
        var metadata = $.parseJSON($(script).html());
        var post = null;
        $.each(metadata.categories, function(idx, category) {
          category = category.replace(/ /g,"_");
          if ((page_category || '').toLowerCase() === "articles" || category === page_category) {
            post = $(script).parent().get();
            return false;
          }
        });
        return post;
      });
      set_posts_visible(posts, true);

      // mark the hash active
      $('.categories li>a[href="' + decodeURIComponent(window.location.hash) + '"]').addClass('active');

      // update the list_caption
      var list_caption = $('.posts-list-caption');
      var caption = (page_category || '').toLowerCase() === "articles"
        ? list_caption.attr('data-caption')
        : ('Category: ' + page_category.replace(/_/g," "));
      list_caption.text(caption);

    } else {

      // no hash filter, make all posts visible (subject to max display)
      set_posts_visible($('.posts-list').children(), true);

      // reset list caption
      var list_caption = $('.posts-list-caption');
      list_caption.text(list_caption.attr('data-caption'));


    }
  }

  // more articles
  function apply_post_limits(apply) {
    if (apply) {
      $('.posts-container').addClass('posts-apply-limit');
      $('.posts-more a').removeClass('hidden');
    } else {
      $('.posts-container').removeClass('posts-apply-limit');
      $('.posts-more a').addClass('hidden');
    }
  }

  // click handling for tags
  $('.dt-tag').click(function(ev) {
    window.location.hash = '#category:' + $(this).text().replace(/ /g, "_");
    return false;
  })

  // hash filter handling
  apply_hash_filter();
  $(window).on('hashchange',function() {
    apply_post_limits(true);
    apply_hash_filter();
  });

  // more articles link
  $('.posts-more a').click(function(e) {
    e.preventDefault();
    apply_post_limits(false);
    apply_hash_filter();
    return false;
  });

}

</script>



<div class="posts-container posts-apply-limit l-page">
<div class="posts-list">
<h1 class="posts-list-caption" data-caption="All articles">All articles</h1>
<a href="articles/RJ-2025-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 12, 2025</div>
<div class="dt-authors">
<div class="dt-author">Niek Den Teuling</div>
<div class="dt-author">Steffen Pauws</div>
<div class="dt-author">Edwin van den Heuvel</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>latrend: A Framework for Clustering Longitudinal Data</h2>
<div class="dt-tags"></div>
<p>Clustering of longitudinal data is used to explore common trends among subjects over time. In this paper, we focus on cases where the sole repeated measurement of interest is numeric. Various R packages have been introduced throughout the years for identifying clusters of longitudinal patterns, summarizing the variability in trajectories between subjects in terms of one or more trends. We introduce the R package latrend as a framework for the unified application of methods for longitudinal clustering, enabling comparisons between methods with minimal coding. The package also serves as an interface to commonly used packages for clustering longitudinal data, including dtwclust, flexmix, kml, lcmm, mclust, mixAK, and mixtools. This enables researchers to easily compare different approaches, implementations, and method specifications. Furthermore, researchers can build upon the standard tools provided by the framework to quickly implement new cluster methods, enabling rapid prototyping.</p>
</div>
</a>
<a href="articles/RJ-2025-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 11, 2025</div>
<div class="dt-authors">
<div class="dt-author">Seongwon Im</div>
<div class="dt-author">Ander Wilson</div>
<div class="dt-author">Daniel Mork</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Structured Bayesian Regression Tree Models for Estimating Distributed Lag Effects: The R Package dlmtree</h2>
<div class="dt-tags"></div>
<p>When examining the relationship between an exposure and an outcome,
there is often a time lag between exposure and the observed effect on
the outcome. A common statistical approach for estimating the
relationship between the outcome and lagged measurements of exposure
is a distributed lag model (DLM). Because repeated measurements are
often autocorrelated, the lagged effects are typically constrained to
vary smoothly over time. A recent statistical development on the
smoothing constraint is a tree structured DLM framework. We present an
R package dlmtree, available on CRAN, that integrates tree structured
DLM and extensions into a comprehensive software package with
user-friendly implementation. A conceptual background on tree
structured DLMs and a demonstration of the fitting process of each
model using simulated data are provided. We also demonstrate inference
and interpretation using the fitted models, including summary and
visualization. Additionally, a built-in shiny app for heterogeneity
analysis is included.</p>
</div>
</a>
<a href="articles/RJ-2025-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 7, 2025</div>
<div class="dt-authors">
<div class="dt-author">David Navarro-Gonzalez</div>
<div class="dt-author">Pere J. Ferrando</div>
<div class="dt-author">Fabia Morales-Vives</div>
<div class="dt-author">Ana Hernandez-Dorado</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SIREN: A Hybrid CFA-EFA R Package for Controlling Acquiescence in Restricted Factorial Solutions</h2>
<div class="dt-tags"></div>
<p>The **siren** package implements a two-step procedure that allows
restricted (confirmatory) factor analytic (FA) solutions to be fitted
in data matrices that have been previously 'cleaned' of the biasing
effects of acquiescent responding (AR) by using an unrestricted
(exploratory) FA specification. So, the procedure which is implemented
is hybrid: i.e. (a) an unrestricted acquiescence (ACQ) factor is first
fitted to the data, (b) the residual data (or covariance) matrix after
the impact of ACQ has been partialled-out is obtained, and (c) a
restricted FA solution is fitted to the residual matrix. Although the
basic foundations of the procedure are known, it contains new
methodological developments that are, all of them, implemented in the
package. So, provided that fully or partially balanced scales are
available, the researcher will be able to: (a) calibrate a
multidimensional CFA solution which is free from AR, (b) assess the
goodness of model-data fit of this solution, and (c) obtain individual
score estimates in the content as well as in the ACQ factors. The
functioning of the program is assessed by means of a simulation study,
and illustrated with a toy example. Its usefulness is also
demonstrated by using an illustrative example in the personality
domain. **siren** is submitted to be a valuable tool for use in item
CFA applications when AR is expected to be operating.</p>
</div>
</a>
<a href="articles/RJ-2025-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 7, 2025</div>
<div class="dt-authors">
<div class="dt-author">Anthony Devaux</div>
<div class="dt-author">Ccile Proust-Lima</div>
<div class="dt-author">Robin Genuer</div>
</div>
</div>
<div class="thumbnail">
<img src="articles/RJ-2025-002/figures/dynforestR_graph.png"/>
</div>
<div class="description">
<h2>Random Forests for Time-Fixed and Time-Dependent Predictors: The DynForest R Package</h2>
<div class="dt-tags"></div>
<p>The R package DynForest implements random forests for predicting a continuous, a categorical, or a (multiple causes) time-to-event outcome based on time-fixed and time-dependent predictors. The main originality of DynForest is that it handles time-dependent predictors that can be endogenous (i.e., impacted by the outcome process), measured with error, and measured at subject-specific times. At each recursive step of the tree building process, the time-dependent predictors are internally summarized into individual features on which the split can be done. This is achieved using flexible linear mixed models (thanks to the R package lcmm), whose specification is pre-specified by the user. DynForest returns the mean for a continuous outcome, the category with a majority vote for a categorical outcome, or the cumulative incidence function over time for a survival outcome. DynForest also computes variable importance and minimal depth to inform on the most predictive variables or groups of variables. This paper aims to guide the user with step-by-step examples for fitting random forests using DynForest.</p>
</div>
</a>
<a href="articles/RJ-2025-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 7, 2025</div>
<div class="dt-authors">
<div class="dt-author">Francesco Bartolucci</div>
<div class="dt-author">Antonio Forcina</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>LCCR: An R Package for Inference on Latent Class Models for Capture-Recapture Data with Covariates</h2>
<div class="dt-tags"></div>
<p>A detailed description of the R package LCCR for the analysis of
capture-recapture data relating to a closed population is provided.
The data that can be analyzed consist of the full capture history for
each sample unit and may possibly include individual covariates. The
package allows the specification and estimation of latent class models
in which the distribution of the capture history conditional on the
latent class and covariates follows either a log-linear model in which
bivariate interactions are allowed, or a logit model for the
conditional probability of capture at each occasion given the previous
capture history. Alternatively, the conditional distribution of each
capture occasion can be formulated by a logit model that may account
for the effect of previous capture occasions. Apart from the
conditional distribution of the capture history, the covariates can
also affect the distribution of the class weights. Estimation is based
on the unconditional maximum likelihood method, suitably extended to
account for the presence of covariates by including unit-specific
weights, which are commonly used in empirical likelihood methods. The
package also allows simulation of capture-recapture data from a
specified model and the computation of the profile confidence interval
for the population size. For illustration, we use a data set about
meningitis cases in an Italian region.</p>
</div>
</a>
<a href="articles/RJ-2025-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 7, 2025</div>
<div class="dt-authors">
<div class="dt-author">Jae-Hwan Jhong</div>
<div class="dt-author">Seyoung Lee</div>
<div class="dt-author">Ja-Yong Koo</div>
<div class="dt-author">Kwan-Young Bak</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>spheresmooth: An R Package for Penalized Piecewise Geodesic Curve Fitting on a Sphere</h2>
<div class="dt-tags"></div>
<p>This paper introduces an R package \CRANpkg{spheresmooth}, which implements a penalized piecewise geodesic curve fitting method on a sphere. Spherical data observed over a continuum arise frequently in various fields including cardiology, computer vision, physiology, and geophysics. We propose an adaptive smoothing method by extending the linear spline approach to spherical data. Penalization based on differences of velocity vectors endows sparsity among control points of the spherical curve, which enables data-adaptive curve fitting. The proposed method is implemented with a Riemannian block coordinate descent algorithm. Illustrations on Triassic and Jurassic polar wander data and tropical cyclone data demonstrate practicality of the proposed method and the associated \CRANpkg{spheresmooth} package.</p>
</div>
</a>
<a href="articles/RJ-2025-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 7, 2025</div>
<div class="dt-authors">
<div class="dt-author">Zehang Richard Li</div>
<div class="dt-author">Bryan D Martin</div>
<div class="dt-author">Tracy Qi Dong</div>
<div class="dt-author">Geir-Arne Fuglstad</div>
<div class="dt-author">Jessica Godwin</div>
<div class="dt-author">John Paige</div>
<div class="dt-author">Andrea Riebler</div>
<div class="dt-author">Samuel J Clark</div>
<div class="dt-author">Jon Wakefield</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Space-Time Smoothing of Survey Outcomes using the R Package SUMMER</h2>
<div class="dt-tags"></div>
<p>The increasing availability of complex survey data, and the continued need for estimates of demographic and health indicators at a fine spatial and temporal scale, has led to the need for spatio-temporal smoothing methods that acknowledge the manner in which the data were collected. The open source R package SUMMER implements a variety of methods for spatial or spatio-temporal smoothing of survey outcomes. In this paper, we focus primarily on demographic and health indicators. Our methods are particularly useful for data from Demographic Health Surveys (DHS) and Multiple Indicator Cluster Surveys (MICS). We build upon functions within the survey package, and use INLA for fast Bayesian computation. This paper includes a brief overview of these methods and illustrates the workflow of processing surveys, fitting space-time smoothing models for both binary and composite indicators, and visualizing results with both simulated data and DHS surveys.</p>
</div>
</a>
<a href="articles/RJ-2025-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 7, 2025</div>
<div class="dt-authors">
<div class="dt-author">Yifei Huang</div>
<div class="dt-author">Liping Tong</div>
<div class="dt-author">Jie Yang</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>CDsampling: An R Package for Constrained D-Optimal Sampling in Paid Research Studies</h2>
<div class="dt-tags"></div>
<p>In the context of paid research studies and clinical trials, budget
considerations often require patient sampling from available
populations, which comes with inherent constraints. We introduce the R
package CDsampling, which is the first to our knowledge to integrate
optimal design theories within the framework of constrained sampling.
This package offers the possibility to find both D-optimal approximate
and exact allocations for samplings with or without constraints.
Additionally, it provides functions to find constrained uniform
sampling as a robust sampling strategy when the model information is
limited. To demonstrate its efficacy, we provide simulated examples
and a real-data example with datasets embedded in the package and
compare them with classical sampling methods. Furthermore, the
CDsampling package revisits the theoretical results of the Fisher
information matrix for generalized linear models (including the
regular linear regression model) and multinomial logistic models,
offering functions for its computation.</p>
</div>
</a>
<a href="articles/RJ-2025-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 7, 2025</div>
<div class="dt-authors">
<div class="dt-author">Carles Bret</div>
<div class="dt-author">Jesse Wheeler</div>
<div class="dt-author">Aaron A. King</div>
<div class="dt-author">Edward L. Ionides</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>panelPomp: Analysis of Panel Data via Partially Observed Markov Processes in R</h2>
<div class="dt-tags"></div>
<p>Panel data arise when time series measurements are collected from multiple, dynamically independent but structurally related systems. Each system's time series can be modeled as a partially observed Markov process (POMP), and the ensemble of these models is called a PanelPOMP. If the time series are relatively short, statistical inference for each time series must draw information from across the entire panel. The component systems in the panel are called units; model parameters may be shared between units or may be unit-specific. Differences between units may be of direct inferential interest or may be a nuisance for studying the commonalities. The R package panelPomp supports analysis of panel data via a general class of PanelPOMP models. This includes a suite of tools for manipulation of models and data that take advantage of the panel structure. The panelPomp package currently highlights recent advances enabling likelihood based inference via simulation based algorithms. However, the general framework provided by panelPomp supports development of additional, new inference methodology for panel data.</p>
</div>
</a>
<a href="articles/RJ-2025-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 7, 2025</div>
<div class="dt-authors">
<div class="dt-author">Avi Kenny</div>
<div class="dt-author">Charles J. Wolock</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SimEngine: A Modular Framework for Statistical Simulations in R</h2>
<div class="dt-tags"></div>
<p>This article describes
[**SimEngine**](https://CRAN.R-project.org/package=SimEngine), an
open-source R package for structuring, maintaining, running, and
debugging statistical simulations on both local and cluster-based
computing environments. Several R packages exist for facilitating
simulations, but
[**SimEngine**](https://CRAN.R-project.org/package=SimEngine) is the
only package specifically designed for running simulations in parallel
via job schedulers on high-performance cluster computing systems. The
package provides structure and functionality for common simulation
tasks, such as setting simulation levels, managing seeds for random
number generation, and calculating summary metrics (such as bias and
confidence interval coverage).
[**SimEngine**](https://CRAN.R-project.org/package=SimEngine) also
brings several unique features, such as automatic calculation of Monte
Carlo error and information sharing across simulation replicates. We
provide an overview of the package and demonstrate some of its
advanced functionality.</p>
</div>
</a>
<a href="articles/RJ-2024-033/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 17, 2025</div>
<div class="dt-authors">
<div class="dt-author">Seewoo Li</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-033/distill-preview.png"/>
</div>
<div class="description">
<h2>IRTest: An R Package for Item Response Theory with Estimation of Latent Distribution</h2>
<div class="dt-tags"></div>
<p>Item response theory (IRT) models the relationship between respondents'  latent traits and their responses to specific items. One key aspect of IRT is  the assumption about the distribution of the latent variables,  which can influence parameter estimation accuracy.  While a normal distribution has been conventionally assumed,  this may not always be appropriate. When the assumption of normality is violated,  latent distribution estimation (LDE) can enhance parameter estimation accuracy  by accommodating non-normal characteristics. Despite there being several methods proposed  for LDE in IRT, there is a lack of software designed to handle their implementations.  This paper introduces IRTest, a software program developed for  IRT analysis that incorporates LDE procedures.  It outlines the statistical foundation of LDE,  details the functionalities of IRTest, and provides examples of IRT analyses  to demonstrate the software's applications.</p>
</div>
</a>
<a href="articles/RJ-2024-041/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 17, 2025</div>
<div class="dt-authors">
<div class="dt-author">Csar Lobato-Fernndez</div>
<div class="dt-author">Juan A. Ferrer-Bonsoms</div>
<div class="dt-author">Angel Rubio</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-041/distill-preview.png"/>
</div>
<div class="description">
<h2>GPUmatrix: Seamlessly harness the power of GPU computing in R</h2>
<div class="dt-tags"></div>
<p>GPUs are invaluable for data analysis, particularly in statistics and linear algebra, but integrating them with R has been challenging due to the lack of transparent, easily maintainable packages that don't require significant code alterations. Recognizing this gap, we've developed the GPUmatrix package, now available on CRAN, which emulates the Matrix package's behavior, enabling R to harness the power of GPUs for computations with minimal code adjustments. GPUmatrix supports both single (FP32) and double (FP64) precision data types and includes support for sparse matrices, ensuring broad applicability. Designed for ease of use, it requires only slight modifications to existing code, leveraging the Torch or Tensorflow R packages for GPU operations. We've validated its effectiveness in various statistical and machine learning tasks, including non-negative matrix factorization, logistic regression, and general linear models, and provided a comparative analysis of GPU versus CPU performance, highlighting significant efficiency gains.</p>
</div>
</a>
<a href="articles/RJ-2024-036/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 16, 2025</div>
<div class="dt-authors">
<div class="dt-author">Fulvia Pennoni</div>
<div class="dt-author">Silvia Pandolfi</div>
<div class="dt-author">Francesco Bartolucci</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-036/distill-preview.png"/>
</div>
<div class="description">
<h2>LMest: An R Package for Estimating Generalized Latent Markov Models</h2>
<div class="dt-tags"></div>
<p>We provide a detailed overview of the updated version of the R package LMest, which offers functionalities for estimating Markov chain and latent or hidden Markov models for time series and longitudinal data. This overview includes a description of the modeling structure, maximum-likelihood estimation based on the Expectation-Maximization algorithm, and related issues. Practical applications of these models are illustrated using real and simulated data with both categorical and continuous responses. The latter are handled under the assumption of the Gaussian distribution given the latent process. When describing the main functions of the package, we refer to potential applicative contexts across various fields. The LMest package introduces several key novelties compared to previous versions. It now handles missing responses under the missing-at-random assumption and provides imputed values. The implemented functions allow users to display and visualize model results. Additionally, the package includes functions to perform parametric bootstrap for inferential procedures and to simulate data with complex structures in longitudinal contexts.</p>
</div>
</a>
<a href="articles/RJ-2024-037/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 16, 2025</div>
<div class="dt-authors">
<div class="dt-author">Camille Sabathe</div>
<div class="dt-author">Yohann Foucher</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-037/RJ-2024-037_files/figure-html5/calibfig2-1.png"/>
</div>
<div class="description">
<h2>survivalSL: an R Package for Predicting Survival by a Super Learner</h2>
<div class="dt-tags"></div>
<p>The R package \pkg{survivalSL} contains a variety of functions to construct a super learner in the presence of censored times-to-event and to evaluate its prognostic capacities. Compared to the available packages, we propose additional learners, loss functions for the parameter estimations, and user-friendly functions for evaluating prognostic capacities and predicting survival curves from new observations. We performed simulations to describe the value of our proposal. We also detailed its usage by an application in multiple sclerosis. Because machine learning is increasingly being used in predictive studies with right-censoring, we believe that our solution can be useful for a large community of data analysts, beyond this clinical application .</p>
</div>
</a>
<a href="articles/RJ-2024-034/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 14, 2025</div>
<div class="dt-authors">
<div class="dt-author">Rani Basna</div>
<div class="dt-author">Hiba Nassar</div>
<div class="dt-author">Krzysztof Podgrski</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Splinets -- Orthogonal Splines for Functional Data Analysis</h2>
<div class="dt-tags"></div>
<p>This study introduces an efficient workflow for functional data
analysis in classification problems, utilizing advanced orthogonal
spline bases. The methodology is based on the flexible Splinets
package, featuring a novel spline representation designed for enhanced
data efficiency. The focus here is to show that the novel features
make the package a powerful and efficient tool for advanced functional
data analysis. Two main aspects of spline implemented in the package
are behind this effectiveness: 1) Utilization of Orthonormal Spline
Bases -- the workflow incorporates orthonormal spline bases, known as
splinets, ensuring a robust foundation for data representation; 2)
Consideration of Spline Support Sets -- the implemented spline object
representation accounts for spline support sets, which refines the
accuracy of sparse data representation. Particularly noteworthy are
the improvements achieved in scenarios where data sparsity and
dimension reduction are critical factors. The computational engine of
the package is the dyadic orthonormalization of B-splines that leads
the so-called splinets -- the efficient orthonormal basis of splines
spanned over arbitrarily distributed knots. Importantly, the locality
of $B$-splines concerning support sets is preserved in the
corresponding splinet. This allows for the mathematical elegance of
the data representation in an orthogonal basis. However, if one wishes
to traditionally use the $B$-splines it is equally easy and efficient
because all the computational burden is then carried in the background
by the splinets. Using the locality of the orthogonal splinet, along
with implemented algorithms, the functional data classification
workflow is presented in a case study in which the classic Fashion
MINST dataset is used. Significant efficiency gains obtained by
utilization of the package are highlighted including functional data
representation through stable and efficient computations of the
functional principal components. Several examples based on classical
functional data sets, such as the wine data set, showing the
convenience and elegance of working with Splinets are included as
well.</p>
</div>
</a>
<a href="articles/RJ-2024-038/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 14, 2025</div>
<div class="dt-authors">
<div class="dt-author">Sam Allen</div>
<div class="dt-author">Noelia Otero</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-038/distill-preview.png"/>
</div>
<div class="description">
<h2>Calculating Standardised Indices Using SEI</h2>
<div class="dt-tags"></div>
<p>Standardised indices are measurements of variables on a standardised scale. The standardised scale facilitates comparisons between different variables, and its probabilistic interpretation means the indices are effective for risk management and decision making. Standardised indices have become popular in weather and climate settings, for example within operational drought monitoring systems, and have also been applied in other contexts, such as to energy variables. To facilitate their implementation in practice, the SEI package in R allows the flexible calculation of standardised indices. This paper discusses the theory underlying well-known standardised indices, outlines the general framework to construct them, and provides implementation details for the SEI package. Two case studies are presented whereby standardised indices are applied to climate and energy variables.</p>
</div>
</a>
<a href="articles/RJ-2024-039/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 14, 2025</div>
<div class="dt-authors">
<div class="dt-author">Gyrgy Terdik</div>
<div class="dt-author">Emanuele Taufer</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-039/distill-preview.png"/>
</div>
<div class="description">
<h2>MultiStatM: Multivariate Statistical Methods in R</h2>
<div class="dt-tags"></div>
<p>The package MultiStatM presents a vectorial approach to multivariate moments and cumulants.  Functions provided concern algorithms to build set partitions and commutator matrices,  multivariate d-Hermite polynomials;  theoretical  vector moments and vector cumulants  of multivariate distributions and their conversion formulae. Applications discussed concern  multivariate measures of skewness and kurtosis;   asymptotic covariances for d-variate Hermite polynomials and multivariate moments and       cumulants;  Gram-Charlier approximations.</p>
</div>
</a>
<a href="articles/RJ-2024-040/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 14, 2025</div>
<div class="dt-authors">
<div class="dt-author">Raul Cruz-Cano</div>
<div class="dt-author">Aaron Cohen</div>
<div class="dt-author">Erin Mead-Morse</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-040/distill-preview.png"/>
</div>
<div class="description">
<h2>Canonical Correlation Analysis of Survey Data: The SurveyCC R Package</h2>
<div class="dt-tags"></div>
<p>Classic Canonical Correlation Analysis (CCA) is a popular statistical method that allows for the analysis of the associations between two sets of variables. However, currently it cannot be applied following the published methodological documentation to data sets collected using complex survey design (CSD), which includes factors, such as replicate weights, clusters, and strata, that are critical for the accurate calculation of the statistical significance of any correlation. To close this gap, we have developed the Survey CC algorithm and implemented it in an R package. We describe the theoretical foundations of our algorithm and provide a detailed report of the options of the function that performs it. Moreover, the application of our newly developed method to several national survey data sets shows the differences in conclusions that can be reached if the CSD elements are not taken into consideration during the calculation of the statistical significance of the canonical correlations.</p>
</div>
</a>
<a href="articles/RJ-2024-042/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 14, 2025</div>
<div class="dt-authors">
<div class="dt-author">Antony Unwin</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-042/distill-preview.png"/>
</div>
<div class="description">
<h2>UpAndDownPlots: An R Package for Displaying Absolute and Percentage Changes</h2>
<div class="dt-tags"></div>
<p>UpAndDown plots display the ups and downs of sector changes that make up an overall change between two time points.  They show percentage changes by height and absolute changes by area.  Most alternative displays only show percentage changes.  UpAndDown plots can visualise changes in indices, in consumer markets, in stock markets, in elections, showing how the changes for sectors or for individual components contribute to the overall change.  Examples in this paper include the UK's Consumer Price Index, Northern Ireland population estimates, and the German car market.</p>
</div>
</a>
<a href="articles/RJ-2024-035/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 27, 2025</div>
<div class="dt-authors">
<div class="dt-author">Luke Mosley</div>
<div class="dt-author">Kaveh Salehzadeh Nobari</div>
<div class="dt-author">Giuseppe Brandi</div>
<div class="dt-author">Alex Gibberd</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-035/RJ-2024-035_files/figure-html5/sub1-1.png"/>
</div>
<div class="description">
<h2>Disaggregating Time-Series with Many Indicators: An Overview of the DisaggregateTS Package</h2>
<div class="dt-tags"></div>
<p>Low-frequency time-series (e.g., quarterly data) are often treated as benchmarks for interpolating to higher frequencies, since they generally exhibit greater precision and accuracy in contrast to their high-frequency counterparts (e.g., monthly data) reported by governmental bodies. An array of regression-based methods have been proposed in the literature which aim to estimate a target high-frequency series using higher frequency indicators. However, in the era of big data and with the prevalence of large volumes of administrative data-sources there is a need to extend traditional methods to work in high-dimensional settings, i.e., where the number of indicators is similar or larger than the number of low-frequency samples. The package DisaggregateTS includes both classical regressions-based disaggregation methods alongside recent extensions to high-dimensional settings. This paper provides guidance on how to implement these methods via the package in R, and demonstrates their use in an application to disaggregating CO2 emissions.</p>
</div>
</a>
<a href="articles/RJ-2024-023/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 20, 2025</div>
<div class="dt-authors">
<div class="dt-author">Pyry Kantanen</div>
<div class="dt-author">Erik Blow</div>
<div class="dt-author">Aleksi Lahtinen</div>
<div class="dt-author">Mns Magnusson</div>
<div class="dt-author">Jussi Paananen</div>
<div class="dt-author">Leo Lahti</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Validating and Extracting Information from National Identification Numbers in R: The Case of Finland and Sweden</h2>
<div class="dt-tags"></div>
<p>National identification numbers (NIN) and similar identification code systems are widely used for uniquely identifying individuals and organizations in Finland, Sweden, and many other countries. To increase the general understanding of such techniques of identification, openly available methods and tools for NIN analysis and validation are needed. The hetu and sweidnumbr R packages provide functions for extracting embedded information, checking the validity, and generating random but valid numbers in the context of Finnish and Swedish NINs and other identification codes. In this article, we demonstrate these functions from both packages and provide theoretical context and motivation on the importance of the subject matter. Our work contributes to the growing toolkit of standardized methods for computational social science research, epidemiology, demographic studies, and other register-based inquiries.</p>
</div>
</a>
<a href="articles/RJ-2024-024/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 20, 2025</div>
<div class="dt-authors">
<div class="dt-author">Holger Lwe</div>
<div class="dt-author">Christian A. Scholbeck</div>
<div class="dt-author">Christian Heumann</div>
<div class="dt-author">Bernd Bischl</div>
<div class="dt-author">Giuseppe Casalicchio</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>fmeffects: An R Package for Forward Marginal Effects</h2>
<div class="dt-tags"></div>
<p>Forward marginal effects have recently been introduced as a versatile
and effective model-agnostic interpretation method particularly suited
for non-linear and non-parametric prediction models. They provide
comprehensible model explanations of the form: if we change feature
values by a pre-specified step size, what is the change in the
predicted outcome? We present the R package fmeffects, the first
software implementation of the theory surrounding forward marginal
effects. The relevant theoretical background, package functionality
and handling, as well as the software design and options for future
extensions are discussed in this paper.</p>
</div>
</a>
<a href="articles/RJ-2024-025/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 20, 2025</div>
<div class="dt-authors">
<div class="dt-author">Miriam Esteve</div>
<div class="dt-author">Raquel Bosch-Romeu</div>
<div class="dt-author">Antonio Falco</div>
<div class="dt-author">Jaume Fores</div>
<div class="dt-author">Joan Climent</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>GSSTDA: Implementation in an R Package of the Progression of Disease with Survival Analysis (PAD-S) that Integrates Information on Genes Linked to Survival in the Mapper Filter Function</h2>
<div class="dt-tags"></div>
<p>GSSTDA is a new package for R that implements a new analysis for
trascriptomic data, the Progression Analysis of Disease with Survival
(PAD-S) by Fores-Martos et al. (2022), which allows to identify groups
of samples differentiated by both survival and idiosyncratic
biological features. Although it was designed for transcriptomic
analysis, it can be used with other types of continuous omics data.
The package implements the main algorithms associated with this
methodology, which first removes the part of expression that is
considered physiological using the Disease-Specific Genomic Analysis
(DSGA) and then analyzes it using an unsupervised classification
scheme based on Topological Data Analysis (TDA), the Mapper algorithm.
The implementation includes code to perform the different steps of
this analysis: data preprocessing by DSGA, the selection of genes for
further analysis and a new filter function, which integrates
information about genes related to survival, and the Mapper algorithm
for generating a topological invariant Reeb graph. These functions can
be used independently, although a function that performs the entire
analysis is provided. This paper describes the methodology and
implementation of these functions, and reports numerical results using
an extract of real data base application.</p>
</div>
</a>
<a href="articles/RJ-2024-026/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 20, 2025</div>
<div class="dt-authors">
<div class="dt-author">Lorena Gril</div>
<div class="dt-author">Laura Steinkemper</div>
<div class="dt-author">Marcus Gro</div>
<div class="dt-author">Ulrich Rendtel</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Kernel Heaping - Kernel Density Estimation from regional aggregates via measurement error model</h2>
<div class="dt-tags"></div>
<p>The phenomenon of "aggregation" often occurs in the regional
dissemination of information via choropleth maps. Choropleth maps
represent areas or regions that have been subdivided and color-coded
proportionally to ordinal or scaled quantitative data. By construction
discontinuities at the boundaries of rigid aggregation areas, often of
administrative origin, occur and inadequate choices of reference areas
can lead to errors, misinterpretations and difficulties in the
identification of local clusters. However, these representations do
not reflect the reality. Therefore, a smooth representation of
georeferenced data is a common goal. The use of naive non-parametric
kernel density estimators based on aggregates positioned at the
centroids of the areas result also in an inadequate representation of
reality. Therefore, an iterative method based on the Simulated
Expectation Maximization algorithm was implemented in the
Kernelheaping package. The proposed approach is based on a partly
Bayesian algorithm treating the true unknown geocoordinates as
additional parameters and results in a corrected kernel density
estimate.</p>
</div>
</a>
<a href="articles/RJ-2024-027/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 20, 2025</div>
<div class="dt-authors">
<div class="dt-author">Umut Altay</div>
<div class="dt-author">John Paige</div>
<div class="dt-author">Andrea Riebler</div>
<div class="dt-author">Geir-Arne Fuglstad</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>GeoAdjust: Adjusting for Positional Uncertainty in Geostatistial Analysis of DHS Data</h2>
<div class="dt-tags"></div>
<p>The R-package GeoAdjust adjusts for positional uncertainty in GPS
coordinates and performs fast empirical Bayesian geostatistical
inference for household survey data from the Demographic and Health
Surveys (DHS) Program. DHS household survey data is important for
tracking demographic and health indicators, but is published with
intentional positional error to preserve the privacy of the household
respondents. Such jittering has recently been shown to deteriorate
geostatistical inference and prediction, and GeoAdjust is the first
software package that corrects for jittering in geostatistical models
containing both spatial random effects and raster- and distance-based
covariates. The package provides inference for model parameters and
predictions at unobserved locations, and supports Gaussian, binomial
and Poisson likelihoods with identity link, logit link, and log link
functions, respectively. GeoAdjust provides functions that make model
and prior specification intuitive and flexible for the user, as well
as routines for plotting and output analysis.</p>
</div>
</a>
<a href="articles/RJ-2024-028/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 20, 2025</div>
<div class="dt-authors">
<div class="dt-author">Prabrisha Rakshit</div>
<div class="dt-author">Zhenyu Wang</div>
<div class="dt-author">Tony Cai</div>
<div class="dt-author">Zijian Guo</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SIHR: Statistical Inference in High-Dimensional Linear and Logistic Regression Models</h2>
<div class="dt-tags"></div>
<p>We introduce the R package SIHR for statistical inference in
high-dimensional generalized linear models with continuous and binary
outcomes. The package provides functionalities for constructing
confidence intervals and performing hypothesis tests for
low-dimensional objectives in both one-sample and two-sample
regression settings. We illustrate the usage of SIHR through simulated
examples and present real data applications to demonstrate the
package's performance and practicality.</p>
</div>
</a>
<a href="articles/RJ-2024-029/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 20, 2025</div>
<div class="dt-authors">
<div class="dt-author">Shubo Sun</div>
<div class="dt-author">Zifeng Zhao</div>
<div class="dt-author">Feiyu Jiang</div>
<div class="dt-author">Xiaofeng Shao</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SNSeg: An R Package for Time Series Segmentation via Self-Normalization</h2>
<div class="dt-tags"></div>
<p>T</p>
</div>
</a>
<a href="articles/RJ-2024-030/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 20, 2025</div>
<div class="dt-authors">
<div class="dt-author">Qi Yu</div>
<div class="dt-author">Limin Peng</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SLCARE: An R Package for Semiparametric Latent Class Analysis of Recurrent Events</h2>
<div class="dt-tags"></div>
<p>Recurrent event data frequently arise in biomedical follow-up studies. The concept of latent classes  enables researchers to characterize complex population heterogeneity in a plausible and parsimonious way. This article introduces the R package SLCARE, which implements a robust and flexible algorithm  to  carry out Zhao, Peng, and Hanfelt (2022)s latent class analysis method for recurrent event data, where  semiparametric multiplicative intensity modeling is adopted. SLCARE returns estimates for non-functional model parameters along with the associated variance estimates and $p$ values. Visualization tools are provided to depict the estimated functional model parameters and related functional quantities of interest. SLCARE also delivers a model checking plot  to help assess the adequacy of the fitted model.</p>
</div>
</a>
<a href="articles/RJ-2024-031/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 20, 2025</div>
<div class="dt-authors">
<div class="dt-author">Selcuk Korkmaz</div>
<div class="dt-author">Bilge Eren Yamasan</div>
<div class="dt-author">Dincer Goksuluk</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-031/distill-preview.png"/>
</div>
<div class="description">
<h2>PubChemR: An R Package for Accessing Chemical Data from PubChem</h2>
<div class="dt-tags"></div>
<p>Chemical data is a cornerstone in the fields of chemistry, pharmacology, bioinformatics, and environmental science. The PubChemR package provides a comprehensive R interface to the PubChem database, which is one of the largest and most complete repositories of chemical data. This package simplifies the process of querying and retrieving chemical information, including compound structures, properties, biological activities, and more, directly from within R. By leveraging PubChemR, users can programmatically access a wealth of chemical data, which is essential for research and analysis in the chemical sciences. The package supports various functionalities such as searching by chemical identifiers, downloading chemical structures, and retrieving bioassay results, among others. PubChemR is designed to be user-friendly, providing a intuitive experience for R users ranging from academic researchers to practitioners across various scientific disciplines. This paper presents the capabilities of PubChemR, demonstrates its use through practical examples, and discusses its potential impact on chemical data analysis.</p>
</div>
</a>
<a href="articles/RJ-2024-032/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 20, 2025</div>
<div class="dt-authors">
<div class="dt-author">Tim Ginker</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-032/distill-preview.png"/>
</div>
<div class="description">
<h2>boiwsa: An R Package for Seasonal Adjustment of Weekly Data</h2>
<div class="dt-tags"></div>
<p>This article introduces the R package boiwsa for the seasonal adjustment of weekly data based on the discounted least squares method. It provides a user-friendly interface for computing seasonally adjusted estimates of weekly data and includes functions for creation of country-specific prior adjustment variables, as well as diagnostic tools to assess the quality of the adjustments. The utility of the package is demonstrated through two case studies: one based on US data of gasoline production characterized by a strong trend-cycle and dominant intra-yearly seasonality, and the other based on Israeli data of initial unemployment claims with two seasonal cycles (intra-yearly and intra-monthly) and the impact of two moving holidays.</p>
</div>
</a>
<a href="articles/RJ-2024-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 11, 2025</div>
<div class="dt-authors">
<div class="dt-author">Yinqi Zhao</div>
<div class="dt-author">Qiran Jia</div>
<div class="dt-author">Jesse A. Goodrich</div>
<div class="dt-author">David V. Conti</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>LUCIDus: An R Package For Implementing Latent Unknown Clustering By Integrating Multi-omics Data (LUCID) With Phenotypic Traits</h2>
<div class="dt-tags"></div>
<p>Many studies are leveraging current technologies to obtain multiple
omics measurements on the same individuals. These measurements are
usually cross-sectional, and methods developed and commonly used focus
on omic integration at a single time point. More unique, and a growing
area of interest, are studies that leverage biology or the temporal
sequence of measurements to relate long-term exposures or germline
genetics to intermediate measures capturing transitional processes
that ultimately result in an outcome. In this context, we have
previously introduced an integrative model named Latent Unknown
Clustering by Integrating multi-omics Data (LUCID) aiming to
distinguish unique effects of environmental exposures or germline
genetics and informative omic effects while jointly estimating
subgroups of individuals relevant to the outcome of interest. This
multiple omics analysis consists of early integration (concatenation
of omic layers to estimate common subgroups); intermediate integration
(omic-layer-specific estimation of subgroups that are all related to
the outcome); and late integration (omic-layer-specific estimation of
subgroups that are then interrelated by a priori structures). In this
article, we introduce LUCIDus version 3, an R package to implement the
LUCID model. We review the statistical background of the model and
introduce the workflow of LUCIDus, including model fitting, model
selection, interpretation, inference, and prediction. Throughout, we
use a realistic but simulated dataset based on an ongoing study, the
Human Early Life Exposome Study (HELIX), to illustrate the workflow.</p>
</div>
</a>
<a href="articles/RJ-2024-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 11, 2025</div>
<div class="dt-authors">
<div class="dt-author">Maciej Romaniuk</div>
<div class="dt-author">Przemysaw Grzegorzewski</div>
<div class="dt-author">Abbas Parchami</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-016/flowchart3.png"/>
</div>
<div class="description">
<h2>FuzzySimRes: Epistemic Bootstrap -- an Efficient Tool for Statistical Inference Based on Imprecise Data</h2>
<div class="dt-tags"></div>
<p>The classical Efron's bootstrap is widely used in many areas of
statistical inference, including imprecise data. In our new package
FuzzySimRes, we adapted the bootstrap methodology to epistemic fuzzy
data, i.e., fuzzy perceptions of the usual real-valued random
variables. The epistemic bootstrap algorithms deliver real-valued
samples generated randomly from the initial fuzzy sample. Then, these
samples can be utilized directly in various statistical procedures.
Moreover, we implemented a practically oriented simulation procedure
to generate synthetic fuzzy samples and provided a real-life epistemic
dataset ready to use for various techniques of statistical analysis.
Some examples of their applications, together with the comparisons of
the epistemic bootstrap algorithms and the respective benchmarks, are
also discussed.</p>
</div>
</a>
<a href="articles/RJ-2024-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 11, 2025</div>
<div class="dt-authors">
<div class="dt-author">Hossein Haghbin</div>
<div class="dt-author">Jordan Trinka</div>
<div class="dt-author">Mehdi Maadooliat</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-019/figures/call_3.png"/>
</div>
<div class="description">
<h2>Rfssa: An R Package for Functional Singular Spectrum Analysis</h2>
<div class="dt-tags"></div>
<p>Functional Singular Spectrum Analysis (FSSA) is a non-parametric
approach for analyzing Functional Time Series (FTS) and Multivariate
FTS (MFTS) data. This paper introduces Rfssa, an R package that
addresses implementing FSSA for FTS and MFTS data types. Rfssa
provides a flexible container, the funts class, for FTS/MFTS data
observed on one-dimensional or multi-dimensional domains. It accepts
arbitrary basis systems and offers powerful graphical tools for
visualizing time-varying features and pattern changes. The package
incorporates two forecasting algorithms for FTS data. Developed using
object-oriented programming and Rcpp/RcppArmadillo, Rfssa ensures
computational efficiency. The paper covers theoretical background,
technical details, usage examples, and highlights potential
applications of Rfssa.</p>
</div>
</a>
<a href="articles/RJ-2024-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 9, 2025</div>
<div class="dt-authors">
<div class="dt-author">Emi Tanaka</div>
<div class="dt-author">Dewi Amaliah</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-013/figures/plot-lorenz-1.png"/>
</div>
<div class="description">
<h2>Current State and Prospects of R-Packages for the Design of Experiments</h2>
<div class="dt-tags"></div>
<p>Re-running an experiment is generally costly and, in some cases,
impossible due to limited resources; therefore, the design of an
experiment plays a critical role in increasing the quality of
experimental data. In this paper, we describe the current state of
R-packages for the design of experiments through an exploratory data
analysis of package downloads, package metadata, and a comparison of
characteristics with other topics. We observed that experimental
designs in practice appear to be sufficiently manufactured by a small
number of packages, and the development of experimental designs often
occurs in silos. We also discuss the interface designs of widely
utilized R packages in the field of experimental design and discuss
their future prospects for advancing the field in practice.</p>
</div>
</a>
<a href="articles/RJ-2024-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 9, 2025</div>
<div class="dt-authors">
<div class="dt-author">Mirko Signorelli</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-014/pencal-RJ_files/figure-latex/kaplan-1.png"/>
</div>
<div class="description">
<h2>pencal: an R Package for the Dynamic Prediction of Survival with Many Longitudinal Predictors</h2>
<div class="dt-tags"></div>
<p>In survival analysis, longitudinal information on the health status of
a patient can be used to dynamically update the predicted probability
that a patient will experience an event of interest. Traditional
approaches to dynamic prediction such as joint models become
computationally unfeasible with more than a handful of longitudinal
covariates, warranting the development of methods that can handle a
larger number of longitudinal covariates. We introduce the R package
pencal, which implements a Penalized Regression Calibration (PRC)
approach that makes it possible to handle many longitudinal covariates
as predictors of survival. pencal uses mixed-effects models to
summarize the trajectories of the longitudinal covariates up to a
prespecified landmark time, and a penalized Cox model to predict
survival based on both baseline covariates and summary measures of the
longitudinal covariates. This article illustrates the structure of the
R package, provides a step by step example showing how to estimate
PRC, compute dynamic predictions of survival and validate performance,
and shows how parallelization can be used to significantly reduce
computing time.</p>
</div>
</a>
<a href="articles/RJ-2024-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 9, 2025</div>
<div class="dt-authors">
<div class="dt-author">Noah Greifer</div>
<div class="dt-author">Steven Worthington</div>
<div class="dt-author">Stefano Iacus</div>
<div class="dt-author">Gary King</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-015/figures/plot1-1.png"/>
</div>
<div class="description">
<h2>clarify: Simulation-Based Inference for Regression Models</h2>
<div class="dt-tags"></div>
<p>Simulation-based inference is an alternative to the delta method for computing the uncertainty around regression post-estimation (i.e., derived) quantities such as average marginal effects, average adjusted predictions, and other functions of model parameters. It works by drawing model parameters from their joint distribution and estimating quantities of interest from each set of simulated values, which form a simulated "posterior" distribution of the quantity from which confidence intervals can be computed. clarify provides a simple, unified interface for performing simulation-based inference for any user-specified derived quantities as well as wrappers for common quantities of interest. clarify supports a large and growing number of models through its interface with the marginaleffects package and provides native support for multiply imputed data.</p>
</div>
</a>
<a href="articles/RJ-2024-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 9, 2025</div>
<div class="dt-authors">
<div class="dt-author">Zhiwen Tan</div>
<div class="dt-author">Chang Shen</div>
<div class="dt-author">Zihang Lu</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-017/Figures/traj.jpeg"/>
</div>
<div class="description">
<h2>BCClong: An R Package for Bayesian Consensus Clustering for Multiple Longitudinal Features</h2>
<div class="dt-tags"></div>
<p>It is very common nowadays for a study to collect multiple
longitudinal features and appropriately integrating these features
simultaneously for defining individual subgroups (i.e., clusters)
becomes increasingly crucial to understanding population heterogeneity
and predicting future outcomes. The aim of this paper is to describe a
new package, BCClong, which implements a Bayesian consensus
clustering (BCC) model for multiple longitudinal features. Compared to
existing packages, several key features make the BCClong package
appealing: (a) it allows simultaneous clustering of mixed-type (e.g.,
continuous, discrete and categorical) longitudinal features, (b) it
allows each longitudinal feature to be collected from different
sources with measurements taken at distinct sets of time points (known
as irregularly sampled longitudinal data), (c) it relaxes the
assumption that all features have the same clustering structure by
estimating the feature-specific (local) clusterings and consensus
(global) clustering. Using two real data examples, we provide a
tutorial with step-by-step instructions on using the package.</p>
</div>
</a>
<a href="articles/RJ-2024-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 9, 2025</div>
<div class="dt-authors">
<div class="dt-author">Maeve Upton</div>
<div class="dt-author">Andrew Parnell</div>
<div class="dt-author">Niamh Cahill</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>reslr: An R Package for Relative Sea Level Modelling</h2>
<div class="dt-tags"></div>
<p>We present reslr, an R package to perform Bayesian modelling of relative sea level data. We include a variety of different statistical models previously proposed in the literature, with a unifying framework for loading data, fitting models, and summarising the results. Relative sea-level data often contain measurement error in multiple dimensions, and so our package allows for these to be included in the statistical models. When plotting the output sea level curves, the focus is often on comparing rates of change, and so our package allows for computation of the derivatives of sea level curves with appropriate consideration of the uncertainty. We provide a large example dataset from the Atlantic coast of North America and show some of the results that might be obtained from our package.</p>
</div>
</a>
<a href="articles/RJ-2024-020/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 8, 2025</div>
<div class="dt-authors">
<div class="dt-author">Hannah Comiskey</div>
<div class="dt-author">Niamh Cahill</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>mcmsupply: An R Package for Estimating Contraceptive Method Market Supply Shares</h2>
<div class="dt-tags"></div>
<p>In this paper, we introduce the R package mcmsupply which implements Bayesian hierarchical models for estimating and projecting modern contraceptive market supply shares over time. The package implements four model types. These models vary by the administration level of their outcome estimates (national or subnational estimates) and dataset type utilised in the estimation (multi-country or single-country contraceptive market supply datasets). The mcmsupply package contains a compilation of national and subnational level contraceptive source datasets, generated by Integrated Public Use Microdata Series (IPUMS) and Demographic and Health Survey (DHS) microdata. We describe the functions that implement the models through practical examples. The annual estimates and projections with uncertainty of the contraceptive market supply, produced by mcmsupply at a national and subnational level, are the first of their kind. These estimates and projections have diverse applications, including acting as an indicator of family planning market stability over time and being utilised in the calculation of estimates of modern contraceptive use.</p>
</div>
</a>
<a href="articles/RJ-2024-021/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 8, 2025</div>
<div class="dt-authors">
<div class="dt-author">Michael Hahsler</div>
<div class="dt-author">Anthony R. Cassandra</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-021/RJ-2024-021_files/figure-html5/tiger-transition-1.png"/>
</div>
<div class="description">
<h2>Pomdp: A Computational Infrastructure for Partially Observable Markov Decision Processes</h2>
<div class="dt-tags"></div>
<p>Many important problems involve decision-making under uncertainty. For example, a medical professional needs to make decisions about  the best treatment option based on limited information about the  current state of the patient and uncertainty about outcomes. Different approaches have been developed by the applied mathematics, operations research, and artificial intelligence communities to address  this difficult class of decision-making problems. This paper presents the pomdp package, which provides a computational infrastructure for an approach called the partially  observable Markov decision process (POMDP), which models the problem as a discrete-time stochastic control process. The package lets the user specify POMDPs using familiar R syntax, apply state-of-the-art POMDP solvers, and then take full advantage of R's range of capabilities,  including statistical analysis, simulation, and visualization, to work with the resulting models.</p>
</div>
</a>
<a href="articles/RJ-2024-022/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 8, 2025</div>
<div class="dt-authors">
<div class="dt-author">Erik S. Wright</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Fast and Flexible Search for Homologous Biological Sequences with DECIPHER v3</h2>
<div class="dt-tags"></div>
<p>The rapid growth in available biological sequences makes large-scale analyses increasingly challenging. The DECIPHER package was designed with the objective of helping to manage big biological data, which is even more relevant today than when the package was first introduced. Here, I present DECIPHER version 3 with improvements to sequence databases, as well as fast and flexible sequence search. DECIPHER now allows users to find regions of local similarity between sets of DNA, RNA, or amino acid sequences at high speed. I show the power of DECIPHER v3 by (a) comparing against BLAST and MMseqs2 on a protein homology benchmark, (b) locating nucleotide sequences in a genome, (c) finding the nearest sequences in a reference database, and (d) searching for orthologous sequences common to human and zebrafish genomes. Search hits can be quickly aligned, which enables a variety of downstream applications. These new features of DECIPHER v3 make it easier to manage big biological sequence data.</p>
</div>
</a>
<a href="articles/RJ-2024-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 11, 2025</div>
<div class="dt-authors">
<div class="dt-author">Bettina Grn</div>
<div class="dt-author">Kurt Hornik</div>
<div class="dt-author">Torsten Hothorn</div>
<div class="dt-author">Theresa Scharl</div>
<div class="dt-author">Achim Zeileis</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Remembering Friedrich "Fritz" Leisch</h2>
<div class="dt-tags"></div>
<p>This article remembers our friend and colleague Fritz Leisch (1968--2024) who sadly died earlier this year. Many of the readers of The R Journal will know Fritz as a member of the R Core Team and for many of his contributions to the R community. For us, the co-authors of this article, he was an important companion on our journey with the R project and other scientific endeavours over the years. In the following, we provide a brief synopsis of his career, present his key contributions to the R project and to the scientific community more generally, acknowledge his academic service, and highlight his teaching and mentoring achievements.</p>
</div>
</a>
<a href="articles/RJ-2024-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 11, 2025</div>
<div class="dt-authors">
<div class="dt-author">Rui J. Costa</div>
<div class="dt-author">Moritz Gerstung</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-002/figures/package_summary_figure.png"/>
</div>
<div class="description">
<h2>ebmstate: An R Package For Disease Progression Analysis Under Empirical Bayes Cox Models</h2>
<div class="dt-tags"></div>
<p>The new R package ebmstate is a package for multi-state survival
analysis. It is suitable for high-dimensional data and allows point
and interval estimation of relative transition hazards, cumulative
transition hazards and state occupation probabilities, under
clock-forward and clock-reset Cox models. Our package extends the
package mstate in a threefold manner: it transforms the Cox regression
model into an empirical Bayes model that can handle high-dimensional
data; it introduces an analytical, Fourier transform-based estimator
of state occupation probabilities for clock-reset models that is much
faster than the corresponding, simulation-based estimator in mstate;
and it replaces asymptotic confidence intervals meant for the
low-dimensional setting by non-parametric bootstrap confidence
intervals. Our package supports multi-state models of arbitrary
structure, but the estimators of state occupation probabilities are
valid for transition structures without cycles only. Once the input
data is in the required format, estimation is handled automatically.
The present paper includes a tutorial on how to use ebmstate to
estimate transition hazards and state occupation probabilities, as
well as a simulation study showing how it outperforms mstate in
higher-dimensional settings.</p>
</div>
</a>
<a href="articles/RJ-2024-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 11, 2025</div>
<div class="dt-authors">
<div class="dt-author">Thomas A. Metzger</div>
<div class="dt-author">Christopher T. Franck</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-010/figures/intro4.png"/>
</div>
<div class="description">
<h2>Bayesian Model Selection with Latent Group-Based Effects and Variances with the R Package slgf</h2>
<div class="dt-tags"></div>
<p>Linear modeling is ubiquitous, but performance can suffer when the
model is misspecified. We have recently demonstrated that latent
groupings in the levels of categorical predictors can complicate
inference in a variety of fields including bioinformatics,
agriculture, industry, engineering, and medicine. Here we present the
R package slgf which enables the user to easily implement our
recently-developed approach to detect group-based regression effects,
latent interactions, and/or heteroscedastic error variance through
Bayesian model selection. We focus on the scenario in which the levels
of a categorical predictor exhibit two latent groups. We treat the
detection of this grouping structure as an unsupervised learning
problem by searching the space of possible groupings of factor levels.
First we review the suspected latent grouping factor (SLGF) method.
Next, using both observational and experimental data, we illustrate
the usage of slgf in the context of several common linear model
layouts: one-way analysis of variance (ANOVA), analysis of covariance
(ANCOVA), a two-way replicated layout, and a two-way unreplicated
layout. We have selected data that reveal the shortcomings of
classical analyses to emphasize the advantage our method can provide
when a latent grouping structure is present.</p>
</div>
</a>
<a href="articles/RJ-2024-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 11, 2025</div>
<div class="dt-authors">
<div class="dt-author">Yutong Wu</div>
<div class="dt-author">Abhra Sarkar</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-011/figs/data-model.png"/>
</div>
<div class="description">
<h2>BMRMM: An R Package for Bayesian Markov (Renewal) Mixed Models</h2>
<div class="dt-tags"></div>
<p>We introduce the BMRMM
package implementing Bayesian inference for a class of Markov renewal
mixed models which can characterize the stochastic dynamics of a
collection of sequences, each comprising alternative instances of
categorical states and associated continuous duration times, while
being influenced by a set of exogenous factors as well as a 'random'
individual. The default setting flexibly models the state transition
probabilities using mixtures of Dirichlet distributions and the
duration times using mixtures of gamma kernels while also allowing
variable selection for both. Modeling such data using simpler Markov
mixed models also remains an option, either by ignoring the duration
times altogether or by replacing them with instances of an additional
category obtained by discretizing them by a user-specified unit. The
option is also useful when data on duration times may not be available
in the first place. We demonstrate the package's utility using two
data sets.</p>
</div>
</a>
<a href="articles/RJ-2024-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 10, 2025</div>
<div class="dt-authors">
<div class="dt-author">Gianmarco Vacca</div>
<div class="dt-author">Maria Zoia</div>
<div class="dt-author">Stefano Bertelli</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-003/figures/sim_ts.png"/>
</div>
<div class="description">
<h2>bootCT: An R Package for Bootstrap Cointegration Tests in ARDL Models</h2>
<div class="dt-tags"></div>
<p>The Autoregressive Distributed Lag approach to cointegration or bound
testing, proposed by Pesaran in 2001, has become prominent in
empirical research. Although this approach has many advantages over
the classical cointegration tests, it is not exempt from drawbacks,
such as possible inconclusive inference and distortion in size.
Recently, Bertelli and coauthors developed a bootstrap approach to the
bound tests to overcome these drawbacks. This paper introduces the R
package bootCT, which implements this method by deriving the bootstrap
versions of the bound tests and of the asymptotic F-test on the
independent variables proposed by Sam and coauthors in 2019. As a
spinoff, a general method for generating random multivariate time
series following a given VECM/ARDL structure is provided in the
package. Empirical applications showcase the main functionality of the
package.</p>
</div>
</a>
<a href="articles/RJ-2024-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 10, 2025</div>
<div class="dt-authors">
<div class="dt-author">Alicja Wolny--Dominiak</div>
<div class="dt-author">Tomasz ado</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-004/mapaAll.png"/>
</div>
<div class="description">
<h2>Prediction, Bootstrapping and Monte Carlo Analyses Based on Linear Mixed Models with QAPE 2.0 Package</h2>
<div class="dt-tags"></div>
<p>The paper presents a new R package
[**qape**](https://CRAN.R-project.org/package=qape) for prediction,
accuracy estimation of various predictors and Monte Carlo simulation
studies of properties of both predictors and estimators of accuracy
measures. It allows to predict any population and subpopulation
characteristics of the response variable based on the Linear Mixed
Model (LMM). The response variable can be transformed, e.g. to
logarithm and the data can be in the cross-sectional or longitudinal
framework. Three bootstrap algorithms are developed: parametric,
residual and double, allowing to estimate the prediction accuracy.
Analyses can also include Monte Carlo simulation studies of properties
of the methods used. Unlike other packages, in the prediction process
the user can flexibly define the predictor, the model, the
transformation function of the response variable, the predicted
characteristics and the method of accuracy estimation.</p>
</div>
</a>
<a href="articles/RJ-2024-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 10, 2025</div>
<div class="dt-authors">
<div class="dt-author">Dominik S. Meier</div>
<div class="dt-author">Rui Mata</div>
<div class="dt-author">Dirk U. Wulff</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-005/default_plot_revision.png"/>
</div>
<div class="description">
<h2>text2sdg: An R Package to Monitor Sustainable Development Goals from Text</h2>
<div class="dt-tags"></div>
<p>Monitoring progress on the United Nations Sustainable Development
Goals (SDGs) is important for both academic and non-academic
organizations. Existing approaches to monitoring SDGs have focused on
specific data types; namely, publications listed in proprietary
research databases. We present the text2sdg package for the R
language, a user-friendly, open-source package that detects SDGs in
text data using different individual query systems, an ensemble of
query systems, or custom-made ones. The text2sdg package thereby
facilitates the monitoring of SDGs for a wide array of text sources
and provides a much-needed basis for validating and improving extant
methods to detect SDGs from text.</p>
</div>
</a>
<a href="articles/RJ-2024-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 10, 2025</div>
<div class="dt-authors">
<div class="dt-author">Carolina Vasconcelos</div>
<div class="dt-author">Bruno Damsio</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>GenMarkov:  Modeling Generalized Multivariate Markov Chains in R</h2>
<div class="dt-tags"></div>
<p>This article proposes a new generalization of the Multivariate Markov Chains (MMC) model. The future values of a Markov chain commonly depend on only the past values of the chain in an autoregressive fashion. The generalization proposed in this work also considers exogenous variables that can be deterministic or stochastic.  Furthermore, the effects of the MMC's past values and the effects of pre-determined or exogenous covariates are considered in our model by considering a non-homogeneous Markov chain. The Monte Carlo simulation study findings showed that our model consistently detected a non-homogeneous Markov chain. Besides, an empirical illustration demonstrated the relevance of this new model by estimating probability transition matrices over the space state of the exogenous variable. An additional and practical contribution of this work is the development of a novel R package with this generalization.</p>
</div>
</a>
<a href="articles/RJ-2024-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 10, 2025</div>
<div class="dt-authors">
<div class="dt-author">Kyu Hyun Kim</div>
<div class="dt-author">Sangwook Kang</div>
<div class="dt-author">Sy Han Chiou</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-007/vplot_t0_c3_Q50.png"/>
</div>
<div class="description">
<h2>Fitting a Quantile Regression Model for Residual Life with the R Package qris</h2>
<div class="dt-tags"></div>
<p>In survival analysis, regression modeling has traditionally focused on
assessing covariate effects on survival times, which is defined as the
elapsed time between a baseline and event time. Nevertheless, focusing
on residual life can provide a more dynamic assessment of covariate
effects, as it offers more updated information at specific time points
between the baseline and event occurrence. Statistical methods for
fitting quantile regression models have recently been proposed,
providing favorable alternatives to modeling the mean of residual
lifetimes. Despite these progresses, the lack of computer software
that implements these methods remains an obstacle for researchers
analyzing data in practice. In this paper, we introduce an R package
qris, which
implements methods for fitting semiparametric quantile regression
models on residual life subject to right censoring. We demonstrate the
effectiveness and versatility of this package through comprehensive
simulation studies and a real-world data example, showcasing its
valuable contributions to survival analysis research.</p>
</div>
</a>
<a href="articles/RJ-2024-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 10, 2025</div>
<div class="dt-authors">
<div class="dt-author">Asael Alonzo Matamoros</div>
<div class="dt-author">Alicia Nieto-Reyes</div>
<div class="dt-author">Claudio Agostinelli</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>nortsTest: An R Package for Assessing Normality of Stationary Processes</h2>
<div class="dt-tags"></div>
<p>Normality is the central assumption for analyzing dependent data in several time series models, and the literature has widely studied normality tests. However, the implementations of these tests are limited. The nortsTest package is dedicated to fill this void. The package performs the asymptotic and bootstrap versions of the tests of Epps and Lobato and Velasco and the tests of Psaradakis and Vavra, random projections and El Bouch for normality of stationary processes. These tests are for univariate stationary processes but for El Bouch that also allows bivariate stationary processes. In addition, the package offers visual diagnostics for checking stationarity and normality assumptions for the most used time series models in several R packages. This work aims to show the package's functionality, presenting each test performance with simulated examples and the package utility for model diagnostic in time series analysis.</p>
</div>
</a>
<a href="articles/RJ-2024-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 10, 2025</div>
<div class="dt-authors">
<div class="dt-author">Laurence A. Clarfeld</div>
<div class="dt-author">Caroline Tang</div>
<div class="dt-author">Therese Donovan</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2024-009/images/figure1.png"/>
</div>
<div class="description">
<h2>shinymgr: A Framework for Building, Managing, and Stitching Shiny Modules into Reproducible Workflows</h2>
<div class="dt-tags"></div>
<p>The R package shinymgr provides a unifying framework that allows Shiny developers to create, manage, and deploy a master Shiny application comprised of one or more "apps", where an "app" is a tab-based workflow that guides end-users through a step-by-step analysis. Each tab in a given "app" consists of one or more Shiny modules. The shinymgr app builder allows developers to "stitch" Shiny modules together so that outputs from one module serve as inputs to the next, creating an analysis pipeline that is easy to implement and maintain. Apps developed using shinymgr can be incorporated into R packages or deployed on a server, where they are accessible to end-users.  Users of shinymgr apps can save analyses as an RDS file that fully reproduces the analytic steps and can be ingested into an RMarkdown or Quarto report for rapid reporting. In short, developers use the shinymgr framework to write Shiny modules and seamlessly combine them into Shiny apps, and end-users of these apps can execute reproducible analyses that can be incorporated into reports for rapid dissemination. A comprehensive overview of the package is provided by 12 learnr tutorials.</p>
</div>
</a>
<a href="articles/RJ-2023-092/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 26, 2024</div>
<div class="dt-authors">
<div class="dt-author">Enrique Fes</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>exvatools: Value Added in Exports and Other Input-Output Table Analysis Tools</h2>
<div class="dt-tags"></div>
<p>This article introduces an R package, exvatools, that simplifies the analysis of trade in value added with  international input-output tables. It provides a full set of commands for data extraction, matrix creation and manipulation, decomposition  of value added in gross exports (using alternative methodologies)  and a straightforward calculation of many value added indicators.  It can handle both raw data from well-known public input-output databases and custom data. It has a wide sector and geographical flexibility and can be easily expanded and adapted to specific economic analysis needs, facilitating a better understanding and a wider use of the available statistical resources to study globalization.</p>
</div>
</a>
<a href="articles/RJ-2023-095/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 26, 2024</div>
<div class="dt-authors">
<div class="dt-author">Daniel Gomon</div>
<div class="dt-author">Marta Fiocco</div>
<div class="dt-author">Hein Putter</div>
<div class="dt-author">Mirko Signorelli</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-095/RJ-2023-095_files/figure-html5/assisted-plots-html-1.png"/>
</div>
<div class="description">
<h2>SUrvival Control Chart EStimation Software in R: the success Package</h2>
<div class="dt-tags"></div>
<p>Monitoring the quality of statistical processes has been of great importance, mostly in industrial applications. Control charts are widely used for this purpose, but often lack the ability to monitor survival outcomes. Recently, inspecting survival outcomes has become of interest, especially in medical settings where outcomes often depend on risk factors of patients. For this reason many new survival control charts have been devised and existing ones have been extended to incorporate survival outcomes. The package `success` allows users to construct risk-adjusted control charts for survival data. Functions to determine control chart parameters are included, which can be used even without expert knowledge on the subject of control charts. The package allows to create static as well as interactive charts, which are built using `ggplot2` [@ggplot2R] and `plotly` [@plotlyR].</p>
</div>
</a>
<a href="articles/RJ-2023-080/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 11, 2024</div>
<div class="dt-authors">
<div class="dt-author">Li-Pang Chen</div>
<div class="dt-author">Bangxu Qiu</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SIMEXBoost: An R package for Analysis of High-Dimensional Error-Prone Data Based on Boosting Method</h2>
<div class="dt-tags"></div>
<p>Boosting is a powerful statistical learning method. Its key feature is the ability to derive a strong learner from simple yet weak learners by iteratively updating the learning results. Moreover, boosting algorithms have been employed to do variable selection and estimation for regression models. However, measurement error usually appears in covariates. Ignoring measurement error can lead to biased estimates and wrong inferences. To the best of our knowledge, few packages have been developed to address measurement error and variable selection simultaneously by using boosting algorithms. In this paper, we introduce an R package [SIMEXBoost](https://CRAN.R-project.org/package=SIMEXBoost), which covers some widely used regression models and applies the simulation and extrapolation method to deal with measurement error effects. Moreover, the package [SIMEXBoost](https://CRAN.R-project.org/package=SIMEXBoost) enables us to do variable selection and estimation for high-dimensional data under various regression models. To assess the performance and illustrate the features of the package, we conduct numerical studies.</p>
</div>
</a>
<a href="articles/RJ-2023-081/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 11, 2024</div>
<div class="dt-authors">
<div class="dt-author">Christopher R. Bilder</div>
<div class="dt-author">Brianna D. Hitt</div>
<div class="dt-author">Brad J. Biggerstaff</div>
<div class="dt-author">Joshua M. Tebbs</div>
<div class="dt-author">Christopher S. McMahan</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>binGroup2: Statistical Tools for Infection Identification via Group Testing</h2>
<div class="dt-tags"></div>
<p>Group testing is the process of testing items as an amalgamation, rather than separately, to determine the binary status for each item. Its use was especially important during the COVID-19 pandemic through testing specimens for SARS-CoV-2. The adoption of group testing for this and many other applications is because members of a negative testing group can be declared negative with potentially only one test. This subsequently leads to significant increases in laboratory testing capacity. Whenever a group testing algorithm is put into practice, it is critical for laboratories to understand the algorithm's operating characteristics, such as the expected number of tests. Our paper presents the [binGroup2](https://CRAN.R-project.org/package=binGroup2) package that provides the statistical tools for this purpose. This R package is the first to address the identification aspect of group testing for a wide variety of algorithms. We illustrate its use through COVID-19 and chlamydia/gonorrhea applications of group testing.</p>
</div>
</a>
<a href="articles/RJ-2023-082/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 11, 2024</div>
<div class="dt-authors">
<div class="dt-author">Staci Hepler</div>
<div class="dt-author">Robert Erhardt</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>multiocc: An R Package for Spatio-Temporal Occupancy Models for Multiple Species</h2>
<div class="dt-tags"></div>
<p>Spatio-temporal occupancy models are used to model the presence or absence of a species at particular locations and times, while accounting for dependence in both space and time. Multivariate extensions can be used to simultaneously model multiple species, which introduces another dimension to the dependence structure in the data. In this paper we introduce multiocc, an `R` package for fitting multivariate spatio-temporal occupancy models. We demonstrate the use of this package fitting the multi-species spatio-temporal occupancy model to data on six species of birds from the Swiss MHB Breeding Bird Survey.</p>
</div>
</a>
<a href="articles/RJ-2023-083/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 11, 2024</div>
<div class="dt-authors">
<div class="dt-author">Gustav Jonzon</div>
<div class="dt-author">Michael C Sachs</div>
<div class="dt-author">Erin E Gabriel</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-083/figures/InterfaceStart2.png"/>
</div>
<div class="description">
<h2>Accessible Computation of Tight Symbolic Bounds on Causal Effects using an Intuitive Graphical Interface</h2>
<div class="dt-tags"></div>
<p>Strong untestable assumptions are almost universal in causal point estimation. In particular settings, bounds can be derived to narrow the possible range of a causal effect. Symbolic bounds apply to all settings that can be depicted using the same directed acyclic graph and for the same effect of interest. Although the core of the methodology for deriving symbolic bounds has been previously developed, the means of implementation and computation have been lacking. Our R-package causaloptim aims to solve this usability problem by providing the user with a graphical interface through Shiny. This interface takes input in a form that most researchers with an interest in causal inference will be familiar: a graph drawn in the user's web browser and a causal query written in text using common counterfactual notation.</p>
</div>
</a>
<a href="articles/RJ-2023-084/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 11, 2024</div>
<div class="dt-authors">
<div class="dt-author">Liangkang Wang</div>
<div class="dt-author">Irina Gaynanova</div>
<div class="dt-author">Benjamin Risk</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-084/figures/Original_data_figure.png"/>
</div>
<div class="description">
<h2>singR: An R Package for Simultaneous Non-Gaussian Component Analysis for Data Integration</h2>
<div class="dt-tags"></div>
<p>This paper introduces an R package singR that implements Simultaneous non-Gaussian Component Analysis (SING) for data integration. SING uses a non-Gaussian measure of information to extract feature loadings and scores (latent variables) that are shared across multiple datasets. We describe the functions implemented in singR and showcase their use on two examples. The first example is a toy example working with images. The second example is a simulated study integrating functional connectivity estimates from a resting-state functional magnetic resonance imaging dataset and task activation maps from a working memory functional magnetic resonance imaging dataset. The SING model can produce joint components that accurately reflect information shared by multiple datasets, particularly for datasets with non-Gaussian features such as neuroimaging.</p>
</div>
</a>
<a href="articles/RJ-2023-085/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 11, 2024</div>
<div class="dt-authors">
<div class="dt-author">Mengyang Gu</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>RobustCalibration: Robust Calibration of Computer Models in R</h2>
<div class="dt-tags"></div>
<p>Two fundamental research tasks in science and engineering are forward predictions and data inversion. This article introduces a new R package [RobustCalibration](https://CRAN.R-project.org/package=RobustCalibration) for Bayesian data inversion and model calibration using experiments and field observations. Mathematical models for forward predictions are often written in computer code, and they can be computationally expensive to run. To overcome the computational bottleneck from the simulator, we implemented a statistical emulator from the [RobustGaSP](https://CRAN.R-project.org/package=RobustGaSP) package for emulating both scalar-valued or vector-valued computer model outputs. Both posterior sampling and maximum likelihood approach are implemented in the [RobustCalibration](https://CRAN.R-project.org/package=RobustCalibration) package for parameter estimation. For imperfect computer models, we implement the Gaussian stochastic process and scaled Gaussian stochastic process for modeling the discrepancy function between the reality and mathematical model. This package is applicable to various other types of field observations and models, such as repeated experiments, multiple sources of measurements and correlated measurement bias. We discuss numerical examples of calibrating mathematical models that have closed-form expressions, and differential equations solved by numerical methods.</p>
</div>
</a>
<a href="articles/RJ-2023-086/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 11, 2024</div>
<div class="dt-authors">
<div class="dt-author">Hillary M. Heiling</div>
<div class="dt-author">Naim U. Rashid</div>
<div class="dt-author">Quefeng Li</div>
<div class="dt-author">Joseph G. Ibrahim</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>glmmPen: High Dimensional Penalized Generalized Linear Mixed Models</h2>
<div class="dt-tags"></div>
<p>Generalized linear mixed models (GLMMs) are widely used in research for their ability to model correlated outcomes with non-Gaussian conditional distributions. The proper selection of fixed and random effects is a critical part of the modeling process since model misspecification may lead to significant bias. However, the joint selection of fixed and random effects has historically been limited to lower-dimensional GLMMs, largely due to the use of criterion-based model selection strategies. Here we present the R package glmmPen, one of the first to select fixed and random effects in higher dimension using a penalized GLMM modeling framework. Model parameters are estimated using a Monte Carlo Expectation Conditional Minimization (MCECM) algorithm, which leverages Stan and RcppArmadillo for increased computational efficiency. Our package supports the Binomial, Gaussian, and Poisson families and multiple penalty functions. In this manuscript we discuss the modeling procedure, estimation scheme, and software implementation through application to a pancreatic cancer subtyping study. Simulation results show our method has good performance in selecting both the fixed and random effects in high dimensional GLMMs.</p>
</div>
</a>
<a href="articles/RJ-2023-087/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 11, 2024</div>
<div class="dt-authors">
<div class="dt-author">Susana Daz-Coto</div>
<div class="dt-author">Pablo Martnez-Camblor</div>
<div class="dt-author">Norberto Corral-Blanco</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Unified ROC Curve Estimator for Diagnosis and Prognosis Studies: The sMSROC Package</h2>
<div class="dt-tags"></div>
<p>The binary classification problem is a hot topic in Statistics. Its close relationship with the diagnosis and the prognosis of diseases makes it crucial in biomedical research. In this context, it is important to identify biomarkers that may help to classify individuals into different classes, for example, diseased vs. not diseased. The Receiver Operating-Characteristic (ROC) curve is a graphical tool commonly used to assess the accuracy of such classification. Given the diverse nature of diagnosis and prognosis problems, the ROC curve estimation has been tackled from separate perspectives in each setting. The Two-stages Mixed-Subjects (sMS) ROC curve estimator fits both scenarios. Besides, it can handle data with missing or incomplete outcome values. This paper introduces the [R](R){.uri} package sMSROC which implements the sMS ROC estimator, and includes tools that may support researchers in their decision making. Its practical application is illustrated on three real-world datasets.</p>
</div>
</a>
<a href="articles/RJ-2023-088/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 11, 2024</div>
<div class="dt-authors">
<div class="dt-author">yvind Langsrud</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-088/figures/young_old_EU_nonEU_Total.png"/>
</div>
<div class="description">
<h2>Sparse Model Matrices for Multidimensional Hierarchical Aggregation</h2>
<div class="dt-tags"></div>
<p>Multidimensional hierarchical sum aggregations can be formulated as matrix multiplications involving dummy matrices which can be referred to as model matrices. In contrast to standard model matrices, all categories of all variables must be included. For this purpose, the R package SSBtools includes functionality to create model matrices in two alternative ways, by model formulas or by so-called hierarchies. The latter means a coding of hierarchical relationships, and this can be done in several ways. Tree-shaped hierarchies are not required. The internal standard in the package is a parent-child coding. Functionality to find hierarchies automatically from the data is also included. The model matrix functionality is applied in several R packages for statistical disclosure control. This enables general implementation of methods and a flexible user interface. This paper describes the model matrix and hierarchy functions in SSBtools, as well as the methods and functions behind it.</p>
</div>
</a>
<a href="articles/RJ-2023-089/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 11, 2024</div>
<div class="dt-authors">
<div class="dt-author">Massimo Aria</div>
<div class="dt-author">Trang Le</div>
<div class="dt-author">Corrado Cuccurullo</div>
<div class="dt-author">Alessandra Belfiore</div>
<div class="dt-author">June Choe</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>openalexR: An R-Tool for Collecting Bibliometric Data from OpenAlex</h2>
<div class="dt-tags"></div>
<p>Bibliographic databases are indispensable sources of information on published literature. OpenAlex is an open-source collection of academic metadata that enable comprehensive bibliographic analyses [@priem2022openalex]. In this paper, we provide details on the implementation of openalexR, an R package to interface with the OpenAlex API. We present a general overview of its main functions and several detailed examples of its use. Following best API package practices, openalexR offers an intuitive interface for collecting information on different entities, including works, authors, institutions, sources, and concepts. openalexR exposes to the user different API parameters including filtering, searching, sorting, and grouping. This new open-source package is well-documented and available on CRAN.</p>
</div>
</a>
<a href="articles/RJ-2023-090/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 11, 2024</div>
<div class="dt-authors">
<div class="dt-author">Mikkel Meyer Andersen</div>
<div class="dt-author">Sren Hjsgaard</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-090/RJ-2023-090_files/figure-html5/calculus-1.png"/>
</div>
<div class="description">
<h2>Computer Algebra in R Bridges a Gap Between Symbolic Mathematics and Data in the Teaching of Statistics and Data Science</h2>
<div class="dt-tags"></div>
<p>The capability of R to do symbolic mathematics is enhanced by the  reticulate and caracas packages. The workhorse behind these packages is the Python computer algebra library SymPy.  Via reticulate, the SymPy library can be accessed from within R.  This, however, requires some knowledge of SymPy, Python and reticulate. The caracas package, on the other hand, provides access to SymPy (via reticulate) but by  using R syntax, and this is the main contribution of caracas. We show examples of how to use the  SymPy library from R via reticulate and caracas. Using caracas,  we demonstrate how mathematics and statistics can benefit from  bridging computer algebra and data via R.  The caracas package integrates well with Rmarkdown and Quarto,  and as such supports creation of teaching material and scientific reports. As inspiration for teachers, we include ideas for  small student projects.</p>
</div>
</a>
<a href="articles/RJ-2023-091/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 11, 2024</div>
<div class="dt-authors">
<div class="dt-author">John C. Nash</div>
<div class="dt-author">Arkajyoti Bhattacharjee</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-091/RJ-2023-091_files/figure-html5/ex01-1.png"/>
</div>
<div class="description">
<h2>A Comparison of R Tools for Nonlinear Least Squares Modeling</h2>
<div class="dt-tags"></div>
<p>Our Google Summer of Code project "Improvements to `nls()`" investigated rationalizing R tools for nonlinear regression and nonlinear estimation tools by considering usability, maintainability, and functionality, especially for a Gauss-Newton solver. &lt;!-- JN: copyedit essentially accepted --&gt; The rich features of `nls()` are weakened by several deficiencies and inconsistencies such as a lack of stabilization of the Gauss-Newton solver. Further considerations are the usability and  maintainability of the code base that provides the functionality `nls()` claims to offer. Various packages, including our `nlsr`, provide alternative capabilities. We consider the differences in goals, approaches, and features of different tools for nonlinear least squares modeling in R. Discussion of  these matters is relevant to improving R generally as well as its  nonlinear estimation tools.</p>
</div>
</a>
<a href="articles/RJ-2023-093/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 11, 2024</div>
<div class="dt-authors">
<div class="dt-author">Francisco F. Queiroz</div>
<div class="dt-author">Silvia L.P. Ferrari</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>PLreg: An R Package for Modeling Bounded Continuous Data</h2>
<div class="dt-tags"></div>
<p>The power logit class of distributions is useful for modeling continuous data on the unit interval, such as fractions and proportions. It is very flexible and the parameters represent the median, dispersion and skewness of the distribution. Based on the power logit class, Queiroz and Ferrari (2023b, *Statistical Modelling*) proposed the power logit regression models. The dependent variable is assumed to have a distribution in the power logit class, with its median and dispersion linked to regressors through linear predictors with unknown coefficients. We present the R package **PLreg** which implements a suite of functions for working with power logit class of distributions and the associated regression models. This paper describes and illustrates the methods and algorithms implemented in the package, including tools for parameter estimation, diagnosis of fitted models, and various helper functions for working with power logit distributions, including density, cumulative distribution, quantile, and random number generating functions. Additional examples are presented to show the ability of the **PLreg** package to fit generalized Johnson SB, log-log, and inflated power logit regression models.</p>
</div>
</a>
<a href="articles/RJ-2023-094/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 11, 2024</div>
<div class="dt-authors">
<div class="dt-author">Mirko Armillotta</div>
<div class="dt-author">Michail Tsagris</div>
<div class="dt-author">Konstantinos Fokianos</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Inference for Network Count Time Series with the R Package PNAR</h2>
<div class="dt-tags"></div>
<p>We introduce a new R package useful for inference about network count time series. Such data are frequently encountered in statistics and they are usually treated as multivariate time series. Their statistical analysis is based on linear or log-linear models. Nonlinear models, which have been applied successfully in several research areas, have been neglected from such applications mainly because of their computational complexity. We provide R users the flexibility to fit and study nonlinear network count time series models which include either a drift in the intercept or a regime switching mechanism. We develop several computational tools including estimation of various count Network Autoregressive models and fast computational algorithms for testing linearity in standard cases and when non-identifiable parameters hamper the analysis. Finally, we introduce a copula Poisson algorithm for simulating multivariate network count time series. We illustrate the methodology by modeling weekly number of influenza cases in Germany.</p>
</div>
</a>
<a href="articles/RJ-2023-065/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 3, 2024</div>
<div class="dt-authors">
<div class="dt-author">Angel Udas</div>
<div class="dt-author">Bruna Grizzetti</div>
<div class="dt-author">Olga Vigiak</div>
<div class="dt-author">Alberto Aloe</div>
<div class="dt-author">Cesar Alfaro</div>
<div class="dt-author">Javier Gomez</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-065/distill-preview.png"/>
</div>
<div class="description">
<h2>GREENeR: An R Package to Estimate and Visualize Nutrients Pressures on Surface Waters</h2>
<div class="dt-tags"></div>
<p>Nutrient pollution affects fresh and coastal waters around the globe. Planning mitigating actions requires tools to assess fluxes of nutrient emissions to waters and expected restoration impacts. Conceptual river basin models take advantage of data on nutrient emissions and concentrations at monitoring stations, providing a physical interpretation of monitored conditions, and enabling scenario analysis. The GREENeR package streamlines water quality model in a region of interest, considering nutrient pathways and the hydrological structure of the river network. The package merges data sources, analyzes local conditions, calibrate the model, and assesses yearly nutrient levels along the river network, determining contributions of load in freshwaters from diffuse and point sources. The package is enriched with functions to perform thorough parameter sensitivity analysis and for mapping nutrient sources and fluxes. The functionalities of the package are demonstrated using datasets from the Vistula river basin.</p>
</div>
</a>
<a href="articles/RJ-2023-060/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 18, 2023</div>
<div class="dt-authors">
<div class="dt-author">Lijin Zhang</div>
<div class="dt-author">Xueyang Li</div>
<div class="dt-author">Zhiyong Zhang</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Variety and Mainstays of the R Developer Community</h2>
<div class="dt-tags"></div>
<p>The thriving developer community has a significant impact on the widespread use of R software. To better understand this community, we conducted a study analyzing all R packages available on CRAN. We identified the most popular topics of R packages by text mining the package descriptions. Additionally, using network centrality measures, we discovered the important packages in the package dependency network and influential developers in the global R community. Our analysis showed that among the 20 topics identified in the topic model, *Data Import, Export, and Wrangling*, as well as *Data Visualization, Result Presentation, and Interactive Web Applications*, were particularly popular among influential packages and developers. These findings provide valuable insights into the R community.</p>
</div>
</a>
<a href="articles/RJ-2023-061/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 18, 2023</div>
<div class="dt-authors">
<div class="dt-author">Edgar Santos-Fernandez</div>
<div class="dt-author">Jay M. Ver Hoef</div>
<div class="dt-author">James McGree</div>
<div class="dt-author">Daniel J. Isaak</div>
<div class="dt-author">Kerrie Mengersen</div>
<div class="dt-author">Erin E. Peterson</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SSNbayes: An R Package for Bayesian Spatio-Temporal Modelling on Stream Networks</h2>
<div class="dt-tags"></div>
<p>Spatio-temporal models are widely used in many research areas from ecology to epidemiology. However, a limited number of computational tools are available for modeling river network datasets in space and time. In this paper, we introduce the `R` package [SSNbayes](https://CRAN.R-project.org/package=SSNbayes) for fitting Bayesian spatio-temporal models and making predictions on branching stream networks. [SSNbayes](https://CRAN.R-project.org/package=SSNbayes) provides a linear regression framework with multiple options for incorporating spatial and temporal autocorrelation. Spatial dependence is captured using stream distance and flow connectivity while temporal autocorrelation is modelled using vector autoregression approaches. [SSNbayes](https://CRAN.R-project.org/package=SSNbayes) provides the functionality to make predictions across the whole network, compute exceedance probabilities, and other probabilistic estimates, such as the proportion of suitable habitat. We illustrate the functionality of the package using a stream temperature dataset collected in the Clearwater River Basin, USA.</p>
</div>
</a>
<a href="articles/RJ-2023-062/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 18, 2023</div>
<div class="dt-authors">
<div class="dt-author">Aniek Sies</div>
<div class="dt-author">Iven Van Mechelen</div>
<div class="dt-author">Kristof Meers</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>C443: An R package to See a Forest for the Trees</h2>
<div class="dt-tags"></div>
<p>Classification trees, well-known for their ease of interpretation, are a widely used tool to solve statistical learning problems. However, researchers often end up with a forest rather than an individual classification tree, which implies a major cost due to the loss of the transparency of individual trees. Therefore, an important challenge is to enjoy the benefits of forests without paying this cost. In this paper, we propose the R package C443. The C443 methodology simplifies a forest into one or a few condensed summary trees, to gain insight into its central tendency and heterogeneity. This is done by clustering the trees in the forest based on similarities between them, and on post-processing the clustering output. We will elaborate upon the implementation of the methodology in the package, and will illustrate its use with three examples.</p>
</div>
</a>
<a href="articles/RJ-2023-063/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 18, 2023</div>
<div class="dt-authors">
<div class="dt-author">Marta Cousido-Rocha</div>
<div class="dt-author">Jacobo de Ua-lvarez</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>TwoSampleTest.HD: An R Package for the Two-Sample Problem with High-Dimensional Data</h2>
<div class="dt-tags"></div>
<p>The two-sample problem refers to the comparison of two probability distributions via two independent samples. With high-dimensional data, such comparison is performed along a large number $p$ of possibly correlated variables or outcomes. In genomics, for instance, the variables may represent gene expression levels for $p$ locations, recorded for two (usually small) groups of individuals. In this paper we introduce [TwoSampleTest.HD](https://CRAN.R-project.org/package=TwoSampleTest.HD), a new `R` package to test for the equal distribution of the $p$ outcomes. Specifically, TwoSampleTest.HD implements the tests recently proposed by [@Marta2] for the low sample size, large dimensional setting. These tests take the possible dependence among the $p$ variables into account, and work for sample sizes as small as two. The tests are based on the distance between the empirical characteristic functions of the two samples, when averaged along the $p$ locations. Different options to estimate the variance of the test statistic under dependence are allowed. The package TwoSampleTest.HD provides the user with individual permutation $p$-values too, so feature discovery is possible when the null hypothesis of equal distribution is rejected. We illustrate the usage of the package through the analysis of simulated and real data, where results provided by alternative approaches are considered for comparison purposes. In particular, benefits of the implemented tests relative to ordinary multiple comparison procedures are highlighted. Practical recommendations are given.</p>
</div>
</a>
<a href="articles/RJ-2023-064/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 18, 2023</div>
<div class="dt-authors">
<div class="dt-author">Jeffrey M. Pullin</div>
<div class="dt-author">Lyle C. Gurrin</div>
<div class="dt-author">Damjan Vukcevic</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-064/tikz/figrelationships.png"/>
</div>
<div class="description">
<h2>Statistical Models for Repeated Categorical Ratings: The R Package rater</h2>
<div class="dt-tags"></div>
<p>A common problem in many disciplines is the need to assign a set of items into categories or classes with known labels.  This is often done by one or more expert raters, or sometimes by an automated process.  If these assignments or 'ratings' are difficult to make accurately, a common tactic is to repeat them by different raters, or even by the same rater multiple times on different occasions. We present an R package rater, available on CRAN, that implements Bayesian versions of several statistical models for analysis of repeated categorical rating data. Inference is possible for the true underlying (latent) class of each item, as well as the accuracy of each rater. The models are extensions of, and include, the Dawid--Skene model, and we implemented them using the Stan probabilistic programming language.  We illustrate the use of rater through a few examples.  We also discuss in detail the techniques of marginalisation and conditioning, which are necessary for these models but also apply more generally to other models implemented in Stan.</p>
</div>
</a>
<a href="articles/RJ-2023-066/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 18, 2023</div>
<div class="dt-authors">
<div class="dt-author">Jane Pan</div>
<div class="dt-author">Sudipto Banerjee</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>bayesassurance: An R Package for Calculating Sample Size and Bayesian Assurance</h2>
<div class="dt-tags"></div>
<p>In this paper, we present bayesassurance, an [R]{.sans-serif} package designed for computing Bayesian assurance criteria which can be used to determine sample size in Bayesian inference setting. The functions included in the [R]{.sans-serif} package offer a two-stage framework using design priors to specify the population from which the data will be collected and analysis priors to fit a Bayesian model. We also demonstrate that frequentist sample size calculations are exactly reproduced as special cases of evaluating Bayesian assurance functions using appropriately specified priors.</p>
</div>
</a>
<a href="articles/RJ-2023-067/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 18, 2023</div>
<div class="dt-authors">
<div class="dt-author">Connor Puritz</div>
<div class="dt-author">Elan Ness-Cohn</div>
<div class="dt-author">Rosemary Braun</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>fasano.franceschini.test: An Implementation of a Multivariate KS Test in R</h2>
<div class="dt-tags"></div>
<p>The Kolmogorov--Smirnov (KS) test is a nonparametric statistical test used to test for differences between univariate probability distributions. The versatility of the KS test has made it a cornerstone of statistical analysis across many scientific disciplines. However, the test proposed by Kolmogorov and Smirnov does not easily extend to multivariate distributions. Here we present the [fasano.franceschini.test](https://CRAN.R-project.org/package=fasano.franceschini.test) package, an R implementation of a multivariate two-sample KS test described by @ff1987. The fasano.franceschini.test package provides a test that is computationally efficient, applicable to data of any dimension and type (continuous, discrete, or mixed), and that performs competitively with similar R packages.</p>
</div>
</a>
<a href="articles/RJ-2023-068/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 18, 2023</div>
<div class="dt-authors">
<div class="dt-author">Francisco Palm-Perales</div>
<div class="dt-author">Virgilio Gmez-Rubio</div>
<div class="dt-author">Roger S. Bivand</div>
<div class="dt-author">Michela Cameletti</div>
<div class="dt-author">Hvard Rue</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Bayesian Inference for Multivariate Spatial Models with INLA</h2>
<div class="dt-tags"></div>
<p>Bayesian methods and software for spatial data analysis are well-established now in the broader scientific community generally and in the spatial data analysis community specifically. Despite the wide application of spatial models, the analysis of multivariate spatial data using the integrated nested Laplace approximation through its R package (R-INLA) has not been widely described in the existing literature. Therefore, the main objective of this article is to demonstrate that R-INLA is a convenient toolbox to analyse different types of multivariate spatial datasets. This will be illustrated by analysing three datasets which are publicly available. Furthermore, the details and the R code of these analyses are provided to exemplify how to fit models to multivariate spatial datasets with R-INLA.</p>
</div>
</a>
<a href="articles/RJ-2023-069/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 18, 2023</div>
<div class="dt-authors">
<div class="dt-author">Giulio Barcaroli</div>
<div class="dt-author">Andrea Fasulo</div>
<div class="dt-author">Alessio Guandalini</div>
<div class="dt-author">Marco D. Terribili</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Two-Stage Sampling Design and Sample Selection with the R Package R2BEAT</h2>
<div class="dt-tags"></div>
<p>R2BEAT ("R 'to' Bethel Extended Allocation for Two-stage sampling")
is an R package for the optimal allocation of a sample. Its
peculiarity lies in properly addressing allocation problems for
two-stage and complex sampling designs with multi-domain and
multi-purpose aims. This is common in many official and non-official
statistical surveys, therefore R2BEAT could become an essential tool
for planning a sample survey. The functions implemented in R2BEAT
allow the use of different workflows, depending on the available
information on one or more interest variables. The package covers all
the phases, from the optimization of the sample to the selection of
the Primary and Secondary Stage Units. Furthermore, it provides
several outputs for evaluating the allocation results.</p>
</div>
</a>
<a href="articles/RJ-2023-070/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 18, 2023</div>
<div class="dt-authors">
<div class="dt-author">Dom Owens</div>
<div class="dt-author">Haeran Cho</div>
<div class="dt-author">Matteo Barigozzi</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>fnets: An R Package for Network Estimation and Forecasting via Factor-Adjusted VAR Modelling</h2>
<div class="dt-tags"></div>
<p>Vector autoregressive (VAR) models are useful for modelling high-dimensional time series data. This paper introduces the package [fnets](https://CRAN.R-project.org/package=fnets), which implements the suite of methodologies proposed by [@barigozzi2022fnets] for the network estimation and forecasting of high-dimensional time series under a factor-adjusted vector autoregressive model, which permits strong spatial and temporal correlations in the data. Additionally, we provide tools for visualising the networks underlying the time series data after adjusting for the presence of factors. The package also offers data-driven methods for selecting tuning parameters including the number of factors, the order of autoregression, and thresholds for estimating the edge sets of the networks of interest in time series analysis. We demonstrate various features of fnets on simulated datasets as well as real data on electricity prices.</p>
</div>
</a>
<a href="articles/RJ-2023-071/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 18, 2023</div>
<div class="dt-authors">
<div class="dt-author">Achim Zeileis</div>
<div class="dt-author">Paul Murrell</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-071/RJ-2023-071_files/figure-html5/colorcatcont-1.png"/>
</div>
<div class="description">
<h2>Coloring in R's Blind Spot</h2>
<div class="dt-tags"></div>
<p>Prior to version 4.0.0 R had a poor default color palette (using highly saturated red, green, blue, etc.) and provided very few alternative palettes, most of which also had poor perceptual properties (like the infamous rainbow palette). Starting with version 4.0.0 R gained a new and much improved default palette and, in addition, a selection of more than 100 well-established palettes are now available via the functions `palette.colors()` and `hcl.colors()`. The former provides a range of popular qualitative palettes for categorical data while the latter closely approximates many popular sequential and diverging palettes by systematically varying the perceptual hue, chroma, and luminance (HCL) properties in the palette.  This paper provides a mix of contributions including an overview of the new color functions and the palettes they provide along with advice about which palettes are appropriate for specific tasks, especially with regard to making them accessible to viewers with color vision deficiencies.</p>
</div>
</a>
<a href="articles/RJ-2023-072/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 18, 2023</div>
<div class="dt-authors">
<div class="dt-author">Paul Murrell</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-072/RJ-2023-072_files/figure-html5/diagram-1.png"/>
</div>
<div class="description">
<h2>Updates to the R Graphics Engine:  One Person's Chart Junk is Another's Chart Treasure</h2>
<div class="dt-tags"></div>
<p>Starting from R version 4.1.0, the R graphics engine has gained support for gradient fills, pattern fills, clipping paths, masks, compositing operators, and stroked and filled paths. This document provides a basic introduction to each of these new features and demonstrates how to use the new features in R.</p>
</div>
</a>
<a href="articles/RJ-2023-073/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 18, 2023</div>
<div class="dt-authors">
<div class="dt-author">Matthias Gondan</div>
<div class="dt-author">Irene Alfarone</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>mathml: Translate R Expressions to MathML and LaTeX</h2>
<div class="dt-tags"></div>
<p>This Rpackage translates Robjects to suitable elements in MathML or LaTeX, thereby allowing for a pretty mathematical representation of Robjects and functions in data analyses, scientific reports and interactive web content. In the RMarkdown document rendering language, Rcode and mathematical content already exist side-by-side. The present package enables use of the same Robjects for both data analysis and typesetting in documents or web content. This tightens the link between the statistical analysis and its verbal description or symbolic representation, which is another step towards reproducible science. User-defined hooks enable extension of the package by mapping specific variables or functions to new MathML and LaTeX entities. Throughout the paper, examples are given for the functions of the package, and a case study illustrates its use in a scientific report.</p>
</div>
</a>
<a href="articles/RJ-2023-049/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 9, 2023</div>
<div class="dt-authors">
<div class="dt-author">Rosaria Lombardo</div>
<div class="dt-author">Michel van de Velden</div>
<div class="dt-author">Eric J. Beh</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Three-Way Correspondence Analysis in R</h2>
<div class="dt-tags"></div>
<p>Three-way correspondence analysis is a suitable multivariate method for visualising the association in three-way categorical data, modelling the global dependence, or reducing dimensionality. This paper provides a description of an R package for performing three-way correspondence analysis: CA3variants. The functions in this package allow the analyst to perform several variations of this analysis, depending on the research question being posed and/or the properties underlying the data. Users can opt for the classical (symmetrical) approach or the non-symmetric variant - the latter is particularly useful if one of the three categorical variables is treated as a response variable. In addition, to perform the necessary three-way decompositions, a Tucker3 and a trivariate moment decomposition (using orthogonal polynomials) can be utilized. The Tucker3 method of decomposition can be used when one or more of the categorical variables is nominal while for ordinal variables the trivariate moment decomposition can be used. The package also provides a function that can be used to choose the model dimensionality.</p>
</div>
</a>
<a href="articles/RJ-2023-040/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 8, 2023</div>
<div class="dt-authors">
<div class="dt-author">J. A. F. Torvisco</div>
<div class="dt-author">R. Bentez</div>
<div class="dt-author">M. R. Arias</div>
<div class="dt-author">J. CabelloSnchez</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>nlstac: Non-Gradient Separable Nonlinear Least Squares Fitting</h2>
<div class="dt-tags"></div>
<p>A new package for nonlinear least squares fitting is introduced in this paper. This package implements a recently developed algorithm that, for certain types of nonlinear curve fitting, reduces the number of nonlinear parameters to be fitted. One notable feature of this method is the absence of initialization which is typically necessary for nonlinear fitting gradient-based algorithms. Instead, just some bounds for the nonlinear parameters are required. Even though convergence for this method is guaranteed for exponential decay using the max-norm, the algorithm exhibits remarkable robustness, and its use has been extended to a wide range of functions using the Euclidean norm. Furthermore, this data-fitting package can also serve as a valuable resource for providing accurate initial parameters to other algorithms that rely on them.</p>
</div>
</a>
<a href="articles/RJ-2023-050/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 8, 2023</div>
<div class="dt-authors">
<div class="dt-author">Mauricio Sarrias</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-050/distill-preview.png"/>
</div>
<div class="description">
<h2>Estimating Heteroskedastic and Instrumental Variable Models for Binary Outcome Variables in R</h2>
<div class="dt-tags"></div>
<p>The objective of this article is to introduce the package Rchoice which provides functionality for estimating heteroskedastic and instrumental variable models for binary outcomes, whith emphasis on the calculation of the average marginal effects. To do so, I introduce two new functions of the Rchoice package using widely known applied examples. I also show how users can generate publication-ready tables of regression model estimates.</p>
</div>
</a>
<a href="articles/RJ-2023-055/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 8, 2023</div>
<div class="dt-authors">
<div class="dt-author">Garyfallos Konstantinoudis</div>
<div class="dt-author">Virgilio Gmez-Rubio</div>
<div class="dt-author">Michela Cameletti</div>
<div class="dt-author">Monica Pirani</div>
<div class="dt-author">Gianluca Baio</div>
<div class="dt-author">Marta Blangiardo</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>A Workflow for Estimating and Visualising Excess Mortality During the COVID-19 Pandemic</h2>
<div class="dt-tags"></div>
<p>COVID-19 related deaths estimates underestimate the pandemic burden on mortality because they suffer from completeness and accuracy issues. Excess mortality is a popular alternative, as it compares the observed number of deaths versus the number that would be expected if the pandemic did not occur. The expected number of deaths depends on population trends, temperature, and spatio-temporal patterns. In addition to this, high geographical resolution is required to examine within country trends and the effectiveness of the different public health policies. In this tutorial, we propose a workflow using R for estimating and visualising excess mortality at high geographical resolution. We show a case study estimating excess deaths during 2020 in Italy. The proposed workflow is fast to implement and allows for combining different models and presenting aggregated results based on factors such as age, sex, and spatial location. This makes it a particularly powerful and appealing workflow for online monitoring of the pandemic burden and timely policy making.</p>
</div>
</a>
<a href="articles/RJ-2023-041/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2023</div>
<div class="dt-authors">
<div class="dt-author">Ezequiel Toum</div>
<div class="dt-author">Pierre Pitte</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-041/distill-preview.png"/>
</div>
<div class="description">
<h2>hydrotoolbox, a Package for Hydrometeorological Data Management</h2>
<div class="dt-tags"></div>
<p>The hydrometeorological data provided by federal agencies, research groups and private companies tend to be heterogeneous: records are kept in different formats, quality control processes are not standardized and may even vary within a given agency, variables are not always recorded with the same temporal resolution, and there are data gaps and incorrectly recorded values. Once these problems are dealt with, it is useful to have tools to safely store and manipulate the series, providing temporal aggregation, interactive visualization for analysis, static graphics to publish and/or communicate results, techniques to correct and/or modify the series, among others. Here we introduce a package written in the R language using object-oriented programming and designed to accomplish these objectives, giving to the user a general framework for working with any kind of hydrometeorological series. We present the package design, its strengths, limitations and show its application for two real cases.</p>
</div>
</a>
<a href="articles/RJ-2023-042/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2023</div>
<div class="dt-authors">
<div class="dt-author">Prajual Maheshwari</div>
<div class="dt-author">Mohammad Arshad Rahman</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-042/EducFreqDist.png"/>
</div>
<div class="description">
<h2>bqror: An R package for Bayesian Quantile Regression in Ordinal Models</h2>
<div class="dt-tags"></div>
<p>This article describes an R package [bqror](https://CRAN.R-project.org/package=bqror) that estimates Bayesian quantile regression in ordinal models introduced in Rahman (2016). The paper classifies ordinal models into two types and offers computationally efficient yet simple Markov chain Monte Carlo (MCMC) algorithms for estimating ordinal quantile regression. The generic ordinal model with 3 or more outcomes (labeled $OR_{I}$ model) is estimated by a combination of Gibbs sampling and Metropolis-Hastings algorithm, whereas an ordinal model with exactly 3 outcomes (labeled $OR_{II}$ model) is estimated using a Gibbs sampling algorithm only. In line with the Bayesian literature, we suggest using the marginal likelihood for comparing alternative quantile regression models and explain how to compute it. The models and their estimation procedures are illustrated via multiple simulation studies and implemented in two applications. The article also describes several functions contained within the [bqror](https://CRAN.R-project.org/package=bqror) package, and illustrates their usage for estimation, inference, and assessing model fit.</p>
</div>
</a>
<a href="articles/RJ-2023-043/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2023</div>
<div class="dt-authors">
<div class="dt-author">Bastien Chassagnol</div>
<div class="dt-author">Antoine Bichat</div>
<div class="dt-author">Chema Boudjeniba</div>
<div class="dt-author">Pierre-Henri Wuillemin</div>
<div class="dt-author">Mickal Guedj</div>
<div class="dt-author">David Gohel</div>
<div class="dt-author">Gregory Nuel</div>
<div class="dt-author">Etienne Becht</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-043/figures/flowchart_packages_selection.png"/>
</div>
<div class="description">
<h2>Gaussian Mixture Models in R</h2>
<div class="dt-tags"></div>
<p>Gaussian mixture models (GMMs) are widely used for modelling stochastic problems. Indeed, a wide diversity of packages have been developed in R. However, no recent review describing the main features offered by these packages and comparing their performances has been performed. In this article, we first introduce GMMs and the EM algorithm used to retrieve the parameters of the model and analyse the main features implemented among seven of the most widely used R packages. We then empirically compare their statistical and computational performances in relation with the choice of the initialisation algorithm and the complexity of the mixture. We demonstrate that the best estimation with well-separated components or with a small number of components with distinguishable modes is obtained with REBMIX initialisation, implemented in the [rebmix](https://CRAN.R-project.org/package=rebmix) package, while the best estimation with highly overlapping components is obtained with *k*-means or random initialisation. Importantly, we show that implementation details in the EM algorithm yield differences in the parameters' estimation. Especially, packages [mixtools](https://CRAN.R-project.org/package=mixtools) (Young et al. 2020) and [Rmixmod](https://CRAN.R-project.org/package=Rmixmod) (Langrognet et al. 2021) estimate the parameters of the mixture with smaller bias, while the RMSE and variability of the estimates is smaller with packages [bgmm](https://CRAN.R-project.org/package=bgmm) (Ewa Szczurek 2021) , [EMCluster](https://CRAN.R-project.org/package=EMCluster) (W.-C. Chen and Maitra 2022) , [GMKMcharlie](https://CRAN.R-project.org/package=GMKMcharlie) (Liu 2021), [flexmix](https://CRAN.R-project.org/package=flexmix) (Gruen and Leisch 2022) and [mclust](https://CRAN.R-project.org/package=mclust) (Fraley, Raftery, and Scrucca 2022). The comparison of these packages provides R users with useful recommendations for improving the computational and statistical performance of their clustering and for identifying common deficiencies. Additionally, we propose several improvements in the development of a future, unified mixture model package.</p>
</div>
</a>
<a href="articles/RJ-2023-044/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2023</div>
<div class="dt-authors">
<div class="dt-author">Montasser Ghachem</div>
<div class="dt-author">Oguz Ersan</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>PINstimation: An R Package for Estimating Probability of Informed Trading Models</h2>
<div class="dt-tags"></div>
<p>The purpose of this paper is to introduce the R package [PINstimation](https://CRAN.R-project.org/package=PINstimation). The package is designed for fast and accurate estimation of the probability of informed trading models through the implementation of well-established estimation methods. The models covered are the original PIN model [@easley1992time; @easley1996liquidity], the multilayer PIN model [@ersan2016multilayer], the adjusted PIN model [@duarte2009why], and the volume- synchronized PIN [@Easley2011microstructure; @Easley2012Flow]. These core functionalities of the package are supplemented with utilities for data simulation, aggregation and classification tools. In addition to a detailed overview of the package functions, we provide a brief theoretical review of the main methods implemented in the package. Further, we provide examples of use of the package on trade-level data for 58 Swedish stocks, and report straightforward, comparative and intriguing findings on informed trading. These examples aim to highlight the capabilities of the package in tackling relevant research questions and illustrate the wide usage possibilities of PINstimation for both academics and practitioners.</p>
</div>
</a>
<a href="articles/RJ-2023-045/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2023</div>
<div class="dt-authors">
<div class="dt-author">Sagiru Mati</div>
<div class="dt-author">Irfan Civcir</div>
<div class="dt-author">S. I. Abba</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-045/RJ-2023-045_files/figure-html5/fig-flowchart-1.png"/>
</div>
<div class="description">
<h2>EviewsR: An R Package for Dynamic and Reproducible Research Using EViews, R, R Markdown and Quarto</h2>
<div class="dt-tags"></div>
<p>EViews is a software designed for conducting econometric data analysis. There exists a one-way communication between EViews and R, as the former can run the code of the latter, but the reverse is not the case. We describe [EviewsR](https://CRAN.R-project.org/package=EviewsR), an R package which allows users of R, R Markdown and Quarto to execute EViews code. In essence, [EviewsR](https://CRAN.R-project.org/package=EviewsR) does not only provide functions for base R, but also adds EViews to the existing [knitr](https://CRAN.R-project.org/package=knitr)'s knit-engines. We also show how EViews equation, graph, series, and table objects can be imported and customised dynamically and reproducibly in R, R Markdown and Quarto document. Therefore, [EviewsR](https://CRAN.R-project.org/package=EviewsR) seeks to improve the accuracy, transparency and reproducibility of research conducted with EViews and R.</p>
</div>
</a>
<a href="articles/RJ-2023-046/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2023</div>
<div class="dt-authors">
<div class="dt-author">Paul Harrison</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-046/distill-preview.png"/>
</div>
<div class="description">
<h2>langevitour: Smooth Interactive Touring of High Dimensions, Demonstrated with scRNA-Seq Data</h2>
<div class="dt-tags"></div>
<p>langevitour displays interactive animated 2D projections of high-dimensional datasets.
Langevin Dynamics is used to produce a smooth path of projections. Projections are initially explored at random. A "guide" can be activated to look for an informative projection, or variables can be manually positioned. After a projection of particular interest has been found, continuing small motions provide a channel of visual information not present in a static scatter plot.
langevitour is implemented in Javascript, allowing for a high frame rate and responsive interaction, and can be used directly from the R environment or embedded in HTML documents produced using R.
Single cell RNA-sequencing (scRNA-Seq) data is used to demonstrate the widget. langevitour's linear projections provide a less distorted view of this data than commonly used non-linear dimensionality reductions such as UMAP.</p>
</div>
</a>
<a href="articles/RJ-2023-047/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2023</div>
<div class="dt-authors">
<div class="dt-author">Rafael Fuentealba-Chaura</div>
<div class="dt-author">Daniel Guinea-Martin</div>
<div class="dt-author">Ricardo Mora</div>
<div class="dt-author">Julio Rojas-Mora</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>mutualinf: An R Package for Computing and Decomposing the Mutual Information Index of Segregation</h2>
<div class="dt-tags"></div>
<p>In this article, we present the R package [mutualinf](https://CRAN.R-project.org/package=mutualinf) for computing and decomposing the mutual information index of segregation by means of recursion and parallelization techniques. The mutual information index is the only multigroup index of segregation that satisfies strong decomposability properties, both for organizational units and groups. The [mutualinf](https://CRAN.R-project.org/package=mutualinf) package contributes by (1) implementing the decomposition of the mutual information index into a "between" and a "within" term; (2) computing, in a single call, a chain of decompositions that involve one "between" term and several "within" terms; (3) providing the contributions of the variables that define the groups or the organizational units to the overall segregation; and (4) providing the demographic weights and local indexes employed in the computation of the "within" term. We illustrate the use of [mutualinf](https://CRAN.R-project.org/package=mutualinf) using Chilean school enrollment data. With these data, we study socioeconomic and ethnic segregation in schools.</p>
</div>
</a>
<a href="articles/RJ-2023-048/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2023</div>
<div class="dt-authors">
<div class="dt-author">James Otto</div>
<div class="dt-author">David Kahle</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ggdensity: Improved Bivariate Density Visualization in R</h2>
<div class="dt-tags"></div>
<p>The [ggdensity](https://CRAN.R-project.org/package=ggdensity) R package extends the functionality of [ggplot2](https://CRAN.R-project.org/package=ggplot2) by providing more interpretable visualizations of bivariate density estimates using highest density regions (HDRs). The visualizations are created via drop-in replacements for the standard [ggplot2](https://CRAN.R-project.org/package=ggplot2) functions used for this purpose: geom_hdr() for geom_density_2d_filled() and geom_hdr_lines() for geom_density_2d(). These new geoms improve on those of [ggplot2](https://CRAN.R-project.org/package=ggplot2) by communicating the probabilities associated with the displayed regions. Various statistically rigorous estimators are available, as well as convenience functions geom_hdr_fun() and geom_hdr_fun_lines() for plotting HDRs of user-specified probability density functions. Associated geoms for rug plots and pointdensity scatterplots are also presented.</p>
</div>
</a>
<a href="articles/RJ-2023-051/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2023</div>
<div class="dt-authors">
<div class="dt-author">Giuseppe Lamberti,</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>genpathmox: An R Package to Tackle Numerous Categorical Variables and Heterogeneity in Partial Least Squares Structural Equation Modeling</h2>
<div class="dt-tags"></div>
<p>Partial least squares structural equation modeling (PLS-SEM), combined with the analysis of the effects of categorical variables after estimating the model, is a well-established statistical approach to the study of complex relationships between variables. However, the statistical methods and software packages available are limited when we are interested in assessing the effects of several categorical variables and shaping different groups following different models. Following the framework established by @Lamberti16, we have developed the [genpathmox](https://CRAN.R-project.org/package=genpathmox) *R* packageforhandling a large number of categorical variables when faced with heterogeneity in PLS-SEM. The package has functions for various aspects of the analysis of heterogeneity inPLS-SEM models,including estimation, visualization, and hypothesis testing. In this paper, we describe the implementation ofgenpathmoxin detail and demonstrate its usefulness by analyzing employee satisfaction data.</p>
</div>
</a>
<a href="articles/RJ-2023-052/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2023</div>
<div class="dt-authors">
<div class="dt-author">Casper Hart</div>
<div class="dt-author">Earo Wang</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-052/distill-preview.png"/>
</div>
<div class="description">
<h2>Taking the Scenic Route: Interactive and Performant Tour Animations</h2>
<div class="dt-tags"></div>
<p>The tour provides a useful vehicle for exploring high dimensional datasets. It works by combining a sequence of projections---the tour path---in to an animation---the display method. Current display implementations in R are limited in their interactivity and portability, and give poor performance and jerky animations even for small datasets.
We take a detour into web technologies, such as Three.js and WebGL, to support smooth and performant tour visualisations. The R package detourr implements a set of display tools that allow for rich interactions (including orbit controls, scrubbing, and brushing) and smooth animations for large datasets. It provides a declarative R interface which is accessible to new users, and it supports linked views using crosstalk and shiny. The resulting animations are portable across a wide range of browsers and devices. We also extend the radial transformation of the Sage Tour (@laa2021burning) to 3 or more dimensions with an implementation in 3D, and provide a simplified implementation of the Slice Tour (@laa2020slice).</p>
</div>
</a>
<a href="articles/RJ-2023-053/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2023</div>
<div class="dt-authors">
<div class="dt-author">Santtu Tikka</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Identifying Counterfactual Queries with the R Package cfid</h2>
<div class="dt-tags"></div>
<p>In the framework of structural causal models, counterfactual queries describe events that concern multiple alternative states of the system under study. Counterfactual queries often take the form of "what if" type questions such as "would an applicant have been hired if they had over 10 years of experience, when in reality they only had 5 years of experience?" Such questions and counterfactual inference in general are crucial, for example when addressing the problem of fairness in decision-making. Because counterfactual events contain contradictory states of the world, it is impossible to conduct a randomized experiment to address them without making several restrictive assumptions. However, it is sometimes possible to identify such queries from observational and experimental data by representing the system under study as a causal model, and the available data as symbolic probability distributions. @shpitser2007 constructed two algorithms, called ID\* and IDC\*, for identifying counterfactual queries and conditional counterfactual queries, respectively. These two algorithms are analogous to the ID and IDC algorithms by @shpitser2006id [@shpitser2006idc] for identification of interventional distributions, which were implemented in R by @tikka2017 in the causaleffect package. We present the R package [cfid](https://CRAN.R-project.org/package=cfid) that implements the ID\* and IDC\* algorithms. Identification of counterfactual queries and the features of cfid are demonstrated via examples.</p>
</div>
</a>
<a href="articles/RJ-2023-054/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2023</div>
<div class="dt-authors">
<div class="dt-author">Alan Inglis</div>
<div class="dt-author">Andrew Parnell</div>
<div class="dt-author">Catherine Hurley</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-054/distill-preview.png"/>
</div>
<div class="description">
<h2>vivid: An R package for Variable Importance and Variable Interactions Displays for Machine Learning Models</h2>
<div class="dt-tags"></div>
<p>We present vivid, an R package for visualizing variable importance and variable interactions in machine learning models. The package provides  heatmap and graph-based displays for viewing variable importance and interaction jointly, and partial dependence plots in both a matrix layout and an alternative layout emphasizing important variable subsets. With the intention of increasing machine learning models' interpretability and making the work applicable to a wider readership, we discuss the design choices behind our implementation by focusing on the package structure and providing an in-depth look at the package functions and key features. We also provide a practical illustration of the software in use on a data set.</p>
</div>
</a>
<a href="articles/RJ-2023-056/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2023</div>
<div class="dt-authors">
<div class="dt-author">L.H. Vanegas</div>
<div class="dt-author">L.M. Rondn</div>
<div class="dt-author">G.A. Paula</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Generalized Estimating Equations using the new R package glmtoolbox</h2>
<div class="dt-tags"></div>
<p>This paper introduces a very comprehensive implementation, available in the new `R` package `glmtoolbox`, of a very flexible statistical tool known as Generalized Estimating Equations (GEE), which analyzes cluster correlated data utilizing marginal models. As well as providing more built-in structures for the working correlation matrix than other GEE implementations in `R`, this GEE implementation also allows the user to: $(1)$ compute several estimates of the variance-covariance matrix of the estimators of the parameters of interest; $(2)$ compute several criteria to assist the selection of the structure for the working-correlation matrix; $(3)$ compare nested models using the Wald test as well as the generalized score test; $(4)$ assess the goodness-of-fit of the model using Pearson-, deviance- and Mahalanobis-type residuals; $(5)$ perform sensibility analysis using the global influence approach (that is, dfbeta statistic and Cook's distance) as well as the local influence approach; $(6)$ use several criteria to perform variable selection using a hybrid stepwise procedure; $(7)$ fit models with nonlinear predictors; $(8)$ handle dropout-type missing data under MAR rather than MCAR assumption by using observation-specific or cluster-specific weighted methods. The capabilities of this GEE implementation are illustrated by analyzing four real datasets obtained from longitudinal studies.</p>
</div>
</a>
<a href="articles/RJ-2023-057/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2023</div>
<div class="dt-authors">
<div class="dt-author">Mart Renedo-Mirambell</div>
<div class="dt-author">Argimiro Arratia</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>clustAnalytics: An R Package for Assessing Stability and Significance of Communities in Networks</h2>
<div class="dt-tags"></div>
<p>This paper introduces the R package [clustAnalytics](https://CRAN.R-project.org/package=clustAnalytics), which comprises a set of criteria for assessing the significance and stability of communities in networks found by any clustering algorithm. [clustAnalytics](https://CRAN.R-project.org/package=clustAnalytics) works with graphs of class [igraph](https://CRAN.R-project.org/package=igraph) from the R-package [igraph](https://CRAN.R-project.org/package=igraph), extended to handle weighted and/or directed graphs. [clustAnalytics](https://CRAN.R-project.org/package=clustAnalytics) provides a set of community scoring functions, and methods to systematically compare their values to those of a suitable null model, which are of use when testing for cluster significance. It also provides a non parametric bootstrap method combined with similarity metrics derived from information theory and combinatorics, useful when testing for cluster stability, as well as a method to synthetically generate a weighted network with a ground truth community structure based on the preferential attachment model construction, producing networks with communities and scale-free degree distribution.</p>
</div>
</a>
<a href="articles/RJ-2023-032/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 24, 2023</div>
<div class="dt-authors">
<div class="dt-author">Gustavo Soutinho</div>
<div class="dt-author">Lus Meira-Machado</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>markovMSM: An R Package for Checking the Markov Condition in Multi-State Survival Data</h2>
<div class="dt-tags"></div>
<p>Multi-state models can be used to describe processes in which an individual moves through a finite number of states in continuous time. These models allow a detailed view of the evolution or recovery of the process and can be used to study the effect of a vector of explanatory variables on the transition intensities or to obtain prediction probabilities of future events after a given event history. In both cases, before using these models, we have to evaluate whether the Markov assumption is tenable. This paper introduces the [markovMSM](https://CRAN.R-project.org/package=markovMSM) package, a software application for R, which considers tests of the Markov assumption that are applicable to general multi-state models. Three approaches using existing methodology are considered: a simple method based on including covariates depending on the history; methods based on measuring the discrepancy of the non-Markov estimators of the transition probabilities to the Markovian Aalen-Johansen estimators; and, finally, methods that were developed by considering summaries from families of log-rank statistics where individuals are grouped by the state occupied by the process at a particular time point. The main functionalities of the [markovMSM](https://CRAN.R-project.org/package=markovMSM) package are illustrated using real data examples.</p>
</div>
</a>
<a href="articles/RJ-2023-039/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 24, 2023</div>
<div class="dt-authors">
<div class="dt-author">Sylvia Harmening</div>
<div class="dt-author">Ann-Kristin Kreutzmann</div>
<div class="dt-author">Sren Schmidt</div>
<div class="dt-author">Nicola Salvati</div>
<div class="dt-author">Timo Schmid</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>A Framework for Producing Small Area Estimates Based on Area-Level Models in R</h2>
<div class="dt-tags"></div>
<p>The R package [emdi](https://CRAN.R-project.org/package=emdi) facilitates the estimation of regionally disaggregated indicators using small area estimation methods and provides tools for model building, diagnostics, presenting, and exporting the results. The package version 1.1.7 includes unit-level small area models that rely on access to micro data. The area-level model by @Fay1979 and various extensions have been added to the package since the release of version 2.0.0. These extensions include (a) area-level models with back-transformations, (b) spatial and robust extensions, (c) adjusted variance estimation methods, and (d) area-level models that account for measurement errors. Corresponding mean squared error estimators are implemented for assessing the uncertainty. User-friendly tools like a stepwise variable selection, model diagnostics, benchmarking options, high quality maps and results exportation options enable a complete analysis procedure. The functionality of the package is illustrated by examples based on synthetic data for Austrian districts.</p>
</div>
</a>
<a href="articles/RJ-2023-031/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 7, 2023</div>
<div class="dt-authors">
<div class="dt-author">Peder Bacher</div>
<div class="dt-author">Hjrleifur G. Bergsteinsson</div>
<div class="dt-author">Linde Frlke</div>
<div class="dt-author">Mikkel L. Srensen</div>
<div class="dt-author">Julian Lemos-Vinasco</div>
<div class="dt-author">Jon Liisberg</div>
<div class="dt-author">Jan Kloppenborg Mller</div>
<div class="dt-author">Henrik Aalborg Nielsen</div>
<div class="dt-author">Henrik Madsen</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Onlineforecast: An R Package for Adaptive and Recursive Forecasting</h2>
<div class="dt-tags"></div>
<p>Systems that rely on forecasts to make decisions, e.g.control or energy trading systems, require frequent updates of the forecasts. Usually, the forecasts are updated whenever new observations become available, hence in an online setting. We present the [R]{.sans-serif} package [[onlineforecast](https://onlineforecasting.org)]{.sans-serif} that provides a generalized setup of data and models for online forecasting. It has functionality for time-adaptive fitting of dynamical and non-linear models. The setup is tailored to enable the effective use of forecasts as model inputs, e.g.numerical weather forecast. Users can create new models for their particular applications and run models in an operational setting. The package also allows users to easily replace parts of the setup, e.g.using new methods for estimation. The package comes with comprehensive vignettes and examples of online forecasting applications in energy systems, but can easily be applied for online forecasting in all fields.</p>
</div>
</a>
<a href="articles/RJ-2023-033/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 7, 2023</div>
<div class="dt-authors">
<div class="dt-author">Ufuk Beyaztas</div>
<div class="dt-author">Han Lin Shang</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>RobustFunctionalLinearRegressionModels</h2>
<div class="dt-tags"></div>
<p>With advancements in technology and data storage, the availability of functional data whose sample observations are recorded over a continuum, such as time, wavelength, space grids, and depth, progressively increases in almost all scientific branches. The functional linear regression models, including scalar-on-function and function-on-function, have become popular tools for exploring the functional relationships between the scalar response-functional predictors and functional response-functional predictors, respectively. However, most existing estimation strategies are based on non-robust estimators that are seriously hindered by outlying observations, which are common in applied research. In the case of outliers, the non-robust methods lead to undesirable estimation and prediction results. Using a readily-available [R]{.sans-serif} package robflreg, this paper presents several robust methods build upon the functional principal component analysis for modeling and predicting scalar-on-function and function-on-function regression models in the presence of outliers. The methods are demonstrated via simulated and empirical datasets.</p>
</div>
</a>
<a href="articles/RJ-2023-021/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 26, 2023</div>
<div class="dt-authors">
<div class="dt-author">Stephanie Kobakian</div>
<div class="dt-author">Dianne Cook</div>
<div class="dt-author">Earl Duncan</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-021/RJ-2023-021_files/figure-html5/choro-1.png"/>
</div>
<div class="description">
<h2>A Hexagon Tile Map Algorithm for Displaying Spatial Data</h2>
<div class="dt-tags"></div>
<p>Spatial distributions have been presented on alternative representations of geography, such as cartograms, for many years. In modern times, interactivity and animation have allowed alternative displays to play a larger role. Alternative representations have been popularised by online news sites, and digital atlases with a focus on public consumption. Applications are increasingly widespread, especially in the areas of disease mapping, and election results. The algorithm presented here creates a display that uses tessellated hexagons to represent a set of spatial polygons, and is implemented in the R package called sugarbag. It allocates these hexagons in a manner that preserves the spatial relationship of the geographic units, in light of their positions to points of interest. The display showcases spatial distributions, by emphasising the small geographical regions that are often difficult to locate on geographic maps.</p>
</div>
</a>
<a href="articles/RJ-2023-022/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 26, 2023</div>
<div class="dt-authors">
<div class="dt-author">Weihao Li</div>
<div class="dt-author">Emily Dodwell</div>
<div class="dt-author">Dianne Cook</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-022/RJ-2023-022_files/figure-html5/step2figs-1.png"/>
</div>
<div class="description">
<h2>A Clustering Algorithm to Organize Satellite Hotspot Data for the Purpose of Tracking Bushfires Remotely</h2>
<div class="dt-tags"></div>
<p>This paper proposes a spatiotemporal clustering algorithm and its implementation in the R package spotoroo. This work is motivated by the catastrophic bushfires in Australia throughout the summer of 2019-2020 and made possible by the availability of satellite hotspot data. The algorithm is inspired by two existing spatiotemporal clustering algorithms but makes enhancements to cluster points spatially in conjunction with their movement across consecutive time periods. It also allows for the adjustment of key parameters, if required, for different locations and satellite data sources. Bushfire data from Victoria, Australia, is used to illustrate the algorithm and its use within the package.</p>
</div>
</a>
<a href="articles/RJ-2023-023/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 26, 2023</div>
<div class="dt-authors">
<div class="dt-author">Rafael Ayala</div>
<div class="dt-author">Daniel Ayala</div>
<div class="dt-author">Lara Sells Vidal</div>
<div class="dt-author">David Ruiz</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-023/RJ-2023-023_files/figure-html5/groundtrack-Molniya-1.png"/>
</div>
<div class="description">
<h2>asteRisk - Integration and Analysis of Satellite Positional Data in R</h2>
<div class="dt-tags"></div>
<p>Over the past few years, the amount of artificial satellites orbiting Earth has grown fast, with close to a thousand new launches per year. Reliable calculation of the evolution of the satellites' position over time is required in order to efficiently plan the launch and operation of such satellites, as well as to avoid collisions that could lead to considerable losses and generation of harmful space debris. Here, we present asteRisk, the first R package for analysis of the trajectory of satellites. The package provides native implementations of different methods to calculate the orbit of satellites, as well as tools for importing standard file formats typically used to store satellite position data and to convert satellite coordinates between different frames of reference. Such functionalities provide the foundation for integrating orbital data and astrodynamics analysis in R.</p>
</div>
</a>
<a href="articles/RJ-2023-024/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 26, 2023</div>
<div class="dt-authors">
<div class="dt-author">Tianhai Zu</div>
<div class="dt-author">Yan Yu</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>gplsim: An R Package for Generalized Partially Linear Single-index Models</h2>
<div class="dt-tags"></div>
<p>Generalized partially linear single-index models (GPLSIMs) are important tools in nonparametric regression. They extend popular generalized linear models to allow flexible nonlinear dependence on some predictors while overcoming the "curse of dimensionality." We develop an R package gplsim that implements efficient spline estimation of GPLSIMs, proposed by [@yu_penalized_2002] and [@yu_penalised_2017], for a response variable from a general exponential family. The package builds upon the popular mgcv package for generalized additive models (GAMs) and provides functions that allow users to fit GPLSIMs with various link functions, select smoothing tuning parameter $\lambda$ against generalized cross-validation or alternative choices, and visualize the estimated unknown univariate function of single-index term. In this paper, we discuss the implementation of gplsim in detail, and illustrate the use case through a sine-bump simulation study with various links and a real-data application to air pollution data.</p>
</div>
</a>
<a href="articles/RJ-2023-025/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 26, 2023</div>
<div class="dt-authors">
<div class="dt-author">Jonatan A. Gonzlez</div>
<div class="dt-author">Paula Moraga</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-025/distill-preview.png"/>
</div>
<div class="description">
<h2>Non-Parametric Analysis of Spatial and Spatio-Temporal Point Patterns</h2>
<div class="dt-tags"></div>
<p>The analysis of spatial and spatio-temporal point patterns is becoming increasingly necessary, given the rapid emergence of geographically and temporally indexed data in a wide range of fields. Non-parametric point pattern methods are a highly adaptable approach to answering questions about the real-world using complex data in the form of collections of points. Several methodological advances have been introduced in the last few years. This paper examines the current methodology, including the most recent developments in estimation and computation, and shows how various R packages can be combined to run a set of non-parametric point pattern analyses in a guided and intuitive way. An example of non-specific gastrointestinal disease reports in Hampshire, UK, from 2001 to 2003 is used to illustrate the methods, procedures and interpretations.</p>
</div>
</a>
<a href="articles/RJ-2023-026/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 26, 2023</div>
<div class="dt-authors">
<div class="dt-author">Eun-Hwa Kang</div>
<div class="dt-author">Myungji Ko</div>
<div class="dt-author">Eun-Kyung Lee</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-026/RJ-2023-026_files/figure-html5/Fig0-1.png"/>
</div>
<div class="description">
<h2>nlmeVPC: Visual Model Diagnosis for the Nonlinear Mixed Effect Model</h2>
<div class="dt-tags"></div>
<p>A nonlinear mixed effects model is useful when the data are repeatedly measured within the same unit or correlated between units. Such models are widely used in medicine, disease mechanics, pharmacology, ecology, social science, psychology, etc. After fitting the nonlinear mixed effect model, model diagnostics are essential for verifying that the results are reliable. The visual predictive check (VPC) has recently been highlighted as a visual diagnostic tool for pharmacometric models. This method can also be applied to general nonlinear mixed effects models. However, functions for VPCs in existing R packages are specialized for pharmacometric model diagnosis, and are not suitable for general nonlinear mixed effect models. In this paper, we propose nlmeVPC, an R package for the visual diagnosis of various nonlinear mixed effect models. The nlmeVPC package allows for more diverse model diagnostics, including visual diagnostic tools that extend the concept of VPCs along with the capabilities of existing R packages.</p>
</div>
</a>
<a href="articles/RJ-2023-027/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 26, 2023</div>
<div class="dt-authors">
<div class="dt-author">Saptarshi Chakraborty</div>
<div class="dt-author">Marianthi Markatou</div>
<div class="dt-author">Robert Ball</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-027/RJ-2023-027_files/figure-html5/show-heatmap-poisson-statin46-1.png"/>
</div>
<div class="description">
<h2>Likelihood Ratio Test-Based Drug Safety Assessment using R Package pvLRT</h2>
<div class="dt-tags"></div>
<p>Medical product safety continues to be a key concern of the twenty-first century. Several spontaneous adverse events reporting databases established across the world continuously collect and archive adverse events data on various medical products. Determining signals of disproportional reporting (SDR) of product/adverse event pairs from these large-scale databases require the use of principled statistical techniques. Likelihood ratio test (LRT)-based approaches are particularly noteworthy in this context as they permit objective SDR detection without requiring ad hoc thresholds. However, their implementation is non-trivial due to analytical complexities, which necessitate the use of computation-heavy methods. Here we introduce R package pvLRT which implements a suite of LRT approaches, along with various post-processing and graphical summary functions, to facilitate simplified use of the methodologies. Detailed examples are provided to illustrate the package through analyses of three real product safety datasets obtained from publicly available FDA FAERS and VAERS databases.</p>
</div>
</a>
<a href="articles/RJ-2023-028/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 26, 2023</div>
<div class="dt-authors">
<div class="dt-author">Taban Baghfalaki</div>
<div class="dt-author">Pierre-Emmanuel Sugier</div>
<div class="dt-author">Yazdan Asgari</div>
<div class="dt-author">Thrse Truong</div>
<div class="dt-author">Benoit Liquet</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-028/distill-preview.png"/>
</div>
<div class="description">
<h2>GCPBayes:  An R package for studying Cross-Phenotype Genetic Associations with Group-level Bayesian Meta-Analysis</h2>
<div class="dt-tags"></div>
<p>Several R packages have been developed to study cross-phenotypes associations (or pleiotropy) at the SNP-level, based on summary statistics data from genome-wide association studies (GWAS). However, none of them allow for consideration of the underlying group structure of the data. We developed an R package, entitled GCPBayes (Group level Bayesian Meta-Analysis for Studying Cross-Phenotype Genetic Associations), introduced by Baghfalaki et al. (2021), that implements continuous and Dirac spike priors for group selection, and also a Bayesian sparse group selection approach with hierarchical spike and slab priors, to select important variables at the group level and within the groups. The methods use summary statistics data from association studies or individual level data as inputs, and perform Bayesian meta-analysis approaches across multiple phenotypes to detect pleiotropy at both group-level (e.g., at the gene or pathway level) and within group (e.g., at the SNP level).</p>
</div>
</a>
<a href="articles/RJ-2023-029/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 26, 2023</div>
<div class="dt-authors">
<div class="dt-author">Frank Konietschke</div>
<div class="dt-author">Edgar Brunner</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>rankFD: An R Software Package for Nonparametric Analysis of General Factorial Designs</h2>
<div class="dt-tags"></div>
<p>Many experiments can be modeled by a factorial design which allows statistical analysis of main factors and their interactions. A plethora of parametric inference procedures have been developed, for instance based on normality and additivity of the effects. However, often, it is not reasonable to assume a parametric model, or even normality, and effects may not be expressed well in terms of location shifts. In these situations, the use of a fully nonparametric model may be advisable. Nevertheless, until very recently, the straightforward application of nonparametric methods in complex designs has been hampered by the lack of a comprehensive R package. This gap has now been closed by the novel R-package [rankFD](https://CRAN.R-project.org/package=rankFD) that implements current state of the art nonparametric ranking methods for the analysis of factorial designs. In this paper, we describe its use, along with detailed interpretations of the results.</p>
</div>
</a>
<a href="articles/RJ-2023-030/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 26, 2023</div>
<div class="dt-authors">
<div class="dt-author">Rolf Simoes</div>
<div class="dt-author">Alber Sanchez</div>
<div class="dt-author">Michelle C. A. Picoli</div>
<div class="dt-author">Patrick Meyfroidt</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The segmetric Package: Metrics for Assessing Segmentation Accuracy for Geospatial Data</h2>
<div class="dt-tags"></div>
<p>Segmentation methods are a valuable tool for exploring spatial data by identifying objects based on images' features. However, proper segmentation assessment is critical for obtaining high-quality results and running well-tuned segmentation algorithms Usually, various metrics are used to inform different types of errors that dominate the results. We describe a new R package, [segmetric](https://CRAN.R-project.org/package=segmetric), for assessing and analyzing the geospatial segmentation of satellite images. This package unifies code and knowledge spread across different software implementations and research papers to provide a variety of supervised segmentation metrics available in the literature. It also allows users to create their own metrics to evaluate the accuracy of segmented objects based on reference polygons. We hope this package helps to fulfill some of the needs of the R community that works with Earth Observation data.</p>
</div>
</a>
<a href="articles/RJ-2023-034/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 26, 2023</div>
<div class="dt-authors">
<div class="dt-author">Florian Pfisterer</div>
<div class="dt-author">Siyi Wei</div>
<div class="dt-author">Sebastian Vollmer</div>
<div class="dt-author">Michel Lang</div>
<div class="dt-author">Bernd Bischl</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-034/RJ-2023-034_files/figure-html5/bmrbox-1.png"/>
</div>
<div class="description">
<h2>Fairness Audits and Debiasing Using mlr3fairness</h2>
<div class="dt-tags"></div>
<p>Given an increase in data-driven automated decision-making based on machine learning  (ML) models, it is imperative that, along with tools to develop and improve such models, there are sufficient capabilities to analyze and assess models with respect to potential biases. We present the package mlr3fairness, a collection of metrics and methods that allow for the assessment of bias in machine learning models. Our package implements a variety of widely used fairness metrics that can be used to audit models for potential biases, along with a set of visualizations that can help to provide additional insights into such biases.  mlr3fairness furthermore integrates bias mitigation methods for machine learning models through data pre-processing or post-processing of predictions.  These allow practitioners to trade off performance and fairness metrics that are appropriate for their use case.</p>
</div>
</a>
<a href="articles/RJ-2023-035/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 26, 2023</div>
<div class="dt-authors">
<div class="dt-author">Duc-Khanh To</div>
<div class="dt-author">Gianfranco Adimari</div>
<div class="dt-author">Monica Chiogna</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ClusROC: An R Package for ROC Analysis in Three-Class Classification Problems for Clustered Data</h2>
<div class="dt-tags"></div>
<p>This paper introduces an R package for ROC analysis in three-class classification problems, for clustered data in the presence of covariates, named ClusROC. The clustered data that we address have some hierarchical structure, i.e., dependent data deriving, for example, from longitudinal studies or repeated measurements. This package implements point and interval covariate-specific estimation of the true class fractions at a fixed pair of thresholds, the ROC surface, the volume under the ROC surface, and the optimal pairs of thresholds. We illustrate the usage of the implemented functions through two practical examples from different fields of research.</p>
</div>
</a>
<a href="articles/RJ-2023-036/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 26, 2023</div>
<div class="dt-authors">
<div class="dt-author">Maciej Romaniuk</div>
<div class="dt-author">Przemysaw Grzegorzewski</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Resampling Fuzzy Numbers with Statistical Applications: FuzzyResampling Package</h2>
<div class="dt-tags"></div>
<p>The classical bootstrap has proven its usefulness in many areas of statistical inference. However, some shortcomings of this method are also known. Therefore, various bootstrap modifications and other resampling algorithms have been introduced, especially for real-valued data. Recently, bootstrap methods have become popular in statistical reasoning based on imprecise data often modeled by fuzzy numbers. One of the challenges faced there is to create bootstrap samples of fuzzy numbers which are similar to initial fuzzy samples but different in some way at the same time. These methods are implemented in [FuzzyResampling](https://CRAN.R-project.org/package=FuzzyResampling) package and applied in different statistical functions like single-sample or two-sample tests for the mean. Besides describing the aforementioned functions, some examples of their applications as well as numerical comparisons of the classical bootstrap with the new resampling algorithms are provided in this contribution.</p>
</div>
</a>
<a href="articles/RJ-2023-037/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 26, 2023</div>
<div class="dt-authors">
<div class="dt-author">Mahmood Kharrati-Kopaei</div>
<div class="dt-author">Zahra Shenavari</div>
<div class="dt-author">Hossein Haghbin</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>combinIT: An R Package for Combining Interaction Tests for Unreplicated Two-Way Tables</h2>
<div class="dt-tags"></div>
<p>Several new tests have been proposed for testing interaction in unreplicated two-way analysis of variance models. Unfortunately, each test is powerful for detecting a pattern of interaction. Therefore, it is reasonable to combine multiple interaction tests to increase the power of detection for significant interactions. We introduce the package [combinIT](https://CRAN.R-project.org/package=combinIT) that provides researchers the results of six existing recommended interaction tests, including: the value of test statistics, exact Monte Carlo p-values, approximated or adjusted p-values, the results of four combined tests and explanations of interaction types if the discussed tests are significant. The software combinIT is a more comprehensive R package in comparison with the two existing packages. In addition, the software is executed quickly to obtain the exact Monte Carlo p-values, even for large Monte Carlo runs, in contrast to existing packages.</p>
</div>
</a>
<a href="articles/RJ-2023-038/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 26, 2023</div>
<div class="dt-authors">
<div class="dt-author">Jincheng Zhou</div>
<div class="dt-author">Jinhui Yang</div>
<div class="dt-author">James S. Hodges</div>
<div class="dt-author">Lifeng Lin</div>
<div class="dt-author">Haitao Chu</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-038/distill-preview.png"/>
</div>
<div class="description">
<h2>Estimating Causal Effects using Bayesian Methods with the R Package BayesCACE</h2>
<div class="dt-tags"></div>
<p>Noncompliance, a common problem in randomized clinical trials (RCTs), complicates the analysis of the causal treatment effect, especially in meta-analysis of RCTs. The complier average causal effect (CACE) measures the effect of an intervention in the latent subgroup of the population that complies with its assigned treatment (the compliers). Recently, Bayesian hierarchical approaches have been proposed to estimate the CACE in a single RCT and a meta-analysis of RCTs. We develop an R package, BayesCACE, to provide user-friendly functions for implementing CACE analysis for binary outcomes based on the flexible Bayesian hierarchical framework. This package includes functions for analyzing data from a single study and for performing a meta-analysis with either complete or incomplete compliance data. The package also provides various functions for generating forest, trace, posterior density, and auto-correlation plots, which can be useful to review noncompliance rates, visually assess the model, and obtain study-specific and overall CACEs.</p>
</div>
</a>
<a href="articles/RJ-2023-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 9, 2023</div>
<div class="dt-authors">
<div class="dt-author">Jakob Raymaekers</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>robslopes: Efficient Computation of the (Repeated) Median Slope</h2>
<div class="dt-tags"></div>
<p>Modern use of slope estimation often involves the (repeated) estimation of a large number of slopes on a large number of data points. Some of the most popular non-parametric and robust alternatives to the least squares estimator are the Theil-Sen and Siegel's repeated median slope estimators. The [*robslopes*](https://CRAN.R-project.org/package=robslopes) package contains fast algorithms for these slope estimators. The implemented randomized algorithms run in $\mathcal{O}(n\log(n))$ and $\mathcal{O}(n\log^2(n))$ expected time respectively and use $\mathcal{O}(n)$ space. They achieve speedups up to a factor $10^3$ compared with existing implementations for common sample sizes, as illustrated in a benchmark study, and they allow for the possibility of estimating the slopes on samples of size $10^5$ and larger thanks to the limited space usage. Finally, the original algorithms are adjusted in order to properly handle duplicate values in the data set.</p>
</div>
</a>
<a href="articles/RJ-2023-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 9, 2023</div>
<div class="dt-authors">
<div class="dt-author">Haley Jeppson</div>
<div class="dt-author">Heike Hofmann</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-013/distill-preview.png"/>
</div>
<div class="description">
<h2>Generalized Mosaic Plots in the ggplot2 Framework</h2>
<div class="dt-tags"></div>
<p>Graphical methods for categorical variables are not well developed when compared with visualizations for numeric data. One method available for  multidimensional categorical data visualizations is mosaic plots. Mosaic plots are an easy and powerful option for identifying relationships between multiple categorical variables. Although various packages have implemented mosaic plots, no implementation within the grammar of graphics supports mosaic plots. We present a new implementation of mosaic plots in R, ggmosaic, that implements a custom ggplot2 geom designed for generalized mosaic plots. Equipped with the functionality and flexibility of ggplot2, ggmosaic introduces new features not previously available for mosaic plots, including a novel method of incorporating a rendering of the underlying density via jittering. This paper provides an overview of the implementation and examples that highlight the versatility and ease of use of ggmosaic while demonstrating the practicality of mosaic plots.</p>
</div>
</a>
<a href="articles/RJ-2023-020/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 25, 2023</div>
<div class="dt-authors">
<div class="dt-author">Zehang Richard Li</div>
<div class="dt-author">Jason Thomas</div>
<div class="dt-author">Eungang Choi</div>
<div class="dt-author">Tyler H. McCormick</div>
<div class="dt-author">Samuel J Clark</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The openVA Toolkit for Verbal Autopsies</h2>
<div class="dt-tags"></div>
<p>Verbal autopsy (VA) is a survey-based tool widely used to infer cause of death (COD) in regions without complete-coverage civil registration and vital statistics systems. In such settings, many deaths happen outside of medical facilities and are not officially documented by a medical professional. VA surveys, consisting of signs and symptoms reported by a person close to the decedent, are used to infer the COD for an individual, and to estimate and monitor the COD distribution in the population. Several classification algorithms have been developed and widely used to assign causes of death using VA data. However, the incompatibility between different idiosyncratic model implementations and required data structure makes it difficult to systematically apply and compare different methods. The openVA package provides the first standardized framework for analyzing VA data that is compatible with all openly available methods and data structure. It provides an open-source, R implementation of several most widely used VA methods. It supports different data input and output formats, and customizable information about the associations between causes and symptoms. The paper discusses the relevant algorithms, their implementations in R packages under the openVA suite, and demonstrates the pipeline of model fitting, summary, comparison, and visualization in the R environment.</p>
</div>
</a>
<a href="articles/RJ-2023-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 10, 2023</div>
<div class="dt-authors">
<div class="dt-author">David M. Kaplan</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-001/RJ-2023-001_files/figure-html5/addinfigure-1.png"/>
</div>
<div class="description">
<h2>knitrdata: A Tool for Creating Standalone Rmarkdown Source Documents</h2>
<div class="dt-tags"></div>
<p>Though Rmarkdown is a powerful tool for integrating text with code for analyses in a single source document exportable to a variety of output formats, until now there has been no simple way to integrate the data behind analyses into Rmarkdown source documents. The `knitrdata` package makes it possible for arbitrary text and binary data to be integrated directly into Rmarkdown source documents via implementation of a new `data` chunk type. The package includes command-line and graphical tools that facilitate creating and inserting `data` chunks into Rmarkdown documents, and the treatment of `data` chunks is highly configurable via chunk options. These tools allow one to easily create fully standalone Rmarkdown source documents integrating data, ancillary formatting files, analysis code and text in a single file. Used properly, the package can facilitate open distribution of source documents that demonstrate computational reproducibility of scientific results.</p>
</div>
</a>
<a href="articles/RJ-2023-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 10, 2023</div>
<div class="dt-authors">
<div class="dt-author">Antonio J. Sez-Castillo</div>
<div class="dt-author">Antonio Conde-Snchez</div>
<div class="dt-author">Francisco Martnez</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>DGLMExtPois: Advances in Dealing with Over and Under-dispersion in a Double GLM Framework</h2>
<div class="dt-tags"></div>
<p>In recent years the use of regression models for under-dispersed count data, such as COM-Poisson or hyper-Poisson models, has increased. In this paper the *DGLMExtPois* package is presented. *DGLMExtPois* includes a new procedure to estimate the coefficients of a hyper-Poisson regression model within a GLM framework. The estimation process uses a gradient-based algorithm to solve a nonlinear constrained optimization problem. The package also provides an implementation of the COM-Poisson model, proposed by @huang, to make it easy to compare both models. The functionality of the package is illustrated by fitting a model to a real dataset. Furthermore, an experimental comparison is made with other related packages, although none of these packages allow you to fit a hyper-Poisson model.</p>
</div>
</a>
<a href="articles/RJ-2023-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 10, 2023</div>
<div class="dt-authors">
<div class="dt-author">Barbara Lerner</div>
<div class="dt-author">Emery Boose</div>
<div class="dt-author">Orenna Brand</div>
<div class="dt-author">Aaron M. Ellison</div>
<div class="dt-author">Elizabeth Fong</div>
<div class="dt-author">Matthew Lau</div>
<div class="dt-author">Khanh Ngo</div>
<div class="dt-author">Thomas Pasquier</div>
<div class="dt-author">Luis A. Perez</div>
<div class="dt-author">Margo Seltzer</div>
<div class="dt-author">Rose Sheehan</div>
<div class="dt-author">Joseph Wonsil</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Making Provenance Work for You</h2>
<div class="dt-tags"></div>
<p>To be useful, scientific results must be reproducible and trustworthy. Data provenance---the history of data and how it was computed---underlies reproducibility of, and trust in, data analyses. Our work focuses on collecting data provenance from R scripts and providing tools that use the provenance to increase the reproducibility of and trust in analyses done in R. Specifically, our "End-to-end provenance tools" ("E2ETools") use data provenance to: document the computing environment and inputs and outputs of a script's execution; support script debugging and exploration; and explain differences in behavior across repeated executions of the same script. Use of these tools can help both the original author and later users of a script reproduce and trust its results.</p>
</div>
</a>
<a href="articles/RJ-2023-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 10, 2023</div>
<div class="dt-authors">
<div class="dt-author">Jadon Wagstaff</div>
<div class="dt-author">Brennan Bean</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>remap: Regionalized Models with Spatially Smooth Predictions</h2>
<div class="dt-tags"></div>
<p>Traditional spatial modeling approaches assume that data are second-order stationary, which is rarely true over large geographical areas. A simple way to model nonstationary data is to partition the space and build models for each region in the partition. This has the side effect of creating discontinuities in the prediction surface at region borders. The regional border smoothing approach ensures continuous predictions by using a weighted average of predictions from regional models. The R package *remap* is an implementation of regional border smoothing that builds a collection of spatial models. Special consideration is given to distance calculations that make *remap* package scalable to large problems. Using the *remap* package, as opposed to global spatial models, results in improved prediction accuracy on test data. These accuracy improvements, coupled with their computational feasibility, illustrate the efficacy of the *remap* approach to modeling nonstationary data.</p>
</div>
</a>
<a href="articles/RJ-2023-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 10, 2023</div>
<div class="dt-authors">
<div class="dt-author">Valeria Trivellone</div>
<div class="dt-author">Sabrina B. L. Araujo</div>
<div class="dt-author">Bernd Panassiti</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>HostSwitch: An R Package to Simulate the Extent of Host-Switching by a Consumer</h2>
<div class="dt-tags"></div>
<p>In biology a general definition for host switch is when an organism (consumer) uses a new host (which represents a resource). The host switch process by a consumer may happen through its pre-existing capability to use a sub-optimal resource. The [*HostSwitch*](https://CRAN.R-project.org/package=HostSwitch) R package provides functions to simulate the dynamics of host switching (extent and frequency) in the population of a consumer that interacts with current and potential hosts over the generations. The [*HostSwitch*](https://CRAN.R-project.org/package=HostSwitch) package is based on a Individual-Based mock-up model published in FORTRAN by @araujo_understanding_2015. The package largely improve the previous mock-up model, by implementing numerous new functionalities such as comparison and evaluation of simulations with several customizable parameters to accommodate several types of biological consumer-host associations, an interactive visualization of the model, an in-depth description of the parameters in a biological context. Finally, we provided three real world scenarios taken from the literature selected from ecology, agriculture and parasitology. This package is intended to reach researchers in the broad field of biology interested in simulating the process of host switch of different types of symbiotic biological associations.</p>
</div>
</a>
<a href="articles/RJ-2023-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 10, 2023</div>
<div class="dt-authors">
<div class="dt-author">Gregory Guernec</div>
<div class="dt-author">Valerie Gares</div>
<div class="dt-author">Jeremy Omer</div>
<div class="dt-author">Philippe Saint-Pierre</div>
<div class="dt-author">Nicolas Savy</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>OTrecod: An R Package for Data Fusion using Optimal Transportation Theory</h2>
<div class="dt-tags"></div>
<p>The advances of information technologies often confront users with a large amount of data which is  essential to integrate easily. In this context, creating a single database from multiple separate data sources can appear as an attractive but complex issue when same information of interest is stored in at least two distinct encodings. In this situation, merging the data sources consists in finding a common recoding scale to fill the incomplete information in a synthetic database. The OTrecod package provides R-users two functions  dedicated to solve this recoding problem using optimal transportation theory. Specific arguments of these functions enrich the algorithms by relaxing distributional constraints or adding a regularization term to make the data fusion more flexible.
The OTrecod package also provides a set of support functions dedicated to the harmonization of separate data sources, the handling of incomplete information and the selection of matching variables. This paper gives all the keys to quickly understand and master  the original algorithms implemented in the OTrecod package, assisting step by step the user in its data fusion project.</p>
</div>
</a>
<a href="articles/RJ-2023-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 10, 2023</div>
<div class="dt-authors">
<div class="dt-author">Marios Batsaris</div>
<div class="dt-author">Dimitris Kavroudakis</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-007/distill-preview.png"/>
</div>
<div class="description">
<h2>populR: a Package for Population Downscaling in R</h2>
<div class="dt-tags"></div>
<p>Population data provision is usually framed by regulations and restrictions and hence spatially aggregated in predefined enumeration units such as city blocks and census tracts. Many applications require population data at finer scale, and therefore, one may use downscaling methods to transform population counts from coarse spatial units into smaller ones. Although numerous methods for downscaling of population data have been reported in the scientific literature, only a limited number of implementation tools exist. In this study, we introduce populR, an R package that responds to this need. populR provides two downscaling methods, namely Areal Weighted Interpolation and Volume Weighted Interpolation, which are illustrated and compared to alternative implementations in the sf and areal packages using a case study from Mytilini, Greece. The results provide evidence that the vwi approach outperforms the others, and thus, we believe R users may gain significant advantage by using populR for population downscaling.</p>
</div>
</a>
<a href="articles/RJ-2023-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 10, 2023</div>
<div class="dt-authors">
<div class="dt-author">Songyan Yu</div>
<div class="dt-author">Christopher G. McBride</div>
<div class="dt-author">Marieke A. Frassl</div>
<div class="dt-author">Matthew R. Hipsey</div>
<div class="dt-author">David P. Hamilton</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>dycdtools: an R Package for Assisting Calibration and Visualising Outputs of an Aquatic Ecosystem Model</h2>
<div class="dt-tags"></div>
<p>The high complexity of aquatic ecosystem models (AEMs) necessitates a large number of parameters that need calibration, and visualisation of their multifaceted and multi-layered simulation results is necessary for effective communication. Here we present an R package "dycdtools" that contains calibration and post-processing tools for a widely applied aquatic ecosystem model (DYRESM-CAEDYM). The calibration assistant function within the package automatically tests a large number of combinations of parameter values and returns corresponding values for goodness-of-fit, allowing users to narrow parameter ranges or optimise parameter values. The post-processing functions enable users to visualise modelling outputs in four ways: as contours, profiles, time series, and scatterplots. The "dycdtools" package is the first open-source calibration and post-processing tool for DYRESM-CAEDYM, and can also be adjusted for other AEMs with a similar structure. This package is useful to reduce the calibration burden for users and to effectively communicate model results with a broader community.</p>
</div>
</a>
<a href="articles/RJ-2023-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 10, 2023</div>
<div class="dt-authors">
<div class="dt-author">Hanpu Zhou</div>
<div class="dt-author">Hong Wang*</div>
<div class="dt-author">Sizheng Wang</div>
<div class="dt-author">Yi Zou</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SurvMetrics: An R package for Predictive Evaluation Metrics in Survival Analysis</h2>
<div class="dt-tags"></div>
<p>Recently, survival models have found vast applications in biostatistics, bioinformatics, reliability engineering, finance and related fields. But there are few R packages focusing on evaluating the predictive power of survival models. This lack of handy software on evaluating survival predictions hinders further applications of survival analysis for practitioners. In this research, we want to fill this gap by providing an \"all-in-one\" R package which implements most predictive evaluation metrics in survival analysis. In the proposed *SurvMetrics* R package, we implement concordance index for both untied and tied survival data; we give a new calculation process of Brier score and integrated Brier score; we also extend the applicability of integrated absolute error and integrated square error for real data. For models that can output survival time predictions, a simplified metric called mean absolute error is also implemented. In addition, we test the effectiveness of all these metrics on simulated and real survival data sets. The newly developed *SurvMetrics* R package is available on CRAN at &lt;https://CRAN.R-project.org/package=SurvMetrics&gt; and GitHub at &lt;https://github.com/skyee1/SurvMetrics&gt;.</p>
</div>
</a>
<a href="articles/RJ-2023-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 10, 2023</div>
<div class="dt-authors">
<div class="dt-author">Roman Salmeron Gomez</div>
<div class="dt-author">Catalina B. Garcia Garcia</div>
<div class="dt-author">Ainara Rodriguez Sanchez</div>
<div class="dt-author">Claudia Garcia Garcia</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-010/distill-preview.png"/>
</div>
<div class="description">
<h2>Limitations in Detecting Multicollinearity due to Scaling Issues in the mcvis Package</h2>
<div class="dt-tags"></div>
<p>Transformation of the observed data is a very common practice when a troubling degree of near multicollinearity is detected in a linear regression model. However, it is important to take into account that these transformations may affect the detection of this problem, so they should not be performed systematically. In this paper we analyze the transformation of the data when applying the R package mcvis, showing that it only detects essential near multicollinearity when the *studentise* transformation is performed.</p>
</div>
</a>
<a href="articles/RJ-2023-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 10, 2023</div>
<div class="dt-authors">
<div class="dt-author">Pariya Behrouzi</div>
<div class="dt-author">Danny Arends</div>
<div class="dt-author">Ernst C. Wit</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>netgwas: An R Package for Network-Based Genome Wide Association Studies</h2>
<div class="dt-tags"></div>
<p>Graphical models are a powerful tool in modelling and analysing complex biological associations in high-dimensional data. The R-package *netgwas* implements the recent methodological development on copula graphical models to (i) construct linkage maps, (ii) infer linkage disequilibrium networks from genotype data, and (iii) detect high-dimensional genotype-phenotype networks. The *netgwas* learns the structure of networks from ordinal data and mixed ordinal-and-continuous data. Here, we apply the functionality in *netgwas* to various multivariate example datasets taken from the literature to demonstrate the kind of insight that can be obtained from the package. We show that our package offers a more realistic association analysis than the classical approaches, as it discriminates between direct and induced correlations by adjusting for the effect of all other variables while performing pairwise associations. This feature controls for spurious interactions between variables that can arise from conventional approaches in a biological sense. The *netgwas* package uses a parallelization strategy on multi-core processors to speed-up computations.</p>
</div>
</a>
<a href="articles/RJ-2023-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 10, 2023</div>
<div class="dt-authors">
<div class="dt-author">Joseph Zemmels</div>
<div class="dt-author">Susan VanderPlas</div>
<div class="dt-author">Heike Hofmann</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-014/distill-preview.png"/>
</div>
<div class="description">
<h2>A Study in Reproducibility: The Congruent Matching Cells Algorithm and cmcR Package</h2>
<div class="dt-tags"></div>
<p>Scientific research is driven by our ability to use methods, procedures, and materials from previous studies and further research by adding to it. As the need for computationally-intensive methods to analyze large amounts of data grows, the criteria needed to achieve reproducibility, specifically computational reproducibility, have become more sophisticated. In general, prosaic descriptions of algorithms are not detailed or precise enough to ensure complete reproducibility of a method. Results may be sensitive to conditions not commonly specified in written-word descriptions such as implicit parameter settings or the programming language used. To achieve true computational reproducibility, it is necessary to provide all intermediate data and code used to produce published results. In this paper, we consider a class of algorithms developed to perform firearm evidence identification on cartridge case evidence known as the *Congruent Matching Cells* (CMC) methods. To date, these algorithms have been published as textual descriptions only. We introduce the first open-source implementation of the Congruent Matching Cells methods in the R package cmcR. We have structured the cmcR package as a set of sequential, modularized functions intended to ease the process of parameter experimentation. We use cmcR and a novel variance ratio statistic to explore the CMC methodology and demonstrate how to fill in the gaps when provided with computationally ambiguous descriptions of algorithms.</p>
</div>
</a>
<a href="articles/RJ-2023-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 10, 2023</div>
<div class="dt-authors">
<div class="dt-author">Adam Loy</div>
<div class="dt-author">Jenna Korobova</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-015/distill-preview.png"/>
</div>
<div class="description">
<h2>Bootstrapping Clustered Data in R using lmeresampler</h2>
<div class="dt-tags"></div>
<p>Linear mixed-effects models are commonly used to analyze clustered data structures. There are numerous packages to fit these models in R and conduct likelihood-based inference. The implementation of resampling-based procedures for inference are more  limited. In this paper, we introduce the lmeresampler package for bootstrapping nested linear mixed-effects models fit via lme4 or nlme. Bootstrap  estimation allows for bias correction, adjusted standard errors and confidence  intervals for small samples sizes and when distributional assumptions break down.  We will also illustrate how bootstrap resampling can be used to diagnose this model  class. In addition, lmeresampler makes it easy to construct interval estimates  of functions of model parameters.</p>
</div>
</a>
<a href="articles/RJ-2023-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 10, 2023</div>
<div class="dt-authors">
<div class="dt-author">Yueqi Shen</div>
<div class="dt-author">Matthew A. Psioda</div>
<div class="dt-author">Joseph G. Ibrahim</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>BayesPPD: An R Package for Bayesian Sample Size Determination Using the Power and Normalized Power Prior for Generalized Linear Models</h2>
<div class="dt-tags"></div>
<p>The R package *BayesPPD* (Bayesian Power Prior Design) supports Bayesian power and type I error calculation and model fitting after incorporating historical data with the power prior and the normalized power prior for generalized linear models (GLM). The package accommodates summary level data or subject level data with covariate information. It supports use of multiple historical datasets as well as design without historical data. Supported distributions for responses include normal, binary (Bernoulli/binomial), Poisson and exponential. The power parameter can be fixed or modeled as random using a normalized power prior for each of these distributions. In addition, the package supports the use of arbitrary sampling priors for computing Bayesian power and type I error rates. In addition to describing the statistical methodology and functions implemented in the package to enable sample size determination (SSD), we also demonstrate the use of *BayesPPD* in two comprehensive case studies.</p>
</div>
</a>
<a href="articles/RJ-2023-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 10, 2023</div>
<div class="dt-authors">
<div class="dt-author">Emily C. Zabor</div>
<div class="dt-author">Brian P. Hobbs</div>
<div class="dt-author">Michael J. Kane</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ppseq: An R Package for Sequential Predictive Probability Monitoring</h2>
<div class="dt-tags"></div>
<p>Advances in drug discovery have produced numerous biomarker-guided therapeutic strategies for treating cancer. Yet the promise of precision medicine comes with the cost of increased complexity. Recent trials of targeted treatments have included expansion cohorts with sample sizes far exceeding those in traditional early phase trials of chemotherapeutic agents. The enlarged sample sizes raise ethical concerns for patients who enroll in clinical trials, and emphasize the need for rigorous statistical designs to ensure that trials can stop early for futility while maintaining traditional control of type I error and power. The R package ppseq provides a framework for designing early phase clinical trials of binary endpoints using sequential futility monitoring based on Bayesian predictive probability. Trial designs can be compared using interactive plots and selected based on measures of efficiency or accuracy.</p>
</div>
</a>
<a href="articles/RJ-2023-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 10, 2023</div>
<div class="dt-authors">
<div class="dt-author">Haixu Wang</div>
<div class="dt-author">Jiguo Cao</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>pCODE: Estimating Parameters of ODE Models</h2>
<div class="dt-tags"></div>
<p>The ordinary differential equation (ODE) models are prominent to characterize the mechanism of dynamical systems with various applications in biology, engineering, and many other areas. While the form of ODE models is often proposed based on the understanding or assumption of the dynamical systems, the values of ODE model parameters are often unknown. Hence, it is of great interest to estimate the ODE parameters once the observations of dynamic systems become available. The parameter cascade method initially proposed by [@parcascade] is shown to provide an accurate estimation of ODE parameters from the noisy observations at a low computational cost. This method is further promoted with the implementation in the R package *CollocInfer* by [@CollocInfer]. However, one bottleneck in using *CollocInfer* to implement the parameter cascade method is the tedious derivations and coding of the Jacobian and Hessian matrices required by the objective functions for doing estimation. We develop an R package *pCODE* to implement the parameter cascade method, which has the advantage that the users are not required to provide any Jacobian or Hessian matrices. Functions in the *pCODE* package accommodate users for estimating ODE parameters along with their variances and tuning the smoothing parameters. The package is demonstrated and assessed with four simulation examples with various settings. We show that *pCODE* offers a derivative-free procedure to estimate any ODE models where its functions are easy to understand and apply. Furthermore, the package has an online Shiny app at &lt;https://pcode.shinyapps.io/pcode/&gt;.</p>
</div>
</a>
<a href="articles/RJ-2023-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 10, 2023</div>
<div class="dt-authors">
<div class="dt-author">Martin R. Smith</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2023-019/Flow.svg"/>
</div>
<div class="description">
<h2>TreeSearch: Morphological Phylogenetic Analysis in R</h2>
<div class="dt-tags"></div>
<p>TreeSearch is an R package for phylogenetic analysis, optimized for discrete character data. Tree search may be conducted using equal or implied step weights with an explicit (albeit inexact) allowance for inapplicable character entries, avoiding some of the pitfalls inherent in standard parsimony methods. Profile parsimony and user-specified optimality criteria are supported.
A graphical interface, which requires no familiarity with R, is designed to help a user to improve the quality of datasets through critical review of underpinning character codings; and to obtain additional information from results by identifying and summarizing clusters of similar trees, mapping the distribution of trees, and removing 'rogue' taxa that obscure underlying relationships.
Taken together, the package aims to support methodological rigour at each step of data collection, analysis, and the exploration of phylogenetic results.</p>
</div>
</a>
<a href="articles/RJ-2022-042/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 17, 2023</div>
<div class="dt-authors">
<div class="dt-author">Yu-Hyeong Jang</div>
<div class="dt-author">SungBum Kim</div>
<div class="dt-author">Hyun-Ju Jung</div>
<div class="dt-author">Hyoung-Moon Kim (Corresponding author)</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>WLinfer: Statistical Inference for Weighted Lindley Distribution</h2>
<div class="dt-tags"></div>
<p>New distributions are still being suggested for better fitting of a distribution to data, as it is one of the most fundamental problems in terms of the parametric approach. One of such is weighted Lindley (WL) distribution [@ghitany:2011]. Even though WL distribution has become increasingly popular as a possible alternative to traditional distributions such as gamma and log normal distributions, fitting it to data has rarely been addressed in existing R packages. This is the reason we present the [*WLinfer*](https://CRAN.R-project.org/package=WLinfer) package that implements overall statistical inference for WL distribution. In particular, *WLinfer* enables one to conduct the goodness of fit test, point estimation, bias correction, interval estimation, and the likelihood ratio test simply with the `WL` function which is at the core of this package. To assist users who are unfamiliar with WL distribution, we present a brief review followed by an illustrative example with R codes.</p>
</div>
</a>
<a href="articles/RJ-2022-051/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 14, 2023</div>
<div class="dt-authors">
<div class="dt-author">Peter Cahusac</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Log Likelihood Ratios for Common Statistical Tests Using the likelihoodR Package</h2>
<div class="dt-tags"></div>
<p>The **likelihoodR** package has been developed to allow users to obtain statistics according to the likelihood approach to statistical inference. Commonly used tests are available in the package, such as: *t* tests, ANOVA, correlation, regression and a range of categorical analyses. In addition, there is a sample size calculator for *t* tests, based upon the concepts of strength of evidence, and the probabilities of misleading and weak evidence.</p>
</div>
</a>
<a href="articles/RJ-2022-043/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 20, 2022</div>
<div class="dt-authors">
<div class="dt-author">Ehsan Masoudi</div>
<div class="dt-author">Heinz Holling</div>
<div class="dt-author">Weng Kee Wong</div>
<div class="dt-author">Seongho Kim</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ICAOD: An R Package for Finding Optimal designs for Nonlinear Statistical Models by Imperialist Competitive Algorithm</h2>
<div class="dt-tags"></div>
<p>Optimal design ideas are increasingly used in different disciplines to rein in experimental costs. Given a nonlinear statistical model and a design criterion, optimal designs determine the number of experimental points to observe the responses, the design points and the number of replications at each design point. Currently, there are very few free and effective computing tools for finding different types of optimal designs for a general nonlinear model, especially when the criterion is not differentiable. We introduce an R package [*ICAOD*](https://CRAN.R-project.org/package=ICAOD) to find various types of optimal designs and they include locally, minimax and Bayesian optimal designs for different nonlinear statistical models. Our main computational tool is a novel metaheuristic algorithm called imperialist competitive algorithm (ICA) and inspired by socio-political behavior of humans and colonialism. We demonstrate its capability and effectiveness using several applications. The package also includes several theory-based tools to assess optimality of a generated design when the criterion is a convex function of the design.</p>
</div>
</a>
<a href="articles/RJ-2022-044/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 20, 2022</div>
<div class="dt-authors">
<div class="dt-author">Itsaso Rodrguez</div>
<div class="dt-author">Itziar Irigoien</div>
<div class="dt-author">Basilio Sierra</div>
<div class="dt-author">Concepcin Arenas</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>dbcsp: User-friendly R package for Distance-Based Common Spatial Patterns</h2>
<div class="dt-tags"></div>
<p>Common Spatial Patterns (CSP) is a widely used method to analyse electroencephalography (EEG) data, concerning the supervised classification of the activity of brain. More generally, it can be useful to distinguish between multivariate signals recorded during a time span for two different classes. CSP is based on the simultaneous diagonalization of the average covariance matrices of signals from both classes and it allows the data to be projected into a low-dimensional subspace. Once the data are represented in a low-dimensional subspace, a classification step must be carried out. The original CSP method is based on the Euclidean distance between signals, and here we extend it so that it can be applied on any appropriate distance for data at hand. Both the classical CSP and the new Distance-Based CSP (DB-CSP) are implemented in an R package, called *dbcsp*.</p>
</div>
</a>
<a href="articles/RJ-2022-045/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 20, 2022</div>
<div class="dt-authors">
<div class="dt-author">Camille Frvent</div>
<div class="dt-author">Mohamed-Salem Ahmed</div>
<div class="dt-author">Julien Soula</div>
<div class="dt-author">Lionel Cucala</div>
<div class="dt-author">Zaineb Smida</div>
<div class="dt-author">Sophie Dabo-Niang</div>
<div class="dt-author">Michal Genin</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The R Package HDSpatialScan for the Detection of Clusters of Multivariate and Functional Data using Spatial Scan Statistics</h2>
<div class="dt-tags"></div>
<p>This paper introduces the R package [*HDSpatialScan*](https://CRAN.R-project.org/package=HDSpatialScan). This package allows users to easily apply spatial scan statistics to real-valued multivariate data or both univariate and multivariate functional data. It also permits plotting the detected clusters and to summarize them. In this article the methods are presented and the use of the package is illustrated through examples on environmental data provided in the package.</p>
</div>
</a>
<a href="articles/RJ-2022-046/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 20, 2022</div>
<div class="dt-authors">
<div class="dt-author">Paula Saavedra-Nieves</div>
<div class="dt-author">Rosa M. Crujeiras</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>HDiR: An R Package for Computation and Nonparametric Plug-in Estimation of Directional Highest Density Regions and General Level Sets</h2>
<div class="dt-tags"></div>
<p>A deeper understanding of a distribution support, being able to determine regions of a certain (possibly high) probability content is an important task in several research fields. Package *HDiR* for R is designed for exact computation of directional (circular and spherical) highest density regions and density level sets when the density is fully known. Otherwise, *HDiR* implements nonparametric plug-in methods based on different kernel density estimates for reconstructing this kind of sets. Additionally, it also allows the computation and plug-in estimation of level sets for general functions (not necessarily a density). Some exploratory tools, such as suitably adapted distances and scatterplots, are also implemented. Two original datasets and spherical density models are used for illustrating *HDiR* functionalities.</p>
</div>
</a>
<a href="articles/RJ-2022-047/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 20, 2022</div>
<div class="dt-authors">
<div class="dt-author">Daeyoung Lim</div>
<div class="dt-author">Ming-Hui Chen</div>
<div class="dt-author">Joseph G. Ibrahim</div>
<div class="dt-author">Sungduk Kim</div>
<div class="dt-author">Arvind K. Shah</div>
<div class="dt-author">Jianxin Lin</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>metapack: An R Package for Bayesian Meta-Analysis and Network Meta-Analysis with a Unified Formula Interface</h2>
<div class="dt-tags"></div>
<p>Meta-analysis, a statistical procedure that compares, combines, and synthesizes research findings from multiple studies in a principled manner, has become popular in a variety of fields. Meta-analyses using study-level (or equivalently *aggregate*) data are of particular interest due to data availability and modeling flexibility. In this paper, we describe an R package *metapack* that introduces a unified formula interface for both meta-analysis and network meta-analysis. The user interface---and therefore the package---allows flexible variance-covariance modeling for multivariate meta-analysis models and univariate network meta-analysis models. Complicated computing for these models has prevented their widespread adoption. The package also provides functions to generate relevant plots and perform statistical inferences like model assessments. Use cases are demonstrated using two real data sets contained in *metapack*.</p>
</div>
</a>
<a href="articles/RJ-2022-048/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 20, 2022</div>
<div class="dt-authors">
<div class="dt-author">Kyle Butts</div>
<div class="dt-author">John Gardner</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2022-048/distill-preview.png"/>
</div>
<div class="description">
<h2>did2s: Two-Stage Difference-in-Differences</h2>
<div class="dt-tags"></div>
<p>Recent work has highlighted the difficulties of estimating difference-in-differences models when the treatment is adopted at different times for different units. This article introduces the R package did2s which implements the estimator introduced in @Gardner_2021. The article provides an approachable review of the underlying econometric theory and introduces the syntax for the function `did2s`. Further, the package introduces functions, event_study and plot_event_study, which uses a common syntax to implement all of the modern event-study estimators.</p>
</div>
</a>
<a href="articles/RJ-2022-049/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 20, 2022</div>
<div class="dt-authors">
<div class="dt-author">Derick S. Baum</div>
<div class="dt-author">Xiang Zhou</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>rbw: An R Package for Constructing Residual Balancing Weights</h2>
<div class="dt-tags"></div>
<p>We describe the R package [*rbw*](https://CRAN.R-project.org/package=rbw), which implements the method of residual balancing weights (RBW) for estimating marginal structural models. In contrast to other methods such as inverse probability weighting (IPW) and covariate balancing propensity scores (CBPS), RBW involves modeling the conditional means of post-treatment confounders instead of the conditional distributions of the treatment to construct the weights. RBW is thus easier to use with continuous treatments, and the method is less susceptible to model misspecification issues that often arise when modeling the conditional distributions of treatments. RBW is also advantageous from a computational perspective. As its weighting procedure involves a convex optimization problem, RBW typically locates a solution considerably faster than other methods whose optimization relies on nonconvex loss functions --- such as the recently proposed nonparametric version of CBPS. We explain the rationale behind RBW, describe the functions in [*rbw*](https://CRAN.R-project.org/package=rbw), and then use real-world data to illustrate their applications in three scenarios: effect estimation for point treatments, causal mediation analysis, and effect estimation for time-varying treatments with time-varying confounders.</p>
</div>
</a>
<a href="articles/RJ-2022-050/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 20, 2022</div>
<div class="dt-authors">
<div class="dt-author">William Kumler</div>
<div class="dt-author">Anitra E. Ingalls</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Tidy Data Neatly Resolves Mass-Spectrometry's Ragged Arrays</h2>
<div class="dt-tags"></div>
<p>Mass spectrometry (MS) is a powerful tool for measuring biomolecules, but the data produced is often difficult to handle computationally because it is stored as a ragged array. In R, this format is typically encoded in complex S4 objects built around environments, requiring an extensive background in R to perform even simple tasks. However, the adoption of tidy data [@wickham2014] provides an alternate data structure that is highly intuitive and works neatly with base R functions and common packages, as well as other programming languages. Here, we discuss the current state of R-based MS data processing, the convenience and challenges of integrating tidy data techniques into MS data processing, and present [*RaMS*](https://CRAN.R-project.org/package=RaMS), a package that produces tidy representations of MS data.</p>
</div>
</a>
<a href="articles/RJ-2022-052/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 20, 2022</div>
<div class="dt-authors">
<div class="dt-author">Sahir Rai Bhatnagar*</div>
<div class="dt-author">Maxime Turgeon*</div>
<div class="dt-author">Jesse Islam</div>
<div class="dt-author">James A. Hanley</div>
<div class="dt-author">Olli Saarela</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2022-052/plot-erspc-data-1.png"/>
</div>
<div class="description">
<h2>casebase: An Alternative Framework for Survival Analysis and Comparison of Event Rates</h2>
<div class="dt-tags"></div>
<p>In clinical studies of time-to-event data, a quantity of interest to the clinician is their patient's risk of an event. However, methods relying on time matching or risk-set sampling (including Cox regression) eliminate the baseline hazard from the estimating function. As a consequence, the focus has been on reporting hazard ratios instead of survival or cumulative incidence curves. Indeed, reporting patient risk or cumulative incidence requires a separate estimation of the baseline hazard. Using case-base sampling, Hanley &amp; Miettinen (2009) explained how parametric hazard functions can be estimated in continuous-time using logistic regression. Their approach naturally leads to estimates of the survival or risk function that are smooth-in-time. In this paper, we present the casebase R package, a comprehensive and flexible toolkit for parametric survival analysis. We describe how the case-base framework can also be used in more complex settings: non-linear functions of time and non-proportional hazards, competing risks, and variable selection. Our package also includes an extensive array of visualization tools to complement the analysis. We illustrate all these features through three different case studies. * SRB and MT contributed equally to this work.</p>
</div>
</a>
<a href="articles/RJ-2022-053/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 20, 2022</div>
<div class="dt-authors">
<div class="dt-author">Manuel Escabias</div>
<div class="dt-author">Ana M. Aguilera</div>
<div class="dt-author">Christian Acal</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>logitFD: an R package for functional principal component logit regression</h2>
<div class="dt-tags"></div>
<p>The functional logit regression model was proposed by [@Escabias04] with the objective of modeling a scalar binary response variable from a functional predictor. The model estimation proposed in that case was performed in a subspace of $L^2(T)$ of squared integrable functions of finite dimension, generated by a finite set of basis functions. For that estimation it was assumed that the curves of the functional predictor and the functional parameter of the model belong to the same finite subspace. The estimation so obtained was affected by high multicollinearity problems and the solution given to these problems was based on different functional principal component analysis. The [*logitFD*](https://CRAN.R-project.org/package=logitFD) package introduced here provides a toolbox for the fit of these models by implementing the different proposed solutions and by generalizing the model proposed in 2004 to the case of several functional and non-functional predictors. The performance of the functions is illustrated by using data sets of functional data included in the [*fda.usc*](https://CRAN.R-project.org/package=fda.usc) package from R-CRAN.</p>
</div>
</a>
<a href="articles/RJ-2022-054/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 20, 2022</div>
<div class="dt-authors">
<div class="dt-author">Miriam Esteve</div>
<div class="dt-author">Victor Espaa</div>
<div class="dt-author">Juan Aparicio</div>
<div class="dt-author">Xavier Barber</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2022-054/distill-preview.png"/>
</div>
<div class="description">
<h2>eat: An R Package for fitting Efficiency Analysis Trees</h2>
<div class="dt-tags"></div>
<p>eat is a new package for R that includes functions to estimate production frontiers and technical efficiency measures through non-parametric techniques based upon regression trees. The package specifically implements the main algorithms associated with a recently introduced methodology for estimating the efficiency of a set of decision-making units in Economics and Engineering through Machine Learning techniques, called Efficiency Analysis Trees [@esteve2020]. The package includes code for estimating input- and output-oriented radial measures, input- and output-oriented Russell measures, the directional distance function and the weighted additive model, plotting graphical representations of the production frontier by tree structures, and determining rankings of importance of input variables in the analysis. Additionally, it includes the code to perform an adaptation of Random Forest in estimating technical efficiency. This paper describes the methodology and implementation of the functions, and reports numerical results using a real data base application.</p>
</div>
</a>
<a href="articles/RJ-2022-055/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 20, 2022</div>
<div class="dt-authors">
<div class="dt-author">Kevin Wright</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2022-055/distill-preview.png"/>
</div>
<div class="description">
<h2>Will the Real Hopkins Statistic Please Stand Up?</h2>
<div class="dt-tags"></div>
<p>Hopkins statistic [@hopkins1954new] can be used to test for spatial randomness of data and for detecting clusters in data. Although the method is nearly 70 years old, there is persistent confusion regarding the definition and calculation of the statistic. We investigate the confusion and its possible origin. Using the most general definition of Hopkins statistic, we perform a small simulation to verify its distributional properties, provide a visualization of how the statistic is calculated, and provide a fast R function to correctly calculate the statistic.  Finally, we propose a protocol of five questions to guide the use of Hopkins statistic.</p>
</div>
</a>
<a href="articles/RJ-2022-056/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 20, 2022</div>
<div class="dt-authors">
<div class="dt-author">Bruce J. Swihart</div>
<div class="dt-author">John P. Nolan</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Multivariate Subgaussian Stable Distributions in R</h2>
<div class="dt-tags"></div>
<p>We introduce and showcase [*mvpd*](https://CRAN.R-project.org/package=mvpd) (an acronym for *m*ulti*v*ariate *p*roduct *d*istributions), a package that uses a product distribution approach to calculating multivariate subgaussian stable distribution functions. The family of multivariate subgaussian stable distributions are elliptically contoured multivariate stable distributions that contain the multivariate Cauchy and the multivariate normal distribution. These distributions can be useful in modeling data and phenomena that have heavier tails than the normal distribution (more frequent occurrence of extreme values). Application areas include log returns for stocks, signal processing for radar and sonar data, astronomy, and hunting patterns of sharks.</p>
</div>
</a>
<a href="articles/RJ-2022-057/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 20, 2022</div>
<div class="dt-authors">
<div class="dt-author">Dalibor Trapl</div>
<div class="dt-author">Vojtech Spiwok</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2022-057/distill-preview.png"/>
</div>
<div class="description">
<h2>Analysis of the Results of Metadynamics Simulations by metadynminer and metadynminer3d</h2>
<div class="dt-tags"></div>
<p>Molecular simulations solve the equation of motion of molecular systems, making the 3D shapes of molecules four-dimensional by adding the time coordinate. These methods have great potential in drug discovery because they can realistically model the structures of protein molecules targeted by drugs, as well as the process of binding of a potential drug to its molecular target. However, routine application of biomolecular simulations is hampered by the very high computational costs of this method. Several methods have been developed to address this problem. One of them, metadynamics, disfavors states of the simulated system that have been already visited and thus forces the system to explore new states. Here we present the package metadynminer and metadynminer3d to analyze and visualize results from metadynamics, in particular those produced by a popular metadynamics package Plumed.</p>
</div>
</a>
<a href="articles/RJ-2022-058/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 20, 2022</div>
<div class="dt-authors">
<div class="dt-author">Liangyuan Hu</div>
<div class="dt-author">Jiayi Ji</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>CIMTx: An R Package for Causal Inference with Multiple Treatments using Observational Data</h2>
<div class="dt-tags"></div>
<p>[*CIMTx*](https://CRAN.R-project.org/package=CIMTx) provides efficient and unified functions to implement modern methods for causal inferences with multiple treatments using observational data with a focus on binary outcomes. The methods include regression adjustment, inverse probability of treatment weighting, Bayesian additive regression trees, regression adjustment with multivariate spline of the generalized propensity score, vector matching and targeted maximum likelihood estimation. In addition, [*CIMTx*](https://CRAN.R-project.org/package=CIMTx) illustrates ways in which users can simulate data adhering to the complex data structures in the multiple treatment setting. Furthermore, the [*CIMTx*](https://CRAN.R-project.org/package=CIMTx) package offers a unique set of features to address the key causal assumptions: positivity and ignorability. For the positivity assumption, [*CIMTx*](https://CRAN.R-project.org/package=CIMTx) demonstrates techniques to identify the common support region for retaining inferential units using inverse probability of treatment weighting, Bayesian additive regression trees and vector matching. To handle the ignorability assumption, [*CIMTx*](https://CRAN.R-project.org/package=CIMTx) provides a flexible Monte Carlo sensitivity analysis approach to evaluate how causal conclusions would be altered in response to different magnitude of departure from ignorable treatment assignment.</p>
</div>
</a>
<a href="articles/RJ-2022-041/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 12, 2022</div>
<div class="dt-authors">
<div class="dt-author">Johannes Titz</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Introducing fastpos: A Fast R Implementation to Find the Critical Point of Stability for a Correlation</h2>
<div class="dt-tags"></div>
<p>The R package fastpos provides a fast algorithm to estimate the required sample size for a Pearson correlation to *stabilize* [@schonbrodt2013]. The stability approach is an innovative alternative to other means of sample size planning, such as power analysis. Although the approach is young, it has already attracted much interest in the research community. Still, to date, there exists no easy way to use the stability approach because there is no analytical solution and a simulation approach is computationally expensive with a quadratic time complexity. The presented package overcomes this limitation by speeding up the calculation of correlations and achieving linear time complexity. For typical parameters, the theoretical speedup is around a factor of 250, which was empirically confirmed in a comparison with the original implementation `corEvol`. This speedup allows practitioners to use the stability approach to plan for sample size and theoreticians to further explore the method.</p>
</div>
</a>
<a href="articles/RJ-2022-023/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 11, 2022</div>
<div class="dt-authors">
<div class="dt-author">Nicholas Tierney</div>
<div class="dt-author">Dianne Cook</div>
<div class="dt-author">Tania Prvan</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2022-023/RJ-2022-023_files/figure-html5/heights-sample-plot-1.png"/>
</div>
<div class="description">
<h2>brolgar: An R package to BRowse Over Longitudinal Data Graphically and Analytically in R</h2>
<div class="dt-tags"></div>
<p>Longitudinal (panel) data provide the opportunity to examine temporal patterns of individuals, because measurements are collected on the same person at different, and often irregular, time points. The data is typically visualised using a "spaghetti plot", where a line plot is drawn for each individual. When overlaid in one plot, it can have the appearance of a bowl of spaghetti. With even a small number of subjects, these plots are too overloaded to be read easily. The interesting aspects of individual differences are lost in the noise. Longitudinal data is often modelled with a hierarchical linear model to capture the overall trends, and variation among individuals, while accounting for various levels of dependence. However, these models can be difficult to fit, and can miss unusual individual patterns. Better visual tools can help to diagnose longitudinal models, and better capture the individual experiences. This paper introduces the R package, brolgar (BRowse over Longitudinal data Graphically and Analytically in R), which provides tools to identify and summarise interesting individual patterns in longitudinal data.</p>
</div>
</a>
<a href="articles/RJ-2022-025/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 11, 2022</div>
<div class="dt-authors">
<div class="dt-author">Tian-Yuan Huang</div>
<div class="dt-author">Li Li</div>
<div class="dt-author">Liying Yang</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2022-025/distill-preview.png"/>
</div>
<div class="description">
<h2>akc: A Tidy Framework for Automatic Knowledge Classification in R</h2>
<div class="dt-tags"></div>
<p>Knowledge classification is an extensive and practical approach in domain knowledge management. Automatically extracting and organizing knowledge from unstructured textual data is desirable and appealing in various circumstances. In this paper, the tidy framework for automatic knowledge classification supported by the akc package is introduced. With  powerful support from the R ecosystem, the akc framework can handle multiple procedures in data science workflow, including text cleaning, keyword extraction, synonyms consolidation and data presentation. While focusing on bibliometric analysis, the akc package is extensible to be used in other contexts. This paper introduces the framework and its features in detail. Specific examples are given to guide the potential users and developers to participate in open science of text mining.</p>
</div>
</a>
<a href="articles/RJ-2022-028/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 19, 2022</div>
<div class="dt-authors">
<div class="dt-author">Devin W. Goodsman</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2022-028/distill-preview.png"/>
</div>
<div class="description">
<h2>Quantifying Population Movement Using a Novel Implementation of Digital Image Correlation in the ICvectorfields Package</h2>
<div class="dt-tags"></div>
<p>Movements in imagery captivate the human eye and imagination. They are also of interest in variety of scientific disciplines that study spatiotemporal dynamics. Popular methods for quantifying movement in imagery include particle image velocimetry and digital image correlation. Both methods are widely applied in engineering and materials science, but less applied in other disciplines. This paper describes an implementation of a basic digital image correlation algorithm in R as well as an extension designed to quantify persistent movement velocities in sequences of three or more images. Algorithms are applied in the novel arena of landscape ecology to quantify population movement and to produce vector fields for easy visualization of complex movement patterns across space. Functions to facilitate analyses are available in ICvectorfields \citep{ICvf}. These methods and functions are likely to produce novel insights in theoretical and landscape ecology because they facilitate visualization and comparison of theoretical and observed data in complex and heterogeneous environments.</p>
</div>
</a>
<a href="articles/RJ-2022-034/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 19, 2022</div>
<div class="dt-authors">
<div class="dt-author">Josep L. Carrasco</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2022-034/distill-preview.png"/>
</div>
<div class="description">
<h2>iccCounts: An R Package to Estimate the Intraclass Correlation Coefficient for Assessing Agreement with Count Data</h2>
<div class="dt-tags"></div>
<p>The intraclass correlation coefficient (ICC) is a widely used index to assess agreement with continuous data. The common approach for estimating the ICC involves estimating the variance components of a linear mixed model under assumptions such as linearity and normality of effects. However, if the outcomes are counts these assumptions are not met and the ICC estimates are biased and inefficient. In this situation, it is necessary to use alternative approaches that are better suited for count data. Here, the iccCounts R package is introduced for estimating the ICC under the Poisson, Negative Binomial, Zero-Inflated Poisson and Zero-Inflated Negative Binomial distributions. The utility of the iccCounts package is illustrated by three examples that involve the assessment of repeatability and concordance with count data.</p>
</div>
</a>
<a href="articles/RJ-2022-035/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 13, 2022</div>
<div class="dt-authors">
<div class="dt-author">Wangqian Ju</div>
<div class="dt-author">Heike Hofmann</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2022-035/img/barrel_bullet_ps.png"/>
</div>
<div class="description">
<h2>An Open-Source Implementation of the CMPS Algorithm for Assessing Similarity of Bullets</h2>
<div class="dt-tags"></div>
<p>In this paper, we introduce the R package cmpsR, an open-source implementation of the Congruent Matching Profile Segments (CMPS) method developed at the National Institute of Standards and Technology (NIST) for objective comparison of striated tool marks. The functionality of the package is showcased by examples of bullet signatures that come with the package. Graphing tools are implemented in the package as well for users to assess and understand the CMPS results. Initial tests were performed on bullet signatures generated from two sets of 3D scans in the Hamby study under the framework suggested by the R package `bulletxtrctr`. New metrics based on CMPS scores are introduced and compared with existing metrics. A measure called sum of squares ratio is included, and how it can be used for evaluating different scans, metrics, or parameters is showcased with the Hamby study data sets. An open-source implementation of the CMPS algorithm makes the algorithm more accessible, generates reproducible results, and facilitates further studies of the algorithm such as method comparisons.</p>
</div>
</a>
<a href="articles/RJ-2022-036/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 13, 2022</div>
<div class="dt-authors">
<div class="dt-author">Bryan A. Fuentes</div>
<div class="dt-author">Minerva J. Dorantes</div>
<div class="dt-author">John R. Tipton</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2022-036/distill-preview.png"/>
</div>
<div class="description">
<h2>rassta: Raster-Based Spatial Stratification Algorithms</h2>
<div class="dt-tags"></div>
<p>Spatial stratification of landscapes allows for the development of efficient  sampling surveys, the inclusion of domain knowledge in data-driven modeling  frameworks, and the production of information relating the spatial variability  of response phenomena to that of landscape processes. This work presents the  rassta package as a collection of algorithms dedicated to the spatial  stratification of landscapes, the calculation of landscape correspondence  metrics across geographic space, and the application of these metrics for  spatial sampling and modeling of environmental phenomena. The theoretical  background of rassta is presented through references to several studies  which have benefited from landscape stratification routines. The functionality  of rassta is presented through code examples which are complemented with  the geographic visualization of their outputs.</p>
</div>
</a>
<a href="articles/RJ-2022-024/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 11, 2022</div>
<div class="dt-authors">
<div class="dt-author">Mary Gregg</div>
<div class="dt-author">Somnath Datta</div>
<div class="dt-author">Douglas Lorenz</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>htestClust: A Package for Marginal Inference of Clustered Data Under Informative Cluster Size</h2>
<div class="dt-tags"></div>
<p>When observations are collected in/organized into observational units, within which observations may be dependent, those observational units are often referred to as \"clustered\" and the data as \"clustered data\". Examples of clustered data include repeated measures or hierarchical shared association (e.g., individuals within families). This paper provides an overview of the R package [*htestClust*](https://CRAN.R-project.org/package=htestClust), a tool for the marginal analysis of such clustered data with potentially informative cluster and/or group sizes. Contained in *htestClust* are clustered data analogues to the following classical hypothesis tests: rank-sum, signed rank, $t$-, one-way ANOVA, F, Levene, Pearson/Spearman/Kendall correlation, proportion, goodness-of-fit, independence, and McNemar. Additional functions allow users to visualize and test for informative cluster size. This package has an easy-to-use interface mimicking that of classical hypothesis-testing functions in the R environment. Various features of this package are illustrated through simple examples.</p>
</div>
</a>
<a href="articles/RJ-2022-026/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 11, 2022</div>
<div class="dt-authors">
<div class="dt-author">Jiahui Xu</div>
<div class="dt-author">Liying Luo</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>APCI: An R and Stata Package for Visualizing and Analyzing Age-Period-Cohort Data</h2>
<div class="dt-tags"></div>
<p>Social scientists have frequently attempted to assess the relative contribution of age, period, and cohort variables to the overall trend in an outcome. We develop an R package [*APCI*](https://CRAN.R-project.org/package=APCI) (and Stata command `apci`) to implement the age-period-cohort-interaction (APC-I) model for estimating and testing age, period, and cohort patterns in various types of outcomes for pooled cross-sectional data and multi-cohort panel data. Package [*APCI*](https://CRAN.R-project.org/package=APCI) also provides a set of functions for visualizing the data and modeling results. We demonstrate the usage of package [*APCI*](https://CRAN.R-project.org/package=APCI) with empirical data from the Current Population Survey. We show that package [*APCI*](https://CRAN.R-project.org/package=APCI) provides useful visualization and analytical tools for understanding age, period, and cohort trends in various types of outcomes.</p>
</div>
</a>
<a href="articles/RJ-2022-027/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 11, 2022</div>
<div class="dt-authors">
<div class="dt-author">Frank Weber</div>
<div class="dt-author">Katja Ickstadt</div>
<div class="dt-author">nne Glass</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>shinybrms: Fitting Bayesian Regression Models Using a Graphical User Interface for the R Package brms</h2>
<div class="dt-tags"></div>
<p>Despite their advantages, the application of Bayesian regression models is still the exception compared to frequentist regression models. Here, we present our R package [*shinybrms*](https://CRAN.R-project.org/package=shinybrms) which provides a graphical user interface for fitting Bayesian regression models, with the frontend consisting of a [*shiny*](https://CRAN.R-project.org/package=shiny) app and the backend relying on the R package [*brms*](https://CRAN.R-project.org/package=brms) which in turn relies on Stan. With *shinybrms*, we hope that Bayesian regression models (and regression models in general) will become more popular in applied research, data analyses, and teaching. Here, we illustrate our graphical user interface by the help of an example from medical research.</p>
</div>
</a>
<a href="articles/RJ-2022-029/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 11, 2022</div>
<div class="dt-authors">
<div class="dt-author">scar Lado-Baleato</div>
<div class="dt-author">Javier Roca-Pardias</div>
<div class="dt-author">Carmen Cadarso-Surez</div>
<div class="dt-author">Francisco Gude</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Refreg: An R Package for Estimating Conditional Reference Regions</h2>
<div class="dt-tags"></div>
<p>Multivariate reference regions (MVR) represent the extension of the reference interval concept to the multivariate setting. A reference interval is defined by two threshold points between which a high percentage of healthy subjects' results, usually 95%, are contained. Analogously, an MVR characterizes the values of several diagnostic tests most frequently found among non-diseased subjects by defining a convex hull containing 95% of the results. MVRs have great applicability when working with diseases that are diagnosed via more than one continuous test, e.g., diabetes or hypothyroidism. The present work introduces *refreg*, an R package for estimating conditional MVRs. The reference region is non-parametrically estimated using a multivariate kernel density estimator, and its shape allowed to change under the influence of covariates. The effects of covariates on the multivariate variable means, and on their variance-covariance matrix, are estimated by flexible additive predictors. Continuous covariate non-linear effects can be estimated by penalized spline smoothers. The package allows the user to propose, for instance, an age-specific diagnostic rule based on the joint distribution of two non-Gaussian, continuous test results. The usefulness of the *refreg* package in clinical practice is illustrated with a real case in diabetes research, with an age-specific reference region proposed for the joint interpretation of two glycemia markers (fasting plasma glucose and glycated hemoglobin). To show that the *refreg* package can also be used in other, and indeed very different fields, an example is provided for the joint prediction of two atmospheric pollutants (SO$_2$, and NO$_x$). Additionally, the text discusses how, conceptually, this method could be extended to more than two dimensions.</p>
</div>
</a>
<a href="articles/RJ-2022-030/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 11, 2022</div>
<div class="dt-authors">
<div class="dt-author">Ping-Yang Chen</div>
<div class="dt-author">Hsing-Ming Chang</div>
<div class="dt-author">Yu-Ting Chen</div>
<div class="dt-author">Jung-Ying Tzeng</div>
<div class="dt-author">Sheng-Mao Chang</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>TensorTest2D: Fitting Generalized Linear Models with Matrix Covariates</h2>
<div class="dt-tags"></div>
<p>The [*TensorTest2D*](https://CRAN.R-project.org/package=TensorTest2D) package provides the means to fit generalized linear models on second-order tensor type data. Functions within this package can be used for parameter estimation (e.g., estimating regression coefficients and their standard deviations) and hypothesis testing. We use two examples to illustrate the utility of our package in analyzing data from different disciplines. In the first example, a tensor regression model is used to study the effect of multi-omics predictors on a continuous outcome variable which is associated with drug sensitivity. In the second example, we draw a subset of the MNIST handwritten images and fit to them a logistic tensor regression model. A significance test characterizes the image pattern that tells the difference between two handwritten digits. We also provide a function to visualize the areas as effective classifiers based on a tensor regression model. The visualization tool can also be used together with other variable selection techniques, such as the LASSO, to inform the selection results.</p>
</div>
</a>
<a href="articles/RJ-2022-031/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 11, 2022</div>
<div class="dt-authors">
<div class="dt-author">Vicente J. Bols</div>
<div class="dt-author">Rafael Bentez</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>wavScalogram: An R Package with Wavelet Scalogram Tools for Time Series Analysis</h2>
<div class="dt-tags"></div>
<p>In this work we present the *wavScalogram* R package, which contains methods based on wavelet scalograms for time series analysis. These methods are related to two main wavelet tools: the windowed scalogram difference and the scale index. The windowed scalogram difference compares two time series, identifying if their scalograms follow similar patterns at different scales and times, and it is thus a useful complement to other comparison tools such as the squared wavelet coherence. On the other hand, the scale index provides a numerical estimation of the degree of non-periodicity of a time series and it is widely used in many scientific areas.</p>
</div>
</a>
<a href="articles/RJ-2022-032/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 11, 2022</div>
<div class="dt-authors">
<div class="dt-author">Seungki Hong</div>
<div class="dt-author">Sungkyu Jung</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ClusTorus: An R Package for Prediction and Clustering on the Torus by Conformal Prediction</h2>
<div class="dt-tags"></div>
<p>Protein structure data consist of several dihedral angles, lying on a multidimensional torus. Analyzing such data has been and continues to be key in understanding functional properties of proteins. However, most of the existing statistical methods assume that data are on Euclidean spaces, and thus they are improper to deal with angular data. In this paper, we introduce the package *ClusTorus* specialized to analyzing multivariate angular data. The package collects some tools and routines to perform algorithmic clustering and model-based clustering for data on the torus. In particular, the package enables the construction of conformal prediction sets and predictive clustering, based on kernel density estimates and mixture model estimates. A novel hyperparameter selection strategy for predictive clustering is also implemented, with improved stability and computational efficiency. We demonstrate the use of the package in clustering protein dihedral angles from two real data sets.</p>
</div>
</a>
<a href="articles/RJ-2022-033/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 11, 2022</div>
<div class="dt-authors">
<div class="dt-author">Elvira Di Nardo</div>
<div class="dt-author">Giuseppe Guarino</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>kStatistics: Unbiased Estimates of Joint Cumulant Products from the Multivariate Fa Di Bruno's Formula</h2>
<div class="dt-tags"></div>
<p>kStatistics is a package in `R` that serves as a unified framework for estimating univariate and multivariate cumulants as well as products of univariate and multivariate cumulants of a random sample, using unbiased estimators with minimum variance. The main computational machinery of kStatistics  is an algorithm for computing multi-index partitions. The same algorithm underlies the general-purpose multivariate Fa di Bruno's formula, which therefore has been included in the last release of the package. This formula gives the coefficients of formal power series compositions as well as the partial derivatives of multivariable function compositions. One of the most significant applications of this formula is the possibility to generate many well-known polynomial families as special cases. So, in the package, there are special functions for generating very popular polynomial families, such as the  Bell polynomials. However, further families can be obtained, for suitable choices of the formal power series involved in the composition or when suitable symbolic strategies are employed. In both cases, we give examples on how to modify the `R` codes of the package to accomplish this task. Future developments are addressed at the end of the paper</p>
</div>
</a>
<a href="articles/RJ-2022-037/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 11, 2022</div>
<div class="dt-authors">
<div class="dt-author">Jenny Farmer</div>
<div class="dt-author">Donald Jacobs</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>PDFEstimator: An R Package for Density Estimation and Analysis</h2>
<div class="dt-tags"></div>
<p>This article presents *PDFEstimator*, an R package for nonparametric probability density estimation and analysis, as both a practical enhancement and alternative to kernel-based estimators. *PDFEstimator* creates fast, highly accurate, data-driven probability density estimates for continuous random data through an intuitive interface. Excellent results are obtained for a diverse set of data distributions ranging from 10 to $10^6$ samples when invoked with default parameter definitions in the absence of user directives. Additionally, the package contains methods for assessing the quality of any estimate, including robust plotting functions for detailed visualization and trouble-shooting. Usage of *PDFEstimator* is illustrated through a variety of examples, including comparisons to several kernel density methods.</p>
</div>
</a>
<a href="articles/RJ-2022-038/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 11, 2022</div>
<div class="dt-authors">
<div class="dt-author">D. Jan van der Laan</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>reclin2: a Toolkit for Record Linkage and Deduplication</h2>
<div class="dt-tags"></div>
<p>The goal of record linkage and deduplication is to detect which records belong to the same object in data sets where the identifiers of the objects contain errors and missing values. The main design considerations of *reclin2* are: modularity/flexibility, speed and the ability to handle large data sets. The first points makes it easy for users to extend the package with custom process steps. This flexibility is obtained by using simple data structures and by following as close as possible common interfaces in R. For large problems it is possible to distribute the work over multiple worker nodes. A benchmark comparison to other record linkage packages for R, shows that for this specific benchmark, the *fastLink* package performs best. However, this package only performs one specific type of record linkage model. The performance of *reclin2* is not far behind the of *fastLink* while allowing for much greater flexibility.</p>
</div>
</a>
<a href="articles/RJ-2022-039/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 11, 2022</div>
<div class="dt-authors">
<div class="dt-author">Javier Alcaraz</div>
<div class="dt-author">Laura Anton-Sanchez</div>
<div class="dt-author">Juan Francisco Monge</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The Concordance Test, an Alternative to Kruskal-Wallis Based on the Kendall-tau Distance: An R Package</h2>
<div class="dt-tags"></div>
<p>The Kendall rank correlation coefficient, based on the Kendall-$\tau$ distance, is used to measure the ordinal association between two measurements. In this paper, we introduce a new coefficient also based on the Kendall-$\tau$ distance, the Concordance coefficient, and a test to measure whether different samples come from the same distribution. This work also presents a new R package, *ConcordanceTest*, with the implementation of the proposed coefficient. We illustrate the use of the Concordance coefficient to measure the ordinal association between quantity and quality measures when two or more samples are considered. In this sense, the Concordance coefficient can be seen as a generalization of the Kendall rank correlation coefficient and an alternative to the non-parametric mean rank-based methods for comparing two or more samples. A comparison of the proposed Concordance coefficient and the classical Kruskal-Wallis statistic is presented through a comparison of the exact distributions of both statistics.</p>
</div>
</a>
<a href="articles/RJ-2022-040/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 11, 2022</div>
<div class="dt-authors">
<div class="dt-author">Imke Mayer</div>
<div class="dt-author">Aude Sportisse</div>
<div class="dt-author">Julie Josse</div>
<div class="dt-author">Nicholas Tierney</div>
<div class="dt-author">Nathalie Vialaneix</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>R-miss-tastic: a unified platform for missing values methods and workflows</h2>
<div class="dt-tags"></div>
<p>Missing values are unavoidable when working with data. Their occurrence is exacerbated as more data from different sources become available. However, most statistical models and visualization methods require complete data, and improper handling of missing data results in information loss or biased analyses. Since the seminal work of Rubin (1976), a burgeoning literature on missing values has arisen, with heterogeneous aims and motivations. This led to the development of various methods, formalizations, and tools. For practitioners, however, it remains a challenge to decide which method is most appropriate for their problem, in part because this topic is not systematically covered in statistics or data science curricula. To help address this challenge, we have launched the `R-miss-tastic` platform, which aims to provide an overview of standard missing values problems, methods, and relevant implementations of methodologies. Beyond gathering and organizing a large majority of the material on missing data (bibliography, courses, tutorials, implementations), `R-miss-tastic` covers the development of standardized analysis workows. Indeed, we have developed several pipelines in R and Python to allow for hands-on illustration of and recommendations on missing values handling in various statistical tasks such as matrix completion, estimation, and prediction, while ensuring reproducibility of the analyses. Finally, the platform is dedicated to users who analyze incomplete data, researchers who want to compare their methods and search for an up-to-date bibliography, and teachers who are looking for didactic materials (notebooks, recordings, lecture notes).</p>
</div>
</a>
<a href="articles/RJ-2022-022/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 4, 2022</div>
<div class="dt-authors">
<div class="dt-author">Samuel Iddi</div>
<div class="dt-author">Michael C Donohue</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Power and Sample Size for Longitudinal Models in R -- The longpower Package and Shiny App</h2>
<div class="dt-tags"></div>
<p>Longitudinal studies are ubiquitous in medical and clinical research. Sample size computations are critical to ensure that these studies are sufficiently powered to provide reliable and valid inferences. There are several methodologies for calculating sample sizes for longitudinal studies that depend on many considerations including the study design features, outcome type and distribution, and proposed analytical methods. We briefly review the literature and describe sample size formulas for continuous longitudinal data. We then apply the methods using example studies comparing treatment versus control groups in randomized trials assessing treatment effect on clinical outcomes. We also introduce a Shiny app that we developed to assist researchers with obtaining required sample sizes for longitudinal studies by allowing users to enter required pilot estimates. For Alzheimer's studies, the app can estimate required pilot parameters using data from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Illustrative examples are used to demonstrate how the package and app can be used to generate sample size and power curves. The package and app are designed to help researchers easily assess the operating characteristics of study designs for Alzheimer's clinical trials and other research studies with longitudinal continuous outcomes. Data used in preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu).</p>
</div>
</a>
<a href="articles/RJ-2022-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 27, 2022</div>
<div class="dt-authors">
<div class="dt-author">Jakub Winiewski</div>
<div class="dt-author">Przemysaw Biecek</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2022-019/table1.png"/>
</div>
<div class="description">
<h2>fairmodels: a Flexible Tool for Bias Detection, Visualization, and Mitigation in Binary Classification Models</h2>
<div class="dt-tags"></div>
<p>Machine learning decision systems are becoming omnipresent in our lives. From dating apps to rating loan seekers, algorithms affect both our well-being and future. Typically, however, these systems are not infallible. Moreover, complex predictive models are eager to learn social biases present in historical data that may increase discrimination. If we want to create models responsibly, we need tools for in-depth validation of models also from potential discrimination. This article introduces an R package fairmodels that helps to validate fairness and eliminate bias in binary classification models quickly and flexibly. The fairmodels package offers a model-agnostic approach to bias detection, visualization, and mitigation. The implemented functions and fairness metrics enable model fairness validation from different perspectives. In addition, the package includes a series of methods for bias mitigation that aim to diminish the discrimination in the model.  The package is designed to examine a single model and facilitate comparisons between multiple models.</p>
</div>
</a>
<a href="articles/RJ-2022-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 22, 2022</div>
<div class="dt-authors">
<div class="dt-author">Isabel Casas</div>
<div class="dt-author">Rubn Fernndez-Casal</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>tvReg: Time-varying Coefficients in Multi-Equation Regression in R</h2>
<div class="dt-tags"></div>
<p>This article explains the usage of R package [*tvReg*](https://CRAN.R-project.org/package=tvReg), publicly available for download from the Comprehensive R Archive Network, via its application to economic and finance problems. The six basic functions in this package cover the kernel estimation of semiparametric panel data, seemingly unrelated equations, vector autoregressive, impulse response, and linear regression models whose coefficients may vary with time or any random variable. Moreover, this package provides methods for the graphical display of results, forecast, prediction, extraction of the residuals and fitted values, bandwidth selection and nonparametric estimation of the time-varying variance-covariance matrix of the error term. Applications to risk management, portfolio management, asset management and monetary policy are used as examples of these functions usage.</p>
</div>
</a>
<a href="articles/RJ-2022-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 22, 2022</div>
<div class="dt-authors">
<div class="dt-author">Tianhui Zhou</div>
<div class="dt-author">Guangyu Tong</div>
<div class="dt-author">Fan Li</div>
<div class="dt-author">Laine E. Thomas</div>
<div class="dt-author">Fan Li</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>PSweight: An R Package for Propensity Score Weighting Analysis</h2>
<div class="dt-tags"></div>
<p>Propensity score weighting is an important tool for comparative effectiveness research. Besides the inverse probability of treatment weights (IPW), recent development has introduced a general class of balancing weights, corresponding to alternative target populations and estimands. In particular, the overlap weights (OW) lead to optimal covariate balance and estimation efficiency, and a target population of scientific and policy interest. We develop the R package [*PSweight*](https://CRAN.R-project.org/package=PSweight) to provide a comprehensive design and analysis platform for causal inference based on propensity score weighting. *PSweight* supports (i) a variety of balancing weights, (ii) binary and multiple treatments, (iii) simple and augmented weighting estimators, (iv) nuisance-adjusted sandwich variances, and (v) ratio estimands. *PSweight* also provides diagnostic tables and graphs for covariate balance assessment. We demonstrate the functionality of the package using a data example from the National Child Development Survey (NCDS), where we evaluate the causal effect of educational attainment on income.</p>
</div>
</a>
<a href="articles/RJ-2022-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 22, 2022</div>
<div class="dt-authors">
<div class="dt-author">Jongmin Lee</div>
<div class="dt-author">Jang-Hyun Kim</div>
<div class="dt-author">Hee-Seok Oh</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>spherepc: An R Package for Dimension Reduction on a Sphere</h2>
<div class="dt-tags"></div>
<p>Dimension reduction is a technique that can compress given data and reduce noise. Recently, a dimension reduction technique on spheres, called spherical principal curves (SPC), has been proposed. SPC fits a curve that passes through the middle of data with a stationary property on spheres. In addition, a study of local principal geodesics (LPG) is considered to identify the complex structure of data. Through the description and implementation of various examples, this paper introduces an R package [*spherepc*](https://CRAN.R-project.org/package=spherepc) for dimension reduction of data lying on a sphere, including existing methods, SPC and LPG.</p>
</div>
</a>
<a href="articles/RJ-2022-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2022</div>
<div class="dt-authors">
<div class="dt-author">Lukas Baumann</div>
<div class="dt-author">Maximilian Pilz</div>
<div class="dt-author">Meinhard Kieser</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>blindrecalc - An R Package for Blinded Sample Size Recalculation</h2>
<div class="dt-tags"></div>
<p>Besides the type 1 and type 2 error rate and the clinically relevant effect size, the sample size of a clinical trial depends on so-called nuisance parameters for which the concrete values are usually unknown when a clinical trial is planned. When the uncertainty about the magnitude of these parameters is high, an internal pilot study design with a blinded sample size recalculation can be used to achieve the target power even when the initially assumed value for the nuisance parameter is wrong. In this paper, we present the R-package *blindrecalc* that helps with planning a clinical trial with such a design by computing the operating characteristics and the distribution of the total sample size under different true values of the nuisance parameter. We implemented methods for continuous and binary outcomes in the superiority and the non-inferiority setting.</p>
</div>
</a>
<a href="articles/RJ-2022-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2022</div>
<div class="dt-authors">
<div class="dt-author">Halaleh Kamari</div>
<div class="dt-author">Sylvie Huet</div>
<div class="dt-author">Marie-Luce Taupin</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>RKHSMetaMod: An R Package to Estimate the Hoeffding Decomposition of a Complex Model by Solving RKHS Ridge Group Sparse Optimization Problem</h2>
<div class="dt-tags"></div>
<p>In this paper, we propose an R package, called [*RKHSMetaMod*](https://CRAN.R-project.org/package=RKHSMetaMod), that implements a procedure for estimating a meta-model of a complex model. The meta-model approximates the Hoeffding decomposition of the complex model and allows us to perform sensitivity analysis on it. It belongs to a reproducing kernel Hilbert space that is constructed as a direct sum of Hilbert spaces. The estimator of the meta-model is the solution of a penalized empirical least-squares minimization with the sum of the Hilbert norm and the empirical $L^2$-norm. This procedure, called RKHS ridge group sparse, allows both to select and estimate the terms in the Hoeffding decomposition, and therefore, to select and estimate the Sobol indices that are non-zero. The [*RKHSMetaMod*](https://CRAN.R-project.org/package=RKHSMetaMod) package provides an interface from the R statistical computing environment to the C++ libraries *Eigen* and *GSL*. In order to speed up the execution time and optimize the storage memory, except for a function that is written in R, all of the functions of this package are written using the efficient C++ libraries through [*RcppEigen*](https://CRAN.R-project.org/package=RcppEigen) and [*RcppGSL*](https://CRAN.R-project.org/package=RcppGSL) packages. These functions are then interfaced in the R environment in order to propose a user-friendly package.</p>
</div>
</a>
<a href="articles/RJ-2022-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2022</div>
<div class="dt-authors">
<div class="dt-author">Cristiana Vlcea</div>
<div class="dt-author">Liliana Popescu</div>
<div class="dt-author">Alin Clincea</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Measuring the Extent and Patterns of Urban Shrinkage for Small Towns Using R</h2>
<div class="dt-tags"></div>
<p>Urban shrinking is a phenomenon as common as urban expansion nowadays and it affects urban settlements of all sizes, especially from developed and industrialized countries in Europe, America and Asia. The paper aims to assess the patterns of shrinkage for small and medium sized towns in Oltenia region (Romania), considering demographic, economic and social indicators with a methodological approach which considers the use of different functions and applications of R packages. Thirteen selected indicators are analysed to perform the multivariate analysis on Principal Component Analysis using the `prcomp()` function and the [*ggplot2*](https://CRAN.R-project.org/package=ggplot2) package to visualize the patterns of urban shrinkage. Two composite indicators were additionally created to measure the extent of urban shrinkage: CSI (Composite Shrinking Index) and RDC (Regional Demographic Change) for two-time intervals. Based on the CSI, three major categories of shrinking were observed: persistent shrinkage, mild shrinking or slow evolution toward shrinking, where the vast majority of towns are found (including mining towns, where there still is a delayed restructuring of state-owned enterprises, and towns characterised by the agrarization of local economies), and stagnant/stabilized shrinkage.</p>
</div>
</a>
<a href="articles/RJ-2022-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2022</div>
<div class="dt-authors">
<div class="dt-author">Camille J. Hochheimer, PhD</div>
<div class="dt-author">Roy T. Sabo, PhD</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>cpsurvsim: An R Package for Simulating Data from Change-Point Hazard Distributions</h2>
<div class="dt-tags"></div>
<p>Change-point hazard models have several practical applications, including modeling processes such as cancer mortality rates and disease progression. While the inverse cumulative distribution function (CDF) method is commonly used for simulating data, we demonstrate the shortcomings of this approach when simulating data from change-point hazard distributions with more than a scale parameter. We propose an alternative method of simulating this data that takes advantage of the memoryless property of survival data and introduce the R package *cpsurvsim* which implements both simulation methods. The functions of *cpsurvsim* are discussed, demonstrated, and compared.</p>
</div>
</a>
<a href="articles/RJ-2022-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2022</div>
<div class="dt-authors">
<div class="dt-author">Chia-Yi Yen</div>
<div class="dt-author">Mia Huai-Wen Chang</div>
<div class="dt-author">Chung-hong Chan</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>A Computational Analysis of the Dynamics of R Style Based on 108 Million Lines of Code from All CRAN Packages in the Past 21 Years</h2>
<div class="dt-tags"></div>
<p>The flexibility of R and the diversity of the R community leads to a large number of programming styles applied in R packages. We have analyzed 108 million lines of R code from CRAN and quantified the evolution in popularity of 12 style-elements from 1998 to 2019. We attribute 3 main factors that drive changes in programming style: the effect of style-guides, the effect of introducing new features, and the effect of editors. We observe in the data that a consensus in programming style is forming, such as using lower snake case for function names (e.g. softplus_func) and \&lt;- rather than = for assignment.</p>
</div>
</a>
<a href="articles/RJ-2022-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2022</div>
<div class="dt-authors">
<div class="dt-author">Zebulun Arendsee</div>
<div class="dt-author">Jennifer Chang</div>
<div class="dt-author">Eve Wurtele</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>rmonad: pipelines you can compute on</h2>
<div class="dt-tags"></div>
<p>The [*rmonad*](https://CRAN.R-project.org/package=rmonad) package presents a monadic pipeline toolset for chaining functions into stateful, branching pipelines. As functions in the pipeline are run, their results are merged into a graph of all past operations. The resulting structure allows downstream computation on node documentation, intermediate data, performance stats, and any raised messages, warnings or errors, as well as the final results. [*rmonad*](https://CRAN.R-project.org/package=rmonad) is a novel approach to designing reproducible, well-documented, and maintainable workflows in R.</p>
</div>
</a>
<a href="articles/RJ-2022-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2022</div>
<div class="dt-authors">
<div class="dt-author">Hassan Pazira</div>
<div class="dt-author">Luigi Augugliaro</div>
<div class="dt-author">Ernst C. Wit</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>A Software Tool For Sparse Estimation Of A General Class Of High-dimensional GLMs</h2>
<div class="dt-tags"></div>
<p>Generalized linear models are the workhorse of many inferential problems. Also in the modern era with high-dimensional settings, such models have been proven to be effective exploratory tools. Most attention has been paid to Gaussian, binomial and Poisson settings, which have efficient computational implementations and where either the dispersion parameter is largely irrelevant or absent. However, general GLMs have dispersion parameters $\phi$ that affect the value of the log-likelihood. This in turn, affects the value of various information criteria such as AIC and BIC, and has a considerable impact on the computation and selection of the optimal model. The R-package [*dglars*](https://CRAN.R-project.org/package=dglars) is one of the standard packages to perform high-dimensional analyses for GLMs. Being based on fundamental likelihood considerations, rather than arbitrary penalization, it naturally extends to the general GLM setting. In this paper, we present an improved predictor-corrector (IPC) algorithm for computing the differential geometric least angle regression (dgLARS) solution curve, proposed in [@Augug13] and [@pazira]. We describe the implementation of a stable estimator of the dispersion parameter proposed in [@pazira] for high-dimensional exponential dispersion models. A simulation study is conducted to test the performance of the proposed methods and algorithms. We illustrate the methods using an example. The described improvements have been implemented in a new version of the R-package [*dglars*](https://CRAN.R-project.org/package=dglars).</p>
</div>
</a>
<a href="articles/RJ-2022-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2022</div>
<div class="dt-authors">
<div class="dt-author">Riko Kelter</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>bayesanova: An R package for Bayesian Inference in the Analysis of Variance via Markov Chain Monte Carlo in Gaussian Mixture Models</h2>
<div class="dt-tags"></div>
<p>This paper introduces the R package [*bayesanova*](https://CRAN.R-project.org/package=bayesanova), which performs Bayesian inference in the analysis of variance (ANOVA). Traditional ANOVA based on null hypothesis significance testing (NHST) is prone to overestimating effects and stating effects if none are present. Bayesian ANOVAs developed so far are based on Bayes factors (BF), which also enforce a hypothesis testing stance. Instead, the Bayesian ANOVA implemented in *bayesanova* focusses on effect size estimation and is based on a Gaussian mixture with known allocations, for which full posterior inference for the component parameters is implemented via Markov-Chain-Monte-Carlo (MCMC). Inference for the difference in means, standard deviations and effect sizes between each of the groups is obtained automatically. Estimation of the parameters instead of hypothesis testing is embraced via the region of practical equivalence (ROPE), and helper functions provide checks of the model assumptions and visualization of the results.</p>
</div>
</a>
<a href="articles/RJ-2022-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2022</div>
<div class="dt-authors">
<div class="dt-author">Sami Aldag</div>
<div class="dt-author">Dogukan Topcuoglu</div>
<div class="dt-author">Gul Inan</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Revisiting Historical Bar Graphics on Epidemics in the Era of R ggplot2</h2>
<div class="dt-tags"></div>
<p>This study is motivated by an article published in a local history magazine on "Pandemics in the History". That article was also motivated by a government report involving several statistical graphics which were drawn by hand in 1938 and used to summarize official statistics on epidemics occurred between the years 1923 and 1937. Due to the aesthetic information design available on these historical graphs, in this study, we would like to investigate how graphical elements of the graphs such as titles, axis lines, axis tick marks, tick mark labels, colors, and data values are presented on these graphics and how to reproduce these historical graphics via well-known data visualization package [*ggplot2*](https://CRAN.R-project.org/package=ggplot2) in our era.</p>
</div>
</a>
<a href="articles/RJ-2022-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2022</div>
<div class="dt-authors">
<div class="dt-author">Cansu Alakus</div>
<div class="dt-author">Denis Larocque</div>
<div class="dt-author">Aurlie Labbe</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>RFpredInterval: An R Package for Prediction Intervals with Random Forests and Boosted Forests</h2>
<div class="dt-tags"></div>
<p>Like many predictive models, random forests provide point predictions for new observations. Besides the point prediction, it is important to quantify the uncertainty in the prediction. Prediction intervals provide information about the reliability of the point predictions. We have developed a comprehensive R package, [*RFpredInterval*](https://CRAN.R-project.org/package=RFpredInterval), that integrates 16 methods to build prediction intervals with random forests and boosted forests. The set of methods implemented in the package includes a new method to build prediction intervals with boosted forests (PIBF) and 15 method variations to produce prediction intervals with random forests, as proposed by [@roy_prediction_2020]. We perform an extensive simulation study and apply real data analyses to compare the performance of the proposed method to ten existing methods for building prediction intervals with random forests. The results show that the proposed method is very competitive and, globally, outperforms competing methods.</p>
</div>
</a>
<a href="articles/RJ-2022-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2022</div>
<div class="dt-authors">
<div class="dt-author">Anders D. Sleire</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>etrm: Energy Trading and Risk Management in R</h2>
<div class="dt-tags"></div>
<p>This paper introduces [*etrm*](https://CRAN.R-project.org/package=etrm), an R package with tools for trading and financial risk management in energy markets. Contracts for electric power and natural gas differ from most other commodities due to the fact that physical delivery takes place over a time interval, and not at a specific point in time. There is typically strong seasonality, limited storage and transmission capacity and strong correlation between price and required volume. Such characteristics need to be taken into account when pricing contracts and managing financial risk related to energy procurement. Tools for these task are usually bundled into proprietary Energy Trading Risk Management (ETRM) systems delivered by specialized IT vendors. The [*etrm*](https://CRAN.R-project.org/package=etrm) package offers a transparent solution for building a forward price curve for energy commodities which is consistent with methods widely used in the industry. The user's fundamental market view may be combined with contract price quotes to form a forward curve that replicate current market prices, as described in @ollmar2003analysis and @benth2007extracting. [*etrm*](https://CRAN.R-project.org/package=etrm) also provides implementations of five portfolio insurance trading strategies for energy price risk management. The forward market curve and the energy price hedging strategies are core elements in an ETRM system, which to the best of the author's knowledge has not been previously available in the R ecosystem.</p>
</div>
</a>
<a href="articles/RJ-2022-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2022</div>
<div class="dt-authors">
<div class="dt-author">Pablo Cordero</div>
<div class="dt-author">Manuel Enciso</div>
<div class="dt-author">Domingo Lpez-Rodrguez</div>
<div class="dt-author">ngel Mora</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>fcaR, Formal Concept Analysis with R</h2>
<div class="dt-tags"></div>
<p>Formal concept analysis (FCA) is a solid mathematical framework to manage information based on logic and lattice theory. It defines two explicit representations of the knowledge present in a dataset as concepts and implications. This paper describes an R package called [*fcaR*](https://CRAN.R-project.org/package=fcaR) that implements FCA's core notions and techniques. Additionally, it implements the extension of FCA to fuzzy datasets and a simplification logic to develop automated reasoning tools. This package is the first to implement FCA techniques in R. Therefore, emphasis has been put on defining classes and methods that could be reusable and extensible by the community. Furthermore, the package incorporates an interface with the [*arules*](https://CRAN.R-project.org/package=arules) package, probably the most used package regarding association rules, closely related to FCA. Finally, we show an application of the use of the package to design a recommender system based on logic for diagnosis in neurological pathologies.</p>
</div>
</a>
<a href="articles/RJ-2022-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2022</div>
<div class="dt-authors">
<div class="dt-author">Itziar Fernndez</div>
<div class="dt-author">Alejandro Rodrguez-Collado</div>
<div class="dt-author">Yolanda Larriba</div>
<div class="dt-author">Adrin Lamela</div>
<div class="dt-author">Christian Canedo</div>
<div class="dt-author">Cristina Rueda</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>FMM: An R Package for Modeling Rhythmic Patterns in Oscillatory Systems</h2>
<div class="dt-tags"></div>
<p>This paper is dedicated to the R package *FMM* which implements a novel approach to describe rhythmic patterns in oscillatory signals. The frequency modulated (FMM) model is defined as a parametric signal plus a Gaussian noise, where the signal can be described as a single or a sum of waves. The FMM approach is flexible enough to describe a great variety of rhythmic patterns. The *FMM* package includes all required functions to fit and explore single and multi-wave FMM models, as well as a restricted version that allows equality constraints between parameters representing a priori knowledge about the shape to be included. Moreover, the *FMM* package can generate synthetic data and visualize the results of the fitting process. The potential of this methodology is illustrated with examples of such biological oscillations as the circadian rhythm in gene expression, the electrical activity of the heartbeat and the neuronal activity.</p>
</div>
</a>
<a href="articles/RJ-2022-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2022</div>
<div class="dt-authors">
<div class="dt-author">Yuanhua Feng</div>
<div class="dt-author">Thomas Gries</div>
<div class="dt-author">Sebastian Letmathe</div>
<div class="dt-author">Dominik Schulz</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The smoots Package in R for Semiparametric Modeling of Trend Stationary Time Series</h2>
<div class="dt-tags"></div>
<p>This paper is an introduction to the new package in R called [*smoots*](https://CRAN.R-project.org/package=smoots) (smoothing time series), developed for data-driven local polynomial smoothing of trend-stationary time series. Functions for data-driven estimation of the first and second derivatives of the trend are also built-in. It is first applied to monthly changes of the global temperature. The quarterly US-GDP series shows that this package can also be well applied to a semiparametric multiplicative component model for non-negative time series via the log-transformation. Furthermore, we introduced a semiparametric Log-GARCH and a semiparametric Log-ACD model, which can be easily estimated by the *smoots* package. Of course, this package applies to suitable time series from any other research area. The *smoots* package also provides a useful tool for teaching time series analysis, because many practical time series follow an additive or a multiplicative component model.</p>
</div>
</a>
<a href="articles/RJ-2022-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2022</div>
<div class="dt-authors">
<div class="dt-author">Andrea Bucci</div>
<div class="dt-author">Giulio Palomba</div>
<div class="dt-author">Eduardo Rossi</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>starvars: An R Package for Analysing Nonlinearities in Multivariate Time Series</h2>
<div class="dt-tags"></div>
<p>Although linear autoregressive models are useful to practitioners in different fields, often a nonlinear specification would be more appropriate in time series analysis. In general, there are many alternative approaches to nonlinearity modelling, one consists in assuming multiple regimes. Among the possible specifications that account for regime changes in the multivariate framework, smooth transition models are the most general, since they nest both linear and threshold autoregressive models. This paper introduces the [*starvars*](https://CRAN.R-project.org/package=starvars) package which estimates and predicts the Vector Logistic Smooth Transition model in a very general setting which also includes predetermined variables. In comparison to the existing R packages, *starvars* offers the estimation of the Vector Smooth Transition model both by maximum likelihood and nonlinear least squares. The package allows also to test for nonlinearity in a multivariate setting and detect the presence of common breaks. Furthermore, the package computes multi-step-ahead forecasts. Finally, an illustration with financial time series is provided to show its usage.</p>
</div>
</a>
<a href="articles/RJ-2022-020/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2022</div>
<div class="dt-authors">
<div class="dt-author">Allison M. Horst</div>
<div class="dt-author">Alison Presmanes Hill</div>
<div class="dt-author">Kristen B. Gorman</div>
</div>
</div>
<div class="thumbnail">
<img data-src="https://allisonhorst.github.io/palmerpenguins/logo.png"/>
</div>
<div class="description">
<h2>Palmer Archipelago Penguins Data in the palmerpenguins R Package - An Alternative to Anderson's Irises</h2>
<div class="dt-tags"></div>
<p>In 1935, Edgar Anderson collected size measurements for 150 flowers from three species of *Iris* on the Gasp Peninsula in Quebec, Canada. Since then, Anderson's *Iris* observations have become a classic dataset in statistics, machine learning, and data science teaching materials. It is included in the base R datasets package as `iris`, making it easy for users to access without knowing much about it. However, the lack of data documentation, presence of non-intuitive variables (e.g. "sepal width"), and perfectly balanced groups with zero missing values make `iris` an inadequate and stale dataset for teaching and learning modern data science skills. Users would benefit from working with a more representative, real-world environmental dataset with a clear link to current scientific research. Importantly, Andersons *Iris* data appeared in a 1936 publication by R. A. Fisher in the *Annals of Eugenics* (which is often the first-listed citation for the dataset), inextricably linking `iris` to eugenics research. Thus, a modern alternative to `iris` is needed. In this paper, we introduce the palmerpenguins R package [@R-palmerpenguins], which includes body size measurements collected from 2007 - 2009 for three species of *Pygoscelis* penguins that breed on islands throughout the Palmer Archipelago, Antarctica. The `penguins` dataset in palmerpenguins provides an approachable, charismatic, and near drop-in replacement for `iris` with topical relevance for polar climate change and environmental impacts on marine predators. Since the release on CRAN in July 2020, the palmerpenguins package has been downloaded over 462,000 times, highlighting the demand and widespread adoption of this viable `iris` alternative.  We directly compare the `iris` and `penguins` datasets for selected analyses to demonstrate that R users, in particular teachers and learners currently using `iris`, can switch to the Palmer Archipelago penguins for many use cases including data wrangling, visualization, linear modeling, multivariate analysis (e.g., PCA), cluster analysis and classification (e.g., by k-means).</p>
</div>
</a>
<a href="articles/RJ-2022-021/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2022</div>
<div class="dt-authors">
<div class="dt-author">Chak Hau Michael Tso</div>
<div class="dt-author">Michael Hollaway</div>
<div class="dt-author">Rebecca Killick</div>
<div class="dt-author">Peter Henrys</div>
<div class="dt-author">Don Monteith</div>
<div class="dt-author">John Watkins</div>
<div class="dt-author">Gordon Blair</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2022-021/distill-preview.png"/>
</div>
<div class="description">
<h2>Advancing Reproducible Research by Publishing R Markdown Notebooks as Interactive Sandboxes Using the learnr Package</h2>
<div class="dt-tags"></div>
<p>Various R packages and best practices have played a pivotal role to promote the Findability, Accessibility, Interoperability, and Reuse (FAIR) principles of open science. For example, (1) well-documented R scripts and notebooks with rich narratives are deposited at a trusted data centre, (2) R Markdown interactive notebooks can be run on-demand as a web service, and (3) R Shiny web apps provide nice user interfaces to explore research outputs. However, notebooks require users to go through the entire analysis, while Shiny apps do not expose the underlying code and require extra work for UI design. We propose using the learnr package to expose certain code chunks in R Markdown so that users can readily experiment with them in guided, editable, isolated, executable, and resettable code sandboxes. Our approach does not replace the existing use of notebooks and Shiny apps, but it adds another level of abstraction between them to promote reproducible science.</p>
</div>
</a>
<a href="articles/RJ-2021-106/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 4, 2022</div>
<div class="dt-authors">
<div class="dt-author">Anthony-Alexander Christidis</div>
<div class="dt-author">R. Doug Martin</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-106/preview.png"/>
</div>
<div class="description">
<h2>RPESE: Risk and Performance Estimators Standard Errors with Serially Dependent Data</h2>
<div class="dt-tags"></div>
<p>The R package [*RPESE*](https://CRAN.R-project.org/package=RPESE) (Risk and Performance Estimators Standard Errors) implements a new method for computing accurate standard errors of risk and performance estimators when returns are serially dependent. The new method makes use of the representation of a risk or performance estimator as a summation of a time series of influence-function (IF) transformed returns, and computes estimator standard errors using a sophisticated method of estimating the spectral density at frequency zero of the time series of IF-transformed returns. Two additional packages used by [*RPESE*](https://CRAN.R-project.org/package=RPESE) are introduced, namely [*RPEIF*](https://CRAN.R-project.org/package=RPEIF) which computes and provides graphical displays of the IF of risk and performance estimators, and [*RPEGLMEN*](https://CRAN.R-project.org/package=RPEGLMEN) which implements a regularized Gamma generalized linear model polynomial fit to the periodogram of the time series of the IF-transformed returns. A Monte Carlo study shows that the new method provides more accurate estimates of standard errors for risk and performance estimators compared to well-known alternative methods in the presence of serial correlation.</p>
</div>
</a>
<a href="articles/RJ-2021-097/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Jinhui Yang</div>
<div class="dt-author">Lifeng Lin</div>
<div class="dt-author">Haitao Chu</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-097/preview.png"/>
</div>
<div class="description">
<h2>BayesSenMC: an R package for Bayesian Sensitivity Analysis of Misclassification</h2>
<div class="dt-tags"></div>
<p>In case--control studies, the odds ratio is commonly used to summarize the association between a binary exposure and a dichotomous outcome. However, exposure misclassification frequently appears in case--control studies due to inaccurate data reporting, which can produce bias in measures of association. In this article, we implement a Bayesian sensitivity analysis of misclassification to provide a full posterior inference on the corrected odds ratio under both non-differential and differential misclassification. We present an [R]{.sans-serif} [@R] package [*BayesSenMC*](https://CRAN.R-project.org/package=BayesSenMC), which provides user-friendly functions for its implementation. The usage is illustrated by a real data analysis on the association between bipolar disorder and rheumatoid arthritis.</p>
</div>
</a>
<a href="articles/RJ-2021-098/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Kexuan Yang</div>
<div class="dt-author">Sang Kyu Lee</div>
<div class="dt-author">Jun Zhao</div>
<div class="dt-author">Hyoung-Moon Kim</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>EMSS: New EM-type algorithms for the Heckman selection model in R</h2>
<div class="dt-tags"></div>
<p>When investigators observe non-random samples from populations, sample selectivity problems may occur. The Heckman selection model is widely used to deal with selectivity problems. Based on the EM algorithm, [@Zhaoetal:2020] developed three algorithms, namely, ECM, ECM(NR), and ECME(NR), which also have the EM algorithm's main advantages: stability and ease of implementation. This paper provides the implementation of these three new EM-type algorithms in the package *EMSS* and illustrates the usage of the package on several simulated and real data examples. The comparison between the maximum likelihood estimation method (MLE) and three new EM-type algorithms in robustness issues is further discussed.</p>
</div>
</a>
<a href="articles/RJ-2021-099/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Daro Ramos-Lpez</div>
<div class="dt-author">Ana D. Maldonado</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-099/preview.png"/>
</div>
<div class="description">
<h2>Analysis of Corneal Data in R with the rPACI Package</h2>
<div class="dt-tags"></div>
<p>In ophthalmology, the early detection of keratoconus is still a crucial problem. Placido disk corneal topographers are essential in clinical practice, and many indices for diagnosing corneal irregularities exist. The main goal of this work is to present the R package *rPACI*, providing several functions to handle and analyze corneal data. This package implements primary indices of corneal irregularity (based on geometrical properties) and compound indices built from the primary ones, either using a generalized linear model or as a Bayesian classifier using a hybrid Bayesian network and performing approximate inference. *rPACI* aims to make the analysis of corneal data accessible for practitioners and researchers in the field. Moreover, a *shiny* app was developed to use *rPACI* in any web browser in a truly user-friendly graphical interface without installing R or writing any R code. It is openly deployed at &lt;https://admaldonado.shinyapps.io/rPACI/&gt;.</p>
</div>
</a>
<a href="articles/RJ-2021-100/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">lvaro Briz-Redn</div>
<div class="dt-author">Francisco Martnez-Ruiz</div>
<div class="dt-author">Francisco Montes</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-100/preview.png"/>
</div>
<div class="description">
<h2>DRHotNet: An R package for detecting differential risk hotspots on a linear network</h2>
<div class="dt-tags"></div>
<p>One of the most common applications of spatial data analysis is detecting zones, at a certain scale, where a point-referenced event under study is especially concentrated. The detection of such zones, which are usually referred to as hotspots, is essential in certain fields such as criminology, epidemiology, or traffic safety. Traditionally, hotspot detection procedures have been developed over areal units of analysis. Although working at this spatial scale can be suitable enough for many research or practical purposes, detecting hotspots at a more accurate level (for instance, at the road segment level) may be more convenient sometimes. Furthermore, it is typical that hotspot detection procedures are entirely focused on the determination of zones where an event is (overall) highly concentrated. It is less common, by far, that such procedures focus on detecting zones where a specific type of event is overrepresented in comparison with the other types observed, which have been denoted as differential risk hotspots. The R package *DRHotNet* provides several functionalities to facilitate the detection of differential risk hotspots within a linear network. In this paper, *DRHotNet* is depicted, and its usage in the R console is shown through a detailed analysis of a crime dataset.</p>
</div>
</a>
<a href="articles/RJ-2021-101/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Ali Sabri Taylan</div>
<div class="dt-author">Guckan Yapar</div>
<div class="dt-author">Hanife Taylan Selamlar</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-101/preview.png"/>
</div>
<div class="description">
<h2>Automatic Time Series Forecasting with Ata Method in R: ATAforecasting Package</h2>
<div class="dt-tags"></div>
<p>Ata method is a new univariate time series forecasting method that provides innovative solutions to issues faced during the initialization and optimization stages of existing methods. The Ata method's forecasting performance is superior to existing methods in terms of easy implementation and accurate forecasting. It can be applied to non-seasonal or deseasonalized time series, where the deseasonalization can be performed via any preferred decomposition method. The R package [*ATAforecasting*](https://CRAN.R-project.org/package=ATAforecasting) was developed as a comprehensive toolkit for automatic time series forecasting. It focuses on modeling all types of time series components with any preferred Ata methods and handling seasonality patterns by utilizing some popular decomposition techniques. The *ATAforecasting* package allows researchers to model seasonality with STL, STLplus, TBATS, stR, and TRAMO/SEATS, and power family transformation and analyze the any time series with a simple Ata method and additive, multiplicative, damped trend the Ata methods and level fixed Ata trended methods. It offers functions for researchers and data analysts to model any type of time series data sets without requiring specialization. However, an expert user may use the functions that can model all possible time series behaviors. The package also incorporates types of model specifications and their graphs, uses different accuracy measures that surely increase the Ata method's performance.</p>
</div>
</a>
<a href="articles/RJ-2021-102/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Jeremy Gelb</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-102/preview.png"/>
</div>
<div class="description">
<h2>spNetwork: A Package for Network Kernel Density Estimation</h2>
<div class="dt-tags"></div>
<p>This paper introduces the new package [*spNetwork*](https://CRAN.R-project.org/package=spNetwork) that provides functions to perform Network Kernel Density Estimate analysis (NKDE). This method is an extension of the classical Kernel Density Estimate (KDE), a non parametric approach to estimate the intensity of a spatial process. More specifically, it adapts the KDE for cases when the study area is a network, constraining the location of events (such as accidents on roads, leaks in pipes, fish in rivers, etc.). We present and discuss in this paper the three main versions of NKDE: simple, discontinuous, and continuous that are implemented in [*spNetwork*](https://CRAN.R-project.org/package=spNetwork). We illustrate how to apply the three methods and map their results using a sample from a real dataset representing bike accidents in a central neighborhood of Montreal. We also describe the optimization techniques used to reduce calculation time and investigate their impacts when applying the three NKDE to a city-wide dataset.</p>
</div>
</a>
<a href="articles/RJ-2021-103/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Jouni Helske</div>
<div class="dt-author">Matti Vihola</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-103/preview.png"/>
</div>
<div class="description">
<h2>bssm: Bayesian Inference of Non-linear and Non-Gaussian State Space Models in R</h2>
<div class="dt-tags"></div>
<p>We present an R package [*bssm*](https://CRAN.R-project.org/package=bssm) for Bayesian non-linear/non-Gaussian state space modeling. Unlike the existing packages, *bssm* allows for easy-to-use approximate inference based on Gaussian approximations such as the Laplace approximation and the extended Kalman filter. The package also accommodates discretely observed latent diffusion processes. The inference is based on fully automatic, adaptive Markov chain Monte Carlo (MCMC) on the hyperparameters, with optional importance sampling post-correction to eliminate any approximation bias. The package also implements a direct pseudo-marginal MCMC and a delayed acceptance pseudo-marginal MCMC using intermediate approximations. The package offers an easy-to-use interface to define models with linear-Gaussian state dynamics with non-Gaussian observation models and has an [*Rcpp*](https://CRAN.R-project.org/package=Rcpp) interface for specifying custom non-linear and diffusion models.</p>
</div>
</a>
<a href="articles/RJ-2021-104/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Jean-Paul Fox</div>
<div class="dt-author">Konrad Klotzke</div>
<div class="dt-author">Duco Veen</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-104/preview.png"/>
</div>
<div class="description">
<h2>Generalized Linear Randomized Response Modeling using GLMMRR</h2>
<div class="dt-tags"></div>
<p>Randomized response (RR) designs are used to collect response data about sensitive behaviors (e.g., criminal behavior, sexual desires). The modeling of RR data is more complex since it requires a description of the RR process. For the class of generalized linear mixed models (GLMMs), the RR process can be represented by an adjusted link function, which relates the expected RR to the linear predictor for most common RR designs. The package *GLMMRR* includes modified link functions for four different cumulative distributions (i.e., logistic, cumulative normal, Gumbel, Cauchy) for GLMs and GLMMs, where the package *lme4* facilitates ML and REML estimation. The mixed modeling framework in *GLMMRR* can be used to jointly analyze data collected under different designs (e.g., dual questioning, multilevel, mixed mode, repeated measurements designs, multiple-group designs). Model-fit tests, tools for residual analyses, and plot functions to give support to a profound RR data analysis are added to the well-known features of the GLM and GLMM software (package *lme4*). Data of and Jann (2018) and Jann, and Diekmann (2014) are used to illustrate the methodology and software.</p>
</div>
</a>
<a href="articles/RJ-2021-105/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">H. Sherry Zhang</div>
<div class="dt-author">Dianne Cook</div>
<div class="dt-author">Ursula Laa</div>
<div class="dt-author">Nicolas Langren</div>
<div class="dt-author">Patricia Menndez</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-105/preview.png"/>
</div>
<div class="description">
<h2>Visual Diagnostics for Constrained Optimisation with Application to Guided Tours</h2>
<div class="dt-tags"></div>
<p>A guided tour helps to visualise high-dimensional data by showing low-dimensional projections along a projection pursuit optimisation path. Projection pursuit is a generalisation of principal component analysis in the sense that different indexes are used to define the interestingness of the projected data. While much work has been done in developing new indexes in the literature, less has been done on understanding the optimisation. Index functions can be noisy, might have multiple local maxima as well as an optimal maximum, and are constrained to generate orthonormal projection frames, which complicates the optimization. In addition, projection pursuit is primarily used for exploratory data analysis, and finding the local maxima is also useful. The guided tour is especially useful for exploration because it conducts geodesic interpolation connecting steps in the optimisation and shows how the projected data changes as a maxima is approached. This work provides new visual diagnostics for examining a choice of optimisation procedure based on the provision of a new data object which collects information throughout the optimisation. It has helped to diagnose and fix several problems with projection pursuit guided tour. This work might be useful more broadly for diagnosing optimisers and comparing their performance. The diagnostics are implemented in the R package [ferrn](https://github.com/huizezhang-sherry/ferrn).</p>
</div>
</a>
<a href="articles/RJ-2021-107/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Gamze Gven</div>
<div class="dt-author">kr Acta</div>
<div class="dt-author">Hatice amkar</div>
<div class="dt-author">Birdal enolu</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>RobustBF: An R Package for Robust Solution to the Behrens-Fisher Problem</h2>
<div class="dt-tags"></div>
<p>Welch's two-sample $t$-test based on least squares (LS) estimators is generally used to test the equality of two normal means when the variances are not equal. However, this test loses its power when the underlying distribution is not normal. In this paper, two different tests are proposed to test the equality of two long-tailed symmetric (LTS) means under heterogeneous variances. Adaptive modified maximum likelihood (AMML) estimators are used in developing the proposed tests since they are highly efficient under LTS distribution. An R package called [*RobustBF*](https://CRAN.R-project.org/package=RobustBF) is given to show the implementation of these tests. Simulated Type I error rates and powers of the proposed tests are also given and compared with Welch's $t$-test based on LS estimators via an extensive Monte Carlo simulation study.</p>
</div>
</a>
<a href="articles/RJ-2021-108/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 14, 2021</div>
<div class="dt-authors">
<div class="dt-author">Melina Vidoni</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Software Engineering and R Programming: A Call for Research</h2>
<div class="dt-tags"></div>
<p>Although R programming has been a part of research since its origins in the 1990s, few studies address scientific software development from a Software Engineering (SE) perspective. The past few years have seen unparalleled growth in the R community, and it is time to push the boundaries of SE research and R programming forwards. This paper discusses relevant studies that close this gap Additionally, it proposes a set of good practices derived from those findings aiming to act as a call-to-arms for both the R and RSE (Research SE) community to explore specific, interdisciplinary paths of research.</p>
</div>
</a>
<a href="articles/RJ-2021-109/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 14, 2021</div>
<div class="dt-authors">
<div class="dt-author">William Michael Landau</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>We Need Trustworthy R Packages</h2>
<div class="dt-tags"></div>
<p>There is a need for rigorous software engineering in R packages, and there is a need for new research to bridge scientific computing with more traditional computing. Automated tools, interdisciplinary graduate courses, code reviews, and a welcoming developer community will continue to democratize best practices. Democratized software engineering will improve the quality, correctness, and integrity of scientific software, and by extension, the disciplines that rely on it.</p>
</div>
</a>
<a href="articles/RJ-2021-110/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 14, 2021</div>
<div class="dt-authors">
<div class="dt-author">Malle Salmon</div>
<div class="dt-author">Karthik Ram</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The R Developer Community Does Have a Strong Software Engineering Culture</h2>
<div class="dt-tags"></div>
<p>There is a strong software engineering culture in the R developer community. We recommend creating, updating and vetting packages as well as keeping up with community standards. We invite contributions to the rOpenSci project, where participants can gain experience that will shape their work and that of their peers.</p>
</div>
</a>
<a href="articles/RJ-2021-111/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 14, 2021</div>
<div class="dt-authors">
<div class="dt-author">Simon Urbanek</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The R Quest: from Users to Developers</h2>
<div class="dt-tags"></div>
<p>R is not a programming language, and this produces the inherent dichotomy between analytics and software engineering. With the emergence of data science, the opportunity exists to bridge this gap, especially through teaching practices.</p>
</div>
</a>
<a href="articles/RJ-2021-112/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 14, 2021</div>
<div class="dt-authors">
<div class="dt-author">Melina Vidoni</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Rejoinder: Software Engineering and R Programming</h2>
<div class="dt-tags"></div>
<p>It is a pleasure to take part in such fruitful discussion about the relationship between Software Engineering and R programming, and what could be gain by allowing each to look more closely at the other. Several discussants make valuable arguments that ought to be further discussed.</p>
</div>
</a>
<a href="articles/RJ-2021-096/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Novia Permatasari</div>
<div class="dt-author">Azka Ubaidillah</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-096/preview.png"/>
</div>
<div class="description">
<h2>msae: An R Package of Multivariate Fay-Herriot Models for Small Area Estimation</h2>
<div class="dt-tags"></div>
<p>The paper introduces an R Package of multivariate Fay-Herriot models for small area estimation named *msae*. This package implements four types of Fay-Herriot models, including univariate Fay-Herriot model (model 0), multivariate Fay-Herriot model (model 1), autoregressive multivariate Fay-Herriot model (model 2), and heteroskedastic autoregressive multivariate Fay-Herriot model (model 3). It also contains some datasets generated based on multivariate Fay-Herriot models. We describe and implement functions through various practical examples. Multivariate Fay-Herriot models produce a more efficient parameter estimation than direct estimation and univariate model.</p>
</div>
</a>
<a href="articles/RJ-2021-048/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 10, 2021</div>
<div class="dt-authors">
<div class="dt-author">Henrik Bengtsson</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>A Unifying Framework for Parallel and Distributed Processing in R using Futures</h2>
<div class="dt-tags"></div>
<p>A future is a programming construct designed for concurrent and asynchronous evaluation of code, making it particularly useful for parallel processing. The *future* package implements the Future API for programming with futures in R. This minimal API provides sufficient constructs for implementing parallel versions of well-established, high-level map-reduce APIs. The future ecosystem supports exception handling, output and condition relaying, parallel random number generation, and automatic identification of globals lowering the threshold to parallelize code. The Future API bridges parallel frontends with parallel backends, following the philosophy that end-users are the ones who choose the parallel backend while the developer focuses on what to parallelize. A variety of backends exist, and third-party contributions meeting the specifications, which ensure that the same code works on all backends, are automatically supported. The future framework solves several problems not addressed by other parallel frameworks in R.</p>
</div>
</a>
<a href="articles/RJ-2021-087/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 25, 2021</div>
<div class="dt-authors">
<div class="dt-author">Thiago R. Santos</div>
<div class="dt-author">Dani Gamerman</div>
<div class="dt-author">Glaura C. Franco</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-087/preview.png"/>
</div>
<div class="description">
<h2>NGSSEML: Non-Gaussian State Space with Exact Marginal Likelihood</h2>
<div class="dt-tags"></div>
<p>The number of packages/software for Gaussian State Space models has
increased over recent decades. However, there are very few codes
available for non-Gaussian State Space (NGSS) models due to analytical
intractability that prevents exact calculations. One of the few
tractable exceptions is the family of NGSS with exact marginal
likelihood, named NGSSEML. In this work, we present the wide range of
data formats and distributions handled by NGSSEML and a package in the
R language to perform classical and Bayesian inference for them.
Special functions for filtering, forecasting, and smoothing procedures
and the exact calculation of the marginal likelihood function are
provided. The methods implemented in the package are illustrated for
count and volatility time series and some reliability/survival models,
showing that the codes are easy to handle. Therefore, the NGSSEML
family emerges as a simple and interesting option/alternative for
modeling non-Gaussian time-varying structures commonly encountered in
time series and reliability/survival studies.\
**Keywords**: Bayesian, classical inference, reliability, smoothing,
time series, software R</p>
</div>
</a>
<a href="articles/RJ-2021-088/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 19, 2021</div>
<div class="dt-authors">
<div class="dt-author">Shaobo Li</div>
<div class="dt-author">Xiaorui Zhu</div>
<div class="dt-author">Yuejie Chen</div>
<div class="dt-author">Dungang Liu</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-088/preview.png"/>
</div>
<div class="description">
<h2>PAsso: an R Package for Assessing Partial Association between Ordinal Variables</h2>
<div class="dt-tags"></div>
<p>Partial association, the dependency between variables after adjusting for a set of covariates, is an important statistical notion for scientific research. However, if the variables of interest are ordered categorical data, the development of statistical methods and software for assessing their partial association is limited. Following the framework established by @liu2020jasa, we develop an R package [*PAsso*](https://CRAN.R-project.org/package=PAsso) for assessing **P**artial **Asso**ciations between ordinal variables. The package provides various functions that allow users to perform a wide spectrum of assessments, including quantification, visualization, and hypothesis testing. In this paper, we discuss the implementation of *PAsso* in detail and demonstrate its utility through an analysis of the 2016 American National Election Study.</p>
</div>
</a>
<a href="articles/RJ-2021-089/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 19, 2021</div>
<div class="dt-authors">
<div class="dt-author">Viviane Philipps</div>
<div class="dt-author">Boris P. Hejblum</div>
<div class="dt-author">Mlanie Prague</div>
<div class="dt-author">Daniel Commenges</div>
<div class="dt-author">Ccile Proust-Lima</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-089/preview.png"/>
</div>
<div class="description">
<h2>Robust and Efficient Optimization Using a Marquardt-Levenberg Algorithm with R Package marqLevAlg</h2>
<div class="dt-tags"></div>
<p>Implementations in R of classical general-purpose algorithms for local optimization generally have two major limitations which cause difficulties in applications to complex problems: too loose convergence criteria and too long calculation time. By relying on a Marquardt-Levenberg algorithm (MLA), a Newton-like method particularly robust for solving local optimization problems, we provide with marqLevAlg package an efficient and general-purpose local optimizer which (i) prevents convergence to saddle points by using a stringent convergence criterion based on the relative distance to minimum/maximum in addition to the stability of the parameters and of the objective function; and (ii) reduces the computation time in complex settings by allowing parallel calculations at each iteration. We demonstrate through a variety of cases from the literature that our implementation reliably and consistently reaches the optimum (even when other optimizers fail) and also largely reduces computational time in complex settings through the example of maximum likelihood estimation of different sophisticated statistical models.</p>
</div>
</a>
<a href="articles/RJ-2021-090/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 19, 2021</div>
<div class="dt-authors">
<div class="dt-author">Zhixin Lun</div>
<div class="dt-author">Ravindra Khattree</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-090/preview.png"/>
</div>
<div class="description">
<h2>An R package for Non-Normal Multivariate Distributions: Simulation and Probability Calculations from Multivariate Lomax (Pareto Type II) and Other Related Distributions</h2>
<div class="dt-tags"></div>
<p>Convenient and easy-to-use programs are readily available in R to simulate data from and probability calculations for several common multivariate distributions such as normal and $t$. However, functions for doing so from other less common multivariate distributions, especially those which are asymmetric, are not as readily available, either in R or otherwise. We introduce the R package *NonNorMvtDist* to generate random numbers from multivariate Lomax distribution, which constitutes a very flexible family of skewed multivariate distributions. Further, by applying certain useful properties of multivariate Lomax distribution, multivariate cases of generalized Lomax, Mardia's Pareto of Type I, Logistic, Burr, Cook-Johnson's uniform, $F$, and inverted beta can be also considered, and random numbers from these distributions can be generated. Methods for the probability and the equicoordinate quantile calculations for all these distributions are then provided. This work substantially enriches the existing R toolbox for nonnormal or nonsymmetric multivariate probability distributions.</p>
</div>
</a>
<a href="articles/RJ-2021-091/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 19, 2021</div>
<div class="dt-authors">
<div class="dt-author">Javier Rodrguez-Cuadrado</div>
<div class="dt-author">Juan C. Laria</div>
<div class="dt-author">David Delgado-Gmez</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-091/preview.png"/>
</div>
<div class="description">
<h2>cat.dt: An R package for fast construction of accurate Computerized Adaptive Tests using Decision Trees</h2>
<div class="dt-tags"></div>
<p>This article introduces the *cat.dt* package for the creation of Computerized Adaptive Tests (CATs). Unlike existing packages, the *cat.dt* package represents the CAT in a Decision Tree (DT) structure. This allows building the test before its administration, ensuring that the creation time of the test is independent of the number of participants. Moreover, to accelerate the construction of the tree, the package controls its growth by joining nodes with similar estimations or distributions of the ability level and uses techniques such as message passing and pre-calculations. The constructed tree, as well as the estimation procedure, can be visualized using the graphical tools included in the package. An experiment designed to evaluate its performance shows that the *cat.dt* package drastically reduces computational time in the creation of CATs without compromising accuracy.</p>
</div>
</a>
<a href="articles/RJ-2021-092/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 19, 2021</div>
<div class="dt-authors">
<div class="dt-author">Tianhai Zu</div>
<div class="dt-author">Yan Yu</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-092/preview.png"/>
</div>
<div class="description">
<h2>SIQR: An R Package for Single-index Quantile Regression</h2>
<div class="dt-tags"></div>
<p>We develop an R package *SIQR* that implements the single-index quantile regression (SIQR) models via an efficient iterative local linear approach in [@wu_single-index_2010]. Single-index quantile regression models are important tools in semiparametric regression to provide a comprehensive view of the conditional distributions of a response variable. It is especially useful when the data is heterogeneous or heavy-tailed. The package provides functions that allow users to fit SIQR models, predict, provide standard errors of the single-index coefficients via bootstrap, and visualize the estimated univariate function. We apply the R package *SIQR* to a well-known Boston Housing data.</p>
</div>
</a>
<a href="articles/RJ-2021-093/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 19, 2021</div>
<div class="dt-authors">
<div class="dt-author">Yuliang Xu</div>
<div class="dt-author">Shuo Shuo Liu</div>
<div class="dt-author">Grace Y. Yi</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-093/preview.png"/>
</div>
<div class="description">
<h2>mgee2: An R package for marginal analysis of longitudinal ordinal data with misclassified responses and covariates</h2>
<div class="dt-tags"></div>
<p>Marginal methods have been widely used for analyzing longitudinal ordinal data due to their simplicity in model assumptions, robustness in inference results, and easiness in the implementation. However, they are often inapplicable in the presence of measurement errors in the variables. Under the setup of longitudinal studies with ordinal responses and covariates subject to misclassification, @Chen2013 developed marginal methods for misclassification adjustments using the second-order estimating equations and proposed a two-stage estimation approach when the validation subsample is available. Parameter estimation is conducted through the Newton-Raphson algorithm, and the asymptotic distribution of the estimators is established. While the methods of @Chen2013 can successfully correct the misclassification effects, its implementation is not accessible to general users due to the lack of a software package. In this paper, we develop an R package, [*mgee2*](https://CRAN.R-project.org/package=mgee2), to implement the marginal methods proposed by @Chen2013. To evaluate the performance and illustrate the features of the package, we conduct numerical studies.</p>
</div>
</a>
<a href="articles/RJ-2021-094/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 19, 2021</div>
<div class="dt-authors">
<div class="dt-author">Jinpu Li</div>
<div class="dt-author">Ryan P. Knigge</div>
<div class="dt-author">Kaiyi Chen</div>
<div class="dt-author">Emily V. Leary, Ph.D.</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-094/preview.png"/>
</div>
<div class="description">
<h2>PASSED: Calculate Power and Sample Size for Two Sample Tests</h2>
<div class="dt-tags"></div>
<p>Power and sample size estimation are critical aspects of study design to demonstrate minimized risk for subjects and justify the allocation of time, money, and other resources. Researchers often work with response variables that take the form of various distributions. Here, we present an R package, [*PASSED*](https://CRAN.R-project.org/package=PASSED), that allows flexibility with seven common distributions and multiple options to accommodate sample size or power analysis. The relevant statistical theory, calculations, and examples for each distribution using *PASSED* are discussed in this paper.</p>
</div>
</a>
<a href="articles/RJ-2021-095/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 19, 2021</div>
<div class="dt-authors">
<div class="dt-author">Rafael Ayala</div>
<div class="dt-author">Daniel Ayala</div>
<div class="dt-author">Lara Sells Vidal</div>
<div class="dt-author">David Ruiz</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-095/preview.png"/>
</div>
<div class="description">
<h2>openSkies - Integration of Aviation Data into the R Ecosystem</h2>
<div class="dt-tags"></div>
<p>Aviation data has become increasingly more accessible to the public thanks to the adoption of technologies such as Automatic Dependent Surveillance-Broadcast (ADS-B) and Mode S, which provide aircraft information over publicly accessible radio channels. Furthermore, the OpenSky Network provides multiple public resources to access such air traffic data from a large network of ADS-B receivers. Here, we present *openSkies*, the first R package for processing public air traffic data. The package provides an interface to the OpenSky Network resources, standardized data structures to represent the different entities involved in air traffic data, and functionalities to analyze and visualize such data. Furthermore, the portability of the implemented data structures makes *openSkies* easily reusable by other packages, therefore laying the foundation of aviation data engineering in R.</p>
</div>
</a>
<a href="articles/RJ-2021-079/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 20, 2021</div>
<div class="dt-authors">
<div class="dt-author">Hkon Otneim</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-079/preview.png"/>
</div>
<div class="description">
<h2>lg: An R package for Local Gaussian Approximations</h2>
<div class="dt-tags"></div>
<p>The package [*lg*](https://CRAN.R-project.org/package=lg) for the R programming language provides implementations of recent methodological advances on applications of the local Gaussian correlation. This includes the estimation of the local Gaussian correlation itself, multivariate density estimation, conditional density estimation, various tests for independence and conditional independence, as well as a graphical module for creating dependence maps. This paper describes the [*lg*](https://CRAN.R-project.org/package=lg) package, its principles, and its practical use.</p>
</div>
</a>
<a href="articles/RJ-2021-080/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 20, 2021</div>
<div class="dt-authors">
<div class="dt-author">Jingchen Hu</div>
<div class="dt-author">Olanrewaju Akande</div>
<div class="dt-author">Quanli Wang</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-080/preview.png"/>
</div>
<div class="description">
<h2>Multiple Imputation and Synthetic Data Generation with NPBayesImputeCat</h2>
<div class="dt-tags"></div>
<p>In many contexts, missing data and disclosure control are ubiquitous and challenging issues. In particular, at statistical agencies, the respondent-level data they collect from surveys and censuses can suffer from high rates of missingness. Furthermore, agencies are obliged to protect respondents' privacy when publishing the collected data for public use. The [*NPBayesImputeCat*](https://CRAN.R-project.org/package=NPBayesImputeCat) R package, introduced in this paper, provides routines to i) create multiple imputations for missing data and ii) create synthetic data for statistical disclosure control, for multivariate categorical data, with or without structural zeros. We describe the Dirichlet process mixture of products of the multinomial distributions model used in the package and illustrate various uses of the package using data samples from the American Community Survey (ACS). We also compare results of the missing data imputation to the [*mice*](https://CRAN.R-project.org/package=mice) R package and those of the synthetic data generation to the [*synthpop*](https://CRAN.R-project.org/package=synthpop) R package.</p>
</div>
</a>
<a href="articles/RJ-2021-081/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 20, 2021</div>
<div class="dt-authors">
<div class="dt-author">Andrs Ramrez--Hassan</div>
<div class="dt-author">Mateo Graciano-Londoo</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-081/preview.png"/>
</div>
<div class="description">
<h2>A GUIded tour of Bayesian regression</h2>
<div class="dt-tags"></div>
<p>This paper presents a Graphical User Interface (GUI) to carry out a Bayesian regression analysis in a very friendly environment without any programming skills (drag and drop). This paper is designed for teaching and applied purposes at an introductory level. Our GUI is based on an interactive web application using shiny and libraries from R. We carry out some applications to highlight the potential of our GUI for applied researchers and practitioners. In addition, the Help option in the main tap panel has an extended version of this paper, where we present the basic theory underlying all regression models that we developed in our GUI and more applications associated with each model.</p>
</div>
</a>
<a href="articles/RJ-2021-082/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 20, 2021</div>
<div class="dt-authors">
<div class="dt-author">David Moria</div>
<div class="dt-author">Gilma Hernndez-Herrera</div>
<div class="dt-author">Albert Navarro</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-082/preview.png"/>
</div>
<div class="description">
<h2>miRecSurv Package: Prentice-Williams-Peterson Models with Multiple Imputation of Unknown Number of Previous Episodes</h2>
<div class="dt-tags"></div>
<p>Left censoring can occur with relative frequency when analyzing recurrent events in epidemiological studies, especially observational ones. Concretely, the inclusion of individuals that were already at risk before the effective initiation in a cohort study may cause the unawareness of prior episodes that have already been experienced, and this will easily lead to biased and inefficient estimates. The [*miRecSurv*](https://CRAN.R-project.org/package=miRecSurv) package is based on the use of models with specific baseline hazard, with multiple imputation of the number of prior episodes when unknown by means of the COMPoisson distribution, a very flexible count distribution that can handle over, sub, and equidispersion, with a stratified model depending on whether the individual had or had not previously been at risk, and the use of a frailty term. The usage of the package is illustrated by means of a real data example based on an occupational cohort study and a simulation study.</p>
</div>
</a>
<a href="articles/RJ-2021-083/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 20, 2021</div>
<div class="dt-authors">
<div class="dt-author">Kazushi Maruo</div>
<div class="dt-author">Ryota Ishii</div>
<div class="dt-author">Yusuke Yamaguchi</div>
<div class="dt-author">Masahiko Gosho</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-083/preview.png"/>
</div>
<div class="description">
<h2>bcmixed: A Package for Median Inference on Longitudinal Data with the Box--Cox Transformation</h2>
<div class="dt-tags"></div>
<p>This article illustrates the use of the [*bcmixed*](https://CRAN.R-project.org/package=bcmixed) package and focuses on the two main functions: `bcmarg` and `bcmmrm`. The `bcmarg` function provides inference results for a marginal model of a mixed effect model using the Box--Cox transformation. The `bcmmrm` function provides model median inferences based on the mixed effect models for repeated measures analysis using the Box--Cox transformation for longitudinal randomized clinical trials. Using the `bcmmrm` function, analysis results with high power and high interpretability for treatment effects can be obtained for longitudinal randomized clinical trials with skewed outcomes. Further, the *bcmixed* package provides summarizing and visualization tools, which would be helpful to write clinical trial reports.</p>
</div>
</a>
<a href="articles/RJ-2021-085/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 20, 2021</div>
<div class="dt-authors">
<div class="dt-author">Sebastian Juhl</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-085/preview.png"/>
</div>
<div class="description">
<h2>spfilteR: An R package for Semiparametric Spatial Filtering with Eigenvectors in (Generalized) Linear Models</h2>
<div class="dt-tags"></div>
<p>Eigenvector-based Spatial filtering constitutes a highly flexible semiparametric approach to account for spatial autocorrelation in a regression framework. It combines judiciously selected eigenvectors from a transformed connectivity matrix to construct a synthetic spatial filter and remove spatial patterns from model residuals. This article introduces the [*spfilteR*](https://CRAN.R-project.org/package=spfilteR) package that provides several useful and flexible tools to estimate spatially filtered linear and generalized linear models in R. While the package features functions to identify relevant eigenvectors based on different selection criteria in an unsupervised fashion, it also helps users to perform supervised spatial filtering and to select eigenvectors based on alternative user-defined criteria. Besides a brief discussion of the eigenvector-based spatial filtering approach, this article presents the main functions of the package and illustrates their usage. Comparison to alternative implementations in other R packages highlights the added value of the *spfilteR* package.</p>
</div>
</a>
<a href="articles/RJ-2021-086/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 20, 2021</div>
<div class="dt-authors">
<div class="dt-author">Adrian E. Raftery</div>
<div class="dt-author">Hana evkov</div>
<div class="dt-author">Bernard W. Silverman</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-086/preview.png"/>
</div>
<div class="description">
<h2>The vote Package: Single Transferable Vote and Other Electoral Systems in R</h2>
<div class="dt-tags"></div>
<p>We describe the [*vote*](https://CRAN.R-project.org/package=vote) package in R, which implements the plurality (or first-past-the-post), two-round runoff, score, approval, and Single Transferable Vote (STV) electoral systems, as well as methods for selecting the Condorcet winner and loser. We emphasize the STV system, which we have found to work well in practice for multi-winner elections with small electorates, such as committee and council elections, and the selection of multiple job candidates. For single-winner elections, STV is also called Instant Runoff Voting (IRV), Ranked Choice Voting (RCV), or the alternative vote (AV) system. The package also implements the STV system with equal preferences, for the first time in a software package, to our knowledge. It also implements a new variant of STV, in which a minimum number of candidates from a specified group are required to be elected. We illustrate the package with several real examples.</p>
</div>
</a>
<a href="articles/RJ-2021-069/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2021</div>
<div class="dt-authors">
<div class="dt-author">Ran Xu</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-069/preview.png"/>
</div>
<div class="description">
<h2>Estimating Social Influence Effects in Networks Using A Latent Space Adjusted Approach in R</h2>
<div class="dt-tags"></div>
<p>Social influence effects have been extensively studied in various empirical network research. However, many challenges remain in estimating social influence effects in networks, as influence effects are often entangled with other factors, such as homophily in the selection process and the common social-environmental factors that individuals are embedded in. Methods currently available either do not solve these problems or require stringent assumptions. Recent works by Xu (2018) and others have shown that a latent space adjusted approach based on the latent space model has the potential to disentangle the influence effects from other processes, and the simulation evidence has shown that this approach outperforms other state-of-the-art approaches in terms of recovering the true social influence effect when there is an unobserved trait co-determining influence and selection. In this paper, I will further illustrate how the latent space adjusted approach can account for bias in the estimation of social influence effects and how this approach can be easily implemented in R.</p>
</div>
</a>
<a href="articles/RJ-2021-070/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2021</div>
<div class="dt-authors">
<div class="dt-author">Gustavo Soutinho</div>
<div class="dt-author">Marta Sestelo</div>
<div class="dt-author">Lus Meira-Machado</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-070/preview.png"/>
</div>
<div class="description">
<h2>survidm: An R package for Inference and Prediction in an Illness-Death Model</h2>
<div class="dt-tags"></div>
<p>Multi-state models are a useful way of describing a process in which an individual moves through a number of finite states in continuous time. The illness-death model plays a central role in the theory and practice of these models, describing the dynamics of healthy subjects who may move to an intermediate \"diseased\" state before entering into a terminal absorbing state. In these models, one important goal is the modeling of transition rates which is usually done by studying the relationship between covariates and disease evolution. However, biomedical researchers are also interested in reporting other interpretable results in a simple and summarized manner. These include estimates of predictive probabilities, such as the transition probabilities, occupation probabilities, cumulative incidence functions, and the sojourn time distributions. The development of [*survidm*](https://CRAN.R-project.org/package=survidm) package has been motivated by recent contribution that provides answers to all these topics. An illustration of the software usage is included using real data.</p>
</div>
</a>
<a href="articles/RJ-2021-071/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2021</div>
<div class="dt-authors">
<div class="dt-author">Rachid Boumaza</div>
<div class="dt-author">Pierre Santagostini</div>
<div class="dt-author">Smail Yousfi</div>
<div class="dt-author">Sabine Demotes-Mainard</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-071/preview.png"/>
</div>
<div class="description">
<h2>dad: an R Package for Visualisation, Classification and Discrimination of Multivariate Groups Modelled by their Densities</h2>
<div class="dt-tags"></div>
<p>Multidimensional scaling (MDS), hierarchical cluster analysis (HCA), and discriminant analysis (DA) are classical techniques which deal with data made of $n$ individuals and $p$ variables. When the individuals are divided into $T$ groups, the R package *dad* associates with each group a multivariate probability density function and then carries out these techniques on the densities, which are estimated by the data under consideration. These techniques are based on distance measures between densities: chi-square, Hellinger, Jeffreys, Jensen-Shannon, and $L^p$ for discrete densities, Hellinger , Jeffreys, $L^2$, and 2-Wasserstein for Gaussian densities, and $L^2$ for numeric non-Gaussian densities estimated by the Gaussian kernel method. Practical methods help the user to give meaning to the outputs in the context of MDS and HCA and to look for an optimal prediction in the context of DA based on the one-leave-out misclassification ratio. Some functions for data management or basic statistics calculations on groups are annexed.</p>
</div>
</a>
<a href="articles/RJ-2021-072/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2021</div>
<div class="dt-authors">
<div class="dt-author">Andrew G. Allmon</div>
<div class="dt-author">J. S. Marron</div>
<div class="dt-author">Michael G. Hudgens</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-072/preview.png"/>
</div>
<div class="description">
<h2>diproperm: An R Package for the DiProPerm Test</h2>
<div class="dt-tags"></div>
<p>High-dimensional low sample size (HDLSS) data sets frequently emerge in many biomedical applications. The direction-projection-permutation (DiProPerm) test is a two-sample hypothesis test for comparing two high-dimensional distributions. The DiProPerm test is exact, i.e., the type I error is guaranteed to be controlled at the nominal level for any sample size, and thus is applicable in the HDLSS setting. This paper discusses the key components of the DiProPerm test, introduces the [*diproperm*](https://CRAN.R-project.org/package=diproperm) R package, and demonstrates the package on a real-world data set.</p>
</div>
</a>
<a href="articles/RJ-2021-073/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2021</div>
<div class="dt-authors">
<div class="dt-author">Farhad Pishgar</div>
<div class="dt-author">Noah Greifer</div>
<div class="dt-author">Clmence Leyrat</div>
<div class="dt-author">Elizabeth Stuart</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-073/preview.png"/>
</div>
<div class="description">
<h2>MatchThem:: Matching and Weighting after Multiple Imputation</h2>
<div class="dt-tags"></div>
<p>Balancing the distributions of the confounders across the exposure levels in an observational study through matching or weighting is an accepted method to control for confounding due to these variables when estimating the association between an exposure and outcome and reducing the degree of dependence on certain modeling assumptions. Despite the increasing popularity in practice, these procedures cannot be immediately applied to datasets with missing values. Multiple imputation of the missing data is a popular approach to account for missing values while preserving the number of units in the dataset and accounting for the uncertainty in the missing values. However, to the best of our knowledge, there is no comprehensive matching and weighting software that can be easily implemented with multiply imputed datasets. In this paper, we review this problem and suggest a framework to map out the matching and weighting of multiply imputed datasets to 5 actions as well as the best practices to assess balance in these datasets after matching and weighting. We also illustrate these approaches using a companion package for R, *MatchThem*.</p>
</div>
</a>
<a href="articles/RJ-2021-074/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2021</div>
<div class="dt-authors">
<div class="dt-author">A. Pedro Duarte Silva</div>
<div class="dt-author">Paula Brito</div>
<div class="dt-author">Peter Filzmoser</div>
<div class="dt-author">Jos G. Dias</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-074/preview.png"/>
</div>
<div class="description">
<h2>MAINT.Data: Modelling and Analysing Interval Data in R</h2>
<div class="dt-tags"></div>
<p>We present the CRAN R package *MAINT.Data* for the modelling and analysis of multivariate interval data, i.e., where units are described by variables whose values are intervals of $I\!\! R$, representing intrinsic variability. Parametric inference methodologies based on probabilistic models for interval variables have been developed, where each interval is represented by its midpoint and log-range, for which multivariate Normal and Skew-Normal distributions are assumed. The intrinsic nature of the interval variables leads to special structures of the variance-covariance matrix, which are represented by four different possible configurations. *MAINT.Data* implements the proposed methodologies in the S4 object system, introducing a specific data class for representing interval data. It includes functions and methods for modelling and analysing interval data, in particular maximum likelihood estimation, statistical tests for the different configurations, (M)ANOVA and Discriminant Analysis. For the Gaussian model, Model-based Clustering, robust estimation, outlier detection and Robust Discriminant Analysis are also available.</p>
</div>
</a>
<a href="articles/RJ-2021-075/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2021</div>
<div class="dt-authors">
<div class="dt-author">Blint Tamsi</div>
<div class="dt-author">Torsten Hothorn</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-075/preview.png"/>
</div>
<div class="description">
<h2>tramME: Mixed-Effects Transformation Models Using Template Model Builder</h2>
<div class="dt-tags"></div>
<p>Linear transformation models constitute a general family of parametric regression models for discrete and continuous responses. To accommodate correlated responses, the model is extended by incorporating mixed effects. This article presents the Rpackage *tramME*, which builds on existing implementations of transformation models (*mlt* and *tram* packages) as well as Laplace approximation and automatic differentiation (using the *TMB* package), to calculate estimates and perform likelihood inference in mixed-effects transformation models. The resulting framework can be readily applied to a wide range of regression problems with grouped data structures.</p>
</div>
</a>
<a href="articles/RJ-2021-076/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2021</div>
<div class="dt-authors">
<div class="dt-author">Tony Pourmohamad</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-076/preview.png"/>
</div>
<div class="description">
<h2>CompModels: A Suite of Computer Model Test Functions for Bayesian Optimization</h2>
<div class="dt-tags"></div>
<p>The [*CompModels*](https://CRAN.R-project.org/package=CompModels) package for R provides a suite of computer model test functions that can be used for computer model prediction/emulation, uncertainty quantification, and calibration. Moreover, the [*CompModels*](https://CRAN.R-project.org/package=CompModels) package is especially well suited for the sequential optimization of computer models. The package is a mix of real-world physics problems, known mathematical functions, and black-box functions that have been converted into computer models with the goal of Bayesian (i.e., sequential) optimization in mind. Likewise, the package contains computer models that represent either the constrained or unconstrained optimization case, each with varying levels of difficulty. In this paper, we illustrate the use of the package with both real-world examples and black-box functions by solving constrained optimization problems via Bayesian optimization. Ultimately, the package is shown to provide users with a source of computer model test functions that are reproducible, shareable, and that can be used for benchmarking of novel optimization methods.</p>
</div>
</a>
<a href="articles/RJ-2021-077/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2021</div>
<div class="dt-authors">
<div class="dt-author">Apostolos Chalkis</div>
<div class="dt-author">Vissarion Fisikopoulos</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-077/preview.png"/>
</div>
<div class="description">
<h2>volesti: Volume Approximation and Sampling for Convex Polytopes in R</h2>
<div class="dt-tags"></div>
<p>Sampling from high-dimensional distributions and volume approximation of convex bodies are fundamental operations that appear in optimization, finance, engineering, artificial intelligence, and machine learning. In this paper, we present *volesti*, an R package that provides efficient, scalable algorithms for volume estimation, uniform, and Gaussian sampling from convex polytopes. *volesti* scales to hundreds of dimensions, handles efficiently three different types of polyhedra and provides non existing sampling routines to R. We demonstrate the power of *volesti* by solving several challenging problems using the R language.</p>
</div>
</a>
<a href="articles/RJ-2021-078/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2021</div>
<div class="dt-authors">
<div class="dt-author">Slaana Babi</div>
<div class="dt-author">Christophe Ley</div>
<div class="dt-author">Marko Palangeti</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Elliptical Symmetry Tests in R</h2>
<div class="dt-tags"></div>
<p>The assumption of elliptical symmetry has an important role in many theoretical developments and applications. Hence, it is of primary importance to be able to test whether that assumption actually holds true or not. Various tests have been proposed in the literature for this problem. To the best of our knowledge, none of them has been implemented in R. This article describes the R package [*ellipticalsymmetry*](https://CRAN.R-project.org/package=ellipticalsymmetry) which implements several well-known tests for elliptical symmetry together with some recent tests. We demonstrate the testing procedures with a real data example.</p>
</div>
</a>
<a href="articles/RJ-2021-065/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 16, 2021</div>
<div class="dt-authors">
<div class="dt-author">Miguel Ferreiro-Daz</div>
<div class="dt-author">Toms R. Cotos-Yez</div>
<div class="dt-author">Jos R. Mndez</div>
<div class="dt-author">David Ruano-Ords</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The bdpar Package: Big Data Pipelining Architecture for R</h2>
<div class="dt-tags"></div>
<p>In the last years, big data has become a useful paradigm for taking advantage of multiple sources to find relevant knowledge in real domains (such as the design of personalized marketing campaigns or helping to palliate the effects of several fatal diseases). Big data programming tools and methods have evolved over time from a MapReduce to a pipeline-based archetype. Concretely the use of pipelining schemes has become the most reliable way of processing and analyzing large amounts of data. To this end, this work introduces *bdpar*, a new highly customizable pipeline-based framework (using the OOP paradigm provided by [*R6*](https://CRAN.R-project.org/package=R6) package) able to execute multiple preprocessing tasks over heterogeneous data sources. Moreover, to increase the flexibility and performance, *bdpar* provides helpful features such as (i) the definition of a novel object-based pipe operator (`%&gt;|%`), (ii) the ability to easily design and deploy new (and customized) input data parsers, tasks, and pipelines, (iii) only-once execution which avoids the execution of previously processed information (instances), guaranteeing that only new both input data and pipelines are executed, (iv) the capability to perform serial or parallel operations according to the user needs, (v) the inclusion of a debugging mechanism which allows users to check the status of each instance (and find possible errors) throughout the process.</p>
</div>
</a>
<a href="articles/RJ-2021-064/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Daniel Osorio</div>
<div class="dt-author">Kelly Botero</div>
<div class="dt-author">Andrs Pinzn Velasco</div>
<div class="dt-author">Nicols Mendoza-Meja</div>
<div class="dt-author">Felipe Rojas-Rodriguez</div>
<div class="dt-author">George E. Barreto</div>
<div class="dt-author">Janneth Gonzlez</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>g2f as a Novel Tool to Find and Fill Gaps in Metabolic Networks</h2>
<div class="dt-tags"></div>
<p>During the building of a genome-scale metabolic model, there are several dead-end metabolites and substrates which cannot be imported, produced, nor used by any reaction incorporated in the network. The presence of these dead-end metabolites can block out the net flux of the objective function when it is evaluated through Flux Balance Analysis (FBA), and when it is not blocked, bias in the biological conclusions increase. In this aspect, the refinement to restore the connectivity of the network can be carried out manually or using computational algorithms. The *g2f* package was designed as a tool to find the gaps from dead-end metabolites and fill them from the stoichiometric reactions of a reference, filtering candidate reactions using a weighting function. Additionally, this algorithm allows downloading all the sets of gene-associated stoichiometric reactions for a specific organism from the KEGG database. Our package is compatible with both 4.0.0 and 3.6.0 R versions.</p>
</div>
</a>
<a href="articles/RJ-2021-066/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Mara Xos Rodrguez-lvarez</div>
<div class="dt-author">Vanda Incio</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ROCnReg: An R Package for Receiver Operating Characteristic Curve Inference With and Without Covariates</h2>
<div class="dt-tags"></div>
<p>This paper introduces the package *ROCnReg* that allows estimating the pooled ROC curve, the covariate-specific ROC curve, and the covariate-adjusted ROC curve by different methods, both from (semi) parametric and nonparametric perspectives and within Bayesian and frequentist paradigms. From the estimated ROC curve (pooled, covariate-specific, or covariate-adjusted), several summary measures of discriminatory accuracy, such as the (partial) area under the ROC curve and the Youden index, can be obtained. The package also provides functions to obtain ROC-based optimal threshold values using several criteria, namely, the Youden index criterion and the criterion that sets a target value for the false positive fraction. For the Bayesian methods, we provide tools for assessing model fit via posterior predictive checks, while the model choice can be carried out via several information criteria. Numerical and graphical outputs are provided for all methods. This is the only package implementing Bayesian procedures for ROC curves.</p>
</div>
</a>
<a href="articles/RJ-2021-067/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Rolf Turner</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-067/preview.png"/>
</div>
<div class="description">
<h2>A New Versatile Discrete Distribution</h2>
<div class="dt-tags"></div>
<p>This paper introduces a new flexible distribution for discrete data. Approximate moment estimators of the parameters of the distribution, to be used as starting values for numerical optimization procedures, are discussed. "Exact" moment estimation, effected via a numerical procedure, and maximum likelihood estimation, are considered. The quality of the results produced by these estimators is assessed via simulation experiments. Several examples are given of fitting instances of the new distribution to real and simulated data. It is noted that the new distribution is a member of the exponential family. Expressions for the gradient and Hessian of the log-likelihood of the new distribution are derived. The former facilitates the numerical maximization of the likelihood with `optim()`; the latter provides means of calculating or estimating the covariance matrix of of the parameter estimates. A discrepancy between estimates of the covariance matrix obtained by inverting the Hessian and those obtained by Monte Carlo methods is discussed.</p>
</div>
</a>
<a href="articles/RJ-2021-068/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Brandon Bolte</div>
<div class="dt-author">Nicols Schmidt</div>
<div class="dt-author">Sergio Bjar</div>
<div class="dt-author">Nguyen Huynh</div>
<div class="dt-author">Bumba Mukherjee</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>BayesSPsurv: An R Package to Estimate Bayesian (Spatial) Split-Population Survival Models</h2>
<div class="dt-tags"></div>
<p>Survival data often include a fraction of units that are susceptible to an event of interest as well as a fraction of "immune" units. In many applications, spatial clustering in unobserved risk factors across nearby units can also affect their survival rates and odds of becoming immune. To address these methodological challenges, this article introduces our [*BayesSPsurv*](https://CRAN.R-project.org/package=BayesSPsurv) R-package, which fits parametric Bayesian Spatial split-population survival (cure) models that can account for spatial autocorrelation in both subpopulations of the user's time-to-event data. Spatial autocorrelation is modeled with spatially weighted frailties, which are estimated using a conditionally autoregressive prior. The user can also fit parametric cure models with or without nonspatial i.i.d. frailties, and each model can incorporate time-varying covariates. *BayesSPsurv* also includes various functions to conduct pre-estimation spatial autocorrelation tests, visualize results, and assess model performance, all of which are illustrated using data on post-civil war peace survival.</p>
</div>
</a>
<a href="articles/RJ-2021-056/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 13, 2021</div>
<div class="dt-authors">
<div class="dt-author">Mark P.J. van der Loo</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>A Method for Deriving Information from Running R Code</h2>
<div class="dt-tags"></div>
<p>It is often useful to tap information from a running R script. Obvious use cases include monitoring the consumption of resources (time, memory) and logging. Perhaps less obvious cases include tracking changes in R objects or collecting the output of unit tests. In this paper, we demonstrate an approach that abstracts the collection and processing of such secondary information from the running R script. Our approach is based on a combination of three elements. The first element is to build a customized way to evaluate code. The second is labeled *local masking* and it involves temporarily masking a user-facing function so an alternative version of it is called. The third element we label *local side effect*. This refers to the fact that the masking function exports information to the secondary information flow without altering a global state. The result is a method for building systems in pure R that lets users create and control secondary flows of information with minimal impact on their workflow and no global side effects.</p>
</div>
</a>
<a href="articles/RJ-2021-053/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 22, 2021</div>
<div class="dt-authors">
<div class="dt-author">Daniel D. Sjoberg</div>
<div class="dt-author">Karissa Whiting</div>
<div class="dt-author">Michael Curry</div>
<div class="dt-author">Jessica A. Lavery</div>
<div class="dt-author">Joseph Larmarange</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Reproducible Summary Tables with the gtsummary Package</h2>
<div class="dt-tags"></div>
<p>The *gtsummary* package provides an elegant and flexible way to create publication-ready summary tables in R. A critical part of the work of statisticians, data scientists, and analysts is summarizing data sets and regression models in R and publishing or sharing polished summary tables. The *gtsummary* package was created to streamline these everyday analysis tasks by allowing users to easily create reproducible summaries of data sets, regression models, survey data, and survival data with a simple interface and very little code. The package follows a tidy framework, making it easy to integrate with standard data workflows, and offers many table customization features through function arguments, helper functions, and custom themes.</p>
</div>
</a>
<a href="articles/RJ-2021-057/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 22, 2021</div>
<div class="dt-authors">
<div class="dt-author">Genaro Sucarrat</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>garchx: Flexible and Robust GARCH-X Modeling</h2>
<div class="dt-tags"></div>
<p>The *garchx* package provides a user-friendly, fast, flexible, and robust framework for the estimation and inference of GARCH($p,q,r$)-X models, where $p$ is the ARCH order, $q$ is the GARCH order, $r$ is the asymmetry or leverage order, and 'X' indicates that covariates can be included. Quasi Maximum Likelihood (QML) methods ensure estimates are consistent and standard errors valid, even when the standardized innovations are non-normal or dependent, or both. Zero-coefficient restrictions by omission enable parsimonious specifications, and functions to facilitate the non-standard inference associated with zero-restrictions in the null-hypothesis are provided. Finally, in the formal comparisons of precision and speed, the *garchx* package performs well relative to other prominent GARCH-packages on CRAN.</p>
</div>
</a>
<a href="articles/RJ-2021-060/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 22, 2021</div>
<div class="dt-authors">
<div class="dt-author">Ostap Okhrin</div>
<div class="dt-author">Simon Trimborn</div>
<div class="dt-author">Martin Waltz</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>gofCopula: Goodness-of-Fit Tests for Copulae</h2>
<div class="dt-tags"></div>
<p>The last decades show an increased interest in modeling various types of data through copulae. Different copula models have been developed, which lead to the challenge of finding the best fitting model for a particular dataset. From the other side, a strand of literature developed a list of different Goodness-of-Fit (GoF) tests with different powers under different conditions. The usual practice is the selection of the best copula via the $p$-value of the GoF test. Although this method is not purely correct due to the fact that non-rejection does not imply acception, this strategy is favored by practitioners. Unfortunately, different GoF tests often provide contradicting outputs. The proposed R-package brings under one umbrella 13 most used copulae - plus their rotated variants - together with 16 GoF tests and a hybrid one. The package offers flexible margin modeling, automatized parallelization, parameter estimation, as well as a user-friendly interface, and pleasant visualizations of the results. To illustrate the functionality of the package, two exemplary applications are provided.</p>
</div>
</a>
<a href="articles/RJ-2021-059/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2021</div>
<div class="dt-authors">
<div class="dt-author">Ezequiel Toum</div>
<div class="dt-author">Mariano H. Masiokas</div>
<div class="dt-author">Ricardo Villalba</div>
<div class="dt-author">Pierre Pitte</div>
<div class="dt-author">Lucas Ruiz</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The HBV.IANIGLA Hydrological Model</h2>
<div class="dt-tags"></div>
<p>Over the past 40 years, the HBV (Hydrologiska Byrns Vattenbalansavdelning) hydrological model has been one of the most used worldwide due to its robustness, simplicity, and reliable results. Despite these advantages, the available versions impose some limitations for research studies in mountain watersheds dominated by ice-snow melt runoff (i.e., no glacier module, a limited number of elevation bands, among other constraints). Here we present HBV.IANIGLA, a tool for hydroclimatic studies in regions with steep topography and/or cryospheric processes which provides a modular and extended implementation of the HBV model as an R package. To our knowledge, this is the first modular version of the original HBV model. This feature can be very useful for teaching hydrological modeling, as it offers the possibility to build a customized, open-source model that can be adjusted to different requirements of students and users.</p>
</div>
</a>
<a href="articles/RJ-2021-061/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2021</div>
<div class="dt-authors">
<div class="dt-author">Alessandro Beretta</div>
<div class="dt-author">Cdric Heuchenne</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>penPHcure: Variable Selection in Proportional Hazards Cure Model with Time-Varying Covariates</h2>
<div class="dt-tags"></div>
<p>We describe the [*penPHcure*](https://CRAN.R-project.org/package=penPHcure) R package, which implements the semiparametric proportional-hazards (PH) cure model of @Sy_Taylor_2000 extended to time-varying covariates and the variable selection technique based on its SCAD-penalized likelihood proposed by @Beretta_Heuchenne_2019. In survival analysis, cure models are a useful tool when a fraction of the population is likely to be immune from the event of interest. They can separate the effects of certain factors on the probability of being susceptible and on the time until the occurrence of the event. Moreover, the *penPHcure* package allows the user to simulate data from a PH cure model, where the event-times are generated on a continuous scale from a piecewise exponential distribution conditional on time-varying covariates, with a method similar to @Hendry_2014. We present the results of a simulation study to assess the finite sample performance of the methodology and illustrate the functionalities of the *penPHcure* package using criminal recidivism data.</p>
</div>
</a>
<a href="articles/RJ-2021-062/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2021</div>
<div class="dt-authors">
<div class="dt-author">Moreno I. Coco</div>
<div class="dt-author">Dan Mnster</div>
<div class="dt-author">Giuseppe Leonardi</div>
<div class="dt-author">Rick Dale</div>
<div class="dt-author">Sebastian Wallot</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Unidimensional and Multidimensional Methods for Recurrence Quantification Analysis with crqa</h2>
<div class="dt-tags"></div>
<p>Recurrence quantification analysis is a widely used method for characterizing patterns in time series. This article presents a comprehensive survey for conducting a wide range of recurrence-based analyses to quantify the dynamical structure of single and multivariate time series and capture coupling properties underlying leader-follower relationships. The basics of recurrence quantification analysis (RQA) and all its variants are formally introduced step-by-step from the simplest auto-recurrence to the most advanced multivariate case. Importantly, we show how such RQA methods can be deployed under a single computational framework in R using a substantially renewed version of our *crqa* 2.0 package. This package includes implementations of several recent advances in recurrence-based analysis, among them applications to multivariate data and improved entropy calculations for categorical data. We show concrete applications of our package to example data, together with a detailed description of its functions and some guidelines on their usage.</p>
</div>
</a>
<a href="articles/RJ-2021-063/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 21, 2021</div>
<div class="dt-authors">
<div class="dt-author">Rachael C. Aikens</div>
<div class="dt-author">Joseph Rigdon</div>
<div class="dt-author">Justin Lee</div>
<div class="dt-author">Michael Baiocchi</div>
<div class="dt-author">Andrew B. Goldstone</div>
<div class="dt-author">Peter Chiu</div>
<div class="dt-author">Y. Joseph Woo</div>
<div class="dt-author">Jonathan H. Chen</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>stratamatch: Prognostic Score Stratification Using a Pilot Design</h2>
<div class="dt-tags"></div>
<p>Optimal propensity score matching has emerged as one of the most ubiquitous approaches for causal inference studies on observational data. However, outstanding critiques of the statistical properties of propensity score matching have cast doubt on the statistical efficiency of this technique, and the poor scalability of optimal matching to large data sets makes this approach inconvenient if not infeasible for sample sizes that are increasingly commonplace in modern observational data. The [*stratamatch*](https://CRAN.R-project.org/package=stratamatch) package provides implementation support and diagnostics for 'stratified matching designs,' an approach that addresses both of these issues with optimal propensity score matching for large-sample observational studies. First, stratifying the data enables more computationally efficient matching of large data sets. Second, *stratamatch* implements a 'pilot design' approach in order to stratify by a prognostic score, which may increase the precision of the effect estimate and increase power in sensitivity analyses of unmeasured confounding.</p>
</div>
</a>
<a href="articles/RJ-2021-055/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 17, 2021</div>
<div class="dt-authors">
<div class="dt-author">Raphael Sonabend</div>
<div class="dt-author">Franz J. Kirly</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>distr6: R6 Object-Oriented Probability Distributions Interface in R</h2>
<div class="dt-tags"></div>
<p>*distr6* is an object-oriented (OO) probability distributions interface leveraging the extensibility and scalability of R6 and the speed and efficiency of *Rcpp*. Over 50 probability distributions are currently implemented in the package with 'core' methods, including density, distribution, and generating functions, and more 'exotic' ones, including hazards and distribution function anti-derivatives. In addition to simple distributions, *distr6* supports compositions such as truncation, mixtures, and product distributions. This paper presents the core functionality of the package and demonstrates examples for key use-cases. In addition, this paper provides a critical review of the object-oriented programming paradigms in R and describes some novel implementations for design patterns and core object-oriented features introduced by the package for supporting *distr6* components.</p>
</div>
</a>
<a href="articles/RJ-2021-044/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 8, 2021</div>
<div class="dt-authors">
<div class="dt-author">Alexandre Brouste</div>
<div class="dt-author">Christophe Dutang</div>
<div class="dt-author">Darel Noutsa Mieniedou</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>OneStep : LeCam's One-step Estimation Procedure</h2>
<div class="dt-tags"></div>
<p>The *OneStep* package proposes principally an eponymic function that numerically computes Le Cam's one-step estimator, which is asymptotically efficient and can be computed faster than the maximum likelihood estimator for large datasets. Monte Carlo simulations are carried out for several examples (discrete and continuous probability distributions) in order to exhibit the performance of Le Cam's one-step estimation procedure in terms of efficiency and computational cost on observation samples of finite size.</p>
</div>
</a>
<a href="articles/RJ-2021-045/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 8, 2021</div>
<div class="dt-authors">
<div class="dt-author">Paul Walter</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The R Package smicd: Statistical Methods for Interval-Censored Data</h2>
<div class="dt-tags"></div>
<p>The package allows the use of two new statistical methods for the analysis of interval-censored data: 1) direct estimation/prediction of statistical indicators and 2) linear (mixed) regression analysis. Direct estimation of statistical indicators, for instance, poverty and inequality indicators, is facilitated by a non parametric kernel density algorithm. The algorithm is able to account for weights in the estimation of statistical indicators. The standard errors of the statistical indicators are estimated with a non parametric bootstrap. Furthermore, the package offers statistical methods for the estimation of linear and linear mixed regression models with an interval-censored dependent variable, particularly random slope and random intercept models. Parameter estimates are obtained through a stochastic expectation-maximization algorithm. Standard errors are estimated using a non parametric bootstrap in the linear regression model and by a parametric bootstrap in the linear mixed regression model. To handle departures from the model assumptions, fixed (logarithmic) and data-driven (Box-Cox) transformations are incorporated into the algorithm.</p>
</div>
</a>
<a href="articles/RJ-2021-046/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 8, 2021</div>
<div class="dt-authors">
<div class="dt-author">John Hughes</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>krippendorffsalpha: An R Package for Measuring Agreement Using Krippendorff's Alpha Coefficient</h2>
<div class="dt-tags"></div>
<p>R package [*krippendorffsalpha*](https://CRAN.R-project.org/package=krippendorffsalpha) provides tools for measuring agreement using Krippendorff's $\alpha$ coefficient, a well-known nonparametric measure of agreement (also called inter-rater reliability and various other names). This article first develops Krippendorff's $\alpha$ in a natural way and situates $\alpha$ among statistical procedures. Then, the usage of package [*krippendorffsalpha*](https://CRAN.R-project.org/package=krippendorffsalpha) is illustrated via analyses of two datasets, the latter of which was collected during an imaging study of hip cartilage. The package permits users to apply the $\alpha$ methodology using built-in distance functions for the nominal, ordinal, interval, or ratio levels of measurement. User-defined distance functions are also supported. The fitting function can accommodate any number of units, any number of coders, and missingness. Bootstrap inference is supported, and the bootstrap computation can be carried out in parallel.</p>
</div>
</a>
<a href="articles/RJ-2021-047/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 8, 2021</div>
<div class="dt-authors">
<div class="dt-author">Majeed Simaan</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Working with CRSP/COMPUSTAT in R: Reproducible Empirical Asset Pricing</h2>
<div class="dt-tags"></div>
<p>It is common to come across SAS or Stata manuals while working on academic empirical finance research. Nonetheless, given the popularity of open-source programming languages such as R, there are fewer resources in R covering popular databases such as CRSP and COMPUSTAT. The aim of this article is to bridge the gap and illustrate how to leverage R in working with both datasets. As an application, we illustrate how to form size-value portfolios with respect to [@fama1993common] and study the sensitivity of the results with respect to different inputs. Ultimately, the purpose of the article is to advocate reproducible finance research and contribute to the recent idea of "Open Source Cross-Sectional Asset Pricing", proposed by @chen2020open.</p>
</div>
</a>
<a href="articles/RJ-2021-049/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 8, 2021</div>
<div class="dt-authors">
<div class="dt-author">Ana C. Cebrin</div>
<div class="dt-author">Jess Asn</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Analyzing Dependence between Point Processes in Time Using IndTestPP</h2>
<div class="dt-tags"></div>
<p>The need to analyze the dependence between two or more point processes in time appears in many modeling problems related to the occurrence of events, such as the occurrence of climate events at different spatial locations or synchrony detection in spike train analysis. The package *IndTestPP* provides a general framework for all the steps in this type of analysis, and one of its main features is the implementation of three families of tests to study independence given the intensities of the processes, which are not only useful to assess independence but also to identify factors causing dependence. The package also includes functions for generating different types of dependent point processes, and implements computational statistical inference tools using them. An application to characterize the dependence between the occurrence of extreme heat events in three Spanish locations using the package is shown.</p>
</div>
</a>
<a href="articles/RJ-2021-050/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 8, 2021</div>
<div class="dt-authors">
<div class="dt-author">Earo Wang</div>
<div class="dt-author">Dianne Cook</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RJ-2021-050/figure/highlight-retail-1.png"/>
</div>
<div class="description">
<h2>Conversations in Time: Interactive Visualization to Explore Structured Temporal Data</h2>
<div class="dt-tags"></div>
<p>Temporal data often has a hierarchical structure, defined by categorical variables describing different levels, such as political regions or sales products. The nesting of categorical variables produces a hierarchical structure. The tsibbletalk package is developed to allow a user to interactively explore temporal data, relative to the nested or crossed structures. It can help to discover differences between category levels, and uncover interesting periodic or aperiodic slices. The package implements a shared `tsibble` object that allows for linked brushing between coordinated views, and a shiny module that aids in wrapping timelines for seasonal patterns. The tools are demonstrated using two data examples: domestic tourism in Australia and pedestrian traffic in Melbourne.</p>
</div>
</a>
<a href="articles/RJ-2021-051/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 8, 2021</div>
<div class="dt-authors">
<div class="dt-author">Michael Kane</div>
<div class="dt-author">Xun Jiang</div>
<div class="dt-author">Simon Urbanek</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Automating Reproducible, Collaborative Clinical Trial Document Generation with the listdown Package</h2>
<div class="dt-tags"></div>
<p>The conveyance of clinical trial explorations and analysis results from a statistician to a clinical investigator is a critical component of the drug development and clinical research cycle. Automating the process of generating documents for data descriptions, summaries, exploration, and analysis allows the statistician to provide a more comprehensive view of the information captured by a clinical trial, and efficient generation of these documents allows the statistican to focus more on the conceptual development of a trial or trial analysis and less on the implementation of the summaries and results on which decisions are made. This paper explores the use of the *listdown* package for automating reproducible documents in clinical trials that facilitate the collaboration between statisticians and clinicians as well as defining an analysis pipeline for document generation.</p>
</div>
</a>
<a href="articles/RJ-2021-052/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 8, 2021</div>
<div class="dt-authors">
<div class="dt-author">Michael J. Kane</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Towards a Grammar for Processing Clinical Trial Data</h2>
<div class="dt-tags"></div>
<p>The goal of this paper is to help define a path toward a grammar for processing clinical trials by a) defining a format in which we would like to represent data from standardized clinical trial data b) describing a standard set of operations to transform clinical trial data into this format, and c) to identify a set of verbs and other functionality to facilitate data processing and encourage reproducibility in the processing of these data. It provides a background on standard clinical trial data and goes through a simple preprocessing example illustrating the value of the proposed approach through the use of the *forceps* package, which is currently being used for data of this kind.</p>
</div>
</a>
<a href="articles/RJ-2021-054/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 8, 2021</div>
<div class="dt-authors">
<div class="dt-author">Lucas Kook</div>
<div class="dt-author">Torsten Hothorn</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Regularized Transformation Models: The tramnet Package</h2>
<div class="dt-tags"></div>
<p>The [*tramnet*](https://CRAN.R-project.org/package=tramnet) package implements regularized linear transformation models by combining the flexible class of transformation models from [*tram*](https://CRAN.R-project.org/package=tram) with constrained convex optimization implemented in [*CVXR*](https://CRAN.R-project.org/package=CVXR). Regularized transformation models unify many existing and novel regularized regression models under one theoretical and computational framework. Regularization strategies implemented for transformation models in *tramnet* include the Lasso, ridge regression, and the elastic net and follow the parameterization in [*glmnet*](https://CRAN.R-project.org/package=glmnet). Several functionalities for optimizing the hyperparameters, including model-based optimization based on the [*mlrMBO*](https://CRAN.R-project.org/package=mlrMBO) package, are implemented. A multitude of `S3` methods is deployed for visualization, handling, and simulation purposes. This work aims at illustrating all facets of *tramnet* in realistic settings and comparing regularized transformation models with existing implementations of similar models.</p>
</div>
</a>
<a href="articles/RJ-2021-026/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 7, 2021</div>
<div class="dt-authors">
<div class="dt-author">Bo-Young Kim</div>
<div class="dt-author">Yunju Im</div>
<div class="dt-author">Jae Keun Yoo</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SEEDCCA: An Integrated R-Package for Canonical Correlation Analysis and Partial Least Squares</h2>
<div class="dt-tags"></div>
<p>Canonical correlation analysis (CCA) has a long history as an explanatory statistical method in high-dimensional data analysis and has been successfully applied in many scientific fields such as chemometrics, pattern recognition, genomic sequence analysis, and so on. The so-called *seedCCA* is a newly developed *R* package that implements not only the standard and seeded CCA but also partial least squares. The package enables us to fit CCA to large-$p$ and small-$n$ data. The paper provides a complete guide. Also, the seeded CCA application results are compared with the regularized CCA in the existing *R* package. It is believed that the package, along with the paper, will contribute to high-dimensional data analysis in various science field practitioners and that the statistical methodologies in multivariate analysis become more fruitful.</p>
</div>
</a>
<a href="articles/RJ-2021-027/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 7, 2021</div>
<div class="dt-authors">
<div class="dt-author">Ana Lpez-Cheda</div>
<div class="dt-author">M. Amalia Jcome</div>
<div class="dt-author">Ignacio Lpez-de-Ullibarri</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>npcure: An R Package for Nonparametric Inference in Mixture Cure Models</h2>
<div class="dt-tags"></div>
<p>Mixture cure models have been widely used to analyze survival data with a cure fraction. They assume that a subgroup of the individuals under study will never experience the event (cured subjects). So, the goal is twofold: to study both the cure probability and the failure time of the uncured individuals through a proper survival function (latency). The R package *npcure* implements a completely nonparametric approach for estimating these functions in mixture cure models, considering right-censored survival times. Nonparametric estimators for the cure probability and the latency as functions of a covariate are provided. Bootstrap bandwidth selectors for the estimators are included. The package also implements a nonparametric covariate significance test for the cure probability, which can be applied with a continuous, discrete, or qualitative covariate.</p>
</div>
</a>
<a href="articles/RJ-2021-028/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 7, 2021</div>
<div class="dt-authors">
<div class="dt-author">Hong Wang</div>
<div class="dt-author">Ning Li</div>
<div class="dt-author">Shanpeng Li</div>
<div class="dt-author">Gang Li\*</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>JMcmprsk: An R Package for Joint Modelling of Longitudinal and Survival Data with Competing Risks</h2>
<div class="dt-tags"></div>
<p>In this paper, we describe an R package named **JMcmprsk**, for joint modelling of longitudinal and survival data with competing risks. The package in its current version implements two joint models of longitudinal and survival data proposed to handle competing risks survival data together with continuous and ordinal longitudinal outcomes respectively [@elashoff2008joint; @li2010joint]. The corresponding R implementations are further illustrated with real examples. The package also provides simulation functions to simulate datasets for joint modelling with continuous or ordinal outcomes under the competing risks scenario, which provide useful tools to validate and evaluate new joint modelling methods.</p>
</div>
</a>
<a href="articles/RJ-2021-029/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 7, 2021</div>
<div class="dt-authors">
<div class="dt-author">Toby Dylan Hocking</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Wide-to-tall Data Reshaping Using Regular Expressions and the nc Package</h2>
<div class="dt-tags"></div>
<p>Regular expressions are powerful tools for extracting tables from non-tabular text data. Capturing regular expressions that describe the information to extract from column names can be especially useful when reshaping a data table from wide (few rows with many regularly named columns) to tall (fewer columns with more rows). We present the R package *nc* (short for named capture), which provides functions for wide-to-tall data reshaping using regular expressions. We describe the main new ideas of *nc*, and provide detailed comparisons with related R packages (*stats*, *utils*, *data.table*, *tidyr*, *tidyfast*, *tidyfst*, *reshape2*, *cdata*).</p>
</div>
</a>
<a href="articles/RJ-2021-030/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 7, 2021</div>
<div class="dt-authors">
<div class="dt-author">Emmanuel Caron</div>
<div class="dt-author">Jrme Dedecker</div>
<div class="dt-author">Bertrand Michel</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Linear Regression with Stationary Errors: the R Package slm</h2>
<div class="dt-tags"></div>
<p>This paper introduces the R package [*slm*](https://CRAN.R-project.org/package=slm), which stands for Stationary Linear Models. The package contains a set of statistical procedures for linear regression in the general context where the error process is strictly stationary with a short memory. We work in the setting of[@hannan1973central], who proved the asymptotic normality of the (normalized) least squares estimators (LSE) under very mild conditions on the error process. We propose different ways to estimate the asymptotic covariance matrix of the LSE and then to correct the type I error rates of the usual tests on the parameters (as well as confidence intervals). The procedures are evaluated through different sets of simulations.</p>
</div>
</a>
<a href="articles/RJ-2021-031/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 7, 2021</div>
<div class="dt-authors">
<div class="dt-author">Falk Hee</div>
<div class="dt-author">Karina Cucchi</div>
<div class="dt-author">Nura Kawa</div>
<div class="dt-author">Yoram Rubin</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>exPrior: An R Package for the Formulation of Ex-Situ Priors</h2>
<div class="dt-tags"></div>
<p>The [*exPrior*](https://CRAN.R-project.org/package=exPrior) package implements a procedure for formulating informative priors of geostatistical properties for a target field site, called *ex-situ priors* and introduced in [@Cucchi2019]. The procedure uses a Bayesian hierarchical model to assimilate multiple types of data coming from multiple sites considered as similar to the target site. This prior summarizes the information contained in the data in the form of a probability density function that can be used to better inform further geostatistical investigations at the site. The formulation of the prior uses ex-situ data, where the data set can either be gathered by the user or come in the form of a structured database. The package is designed to be flexible in that regard. For illustration purposes and for easiness of use, the package is ready to be used with the worldwide hydrogeological parameter database (WWHYPDA) [@Comunian2009].</p>
</div>
</a>
<a href="articles/RJ-2021-032/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 7, 2021</div>
<div class="dt-authors">
<div class="dt-author">Nora M. Villanueva</div>
<div class="dt-author">Marta Sestelo</div>
<div class="dt-author">Lus Meira-Machado</div>
<div class="dt-author">Javier Roca-Pardias</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>clustcurv: An R Package for Determining Groups in Multiple Curves </h2>
<div class="dt-tags"></div>
<p>In many situations, it could be interesting to ascertain whether groups of curves can be performed, especially when confronted with a considerable number of curves. This paper introduces an R package, known as [*clustcurv*](https://CRAN.R-project.org/package=clustcurv), for determining clusters of curves with an automatic selection of their number. The package can be used for determining groups in multiple survival curves as well as for multiple regression curves. Moreover, it can be used with large numbers of curves. An illustration of the use of *clustcurv* is provided, using both real data examples and artificial data.</p>
</div>
</a>
<a href="articles/RJ-2021-033/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 7, 2021</div>
<div class="dt-authors">
<div class="dt-author">Eashwar V. Somasundaram</div>
<div class="dt-author">Shael E. Brown</div>
<div class="dt-author">Adam Litzler</div>
<div class="dt-author">Jacob G. Scott</div>
<div class="dt-author">Raoul R. Wadhwa</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Benchmarking R packages for Calculation of Persistent Homology</h2>
<div class="dt-tags"></div>
<p>Several persistent homology software libraries have been implemented in R. Specifically, the Dionysus, GUDHI, and Ripser libraries have been wrapped by the **TDA** and **TDAstats** CRAN packages. These software represent powerful analysis tools that are computationally expensive and, to our knowledge, have not been formally benchmarked. Here, we analyze runtime and memory growth for the 2 R packages and the 3 underlying libraries. We find that datasets with less than 3 dimensions can be evaluated with persistent homology fastest by the GUDHI library in the **TDA** package. For higher-dimensional datasets, the Ripser library in the TDAstats package is the fastest. Ripser and **TDAstats** are also the most memory-efficient tools to calculate persistent homology.</p>
</div>
</a>
<a href="articles/RJ-2021-034/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 7, 2021</div>
<div class="dt-authors">
<div class="dt-author">Miguel Flores</div>
<div class="dt-author">Rubn Fernndez-Casal</div>
<div class="dt-author">Salvador Naya</div>
<div class="dt-author">Javier Tarro-Saavedra</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Statistical Quality Control with the qcr Package</h2>
<div class="dt-tags"></div>
<p>The R package [*qcr*](https://CRAN.R-project.org/package=qcr) for Statistical Quality Control (SQC) is introduced and described. It includes a comprehensive set of univariate and multivariate SQC tools that completes and increases the SQC techniques available in R. Apart from integrating different R packages devoted to SQC ([*qcc*](https://CRAN.R-project.org/package=qcc), [*MSQC*](https://CRAN.R-project.org/package=MSQC)), [*qcr*](https://CRAN.R-project.org/package=qcr) provides nonparametric tools that are highly useful when Gaussian assumption is not met. This package computes standard univariate control charts for individual measurements, $\bar{x}$, $S$, $R$, $p$, $np$, $c$, $u$, EWMA, and CUSUM. In addition, it includes functions to perform multivariate control charts such as Hotelling T$^2$, MEWMA and MCUSUM. As representative features, multivariate nonparametric alternatives based on data depth are implemented in this package: $r$, $Q$ and $S$ control charts. The [*qcr*](https://CRAN.R-project.org/package=qcr) library also estimates the most complete set of capability indices from first to the fourth generation, covering the nonparametric alternatives, and performing the corresponding capability analysis graphical outputs, including the process capability plots. Moreover, Phase I and II control charts for functional data are included.</p>
</div>
</a>
<a href="articles/RJ-2021-035/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 7, 2021</div>
<div class="dt-authors">
<div class="dt-author">Markus Fritsch</div>
<div class="dt-author">Andrew Adrian Yu Pua</div>
<div class="dt-author">Joachim Schnurbus</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>pdynmc: A Package for Estimating Linear Dynamic Panel Data Models Based on Nonlinear Moment Conditions</h2>
<div class="dt-tags"></div>
<p>This paper introduces [*pdynmc*](https://CRAN.R-project.org/package=pdynmc), an R package that provides users sufficient flexibility and precise control over the estimation and inference in linear dynamic panel data models. The package primarily allows for the inclusion of nonlinear moment conditions and the use of iterated GMM; additionally, visualizations for data structure and estimation results are provided. The current implementation reflects recent developments in literature, uses sensible argument defaults, and aligns commercial and noncommercial estimation commands. Since the understanding of the model assumptions is vital for setting up plausible estimation routines, we provide a broad introduction of linear dynamic panel data models directed towards practitioners before concisely describing the functionality available in *pdynmc* regarding instrument type, covariate type, estimation methodology, and general configuration. We then demonstrate the functionality by revisiting the popular firm-level dataset of @AreBon1991.</p>
</div>
</a>
<a href="articles/RJ-2021-036/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 7, 2021</div>
<div class="dt-authors">
<div class="dt-author">Julio E. Sandubete</div>
<div class="dt-author">Lorenzo Escot</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>DChaos: An R Package for Chaotic Time Series Analysis</h2>
<div class="dt-tags"></div>
<p>Chaos theory has been hailed as a revolution of thoughts and attracting ever-increasing attention of many scientists from diverse disciplines. Chaotic systems are non-linear deterministic dynamic systems which can behave like an erratic and apparently random motion. A relevant field inside chaos theory is the detection of chaotic behavior from empirical time-series data. One of the main features of chaos is the well-known initial-value sensitivity property. Methods and techniques related to testing the hypothesis of chaos try to quantify the initial-value sensitive property estimating the so-called Lyapunov exponents. This paper describes the main estimation methods of the Lyapunov exponent from time series data. At the same time, we present the *DChaos* library. R users may compute the delayed-coordinate embedding vector from time series data, estimates the best-fitted neural net model from the delayed-coordinate embedding vectors, calculates analytically the partial derivatives from the chosen neural nets model. They can also obtain the neural net estimator of the Lyapunov exponent from the partial derivatives computed previously by two different procedures and four ways of subsampling by blocks. To sum up, the *DChaos* package allows the R users to test robustly the hypothesis of chaos in order to know if the data-generating process behind time series behaves chaotically or not. The package's functionality is illustrated by examples.</p>
</div>
</a>
<a href="articles/RJ-2021-038/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 7, 2021</div>
<div class="dt-authors">
<div class="dt-author">Alejandro Saavedra-Nieves</div>
<div class="dt-author">Paula Saavedra-Nieves</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>IndexNumber: An R Package for Measuring the Evolution of Magnitudes</h2>
<div class="dt-tags"></div>
<p>Index numbers are descriptive statistical measures useful in economic settings for comparing simple and complex magnitudes registered, usually in two time periods. Although this theory has a large history, it still plays an important role in modern today's societies where big amounts of economic data are available and need to be analyzed. After a detailed revision on classical index numbers in literature, this paper is focused on the description of the R package [*IndexNumber*](https://CRAN.R-project.org/package=IndexNumber) with strong capabilities for calculating them. Two of the four real data sets contained in this library are used for illustrating the determination of the index numbers in this work. Graphical tools are also implemented in order to show the time evolution of considered magnitudes simplifying the interpretation of the results.</p>
</div>
</a>
<a href="articles/RJ-2021-039/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 7, 2021</div>
<div class="dt-authors">
<div class="dt-author">Sbastien Wouters</div>
<div class="dt-author">Anne-Christine Da Silva</div>
<div class="dt-author">Frdric Boulvain</div>
<div class="dt-author">Xavier Devleeschouwer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>StratigrapheR: Concepts for Litholog Generation in R </h2>
<div class="dt-tags"></div>
<p>The [*StratigrapheR*](https://CRAN.R-project.org/package=StratigrapheR) package proposes new concepts for the generation of lithological logs, or lithologs, in R. The generation of lithologs in a scripting environment opens new opportunities for the processing and analysis of stratified geological data. Among the new concepts presented: new plotting and data processing methodologies, new general R functions, and computer-oriented data conventions are provided. The package structure allows for these new concepts to be further improved, which can be done independently by any R user. The current limitations of the package are highlighted, along with the limitations in R for geological data processing, to help identify the best paths for improvements.</p>
</div>
</a>
<a href="articles/RJ-2021-040/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 7, 2021</div>
<div class="dt-authors">
<div class="dt-author">Valeria Policastro</div>
<div class="dt-author">Dario Righelli</div>
<div class="dt-author">Annamaria Carissimo</div>
<div class="dt-author">Luisa Cutillo</div>
<div class="dt-author">Italia De Feis</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ROBustness In Network (robin): an R Package for Comparison and Validation of Communities </h2>
<div class="dt-tags"></div>
<p>In network analysis, many community detection algorithms have been developed. However, their implementation leaves unaddressed the question of the statistical validation of the results. Here, we present [*robin*](https://CRAN.R-project.org/package=robin) (ROBustness In Network), an R package to assess the robustness of the community structure of a network found by one or more methods to give indications about their reliability. The procedure initially detects if the community structure found by a set of algorithms is statistically significant and then compares two selected detection algorithms on the same graph to choose the one that better fits the network of interest. We demonstrate the use of our package on the American College Football benchmark dataset.</p>
</div>
</a>
<a href="articles/RJ-2021-041/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 7, 2021</div>
<div class="dt-authors">
<div class="dt-author">Ryan A. Peterson</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Finding Optimal Normalizing Transformations via bestNormalize</h2>
<div class="dt-tags"></div>
<p>The *bestNormalize* R package was designed to help users find a transformation that can effectively normalize a vector regardless of its actual distribution. Each of the many normalization techniques that have been developed has its own strengths and weaknesses, and deciding which to use until data are fully observed is difficult or impossible. This package facilitates choosing between a range of possible transformations and will automatically return the best one, i.e., the one that makes data look the *most* normal. To evaluate and compare the normalization efficacy across a suite of possible transformations, we developed a statistic based on a goodness of fit test divided by its degrees of freedom. Transformations can be seamlessly trained and applied to newly observed data and can be implemented in conjunction with *caret* and *recipes* for data preprocessing in machine learning workflows. Custom transformations and normalization statistics are supported.</p>
</div>
</a>
<a href="articles/RJ-2021-042/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 7, 2021</div>
<div class="dt-authors">
<div class="dt-author">Javier Roca-Pardias</div>
<div class="dt-author">Mara Xos Rodrguez-lvarez</div>
<div class="dt-author">Stefan Sperlich</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Package wsbackfit for Smooth Backfitting Estimation of Generalized Structured Models</h2>
<div class="dt-tags"></div>
<p>A package is introduced that provides the weighted smooth backfitting estimator for a large family of popular semiparametric regression models. This family is known as *generalized structured models*, comprising, for example, generalized varying coefficient model, generalized additive models, mixtures, potentially including parametric parts. The kernel-based weighted smooth backfitting belongs to the statistically most efficient procedures for this model class. Its asymptotic properties are well-understood thanks to the large body of literature about this estimator. The introduced weights allow for the inclusion of sampling weights, trimming, and efficient estimation under heteroscedasticity. Further options facilitate easy handling of aggregated data, prediction, and the presentation of estimation results. Cross-validation methods are provided which can be used for model and bandwidth selection.[^1]</p>
</div>
</a>
<a href="articles/RJ-2021-043/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 7, 2021</div>
<div class="dt-authors">
<div class="dt-author">Sebastian Kreutzer</div>
<div class="dt-author">Johannes Friedrich</div>
<div class="dt-author">Vasilis Pagonis</div>
<div class="dt-author">Christian Laag</div>
<div class="dt-author">Ena Rajovic</div>
<div class="dt-author">Christoph Schmidt</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>RLumCarlo: Simulating Cold Light using Monte Carlo Methods</h2>
<div class="dt-tags"></div>
<p>The luminescence phenomena of insulators and semiconductors (e.g., natural minerals such as quartz) have various application domains. For instance, Earth Sciences and archaeology exploit luminescence as a dating method. Herein, we present the R package [*RLumCarlo*](https://CRAN.R-project.org/package=RLumCarlo) implementing sets of luminescence models to be simulated with Monte Carlo (MC) methods. MC methods make a powerful ally to all kinds of simulation attempts involving stochastic processes. Luminescence production is such a stochastic process in the form of charge (electron-hole pairs) interaction within insulators and semiconductors. To simulate luminescence-signal curves, we distribute single and independent MC processes to virtual MC clusters. [*RLumCarlo*](https://CRAN.R-project.org/package=RLumCarlo) comes with a modularized design and consistent user interface: (1) C++ functions represent the modeling core and implement models for specific stimulations modes. (2) R functions give access to combinations of models and stimulation modes, start the simulation and render terminal and graphical feedback. The combination of MC clusters supports the simulation of complex luminescence phenomena.</p>
</div>
</a>
<a href="articles/RJ-2021-025/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 20, 2021</div>
<div class="dt-authors">
<div class="dt-author">Yuqing Pan</div>
<div class="dt-author">Qing Mai</div>
<div class="dt-author">Xin Zhang</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>TULIP: A Toolbox for Linear Discriminant Analysis with Penalties</h2>
<div class="dt-tags"></div>
<p>Linear discriminant analysis (LDA) is a powerful tool in building classifiers with easy computation and interpretation. Recent advancements in science technology have led to the popularity of datasets with high dimensions, high orders and complicated structure. Such datasetes motivate the generalization of LDA in various research directions. The R package *TULIP* integrates several popular high-dimensional LDA-based methods and provides a comprehensive and user-friendly toolbox for linear, semi-parametric and tensor-variate classification. Functions are included for model fitting, cross validation and prediction. In addition, motivated by datasets with diverse sources of predictors, we further include functions for covariate adjustment. Our package is carefully tailored for low storage and high computation efficiency. Moreover, our package is the first R package for many of these methods, providing great convenience to researchers in this area.</p>
</div>
</a>
<a href="articles/RJ-2021-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Patrick Lloyd-Smith</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Kuhn-Tucker and Multiple Discrete-Continuous Extreme Value Model Estimation and Simulation in R: The rmdcev Package</h2>
<div class="dt-tags"></div>
<p>This paper introduces the package *rmdcev* in R for estimation and simulation of Kuhn-Tucker demand models with individual heterogeneity. The models supported by *rmdcev* are the multiple-discrete continuous extreme value (MDCEV) model and Kuhn-Tucker specification common in the environmental economics literature on recreation demand. Latent class and random parameters specifications can be implemented and the models are fit using maximum likelihood estimation or Bayesian estimation. The *rmdcev* package also implements demand forecasting and welfare calculation for policy simulation. The purpose of this paper is to describe the model estimation and simulation framework and to demonstrate the functionalities of *rmdcev* using real datasets.</p>
</div>
</a>
<a href="articles/RJ-2021-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Xialu Liu</div>
<div class="dt-author">Rong Chen</div>
<div class="dt-author">Ruey Tsay</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>NTS: An R Package for Nonlinear Time Series Analysis</h2>
<div class="dt-tags"></div>
<p>Linear time series models are commonly used in analyzing dependent data and in forecasting. On the other hand, real phenomena often exhibit nonlinear behavior and the observed data show nonlinear dynamics. This paper introduces the R package *NTS* that offers various computational tools and nonlinear models for analyzing nonlinear dependent data. The package fills the gaps of several outstanding R packages for nonlinear time series analysis. Specifically, the *NTS* package covers the implementation of threshold autoregressive (TAR) models, autoregressive conditional mean models with exogenous variables (ACMx), functional autoregressive models, and state-space models. Users can also evaluate and compare the performance of different models and select the best one for prediction. Furthermore, the package implements flexible and comprehensive sequential Monte Carlo methods (also known as particle filters) for modeling non-Gaussian or nonlinear processes. Several examples are used to demonstrate the capabilities of the *NTS* package.</p>
</div>
</a>
<a href="articles/RJ-2021-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Paula Moraga</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Species Distribution Modeling using Spatial Point Processes: a Case Study of Sloth Occurrence in Costa Rica</h2>
<div class="dt-tags"></div>
<p>Species distribution models are widely used in ecology for conservation management of species and their environments. This paper demonstrates how to fit a log-Gaussian Cox process model to predict the intensity of sloth occurrence in Costa Rica, and assess the effect of climatic factors on spatial patterns using the *R-INLA* package. Species occurrence data are retrieved using *spocc*, and spatial climatic variables are obtained with *raster*. Spatial data and results are manipulated and visualized by means of several packages such as *raster* and *tmap*. This paper provides an accessible illustration of spatial point process modeling that can be used to analyze data that arise in a wide range of fields including ecology, epidemiology and the environment.</p>
</div>
</a>
<a href="articles/RJ-2021-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Pere Milln-Martnez</div>
<div class="dt-author">Ramon Oller</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>A Graphical EDA Tool with ggplot2: brinton</h2>
<div class="dt-tags"></div>
<p>We present [*brinton*](https://CRAN.R-project.org/package=brinton) package, which we developed for graphical exploratory data analysis in R. Based on [*ggplot2*](https://CRAN.R-project.org/package=ggplot2), [*gridExtra*](https://CRAN.R-project.org/package=gridExtra) and [*rmarkdown*](https://CRAN.R-project.org/package=rmarkdown), *brinton* package introduces `wideplot()` graphics for exploring the structure of a dataset through a grid of variables and graphic types. It also introduces `longplot()` graphics, which present the entire catalog of available graphics for representing a particular variable using a grid of graphic types and variations on these types. Finally, it introduces the `plotup()` function, which complements the previous two functions in that it presents a particular graphic for a specific variable of a dataset. This set of functions is useful for understanding the structure of a data set, discovering unexpected properties in the data, evaluating different graphic representations of these properties, and selecting a particular graphic for display on the screen.</p>
</div>
</a>
<a href="articles/RJ-2021-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Inmaculada Prez-Bernab</div>
<div class="dt-author">Ana D. Maldonado</div>
<div class="dt-author">Thomas D. Nielsen</div>
<div class="dt-author">Antonio Salmern</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>MoTBFs: An R Package for Learning Hybrid Bayesian Networks Using Mixtures of Truncated Basis Functions</h2>
<div class="dt-tags"></div>
<p>This paper introduces [*MoTBFs*](https://CRAN.R-project.org/package=MoTBFs), an R package for manipulating mixtures of truncated basis functions. This class of functions allows the representation of joint probability distributions involving discrete and continuous variables simultaneously, and includes mixtures of truncated exponentials and mixtures of polynomials as special cases. The package implements functions for learning the parameters of univariate, multivariate, and conditional distributions, and provides support for parameter learning in Bayesian networks with both discrete and continuous variables. Probabilistic inference using forward sampling is also implemented. Part of the functionality of the *MoTBFs* package relies on the [*bnlearn*](https://CRAN.R-project.org/package=bnlearn) package, which includes functions for learning the structure of a Bayesian network from a data set. Leveraging this functionality, the *MoTBFs* package supports learning of MoTBF-based Bayesian networks over hybrid domains. We give a brief introduction to the methodological context and algorithms implemented in the package. An extensive illustrative example is used to describe the package, its functionality, and its usage.</p>
</div>
</a>
<a href="articles/RJ-2021-020/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Michael J. Kane</div>
<div class="dt-author">Nan Chen</div>
<div class="dt-author">Alex Kaizer</div>
<div class="dt-author">Xun Jiang</div>
<div class="dt-author">H. Amy Xia</div>
<div class="dt-author">Brian Hobbs</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Analyzing Basket Trials under Multisource Exchangeability Assumptions</h2>
<div class="dt-tags"></div>
<p>Basket designs are prospective clinical trials that are devised with the hypothesis that the presence of selected molecular features determine a patient's subsequent response to a particular "targeted" treatment strategy. Basket trials are designed to enroll multiple clinical subpopulations to which it is assumed that the therapy in question offers beneficial efficacy in the presence of the targeted molecular profile. The treatment, however, may not offer acceptable efficacy to all subpopulations enrolled. Moreover, for rare disease settings, such as oncology wherein these trials have become popular, marginal measures of statistical evidence are difficult to interpret for sparsely enrolled subpopulations. Consequently, basket trials pose challenges to the traditional paradigm for trial design, which assumes inter-patient exchangeability. The package [*basket*](https://CRAN.R-project.org/package=basket) for the R programmming environment facilitates the analysis of basket trials by implementing multi-source exchangeability models. By evaluating all possible pairwise exchangeability relationships, this hierarchical modeling framework facilitates Bayesian posterior shrinkage among a collection of discrete and pre-specified subpopulations. Analysis functions are provided to implement posterior inference of the response rates and all possible exchangeability relationships between subpopulations. In addition, the package can identify "poolable" subsets of and report their response characteristics. The functionality of the package is demonstrated using data from an oncology study with subpopulations defined by tumor histology.</p>
</div>
</a>
<a href="articles/RJ-2021-021/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Reginal Exavier</div>
<div class="dt-author">Peter Zeilhofer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>OpenLand: Software for Quantitative Analysis and Visualization of Land Use and Cover Change</h2>
<div class="dt-tags"></div>
<p>There is an increasing availability of spatially explicit, freely available land use and cover (LUC) time series worldwide. Because of the enormous amount of data this represents, the continuous updates and improvements in spatial and temporal resolution and category differentiation, as well as increasingly dynamic and complex changes made, manual data extraction and analysis is highly time consuming, and making software tools available to automatize LUC data assessment is becoming imperative. This paper presents a software developed in R, which combines LUC raster time series data and their transitions, calculates state-of-the-art LUC change indicators, and creates spatio-temporal visualizations, all in a coherent workflow. The functionality of the application developed is demonstrated using an LUC dataset of the Pantanal floodplain contribution area in Central Brazil.</p>
</div>
</a>
<a href="articles/RJ-2021-023/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Koushiki Bose, Jianqing Fan</div>
<div class="dt-author">Yuan Ke</div>
<div class="dt-author">Xiaoou Pan, Wen-Xin Zhou</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>FarmTest: An R Package for Factor-Adjusted Robust Multiple Testing</h2>
<div class="dt-tags"></div>
<p>We provide a publicly available library [*FarmTest*](https://CRAN.R-project.org/package=FarmTest) in the R programming system. This library implements a factor-adjusted robust multiple testing principle proposed by [@FKSZ2017] for large-scale simultaneous inference on mean effects. We use a multi-factor model to explicitly capture the dependence among a large pool of variables. Three types of factors are considered: observable, latent, and a mixture of observable and latent factors. The non-factor case, which corresponds to standard multiple mean testing under weak dependence, is also included. The library implements a series of adaptive Huber methods integrated with fast data-driven tuning schemes to estimate model parameters and to construct test statistics that are robust against heavy-tailed and asymmetric error distributions. Extensions to two-sample multiple mean testing problems are also discussed. The results of some simulation experiments and a real data analysis are reported.</p>
</div>
</a>
<a href="articles/RJ-2021-024/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 15, 2021</div>
<div class="dt-authors">
<div class="dt-author">Genaro Sucarrat</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>User-Specified General-to-Specific and Indicator Saturation Methods</h2>
<div class="dt-tags"></div>
<p>General-to-Specific (GETS) modelling provides a comprehensive, systematic and cumulative approach to modelling that is ideally suited for conditional forecasting and counterfactual analysis, whereas Indicator Saturation (ISAT) is a powerful and flexible approach to the detection and estimation of structural breaks (e.g.changes in parameters), and to the detection of outliers. To these ends, multi-path backwards elimination, single and multiple hypothesis tests on the coefficients, diagnostics tests and goodness-of-fit measures are combined to produce a parsimonious final model. In many situations a specific model or estimator is needed, a specific set of diagnostics tests may be required, or a specific fit criterion is preferred. In these situations, if the combination of estimator/model, diagnostics tests and fit criterion is not offered in a pre-programmed way by publicly available software, then the implementation of user-specified GETS and ISAT methods puts a large programming-burden on the user. Generic functions and procedures that facilitate the implementation of user-specified GETS and ISAT methods for specific problems can therefore be of great benefit. The R package *gets* is the first software -- both inside and outside the R universe -- to provide a complete set of facilities for user-specified GETS and ISAT methods: User-specified model/estimator, user-specified diagnostics and user-specified goodness-of-fit criteria. The aim of this article is to illustrate how user-specified GETS and ISAT methods can be implemented with the R package *gets*.</p>
</div>
</a>
<a href="articles/RJ-2021-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 14, 2021</div>
<div class="dt-authors">
<div class="dt-author">Yaohui Zeng</div>
<div class="dt-author">Patrick Breheny</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The biglasso Package: A Memory- and Computation-Efficient Solver for Lasso Model Fitting with Big Data in R</h2>
<div class="dt-tags"></div>
<p>Penalized regression models such as the lasso have been extensively applied to analyzing high-dimensional data sets. However, due to memory limitations, existing R packages like [*glmnet*](https://CRAN.R-project.org/package=glmnet) and [*ncvreg*](https://CRAN.R-project.org/package=ncvreg) are not capable of fitting lasso-type models for ultrahigh-dimensional, multi-gigabyte data sets that are increasingly seen in many areas such as genetics, genomics, biomedical imaging, and high-frequency finance. In this research, we implement an R package called [*biglasso*](https://CRAN.R-project.org/package=biglasso) that tackles this challenge. *biglasso* utilizes memory-mapped files to store the massive data on the disk, only reading data into memory when necessary during model fitting, and is thus able to handle out-of-core computation seamlessly. Moreover, it's equipped with newly proposed, more efficient feature screening rules, which substantially accelerate the computation. Benchmarking experiments show that our *biglasso* package, as compared to existing popular ones like *glmnet*, is much more memory- and computation-efficient. We further analyze a 36 GB simulated GWAS data set on a laptop with only 16 GB RAM to demonstrate the out-of-core computation capability of *biglasso* in analyzing massive data sets that cannot be accommodated by existing R packages.</p>
</div>
</a>
<a href="articles/RJ-2021-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 14, 2021</div>
<div class="dt-authors">
<div class="dt-author">Hsin-wen Chang</div>
<div class="dt-author">Pei-Yuan Tsai</div>
<div class="dt-author">Jen-Tse Kao</div>
<div class="dt-author">Guo-You Lan</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Comparing Multiple Survival Functions with Crossing Hazards in R</h2>
<div class="dt-tags"></div>
<p>It is frequently of interest in time-to-event analysis to compare multiple survival functions nonparametrically. However, when the hazard functions cross, tests in existing R packages do not perform well. To address the issue, we introduce the package *survELtest*, which provides tests for comparing multiple survival functions with possibly crossing hazards. Due to its powerful likelihood ratio formulation, this is the only R package to date that works when the hazard functions cross. We illustrate the use of the procedures in *survELtest* by applying them to data from randomized clinical trials and simulated datasets. We show that these methods lead to more significant results than those obtained by existing R packages.</p>
</div>
</a>
<a href="articles/RJ-2021-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 14, 2021</div>
<div class="dt-authors">
<div class="dt-author">Dongshin Kim</div>
<div class="dt-author">Sangin Lee</div>
<div class="dt-author">Sunghoon Kwon</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>A Unified Algorithm for the Non-Convex Penalized Estimation: The ncpen Package</h2>
<div class="dt-tags"></div>
<p>Various R packages have been developed for the non-convex penalized estimation but they can only be applied to the smoothly clipped absolute deviation (SCAD) or minimax concave penalty (MCP). We develop an R package, entitled *ncpen*, for the non-convex penalized estimation in order to make data analysts to experience other non-convex penalties. The package *ncpen* implements a unified algorithm based on the convex concave procedure and modified local quadratic approximation algorithm, which can be applied to a broader range of non-convex penalties, including the SCAD and MCP as special examples. Many user-friendly functionalities such as generalized information criteria, cross-validation and ridge regularization are provided also.</p>
</div>
</a>
<a href="articles/RJ-2021-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 14, 2021</div>
<div class="dt-authors">
<div class="dt-author">Peter Kasprzak</div>
<div class="dt-author">Lachlan Mitchell</div>
<div class="dt-author">Olena Kravchuk</div>
<div class="dt-author">Andy Timmins</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Six Years of Shiny in Research - Collaborative Development of Web Tools in R</h2>
<div class="dt-tags"></div>
<p>The use of *Shiny* in research publications is investigated over the six and a half years since the appearance of this popular web application framework for R, which has been utilised in many varied research areas. While it is demonstrated that the complexity of *Shiny* applications is limited by the background architecture, and real security concerns exist for novice app developers, the collaborative benefits are worth attention from the wider research community. *Shiny* simplifies the use of complex methodologies for people of different specialities, at the level of proficiency appropriate for the end user. This enables a diverse community of users to interact efficiently, and utilise cutting edge methodologies. The literature reviewed demonstrates that complex methodologies can be put into practice without insisting on investment in professional training, for a comprehensive understanding from all participants. It appears that *Shiny* opens up concurrent benefits in communication between those who analyse data and other disciplines, that would enrich much of the peer-reviewed research.</p>
</div>
</a>
<a href="articles/RJ-2021-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 14, 2021</div>
<div class="dt-authors">
<div class="dt-author">Robert N. Nguyen</div>
<div class="dt-author">James T. Day</div>
<div class="dt-author">David I. Warton</div>
<div class="dt-author">Oscar Lane</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>fitzRoy - An R Package to Encourage Reproducible Sports Analysis</h2>
<div class="dt-tags"></div>
<p>The importance of reproducibility, and the related issue of open access to data, has received a lot of recent attention. Momentum on these issues is gathering in the sports analytics community. While Australian Rules football (AFL) is the leading commercial sport in Australia, unlike popular international sports, there has been no mechanism for the public to access comprehensive statistics on players and teams. Expert commentary currently relies heavily on data that isn't made readily accessible and this produces an unnecessary barrier for the development of an inclusive sports analytics community. We present the R package *fitzRoy* to provide easy access to AFL statistics.</p>
</div>
</a>
<a href="articles/RJ-2021-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 14, 2021</div>
<div class="dt-authors">
<div class="dt-author">Mario Gonzlez Sales</div>
<div class="dt-author">Olivier Barrire</div>
<div class="dt-author">Pierre Olivier Tremblay</div>
<div class="dt-author">Guillaume Bonnefois</div>
<div class="dt-author">Julie Desrochers</div>
<div class="dt-author">Fahima Nekka</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Assembling Pharmacometric Datasets in R - The puzzle Package</h2>
<div class="dt-tags"></div>
<p>Pharmacometric analyses are integral components of the drug
development process. The core of each pharmacometric analysis is a
dataset. The time required to construct a pharmacometrics dataset can
sometimes be higher than the effort required for the modeling *per
se*. To simplify the process, the puzzle R package has been developed
aimed at simplifying and facilitating the time consuming and error
prone task of assembling pharmacometrics datasets.\
Puzzle consist of a series of functions written in R. These functions
create, from tabulated files, datasets that are compatible with the
formatting requirements of the gold standard non-linear mixed effects
modeling software.\
With only one function, `puzzle()`, complex pharmacometrics databases
can easily be assembled. Users are able to select from different
absorption processes such as zero- and first-order, or a combination
of both. Furthermore, datasets containing data from one or more
analytes, and/or one or more responses, and/or time dependent and/or
independent covariates, and/or urine data can be simultaneously
assembled.\
The *puzzle* package is a powerful and efficient tool that helps
modelers, programmers and pharmacometricians through the challenging
process of assembling pharmacometrics datasets.</p>
</div>
</a>
<a href="articles/RJ-2021-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 14, 2021</div>
<div class="dt-authors">
<div class="dt-author">Hesen Li</div>
<div class="dt-author">Dr. Hakan Demirtas</div>
<div class="dt-author">Ruizhe Chen</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>RNGforGPD: An R Package for Generation of Univariate and Multivariate Generalized Poisson Data</h2>
<div class="dt-tags"></div>
<p>This article describes the R package *RNGforGPD*, which is designed for the generation of univariate and multivariate generalized Poisson data. Some illustrative examples are given, the utility and functionality of the package are demonstrated; and its performance is assessed via simulations that are devised around both artificial and real data.</p>
</div>
</a>
<a href="articles/RJ-2021-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 14, 2021</div>
<div class="dt-authors">
<div class="dt-author">Mustafa Cavus</div>
<div class="dt-author">Berna Yazc</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Testing the Equality of Normal Distributed and Independent Groups' Means Under Unequal Variances by doex Package</h2>
<div class="dt-tags"></div>
<p>In this paper, we present the [*doex*](https://CRAN.R-project.org/package=doex) package contains the tests for equality of normal distributed and independent group means under unequal variances such as Cochran F, Welch-Aspin, Welch, Box, Scott-Smith, Brown-Forsythe, Johansen F, Approximate F, Alexander-Govern, Generalized F, Modified Brown-Forsythe, Permutation F, Adjusted Welch, B2, Parametric Bootstrap, Fiducial Approach, and Alvandi Generalized F-test. Most of these tests are not available in any package. Thus, *doex* is easy to use for researchers in multidisciplinary studies. In this study, an extensive Monte-Carlo simulation study is conducted to investigate the performance of the the tests for equality of normal distributed group means under unequal variances</p>
</div>
</a>
<a href="articles/RJ-2021-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 14, 2021</div>
<div class="dt-authors">
<div class="dt-author">Eric S. Kawaguchi</div>
<div class="dt-author">Jenny I. Shen</div>
<div class="dt-author">Gang Li</div>
<div class="dt-author">Marc A. Suchard</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>A Fast and Scalable Implementation Method for Competing Risks Data with the R Package fastcmprsk</h2>
<div class="dt-tags"></div>
<p>Advancements in medical informatics tools and high-throughput biological experimentation make large-scale biomedical data routinely accessible to researchers. Competing risks data are typical in biomedical studies where individuals are at risk to more than one cause (type of event) which can preclude the others from happening. The [@fine1999proportional] proportional subdistribution hazards model is a popular and well-appreciated model for competing risks data and is currently implemented in a number of statistical software packages. However, current implementations are not computationally scalable for large-scale competing risks data. We have developed an R package, [*fastcmprsk*](https://CRAN.R-project.org/package=fastcmprsk), that uses a novel forward-backward scan algorithm to significantly reduce the computational complexity for parameter estimation by exploiting the structure of the subject-specific risk sets. Numerical studies compare the speed and scalability of our implementation to current methods for unpenalized and penalized Fine-Gray regression and show impressive gains in computational efficiency.</p>
</div>
</a>
<a href="articles/RJ-2021-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 14, 2021</div>
<div class="dt-authors">
<div class="dt-author">Margot Selosse</div>
<div class="dt-author">Julien Jacques</div>
<div class="dt-author">Christophe Biernacki</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ordinalClust: An R Package to Analyze Ordinal Data</h2>
<div class="dt-tags"></div>
<p>Ordinal data are used in many domains, especially when measurements are collected from people through observations, tests, or questionnaires. [*ordinalClust*](https://CRAN.R-project.org/package=ordinalClust) is an innovative R package dedicated to ordinal data that provides tools for modeling, clustering, co-clustering and classifying such data. Ordinal data are modeled using the BOS distribution, which is a model with two meaningful parameters referred to as \"position\" and \"precision\". The former indicates the mode of the distribution and the latter describes how scattered the data are around the mode: the user is able to easily interpret the distribution of their data when given these two parameters. The package is based on the co-clustering framework (when rows and columns are simultaneously clustered). The co-clustering approach uses the Latent Block Model (LBM) and the SEM-Gibbs algorithm for parameter inference. On the other hand, the clustering and the classification methods follow on from simplified versions of the SEM-Gibbs algorithm. For the classification process, two approaches are proposed. In the first one, the BOS parameters are estimated from the training dataset in the conventional way. In the second approach, parsimony is introduced by estimating the parameters and column-clusters from the training dataset. We empirically show that this approach can yield better results. For the clustering and co-clustering processes, the ICL-BIC criterion is used for model selection purposes. An overview of these methods is given, and the way to use them with the *ordinalClust* package is described using real datasets. The latest stable package version is available on the Comprehensive R Archive Network (CRAN).</p>
</div>
</a>
<a href="articles/RJ-2021-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 14, 2021</div>
<div class="dt-authors">
<div class="dt-author">Catherine Schramm</div>
<div class="dt-author">Sbastien Jacquemont</div>
<div class="dt-author">Karim Oualkacha</div>
<div class="dt-author">Aurlie Labbe</div>
<div class="dt-author">Celia M.T. Greenwood</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>KSPM: A Package For Kernel Semi-Parametric Models</h2>
<div class="dt-tags"></div>
<p>Kernel semi-parametric models and their equivalence with linear mixed models provide analysts with the flexibility of machine learning methods and a foundation for inference and tests of hypothesis. These models are not impacted by the number of predictor variables, since the kernel trick transforms them to a kernel matrix whose size only depends on the number of subjects. Hence, methods based on this model are appealing and numerous, however only a few R programs are available and none includes a complete set of features. Here, we present the *KSPM* package to fit the kernel semi-parametric model and its extensions in a unified framework. *KSPM* allows multiple kernels and unlimited interactions in the same model. It also includes predictions, statistical tests, variable selection procedure and graphical tools for diagnostics and interpretation of variable effects. Currently *KSPM* is implemented for continuous dependent variables but could be extended to binary or survival outcomes.</p>
</div>
</a>
<a href="articles/RJ-2021-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 14, 2021</div>
<div class="dt-authors">
<div class="dt-author">Raymond Lagonigro</div>
<div class="dt-author">Ramon Oller</div>
<div class="dt-author">Joan Carles Martori</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>AQuadtree: an R Package for Quadtree Anonymization of Point Data</h2>
<div class="dt-tags"></div>
<p>The demand for precise data for analytical purposes grows rapidly among the research community and decision makers as more geographic information is being collected. Laws protecting data privacy are being enforced to prevent data disclosure. Statistical institutes and agencies need methods to preserve confidentiality while maintaining accuracy when disclosing geographic data. In this paper we present the AQuadtree package, a software intended to produce and deal with official spatial data making data privacy and accuracy compatible. The lack of specific methods in R to anonymize spatial data motivated the development of this package, providing an automatic aggregation tool to anonymize point data. We propose a methodology based on hierarchical geographic data structures to create a varying size grid adapted to local area population densities. This article gives insights and hints for implementation and usage. We hope this new tool may be helpful for statistical offices and users of official spatial data.</p>
</div>
</a>
<a href="articles/RJ-2021-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 14, 2021</div>
<div class="dt-authors">
<div class="dt-author">Paul M. Hargarten</div>
<div class="dt-author">David C. Wheeler</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>miWQS: Multiple Imputation Using Weighted Quantile Sum Regression</h2>
<div class="dt-tags"></div>
<p>The *miWQS* package in the Comprehensive R Archive Network (CRAN) utilizes weighted quantile sum regression (WQS) in the multiple imputation (MI) framework. The data analyzed is a set/mixture of continuous and correlated components/chemicals that are reasonable to combine in an index and share a common outcome. These components are also interval-censored between zero and upper thresholds, or detection limits, which may differ among the components. This type of data is found in areas such as chemical epidemiological studies, sociology, and genomics. The *miWQS* package can be run using complete or incomplete data, which may be placed in the first quantile, or imputed using bootstrap or Bayesian approach. This article provides a stepwise and hands-on approach to handle uncertainty due to values below the detection limit in correlated component mixture problems.</p>
</div>
</a>
<a href="articles/RJ-2020-027/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 13, 2020</div>
<div class="dt-authors">
<div class="dt-author">Nicholas Spyrison</div>
<div class="dt-author">Dianne Cook</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>spinifex: An R Package for Creating a Manual Tour of Low-dimensional Projections of Multivariate Data</h2>
<div class="dt-tags"></div>
<p>Dynamic low-dimensional linear projections of multivariate data collectively known as *tours* provide an important tool for exploring multivariate data and models. The R package *tourr* provides functions for several types of tours: grand, guided, little, local and frozen. Each of these can be viewed dynamically, or saved into a data object for animation. This paper describes a new package, *spinifex*, which provides a manual tour of multivariate data where the projection coefficient of a single variable is controlled. The variable is rotated fully into the projection, or completely out of the projection. The resulting sequence of projections can be displayed as an animation, with functions from either the *plotly* or *gganimate* packages. By varying the coefficient of a single variable, it is possible to explore the sensitivity of structure in the projection to that variable. This is particularly useful when used with a projection pursuit guided tour to simplify and understand the solution. The use of the manual tour is applied particle physics data to illustrate the sensitivity of structure in a projection to specific variable contributions.</p>
</div>
</a>
<a href="articles/RJ-2020-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">Daniel Nst</div>
<div class="dt-author">Dirk Eddelbuettel</div>
<div class="dt-author">Dom Bennett</div>
<div class="dt-author">Robrecht Cannoodt</div>
<div class="dt-author">Dav Clark</div>
<div class="dt-author">Gergely Darczi</div>
<div class="dt-author">Mark Edmondson</div>
<div class="dt-author">Colin Fay</div>
<div class="dt-author">Ellis Hughes</div>
<div class="dt-author">Lars Kjeldgaard</div>
<div class="dt-author">Sean Lopp</div>
<div class="dt-author">Ben Marwick</div>
<div class="dt-author">Heather Nolis</div>
<div class="dt-author">Jacqueline Nolis</div>
<div class="dt-author">Hong Ooi</div>
<div class="dt-author">Karthik Ram</div>
<div class="dt-author">Noam Ross</div>
<div class="dt-author">Lori Shepherd</div>
<div class="dt-author">Pter Slymos</div>
<div class="dt-author">Tyson Lee Swetnam</div>
<div class="dt-author">Nitesh Turaga</div>
<div class="dt-author">Charlotte Van Petegem</div>
<div class="dt-author">Jason Williams</div>
<div class="dt-author">Craig Willis</div>
<div class="dt-author">Nan Xiao</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The Rockerverse: Packages and Applications for Containerisation with R</h2>
<div class="dt-tags"></div>
<p>The Rocker Project provides widely used Docker images for R across different application scenarios. This article surveys downstream projects that build upon the Rocker Project images and presents the current state of R packages for managing Docker images and controlling containers. These use cases cover diverse topics such as package development, reproducible research, collaborative work, cloud-based data processing, and production deployment of services. The variety of applications demonstrates the power of the Rocker Project specifically and containerisation in general. Across the diverse ways to use containers, we identified common themes: reproducible environments, scalability and efficiency, and portability across clouds. We conclude that the current growth and diversification of use cases is likely to continue its positive impact, but see the need for consolidating the Rockerverse ecosystem of packages, developing common practices for applications, and exploring alternative containerisation software.</p>
</div>
</a>
<a href="articles/RJ-2020-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">Stepan Mazur</div>
<div class="dt-author">Dmitry Otryakhin</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Linear Fractional Stable Motion with the rlfsm R Package</h2>
<div class="dt-tags"></div>
<p>Linear fractional stable motion is a type of a stochastic integral driven by symmetric alpha-stable Lvy motion. The integral could be considered as a non-Gaussian analogue of the fractional Brownian motion. The present paper discusses R package *rlfsm* created for numerical procedures with the linear fractional stable motion. It is a set of tools for simulation of these processes as well as performing statistical inference and simulation studies on them. We introduce: tools that we developed to work with that type of motions as well as methods and ideas underlying them. Also we perform numerical experiments to show finite-sample behavior of certain estimators of the integral, and give an idea of how to envelope workflow related to the linear fractional stable motion in S4 classes and methods. Supplementary materials, including codes for numerical experiments, are available online. *rlfsm* could be found on CRAN and gitlab.</p>
</div>
</a>
<a href="articles/RJ-2020-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">Juan Carlos Gonalves-Dosantos</div>
<div class="dt-author">Ignacio Garca-Jurado</div>
<div class="dt-author">Julian Costa</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ProjectManagement: an R Package for Managing Projects</h2>
<div class="dt-tags"></div>
<p>Project management is an important body of knowledge and practices that comprises the planning, organisation and control of resources to achieve one or more pre-determined objectives. In this paper, we introduce *ProjectManagement*, a new R package that provides the necessary tools to manage projects in a broad sense, and illustrate its use by examples.</p>
</div>
</a>
<a href="articles/RJ-2020-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">Dennis Prangle</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>gk: An R Package for the g-and-k and Generalised g-and-h Distributions</h2>
<div class="dt-tags"></div>
<p>The g-and-k and (generalised) g-and-h distributions are flexible univariate distributions which can model highly skewed or heavy tailed data through only four parameters: location and scale, and two shape parameters influencing the skewness and kurtosis. These distributions have the unusual property that they are defined through their quantile function (inverse cumulative distribution function) and their density is unavailable in closed form, which makes parameter inference complicated. This paper presents the *gk* R package to work with these distributions. It provides the usual distribution functions and several algorithms for inference of independent identically distributed data, including the finite difference stochastic approximation method, which has not been used before for this problem.</p>
</div>
</a>
<a href="articles/RJ-2020-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">Lucy D'Agostino McGowan</div>
<div class="dt-author">Sean Kross</div>
<div class="dt-author">Jeffrey Leek</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Tools for Analyzing R Code the Tidy Way</h2>
<div class="dt-tags"></div>
<p>With the current emphasis on reproducibility and replicability, there is an increasing need to examine how data analyses are conducted. In order to analyze the between researcher variability in data analysis choices as well as the aspects within the data analysis pipeline that contribute to the variability in results, we have created two R packages: [*matahari*](https://CRAN.R-project.org/package=matahari) and [*tidycode*](https://CRAN.R-project.org/package=tidycode). These packages build on methods created for natural language processing; rather than allowing for the processing of natural language, we focus on R code as the substrate of interest. The [*matahari*](https://CRAN.R-project.org/package=matahari) package facilitates the logging of everything that is typed in the R console or in an R script in a tidy data frame. The [*tidycode*](https://CRAN.R-project.org/package=tidycode) package contains tools to allow for analyzing R calls in a tidy manner. We demonstrate the utility of these packages as well as walk through two examples.</p>
</div>
</a>
<a href="articles/RJ-2020-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">Daniel Fryer</div>
<div class="dt-author">Ming Li</div>
<div class="dt-author">Andriy Olenko</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>rcosmo: R Package for Analysis of Spherical, HEALPix and Cosmological Data</h2>
<div class="dt-tags"></div>
<p>The analysis of spatial observations on a sphere is important in areas such as geosciences, physics and embryo research, just to name a few. The purpose of the package *rcosmo*is to conduct efficient information processing, visualisation, manipulation and spatial statistical analysis of Cosmic Microwave Background (CMB) radiation and other spherical data. The package was developed for spherical data stored in the Hierarchical Equal Area isoLatitude Pixelation (Healpix) representation. *rcosmo*has more than 100 different functions. Most of them initially were developed for CMB, but also can be used for other spherical data as *rcosmo*contains tools for transforming spherical data in cartesian and geographic coordinates into the HEALPix representation. We give a general description of the package and illustrate some important functionalities and benchmarks.</p>
</div>
</a>
<a href="articles/RJ-2020-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">Brandon M. Greenwell</div>
<div class="dt-author">Bradley C. Boehmke</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Variable Importance Plots---An Introduction to the vip Package</h2>
<div class="dt-tags"></div>
<p>In the era of "big data", it is becoming more of a challenge to not only build state-of-the-art predictive models, but also gain an understanding of what's really going on in the data. For example, it is often of interest to know which, if any, of the predictors in a fitted model are relatively influential on the predicted outcome. Some modern algorithms---like random forests (RFs) and gradient boosted decision trees (GBMs)---have a natural way of quantifying the importance or relative influence of each feature. Other algorithms---like naive Bayes classifiers and support vector machines---are not capable of doing so and model-agnostic approaches are generally used to measure each predictor's importance. Enter *vip*, an R package for constructing variable importance scores/plots for many types of supervised learning algorithms using model-specific and novel model-agnostic approaches. We'll also discuss a novel way to display both feature importance and feature effects together using sparklines, a very small line chart conveying the general shape or variation in some feature that can be directly embedded in text or tables.</p>
</div>
</a>
<a href="articles/RJ-2020-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">Adla Hladk</div>
<div class="dt-author">Patrcia Martinkov</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>difNLR: Generalized Logistic Regression Models for DIF and DDF Detection</h2>
<div class="dt-tags"></div>
<p>Differential item functioning (DIF) and differential distractor functioning (DDF) are important topics in psychometrics, pointing to potential unfairness in items with respect to minorities or different social groups. Various methods have been proposed to detect these issues. The *difNLR* `R`package extends DIF methods currently provided in other packages by offering approaches based on generalized logistic regression models that account for possible guessing or inattention, and byproviding methods to detect DIF and DDF among ordinal and nominal data. In the current paper, we describe implementation of the main functions of the *difNLR* package, from data generation, through the model fitting and hypothesis testing, to graphical representation of the results. Finally, we provide a real data example to bring the concepts together.</p>
</div>
</a>
<a href="articles/RJ-2020-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">Mara del Mar Rueda</div>
<div class="dt-author">Ramn Ferri-Garca</div>
<div class="dt-author">Luis Castro</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The R package NonProbEst for estimation in non-probability surveys</h2>
<div class="dt-tags"></div>
<p>Different inference procedures are proposed in the literature to correct selection bias that might be introduced with non-random sampling mechanisms. The R package [*NonProbEst*](https://CRAN.R-project.org/package=NonProbEst) enables the estimation of parameters using some of these techniques to correct selection bias in non-probability surveys. The mean and the total of the target variable are estimated using Propensity Score Adjustment, calibration, statistical matching, model-based, model-assisted and model-calibratated techniques. Confidence intervals can also obtained for each method. Machine learning algorithms can be used for estimating the propensities or for predicting the unknown values of the target variable for the non-sampled units. Variance of a given estimator is performed by two different Leave-One-Out jackknife procedures. The functionality of the package is illustrated with example data sets.</p>
</div>
</a>
<a href="articles/RJ-2020-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">Youssef Hmamouche</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>NlinTS: An R Package For Causality Detection in Time Series</h2>
<div class="dt-tags"></div>
<p>The causality is an important concept that is widely studied in the literature, and has several applications, especially when modelling dependencies within complex data, such as multivariate time series. In this article, we present a theoretical description of methods from the [*NlinTS*](https://CRAN.R-project.org/package=NlinTS) package, and we focus on causality measures. The package contains the classical Granger causality test. To handle non-linear time series, we propose an extension of this test using an artificial neural network. The package includes an implementation of the Transfer entropy, which is also considered as a non-linear causality measure based on information theory. For discrete variables, we use the classical Shannon Transfer entropy, while for continuous variables, we adopt the k-nearest neighbors approach to estimate it.</p>
</div>
</a>
<a href="articles/RJ-2020-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">Maciej Bartoszuk</div>
<div class="dt-author">Marek Gagolewski</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SimilaR: R Code Clone and Plagiarism Detection</h2>
<div class="dt-tags"></div>
<p>Third-party software for assuring source code quality is becoming
increasingly popular. Tools that evaluate the coverage of unit tests,
perform static code analysis, or inspect run-time memory use are
crucial in the software development life cycle. More sophisticated
methods allow for performing meta-analyses of large software
repositories, e.g., to discover abstract topics they relate to or
common design patterns applied by their developers. They may be useful
in gaining a better understanding of the component interdependencies,
avoiding cloned code as well as detecting plagiarism in programming
classes.\
A meaningful measure of similarity of computer programs often forms
the basis of such tools. While there are a few noteworthy instruments
for similarity assessment, none of them turns out particularly
suitable for analysing R code chunks. Existing solutions rely on
rather simple techniques and heuristics and fail to provide a user
with the kind of sensitivity and specificity required for working with
R scripts. In order to fill this gap, we propose a new algorithm based
on a Program Dependence Graph, implemented in the *SimilaR* package.
It can serve as a tool not only for improving R code quality but also
for detecting plagiarism, even when it has been masked by applying
some obfuscation techniques or imputing dead code. We demonstrate its
accuracy and efficiency in a real-world case study.</p>
</div>
</a>
<a href="articles/RJ-2020-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">Emily Morris</div>
<div class="dt-author">Kevin He</div>
<div class="dt-author">Yanming Li</div>
<div class="dt-author">Yi Li</div>
<div class="dt-author">Jian Kang</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SurvBoost: An R Package for High-Dimensional Variable Selection in the Stratified Proportional Hazards Model via Gradient Boosting</h2>
<div class="dt-tags"></div>
<p>High-dimensional variable selection in the proportional hazards (PH) model has many successful applications in different areas. In practice, data may involve confounding variables that do not satisfy the PH assumption, in which case the stratified proportional hazards (SPH) model can be adopted to control the confounding effects by stratification without directly modeling the confounding effects. However, there is a lack of computationally efficient statistical software for high-dimensional variable selection in the SPH model. In this work an R package, *SurvBoost*, is developed to implement the gradient boosting algorithm for fitting the SPH model with high-dimensional covariate variables. Simulation studies demonstrate that in many scenarios *SurvBoost* can achieve better selection accuracy and reduce computational time substantially compared to the existing R package that implements boosting algorithms without stratification. The proposed R package is also illustrated by an analysis of gene expression data with survival outcome in The Cancer Genome Atlas study. In addition, a detailed hands-on tutorial for *SurvBoost* is provided.</p>
</div>
</a>
<a href="articles/RJ-2020-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">R. Douglas Martin</div>
<div class="dt-author">Chindhanai Uthaisaad</div>
<div class="dt-author">Daniel Z. Xia</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Skew-t Expected Information Matrix Evaluation and Use for Standard Error Calculations</h2>
<div class="dt-tags"></div>
<p>Skew-t distributions derived from skew-normal distributions, as developed by Azzalini and several co-workers, are popular because of their theoretical foundation and the availability of computational methods in the R package *sn*. One difficulty with this skew-t family is that the elements of the expected information matrix do not have closed form analytic formulas. Thus, we developed a numerical integration method of computing the expected information matrix in the R package *skewtInfo*. The accuracy of our expected information matrix calculation method was confirmed by comparing the result with that obtained using an observed information matrix for a very large sample size. A Monte Carlo study to evaluate the accuracy of the standard errors obtained with our expected information matrix calculation method, for the case of three realistic skew-t parameter vectors, indicates that use of the expected information matrix results in standard errors as accurate as, and sometimes a little more accurate than, use of an observed information matrix.</p>
</div>
</a>
<a href="articles/RJ-2020-020/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">Vineetha Warriyar. K. V.</div>
<div class="dt-author">Waleed Almutiry</div>
<div class="dt-author">Rob Deardon</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2> Individual-Level Modelling of Infectious Disease Data: EpiILM</h2>
<div class="dt-tags"></div>
<p>In this article we introduce the R package *EpiILM*, which provides tools for simulation from, and inference for, discrete-time individual-level models of infectious disease transmission proposed by @deardon2010. The inference is set in a Bayesian framework and is carried out via Metropolis-Hastings Markov chain Monte Carlo (MCMC). For its fast implementation, key functions are coded in Fortran. Both spatial and contact network models are implemented in the package and can be set in either susceptible-infected (SI) or susceptible-infected-removed (SIR) compartmental frameworks. Use of the package is demonstrated through examples involving both simulated and real data.</p>
</div>
</a>
<a href="articles/RJ-2020-021/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">Francisco Bischoff</div>
<div class="dt-author">Pedro Pereira Rodrigues</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>tsmp: An R Package for Time Series with Matrix Profile</h2>
<div class="dt-tags"></div>
<p>This article describes [*tsmp*](https://CRAN.R-project.org/package=tsmp), an R package that implements the MP concept for TS. The [*tsmp*](https://CRAN.R-project.org/package=tsmp) package is a toolkit that allows all-pairs similarity joins, motif, discords and chains discovery, semantic segmentation, etc. Here we describe how the [*tsmp*](https://CRAN.R-project.org/package=tsmp) package may be used by showing some of the use-cases from the original articles and evaluate the algorithm speed in the R environment. This package can be downloaded at &lt;https://CRAN.R-project.org/package=tsmp&gt;.</p>
</div>
</a>
<a href="articles/RJ-2020-022/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">Bulent Altunkaynak</div>
<div class="dt-author">Hamza Gamgam</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>npordtests: An R Package of Nonparametric Tests for Equality of Location Against Ordered Alternatives</h2>
<div class="dt-tags"></div>
<p>Ordered alternatives are an important statistical problem in many situation such as increased risk of congenital malformation caused by excessive alcohol consumption during pregnancy life test experiments, drug-screening studies, dose-finding studies, the doseresponse studies, agerelated response. There are numerous other examples of this nature. In this paper, we present the *npordtests* package to test the equality of locations for ordered alternatives. The package includes the Jonckheere-Terpstra, Beier and Buning's Adaptive, Modified Jonckheere-Terpstra, Terpstra-Magel, Ferdhiana-Terpstra-Magel, KTP, S and Gaur's Gc tests. A simulation study is conducted to determine which test is the most appropriate test for which scenario and to suggest it to the researchers.</p>
</div>
</a>
<a href="articles/RJ-2020-023/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">Sean Kross</div>
<div class="dt-author">Jeffrey T. Leek</div>
<div class="dt-author">John Muschelli</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ari: The Automated R Instructor</h2>
<div class="dt-tags"></div>
<p>We present the `ari` package for automatically generating technology-focused educational videos. The goal of the package is to create reproducible videos, with the ability to change and update video content seamlessly. We present several examples of generating videos including using R Markdown slide decks, PowerPoint slides, or simple images as source material. We also discuss how `ari` can help instructors reach new audiences through programmatically translating materials into other languages.</p>
</div>
</a>
<a href="articles/RJ-2020-024/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">Chi Hyun Lee</div>
<div class="dt-author">Heng Zhou</div>
<div class="dt-author">Jing Ning</div>
<div class="dt-author">Diane D. Liu</div>
<div class="dt-author">Yu Shen</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>CoxPhLb: An R Package for Analyzing Length Biased Data under Cox Model</h2>
<div class="dt-tags"></div>
<p>Data subject to length-biased sampling are frequently encountered in various applications including prevalent cohort studies and are considered as a special case of left-truncated data under the stationarity assumption. Many semiparametric regression methods have been proposed for length-biased data to model the association between covariates and the survival outcome of interest. In this paper, we present a brief review of the statistical methodologies established for the analysis of length-biased data under the Cox model, which is the most commonly adopted semiparametric model, and introduce an R package *CoxPhLb* that implements these methods. Specifically, the package includes features such as fitting the Cox model to explore covariate effects on survival times and checking the proportional hazards model assumptions and the stationarity assumption. We illustrate usage of the package with a simulated data example and a real dataset, the Channing House data, which are publicly available.</p>
</div>
</a>
<a href="articles/RJ-2020-025/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">Tao Sun</div>
<div class="dt-author">Ying Ding</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>CopulaCenR: Copula based Regression Models for Bivariate Censored Data in R</h2>
<div class="dt-tags"></div>
<p>Bivariate time-to-event data frequently arise in research areas such as clinical trials and epidemiological studies, where the occurrence of two events are correlated. In many cases, the exact event times are unknown due to censoring. The copula model is a popular approach for modeling correlated bivariate censored data, in which the two marginal distributions and the between-margin dependence are modeled separately. This article presents the [R]{.sans-serif} package [*CopulaCenR*](https://CRAN.R-project.org/package=CopulaCenR), which is designed for modeling and testing bivariate data under right or (general) interval censoring in a regression setting. It provides a variety of Archimedean copula functions including a flexible two-parameter copula and different types of regression models (parametric and semiparametric) for marginal distributions. In particular, it implements a semiparametric transformation model for the margins with proportional hazards and proportional odds models being its special cases. The numerical optimization is based on a novel two-step algorithm. For the regression parameters, three likelihood-based tests (Wald, generalized score and likelihood ratio tests) are also provided. We use two real data examples to illustrate the key functions in [*CopulaCenR*](https://CRAN.R-project.org/package=CopulaCenR).</p>
</div>
</a>
<a href="articles/RJ-2020-026/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2020</div>
<div class="dt-authors">
<div class="dt-author">ystein Srensen</div>
<div class="dt-author">Marta Crispino</div>
<div class="dt-author">Qinghua Liu</div>
<div class="dt-author">Valeria Vitelli</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>BayesMallows: An R Package for the Bayesian Mallows Model</h2>
<div class="dt-tags"></div>
<p>*BayesMallows* is an R package for analyzing preference data in the form of rankings with the Mallows rank model, and its finite mixture extension, in a Bayesian framework. The model is grounded on the idea that the probability density of an observed ranking decreases exponentially with the distance to the location parameter. It is the first Bayesian implementation that allows wide choices of distances, and it works well with a large amount of items to be ranked. *BayesMallows* handles non-standard data: partial rankings and pairwise comparisons, even in cases including non-transitive preference patterns. The Bayesian paradigm allows coherent quantification of posterior uncertainties of estimates of any quantity of interest. These posteriors are fully available to the user, and the package comes with convienient tools for summarizing and visualizing the posterior distributions.</p>
</div>
</a>
<a href="articles/RJ-2020-028/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2020</div>
<div class="dt-authors">
<div class="dt-author">John M. Chambers</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>S, R, and Data Science</h2>
<div class="dt-tags"></div>
<p>Data science is increasingly important and challenging. It requires
computational tools and programming environments that handle big data
and difficult computations, while supporting creative, high-quality
analysis. The R language and related software play a major role in
computing for data science. R is featured in most programs for
training in the field. R packages provide tools for a wide range of
purposes and users. The description of a new technique, particularly
from research in statistics, is frequently accompanied by an R
package, greatly increasing the usefulness of the description.\
The history of R makes clear its connection to data science. R was
consciously designed to replicate in open-source software the contents
of the S software. S in turn was written by data analysis researchers
at Bell Labs as part of the computing environment for research in data
analysis and collaborations to apply that research, rather than as a
separate project to create a programming language. The features of S
and the design decisions made for it need to be understood in this
broader context of supporting effective data analysis (which would now
be called data science). These characteristics were all transferred to
R and remain central to its effectiveness. Thus, R can be viewed as
based historically on a domain-specific language for the domain of
data science.\
**Note to R Journal readers:**\
The following paper was published online in the History of Programming
Languages (HOPL), Volume 4, in June 2020 (DOI 10.1145/3386334). The
content seems likely to be of interest to many R Journal readers, and
since HOPL is plausibly not typical reading for data scientists, the
editors of the R Journal have kindly offered to republish the paper
here. This is possible thanks also to the enlightened policy of the
ACM, providing for open distribution through the chosen copyright
declaration.</p>
</div>
</a>
<a href="articles/RJ-2020-029/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2020</div>
<div class="dt-authors">
<div class="dt-author">John C. Nash</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Provenance of R's Gradient Optimizers</h2>
<div class="dt-tags"></div>
<p>Gradient optimization methods (function minimizers) are well-represented in both the base and package universe of R [@citeR]. However, some of the methods and the codes developed from them were published before standards for hardware and software were established, in particular the IEEE arithmetic [@IEEE754A]. There have been cases of unexpected behaviour or outright errors, and these are the focus of the **histoRicalg** project. A summary history of some of the tools in R for gradient optimization methods is presented to give perspective on such methods and the occasions where they could be used effectively.</p>
</div>
</a>
<a href="articles/RJ-2020-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 31, 2020</div>
<div class="dt-authors">
<div class="dt-author">Lu Bai</div>
<div class="dt-author">Daniel L. Gillen</div>
<div class="dt-author">Scott M. Bartell</div>
<div class="dt-author">Vernica M. Vieira</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Mapping Smoothed Spatial Effect Estimates from Individual-Level Data: MapGAM </h2>
<div class="dt-tags"></div>
<p>We introduce and illustrate the utility of *MapGAM*, a user-friendly R package that provides a unified framework for estimating, predicting and drawing inference on covariate-adjusted spatial effects using individual-level data. The package also facilitates visualization of spatial effects via automated mapping procedures. *MapGAM* estimates covariate-adjusted spatial associations with a univariate or survival outcome using generalized additive models that include a non-parametric bivariate smooth term of geolocation parameters. Estimation and mapping methods are implemented for continuous, discrete, and right-censored survival data. In the current manuscript, we summarize the methodology implemented in *MapGAM* and illustrate the package using two example simulated datasets: the first considering a case-control study design from the state of Massachusetts and the second considering right-censored survival data from California.</p>
</div>
</a>
<a href="articles/RJ-2020-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 31, 2020</div>
<div class="dt-authors">
<div class="dt-author">Spyros E. Balafas</div>
<div class="dt-author">Wim P. Krijnen</div>
<div class="dt-author">Wendy J. Post</div>
<div class="dt-author">Ernst C. Wit</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>mudfold: An R Package for Nonparametric IRT Modelling of Unfolding Processes</h2>
<div class="dt-tags"></div>
<p>Item response theory (IRT) models for unfolding processes use the responses of individuals to attitudinal tests or questionnaires in order to infer item and person parameters located on a latent continuum. Parametric models in this class use parametric functions to model the response process, which in practice can be restrictive. MUDFOLD (Multiple UniDimensional unFOLDing) can be used to obtain estimates of person and item ranks without imposing strict parametric assumptions on the item response functions (IRFs). This paper describes the implementation of the MUDFOLD method for binary preferential-choice data in the R package *mudfold*. The latter incorporates estimation, visualization, and simulation methods in order to provide R users with utilities for nonparametric analysis of attitudinal questionnaire data. After a brief introduction in IRT, we provide the methodological framework implemented in the package. A description of the available functions is followed by practical examples and suggestions on how this method can be used even outside the field of psychometrics.</p>
</div>
</a>
<a href="articles/RJ-2020-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 31, 2020</div>
<div class="dt-authors">
<div class="dt-author">Matias D. Cattaneo</div>
<div class="dt-author">Max H. Farrell</div>
<div class="dt-author">Yingjie Feng</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>lspartition: Partitioning-Based Least Squares Regression</h2>
<div class="dt-tags"></div>
<p>Nonparametric partitioning-based least squares regression is an important tool in empirical work. Common examples include regressions based on splines, wavelets, and piecewise polynomials. This article discusses the main methodological and numerical features of the R software package *lspartition*, which implements results for partitioning-based least squares (series) regression estimation and inference from @Cattaneo-Farrell_2013_JoE and @Cattaneo-Farrell-Feng_2020_AoS. These results cover the multivariate regression function as well as its derivatives. First, the package provides data-driven methods to choose the number of partition knots optimally, according to integrated mean squared error, yielding optimal point estimation. Second, robust bias correction is implemented to combine this point estimator with valid inference. Third, the package provides estimates and inference for the unknown function both pointwise and *uniformly* in the conditioning variables. In particular, valid confidence *bands* are provided. Finally, an extension to two-sample analysis is developed, which can be used in treatment-control comparisons and related problems.</p>
</div>
</a>
<a href="articles/RJ-2020-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 31, 2020</div>
<div class="dt-authors">
<div class="dt-author">Shuowen Chen</div>
<div class="dt-author">Victor Chernozhukov</div>
<div class="dt-author">Ivn Fernndez-Val</div>
<div class="dt-author">Ye Luo</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SortedEffects: Sorted Causal Effects in R</h2>
<div class="dt-tags"></div>
<p>@sorted:2018 proposed the sorted effect method for nonlinear regression models. This method consists of reporting percentiles of the partial effects, the sorted effects, in addition to the average effect commonly used to summarize the heterogeneity in the partial effects. They also propose to use the sorted effects to carry out classification analysis where the observational units are classified as most and least affected if their partial effect are above or below some tail sorted effects. The R package [*SortedEffects*](https://CRAN.R-project.org/package=SortedEffects) implements the estimation and inference methods therein and provides tools to visualize the results. This vignette serves as an introduction to the package and displays basic functionality of the functions within.</p>
</div>
</a>
<a href="articles/RJ-2019-054/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 6, 2020</div>
<div class="dt-authors">
<div class="dt-author">Lily Medina</div>
<div class="dt-author">Ann-Kristin Kreutzmann</div>
<div class="dt-author">Natalia Rojas-Perilla</div>
<div class="dt-author">Piedad Castro</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The R Package trafo for Transforming Linear Regression Models</h2>
<div class="dt-tags"></div>
<p>Researchers and data-analysts often use the linear regression model for descriptive, predictive, and inferential purposes. This model relies on a set of assumptions that, when not satisfied, yields biased results and noisy estimates. A common problem that can be solved in many ways -- use of less restrictive methods (e.g.generalized linear regression models or non-parametric methods ), variance corrections or transformations of the response variable just to name a few. We focus on the latter option as it allows to keep using the simple and well-known linear regression model. The list of transformations proposed in the literature is long and varies according to the problem they aim to solve. Such diversity can leave analysts lost and confused. We provide a framework implemented as an R-package, *trafo*, to help select suitable transformations depending on the user requirements and data being analyzed. The package *trafo* contains a collection of selected transformations and estimation methods that complement and increase the breadth of methods that exist in R.</p>
</div>
</a>
<a href="articles/RJ-2019-055/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 6, 2020</div>
<div class="dt-authors">
<div class="dt-author">Wadim Djatschenko</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>BondValuation: An R Package for Fixed Coupon Bond Analysis</h2>
<div class="dt-tags"></div>
<p>The purpose of this paper is to introduce the R package [*BondValuation*](https://CRAN.R-project.org/package=BondValuation) for the analysis of large datasets of fixed coupon bonds. The conceptual heterogeneity of fixed coupon bonds traded in the global markets imposes a high degree of complexity on their comparative analysis. Contrary to baseline fixed income theory, in practice, most bonds feature coupon period irregularities. In addition, there are a multitude of day count methods that determine the interest accrual, the cash flows and the discount factors used in bond valuation. Several R packages, *e.g.*, [*fBonds*](https://CRAN.R-project.org/package=fBonds), [*RQuantLib*](https://CRAN.R-project.org/package=RQuantLib), and [*YieldCurve*](https://CRAN.R-project.org/package=YieldCurve), provide tools for fixed income analysis. Nevertheless, none of them is capable of evaluating bonds featuring irregular first and/or final coupon periods, and neither provides adequate coverage of day count conventions currently used in the global bond markets. The R package *BondValuation* closes this gap using the generalized valuation methodology presented in @Djatschenko.</p>
</div>
</a>
<a href="articles/RJ-2019-057/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 6, 2020</div>
<div class="dt-authors">
<div class="dt-author">Henrique Helfer Hoeltgebaum</div>
<div class="dt-author">Heather S. Battey</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>HCmodelSets: An R Package for Specifying Sets of Well-fitting Models in High Dimensions</h2>
<div class="dt-tags"></div>
<p>In the context of regression with a large number of explanatory variables, @cox2017large emphasize that if there are alternative reasonable explanations of the data that are statistically indistinguishable, one should aim to specify as many of these explanations as is feasible. The standard practice, by contrast, is to report a single effective model for prediction. This paper illustrates the R implementation of the new ideas in the package *HCmodelSets*, using simple reproducible examples and real data. Results of some simulation experiments are also reported.</p>
</div>
</a>
<a href="articles/RJ-2019-053/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 28, 2019</div>
<div class="dt-authors">
<div class="dt-author">Philipp Otto</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>spGARCH: An R-Package for Spatial and Spatiotemporal ARCH and GARCH models</h2>
<div class="dt-tags"></div>
<p>In this paper, a general overview on spatial and spatiotemporal ARCH models is provided. In particular, we distinguish between three different spatial ARCH-type models. In addition to the original definition of [@Otto16_arxiv], we introduce an logarithmic spatial ARCH model in this paper. For this new model, maximum-likelihood estimators for the parameters are proposed. In addition, we consider a new complex-valued definition of the spatial ARCH process. Moreover, spatial GARCH models are briefly discussed. From a practical point of view, the use of the R-package [*spGARCH*](https://CRAN.R-project.org/package=spGARCH) is demonstrated. To be precise, we show how the proposed spatial ARCH models can be simulated and summarize the variety of spatial models, which can be estimated by the estimation functions provided in the package. Eventually, we apply all procedures to a real-data example.</p>
</div>
</a>
<a href="articles/RJ-2019-044/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 27, 2019</div>
<div class="dt-authors">
<div class="dt-author">Joan del Castillo</div>
<div class="dt-author">Isabel Serra</div>
<div class="dt-author">Maria Padilla</div>
<div class="dt-author">David Moria</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Fitting Tails by the Empirical Residual Coefficient of Variation: The ercv Package</h2>
<div class="dt-tags"></div>
<p>This article is a self-contained introduction to the R package *ercv* and to the methodology on which it is based through the analysis of nine examples. The methodology is simple and trustworthy for the analysis of extreme values and relates the two main existing methodologies. The package contains R functions for visualizing, fitting and validating the distribution of tails. It also provides multiple threshold tests for a generalized Pareto distribution, together with an automatic threshold selection algorithm.</p>
</div>
</a>
<a href="articles/RJ-2019-045/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 27, 2019</div>
<div class="dt-authors">
<div class="dt-author">John Reisner</div>
<div class="dt-author">Hieu Pham</div>
<div class="dt-author">Sigurdur Olafsson</div>
<div class="dt-author">Stephen Vardeman</div>
<div class="dt-author">Jing Li</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>biclustermd: An R Package for Biclustering with Missing Values</h2>
<div class="dt-tags"></div>
<p>Biclustering is a statistical learning technique that attempts to find homogeneous partitions of rows and columns of a data matrix. For example, movie ratings might be biclustered to group both raters and movies. *biclust* is a current R package allowing users to implement a variety of biclustering algorithms. However, its algorithms do not allow the data matrix to have missing values. We provide a new R package, *biclustermd*, which allows users to perform biclustering on numeric data even in the presence of missing values.</p>
</div>
</a>
<a href="articles/RJ-2019-046/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 27, 2019</div>
<div class="dt-authors">
<div class="dt-author">David P. Hofmeyr</div>
<div class="dt-author">Nicos G. Pavlidis</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>PPCI: an R Package for Cluster Identification using Projection Pursuit</h2>
<div class="dt-tags"></div>
<p>This paper presents the R package PPCI which implements three recently proposed projec tion pursuit methods for clustering. The methods are unified by the approach of defining an optimal hyperplane to separate clusters, and deriving a projection index whose optimiser is the vector normal to this separating hyperplane. Divisive hierarchical clustering algorithms that can detect clusters defined in different subspaces are readily obtained by recursively bi-partitioning the data through such hyperplanes. Projecting onto the vector normal to the optimal hyperplane enables visualisations of the data that can be used to validate the partition at each level of the cluster hierarchy. Clustering models can also be modified in an interactive manner to improve their solutions. Extensions to problems involving clusters which are not linearly separable, and to the problem of finding maximum hard margin hyperplanes for clustering are also discussed.</p>
</div>
</a>
<a href="articles/RJ-2019-048/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 27, 2019</div>
<div class="dt-authors">
<div class="dt-author">Michael Hahsler</div>
<div class="dt-author">Ian Johnson</div>
<div class="dt-author">Tom Kliegr</div>
<div class="dt-author">Jaroslav Kucha</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Associative Classification in R: arc, arulesCBA, and rCBA</h2>
<div class="dt-tags"></div>
<p>Several methods for creating classifiers based on rules discovered via association rule mining have been proposed in the literature. These classifiers are called associative classifiers and the best-known algorithm is Classification Based on Associations (CBA). Interestingly, only very few implementations are available and, until recently, no implementation was available for R. Now, three packages provide CBA. This paper introduces associative classification, the CBA algorithm, and how it can be used in R. A comparison of the three packages is provided to give the potential user an idea about the advantages of each of the implementations. We also show how the packages are related to the existing infrastructure for association rule mining already available in R.</p>
</div>
</a>
<a href="articles/RJ-2019-050/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 27, 2019</div>
<div class="dt-authors">
<div class="dt-author">Toby Dylan Hocking</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Comparing namedCapture with other R packages for regular expressions</h2>
<div class="dt-tags"></div>
<p>Regular expressions are powerful tools for manipulating non-tabular textual data. For many tasks (visualization, machine learning, etc), tables of numbers must be extracted from such data before processing by other R functions. We present the R package [*namedCapture*](https://CRAN.R-project.org/package=namedCapture), which facilitates such tasks by providing a new user-friendly syntax for defining regular expressions in R code. We begin by describing the history of regular expressions and their usage in R. We then describe the new features of the namedCapture package, and provide detailed comparisons with related R packages ([*rex*](https://CRAN.R-project.org/package=rex), [*stringr*](https://CRAN.R-project.org/package=stringr), [*stringi*](https://CRAN.R-project.org/package=stringi), [*tidyr*](https://CRAN.R-project.org/package=tidyr), [*rematch2*](https://CRAN.R-project.org/package=rematch2), [*re2r*](https://CRAN.R-project.org/package=re2r)).</p>
</div>
</a>
<a href="articles/RJ-2019-051/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 27, 2019</div>
<div class="dt-authors">
<div class="dt-author">Sarah Friedrich</div>
<div class="dt-author">Frank Konietschke</div>
<div class="dt-author">Markus Pauly</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Resampling-Based Analysis of Multivariate Data and Repeated Measures Designs with the R Package MANOVA.RM</h2>
<div class="dt-tags"></div>
<p>Nonparametric statistical inference methods for a modern and robust analysis of longitudinal and multivariate data in factorial experiments are essential for research. While existing approaches that rely on specific distributional assumptions of the data (multivariate normality and/or equal covariance matrices) are implemented in statistical software packages, there is a need for user-friendly software that can be used for the analysis of data that do not fulfill the aforementioned assumptions and provide accurate $p$ value and confidence interval estimates. Therefore, newly developed nonparametric statistical methods based on bootstrap- and permutation-approaches, which neither assume multivariate normality nor specific covariance matrices, have been implemented in the freely available R package *MANOVA.RM*. The package is equipped with a graphical user interface for plausible applications in academia and other educational purpose. Several motivating examples illustrate the application of the methods.</p>
</div>
</a>
<a href="articles/RJ-2019-052/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 27, 2019</div>
<div class="dt-authors">
<div class="dt-author">Philipp Admmer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>lpirfs: An R Package to Estimate Impulse Response Functions by Local Projections</h2>
<div class="dt-tags"></div>
<p>Impulse response analysis is a cornerstone in applied (macro-)econometrics. Estimating impulse response functions using local projections (LPs) has become an appealing alternative to the traditional structural vector autoregressive (SVAR) approach. Despite its growing popularity and applications, however, no R package yet exists that makes this method available. In this paper, I introduce *lpirfs*, a fast and flexible R package that provides a broad framework to compute and visualize impulse response functions using LPs for a variety of data sets.</p>
</div>
</a>
<a href="articles/RJ-2020-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 27, 2019</div>
<div class="dt-authors">
<div class="dt-author">Lukas Sablica</div>
<div class="dt-author">Kurt Hornik</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>mistr: A Computational Framework for Mixture and Composite Distributions</h2>
<div class="dt-tags"></div>
<p>Finite mixtures and composite distributions allow to model the probabilistic representation of data with more generality than simple distributions and are useful to consider in a wide range of applications. The R package *mistr* provides an extensible computational framework for creating, transforming, and evaluating these models, together with multiple methods for their visualization and description. In this paper we present the main computational framework of the package and illustrate its application. In addition, we provide and show functions for data modeling using two specific composite distributions as well as a numerical example where a composite distribution is estimated to describe the log-returns of selected stocks.</p>
</div>
</a>
<a href="articles/RJ-2019-042/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 26, 2019</div>
<div class="dt-authors">
<div class="dt-author">Jonathan Kropko</div>
<div class="dt-author">Jeffrey J. Harden</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>coxed: An R Package for Computing Duration-Based Quantities from the Cox Proportional Hazards Model</h2>
<div class="dt-tags"></div>
<p>The Cox proportional hazards model is one of the most frequently used estimators in duration (survival) analysis. Because it is estimated using only the observed durations' rank ordering, typical quantities of interest used to communicate results of the Cox model come from the hazard function (e.g., hazard ratios or percentage changes in the hazard rate). These quantities are substantively vague and difficult for many audiences of research to understand. We introduce a suite of methods in the R package *coxed* to address these problems. The package allows researchers to calculate duration-based quantities from Cox model results, such as the expected duration (or survival time) given covariate values and marginal changes in duration for a specified change in a covariate. These duration-based quantities often match better with researchers' substantive interests and are easily understood by most readers. We describe the methods and illustrate use of the package.</p>
</div>
</a>
<a href="articles/RJ-2019-043/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 26, 2019</div>
<div class="dt-authors">
<div class="dt-author">John R Giles</div>
<div class="dt-author">Henrik Salje</div>
<div class="dt-author">Justin Lessler</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The IDSpatialStats R Package: Quantifying Spatial Dependence of Infectious Disease Spread</h2>
<div class="dt-tags"></div>
<p>Spatial statistics for infectious diseases are important because the spatial and temporal scale over which transmission operates determine the dynamics of disease spread. Many methods for quantifying the distribution and clustering of spatial point patterns have been developed (e.g.$K$-function and pair correlation function) and are routinely applied to infectious disease case occurrence data. However, these methods do not explicitly account for overlapping chains of transmission and require knowledge of the underlying population distribution, which can be limiting when analyzing epidemic case occurrence data. Therefore, we developed two novel spatial statistics that account for these effects to estimate: 1) the mean of the spatial transmission kernel, and 2) the $\tau$-statistic, a measure of global clustering based on pathogen subtype. We briefly introduce these statistics and show how to implement them using the IDSpatialStats R package.</p>
</div>
</a>
<a href="articles/RJ-2019-037/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 20, 2019</div>
<div class="dt-authors">
<div class="dt-author">Stuart Baumann</div>
<div class="dt-author">Margaryta Klymak</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Fixed Point Acceleration in R</h2>
<div class="dt-tags"></div>
<p>A fixed point problem is one where we seek a vector, X, for a function, f, such that f(X) = X. The solution of many such problems can be accelerated by using a fixed point acceleration algorithm. With the release of the *FixedPoint* package there is now a number of algorithms available in **R** that can be used for accelerating the finding of a fixed point of a function. These algorithms include Newton acceleration, Aitken acceleration and Anderson acceleration as well as epsilon extrapolation methods and minimal polynomial methods. This paper demonstrates the use of fixed point accelerators in solving numerical mathematics problems using the algorithms of the *FixedPoint* package as well as the squarem method of the *SQUAREM* package.</p>
</div>
</a>
<a href="articles/RJ-2019-038/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 20, 2019</div>
<div class="dt-authors">
<div class="dt-author">Danilo Alvares</div>
<div class="dt-author">Sebastien Haneuse</div>
<div class="dt-author">Catherine Lee</div>
<div class="dt-author">Kyu Ha Lee</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SemiCompRisks: An R Package for the Analysis of Independent and Cluster-correlated Semi-competing Risks Data</h2>
<div class="dt-tags"></div>
<p>Semi-competing risks refer to the setting where primary scientific interest lies in estimation and inference with respect to a non-terminal event, the occurrence of which is subject to a terminal event. In this paper, we present the R package **SemiCompRisks** that provides functions to perform the analysis of independent/clustered semi-competing risks data under the illness-death multi-state model. The package allows the user to choose the specification for model components from a range of options giving users substantial flexibility, including: accelerated failure time or proportional hazards regression models; parametric or non-parametric specifications for baseline survival functions; parametric or non-parametric specifications for random effects distributions when the data are cluster-correlated; and, a Markov or semi-Markov specification for terminal event following non-terminal event. While estimation is mainly performed within the Bayesian paradigm, the package also provides the maximum likelihood estimation for select parametric models. The package also includes functions for univariate survival analysis as complementary analysis tools.</p>
</div>
</a>
<a href="articles/RJ-2019-039/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 20, 2019</div>
<div class="dt-authors">
<div class="dt-author">Busra Sevinc</div>
<div class="dt-author">Bekir Cetintav</div>
<div class="dt-author">Melek Esemen</div>
<div class="dt-author">Selma Gurler</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>RSSampling: A Pioneering Package for Ranked Set Sampling </h2>
<div class="dt-tags"></div>
<p>Ranked set sampling (RSS) is an advanced data collection method when the exact measurement of an observation is difficult and/or expensive used in a number of research areas, e.g., environment, bioinformatics, ecology, etc. In this method, random sets are drawn from a population and the units in sets are ranked with a ranking mechanism which is based on a visual inspection or a concomitant variable. Because of the importance of working with a good design and easy analysis, there is a need for a software tool which provides sampling designs and statistical inferences based on RSS and its modifications. This paper introduces an R package as a free and easy-to-use analysis tool for both sampling processes and statistical inferences based on RSS and its modified versions. For researchers, the *RSSampling* package provides a sample with RSS, extreme RSS, median RSS, percentile RSS, balanced groups RSS, double versions of RSS, L-RSS, truncation-based RSS, and robust extreme RSS when the judgment rankings are both perfect and imperfect. Researchers can also use this new package to make parametric inferences for the population mean and the variance where the sample is obtained via classical RSS. Moreover, this package includes applications of the nonparametric methods which are one sample sign test, Mann-Whitney-Wilcoxon test, and Wilcoxon signed-rank test procedures. The package is available as *RSSampling* on CRAN.</p>
</div>
</a>
<a href="articles/RJ-2019-040/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 20, 2019</div>
<div class="dt-authors">
<div class="dt-author">Pere J. Ferrando</div>
<div class="dt-author">Urbano Lorenzo-Seva</div>
<div class="dt-author">David Navarro-Gonzalez</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>unival: An FA-based R Package For Assessing Essential Unidimensionality Using External Validity Information</h2>
<div class="dt-tags"></div>
<p>The *unival* package is designed to help researchers decide between unidimensional and correlated-factors solutions in the factor analysis of psychometric measures. The novelty of the approach is its use of *external* information, in which multiple factor scores and general factor scores are related to relevant external variables or criteria. The *unival* package's implementation comes from a series of procedures put forward by @FerrandoLorenzo-Seva:2019 and new methodological developments proposed in this article. We assess models fitted using *unival* by means of a simulation study extending the results obtained in the original proposal. Its usefulness is also assessed through a real-world data example. Based on these results, we conclude *unival* is a valuable tool for use in applications in which the dimensionality of an item set is to be assessed.</p>
</div>
</a>
<a href="articles/RJ-2019-035/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 18, 2019</div>
<div class="dt-authors">
<div class="dt-author">Josue M. Polanco-Martinez</div>
<div class="dt-author">Martin A. Medina-Elizalde</div>
<div class="dt-author">Maria F. Sanchez Goni</div>
<div class="dt-author">Manfred Mudelsee</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>BINCOR: An R package for Estimating the Correlation between Two Unevenly Spaced Time Series</h2>
<div class="dt-tags"></div>
<p>This paper presents a computational program named *BINCOR* (BINned CORrelation) for estimating the correlation between two unevenly spaced time series. This program is also applicable to the situation of two evenly spaced time series not on the same time grid. *BINCOR* is based on a novel estimation approach proposed by [@mudelsee_2010] for estimating the correlation between two climate time series with different timescales. The idea is that autocorrelation (e.g.an AR1 process) means that memory enables values obtained on different time points to be correlated. Binned correlation is performed by resampling the time series under study into time bins on a regular grid, assigning the mean values of the variable under scrutiny within those bins. We present two examples of our *BINCOR* package with real data: instrumental and paleoclimatic time series. In both applications *BINCOR* works properly in detecting well-established relationships between the climate records compared.</p>
</div>
</a>
<a href="articles/RJ-2019-036/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 18, 2019</div>
<div class="dt-authors">
<div class="dt-author">Alicja Gosiewska</div>
<div class="dt-author">Przemysaw Biecek</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>auditor: an R Package for Model-Agnostic Visual Validation and Diagnostics</h2>
<div class="dt-tags"></div>
<p>Machine learning models have successfully been applied to challenges in applied in biology, medicine, finance, physics, and other fields. With modern software it is easy to train even a complex model that fits the training data and results in high accuracy on test set. However, problems often arise when models are confronted with the real-world data. This paper describes methodology and tools for model-agnostic auditing. It provides functinos for assessing and comparing the goodness of fit and performance of models. In addition, the package may be used for analysis of the similarity of residuals and for identification of outliers and influential observations. The examination is carried out by diagnostic scores and visual verification. The code presented in this paper are implemented in the [*auditor*](https://CRAN.R-project.org/package=auditor) package. Its flexible and consistent grammar facilitates the validation models of a large class of models.</p>
</div>
</a>
<a href="articles/RJ-2019-024/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2019</div>
<div class="dt-authors">
<div class="dt-author">Michael Dorman</div>
<div class="dt-author">Evyatar Erell</div>
<div class="dt-author">Adi Vulkan</div>
<div class="dt-author">Itai Kloog</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>shadow: R Package for Geometric Shadow Calculations in an Urban Environment</h2>
<div class="dt-tags"></div>
<p>This paper introduces the *shadow* package for R. The package provides functions for shadow-related calculations in the urban environment, namely shadow height, shadow footprint and Sky View Factor (SVF) calculations, as well as a wrapper function to estimate solar radiation while taking shadow effects into account. All functions operate on a layer of polygons with a height attribute, also known as "extruded polygons" or 2.5D vector data. Such data are associated with accuracy limitations in representing urban environments. However, unlike 3D models, polygonal layers of building outlines along with their height are abundantly available and their processing does not require specialized closed-source 3D software. The present package thus brings spatio-temporal shadow, SVF and solar radiation calculation capabilities to the open-source spatial analysis workflow in R. Package functionality is demonstrated using small reproducible examples for each function. Wider potential use cases include urban environment applications such as evaluation of micro-climatic influence for urban planning, studying urban climatic comfort and estimating photovoltaic energy production potential.</p>
</div>
</a>
<a href="articles/RJ-2019-025/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2019</div>
<div class="dt-authors">
<div class="dt-author">Claudia Cava</div>
<div class="dt-author">Isabella Castiglioni</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Integration of networks and pathways with StarBioTrek package</h2>
<div class="dt-tags"></div>
<p>High-throughput genomic technologies bring to light a comprehensive
hallmark of molecular changes of a disease. It is increasingly evident
that genes are not isolated from each other and the identification of
a gene signature can only partially elucidate the de-regulated
biological functions in a disease. The comprehension of how groups of
genes (pathways) are related to each other (pathway-cross talk) could
explain biological mechanisms causing diseases. Biological pathways
are important tools to identify gene interactions and decrease the
large number of genes to be studied by partitioning them into smaller
groups. Furthermore, recent scientific studies have demonstrated that
an integration of pathways and networks, instead of a single component
of the pathway or a single network, could lead to a deeper
understanding of the pathology.\
*StarBioTrek* is an R package for the integration of biological
pathways and networks which provides a series of functions to support
the user in their analyses. In particular, it implements algorithms to
identify pathways cross-talk networks and gene network drivers in
pathways. It is available as open source and open development software
in the Bioconductor platform.</p>
</div>
</a>
<a href="articles/RJ-2019-026/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2019</div>
<div class="dt-authors">
<div class="dt-author">Dr. Rheanna Mainzer</div>
<div class="dt-author">Dr. Paul Kabaila</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ciuupi: An R package for Computing Confidence Intervals that Utilize Uncertain Prior Information</h2>
<div class="dt-tags"></div>
<p>We have created the R package *ciuupi* to compute confidence intervals that utilize uncertain prior information in linear regression. Unlike post-model-selection confidence intervals, the confidence interval that utilizes uncertain prior information (CIUUPI) implemented in this package has, to an excellent approximation, coverage probability throughout the parameter space that is very close to the desired minimum coverage probability. Furthermore, when the uncertain prior information is correct, the CIUUPI is, on average, shorter than the standard confidence interval constructed using the full linear regression model. In this paper we provide motivating examples of scenarios where the CIUUPI may be used. We then give a detailed description of this interval and the numerical constrained optimization method implemented in R to obtain it. Lastly, using a real data set as an illustrative example, we show how to use the functions in *ciuupi*.</p>
</div>
</a>
<a href="articles/RJ-2019-027/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2019</div>
<div class="dt-authors">
<div class="dt-author">Hengshi Yu</div>
<div class="dt-author">Fan Li</div>
<div class="dt-author">John A. Gallis</div>
<div class="dt-author">Elizabeth L. Turner</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>cvcrand: A Package for Covariate-constrained Randomization and the Clustered Permutation Test for Cluster Randomized Trials</h2>
<div class="dt-tags"></div>
<p>The cluster randomized trial (CRT) is a randomized controlled trial in which randomization is conducted at the cluster level (e.g., school or hospital) and outcomes are measured for each individual within a cluster. Often, the number of clusters available to randomize is small ($\leq$ 20), which increases the chance of baseline covariate imbalance between comparison arms. Such imbalance is particularly problematic when the covariates are predictive of the outcome because it can threaten the internal validity of the CRT. Pair-matching and stratification are two restricted randomization approaches that are frequently used to ensure balance at the design stage. An alternative, less commonly-used restricted randomization approach is covariate-constrained randomization. Covariate-constrained randomization quantifies baseline imbalance of cluster-level covariates using a balance metric and randomly selects a randomization scheme from those with acceptable balance by the balance metric. It is able to accommodate multiple covariates, both categorical and continuous. To facilitate implementation of covariate-constrained randomization for the design of two-arm parallel CRTs, we have developed the *cvcrand* R package. In addition, *cvcrand* also implements the clustered permutation test for analyzing continuous and binary outcomes collected from a CRT designed with covariate-constrained randomization. We used a real cluster randomized trial to illustrate the functions included in the package.</p>
</div>
</a>
<a href="articles/RJ-2019-028/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2019</div>
<div class="dt-authors">
<div class="dt-author">Matteo Quartagno</div>
<div class="dt-author">Simon Grund</div>
<div class="dt-author">James Carpenter</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>jomo: A Flexible Package for Two-level Joint Modelling Multiple Imputation</h2>
<div class="dt-tags"></div>
<p>Multiple imputation is a tool for parameter estimation and inference with partially observed data, which is used increasingly widely in medical and social research. When the data to be imputed are correlated or have a multilevel structure --- repeated observations on patients, school children nested in classes within schools within educational districts --- the imputation model needs to include this structure. Here we introduce our **jo**int **mo**delling package for multiple imputation of multilevel data, [*jomo*](https://CRAN.R-project.org/package=jomo), which uses a multivariate normal model fitted by Markov Chain Monte Carlo (MCMC). Compared to previous packages for multilevel imputation, e.g.[*pan*](https://CRAN.R-project.org/package=pan), *jomo* adds the facility to (i) handle and impute categorical variables using a latent normal structure, (ii) impute level-2 variables, and (iii) allow for cluster-specific covariance matrices, including the option to give them an inverse-Wishart distribution at level 2. The package uses C routines to speed up the computations and has been extensively validated in simulation studies both by ourselves and others.</p>
</div>
</a>
<a href="articles/RJ-2019-029/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2019</div>
<div class="dt-authors">
<div class="dt-author">Di Shu</div>
<div class="dt-author">Grace Y. Yi</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ipwErrorY: An R Package for Estimation of Average Treatment Effect with Misclassified Binary Outcome</h2>
<div class="dt-tags"></div>
<p>It has been well documented that ignoring measurement error may result in severely biased inference results. In recent years, there has been limited but increasing research on causal inference with measurement error. In the presence of misclassified binary outcome variable, [@ShuYi2017] considered the inverse probability weighted estimation of the average treatment effect and proposed valid estimation methods to correct for misclassification effects for various settings. To expedite the application of those methods for situations where misclassification in the binary outcome variable is a real concern, we implement correction methods proposed by [@ShuYi2017] and develop an R package *ipwErrorY* for general users. Simulated datasets are used to illustrate the use of the developed package.</p>
</div>
</a>
<a href="articles/RJ-2019-030/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2019</div>
<div class="dt-authors">
<div class="dt-author">Dr.Florian Gerber</div>
<div class="dt-author">Prof.Dr.Reinhard Furrer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>optimParallel: An R Package Providing a Parallel Version of the L-BFGS-B Optimization Method</h2>
<div class="dt-tags"></div>
<p>The Rpackage *optimParallel* provides a parallel version of the L-BFGS-B optimization method of `optim()`. The main function of the package is `optimParallel()`, which has the same usage and output as `optim()`. Using `optimParallel()` can significantly reduce the optimization time, especially when the evaluation time of the objective function is large and no analytical gradient is available. We introduce the Rpackage and illustrate its implementation, which takes advantage of the lexical scoping mechanism ofR.</p>
</div>
</a>
<a href="articles/RJ-2019-031/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2019</div>
<div class="dt-authors">
<div class="dt-author">Juan Xiong</div>
<div class="dt-author">Grace Y. Yi</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>swgee: An R Package for Analyzing Longitudinal Data with Response Missingness and Covariate Measurement Error</h2>
<div class="dt-tags"></div>
<p>Though longitudinal data often contain missing responses and error-prone covariates, relatively little work has been available to simultaneously correct for the effects of response missingness and covariate measurement error on analysis of longitudinal data. @r26 proposed a simulation based marginal method to adjust for the bias induced by measurement error in covariates as well as by missingness in response. The proposed method focuses on modeling the marginal mean and variance structures, and the missing at random mechanism is assumed. Furthermore, the distribution of covariates are left unspecified. These features make the proposed method applicable to a broad settings. In this paper, we develop an R package, called *swgee*, which implements the method proposed by @r26. Moreover, our package includes additional implementation steps which extend the setting considered by @r26. To describe the use of the package and its main features, we report simulation studies and analyses of a data set arising from the Framingham Heart Study.</p>
</div>
</a>
<a href="articles/RJ-2019-032/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2019</div>
<div class="dt-authors">
<div class="dt-author">Francesca Ieva</div>
<div class="dt-author">Anna Maria Paganoni</div>
<div class="dt-author">Juan Romo</div>
<div class="dt-author">Nicholas Tarabelloni</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>roahd Package: Robust Analysis of High Dimensional Data</h2>
<div class="dt-tags"></div>
<p>The focus of this paper is on the open-source R package *roahd* (**RO**bust **A**nalysis of **H**igh dimensional **D**ata), see [@roahd]. *roahd* has been developed to gather recently proposed statistical methods that deal with the robust inferential analysis of univariate and multivariate functional data. In particular, efficient methods for outlier detection and related graphical tools, methods to represent and simulate functional data, as well as inferential tools for testing differences and dependency among families of curves will be discussed, and the associated functions of the package will be described in details.</p>
</div>
</a>
<a href="articles/RJ-2019-033/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2019</div>
<div class="dt-authors">
<div class="dt-author">Mateusz Staniak</div>
<div class="dt-author">Przemysaw Biecek</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The Landscape of R Packages for Automated Exploratory Data Analysis</h2>
<div class="dt-tags"></div>
<p>The increasing availability of large but noisy data sets with a large
number of heterogeneous variables leads to the increasing interest in
the automation of common tasks for data analysis. The most
time-consuming part of this process is the Exploratory Data Analysis,
crucial for better domain understanding, data cleaning, data
validation, and feature engineering.\
There is a growing number of libraries that attempt to automate some
of the typical Exploratory Data Analysis tasks to make the search for
new insights easier and faster. In this paper, we present a systematic
review of existing tools for Automated Exploratory Data Analysis
(autoEDA). We explore the features of fifteen popular R packages to
identify the parts of analysis that can be effectively automated with
the current tools and to point out new directions for further autoEDA
development.</p>
</div>
</a>
<a href="articles/RJ-2019-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 16, 2019</div>
<div class="dt-authors">
<div class="dt-author">Radosaw Piliszek</div>
<div class="dt-author">Krzysztof Mnich</div>
<div class="dt-author">Szymon Migacz</div>
<div class="dt-author">Pawe Tabaszewski</div>
<div class="dt-author">Andrzej Suecki</div>
<div class="dt-author">Aneta Polewko-Klim</div>
<div class="dt-author">Witold Rudnicki</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>MDFS: MultiDimensional Feature Selection in R</h2>
<div class="dt-tags"></div>
<p>Identification of informative variables in an information system is often performed using simple one-dimensional filtering procedures that discard information about interactions between variables. Such an approach may result in removing some relevant variables from consideration. Here we present an R package *MDFS* (MultiDimensional Feature Selection) that performs identification of informative variables taking into account synergistic interactions between multiple descriptors and the decision variable. *MDFS* is an implementation of an algorithm based on information theory [@DBLP:journals/corr/MnichR17]. The computational kernel of the package is implemented in C++. A high-performance version implemented in CUDA C is also available. The application of *MDFS* is demonstrated using the well-known Madelon dataset, in which a decision variable is generated from synergistic interactions between descriptor variables. It is shown that the application of multidimensional analysis results in better sensitivity and ranking of importance.</p>
</div>
</a>
<a href="articles/RJ-2019-020/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 16, 2019</div>
<div class="dt-authors">
<div class="dt-author">Serge de Valk</div>
<div class="dt-author">Daiane Marcolino de Mattos</div>
<div class="dt-author">Pedro Guilherme Costa Ferreira</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Nowcasting: An R Package for Predicting Economic Variables Using Dynamic Factor Models</h2>
<div class="dt-tags"></div>
<p>The [*nowcasting*](https://CRAN.R-project.org/package=nowcasting) package provides the tools to make forecasts of monthly or quarterly economic variables using dynamic factor models. The objective is to help the user at each step of the forecasting process, starting with the construction of a database, all the way to the interpretation of the forecasts. The dynamic factor model adopted in this package is based on the articles from @giannoneetal2008 and @banburaetal2011. Although there exist several other dynamic factor model packages available for R, ours provides an environment to easily forecast economic variables and interpret results.</p>
</div>
</a>
<a href="articles/RJ-2019-021/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 16, 2019</div>
<div class="dt-authors">
<div class="dt-author">Roberto Sichera</div>
<div class="dt-author">Pietro Pizzuto</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ConvergenceClubs: A Package for Performing the Phillips and Sul's Club Convergence Clustering Procedure</h2>
<div class="dt-tags"></div>
<p>This paper introduces package ConvergenceClubs, which implements functions to perform the @PhillipsSul2007 [@PhillipsSul2009] club convergence clustering procedure in a simple and reproducible manner. The approach proposed by Phillips and Sul to analyse the convergence patterns of groups of economies is formulated as a nonlinear time varying factor model that allows for different time paths as well as individual heterogeneity. Unlike other approaches in which economies are grouped a priori, it also allows the endogenous determination of convergence clubs. The algorithm, usage, and implementation details are discussed.</p>
</div>
</a>
<a href="articles/RJ-2019-022/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 16, 2019</div>
<div class="dt-authors">
<div class="dt-author">Allison Fialkowski</div>
<div class="dt-author">Hemant Tiwari</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SimCorrMix: Simulation of Correlated Data with Multiple Variable Types Including Continuous and Count Mixture Distributions</h2>
<div class="dt-tags"></div>
<p>The *SimCorrMix* package generates correlated continuous (normal, non-normal, and mixture), binary, ordinal, and count (regular and zero-inflated, Poisson and Negative Binomial) variables that mimic real-world data sets. Continuous variables are simulated using either Fleishman's third-order or Headrick's fifth-order power method transformation. Simulation occurs at the component level for continuous mixture distributions, and the target correlation matrix is specified in terms of correlations with components. However, the package contains functions to approximate expected correlations with continuous mixture variables. There are two simulation pathways which calculate intermediate correlations involving count variables differently, increasing accuracy under a wide range of parameters. The package also provides functions to calculate cumulants of continuous mixture distributions, check parameter inputs, calculate feasible correlation boundaries, and summarize and plot simulated variables. *SimCorrMix* is an important addition to existing R simulation packages because it is the first to include continuous mixture and zero-inflated count variables in correlated data sets.</p>
</div>
</a>
<a href="articles/RJ-2019-023/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 16, 2019</div>
<div class="dt-authors">
<div class="dt-author">Alexis Sard-Espinosa</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Time-Series Clustering in R Using the dtwclust Package</h2>
<div class="dt-tags"></div>
<p>Most clustering strategies have not changed considerably since their initial definition. The common improvements are either related to the distance measure used to assess dissimilarity, or the function used to calculate prototypes. Time-series clustering is no exception, with the Dynamic Time Warping distance being particularly popular in that context. This distance is computationally expensive, so many related optimizations have been developed over the years. Since no single clustering algorithm can be said to perform best on all datasets, different strategies must be tested and compared, so a common infrastructure can be advantageous. In this manuscript, a general overview of shape-based time-series clustering is given, including many specifics related to Dynamic Time Warping and associated techniques. At the same time, a description of the [*dtwclust*](https://CRAN.R-project.org/package=dtwclust) package for the R statistical software is provided, showcasing how it can be used to evaluate many different time-series clustering procedures.</p>
</div>
</a>
<a href="articles/RJ-2019-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 15, 2019</div>
<div class="dt-authors">
<div class="dt-author">Charlotte Dion</div>
<div class="dt-author">Simone Hermann</div>
<div class="dt-author">Adeline Samson</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>mixedsde: A Package to Fit Mixed Stochastic Differential Equations</h2>
<div class="dt-tags"></div>
<p>Stochastic differential equations (SDEs) are useful to model continuous stochastic processes. When (independent) repeated temporal data are available, variability between the trajectories can be modeled by introducing random effects in the drift of the SDEs. These models are useful to analyze neuronal data, crack length data, pharmacokinetics, financial data, to cite some applications among other. The `R` package focuses on the estimation of SDEs with linear random effects in the drift. The goal is to estimate the common density of the random effects from repeated discrete observations of the SDE. The package *mixedsde* proposes three estimation methods: a Bayesian parametric, a frequentist parametric and a frequentist nonparametric method. The three procedures are described as well as the main functions of the package. Illustrations are presented on simulated and real data.</p>
</div>
</a>
<a href="articles/RJ-2019-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 15, 2019</div>
<div class="dt-authors">
<div class="dt-author">Emilio Sansano</div>
<div class="dt-author">Ral Montoliu</div>
<div class="dt-author">scar Belmonte</div>
<div class="dt-author">Joaqun Torres-Sospedra</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Indoor Positioning and Fingerprinting: The R Package ipft</h2>
<div class="dt-tags"></div>
<p>Methods based on Received Signal Strength Indicator (RSSI) fingerprinting are in the forefront among several techniques being proposed for indoor positioning. This paper introduces the R package [*ipft*](https://CRAN.R-project.org/package=ipft), which provides algorithms and utility functions for indoor positioning using fingerprinting techniques. These functions are designed for manipulation of RSSI fingerprint data sets, estimation of positions, comparison of the performance of different positioning models, and graphical visualization of data. Well-known machine learning algorithms are implemented in this package to perform analysis and estimations over RSSI data sets. The paper provides a description of these algorithms and functions, as well as examples of its use with real data. The [*ipft*](https://CRAN.R-project.org/package=ipft) package provides a base that we hope to grow into a comprehensive library of fingerprinting-based indoor positioning methodologies.</p>
</div>
</a>
<a href="articles/RJ-2019-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 15, 2019</div>
<div class="dt-authors">
<div class="dt-author">Mengyang Gu</div>
<div class="dt-author">Jess Palomo</div>
<div class="dt-author">James O. Berger</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>RobustGaSP: Robust Gaussian Stochastic Process Emulation in R</h2>
<div class="dt-tags"></div>
<p>Gaussian stochastic process (GaSP) emulation is a powerful tool for approximating computationally intensive computer models. However, estimation of parameters in the GaSP emulator is a challenging task. No closed-form estimator is available and many numerical problems arise with standard estimates, e.g., the maximum likelihood estimator. In this package, we implement a marginal posterior mode estimator, for special priors and parameterizations. This estimation method that meets the robust parameter estimation criteria was discussed in [@Gu2018robustness]; mathematical reasons are provided therein to explain why robust parameter estimation can greatly improve predictive performance of the emulator. In addition, inert inputs (inputs that almost have no effect on the variability of a function) can be identified from the marginal posterior mode estimation at no extra computational cost. The package also implements the parallel partial Gaussian stochastic process (PP GaSP) emulator ([@gu2016parallel]) for the scenario where the computer model has multiple outputs on, for example, spatial-temporal coordinates. The package can be operated in a default mode, but also allows numerous user specifications, such as the capability of specifying trend functions and noise terms. Examples are studied herein to highlight the performance of the package in terms of out-of-sample prediction.</p>
</div>
</a>
<a href="articles/RJ-2019-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 15, 2019</div>
<div class="dt-authors">
<div class="dt-author">Lu Ou</div>
<div class="dt-author">Michael D. Hunter</div>
<div class="dt-author">Sy-Miin Chow</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>What's for dynr: A Package for Linear and Nonlinear Dynamic Modeling in R</h2>
<div class="dt-tags"></div>
<p>Intensive longitudinal data in the behavioral sciences are often noisy, multivariate in nature, and may involve multiple units undergoing regime switches by showing discontinuities interspersed with continuous dynamics. Despite increasing interest in using linear and nonlinear differential/difference equation models with regime switches, there has been a scarcity of software packages that are fast and freely accessible. We have created an R package called *dynr* that can handle a broad class of linear and nonlinear discrete- and continuous-time models, with regime-switching properties and linear Gaussian measurement functions, in C, while maintaining simple and easy-to-learn model specification functions in R. We present the mathematical and computational bases used by the *dynr* R package, and present two illustrative examples to demonstrate the unique features of *dynr*.</p>
</div>
</a>
<a href="articles/RJ-2019-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 15, 2019</div>
<div class="dt-authors">
<div class="dt-author">Gianmarco Vacca</div>
<div class="dt-author">Maria Grazia Zoia</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Identifying and Testing Recursive vs. Interdependent Links in Simultaneous Equation Models via the SIRE Package</h2>
<div class="dt-tags"></div>
<p>Simultaneous equation models (SEMs) are composed of relations which
either represent unidirectional links, which entail a causal
interpretation, or bidirectional links, due to feedback loops, which
lead to the notion of interdependence. The issue is of prominent
interest in several respects. Investigating the causal structure of a
SEM, on the one hand, brings to light the theoretical assumptions
behind the model and, on the other hand, pilots the choice of the
befitting estimation method and of which policy to implement.\
This paper provides an operational method to distinguish causal
relations from interdependent ones in SEMs, such as macro-econometric
models, models in ecology, biology, demography, and so forth. It is
shown that the causal structure of a system crucially rests on the
feedback loops, which possibly affect the equations. These loops are
associated to the non-null entries of the Hadamard product of matrices
encoding the direct and indirect links among the SEM dependent
variables. The effectiveness of feedbacks is verified with a Wald test
based on the significance of the aforementioned non-null entries.\
An R package, *SIRE* (System of Interdependent/Recursive Equations),
provides the operational completion of the methodological and analytic
results of the paper. *SIRE* is applied to a macroeconomic model to
illustrate how this type of analysis proves useful in clarifying the
nature of the complex relations in SEMs.</p>
</div>
</a>
<a href="articles/RJ-2019-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 15, 2019</div>
<div class="dt-authors">
<div class="dt-author">Maria Brigida Ferraro</div>
<div class="dt-author">Paolo Giordani</div>
<div class="dt-author">Alessio Serafini</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>fclust: An R Package for Fuzzy Clustering</h2>
<div class="dt-tags"></div>
<p>Fuzzy clustering methods discover fuzzy partitions where observations can be softly assigned to more than one cluster. The package *fclust* is a toolbox for fuzzy clustering in the R programming language. It not only implements the widely used fuzzy $k$-means (F$k$M) algorithm, but also many F$k$M variants. Fuzzy cluster similarity measures, cluster validity indices and cluster visualization tools are also offered. In the current version, all the functions are rewritten in the C++ language allowing their application in large-size problems. Moreover, new fuzzy relational clustering algorithms for partitioning qualitative/mixed data are provided together with an improved version of the so-called Gustafson-Kessel algorithm to avoid singularity in the cluster covariance matrices. Finally, it is now possible to automatically select the number of clusters by means of the available fuzzy cluster validity indices.</p>
</div>
</a>
<a href="articles/RJ-2019-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 15, 2019</div>
<div class="dt-authors">
<div class="dt-author">Massimo Cannas</div>
<div class="dt-author">Bruno Arpino</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Matching with Clustered Data: the CMatching Package in R</h2>
<div class="dt-tags"></div>
<p>Matching is a well known technique to balance covariates distribution between treated and control units in non-experimental studies. In many fields, clustered data are a very common occurrence in the analysis of observational data and the clustering can add potentially interesting information. Matching algorithms should be adapted to properly exploit the hierarchical structure. In this article we present the CMatching package implementing matching algorithms for clustered data. The package provides functions for obtaining a matched dataset along with estimates of most common parameters of interest and model-based standard errors. A propensity score matching analysis, relating math proficiency with homework completion for students belonging to different schools (based on the NELS-88 data), illustrates in detail the use of the algorithms.</p>
</div>
</a>
<a href="articles/RJ-2019-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 30, 2019</div>
<div class="dt-authors">
<div class="dt-author">Michael Kipp</div>
<div class="dt-author">Ursula Laa</div>
<div class="dt-author">Dianne Cook</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Connecting R with D3 for dynamic graphics, to explore multivariate data with tours</h2>
<div class="dt-tags"></div>
<p>The [*tourr*](https://CRAN.R-project.org/package=tourr) package in R
has several algorithms and displays for showing multivariate data as a
sequence of low-dimensional projections. It can display as a movie but
has no capacity for interaction, such as stop/go, change tour type,
drop/add variables. The
[*tourrGui*](https://CRAN.R-project.org/package=tourrGui) package
provides these sorts of controls, but the interface is programmed with
the dated [*RGtk2*](https://CRAN.R-project.org/package=RGtk2) package.
This work explores using custom messages to pass data from R to D3 for
viewing, using the Shiny framework. This is an approach that can be
generally used for creating all sorts of interactive graphics.\</p>
</div>
</a>
<a href="articles/RJ-2019-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 30, 2019</div>
<div class="dt-authors">
<div class="dt-author">Hyowon An</div>
<div class="dt-author">Justin T. Landis</div>
<div class="dt-author">Aubrey G. Bailey</div>
<div class="dt-author">J. S. Marron</div>
<div class="dt-author">Dirk P. Dittmer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>dr4pl: A Stable Convergence Algorithm for the 4 Parameter Logistic Model</h2>
<div class="dt-tags"></div>
<p>The *4 Parameter Logistic* (*4PL*) *model* has been recognized as a major tool to analyze the relationship between doses and responses in pharmacological experiments. A main strength of this model is that each parameter contributes an intuitive meaning enhancing interpretability of a fitted model. However, implementing the 4PL model using conventional statistical software often encounters numerical errors. This paper highlights the issue of convergence failure and presents several causes with solutions. These causes include outliers and a non-logistic data shape, so useful remedies such as robust estimation, outlier diagnostics and constrained optimization are proposed. These features are implemented in a new R package dr4pl (Dose-Response analysis using the 4 Parameter Logistic model) whose code examples are presented as a separate section. Our R package dr4pl is shown to work well for data sets where the traditional dose-response modelling packages drc and nplr fail.</p>
</div>
</a>
<a href="articles/RJ-2019-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 30, 2019</div>
<div class="dt-authors">
<div class="dt-author">Francisco Martnez</div>
<div class="dt-author">Mara P. Fras</div>
<div class="dt-author">Francisco Charte</div>
<div class="dt-author">Antonio J. Rivera</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Time Series Forecasting with KNN in R: the tsfknn Package</h2>
<div class="dt-tags"></div>
<p>In this paper the *tsfknn* package for time series forecasting using $k$-nearest neighbor regression is described. This package allows users to specify a KNN model and to generate its forecasts. The user can choose among different multi-step ahead strategies and among different functions to aggregate the targets of the nearest neighbors. It is also possible to assess the forecast accuracy of the KNN model.</p>
</div>
</a>
<a href="articles/RJ-2019-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 30, 2019</div>
<div class="dt-authors">
<div class="dt-author">Kasey Jones</div>
<div class="dt-author">Rob Chew</div>
<div class="dt-author">Allison Witman</div>
<div class="dt-author">Yiyan (Echo) Liu</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>rollmatch: An R Package for Rolling Entry Matching</h2>
<div class="dt-tags"></div>
<p>The gold standard of experimental research is the randomized control trial. However, interventions are often implemented without a randomized control group for practical or ethical reasons. Propensity score matching (PSM) is a popular method for minimizing the effects of a randomized experiment from observational data by matching members of a treatment group to similar candidates that did not receive the intervention. Traditional PSM is not designed for studies that enroll participants on a rolling basis and does not provide a solution for interventions in which the baseline and intervention period are undefined in the comparison group. Rolling Entry Matching (REM) is a new matching method that addresses both issues. REM selects comparison members who are similar to intervention members with respect to both static (e.g., race) and dynamic (e.g., health conditions) characteristics. This paper will discuss the key components of REM and introduce the [*rollmatch*](https://CRAN.R-project.org/package=rollmatch) R package.</p>
</div>
</a>
<a href="articles/RJ-2019-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 30, 2019</div>
<div class="dt-authors">
<div class="dt-author">Ruoqing Zhu</div>
<div class="dt-author">Jiyang Zhang</div>
<div class="dt-author">Ruilin Zhao</div>
<div class="dt-author">Peng Xu</div>
<div class="dt-author">Wenzhuo Zhou</div>
<div class="dt-author">Xin Zhang</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>orthoDr: Semiparametric Dimension Reduction via Orthogonality Constrained Optimization</h2>
<div class="dt-tags"></div>
<p>[*orthoDr*](https://CRAN.R-project.org/package=orthoDr) is a package in R that solves dimension reduction problems using orthogonality constrained optimization approach. The package serves as a unified framework for many regression and survival analysis dimension reduction models that utilize semiparametric estimating equations. The main computational machinery of *orthoDr* is a first-order algorithm developed by [@wen2013feasible] for optimization within the Stiefel manifold. We implement the algorithm through Rcpp and OpenMP for fast computation. In addition, we developed a general-purpose solver for such constrained problems with user-specified objective functions, which works as a drop-in version of optim(). The package also serves as a platform for future methodology developments along this line of work.</p>
</div>
</a>
<a href="articles/RJ-2019-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 30, 2019</div>
<div class="dt-authors">
<div class="dt-author">Eric J. Ward</div>
<div class="dt-author">Sean C. Anderson</div>
<div class="dt-author">Luis A. Damiano</div>
<div class="dt-author">Mary E. Hunsicker</div>
<div class="dt-author">Michael A. Litzow</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Modeling regimes with extremes: the bayesdfa package for identifying and forecasting common trends and anomalies in multivariate time-series data</h2>
<div class="dt-tags"></div>
<p>The *bayesdfa* package provides a flexible Bayesian modeling framework for applying dynamic factor analysis (DFA) to multivariate time-series data as a dimension reduction tool. The core estimation is done with the Stan probabilistic programming language. In addition to being one of the few Bayesian implementations of DFA, novel features of this model include (1) optionally modeling latent process deviations as drawn from a Student-t distribution to better model extremes, and (2) optionally including autoregressive and moving-average components in the latent trends. Besides estimation, we provide a series of plotting functions to visualize trends, loadings, and model predicted values. A secondary analysis for some applications is to identify regimes in latent trends. We provide a flexible Bayesian implementation of a Hidden Markov Model --- also written with Stan --- to characterize regime shifts in latent processes. We provide simulation testing and details on parameter sensitivities in supplementary information.</p>
</div>
</a>
<a href="articles/RJ-2019-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 30, 2019</div>
<div class="dt-authors">
<div class="dt-author">Diego Moretti</div>
<div class="dt-author">Luca Valentino</div>
<div class="dt-author">Tiziana Tuoto</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Optimization Routines for Enforcing One-to-One Matches in Record Linkage Problems</h2>
<div class="dt-tags"></div>
<p>Record linkage aims at quickly and accurately identifying if two records represent the same real world entity. In many applications, we are interested in restricting the linkage results to \"1 to 1\" links, that is a single record does not appear more than once in the output. This can be dealt with the transport algorithm. The optimization problem, however, grows quadratically in the size of the input, quickly becoming untreatable for cases with a few thousand records. This paper compares different solutions, provided by some R packages for linear programming solvers. The comparison is done in terms of memory usage and execution time. The aim is to overcome the current implementation in the toolkit RELAIS, specifically developed for record linkage problems. The results highlight improvements beyond expectations. In fact the tested solutions allow successfully executing the \"1 to 1\" reduction for large size datasets up to the largest sample surveys at National Statistical Institutes.</p>
</div>
</a>
<a href="articles/RJ-2019-041/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 30, 2019</div>
<div class="dt-authors">
<div class="dt-author">Jan-Philipp Kolb</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Using Web Services to Work with Geodata in R</h2>
<div class="dt-tags"></div>
<p>Through collaborative mapping, a massive amount of data is accessible.
Many individuals contribute information each day. The growing amount
of geodata is gathered by volunteers or obtained via crowd-sourcing.
One outstanding example of this is the OpenStreetMap (OSM) Project
which provides access to big data in geography. Another online mapping
service that enables the integration of geodata into the analysis is
Google Maps. The expanding content and the availability of geographic
information radically changes the perspective on geodata
(@chilton2009crowdsourcing). Recently many application programming
interfaces (APIs) have been built on OSM and Google Maps. That leads
to a point where it is possible to access sections of geographical
information without the usage of a complex database solution,
especially if one only requires a small data section for a
visualization.\
First tools for spatial analysis have been included in the R language
very early [@bivand2000implementing] and this development will
continue to accelerate, underpinning a continual change. Notably, in
recent years many tools have been developed to enable the usage of R
as a geographic information system (GIS). With a GIS it is possible to
process spatial data. QuantumGIS (QGIS) is a free software solution
for these tasks, and a user interface is available for this purpose. R
is, therefore, an alternative to geographic information systems like
QGIS (@QGIS_software). Besides, add-ins for QGIS and R-packages
([*RQGIS*](https://CRAN.R-project.org/package=RQGIS)) are available,
that enables the combination of R and QGIS (@ma:rqgis). It is the
target of this article to present some of the most important
R-functionalities to download and process geodata from OSM and the
Google Maps API. The focus of this paper is on functions that enable
the natural usage of these APIs.</p>
</div>
</a>
<a href="articles/RJ-2019-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 22, 2019</div>
<div class="dt-authors">
<div class="dt-author">Armin  Strbel</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>atable: Create Tables for Clinical Trial Reports</h2>
<div class="dt-tags"></div>
<p>Examining distributions of variables is the first step in the analysis of a clinical trial before more specific modelling can begin. Reporting these results to stakeholders of the trial is an essential part of a statistician's work. The *atable* package facilitates these steps by offering easy-to-use but still flexible functions.</p>
</div>
</a>
<a href="articles/RJ-2018-081/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 11, 2019</div>
<div class="dt-authors">
<div class="dt-author">Leyla Azarang</div>
<div class="dt-author">Manuel Oviedo de la Fuente</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>idmTPreg: Regression Model for Progressive Illness Death Data</h2>
<div class="dt-tags"></div>
<p>The progressive illness-death model is frequently used in medical applications. For example, the model may be used to describe the disease process in cancer studies. We have developed a new R package called *idmTPreg* to estimate regression coefficients in datasets that can be described by the progressive illness-death model. The motivation for the development of the package is a recent contribution that enables the estimation of possibly time-varying covariate effects on the transition probabilities for a progressive illness-death data. The main feature of the package is that it befits both non-Markov and Markov progressive illness-death data. The package implements the introduced estimators obtained using a direct binomial regression approach. Also, variance estimates and confidence bands are implemented in the package. This article presents guidelines for the use of the package.</p>
</div>
</a>
<a href="articles/RJ-2018-076/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 31, 2018</div>
<div class="dt-authors">
<div class="dt-author">Soren Jordan</div>
<div class="dt-author">Andrew Q. Philips</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Dynamic Simulation and Testing for Single-Equation Cointegrating and Stationary Autoregressive Distributed Lag Models</h2>
<div class="dt-tags"></div>
<p>While autoregressive distributed lagmodels allow for extremely flexible dynamics, interpreting the substantive significance of complex lag structures remains difficult. In this paper we discuss *dynamac* (dynamic autoregressive and cointegrating models), an `R` package designed to assist users in estimating, dynamically simulating, and plotting the results of a variety of autoregressive distributed lagmodels. It also contains a number of post-estimation diagnostics, including a test for cointegration for when researchers are estimating the error-correction variant of the autoregressive distributed lagmodel.</p>
</div>
</a>
<a href="articles/RJ-2018-074/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 13, 2018</div>
<div class="dt-authors">
<div class="dt-author">Patrcia Martinkov</div>
<div class="dt-author">Adla Drabinov</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ShinyItemAnalysis for Teaching Psychometrics and to Enforce Routine Analysis ofEducational Tests</h2>
<div class="dt-tags"></div>
<p>This work introduces *ShinyItemAnalysis*, an R package and an online shiny application for psychometric analysis of educational tests and items. *ShinyItemAnalysis* covers a broad range ofpsychometric methods and offers data examples, model equations, parameter estimates, interpretation of results, together with a selected R code, and is therefore suitable for teaching psychometric concepts with R. Furthermore, the application aspires to be an easy-to-use tool for analysis of educational tests by allowing the users to upload and analyze their own data and to automatically generate analysis reports in PDF or HTML. We argue that psychometric analysis should be a routine part of test development in order to gather proofs of reliability and validity of the measurement, and we demonstrate how *ShinyItemAnalysis* may help enforce this goal.</p>
</div>
</a>
<a href="articles/RJ-2018-075/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 13, 2018</div>
<div class="dt-authors">
<div class="dt-author">Iaki Ucar</div>
<div class="dt-author">Edzer Pebesma</div>
<div class="dt-author">Arturo Azcorra</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Measurement Errors in R</h2>
<div class="dt-tags"></div>
<p>This paper presents an R package to handle and represent measurements with errors in a very simple way. We briefly introduce the main concepts of metrology and propagation of uncertainty, and discuss related R packages. Building upon this, we introduce the *errors* package, which provides a class for associating uncertainty metadata, automated propagation and reporting. Working with *errors* enables transparent, lightweight, less error-prone handling and convenient representation of measurements with errors. Finally, we discuss the advantages, limitations and future work of computing with errors.</p>
</div>
</a>
<a href="articles/RJ-2018-070/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 11, 2018</div>
<div class="dt-authors">
<div class="dt-author">Pedro C. Ferreira</div>
<div class="dt-author">Talitha F. Speranza</div>
<div class="dt-author">Jonatha A. da Costa</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SARIMA Analysis and Automated Model Reports with BETS, an R Package</h2>
<div class="dt-tags"></div>
<p>This article aims to demonstrate how the powerful features of the R package *BETS* can be applied to SARIMA time series analysis. *BETS* provides not only thousands of Brazilian economic time series from different institutions, but also a range of analytical tools, and educational resources. In particular, *BETS* is capable of generating automated model reports for any given time series. These reports rely on a single function call and are able to build three types of models (SARIMA being one of them). The functions need few inputs and output rich content. The output varies according to the inputs and usually consists of a summary of the series properties, step-by-step explanations on how the model was developed, predictions made by the model, and a file containing these predictions. This work focuses on this feature and several other *BETS* functions that are designed to help in modeling time series. We present them in a thorough case study: the SARIMA approach to model and forecast the Brazilian production of intermediate goods index series.</p>
</div>
</a>
<a href="articles/RJ-2018-072/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 11, 2018</div>
<div class="dt-authors">
<div class="dt-author">Mateusz Staniak</div>
<div class="dt-author">Przemysaw Biecek</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Explanations of Model Predictions with live and breakDown Packages</h2>
<div class="dt-tags"></div>
<p>Complex models are commonly used in predictive modeling. In this paper we present R packages that can be used for explaining predictions from complex black box models and attributing parts of these predictions to input features. We introduce two new approaches and corresponding packages for such attribution, namely *live* and *breakDown*. We also compare their results with existing implementations of state-of-the-art solutions, namely, *lime* [@lime_pkg] which implements *Locally Interpretable Model-agnostic Explanations* and *iml* [@iml] which implements *Shapley values*.</p>
</div>
</a>
<a href="articles/RJ-2018-073/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 11, 2018</div>
<div class="dt-authors">
<div class="dt-author">Bojan Mihaljevi</div>
<div class="dt-author">Concha Bielza</div>
<div class="dt-author">Pedro Larraaga</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>bnclassify: Learning Bayesian Network Classifiers</h2>
<div class="dt-tags"></div>
<p>The *bnclassify* package provides state-of-the art algorithms for learning Bayesian network classifiers from data. For structure learning it provides variants of the greedy hill-climbing search, a well-known adaptation of the Chow-Liu algorithm and averaged one-dependence estimators. It provides Bayesian and maximum likelihood parameter estimation, as well as three naive-Bayes-specific methods based on discriminative score optimization and Bayesian model averaging. The implementation is efficient enough to allow for time-consuming discriminative scores on medium-sized data sets. The *bnclassify* package provides utilities for model evaluation, such as cross-validated accuracy and penalized log-likelihood scores, and analysis of the underlying networks, including network plotting via the *Rgraphviz* package. It is extensively tested, with over 200 automated tests that give a code coverage of 94%. Here we present the main functionalities, illustrate them with a number of data sets, and comment on related software.</p>
</div>
</a>
<a href="articles/RJ-2018-053/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 8, 2018</div>
<div class="dt-authors">
<div class="dt-author">Robin Lovelace</div>
<div class="dt-author">Richard Ellison</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>stplanr: A Package for Transport Planning</h2>
<div class="dt-tags"></div>
<p>Tools for transport planning should be flexible, scalable, and transparent. The *stplanr* package demonstrates and provides a home for such tools, with an emphasis on spatial transport data and non-motorized modes. The *stplanr* package facilitates common transport planning tasks including: downloading and cleaning transport datasets; creating geographic "desire lines" from origin-destination (OD) data; route assignment, locally and interfaces to routing services such as [CycleStreets.net](CycleStreets.net){.uri}; calculation of route segment attributes such as bearing and aggregate flow; and 'travel watershed' analysis. This paper demonstrates this functionality using reproducible examples on real transport datasets. More broadly, the experience of developing and using R functions for transport applications shows that open source software can form the basis of a reproducible transport planning workflow. The *stplanr* package, alongside other packages and open source projects, could provide a more transparent and democratically accountable alternative to the current approach, which is heavily reliant on proprietary and relatively inaccessible software.</p>
</div>
</a>
<a href="articles/RJ-2018-054/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 8, 2018</div>
<div class="dt-authors">
<div class="dt-author">Juri Hinz</div>
<div class="dt-author">Jeremy Yee</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>rcss: R package for optimal convex stochastic switching</h2>
<div class="dt-tags"></div>
<p>The R package *rcss* provides users with a tool to approximate the value functions in the Bellman recursion under certain assumptions that guarantee desirable convergence properties. This R package represents the first software implementation of these methods using matrices and nearest neighbors. This package also employs a pathwise dynamic method to gauge the quality of these value function approximations. Statistical analysis can be performed on the results to obtain other useful practical insights. This paper describes *rcss* version 1.6.</p>
</div>
</a>
<a href="articles/RJ-2018-055/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 8, 2018</div>
<div class="dt-authors">
<div class="dt-author">Renata Tiene de Carvalho Yokota</div>
<div class="dt-author">Caspar W. N. Looman</div>
<div class="dt-author">Wilma Johanna Nusselder</div>
<div class="dt-author">Herman Van Oyen</div>
<div class="dt-author">Geert Molenberghs</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>addhaz: Contribution of Chronic Diseases to the Disability Burden Using R</h2>
<div class="dt-tags"></div>
<p>The increase in life expectancy followed by the burden of chronic diseases contributes to disability at older ages. The estimation of how much chronic conditions contribute to disability can be useful to develop public health strategies to reduce the burden. This paper introduces the R package *addhaz*, which is based on the attribution method [@nusselder2004] to partition disability into the additive contributions of diseases using cross-sectional data. The R package includes tools to fit the additive hazard model, the core of the attribution method, to binary and multinomial outcomes. The models are fitted by maximizing the binomial and multinomial log-likelihood functions using constrained optimization. Wald and bootstrap confidence intervals can be obtained for the parameter estimates. Also, the contribution of diseases to the disability prevalence and their bootstrap confidence intervals can be estimated. An additional feature is the possibility to use parallel computing to obtain the bootstrap confidence intervals. In this manuscript, we illustrate the use of *addhaz* with several examples for the binomial and multinomial models, using the data from the Brazilian National Health Survey, 2013.</p>
</div>
</a>
<a href="articles/RJ-2018-056/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 8, 2018</div>
<div class="dt-authors">
<div class="dt-author">Yuzhou Chen</div>
<div class="dt-author">Yulia R. Gel, Kusha Nezafati</div>
<div class="dt-author">Vyacheslav Lyubchich</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Snowboot: Bootstrap Methods for Network Inference</h2>
<div class="dt-tags"></div>
<p>Complex networks are used to describe a broad range of disparate social systems and natural phenomena, from power grids to customer segmentation to human brain connectome. Challenges of parametric model specification and validation inspire a search for more data-driven and flexible nonparametric approaches for inference of complex networks. In this paper we discuss methodology and R implementation of two bootstrap procedures on random networks, that is, patchwork bootstrap of @Thompson:etal:2016 and @Gel:etal:2016 and vertex bootstrap of @Snijders:Borgatti:1999. To our knowledge, the new R package *snowboot* is the first implementation of the vertex and patchwork bootstrap inference on networks in R. Our new package is accompanied with a detailed user's manual, and is compatible with the popular R package on network studies *igraph*. We evaluate the patchwork bootstrap and vertex bootstrap with extensive simulation studies and illustrate their utility in an application to analysis of real world networks.</p>
</div>
</a>
<a href="articles/RJ-2018-057/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 8, 2018</div>
<div class="dt-authors">
<div class="dt-author">Jeffrey Miecznikowski</div>
<div class="dt-author">En-shuo Hsu</div>
<div class="dt-author">Yanhua Chen</div>
<div class="dt-author">Albert Vexler</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>testforDEP: An R Package for Modern Distribution-free Tests and Visualization Tools for Independence</h2>
<div class="dt-tags"></div>
<p>This article introduces [*testforDEP*](https://CRAN.R-project.org/package=testforDEP), a portmanteau R package implementing for the first time several modern tests and visualization tools for independence between two variables. While classical tests for independence are in the base R packages, there have been several recently developed tests for independence that are not available in R. This new package combines the classical tests including Pearson's product moment correlation coefficient method, Kendall's $\tau$ rank correlation coefficient method and Spearman's $\rho$ rank correlation coefficient method with modern tests consisting of an empirical likelihood based test, a density-based empirical likelihood ratio test, Kallenberg data-driven test, maximal information coefficient test, Hoeffding's independence test and the continuous analysis of variance test. For two input vectors of observations, the function `testforDEP` provides a common interface for each of the tests and returns test statistics, corresponding $p$values and bootstrap confidence intervals as output. The function `AUK` provides an interface to visualize Kendall plots and computes the area under the Kendall plot similar to computing the area under a receiver operating characteristic (ROC) curve.</p>
</div>
</a>
<a href="articles/RJ-2018-058/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 8, 2018</div>
<div class="dt-authors">
<div class="dt-author">Julia Silge</div>
<div class="dt-author">John C. Nash</div>
<div class="dt-author">Spencer Graves</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Navigating the R Package Universe</h2>
<div class="dt-tags"></div>
<p>Today, the enormous number of contributed packages available to R
users outstrips any given user's ability to understand how these
packages work, their relative merits, or how they are related to each
other. We organized a plenary session at useR!2017 in Brussels for the
R community to think through these issues and ways forward. This
session considered three key points of discussion. Users can navigate
the universe of R packages with (1) capabilities for directly
searching for R packages, (2) guidance for which packages to use,
e.g., from CRAN Task Views and other sources, and (3) access to common
interfaces for alternative approaches to essentially the same
problem.\</p>
</div>
</a>
<a href="articles/RJ-2018-059/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 8, 2018</div>
<div class="dt-authors">
<div class="dt-author">Dr. Joshua Lambert</div>
<div class="dt-author">Dr. Liyu Gong</div>
<div class="dt-author">Corrine F. Elliott, M.S.</div>
<div class="dt-author">Dr. Katherine Thompson</div>
<div class="dt-author">Dr. Arnold Stromberg</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>rFSA: An R Package for Finding Best Subsets and Interactions</h2>
<div class="dt-tags"></div>
<p>Herein we present the R package [*rFSA*](https://CRAN.R-project.org/package=rFSA), which implements an algorithm for improved variable selection. The algorithm searches a data space for models of a user-specified form that are statistically optimal under a measure of model quality. Many iterations afford a set of *feasible solutions* (or candidate models) that the researcher can evaluate for relevance to his or her questions of interest. The algorithm can be used to formulate new or to improve upon existing models in bioinformatics, health care, and myriad other fields in which the volume of available data has outstripped researchers' practical and computational ability to explore larger subsets or higher-order interaction terms. The package accommodates linear and generalized linear models, as well as a variety of criterion functions such as Allen's PRESS and AIC. New modeling strategies and criterion functions can be adapted easily to work with *rFSA*.</p>
</div>
</a>
<a href="articles/RJ-2018-060/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 8, 2018</div>
<div class="dt-authors">
<div class="dt-author">Muhammad Imdad Ullah</div>
<div class="dt-author">Muhammad Aslam</div>
<div class="dt-author">Saima Altaf</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>lmridge: A Comprehensive R Package for Ridge Regression</h2>
<div class="dt-tags"></div>
<p>The ridge regression estimator, one of the commonly used alternatives to the conventional ordinary least squares estimator, avoids the adverse effects in the situations when there exists some considerable degree of multicollinearity among the regressors. There are many software packages available for estimation of ridge regression coefficients. However, most of them display limited methods to estimate the ridge biasing parameters without testing procedures. Our developed package, *lmridge* can be used to estimate ridge coefficients considering a range of different existing biasing parameters, to test these coefficients with more than 25 ridge related statistics, and to present different graphical displays of these statistics.</p>
</div>
</a>
<a href="articles/RJ-2018-061/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 8, 2018</div>
<div class="dt-authors">
<div class="dt-author">Paul F. Evangelista</div>
<div class="dt-author">David Beskow</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Geospatial Point Density</h2>
<div class="dt-tags"></div>
<p>This paper introduces a spatial point density algorithm designed to be explainable, meaningful, and efficient. Originally designed for military applications, this technique applies to any spatial point process where there is a desire to clearly understand the measurement of density and maintain fidelity of the point locations. Typical spatial density plotting algorithms, such as kernel density estimation, implement some type of smoothing function that often results in a density value that is difficult to interpret. The purpose of the visualization method in this paper is to understand spatial point activity density with precision and meaning. The temporal tendency of the point process as an extension of the point density methodology is also discussed and displayed. Applications include visualization and measurement of any type of spatial point process. Visualization techniques integrate *ggmap* with examples from San Diego crime data.</p>
</div>
</a>
<a href="articles/RJ-2018-063/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 8, 2018</div>
<div class="dt-authors">
<div class="dt-author">Adam Rahman</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>sdpt3r: Semidefinite Quadratic Linear Programming in R</h2>
<div class="dt-tags"></div>
<p>We present the package *sdpt3r*, an R implementation of the Matlab
package SDPT3 [@toh1999sdpt3]. The purpose of the software is to solve
semidefinite quadratic linear programming (SQLP) problems, which
encompasses problems such as D-optimal experimental design, the
nearest correlation matrix problem, and distance weighted
discrimination, as well as problems in graph theory such as finding
the maximum cut or Lovasz number of a graph.\
Current optimization packages in R include *Rdsdp*, *Rcsdp*, *scs*,
*cccp*, and *Rmosek*. Of these, *scs* and *Rmosek* solve a similar
suite of problems. In addition to these solvers, the R packages *CXVR*
and *ROI* provide sophisticated modelling interfaces to these solvers.
As a point of difference from the current solvers in R, *sdpt3r*
allows for log-barrier terms in the objective function, which allows
for problems such as the D-optimal design of experiments to be solved
with minimal modifications . The *sdpt3r* package also provides helper 
functions, which formulate the required input for several well-known 
problems, an additional perk not present in the other R packages.</p>
</div>
</a>
<a href="articles/RJ-2018-064/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 8, 2018</div>
<div class="dt-authors">
<div class="dt-author">David Ardia</div>
<div class="dt-author">Kris Boudt</div>
<div class="dt-author">Leopoldo Catania</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Downside Risk Evaluation with the R Package GAS</h2>
<div class="dt-tags"></div>
<p>Financial risk managers routinely use non--linear time series models to predict the downside risk of the capital under management. They also need to evaluate the adequacy of their model using so--called backtesting procedures. The latter involve hypothesis testing and evaluation of loss functions. This paper shows how the R package *GAS* can be used for both the dynamic prediction and the evaluation of downside risk. Emphasis is given to the two key financial downside risk measures: Value-at-Risk (VaR) and Expected Shortfall (ES). High-level functions for: (i) prediction, (ii) backtesting, and (iii) model comparison are discussed, and code examples are provided. An illustration using the series of log--returns of the Dow Jones Industrial Average constituents is reported.</p>
</div>
</a>
<a href="articles/RJ-2018-065/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 8, 2018</div>
<div class="dt-authors">
<div class="dt-author">Alexander Christensen</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>NetworkToolbox: Methods and Measures for Brain, Cognitive, and Psychometric Network Analysis in R</h2>
<div class="dt-tags"></div>
<p>This article introduces the *NetworkToolbox* package for R. Network analysis offers an intuitive perspective on complex phenomena via models depicted by nodes (variables) and edges (correlations). The ability of networks to model complexity has made them the standard approach for modeling the intricate interactions in the brain. Similarly, networks have become an increasingly attractive model for studying the complexity of psychological and psychopathological phenomena. *NetworkToolbox* aims to provide researchers with state-of-the-art methods and measures for estimating and analyzing brain, cognitive, and psychometric networks. In this article, I introduce *NetworkToolbox* and provide a tutorial for applying some the package's functions to personality data.</p>
</div>
</a>
<a href="articles/RJ-2018-066/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 8, 2018</div>
<div class="dt-authors">
<div class="dt-author">Floid R. Gilbert</div>
<div class="dt-author">David B. Dahl</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>jsr223: A Java Platform Integration for R with Programming Languages Groovy, JavaScript, JRuby, Jython, and Kotlin</h2>
<div class="dt-tags"></div>
<p>The R package *jsr223* is a high-level integration for five programming languages in the Java platform: Groovy, JavaScript, JRuby, Jython, and Kotlin. Each of these languages can use Java objects in their own syntax. Hence, *jsr223* is also an integration for R and the Java platform. It enables developers to leverage Java solutions from within R by embedding code snippets or evaluating script files. This approach is generally easier than *rJava*'s low-level approach that employs the Java Native Interface. *jsr223*'s multi-language support is dependent on the Java Scripting API: an implementation of "JSR-223: Scripting for the Java Platform" that defines a framework to embed scripts in Java applications. The *jsr223* package also features extensive data exchange capabilities and a callback interface that allows embedded scripts to access the current R session. In all, *jsr223* makes solutions developed in Java or any of the *jsr223*-supported languages easier to use in R.</p>
</div>
</a>
<a href="articles/RJ-2018-068/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 8, 2018</div>
<div class="dt-authors">
<div class="dt-author">Travers Ching</div>
<div class="dt-author">Dirk Eddelbuettel</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>RcppMsgPack: MessagePack Headers and Interface Functions for R</h2>
<div class="dt-tags"></div>
<p>MessagePack, or *MsgPack* for short, or when referring to the implementation, is an efficient binary serialization format for exchanging data between different programming languages. The *RcppMsgPack* package provides *R* with both the MessagePack *C++* header files, and the ability to access, create and alter MessagePack objects directly from *R*. The main driver functions of the R interface are two functions `msgpack_pack` and `msgpack_unpack`. The function `msgpack_pack` serializes *R* objects to a raw MessagePack message. The function `msgpack_unpack` de-serializes MessagePack messages back into *R* objects. Several helper functions are available to aid in processing and formatting data including `msgpack_simplify`, `msgpack_format` and `msgpack_map`.</p>
</div>
</a>
<a href="articles/RJ-2018-069/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 8, 2018</div>
<div class="dt-authors">
<div class="dt-author">Georgios Papageorgiou</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>BNSP: an R Package for Fitting Bayesian Semiparametric Regression Models and Variable Selection</h2>
<div class="dt-tags"></div>
<p>The R package [*BNSP*](https://CRAN.R-project.org/package=BNSP) provides a unified framework for semiparametric location-scale regression and stochastic search variable selection. The statistical methodology that the package is built upon utilizes basis function expansions to represent semiparametric covariate effects in the mean and variance functions, and spike-slab priors to perform selection and regularization of the estimated effects. In addition to the main function that performs posterior sampling, the package includes functions for assessing convergence of the sampler, summarizing model fits, visualizing covariate effects and obtaining predictions for new responses or their means given feature/covariate vectors.</p>
</div>
</a>
<a href="articles/RJ-2018-079/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 8, 2018</div>
<div class="dt-authors">
<div class="dt-author">Michael Yeomans</div>
<div class="dt-author">Alejandro Kantor</div>
<div class="dt-author">Dustin Tingley</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The politeness Package: Detecting Politeness in Natural Language</h2>
<div class="dt-tags"></div>
<p>This package provides tools to extract politeness markers in English natural language. It also allows researchers to easily visualize and quantify politeness between groups of documents. This package combines and extends prior research on the linguistic markers of politeness [@brown:1987; @danescu:2013; @voigt:2017]. We demonstrate two applications for detecting politeness in natural language during consequential social interactions---distributive negotiations, and speed dating.</p>
</div>
</a>
<a href="articles/RJ-2018-080/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 8, 2018</div>
<div class="dt-authors">
<div class="dt-author">Adrian Dua</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Consistency Cubes: a fast, efficient method for exact Boolean minimization.</h2>
<div class="dt-tags"></div>
<p>A lot of effort has been spent over the past few decades in the QCA
methodology field, to develop efficient Boolean minimization
algorithms to derive an exact, and more importantly complete list of
minimal prime implicants that explain the initial, observed positive
configurations.\
As the complexity grows exponentially with every new condition, the
required computer memory goes past the current computer resources and
the polynomial time required to solve this problem quickly grows
towards infinity.\
This paper introduces a new alternative to the existing non-polynomial
attempts. It completely solves the memory problem, and preliminary
tests show it is exponentially hundreds of time faster than eQMC, the
current "best" algorithm for QCA in [R]{.sans-serif}, and probes into
a territory where it competes and even outperforms engineering
algorithms such as Espresso, for exact minimizations.\
While speed is not much of an issue now (eQMC is fast enough for
simple data), it might prove to be essential when further developing
towards all possible temporal orders, or searching for configurations
in panel data over time, combined with/or automatic detection of
difficult counterfactuals etc.</p>
</div>
</a>
<a href="articles/RJ-2018-044/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 7, 2018</div>
<div class="dt-authors">
<div class="dt-author">Samantha Duchscherer</div>
<div class="dt-author">Robert Stewart</div>
<div class="dt-author">Marie Urban</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>revengc: An R package to Reverse Engineer Summarized Data</h2>
<div class="dt-tags"></div>
<p>Decoupled (e.g.separate averages) and censored (e.g.$&gt;$ 100 species) variables are continually reported by many well-established organizations, such as the World Health Organization (WHO), Centers for Disease Control and Prevention (CDC), and World Bank. The challenge therefore is to infer what the original data could have been given summarized information. We present an R package that reverse engineers censored and/or decoupled data with two main functions. The `cnbinom.pars()` function estimates the average and dispersion parameter of a censored univariate frequency table. The `rec()` function reverse engineers summarized data into an uncensored bivariate table of probabilities.</p>
</div>
</a>
<a href="articles/RJ-2018-045/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 7, 2018</div>
<div class="dt-authors">
<div class="dt-author">Jae Keun Yoo</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Basis-Adaptive Selection Algorithm in dr-package</h2>
<div class="dt-tags"></div>
<p>Sufficient dimension reduction (SDR) turns out to be a useful dimension reduction tool in high-dimensional regression analysis. [@dr] developed the *dr*-package to implement the four most popular SDR methods. However, the package does not provide any clear guidelines as to which method should be used given a data. Since the four methods may provide dramatically different dimension reduction results, the selection in the *dr*-package is problematic for statistical practitioners. In this paper, a basis-adaptive selection algorithm is developed in order to relieve this issue. The basic idea is to select an SDR method that provides the highest correlation between the basis estimates obtained by the four classical SDR methods. A real data example and numerical studies confirm the practical usefulness of the developed algorithm.</p>
</div>
</a>
<a href="articles/RJ-2018-046/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 7, 2018</div>
<div class="dt-authors">
<div class="dt-author">Jari Miettinen</div>
<div class="dt-author">Klaus Nordhausen</div>
<div class="dt-author">Sara Taskinen</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>fICA: FastICA Algorithms and Their Improved Variants</h2>
<div class="dt-tags"></div>
<p>In independent component analysis (ICA) one searches for mutually independent nongaussian latent variables when the components of the multivariate data are assumed to be linear combinations of them. Arguably, the most popular method to perform ICA is FastICA. There are two classical versions, the deflation-based FastICA where the components are found one by one, and the symmetric FastICA where the components are found simultaneously. These methods have been implemented previously in two R packages, *fastICA* and *ica*. We present the R package *fICA* and compare it to the other packages. Additional features in *fICA* include optimization of the extraction order in the deflation-based version, possibility to use any nonlinearity function, and improvement to convergence of the deflation-based algorithm. The usage of the package is demonstrated by applying it to the real ECG data of a pregnant woman.</p>
</div>
</a>
<a href="articles/RJ-2018-047/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 7, 2018</div>
<div class="dt-authors">
<div class="dt-author">Kasia Sawicka</div>
<div class="dt-author">Gerard B.M. Heuvelink</div>
<div class="dt-author">Dennis J.J. Walvoort</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Spatial Uncertainty Propagation Analysis with the spup R Package</h2>
<div class="dt-tags"></div>
<p>Many environmental and geographical models, such as those used in land degradation, agro-ecological and climate studies, make use of spatially distributed inputs that are known imperfectly. The R package *spup* provides functions for examining the uncertainty propagation from input data and model parameters onto model outputs via the environmental model. The functions include uncertainty model specification, stochastic simulation and propagation of uncertainty using Monte Carlo (MC) techniques. Uncertain variables are described by probability distributions. Both numerical and categorical data types are handled. The package also accommodates spatial auto-correlation within a variable and cross-correlation between variables. The MC realizations may be used as input to the environmental models written in or called from R. This article provides theoretical background and three worked examples that guide users through the application of *spup*.</p>
</div>
</a>
<a href="articles/RJ-2018-048/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 7, 2018</div>
<div class="dt-authors">
<div class="dt-author">Gero Szepannek</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>clustMixType: User-Friendly Clustering of Mixed-Type Data in R</h2>
<div class="dt-tags"></div>
<p>Clustering algorithms are designed to identify groups in data where the traditional emphasis has been on numeric data. In consequence, many existing algorithms are devoted to this kind of data even though a combination of numeric and categorical data is more common in most business applications. Recently, new algorithms for clustering mixed-type data have been proposed based on Huang's k-prototypes algorithm. This paper describes the R package *clustMixType* which provides an implementation of k-prototypes in R.</p>
</div>
</a>
<a href="articles/RJ-2018-049/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 7, 2018</div>
<div class="dt-authors">
<div class="dt-author">Roman Olson</div>
<div class="dt-author">Kelsey L. Ruckert</div>
<div class="dt-author">Won Chang</div>
<div class="dt-author">Klaus Keller</div>
<div class="dt-author">Murali Haran</div>
<div class="dt-author">Soon-Il An</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Stilt: Easy Emulation of Time Series AR(1) Computer Model Output in Multidimensional Parameter Space</h2>
<div class="dt-tags"></div>
<p>Statistically approximating or "emulating" time series model output in parameter space is a common problem in climate science and other fields. There are many packages for spatio-temporal modeling. However, they often lack focus on time series, and exhibit statistical complexity. Here, we present the R package *stilt* designed for simplified AR(1) time series Gaussian process emulation, and provide examples relevant to climate modelling. Notably absent is Markov chain Monte Carlo estimation -- a challenging concept to many scientists. We keep the number of user choices to a minimum. Hence, the package can be useful pedagogically, while still applicable to real life emulation problems. We provide functions for emulator cross-validation, empirical coverage, prediction, as well as response surface plotting. While the examples focus on climate model emulation, the emulator is general and can be also used for kriging spatio-temporal data.</p>
</div>
</a>
<a href="articles/RJ-2018-050/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 7, 2018</div>
<div class="dt-authors">
<div class="dt-author">Vlad Stefan Barbu</div>
<div class="dt-author">Caroline Brard</div>
<div class="dt-author">Dominique Cellier</div>
<div class="dt-author">Mathilde Sautreuil</div>
<div class="dt-author">Nicolas Vergne</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SMM: An `R` Package for Estimation and Simulation of Discrete-time semi-Markov Models</h2>
<div class="dt-tags"></div>
<p>Semi-Markov models, independently introduced by @Lev54, @Smi55 and @Tak54, are a generalization of the well-known Markov models. For semi-Markov models, sojourn times can be arbitrarily distributed, while sojourn times of Markov models are constrained to be exponentially distributed (in continuous time) or geometrically distributed (in discrete time). The aim of this paper is to present the R package *SMM*, devoted to the simulation and estimation of discrete-time multi-state semi-Markov and Markov models. For the semi-Markov case we have considered: parametric and non-parametric estimation; with and without censoring at the beginning and/or at the end of sample paths; one or several independent sample paths. Several discrete-time distributions are considered for the parametric estimation of sojourn time distributions of semi-Markov chains: Uniform, Geometric, Poisson, Discrete Weibull and Binomial Negative.</p>
</div>
</a>
<a href="articles/RJ-2018-051/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 7, 2018</div>
<div class="dt-authors">
<div class="dt-author">Alexandre Almeida</div>
<div class="dt-author">Adam Loy</div>
<div class="dt-author">Heike Hofmann</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ggplot2 Compatible Quantile-Quantile Plots in R</h2>
<div class="dt-tags"></div>
<p>Q-Q plots allow us to assess univariate distributional assumptions by comparing a set of quantiles from the empirical and the theoretical distributions in the form of a scatterplot. To aid in the interpretation of Q-Q plots, reference lines and confidence bands are often added. We can also detrend the Q-Q plot so the vertical comparisons of interest come into focus. Various implementations of Q-Q plots exist in R, but none implements all of these features. *qqplotr* extends *ggplot2* to provide a complete implementation of Q-Q plots. This paper introduces the plotting framework provided by *qqplotr* and provides multiple examples of how it can be used.</p>
</div>
</a>
<a href="articles/RJ-2018-052/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 7, 2018</div>
<div class="dt-authors">
<div class="dt-author">Christoph E. Weiss</div>
<div class="dt-author">Eran Raviv</div>
<div class="dt-author">Gernot Roetzer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Forecast Combinations in R using the ForecastComb Package</h2>
<div class="dt-tags"></div>
<p>This paper introduces the R package *ForecastComb*. The aim is to provide researchers and practitioners with a comprehensive implementation of the most common ways in which forecasts can be combined. The package in its current version covers 15 popular estimation methods for creating a combined forecasts -- including simple methods, regression-based methods, and eigenvector-based methods. It also includes useful tools to deal with common challenges of forecast combination (e.g., missing values in component forecasts, or multicollinearity), and to rationalize and visualize the combination results.</p>
</div>
</a>
<a href="articles/RJ-2018-040/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2018</div>
<div class="dt-authors">
<div class="dt-author">Yanming Li</div>
<div class="dt-author">Brenda Gillespie</div>
<div class="dt-author">Kerby Shedden</div>
<div class="dt-author">John Gillespie</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Profile Likelihood Estimation of the Correlation Coefficient in the Presence of Left, Right or Interval Censoring and Missing Data</h2>
<div class="dt-tags"></div>
<p>We discuss implementation of a profile likelihood method for estimating a Pearson correlation coefficient from bivariate data with censoring and/or missing values. The method is implemented in an [R]{.sans-serif} package *clikcorr* which calculates maximum likelihood estimates of the correlation coefficient when the data are modeled with either a Gaussian or a Student $t$-distribution, in the presence of left, right, or interval censored and/or missing data. The [R]{.sans-serif} package includes functions for conducting inference and also provides graphical functions for visualizing the censored data scatter plot and profile log likelihood function. The performance of *clikcorr* in a variety of circumstances is evaluated through extensive simulation studies. We illustrate the package using two dioxin exposure datasets.</p>
</div>
</a>
<a href="articles/RJ-2018-041/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2018</div>
<div class="dt-authors">
<div class="dt-author">Adriano Rivolli</div>
<div class="dt-author">Andre C. P. L. F. de Carvalho</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The utiml Package: Multi-label Classification in R</h2>
<div class="dt-tags"></div>
<p>Learning classification tasks in which each instance is associated with one or more labels are known as multi-label learning. The implementation of multi-label algorithms, performed by different researchers, have several specificities, like input/output format, different internal functions, distinct programming language, to mention just some of them. As a result, current machine learning tools include only a small subset of multi-label decomposition strategies. The *utiml* package is a framework for the application of classification algorithms to multi-label data. Like the well known MULAN used with Weka, it provides a set of multi-label procedures such as sampling methods, transformation strategies, threshold functions, pre-processing techniques and evaluation metrics. The package was designed to allow users to easily perform complete multi-label classification experiments in the R environment. This paper describes the *utiml* API and illustrates its use in different multi-label classification scenarios.</p>
</div>
</a>
<a href="articles/RJ-2018-042/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2018</div>
<div class="dt-authors">
<div class="dt-author">John Mount</div>
<div class="dt-author">Nina Zumel</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Dot-Pipe: an S3 Extensible Pipe for R</h2>
<div class="dt-tags"></div>
<p>Pipe notation is popular with a large league of R users, with *magrittr* being the dominant realization. However, this should not be enough to consider piping in R as a settled topic that is not subject to further discussion, experimentation, or possibility for improvement. To promote innovation opportunities, we describe the *wrapr* R package and "dot-pipe" notation, a well behaved sequencing operator with S3 extensibility. We include a number of examples of using this pipe to interact with and extend other R packages.</p>
</div>
</a>
<a href="articles/RJ-2018-043/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 17, 2018</div>
<div class="dt-authors">
<div class="dt-author">Sonia Prez Fernndez</div>
<div class="dt-author">Pablo Martnez Camblor</div>
<div class="dt-author">Peter Filzmoser</div>
<div class="dt-author">Norberto Corral</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>nsROC: An R package for Non-Standard ROC Curve Analysis</h2>
<div class="dt-tags"></div>
<p>The receiver operating characteristic (ROC) curve is a graphical method which has become standard in the analysis of diagnostic markers, that is, in the study of the classification ability of a numerical variable. Most of the commercial statistical software provide routines for the standard ROC curve analysis. Of course, there are also many R packages dealing with the ROC estimation as well as other related problems. In this work we introduce the *nsROC* package which incorporates some new ROC curve procedures. Particularly: ROC curve comparison based on general distances among functions for both paired and unpaired designs; efficient confidence bands construction; a generalization of the curve considering different classification subsets than the one involved in the classical definition of the ROC curve; a procedure to deal with censored data in cumulative-dynamic ROC curve estimation for time-to-event outcomes; and a non-parametric ROC curve method for meta-analysis. This is the only R package which implements these particular procedures.</p>
</div>
</a>
<a href="articles/RJ-2018-038/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 29, 2018</div>
<div class="dt-authors">
<div class="dt-author">Zachary M. Jones</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>mmpf: Monte-Carlo Methods for Prediction Functions</h2>
<div class="dt-tags"></div>
<p>Machine learning methods can often learn high-dimensional functions which generalize well but are not human interpretable. The ***mmpf*** package marginalizes prediction functions using Monte-Carlo methods, allowing users to investigate the behavior of these learned functions, as on a lower dimensional subset of input features: partial dependence and variations thereof. This makes machine learning methods more useful in situations where accurate prediction is not the only goal, such as in the social sciences where linear models are commonly used because of their interpretability.</p>
</div>
</a>
<a href="articles/RJ-2018-039/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 29, 2018</div>
<div class="dt-authors">
<div class="dt-author">Guido Kraemer</div>
<div class="dt-author">Markus Reichstein</div>
<div class="dt-author">Miguel D.Mahecha</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>dimRed and coRanking---Unifying Dimensionality Reduction in R</h2>
<div class="dt-tags"></div>
<p>"Dimensionality reduction" (DR) is a widely used approach to find low dimensional and interpretable representations of data that are natively embedded in high-dimensional spaces. DR can be realized by a plethora of methods with different properties, objectives, and, hence, (dis)advantages. The resulting low-dimensional data embeddings are often difficult to compare with objective criteria. Here, we introduce the [***dimRed***](https://CRAN.R-project.org/package=dimRed) and [***coRanking***](https://CRAN.R-project.org/package=coRanking) packages for the R language. These open source software packages enable users to easily access multiple classical and advanced DR methods using a common interface. The packages also provide quality indicators for the embeddings and easy visualization of high dimensional data. The ***coRanking*** package provides the functionality for assessing DR methods in the co-ranking matrix framework. In tandem, these packages allow for uncovering complex structures high dimensional data. Currently 15 DR methods are available in the package, some of which were not previously available to R users. Here, we outline the ***dimRed*** and ***coRanking*** packages and make the implemented methods understandable to the interested reader.</p>
</div>
</a>
<a href="articles/RJ-2018-037/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 13, 2018</div>
<div class="dt-authors">
<div class="dt-author">Timothy Barry</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Collections in R: Review and Proposal</h2>
<div class="dt-tags"></div>
<p>R is a powerful tool for data processing, visualization, and modeling. However, R is slower than other languages used for similar purposes, such as Python. One reason for this is that R lacks base support for collections, abstract data types that store, manipulate, and return data (e.g., sets, maps, stacks). An exciting recent trend in the R extension ecosystem is the development of collection packages, packages that provide classes that implement common collections. At least 12 collection packages are available across the two major R extension repositories, the Comprehensive R Archive Network (CRAN) and Bioconductor. In this article, we compare collection packages in terms of their features, design philosophy, ease of use, and performance on benchmark tests. We demonstrate that, when used well, the data structures provided by collection packages are in many cases significantly faster than the data structures provided by base R. We also highlight current deficiencies among R collection packages and propose avenues of possible improvement. This article provides useful recommendations to R programmers seeking to speed up their programs and aims to inform the development of future collection-oriented software for R.</p>
</div>
</a>
<a href="articles/RJ-2018-036/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 7, 2018</div>
<div class="dt-authors">
<div class="dt-author">Paula Moraga</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Small Area Disease Risk Estimation and Visualization Using R</h2>
<div class="dt-tags"></div>
<p>Small area disease risk estimation is essential for disease prevention and control. In this paper, we demonstrate how R can be used to obtain disease risk estimates and quantify risk factors using areal data. We explain how to define disease risk models and how to perform Bayesian inference using the ***INLA*** package. We also show how to make interactive maps of estimates using the ***leaflet*** package to better understand the disease spatial patterns and communicate the results. We show an example of lung cancer risk in Pennsylvania, United States, in year 2002, and demonstrate that R represents an excellent tool for disease surveillance by enabling reproducible health data analysis.</p>
</div>
</a>
<a href="articles/RJ-2018-035/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2018</div>
<div class="dt-authors">
<div class="dt-author">Waldemar W. Koczkodaj</div>
<div class="dt-author">Feng Li</div>
<div class="dt-author">Alicja Wolny--Dominiak</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>RatingScaleReduction package: stepwise rating scale item reduction without predictability loss</h2>
<div class="dt-tags"></div>
<p>This study presents an innovative method for reducing the number of
rating scale items without predictability loss. The "area under the
receiver operator curve" method (AUC ROC) is used for the stepwise
method of reducing items of a rating scale. ***RatingScaleReduction***
R package contains the presented implementation. Differential
evolution (a metaheuristic for optimization) was applied to one of the
analyzed datasets to illustrate that the presented stepwise method can
be used with other classifiers to reduce the number of rating scale
items (variables). The targeted areas of application are decision
making, data mining, machine learning, and psychometrics.\
**Keywords:** rating scale, receiver operator characteristic, ROC,
AUC, scale reduction.</p>
</div>
</a>
<a href="articles/RJ-2018-034/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 30, 2018</div>
<div class="dt-authors">
<div class="dt-author">Aurore Archimbaud</div>
<div class="dt-author">Klaus Nordhausen</div>
<div class="dt-author">Anne Ruiz-Gazen</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ICSOutlier: Unsupervised Outlier Detection for Low-Dimensional Contamination Structure</h2>
<div class="dt-tags"></div>
<p>Detecting outliers in a multivariate and unsupervised context is an important and ongoing problem notably for quality control. Many statistical methods are already implemented in R and are briefly surveyed in the present paper. But only a few lead to the accurate identification of potential outliers in the case of a small level of contamination. In this particular context, the Invariant Coordinate Selection (ICS) method shows remarkable properties for identifying outliers that lie on a low-dimensional subspace in its first invariant components. It is implemented in the ***ICSOutlier*** package. The main function of the package, `ics.outlier`, offers the possibility of labelling potential outliers in a completely automated way. Four examples, including two real examples in quality control, illustrate the use of the function. Comparing with several other approaches, it appears that ICS is generally as efficient as its competitors and shows an advantage in the context of a small proportion of outliers lying in a low-dimensional subspace. In quality control, the method may help in properly identifying some defective products while not detecting too many false positives.</p>
</div>
</a>
<a href="articles/RJ-2018-033/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 22, 2018</div>
<div class="dt-authors">
<div class="dt-author">Jennifer Broatch</div>
<div class="dt-author">Jennifer Green</div>
<div class="dt-author">Andrew Karl</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>RealVAMS: An R Package for Fitting a Multivariate Value-added Model (VAM)</h2>
<div class="dt-tags"></div>
<p>We present [***RealVAMS***](https://CRAN.R-project.org/package=RealVAMS), an R package for fitting a generalized linear mixed model to multimembership data with partially crossed and partially nested random effects. ***RealVAMS*** utilizes a multivariate generalized linear mixed model with pseudo-likelihood approximation for fitting normally distributed continuous response(s) jointly with a binary outcome. In an educational context, the model is referred to as a multidimensional value-added model, which extends previous theory to estimate the relationships between potential teacher contributions toward different student outcomes and to allow the consideration of a binary, real-world outcome such as graduation. The simultaneous joint modeling of continuous and binary outcomes was not available prior to ***RealVAMS*** due to computational difficulties. In this paper, we discuss the multidimensional model, describe ***RealVAMS***, and demonstrate the use of this package and its modeling options with an educational data set.</p>
</div>
</a>
<a href="articles/RJ-2018-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 21, 2018</div>
<div class="dt-authors">
<div class="dt-author">Cathrine Ulla Jensen</div>
<div class="dt-author">Toke Emil Panduro</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>PanJen: An R package for Ranking Transformations in a Linear Regression</h2>
<div class="dt-tags"></div>
<p>***PanJen*** is an R-package for ranking transformations in linear regressions. It provides users with the ability to explore the relationship between a dependent variable and its independent variables. The package offers an easy and data-driven way to choose a functional form in multiple linear regression models by comparing a range of parametric transformations. The parametric functional forms are benchmarked against each other and a non-parametric transformation. The package allows users to generate plots that show the relation between a covariate and the dependent variable. Furthermore, ***PanJen*** will enable users to specify specific functional transformations, driven by a priori and theory-based hypotheses. The package supplies both model fits and plots that allow users to make informed choices on the functional forms in their regression. We show that the ranking in PanJen outperforms the Box-Tidwell transformation, especially in the presence of inefficiency, heteroscedasticity or endogeneity.</p>
</div>
</a>
<a href="articles/RJ-2018-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 21, 2018</div>
<div class="dt-authors">
<div class="dt-author">M. Iturbide</div>
<div class="dt-author">J.M. Gutirrez</div>
<div class="dt-author">J. Bedia</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Tackling Uncertainties of Species Distribution Model Projections with Package mopa</h2>
<div class="dt-tags"></div>
<p>Species Distribution Models (SDMs) constitute an important tool to assist decision-making in environmental conservation and planning in the context of climate change. Nevertheless, SDM projections are affected by a wide range of uncertainty factors (related to training data, climate projections and SDM techniques), which limit their potential value and credibility. The new package ***mopa*** provides tools for designing comprehensive multi-factor SDM ensemble experiments, combining multiple sources of uncertainty (e.g.baseline climate, pseudo-absence realizations, SDM techniques, future projections) and allowing to assess their contribution to the overall spread of the ensemble projection. In addition, ***mopa*** is seamlessly integrated with the [climate4R](http://www.meteo.unican.es/climate4R) bundle and allows straightforward retrieval and post-processing of state-of-the-art climate datasets (including observations and climate change projections), thus facilitating the proper analysis of key uncertainty factors related to climate data.</p>
</div>
</a>
<a href="articles/RJ-2018-020/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 21, 2018</div>
<div class="dt-authors">
<div class="dt-author">Jongho Im</div>
<div class="dt-author">In Ho Cho</div>
<div class="dt-author">Jae Kwang Kim</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>FHDI: An R Package for Fractional Hot Deck Imputation</h2>
<div class="dt-tags"></div>
<p>Fractional hot deck imputation (FHDI), proposed by [@kalton84] and investigated by [@kim04], is a tool for handling item nonresponse in survey sampling. In FHDI, each missing item is filled with multiple observed values yielding a single completed data set for subsequent analyses. An R package ***FHDI*** is developed to perform FHDI and also the fully efficient fractional imputation (FEFI) method of [@fuller05] to impute multivariate missing data with arbitrary missing patterns. FHDI substitutes missing items with a few observed values jointly obtained from a set of donors whereas the FEFI uses all the possible donors. This paper introduces ***FHDI*** as a tool for implementing the multivariate version of fractional hot deck imputation discussed in [@im15] as well as FEFI. For variance estimation of FHDI and FEFI, the Jackknife method is implemented, and replicated weights are provided as a part of the output.</p>
</div>
</a>
<a href="articles/RJ-2018-021/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 21, 2018</div>
<div class="dt-authors">
<div class="dt-author">Gonzalo Garcia-Donato</div>
<div class="dt-author">Anabel Forte</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Bayesian Testing, Variable Selection and Model Averaging in Linear Models using R with BayesVarSel</h2>
<div class="dt-tags"></div>
<p>In this paper, objective Bayesian methods for hypothesis testing and variable selection in linear models are considered. The focus is on ***BayesVarSel***, an R package that computes posterior probabilities of hypotheses/models and provides a suite of tools to properly summarize the results. We introduce the usage of specific functions to compute several types of model averaging estimations and predictions weighted by posterior probabilities. ***BayesVarSel*** contains exact algorithms to perform fast computations in problems of small to moderate size and heuristic sampling methods to solve large problems. We illustrate the functionalities of the package with several data examples.</p>
</div>
</a>
<a href="articles/RJ-2018-022/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 21, 2018</div>
<div class="dt-authors">
<div class="dt-author">Osman Dag</div>
<div class="dt-author">Anil Dolgun</div>
<div class="dt-author">Naime Meric Konar</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>onewaytests: An R Package for One-Way Tests in Independent Groups Designs</h2>
<div class="dt-tags"></div>
<p>One-way tests in independent groups designs are the most commonly utilized statistical methods with applications on the experiments in medical sciences, pharmaceutical research, agriculture, biology, engineering, social sciences and so on. In this paper, we present the [***onewaytests***](https://CRAN.R-project.org/package=onewaytests) package to investigate treatment effects on the dependent variable. The package offers the one-way tests in independent groups designs, which include ANOVA, Welch's heteroscedastic *F* test, Welch's heteroscedastic *F* test with trimmed means and Winsorized variances, Brown-Forsythe test, Alexander-Govern test, James second order test and Kruskal-Wallis test. The package also provides pairwise comparisons, graphical approaches, and assesses variance homogeneity and normality of data in each group via tests and plots. A simulation study is also conducted to give recommendations for applied researchers on the selection of appropriate one-way tests under assumption violations. Furthermore, especially for non-R users, a user-friendly web application of the package is provided. This application is available at &lt;http://www.softmed.hacettepe.edu.tr/onewaytests&gt;.</p>
</div>
</a>
<a href="articles/RJ-2018-023/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 21, 2018</div>
<div class="dt-authors">
<div class="dt-author">Alejandro Saavedra-Nieves</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Inventorymodel: an R Package for Centralized Inventory Problems</h2>
<div class="dt-tags"></div>
<p>Inventory management of goods is an integral part of logistics systems; common to various economic sectors such as industry, agriculture and trade; and independent of production volume. In general, as companies seek to minimize economic losses, studies on problems of multi-agent inventory have increased in recent years. A multi-agent inventory problem is a situation in which several agents face individual inventory problems and agree to coordinate their orders with the objective of reducing their costs. The R package ***Inventorymodel*** allows the determination of both the optimal policy for some inventory situations with deterministic demands and the allocation of costs from a game-theoretic perspective. The required calculations may be computed for any number of agents although the computational complexity of this class of problems when the involved agents enlarge is not reduced. In this work, the different possibilities that the package offers are described and some examples of usage are also demonstrated.</p>
</div>
</a>
<a href="articles/RJ-2018-024/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 21, 2018</div>
<div class="dt-authors">
<div class="dt-author">Marcus W Beck</div>
<div class="dt-author">Neeraj Bokde</div>
<div class="dt-author">Gualberto Asencio-Corts</div>
<div class="dt-author">Kishore Kulat</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>R Package imputeTestbench to Compare Imputation Methods for Univariate Time Series</h2>
<div class="dt-tags"></div>
<p>Missing observations are common in time series data and several methods are available to impute these values prior to analysis. Variation in statistical characteristics of univariate time series can have a profound effect on characteristics of missing observations and, therefore, the accuracy of different imputation methods. The ***imputeTestbench*** package can be used to compare the prediction accuracy of different methods as related to the amount and type of missing data for a user-supplied dataset. Missing data are simulated by removing observations completely at random or in blocks of different sizes depending on characteristics of the data. Several imputation algorithms are included with the package that vary from simple replacement with means to more complex interpolation methods. The testbench is not limited to the default functions and users can add or remove methods as needed. Plotting functions also allow comparative visualization of the behavior and effectiveness of different algorithms. We present example applications that demonstrate how the package can be used to understand differences in prediction accuracy between methods as affected by characteristics of a dataset and the nature of missing data.</p>
</div>
</a>
<a href="articles/RJ-2018-025/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 21, 2018</div>
<div class="dt-authors">
<div class="dt-author">David Bucklin</div>
<div class="dt-author">Mathieu Basille</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>rpostgis: Linking R with a PostGIS Spatial Database</h2>
<div class="dt-tags"></div>
<p>With the proliferation of sensors and the ease of data collection from online sources, large datasets have become the norm in many scientific disciplines, and efficient data storage, management, and retrival is imperative for large research projects. Relational databases provide a solution, but in order to be useful, must be able to be linked to analysis and visualization tools, such as R. Here, we present a package intended to facilitate integration of R with the open-source database software PostgreSQL, with a focus on its spatial extension, PostGIS. The package ***rpostgis*** (version 1.4.1) provides methods for spatial data handling (vector and raster) between PostGIS-enabled databases and R, methods for R `"data.frame"`s storage in PostgreSQL, and a set of convenient wrappers for common database procedures. We thus expect ***rpostgis*** to be useful for both (1) existing users of spatial data in R and/or PostGIS, and (2) R users who have yet to adopt relational databases for their projects.</p>
</div>
</a>
<a href="articles/RJ-2018-026/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 21, 2018</div>
<div class="dt-authors">
<div class="dt-author">Enio Jelihovschi</div>
<div class="dt-author">Ivan Bezerra Allaman</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>lba: An R Package for Latent Budget Analysis</h2>
<div class="dt-tags"></div>
<p>The latent budget model is a mixture model for compositional data sets in which the entries, a contingency table, may be either realizations from a product multinomial distribution or distribution free. Based on this model, the latent budget analysis considers the interactions of two variables; the explanatory (row) and the response (column) variables. The package ***lba*** uses expectation-maximization and active constraints method (ACM) to carry out, respectively, the maximum likelihood and the least squares estimation of the model parameters. It contains three main functions, `lba` which performs the analysis, `goodnessfit` for model selection and goodness of fit and the plotting functions `plotcorr` and `plotlba` used as a help in the interpretation of the results.</p>
</div>
</a>
<a href="articles/RJ-2018-027/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 21, 2018</div>
<div class="dt-authors">
<div class="dt-author">Michael J.Wurm</div>
<div class="dt-author">Paul J.Rathouz</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Semiparametric Generalized Linear Models with the gldrm Package</h2>
<div class="dt-tags"></div>
<p>This paper introduces a new algorithm to estimate and perform inferences on a recently proposed and developed semiparametric generalized linear model (glm). Rather than selecting a particular parametric exponential family model, such as the Poisson distribution, this semiparametric glm assumes that the response is drawn from the more general exponential tilt family. The regression coefficients and unspecified reference distribution are estimated by maximizing a semiparametric likelihood. The new algorithm incorporates several computational stability and efficiency improvements over the algorithm originally proposed. In particular, the new algorithm performs well for either small or large support for the nonparametric response distribution. The algorithm is implemented in a new R package called *gldrm*.</p>
</div>
</a>
<a href="articles/RJ-2018-028/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 21, 2018</div>
<div class="dt-authors">
<div class="dt-author">Andrzej Palczewski</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>LP Algorithms for Portfolio Optimization: The PortfolioOptim Package</h2>
<div class="dt-tags"></div>
<p>The paper describes two algorithms for financial portfolio optimization with the following risk measures: CVaR, MAD, LSAD and dispersion CVaR. These algorithms can be applied to discrete distributions of asset returns since then the optimization problems can be reduced to linear programs. The first algorithm solves a simple recourse problem as described by Haneveld using Benders decomposition method. The second algorithm finds an optimal portfolio with the smallest distance to a given benchmark portfolio and is an adaptation of the least norm solution (called also normal solution) of linear programs due to Zhao and Li. The algorithms are implemented in R in the package ***PortfolioOptim***.</p>
</div>
</a>
<a href="articles/RJ-2018-029/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 21, 2018</div>
<div class="dt-authors">
<div class="dt-author">Angel Berihuete</div>
<div class="dt-author">Carmen Dolores Ramos</div>
<div class="dt-author">Miguel Angel Sordo</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Welfare, Inequality and Poverty Analysis with rtip: An Approach Based on Stochastic Dominance</h2>
<div class="dt-tags"></div>
<p>Disparities in economic welfare, inequality and poverty across and within countries are of great interest to sociologists, economists, researchers, social organizations and political scientists. Information about these topics is commonly based on surveys. We present a package called ***rtip*** that implements techniques based on stochastic dominance to make unambiguous comparisons, in terms of welfare, poverty and inequality, among income distributions. Besides providing point estimates and confidence intervals for the most commonly used indicators of these characteristics, the package ***rtip*** estimates the usual Lorenz curve, the generalized Lorenz curve, the TIP (Three I's of Poverty) curve and allows to test statistically whether one curve is dominated by another.</p>
</div>
</a>
<a href="articles/RJ-2018-031/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 21, 2018</div>
<div class="dt-authors">
<div class="dt-author">Ioana-Elena Oana</div>
<div class="dt-author">Carsten Q. Schneider</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SetMethods: an Add-on R Package for Advanced QCA</h2>
<div class="dt-tags"></div>
<p>This article presents the functionalities of the R package ***SetMethods***, aimed at performing advanced set-theoretic analyses. This includes functions for performing set-theoretic multi-method research, set-theoretic theory evaluation, Enhanced Standard Analysis, diagnosing the impact of temporal, spatial, or substantive clusterings of the data on the results obtained via Qualitative Comparative Analysis (QCA), indirect calibration, and visualising QCA results via XY plots or radar charts. Each functionality is presented in turn, the conceptual idea and the logic behind the procedure being first summarized, and afterwards illustrated with data from [@SchneiderM2010].</p>
</div>
</a>
<a href="articles/RJ-2018-032/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 21, 2018</div>
<div class="dt-authors">
<div class="dt-author">Martin Happ</div>
<div class="dt-author">Solomon W. Harrar</div>
<div class="dt-author">Arnce C. Bathke</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>HRM: An R Package for Analysing High-dimensional Multi-factor Repeated Measures</h2>
<div class="dt-tags"></div>
<p>High-dimensional longitudinal data pose a serious challenge for statistical inference as many test statistics cannot be computed for high-dimensional data, or they do not maintain the nominal type-I error rate, or have very low power. Therefore, it is necessary to derive new inference methods capable of dealing with high dimensionality, and to make them available to statistics practitioners. One such method is implemented in the package ***HRM*** described in this article. This new method uses a similar approach as the Welch-Satterthwaite $t$-test approximation and works very well for high-dimensional data as long as the data distribution is not too skewed or heavy-tailed. The package also provides a GUI to offer an easy way to apply the methods.</p>
</div>
</a>
<a href="articles/RJ-2018-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 18, 2018</div>
<div class="dt-authors">
<div class="dt-author">Paul-Christian Brkner</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Advanced Bayesian Multilevel Modeling with the R Package brms</h2>
<div class="dt-tags"></div>
<p>The ***brms*** package allows R users to easily specify a wide range of Bayesian single-level and multilevel models which are fit with the probabilistic programming language Stan behind the scenes. Several response distributions are supported, of which all parameters (e.g., location, scale, and shape) can be predicted. Non-linear relationships may be specified using non-linear predictor terms or semi-parametric approaches such as splines or Gaussian processes. Multivariate models can be fit as well. To make all of these modeling options possible in a multilevel framework, ***brms*** provides an intuitive and powerful formula syntax, which extends the well known formula syntax of ***lme4***. The purpose of the present paper is to introduce this syntax in detail and to demonstrate its usefulness with four examples, each showing relevant aspects of the syntax.</p>
</div>
</a>
<a href="articles/RJ-2018-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 16, 2018</div>
<div class="dt-authors">
<div class="dt-author">Csaire J. K. Fouodo</div>
<div class="dt-author">Inke R. Knig</div>
<div class="dt-author">Claus Weihs</div>
<div class="dt-author">Andreas Ziegler</div>
<div class="dt-author">Marvin N. Wright</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Support Vector Machines for Survival Analysis with R</h2>
<div class="dt-tags"></div>
<p>This article introduces the R package [***survivalsvm***](https://CRAN.R-project.org/package=survivalsvm), implementing support vector machines for survival analysis. Three approaches are available in the package: The regression approach takes censoring into account when formulating the inequality constraints of the support vector problem. In the ranking approach, the inequality constraints set the objective to maximize the concordance index for comparable pairs of observations. The hybrid approach combines the regression and ranking constraints in a single model. We describe survival support vector machines and their implementation, provide examples and compare the prediction performance with the Cox proportional hazards model, random survival forests and gradient boosting using several real datasets. On these datasets, survival support vector machines perform on par with the reference methods.</p>
</div>
</a>
<a href="articles/RJ-2018-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 16, 2018</div>
<div class="dt-authors">
<div class="dt-author">Barak Brill</div>
<div class="dt-author">Yair Heller</div>
<div class="dt-author">Ruth Heller</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Nonparametric Independence Tests and $k$-sample Tests for Large Sample Sizes Using Package HHG</h2>
<div class="dt-tags"></div>
<p>Nonparametric tests of independence and $k$-sample tests are ubiquitous in modern applications, but they are typically computationally expensive. We present a family of nonparametric tests that are computationally efficient and powerful for detecting any type of dependence between a pair of univariate random variables. The computational complexity of the suggested tests is sub-quadratic in sample size, allowing calculation of test statistics for millions of observations. We survey both algorithms and the ***HHG*** package in which they are implemented, with usage examples showing the implementation of the proposed tests for both the independence case and the $k$-sample problem. The tests are compared to existing nonparametric tests via several simulation studies comparing both runtime and power. Special focus is given to the design of data structures used in implementation of the tests. These data structures can be useful for developers of nonparametric distribution-free tests.</p>
</div>
</a>
<a href="articles/RJ-2018-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 16, 2018</div>
<div class="dt-authors">
<div class="dt-author">Edzer Pebesma</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Simple Features for R: Standardized Support for Spatial Vector Data</h2>
<div class="dt-tags"></div>
<p>Simple features are a standardized way of encoding spatial vector data (points, lines, polygons) in computers. The ***sf*** package implements simple features in R, and has roughly the same capacity for spatial vector data as packages ***sp***, ***rgeos***, and ***rgdal***. We describe the need for this package, its place in the R package ecosystem, and its potential to connect R to other computer systems. We illustrate this with examples of its use.</p>
</div>
</a>
<a href="articles/RJ-2018-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 16, 2018</div>
<div class="dt-authors">
<div class="dt-author">Stphane Blondeau Da Silva</div>
<div class="dt-author">Anne Da Silva</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Pstat: An R Package to Assess Population Differentiation in Phenotypic Traits</h2>
<div class="dt-tags"></div>
<p>The package [***Pstat***](https://CRAN.R-project.org/package=Pstat) calculates $P_{ST}$ values to assess differentiation among populations from a set of quantitative traits and provides bootstrapped distributions and confidence intervals for $P_{ST}$. Variations of $P_{ST}$ as a function of the parameter $c/h^2$ are studied as well. The package implements different transformations of the measured phenotypic traits to eliminate variation resulting from allometric growth, including calculation of residuals from linear regression, Reist standardization, and the Aitchison transformation.</p>
</div>
</a>
<a href="articles/RJ-2018-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 16, 2018</div>
<div class="dt-authors">
<div class="dt-author">Boxiang Liu</div>
<div class="dt-author">Thomas Quertermous</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Approximating the Sum of Independent Non-Identical Binomial Random Variables</h2>
<div class="dt-tags"></div>
<p>The distribution of the sum of independent non-identical binomial random variables is frequently encountered in areas such as genomics, healthcare, and operations research. Analytical solutions for the density and distribution are usually cumbersome to find and difficult to compute. Several methods have been developed to approximate the distribution, among which is the saddlepoint approximation. However, implementation of the saddlepoint approximation is non-trivial. In this paper, we implement the saddlepoint approximation in the ***sinib*** package and provide two examples to illustrate its usage. One example uses simulated data while the other uses real-world healthcare data. The ***sinib*** package addresses the gap between the theory and the implementation of approximating the sum of independent non-identical binomials.</p>
</div>
</a>
<a href="articles/RJ-2018-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 16, 2018</div>
<div class="dt-authors">
<div class="dt-author">Edmund Jones</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>cchs: An R Package for Stratified Case-Cohort Studies</h2>
<div class="dt-tags"></div>
<p>The [*cchs*](https://CRAN.R-project.org/package=cchs) package contains a function, also called `cchs`, for analyzing data from a stratified case-cohort study, as used in epidemiology. For data from this type of study, `cchs` calculates Estimator III of @borgan2000, which is a score-unbiased estimator for the regression coefficients in the Cox proportional hazards model. From the user's point of view, the function is similar to `coxph` (in the [*survival*](https://CRAN.R-project.org/package=survival) package) and other widely used model-fitting functions. Convenient software has not previously been available for Estimator III since it is complicated to calculate. SAS and S-Plus code-fragments for the calculation have been published, but `cchs` is easier to use and more efficient in terms of time and memory, and can cope with much larger datasets. It also avoids several minor approximations and simplifications.</p>
</div>
</a>
<a href="articles/RJ-2018-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 16, 2018</div>
<div class="dt-authors">
<div class="dt-author">Duygu elik</div>
<div class="dt-author">Murat Tini</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>InfoTrad: An R package for estimating the probability of informed trading</h2>
<div class="dt-tags"></div>
<p>The purpose of this paper is to introduce the R package ***InfoTrad*** for estimating the probability of informed trading (PIN) initially proposed by @1996Easleyetal. PIN is a popular information asymmetry measure that proxies the proportion of informed traders in the market. This study provides a short survey on alternative estimation techniques for the PIN. There are many problems documented in the existing literature in estimating PIN. ***InfoTrad*** package aims to address two problems. First, the sequential trading structure proposed by @1996Easleyetal and later extended by @2002Easleyetal is prone to sample selection bias for stocks with large trading volumes, due to floating point exception. This problem is solved by different factorizations provided by @2010Easleyetal (EHO factorization) and @2011LinandKe (LK factorization). Second, the estimates are prone to bias due to boundary solutions. A grid-search algorithm (YZ algorithm) is proposed by @2012YanandZhang to overcome the bias introduced due to boundary estimates. In recent years, clustering algorithms have become popular due to their flexibility in quickly handling large data sets. @2015Ganetal propose an algorithm (GAN algorithm) to estimate PIN using hierarchical agglomerative clustering which is later extended by @2016ErsanandAlici (EA algorithm). The package ***InfoTrad*** offers LK and EHO factorizations given an input matrix and initial parameter vector. In addition, these factorizations can be used to estimate PIN through YZ algorithm, GAN algorithm and EA algorithm.</p>
</div>
</a>
<a href="articles/RJ-2018-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 16, 2018</div>
<div class="dt-authors">
<div class="dt-author">Daniel Salfran</div>
<div class="dt-author">Martin Spiess</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Generalized Additive Model Multiple Imputation by Chained Equations With Package ImputeRobust</h2>
<div class="dt-tags"></div>
<p>Data analysis, common to all empirical sciences, often requires complete data sets. Unfortunately, real world data collection will usually result in data values not being observed. We present a package for robust multiple imputation (the ***ImputeRobust*** package) that allows the use of generalized additive models for location, scale, and shape in the context of chained equations. The paper describes the basics of the imputation technique which builds on a semi-parametric regression model (GAMLSS) and the algorithms and functions provided with the corresponding package. Furthermore, some illustrative examples are provided.</p>
</div>
</a>
<a href="articles/RJ-2018-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 16, 2018</div>
<div class="dt-authors">
<div class="dt-author">Juhyun Kim</div>
<div class="dt-author">Yiwen Zhang</div>
<div class="dt-author">Joshua Day</div>
<div class="dt-author">Hua Zhou</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>MGLM: An R Package for Multivariate Categorical Data Analysis</h2>
<div class="dt-tags"></div>
<p>Data with multiple responses is ubiquitous in modern applications. However, few tools are available for regression analysis of multivariate counts. The most popular multinomial-logit model has a very restrictive mean-variance structure, limiting its applicability to many data sets. This article introduces an R package ***MGLM***, short for multivariate response generalized linear models, that expands the current tools for regression analysis of polytomous data. Distribution fitting, random number generation, regression, and sparse regression are treated in a unifying framework. The algorithm, usage, and implementation details are discussed.</p>
</div>
</a>
<a href="articles/RJ-2018-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 16, 2018</div>
<div class="dt-authors">
<div class="dt-author">Yuri R. Fonseca</div>
<div class="dt-author">Ricardo P. Masini</div>
<div class="dt-author">Marcelo C. Medeiros</div>
<div class="dt-author">Gabriel F. R. Vasconcelos</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ArCo: An R package to Estimate Artificial Counterfactuals</h2>
<div class="dt-tags"></div>
<p>In this paper we introduce the ***ArCo*** package for R which consists of a set of functions to implement the the Artificial Counterfactual (ArCo) methodology to estimate causal effects of an intervention (treatment) on aggregated data and when a control group is not necessarily available. The ArCo method is a two-step procedure, where in the first stage a counterfactual is estimated from a large panel of time series from a pool of untreated peers. In the second-stage, the average treatment effect over the post-intervention sample is computed. Standard inferential procedures are available. The package is illustrated with both simulated and real datasets.</p>
</div>
</a>
<a href="articles/RJ-2018-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 15, 2018</div>
<div class="dt-authors">
<div class="dt-author">Jonathan Gelfond</div>
<div class="dt-author">Martin Goros</div>
<div class="dt-author">Brian Hernandez</div>
<div class="dt-author">Alex Bokov</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>A System for an Accountable Data Analysis Process in R</h2>
<div class="dt-tags"></div>
<p>Efficiently producing transparent analyses may be difficult for beginners or tedious for the experienced. This implies a need for computing systems and environments that can efficiently satisfy reproducibility and accountability standards. To this end, we have developed a system, R package, and R Shiny application called *adapr* (Accountable Data Analysis Process in R) that is built on the principle of accountable units. An accountable unit is a data file (statistic, table or graphic) that can be associated with a provenance, meaning how it was created, when it was created and who created it, and this is similar to the 'verifiable computational results' (VCR) concept proposed by Gavish and Donoho. Both accountable units and VCRs are version controlled, sharable, and can be incorporated into a collaborative project. However, accountable units use file hashes and do not involve watermarking or public repositories like VCRs. Reproducing collaborative work may be highly complex, requiring repeating computations on multiple systems from multiple authors; however, determining the provenance of each unit is simpler, requiring only a search using file hashes and version control systems.</p>
</div>
</a>
<a href="articles/RJ-2018-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 15, 2018</div>
<div class="dt-authors">
<div class="dt-author">Hui Tang</div>
<div class="dt-author">Elizabeth L. Day</div>
<div class="dt-author">Molly B. Atkinson</div>
<div class="dt-author">Norbert J. Pienta</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>GrpString: An R Package for Analysis of Groups of Strings</h2>
<div class="dt-tags"></div>
<p>The R package ***GrpString*** was developed as a comprehensive toolkit for quantitatively analyzing and comparing groups of strings. It offers functions for researchers and data analysts to prepare strings from event sequences, extract common patterns from strings, and compare patterns between string vectors. The package also finds transition matrices and complexity of strings, determines clusters in a string vector, and examines the statistical difference between two groups of strings.</p>
</div>
</a>
<a href="articles/RJ-2018-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 15, 2018</div>
<div class="dt-authors">
<div class="dt-author">Bilge Baer</div>
<div class="dt-author">Nalan Cinemre</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Epistemic Game Theory: Putting Algorithms to Work</h2>
<div class="dt-tags"></div>
<p>The aim of this study is to construct an epistemic model in which each rational choice under common belief in rationality is supplemented by a type which expresses such a belief. In practice, the finding of type depends on manual solution approach with some mathematical operations in scope of the theory. This approach becomes less convenient with the growth of the size of the game. To solve this difficulty, a linear programming model is constructed for two-player, static and non-cooperative games to find the type that is supporting that player's rational choice is optimal under common belief in rationality and maximizing the utility of the game. Since the optimal choice would only be made from rational choices, it is first necessary to eliminate all strictly dominated choices. In real life, the games are usually large sized. Therefore, the elimination process should be performed in a computer environment. Since software related to game theory was mostly prepared with a result-oriented approach for some types of games, it was necessary to develop software to execute the iterated elimination method. With this regard, a program has been developed that determines the choices that are strictly dominated by pure and randomized choices in two-player games. Two functions named "esdc" and "type" are created by using R statistical programming language for the operations performed in both parts, and these functions are added to the content of an R package after its creation with the name ***EpistemicGameTheory***.</p>
</div>
</a>
<a href="articles/RJ-2018-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 15, 2018</div>
<div class="dt-authors">
<div class="dt-author">Brandon M. Greenwell</div>
<div class="dt-author">Andrew McCarthy</div>
<div class="dt-author">Bradley C. Boehmke</div>
<div class="dt-author">Dungang Liu</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Residuals and Diagnostics for Binary and Ordinal Regression Models: An Introduction to the sure Package</h2>
<div class="dt-tags"></div>
<p>Residual diagnostics is an important topic in the classroom, but it is less often used in practice when the response is binary or ordinal. Part of the reason for this is that generalized models for discrete data, like cumulative link models and logistic regression, do not produce standard residuals that are easily interpreted as those in ordinary linear regression. In this paper, we introduce the R package ***sure***, which implements a recently developed idea of **SU**rrogate **RE**siduals. We demonstrate the utility of the package in detection of cumulative link model misspecification with respect to mean structures, link functions, heteroscedasticity, proportionality, and interaction effects.</p>
</div>
</a>
<a href="articles/RJ-2017-067/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 4, 2017</div>
<div class="dt-authors">
<div class="dt-author">Jannes Muenchow</div>
<div class="dt-author">Patrick Schratz</div>
<div class="dt-author">Alexander Brenning</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>RQGIS: Integrating R with QGIS for Statistical Geocomputing</h2>
<div class="dt-tags"></div>
<p>Integrating R with Geographic Information Systems (GIS) extends R's statistical capabilities with numerous geoprocessing and data handling tools available in a GIS. QGIS is one of the most popular open-source GIS, and it furthermore integrates other GIS programs such as the System for Automated Geoscientific Analyses (SAGA) GIS and the Geographic Resources Analysis Support System (GRASS) GIS within a single software environment. This and its QGIS Python API makes it a perfect candidate for console-based geoprocessing. By establishing an interface, the R package *RQGIS* makes it possible to use QGIS as a geoprocessing workhorse from within R. Compared to other packages building a bridge to GIS (e.g., *rgrass7*, *RSAGA*, *RPyGeo*), *RQGIS* offers a wider range of geoalgorithms, and is often easier to use due to various convenience functions. Finally, *RQGIS* supports the seamless integration of Python code using *reticulate* from within R for improved extendability.</p>
</div>
</a>
<a href="articles/RJ-2017-068/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 4, 2017</div>
<div class="dt-authors">
<div class="dt-author">Simon Bond</div>
<div class="dt-author">Ian R White</div>
<div class="dt-author">Annabel Allison</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>rpsftm: An R Package for Rank Preserving Structural Failure Time Models</h2>
<div class="dt-tags"></div>
<p>Treatment switching in a randomised controlled trial occurs when
participants change from their randomised treatment to the other trial
treatment during the study. Failure to account for treatment switching
in the analysis (i.e.by performing a standard intention-to-treat
analysis) can lead to biased estimates of treatment efficacy. The rank
preserving structural failure time model (RPSFTM) is a method used to
adjust for treatment switching in trials with survival outcomes. The
RPSFTM is due to [@robins:91] and has been developed by
[@white:97; @white:99].\
The method is randomisation based and uses only the randomised
treatment group, observed event times, and treatment history in order
to estimate a causal treatment effect. The treatment effect, $\psi$,
is estimated by balancing counter-factual event times (that would be
observed if no treatment were received) between treatment groups.
G-estimation is used to find the value of $\psi$ such that a test
statistic $Z\left(\psi\right) = 0$. This is usually the test statistic
used in the intention-to-treat analysis, for example, the log rank
test statistic.\
We present an R package, *rpsftm*, that implements the method.</p>
</div>
</a>
<a href="articles/RJ-2017-066/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2017</div>
<div class="dt-authors">
<div class="dt-author">Mollie E. Brooks</div>
<div class="dt-author">Kasper Kristensen</div>
<div class="dt-author">Koen J. van Benthem</div>
<div class="dt-author">Arni Magnusson</div>
<div class="dt-author">Casper W. Berg</div>
<div class="dt-author">Anders Nielsen</div>
<div class="dt-author">Hans J. Skaug</div>
<div class="dt-author">Martin Mchler</div>
<div class="dt-author">Benjamin M. Bolker</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>glmmTMB Balances Speed and Flexibility Among Packages for Zero-inflated Generalized Linear Mixed Modeling</h2>
<div class="dt-tags"></div>
<p>Count data can be analyzed using generalized linear mixed models when observations are correlated in ways that require random effects. However, count data are often *zero-inflated*, containing more zeros than would be expected from the typical error distributions. We present a new package, *glmmTMB*, and compare it to other R packages that fit zero-inflated mixed models. The *glmmTMB* package fits many types of GLMMs and extensions, including models with continuously distributed responses, but here we focus on count responses. *glmmTMB* is faster than *glmmADMB*, *MCMCglmm*, and *brms*, and more flexible than *INLA* and *mgcv* for zero-inflated modeling. One unique feature of *glmmTMB* (among packages that fit zero-inflated mixed models) is its ability to estimate the Conway-Maxwell-Poisson distribution parameterized by the mean. Overall, its most appealing features for new users may be the combination of speed, flexibility, and its interface's similarity to *lme4*.</p>
</div>
</a>
<a href="articles/RJ-2017-064/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 27, 2017</div>
<div class="dt-authors">
<div class="dt-author">Chao Wang</div>
<div class="dt-author">Kung-Sik Chan</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>carx:an R Package to Estimate Censored Autoregressive Time Series with Exogenous Covariates </h2>
<div class="dt-tags"></div>
<p>We implement in the R package ***carx*** a novel and computationally efficient quasi-likelihood method for estimating a censored autoregressive model with exogenous covariates. The proposed quasi-likelihood method reduces to maximum likelihood estimation in absence of censoring. The ***carx*** package contains many useful functions for practical data analysis with censored stochastic regression, including functions for outlier detection, model diagnostics, and prediction with censored time series data. We illustrate the capabilities of the ***carx*** package with simulations and an elaborate real data analysis.</p>
</div>
</a>
<a href="articles/RJ-2017-065/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 27, 2017</div>
<div class="dt-authors">
<div class="dt-author">Carl Boettiger</div>
<div class="dt-author">Dirk Eddelbuettel</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>An Introduction to Rocker: Docker Containers for R</h2>
<div class="dt-tags"></div>
<p>We describe the Rocker project, which provides a widely-used suite of Docker images with customized R environments for particular tasks. We discuss how this suite is organized, and how these tools can increase portability, scaling, reproducibility, and convenience of R users and developers.</p>
</div>
</a>
<a href="articles/RJ-2017-059/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 22, 2017</div>
<div class="dt-authors">
<div class="dt-author">Christopher Gandrud</div>
<div class="dt-author">Laron K. Williams</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Simulating Probabilistic Long-Term Effects in Models with Temporal Dependence</h2>
<div class="dt-tags"></div>
<p>The R package *pltesim* calculates and depicts probabilistic long-term effects in binary models with temporal dependence variables. The package performs two tasks. First, it calculates the change in the probability of the event occurring given a change in a theoretical variable. Second, it calculates the rolling difference in the future probability of the event for two scenarios: one where the event occurred at a given time and one where the event does not occur. The package is consistent with the recent movement to depict meaningful and easy-to-interpret quantities of interest with the requisite measures of uncertainty. It is the first to make it easy for researchers to interpret short- and long-term effects of explanatory variables in binary autoregressive models, which can have important implications for the correct interpretation of these models.</p>
</div>
</a>
<a href="articles/RJ-2017-060/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 22, 2017</div>
<div class="dt-authors">
<div class="dt-author">Xuwen Zhu</div>
<div class="dt-author">Volodymyr Melnykov</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ManlyMix: An R Package for Manly Mixture Modeling</h2>
<div class="dt-tags"></div>
<p>Model-based clustering is a popular technique for grouping objects based on a finite mixture model. It has countless applications in different fields of study. The R package *ManlyMix* implements the Manly mixture model that allows modeling skewness within data groups and performs cluster analysis. *ManlyMix* is a powerful diagnostics tool that is capable of conducting investigation concerning the normality of variables upon fitting of a Manly forward or backward model. Theoretical foundations as well as description of functions are provided. All features of the package are illustrated with examples in great detail. The analysis of real-life datasets demonstrates the flexibility and usefulness of the package.</p>
</div>
</a>
<a href="articles/RJ-2017-061/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 22, 2017</div>
<div class="dt-authors">
<div class="dt-author">Robin K. S. Hankin</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Partial Rank Data with the hyper2 Package: Likelihood Functions for Generalized Bradley-Terry Models</h2>
<div class="dt-tags"></div>
<p>Here I present the *hyper2* package for generalized Bradley-Terry models and give examples from two competitive situations: single scull rowing, and the competitive cooking game show MasterChef Australia. A number of natural statistical hypotheses may be tested straightforwardly using the software.</p>
</div>
</a>
<a href="articles/RJ-2017-062/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 22, 2017</div>
<div class="dt-authors">
<div class="dt-author">Brice Ozenne</div>
<div class="dt-author">Anne Lyngholm Srensen</div>
<div class="dt-author">Thomas Scheike</div>
<div class="dt-author">Christian Torp-Pedersen</div>
<div class="dt-author">Thomas Alexander Gerds</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>riskRegression: Predicting the Risk of an Event using Cox Regression Models</h2>
<div class="dt-tags"></div>
<p>In the presence of competing risks a prediction of the time-dynamic absolute risk of an event can be based on cause-specific Cox regression models for the event and the competing risks [@benichou1990estimates]. We present computationally fast and memory optimized C++ functions with an R interface for predicting the covariate specific absolute risks, their confidence intervals, and their confidence bands based on right censored time to event data. We provide explicit formulas for our implementation of the estimator of the (stratified) baseline hazard function in the presence of tied event times. As a by-product we obtain fast access to the baseline hazards (compared to `survival::basehaz()`) and predictions of survival probabilities, their confidence intervals and confidence bands. Confidence intervals and confidence bands are based on point-wise asymptotic expansions of the corresponding statistical functionals. The software presented here is implemented in the ***riskRegression*** package.</p>
</div>
</a>
<a href="articles/RJ-2017-063/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 22, 2017</div>
<div class="dt-authors">
<div class="dt-author">Travis Canida</div>
<div class="dt-author">John Ihrie</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>openEBGM: An R Implementation of the Gamma-Poisson Shrinker Data Mining Model</h2>
<div class="dt-tags"></div>
<p>We introduce the R package ***openEBGM***, an implementation of the Gamma-Poisson Shrinker (GPS) model for identifying unexpected counts in large contingency tables using an empirical Bayes approach. The Empirical Bayes Geometric Mean (EBGM) and quantile scores are obtained from the GPS model estimates. ***openEBGM*** provides for the evaluation of counts using a number of different methods, including the model-based disproportionality scores, the relative reporting ratio (RR), and the proportional reporting ratio (PRR). Data squashing for computational efficiency and stratification for confounding variable adjustment are included. Application to adverse event detection is discussed.</p>
</div>
</a>
<a href="articles/RJ-2017-057/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 16, 2017</div>
<div class="dt-authors">
<div class="dt-author">Nathan Medina-Rodrguez</div>
<div class="dt-author">ngelo Santana</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Allele Imputation and Haplotype Determination from Databases Composed of Nuclear Families</h2>
<div class="dt-tags"></div>
<p>The *alleHap* package is designed for imputing genetic missing data and reconstruct non-recombinant haplotypes from pedigree databases in a deterministic way. When genotypes of related individuals are available in a number of linked genetic markers, the program starts by identifying haplotypes compatible with the observed genotypes in those markers without missing values. If haplotypes are identified in parents or offspring, missing alleles can be imputed in subjects containing missing values. Several scenarios are analyzed: family completely genotyped, children partially genotyped and parents completely genotyped, children fully genotyped and parents containing entirely or partially missing genotypes, and founders and their offspring both only partially genotyped. The *alleHap* package also has a function to simulate pedigrees including all these scenarios. This article describes in detail how our package works for the desired applications, including illustrated explanations and easily reproducible examples.</p>
</div>
</a>
<a href="articles/RJ-2017-058/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 16, 2017</div>
<div class="dt-authors">
<div class="dt-author">David J. Winter</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>rentrez: An R package for the NCBI eUtils API</h2>
<div class="dt-tags"></div>
<p>The USA National Center for Biotechnology Information (NCBI) is one of the world's most important sources of biological information. NCBI databases like PubMed and GenBank contain millions of records describing bibliographic, genetic, genomic, and medical data. Here I present *rentrez*, a package which provides an R interface to 50 NCBI databases. The package is well-documented, contains an extensive suite of unit tests and has an active user base. The programmatic interface to the NCBI provided by *rentrez* allows researchers to query databases and download or import particular records into R sessions for subsequent analysis. The complete nature of the package, its extensive test-suite and the fact the package implements the NCBI's usage policies all make *rentrez* a powerful aid to developers of new packages that perform more specific tasks.</p>
</div>
</a>
<a href="articles/RJ-2017-056/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 5, 2017</div>
<div class="dt-authors">
<div class="dt-author">Andreas Beger</div>
<div class="dt-author">Daniel W. Hill, Jr.</div>
<div class="dt-author">Nils W. Metternich</div>
<div class="dt-author">Shahryar Minhas</div>
<div class="dt-author">Michael D. Ward</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Splitting It Up: The spduration Split-Population Duration Regression Package for Time-Varying Covariates</h2>
<div class="dt-tags"></div>
<p>We present an implementation of split-population duration regression in the *spduration* [@beger2016spduration] package for R that allows for time-varying covariates. The statistical model accounts for units that are immune to a certain outcome and are not part of the duration process the researcher is primarily interested in. We provide insights for when immune units exist, that can significantly increase the predictive performance compared to standard duration models. The package includes estimation and several post-estimation methods for split-population Weibull and log-logistic models. We provide an empirical application to data on military coups.</p>
</div>
</a>
<a href="articles/RJ-2017-055/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2017</div>
<div class="dt-authors">
<div class="dt-author">Josmar Mazucheli</div>
<div class="dt-author">Andr Felipe Berdusco Menezes</div>
<div class="dt-author">Saralees Nadarajah</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>mle.tools: An R Package for Maximum Likelihood Bias Correction</h2>
<div class="dt-tags"></div>
<p>Recently, [@mazucheli-mletools] uploaded the package *mle.tools* to CRAN. It can be used for bias corrections of maximum likelihood estimates through the methodology proposed by [@MR0237052]. The main function of the package, `coxsnell.bc()`, computes the bias corrected maximum likelihood estimates. Although in general, the bias corrected estimators may be expected to have better sampling properties than the uncorrected estimators, analytical expressions from the formula proposed by [@MR0237052] are either tedious or impossible to obtain. The purpose of this paper is twofolded: to introduce the *mle.tools* package, especially the `coxsnell.bc()` function; secondly, to compare, for thirty one continuous distributions, the bias estimates from the `coxsnell.bc()` function and the bias estimates from analytical expressions available in the literature. We also compare, for five distributions, the observed and expected Fisher information. Our numerical experiments show that the functions are efficient to estimate the biases by the Cox-Snell formula and for calculating the observed and expected Fisher information.</p>
</div>
</a>
<a href="articles/RJ-2017-054/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 31, 2017</div>
<div class="dt-authors">
<div class="dt-author">Hideitsu Hino</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ider: Intrinsic Dimension Estimation with R</h2>
<div class="dt-tags"></div>
<p>In many data analyses, the dimensionality of the observed data is high while its intrinsic dimension remains quite low. Estimating the intrinsic dimension of an observed dataset is an essential preliminary step for dimensionality reduction, manifold learning, and visualization. This paper introduces an R package, named [*ider*](https://CRAN.R-project.org/package=ider), that implements eight intrinsic dimension estimation methods, including a recently proposed method based on a second-order expansion of a probability mass function and a generalized linear model. The usage of each function in the package is explained with datasets generated using a function that is also included in the package.</p>
</div>
</a>
<a href="articles/RJ-2017-052/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 25, 2017</div>
<div class="dt-authors">
<div class="dt-author">Nicholas Syring</div>
<div class="dt-author">Meng Li</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>BayesBD: An R Package for Bayesian Inference on Image Boundaries</h2>
<div class="dt-tags"></div>
<p>We present the *BayesBD* package providing Bayesian inference for boundaries of noisy images. The *BayesBD* package implements flexible Gaussian process priors indexed by the circle to recover the boundary in a binary or Gaussian noised image. The boundary recovered by *BayesBD* has the practical advantages of guaranteed geometric restrictions and convenient joint inferences under certain assumptions, in addition to its desirable theoretical property of achieving (nearly) minimax optimal rate in a way that is adaptive to the unknown smoothness. The core sampling tasks for our model have linear complexity, and are implemented in C++ for computational efficiency using packages *Rcpp* and *RcppArmadillo*. Users can access the full functionality of the package in both the command line and the corresponding *shiny* application. Additionally, the package includes numerous utility functions to aid users in data preparation and analysis of results. We compare *BayesBD* with selected existing packages using both simulations and real data applications, demonstrating the excellent performance and flexibility of *BayesBD* even when the observation contains complicated structural information that may violate its assumptions.</p>
</div>
</a>
<a href="articles/RJ-2017-053/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 25, 2017</div>
<div class="dt-authors">
<div class="dt-author">Ruby Sharma</div>
<div class="dt-author">Sajal Kumar</div>
<div class="dt-author">Hua Zhong</div>
<div class="dt-author">Mingzhou Song</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Simulating Noisy, Nonparametric, and Multivariate Discrete Patterns</h2>
<div class="dt-tags"></div>
<p>Requiring no analytical forms, nonparametric discrete patterns are flexible in representing complex relationships among random variables. This makes them increasingly useful for data-driven applications. However, there appears to be no software tools for simulating nonparametric discrete patterns, which prevents objective evaluation of statistical methods that discover discrete relationships from data. We present a simulator to generate nonparametric discrete functions as contingency tables. User can request strictly many-to-one functional patterns. The simulator can also produce contingency tables representing dependent non-functional and independent relationships. An option is provided to apply random noise to contingency tables. We demonstrate the utility of the simulator by showing the advantage of the FunChisq test over Pearson's chi-square test in detecting functional patterns. This simulator, implemented in the function `simulate_tables` in the R package *FunChisq* (version 2.4.0 or greater), offers an important means to evaluate the performance of nonparametric statistical pattern discovery methods.</p>
</div>
</a>
<a href="articles/RJ-2017-046/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 24, 2017</div>
<div class="dt-authors">
<div class="dt-author">Patrick Breheny</div>
<div class="dt-author">Woodrow Burchett</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Visualization of Regression Models Using visreg</h2>
<div class="dt-tags"></div>
<p>Regression models allow one to isolate the relationship between the outcome and an explanatory variable while the other variables are held constant. Here, we introduce an R package, *visreg*, for the convenient visualization of this relationship via short, simple function calls. In addition to estimates of this relationship, the package also provides pointwise confidence bands and partial residuals to allow assessment of variability as well as outliers and other deviations from modeling assumptions. The package provides several options for visualizing models with interactions, including lattice plots, contour plots, and both static and interactive perspective plots. The implementation of the package is designed to be fully object-oriented and interface seamlessly with R's rich collection of model classes, allowing a consistent interface for visualizing not only linear models, but generalized linear models, proportional hazards models, generalized additive models, robust regression models, and many more.</p>
</div>
</a>
<a href="articles/RJ-2017-047/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 24, 2017</div>
<div class="dt-authors">
<div class="dt-author">Michael Hahsler</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>arulesViz: Interactive Visualization of Association Rules with R</h2>
<div class="dt-tags"></div>
<p>Association rule mining is a popular data mining method to discover interesting relationships between variables in large databases. An extensive toolbox is available in the R-extension package*arules*. However, mining association rules often results in a vast number of found rules, leaving the analyst with the task to go through a large set of rules to identify interesting ones. Sifting manually through extensive sets of rules is time-consuming and strenuous. Visualization and especially interactive visualization has a long history of making large amounts of data better accessible. The R-extension package*arulesViz* provides most popular visualization techniques for association rules. In this paper, we discuss recently added interactive visualizations to explore association rules and demonstrate how easily they can be used in*arulesViz* via a unified interface. With examples, we help to guide the user in selecting appropriate visualizations and interpreting the results.</p>
</div>
</a>
<a href="articles/RJ-2017-048/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 24, 2017</div>
<div class="dt-authors">
<div class="dt-author">Muhammad Imdadullah</div>
<div class="dt-author">Muhammad Aslam</div>
<div class="dt-author">Saima Altaf</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>liureg: A Comprehensive R Package for the Liu Estimation of Linear Regression Model with Collinear Regressors</h2>
<div class="dt-tags"></div>
<p>The Liu regression estimator is now a commonly used alternative to the conventional ordinary least squares estimator that avoids the adverse effects in the situations when there exists a considerable degree of multicollinearity among the regressors. There are only a few software packages available for estimation of the Liu regression coefficients, though with limited methods to estimate the Liu biasing parameter without addressing testing procedures. Our *liureg* package can be used to estimate the Liu regression coefficients utilizing a range of different existing biasing parameters, to test these coefficients with more than 15 Liu related statistics, and to present different graphical displays of these statistics.</p>
</div>
</a>
<a href="articles/RJ-2017-049/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 24, 2017</div>
<div class="dt-authors">
<div class="dt-author">Pablo J. Villacorta</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The welchADF Package for Robust Hypothesis Testing in Unbalanced Multivariate Mixed Models with Heteroscedastic and Non-normal Data</h2>
<div class="dt-tags"></div>
<p>A new R package is presented for dealing with non-normality and variance heterogeneity of sample data when conducting hypothesis tests of main effects and interactions in mixed models. The proposal departs from an existing SAS program which implements Johansen's general formulation of Welch-James's statistic with approximate degrees of freedom, which makes it suitable for testing any linear hypothesis concerning cell means in univariate and multivariate mixed model designs when the data pose non-normality and non-homogeneous variance. Improved type I error rate control is obtained using bootstrapping for calculating an empirical critical value, whereas robustness against non-normality is achieved through trimmed means and Winsorized variances. A wrapper function eases the application of the test in common situations, such as performing omnibus tests on all effects and interactions, pairwise contrasts, and tetrad contrasts of two-way interactions. The package is demonstrated in several problems including unbalanced univariate and multivariate designs.</p>
</div>
</a>
<a href="articles/RJ-2017-050/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 24, 2017</div>
<div class="dt-authors">
<div class="dt-author">Clifford Anderson-Bergman</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Bayesian Regression Models for Interval-censored Data in R</h2>
<div class="dt-tags"></div>
<p>The package ***icenReg*** provides classic survival regression models for interval-censored data. We present an update to the package that extends the parametric models into the Bayesian framework. Core additions include functionality to define the regression model with the standard regression syntax while providing a custom prior function. Several other utility functions are presented that allow for simplified examination of the posterior distribution.</p>
</div>
</a>
<a href="articles/RJ-2017-051/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 24, 2017</div>
<div class="dt-authors">
<div class="dt-author">Pedro Caadilla Jimnez</div>
<div class="dt-author">Yolanda Romn Montoya</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>queueing: A Package For Analysis Of Queueing Networks and Models in R</h2>
<div class="dt-tags"></div>
<p>queueing is a package that solves and provides the main performance measures for both basic Markovian queueing models and single and multiclass product-form queueing networks. It can be used both in education and for professional purposes. It provides an intuitive, straightforward way to build queueing models using S3 methods. The package solves Markovian models of the form M/M/c/K/M/FCFS, open and closed single class Jackson networks, open and closed multiclass networks and mixed networks. Markovian models are used when both the customer inter-arrival time and the server processing time are exponentially distributed. Queueing network solvers are useful for modelling situations in which more than one station must be visited.</p>
</div>
</a>
<a href="articles/RJ-2017-044/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 12, 2017</div>
<div class="dt-authors">
<div class="dt-author">Guillermo Basulto-Elias</div>
<div class="dt-author">Alicia Carriquiry</div>
<div class="dt-author">Kris De Brabanter</div>
<div class="dt-author">Daniel J. Nordman</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>fourierin: An R package to compute Fourier integrals</h2>
<div class="dt-tags"></div>
<p>We present the R package *fourierin* [@basulto2016fourierin] for evaluating functions defined as Fourier-type integrals over a collection of argument values. The integrals are finitely supported with integrands involving continuous functions of one or two variables. As an important application, such Fourier integrals arise in so-called "inversion formulas", where one seeks to evaluate a probability density at a series of points from a given characteristic function (or vice versa) through Fourier transforms. This paper intends to fill a gap in current R software, where tools for repeated evaluation of functions as Fourier integrals are not directly available. We implement two approaches for such computations with numerical integration. In particular, if the argument collection for evaluation corresponds to a regular grid, then an algorithm from @inverarity2002fast may be employed based on a fast Fourier transform, which creates significant improvements in the speed over a second approach to numerical Fourier integration (where the latter also applies to cases where the points for evaluation are not on a grid). We illustrate the package with the computation of probability densities and characteristic functions through Fourier integrals/transforms, for both univariate and bivariate examples.</p>
</div>
</a>
<a href="articles/RJ-2017-045/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 12, 2017</div>
<div class="dt-authors">
<div class="dt-author">Rafael Bentez</div>
<div class="dt-author">Vicente J. Bols</div>
<div class="dt-author">Jos-Luis Toca-Herrera</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>afmToolkit: an R Package for Automated AFM Force-Distance Curves Analysis</h2>
<div class="dt-tags"></div>
<p>Atomic force microscopy (AFM) is widely used to measure molecular and colloidal interactions as well as mechanical properties of biomaterials. In this paper the *afmToolkit* R package is introduced. This package allows the user to automatically batch process AFM force-distance and force-time curves. *afmToolkit* capabilities range from importing ASCII files and preprocessing the curves (contact point detection, baseline correction...) for finding relevant physical information, such as Young's modulus, adhesion energies and exponential decay for force relaxation and creep experiments. This package also contains plotting, summary and feature extraction functions. The package also comes with several data sets so the user can test the aforementioned features with ease. The package *afmToolkit* eases the basic processing of large amount of AFM F-d/t curves at once. It is also flexible enough to easily incorporate new functions as they are needed and can be seen as a programming infrastructure for further algorithm development.</p>
</div>
</a>
<a href="articles/RJ-2017-042/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 7, 2017</div>
<div class="dt-authors">
<div class="dt-author">Aurlie Siberchicot</div>
<div class="dt-author">Alice Julien-Laferrire</div>
<div class="dt-author">Anne-Batrice Dufour</div>
<div class="dt-author">Jean Thioulouse</div>
<div class="dt-author">Stphane Dray</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>adegraphics: An S4 Lattice-Based Package for the Representation of Multivariate Data</h2>
<div class="dt-tags"></div>
<p>The *ade4* package provides tools for multivariate analyses. Whereas new statistical methods have been added regularly in the package since its first release in 2002, the graphical functions, that are used to display the main outputs of an analysis, have not benefited from such enhancements. In this context, the *adegraphics* package, available on CRAN since 2015, is a complete reimplementation of the *ade4* graphical functionalities but with large improvements. The package uses the S4 object system (each graph is an object) and is based on the graphical framework provided by *lattice* and *grid*. We give a brief description of the package and illustrate some important functionalities to build elegant graphs.</p>
</div>
</a>
<a href="articles/RJ-2017-043/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 7, 2017</div>
<div class="dt-authors">
<div class="dt-author">Mirta Beni</div>
<div class="dt-author">Petar Taler</div>
<div class="dt-author">Safet Hamedovi</div>
<div class="dt-author">Emmanuel Karlo Nyarko</div>
<div class="dt-author">Kristian Sabo</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>LeArEst: Length and Area Estimation from Data Measured with Additive Error</h2>
<div class="dt-tags"></div>
<p>This paper describes an R package ***LeArEst*** that can be used for
estimating object dimensions from a noisy image. The package is based
on a simple parametric model for data that are drawn from uniform
distribution contaminated by an additive error. Our package is able to
estimate the length of the object of interest on a given straight line
that intersects it, as well as to estimate the object area when it is
elliptically shaped. The input data may be a numerical vector or an
image in JPEG format. In this paper, background statistical models and
methods for the package are summarized, and the algorithms and key
functions implemented are described. Also, examples that demonstrate
its usage are provided.\
**Availability:** ***LeArEst*** is available on CRAN.</p>
</div>
</a>
<a href="articles/RJ-2017-040/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 25, 2017</div>
<div class="dt-authors">
<div class="dt-author">Nicolae Teodor Melita</div>
<div class="dt-author">Stefan Holban</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>dGAselID: An R Package for Selecting a Variable Number of Features in High Dimensional Data</h2>
<div class="dt-tags"></div>
<p>The *dGAselID* package proposes an original approach to feature selection in high dimensional data. The method is built upon a diploid genetic algorithm. The genotype to phenotype mapping is modeled after the Incomplete Dominance Inheritance, overpassing the necessity to define a dominance scheme. The fitness evaluation is done by user selectable supervised classifiers, from a broad range of options. Cross validation options are also accessible. A new approach to crossover, inspired from the random assortment of chromosomes during meiosis is included. Several mutation operators, inspired from genetics, are also proposed. The package is fully compatible with the data formats used in *Bioconductor* and *MLInterfaces* package, readily applicable to microarray studies, but is flexible to other feature selection applications from high dimensional data. Several options for the visualization of evolution and outcomes are implemented to facilitate the interpretation of results. The package's functionality is illustrated by examples.</p>
</div>
</a>
<a href="articles/RJ-2017-041/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 25, 2017</div>
<div class="dt-authors">
<div class="dt-author">Melanie Prague</div>
<div class="dt-author">Rui Wang</div>
<div class="dt-author">Victor De Gruttola</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>CRTgeeDR: an R Package for Doubly Robust Generalized Estimating Equations Estimations in Cluster Randomized Trials with Missing Data</h2>
<div class="dt-tags"></div>
<p>Semi-parametric approaches based on generalized estimating equations (GEE) are widely used to analyze correlated outcomes in longitudinal settings. In this paper, we present a package *CRTgeeDR* developed for cluster randomized trials with missing data (CRTs). For use of inverse probability weighting to adjust for missing data in cluster randomized trials, we show that other software lead to biased estimation for non-independence working correlation structure. *CRTgeeDR* solves this problem. We also extend the ability of existing packages to allow augmented Doubly Robust GEE estimation (DR). Simulation studies demonstrate the consistency of estimators implemented in *CRTgeeDR* compared to packages such as *geepack* and the gains associated with the use of the DR for analyzing a binary outcome using a logistic regression. Finally, we illustrate the method on data from a sanitation CRT in developing countries.</p>
</div>
</a>
<a href="articles/RJ-2017-039/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 4, 2017</div>
<div class="dt-authors">
<div class="dt-author">Robert J. Gutierrez</div>
<div class="dt-author">Bradley C. Boehmke</div>
<div class="dt-author">Kenneth W. Bauer</div>
<div class="dt-author">Cade M. Saie</div>
<div class="dt-author">Trevor J. Bihl</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>anomalyDetection: Implementation of Augmented Network Log Anomaly Detection Procedures</h2>
<div class="dt-tags"></div>
<p>As the number of cyber-attacks continues to grow on a daily basis, so does the delay in threat detection. For instance, in 2015, the Office of Personnel Management discovered that approximately 21.5 million individual records of Federal employees and contractors had been stolen. On average, the time between an attack and its discovery is more than 200 days. In the case of the OPM breach, the attack had been going on for almost a year. Currently, cyber analysts inspect numerous potential incidents on a daily basis, but have neither the time nor the resources available to perform such a task. *anomalyDetection* aims to curtail the time frame in which anomalous cyber activities go unnoticed and to aid in the efficient discovery of these anomalous transactions among the millions of daily logged events by i) providing an efficient means for pre-processing and aggregating cyber data for analysis by employing a tabular vector transformation and handling multicollinearity concerns; ii) offering numerous built-in multivariate statistical functions such as Mahalanobis distance, factor analysis, principal components analysis to identify anomalous activity, iii) incorporating the pipe operator (`%&gt;%`) to allow it to work well in the *tidyverse* workflow. Combined, *anomalyDetection* offers cyber analysts an efficient and simplified approach to break up network events into time-segment blocks and identify periods associated with suspected anomalies for further evaluation.</p>
</div>
</a>
<a href="articles/RJ-2017-038/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 28, 2017</div>
<div class="dt-authors">
<div class="dt-author">Marius Pfeuffer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ctmcd: An R Package for Estimating the Parameters of a Continuous-Time Markov Chain from Discrete-Time Data</h2>
<div class="dt-tags"></div>
<p>This article introduces the R package *ctmcd*, which provides an implementation of methods for the estimation of the parameters of a continuous-time Markov chain given that data are only available on a discrete-time basis. This data consists of partial observations of the state of the chain, which are made without error at discrete times, an issue also known as the embedding problem for Markov chains. The functions provided comprise matrix logarithm based approximations as described in @Israel01, as well as @Kreinin01, an expectation-maximization algorithm and a Gibbs sampling approach, both introduced by @Bladt05. For the expectation-maximization algorithm Wald confidence intervals based on the Fisher information estimation method of @Oakes99 are provided. For the Gibbs sampling approach, equal-tailed credibility intervals can be obtained. In order to visualize the parameter estimates, a matrix plot function is provided. The methods described are illustrated by Standard and Poor's discrete-time corporate credit rating transition data.</p>
</div>
</a>
<a href="articles/RJ-2017-036/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 24, 2017</div>
<div class="dt-authors">
<div class="dt-author">Giorgio Alfredo Spedicato</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Discrete Time Markov Chains with R</h2>
<div class="dt-tags"></div>
<p>The [*markovchain*](https://CRAN.R-project.org/package=markovchain) package aims to provide S4 classes and methods to easily handle Discrete Time Markov Chains (DTMCs), filling the gap with what is currently available in the CRAN repository. In this work, I provide an exhaustive description of the main functions included in the package, as well as hands-on examples.</p>
</div>
</a>
<a href="articles/RJ-2017-037/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 24, 2017</div>
<div class="dt-authors">
<div class="dt-author">Tyson S. Barrett</div>
<div class="dt-author">Emily Brignone</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Furniture for Quantitative Scientists</h2>
<div class="dt-tags"></div>
<p>A basic understanding of the distributions of study variables and the relationships among them is essential to inform statistical modeling. This understanding is achieved through the computation of summary statistics and exploratory data analysis. Unfortunately, this step tends to be under-emphasized in the research process, in part because of the often tedious nature of thorough exploratory data analysis. The `table1()` function in the *furniture* package streamlines much of the exploratory data analysis process, making the computation and communication of summary statistics simple and beautiful while offering significant time-savings to the researcher.</p>
</div>
</a>
<a href="articles/RJ-2017-034/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 28, 2017</div>
<div class="dt-authors">
<div class="dt-author">Heather Savoy</div>
<div class="dt-author">Falk Hee</div>
<div class="dt-author">Yoram Rubin</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>anchoredDistr: a Package for the Bayesian Inversion of Geostatistical Parameters with Multi-type and Multi-scale Data</h2>
<div class="dt-tags"></div>
<p>The Method of Anchored Distributions (MAD) is a method for Bayesian inversion designed for inferring both local (e.g.point values) and global properties (e.g.mean and variogram parameters) of spatially heterogenous fields using multi-type and multi-scale data. Software implementations of MAD exist in C++ and C# to import data, execute an ensemble of forward model simulations, and perform basic post-processing of calculating likelihood and posterior distributions for a given application. This article describes the R package *anchoredDistr* that has been built to provide an R-based environment for this method. In particular, *anchoredDistr* provides a range of post-processing capabilities for MAD software by taking advantage of the statistical capabilities and wide use of the R language. Two examples from stochastic hydrogeology are provided to highlight the features of the package for MAD applications in inferring anchored distributions of local parameters (e.g.point values of transmissivity) as well as global parameters (e.g.the mean of the spatial random function for hydraulic conductivity).</p>
</div>
</a>
<a href="articles/RJ-2017-035/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 28, 2017</div>
<div class="dt-authors">
<div class="dt-author">Taylor Arnold</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>A Tidy Data Model for Natural Language Processing using cleanNLP</h2>
<div class="dt-tags"></div>
<p>Recent advances in natural language processing have produced libraries that extract low-level features from a collection of raw texts. These features, known as annotations, are usually stored internally in hierarchical, tree-based data structures. This paper proposes a data model to represent annotations as a collection of normalized relational data tables optimized for exploratory data analysis and predictive modeling. The R package *cleanNLP*, which calls one of two state of the art NLP libraries (CoreNLP or spaCy), is presented as an implementation of this data model. It takes raw text as an input and returns a list of normalized tables. Specific annotations provided include tokenization, part of speech tagging, named entity recognition, sentiment analysis, dependency parsing, coreference resolution, and word embeddings. The package currently supports input text in English, German, French, and Spanish.</p>
</div>
</a>
<a href="articles/RJ-2017-030/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 8, 2017</div>
<div class="dt-authors">
<div class="dt-author">Gul Inan</div>
<div class="dt-author">Lan Wang</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>PGEE: An R Package for Analysis of Longitudinal Data with High-Dimensional Covariates</h2>
<div class="dt-tags"></div>
<p>We introduce an R package *PGEE* that implements the penalized generalized estimating equations (GEE) procedure proposed by @wang2012penalized to analyze longitudinal data with a large number of covariates. The *PGEE* package includes three main functions: `CVfit`, `PGEE`, and `MGEE`. The `CVfit` function computes the cross-validated tuning parameter for penalized generalized estimating equations. The function `PGEE` performs simultaneous estimation and variable selection for longitudinal data with high-dimensional covariates; whereas the function `MGEE` fits unpenalized GEE to the data for comparison. The R package *PGEE* is illustrated using a yeast cell-cycle gene expression data set.</p>
</div>
</a>
<a href="articles/RJ-2017-031/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 8, 2017</div>
<div class="dt-authors">
<div class="dt-author">Daniel Osorio</div>
<div class="dt-author">Janneth Gonzlez</div>
<div class="dt-author">Andrs Pinzn</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>minval: An R package for MINimal VALidation of Stoichiometric Reactions</h2>
<div class="dt-tags"></div>
<p>A genome-scale metabolic reconstruction is a compilation of all stoichiometric reactions that can describe the entire cellular metabolism of an organism, and they have become an indispensable tool for our understanding of biological phenomena, covering fields that range from systems biology to bioengineering. Interrogation of metabolic reconstructions are generally carried through Flux Balance Analysis, an optimization method in which the biological sense of the optimal solution is highly sensitive to thermodynamic unbalance caused by the presence of stoichiometric reactions whose compounds are not produced or consumed in any other reaction (orphan metabolites) and by mass unbalance. The *minval* package was designed as a tool to identify orphan metabolites and evaluate the mass and charge balance of stoichiometric reactions. The package also includes functions to characterize and write models in TSV and SBML formats, extract all reactants, products, metabolite names and compartments from a metabolic reconstruction.</p>
</div>
</a>
<a href="articles/RJ-2017-032/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 8, 2017</div>
<div class="dt-authors">
<div class="dt-author">G. Brooke Anderson</div>
<div class="dt-author">Colin Eason</div>
<div class="dt-author">Elizabeth A. Barnes</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Working with Daily Climate Model Output Data in R and the futureheatwaves Package</h2>
<div class="dt-tags"></div>
<p>Research on climate change impacts can require extensive processing of climate model output, especially when using ensemble techniques to incorporate output from multiple climate models and multiple simulations of each model. This processing can be particularly extensive when identifying and characterizing multi-day extreme events like heat waves and frost day spells, as these must be processed from model output with daily time steps. Further, climate model output is in a format and follows standards that may be unfamiliar to most R users. Here, we provide an overview of working with daily climate model output data in R. We then present the *futureheatwaves* package, which we developed to ease the process of identifying, characterizing, and exploring multi-day extreme events in climate model output. This package can input a directory of climate model output files, identify all extreme events using customizable event definitions, and summarize the output using user-specified functions.</p>
</div>
</a>
<a href="articles/RJ-2017-033/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 8, 2017</div>
<div class="dt-authors">
<div class="dt-author">Mingli Chen</div>
<div class="dt-author">Victor Chernozhukov</div>
<div class="dt-author">Ivn Fernndez-Val</div>
<div class="dt-author">Blaise Melly</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Counterfactual: An R Package for Counterfactual Analysis</h2>
<div class="dt-tags"></div>
<p>The *Counterfactual* package implements the estimation and inference methods of @ChernozhukovFernandez-ValMelly2013 for counterfactual analysis. The counterfactual distributions considered are the result of changing either the marginal distribution of covariates related to the outcome variable of interest, or the conditional distribution of the outcome given the covariates. They can be applied to estimate quantile treatment effects and wage decompositions. This paper serves as an introduction to the package and displays basic functionality of the commands contained within.</p>
</div>
</a>
<a href="articles/RJ-2017-029/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 18, 2017</div>
<div class="dt-authors">
<div class="dt-author">Adrien Mazoyer</div>
<div class="dt-author">Rmy Drouilhet</div>
<div class="dt-author">Stphane Despraux</div>
<div class="dt-author">Bernard Ycart</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>flan: An R Package for Inference on Mutation Models.</h2>
<div class="dt-tags"></div>
<p>This paper describes *flan*, a package providing tools for fluctuation analysis of mutant cell counts. It includes functions dedicated to the distribution of final numbers of mutant cells. Parametric estimation and hypothesis testing are also implemented, enabling inference on different sorts of data with several possible methods. An overview of the subject is proposed. The general form of mutation models is described, including the classical models as particular cases. Estimating from a model, when the data have been generated by another, induces different possible biases, which are identified and discussed. The three estimation methods available in the package are described, and their mean squared errors are compared. Finally, implementation is discussed, and a few examples of usage on real data sets are given.</p>
</div>
</a>
<a href="articles/RJ-2017-028/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 12, 2017</div>
<div class="dt-authors">
<div class="dt-author">MichelLang</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>checkmate: Fast Argument Checks for Defensive R Programming</h2>
<div class="dt-tags"></div>
<p>Dynamically typed programming languages like R allow programmers to write generic, flexible and concise code and to interact with the language using an interactive Read-eval-print-loop (REPL). However, this flexibility has its price: As the R interpreter has no information about the expected variable type, many base functions automatically convert the input instead of raising an exception. Unfortunately, this frequently leads to runtime errors deeper down the call stack which obfuscates the original problem and renders debugging challenging. Even worse, unwanted conversions can remain undetected and skew or invalidate the results of a statistical analysis. As a resort, assertions can be employed to detect unexpected input during runtime and to signal understandable and traceable errors. The package *checkmate* provides a plethora of functions to check the type and related properties of the most frequently used R objects and variable types. The package is mostly written in C to avoid any unnecessary performance overhead. Thus, the programmer can conveniently write concise, well-tested assertions which outperforms custom R code for many applications. Furthermore, *checkmate* simplifies writing unit tests using the framework*testthat*[@wickham_2011] by extending it with plenty of additional expectation functions, and registered C routines are available for package developers to perform assertions on arbitrary SEXPs (internal data structure for R objects implemented as struct in C) in compiled code.</p>
</div>
</a>
<a href="articles/RJ-2017-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Taylor Arnold</div>
<div class="dt-author">Michael J. Kane</div>
<div class="dt-author">Simon Urbanek</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>iotools: High-Performance I/O Tools for R</h2>
<div class="dt-tags"></div>
<p>The *iotools* package provides a set of tools for input and output intensive data processing in R. The functions `chunk.apply` and `read.chunk` are supplied to allow for iteratively loading contiguous blocks of data into memory as raw vectors. These raw vectors can then be efficiently converted into matrices and data frames with the *iotools* functions `mstrsplit` and `dstrsplit`. These functions minimize copying of data and avoid the use of intermediate strings in order to drastically improve performance. Finally, we also provide `read.csv.raw` to allow users to read an entire dataset into memory with the same efficient parsing code. In this paper, we present these functions through a set of examples with an emphasis on the flexibility provided by chunk-wise operations. We provide benchmarks comparing the speed of `read.csv.raw` to data loading functions provided in base Rand other contributed packages.</p>
</div>
</a>
<a href="articles/RJ-2017-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Martin Otava</div>
<div class="dt-author">Rudradev Sengupta</div>
<div class="dt-author">Ziv Shkedy</div>
<div class="dt-author">Dan Lin</div>
<div class="dt-author">Setia Pramana</div>
<div class="dt-author">Tobias Verbeke</div>
<div class="dt-author">Philippe Haldermans</div>
<div class="dt-author">Ludwig A. Hothorn</div>
<div class="dt-author">Daniel Gerhard</div>
<div class="dt-author">Rebecca M. Kuiper</div>
<div class="dt-author">Florian Klinglmueller</div>
<div class="dt-author">Adetayo Kasim</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>IsoGeneGUI: Multiple Approaches for Dose-Response Analysis of Microarray Data Using R</h2>
<div class="dt-tags"></div>
<p>The analysis of transcriptomic experiments with ordered covariates, such as dose-response data, has become a central topic in bioinformatics, in particular in omics studies. Consequently, multiple R packages on CRAN and Bioconductor are designed to analyse microarray data from various perspectives under the assumption of order restriction. We introduce the new R package IsoGene Graphical User Interface (*IsoGeneGUI*), an extension of the original *IsoGene* package that includes methods from most of available R packages designed for the analysis of order restricted microarray data, namely *orQA*, *ORIClust*, *goric* and *ORCME*. The methods included in the new *IsoGeneGUI* range from inference and estimation to model selection and clustering tools. The *IsoGeneGUI* is not only the most complete tool for the analysis of order restricted microarray experiments available in R but also it can be used to analyse other types of dose-response data. The package provides all the methods in a user friendly fashion, so analyses can be implemented by users with limited knowledge of R programming.</p>
</div>
</a>
<a href="articles/RJ-2017-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Mark Pickup</div>
<div class="dt-author">Paul Gustafson</div>
<div class="dt-author">Davor Cubranic</div>
<div class="dt-author">Geoffrey Evans</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>OrthoPanels: An R Package for Estimating a Dynamic Panel Model with Fixed Effects Using the Orthogonal Reparameterization Approach</h2>
<div class="dt-tags"></div>
<p>This article describes the R package *OrthoPanels*, which includes the function `opm()`. This function implements the orthogonal reparameterization approach recommended by [@Lancaster2002] to estimate dynamic panel models with fixed effects (and optionally: wave specific intercepts). This article provides a statistical description of the orthogonal reparameterization approach, a demonstration of the package using real-world data, and simulations comparing the estimator to the known-to-be-biased OLS estimator and the commonly used GMM estimator.</p>
</div>
</a>
<a href="articles/RJ-2017-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Jakob Bossek</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>smoof: Single- and Multi-Objective Optimization Test Functions</h2>
<div class="dt-tags"></div>
<p>Benchmarking algorithms for optimization problems usually is carried out by running the algorithms under consideration on a diverse set of benchmark or test functions. A vast variety of test functions was proposed by researchers and is being used for investigations in the literature. The *smoof* package implements a large set of test functions and test function generators for both the single- and multi-objective case in continuous optimization and provides functions to easily create own test functions. Moreover, the package offers some additional helper methods, which can be used in the context of optimization.</p>
</div>
</a>
<a href="articles/RJ-2017-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Sean S. Downey</div>
<div class="dt-author">Guowei Sun</div>
<div class="dt-author">Peter Norquest</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>alineR: an R Package for Optimizing Feature-Weighted Alignments and Linguistic Distances</h2>
<div class="dt-tags"></div>
<p>Linguistic distance measurements are commonly used in anthropology and biology when quantitative and statistical comparisons between words are needed. This is common, for example, when analyzing linguistic and genetic data. Such comparisons can provide insight into historical population patterns and evolutionary processes. However, the most commonly used linguistic distances are derived from edit distances, which do not weight phonetic features that may, for example, represent smaller-scale patterns in linguistic evolution. Thus, computational methods for calculating feature-weighted linguistic distances are needed for linguistic, biological, and evolutionary applications; additionally, the linguistic distances presented here are generic and may have broader applications in fields such as text mining and search, as well as applications in psycholinguistics and morphology. To facilitate this research, we are making available an open-source R software package that performs feature-weighted linguistic distance calculations. The package also includes a supervised learning methodology that uses a genetic algorithm and manually determined alignments to estimate 13 linguistic parameters including feature weights and a skip penalty. Here we present the package and use it to demonstrate the supervised learning methodology by estimating the optimal linguistic parameters for both simulated data and for a sample of Austronesian languages. Our results show that the methodology can estimate these parameters for both simulated and real language data, that optimizing feature weights improves alignment accuracy by approximately 29%, and that optimization significantly affects the resulting distance measurements. Availability: alineR is available on CRAN.</p>
</div>
</a>
<a href="articles/RJ-2017-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Jim Duggan</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Implementing a Metapopulation Bass Diffusion Model using the R Package deSolve</h2>
<div class="dt-tags"></div>
<p>Diffusion is a fundamental process in physical, biological, social and economic settings. Consumer products often go viral, with sales driven by the word of mouth effect, as their adoption spreads through a population. The classic diffusion model used for product adoption is the Bass diffusion model, and this divides a population into two groups of people: potential adopters who are likely to adopt a product, and adopters who have purchased the product, and influence others to adopt. The Bass diffusion model is normally captured in an aggregate form, where no significant consumer differences are modeled. This paper extends the Bass model to capture a spatial perspective, using metapopulation equations from the field of infectious disease modeling. The paper's focus is on simulation of deterministic models by solving ordinary differential equations, and does not encompass parameter estimation. The metapopulation model in implemented in R using the *deSolve* package, and shows the potential of using the R framework to implement large-scale integral equation models, with applications in the field of marketing and consumer behaviour.</p>
</div>
</a>
<a href="articles/RJ-2017-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Christian Margreitter</div>
<div class="dt-author">Chris Oostenbrink</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>MDplot: Visualise Molecular Dynamics</h2>
<div class="dt-tags"></div>
<p>The *MDplot* package provides plotting functions to allow for automated visualisation of molecular dynamics simulation output. It is especially useful in cases where the plot generation is rather tedious due to complex file formats or when a large number of plots are generated. The graphs that are supported range from those which are standard, such as RMSD/RMSF (root-mean-square deviation and root-mean-square fluctuation, respectively) to less standard, such as thermodynamic integration analysis and hydrogen bond monitoring over time. All told, they address many commonly used analyses. In this article, we set out the *MDplot* package's functions, give examples of the function calls, and show the associated plots. Plotting and data parsing is separated in all cases, i.e.the respective functions can be used independently. Thus, data manipulation and the integration of additional file formats is fairly easy. Currently, the loading functions support GROMOS, GROMACS, and AMBER file formats. Moreover, we also provide a Bash interface that allows simple embedding of MDplot into Bash scripts as the final analysis step.</p>
</div>
</a>
<a href="articles/RJ-2017-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Luca Scrucca</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>On Some Extensions to GA Package: Hybrid Optimisation, Parallelisation and Islands Evolution</h2>
<div class="dt-tags"></div>
<p>Genetic algorithms are stochastic iterative algorithms in which a population of individuals evolve by emulating the process of biological evolution and natural selection. The Rpackage *GA* provides a collection of general purpose functions for optimisation using genetic algorithms. This paper describes some enhancements recently introduced in version 3 of the package. In particular, hybrid GAs have been implemented by including the option to perform local searches during the evolution. This allows to combine the power of genetic algorithms with the speed of a local optimiser. Another major improvement is the provision of facilities for parallel computing. Parallelisation has been implemented using both the master-slave approach and the islands evolution model. Several examples of usage are presented, with both real-world data examples and benchmark functions, showing that often high-quality solutions can be obtained more efficiently.</p>
</div>
</a>
<a href="articles/RJ-2017-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Steffen Moritz</div>
<div class="dt-author">Thomas Bartz-Beielstein</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>imputeTS: Time Series Missing Value Imputation in R</h2>
<div class="dt-tags"></div>
<p>The *imputeTS* package specializes on univariate time series imputation. It offers multiple state-of-the-art imputation algorithm implementations along with plotting functions for time series missing data statistics. While imputation in general is a well-known problem and widely covered by R packages, finding packages able to fill missing values in univariate time series is more complicated. The reason for this lies in the fact, that most imputation algorithms rely on inter-attribute correlations, while univariate time series imputation instead needs to employ time dependencies. This paper provides an introduction to the *imputeTS* package and its provided algorithms and tools. Furthermore, it gives a short overview about univariate time series imputation in R.</p>
</div>
</a>
<a href="articles/RJ-2017-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">S.H. Heisterkamp</div>
<div class="dt-author">E. van Willigen</div>
<div class="dt-author">P.M Diderichsen</div>
<div class="dt-author">J. Maringwa</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Update of the nlme Package to Allow a Fixed Standard Deviation of the Residual Error</h2>
<div class="dt-tags"></div>
<p>The use of linear and non-linear mixed models in the life sciences and pharmacometrics is common practice. Estimation of the parameters of models not involving a system of differential equations is often done by the R or S-Plus software with the nonlinear mixed effects *nlme* package. The estimated residual error may be used for diagnosis of the fitted model, but not whether the model correctly describes the relation between response and included variables including the true covariance structure. The latter is only true if the residual error is known in advance. Therefore, it may be necessary or more appropriate to fix the residual error a priori instead of estimate its value. This can be the case if one wants to include evidence from past studies or a theoretical derivation; e.g., when using a binomial model. S-Plus has an option to fix this residual error to a constant, in contrast to R. For convenience, the *nlme* package was customized to offer this option as well. In this paper, we derived the log-likelihoods for the mixed models using a fixed residual error. By using some well-known examples from mixed models, we demonstrated the equivalence of R and S-Plus with respect to the estimates. The updated package has been accepted by the Comprehensive R Archive Network (CRAN) team and will be available at the CRAN website.</p>
</div>
</a>
<a href="articles/RJ-2017-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Hye-Min Choe</div>
<div class="dt-author">Mijeong Kim</div>
<div class="dt-author">Eun-Kyung Lee</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>EMSaov: An R Package for the Analysis of Variance with the Expected Mean Squares and its Shiny Application</h2>
<div class="dt-tags"></div>
<p>*EMSaov* is a new R package that we developed to provide users with an analysis of variance table including the expected mean squares (EMS) for various types of experimental design. It is not easy to find the appropriate test, particularly the denominator for the F statistic that depends on the EMS, when some variables exhibit random effects or when we use a special experimental design such as nested design, repeated measures design, or split-plot design. With *EMSaov*, a user can easily find the F statistic denominator and can determine how to analyze the data when using a special experimental design. We also develop a web application with a GUI interface using the *shiny* package in `R` . We expect that our application can contribute to the efficient and easy analysis of experimental data.</p>
</div>
</a>
<a href="articles/RJ-2017-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Philipp Probst</div>
<div class="dt-author">Quay Au</div>
<div class="dt-author">Giuseppe Casalicchio</div>
<div class="dt-author">Clemens Stachl</div>
<div class="dt-author">Bernd Bischl</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Multilabel Classification with R Package mlr</h2>
<div class="dt-tags"></div>
<p>We implemented several multilabel classification algorithms in the machine learning package mlr. The implemented methods are binary relevance, classifier chains, nested stacking, dependent binary relevance and stacking, which can be used with any base learner that is accessible in mlr. Moreover, there is access to the multilabel classification versions of randomForestSRC and rFerns. All these methods can be easily compared by different implemented multilabel performance measures and resampling methods in the standardized mlr framework. In a benchmark experiment with several multilabel datasets, the performance of the different methods is evaluated.</p>
</div>
</a>
<a href="articles/RJ-2017-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Ping-Yang Chen</div>
<div class="dt-author">Ching-Chuan Chen</div>
<div class="dt-author">Chun-Hao Yang</div>
<div class="dt-author">Sheng-Mao Chang</div>
<div class="dt-author">Kuo-Jung Lee</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>milr: Multiple-Instance Logistic Regression with Lasso Penalty</h2>
<div class="dt-tags"></div>
<p>The purpose of the *milr* package is to analyze multiple-instance data. Ordinary multiple-instance data consists of many independent bags, and each bag is composed of several instances. The statuses of bags and instances are binary. Moreover, the statuses of instances are not observed, whereas the statuses of bags are observed. The functions in this package are applicable for analyzing multiple-instance data, simulating data via logistic regression, and selecting important covariates in the regression model. To this end, maximum likelihood estimation with an expectation-maximization algorithm is implemented for model estimation, and a lasso penalty added to the likelihood function is applied for variable selection. Additionally, an `"milr"` object is applicable to generic functions `fitted`, `predict` and `summary`. Simulated data and a real example are given to demonstrate the features of this package.</p>
</div>
</a>
<a href="articles/RJ-2017-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Axel Gandy</div>
<div class="dt-author">Jan Terje Kvaly</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>spcadjust: An R Package for Adjusting for Estimation Error in Control Charts</h2>
<div class="dt-tags"></div>
<p>In practical applications of control charts the in-control state and the corresponding chart parameters are usually estimated based on some past in-control data. The estimation error then needs to be accounted for. In this paper we present an R package, *spcadjust*, which implements a bootstrap based method for adjusting monitoring schemes to take into account the estimation error. By bootstrapping the past data this method guarantees, with a certain probability, a conditional performance of the chart. In *spcadjust* the method is implement for various types of Shewhart, CUSUM and EWMA charts, various performance criteria, and both parametric and non-parametric bootstrap schemes. In addition to the basic charts, charts based on linear and logistic regression models for risk adjusted monitoring are included, and it is easy for the user to add further charts. Use of the package is demonstrated by examples.</p>
</div>
</a>
<a href="articles/RJ-2017-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Mnica Lpez-Ratn</div>
<div class="dt-author">Elisa M. Molanes-Lpez</div>
<div class="dt-author">Emilio Letn</div>
<div class="dt-author">Carmen Cadarso-Surez</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>GsymPoint: An R Package to Estimate the Generalized Symmetry Point, an Optimal Cut-off Point for Binary Classification in Continuous Diagnostic Tests</h2>
<div class="dt-tags"></div>
<p>In clinical practice, it is very useful to select an optimal cutpoint in the scale of a continuous biomarker or diagnostic test for classifying individuals as healthy or diseased. Several methods for choosing optimal cutpoints have been presented in the literature, depending on the ultimate goal. One of these methods, the generalized symmetry point, recently introduced, generalizes the symmetry point by incorporating the misclassification costs. Two statistical approaches have been proposed in the literature for estimating this optimal cutpoint and its associated sensitivity and specificity measures, a parametric method based on the generalized pivotal quantity and a nonparametric method based on empirical likelihood. In this paper, we introduce [*GsymPoint*](https://CRAN.R-project.org/package=GsymPoint), an R package that implements these methods in a user-friendly environment, allowing the end-user to calculate the generalized symmetry point depending on the levels of certain categorical covariates. The practical use of this package is illustrated using three real biomedical datasets.</p>
</div>
</a>
<a href="articles/RJ-2017-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Brandon M. Greenwell</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>pdp: An R Package for Constructing Partial Dependence Plots</h2>
<div class="dt-tags"></div>
<p>Complex nonparametric models---like neural networks, random forests, and support vector machines---are more common than ever in predictive analytics, especially when dealing with large observational databases that don't adhere to the strict assumptions imposed by traditional statistical techniques (e.g., multiple linear regression which assumes linearity, homoscedasticity, and normality). Unfortunately, it can be challenging to understand the results of such models and explain them to management. Partial dependence plots offer a simple solution. Partial dependence plots are low-dimensional graphical renderings of the prediction function so that the relationship between the outcome and predictors of interest can be more easily understood. These plots are especially useful in explaining the output from black box models. In this paper, we introduce *pdp*, a general R package for constructing partial dependence plots.</p>
</div>
</a>
<a href="articles/RJ-2017-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Rense Nieuwenhuis</div>
<div class="dt-author">Manfred te Grotenhuis</div>
<div class="dt-author">Ben Pelzer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Weighted Effect Coding for Observational Data with wec</h2>
<div class="dt-tags"></div>
<p>Weighted effect coding refers to a specific coding matrix to include factor variables in generalised linear regression models. With weighted effect coding, the effect for each category represents the deviation of that category from the weighted mean (which corresponds to the sample mean). This technique has particularly attractive properties when analysing observational data, that commonly are unbalanced. The *wec* package is introduced, that provides functions to apply weighted effect coding to factor variables, and to interactions between (a.) a factor variable and a continuous variable and between (b.) two factor variables.</p>
</div>
</a>
<a href="articles/RJ-2017-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Razieh Nabi</div>
<div class="dt-author">Xiaogang Su</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>coxphMIC: An R Package for Sparse Estimation of Cox Proportional Hazards Models via Approximated Information Criteria</h2>
<div class="dt-tags"></div>
<p>In this paper, we describe an R package named **coxphMIC**, which implements the sparse estimation method for Cox proportional hazards models via approximated information criterion [@Su:2016]. The developed methodology is named MIC which stands for "Minimizing approximated Information Criteria\". A reparameterization step is introduced to enforce sparsity while at the same time keeping the objective function smooth. As a result, MIC is computationally fast with a superior performance in sparse estimation. Furthermore, the reparameterization tactic yields an additional advantage in terms of circumventing post-selection inference [@Leeb:2005]. The MIC method and its R implementation are introduced and illustrated with the PBC data.</p>
</div>
</a>
<a href="articles/RJ-2017-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Leo Lahti</div>
<div class="dt-author">Janne Huovari</div>
<div class="dt-author">Markus Kainu</div>
<div class="dt-author">Przemysaw Biecek</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Retrieval and Analysis of Eurostat Open Data with the eurostat Package</h2>
<div class="dt-tags"></div>
<p>The increasing availability of open statistical data resources is providing novel opportunities for research and citizen science. Efficient algorithmic tools are needed to realize the full potential of the new information resources. We introduce the *eurostat* R package that provides a collection of custom tools for the Eurostat open data service, including functions to query, download, manipulate, and visualize these data sets in a smooth, automated and reproducible manner. The online documentation provides detailed examples on the analysis of these spatio-temporal data collections. This work provides substantial improvements over the previously available tools, and has been extensively tested by an active user community. The *eurostat* R package contributes to the growing open source ecosystem dedicated to reproducible research in computational social science and digital humanities.</p>
</div>
</a>
<a href="articles/RJ-2017-020/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Thomas Wieland</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Market Area Analysis for Retail and Service Locations with MCI</h2>
<div class="dt-tags"></div>
<p>In retail location analysis, marketing research and spatial planning, the market areas of stores and/or locations are a frequent subject. Market area analyses consist of empirical observations and modeling via theoretical and/or econometric models such as the Huff Model or the Multiplicative Competitive Interaction Model. The authors' package MCI implements the steps of market area analysis into R with a focus on fitting the models and data preparation and processing.</p>
</div>
</a>
<a href="articles/RJ-2017-021/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Neeraj Bokde</div>
<div class="dt-author">Gualberto Asencio-Corts</div>
<div class="dt-author">Francisco Martnez-lvarez</div>
<div class="dt-author">Kishore Kulat</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>PSF: Introduction to R Package for Pattern Sequence Based Forecasting Algorithm</h2>
<div class="dt-tags"></div>
<p>This paper introduces the R package that implements the Pattern Sequence based Forecasting (PSF) algorithm, which was developed for univariate time series forecasting. This algorithm has been successfully applied to many different fields. The PSF algorithm consists of two major parts: clustering and prediction. The clustering part includes selection of the optimum number of clusters. It labels time series data with reference to such clusters. The prediction part includes functions like optimum window size selection for specific patterns and prediction of future values with reference to past pattern sequences. The PSF package consists of various functions to implement the PSF algorithm. It also contains a function which automates all other functions to obtain optimized prediction results. The aim of this package is to promote the PSF algorithm and to ease its usage with minimum efforts. This paper describes all the functions in the PSF package with their syntax. It also provides a simple example. Finally, the usefulness of this package is discussed by comparing it to `auto.arima` and `ets`, well-known time series forecasting functions available on CRAN repository.</p>
</div>
</a>
<a href="articles/RJ-2017-022/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Panagiotis Papastamoulis</div>
<div class="dt-author">Magnus Rattray</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>BayesBinMix: an R Package for Model Based Clustering of Multivariate Binary Data</h2>
<div class="dt-tags"></div>
<p>The *BayesBinMix* package offers a Bayesian framework for clustering binary data with or without missing values by fitting mixtures of multivariate Bernoulli distributions with an unknown number of components. It allows the joint estimation of the number of clusters and model parameters using Markov chain Monte Carlo sampling. Heated chains are run in parallel and accelerate the convergence to the target posterior distribution. Identifiability issues are addressed by implementing label switching algorithms. The package is demonstrated and benchmarked against the Expectation-Maximization algorithm using a simulation study as well as a real dataset.</p>
</div>
</a>
<a href="articles/RJ-2017-023/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Samantha Tyner</div>
<div class="dt-author">Franois Briatte</div>
<div class="dt-author">Heike Hofmann</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Network Visualization with ggplot2</h2>
<div class="dt-tags"></div>
<p>This paper explores three different approaches to visualize networks by building on the grammar of graphics framework implemented in the *ggplot2* package. The goal of each approach is to provide the user with the ability to apply the flexibility of *ggplot2* to the visualization of network data, including through the mapping of network attributes to specific plot aesthetics. By incorporating networks in the *ggplot2* framework, these approaches (1) allow users to enhance networks with additional information on edges and nodes, (2) give access to the strengths of *ggplot2*, such as layers and facets, and (3) convert network data objects to the more familiar data frames.</p>
</div>
</a>
<a href="articles/RJ-2017-024/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Randall Pruim</div>
<div class="dt-author">Daniel T Kaplan</div>
<div class="dt-author">Nicholas J Horton</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The mosaic Package: Helping Students to 'Think with Data' Using R</h2>
<div class="dt-tags"></div>
<p>The mosaic package provides a simplified and systematic introduction to the core functionality related to descriptive statistics, visualization, modeling, and simulation-based inference required in first and second courses in statistics. This introduction to the package describes some of the guiding principles behind the design of the package and provides illustrative examples of several of the most important functions it implements. These can be combined to help students "think with data\" using R in their early course work, starting with simple, yet powerful, declarative commands.</p>
</div>
</a>
<a href="articles/RJ-2017-025/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Joshua P. French</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>autoimage: Multiple Heat Maps for Projected Coordinates</h2>
<div class="dt-tags"></div>
<p>Heat maps are commonly used to display the spatial distribution of a response observed on a two-dimensional grid. The *autoimage* package provides convenient functions for constructing multiple heat maps in unified, seamless way, particularly when working with projected coordinates. The *autoimage* package natively supports: 1. automatic inclusion of a color scale with the plotted image, 2. construction of heat maps for responses observed on regular or irregular grids, as well as non-gridded data, 3. construction of a matrix of heat maps with a common color scale, 4. construction of a matrix of heat maps with individual color scales, 5. projecting coordinates before plotting, 6. easily adding geographic borders, points, and other features to the heat maps. After comparing the *autoimage* package's capabilities for constructing heat maps to those of existing tools, a carefully selected set of examples is used to highlight the capabilities of the *autoimage* package.</p>
</div>
</a>
<a href="articles/RJ-2017-026/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">G. Brooke Anderson</div>
<div class="dt-author">Dirk Eddelbuettel</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Hosting Data Packages via drat: A Case Study with Hurricane Exposure Data</h2>
<div class="dt-tags"></div>
<p>Data-only packages offer a way to provide extended functionality for other R users. However, such packages can be large enough to exceed the package size limit (5 megabytes) for the Comprehensive R Archive Network (CRAN). As an alternative, large data packages can be posted to additional repostiories beyond CRAN itself in a way that allows smaller code packages on CRAN to access and use the data. The *drat* package facilitates creation and use of such alternative repositories and makes it particularly simple to host them via GitHub. CRAN packages can draw on packages posted to *drat* repositories through the use of the 'Additonal_repositories' field in the DESCRIPTION file. This paper describes how R users can create a suite of coordinated packages, in which larger data packages are hosted in an alternative repository created with *drat*, while a smaller code package that interacts with this data is created that can be submitted to CRAN.</p>
</div>
</a>
<a href="articles/RJ-2017-027/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 10, 2017</div>
<div class="dt-authors">
<div class="dt-author">Pablo Morales</div>
<div class="dt-author">Julin Luengo</div>
<div class="dt-author">Lus P.F. Garcia</div>
<div class="dt-author">Ana C. Lorena</div>
<div class="dt-author">Andr C.P.L.F. de Carvalho</div>
<div class="dt-author">Francisco Herrera</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The NoiseFiltersR Package: Label Noise Preprocessing in R</h2>
<div class="dt-tags"></div>
<p>In Data Mining, the value of extracted knowledge is directly related to the quality of the used data. This makes data preprocessing one of the most important steps in the knowledge discovery process. A common problem affecting data quality is the presence of noise. A training set with label noise can reduce the predictive performance of classification learning techniques and increase the overfitting of classification models. In this work we present the *NoiseFiltersR* package. It contains the first extensive R implementation of classical and state-of-the-art label noise filters, which are the most common techniques for preprocessing label noise. The algorithms used for the implementation of the label noise filters are appropriately documented and referenced. They can be called in a R-user-friendly manner, and their results are unified by means of the `"filter"` class, which also benefits from adapted `print` and `summary` methods.</p>
</div>
</a>
<a href="articles/RJ-2016-036/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 3, 2017</div>
<div class="dt-authors">
<div class="dt-author">Claudia Vitolo</div>
<div class="dt-author">Matthew Fry</div>
<div class="dt-author">Wouter Buytaert</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>rnrfa: An R package to Retrieve, Filter and Visualize Data from the UK National River Flow Archive</h2>
<div class="dt-tags"></div>
<p>The UK National River Flow Archive (NRFA) stores several types of hydrological data and metadata: daily river flow and catchment rainfall time series, gauging station and catchment information. Data are served through the NRFA web services via experimental RESTful APIs. Obtaining NRFA data can be unwieldy due to complexities in handling HTTP GET requests and parsing responses in JSON and XML formats. The *rnrfa* package provides a set of functions to programmatically access, filter, and visualize NRFA data using simple R syntax. This paper describes the structure of the *rnrfa* package, including examples using the main functions `gdf()` and `cmr()` for flow and rainfall data, respectively. Visualization examples are also provided with a *shiny* web application and functions provided in the package. Although this package is regional specific, the general framework and structure could be applied to similar databases.</p>
</div>
</a>
<a href="articles/RJ-2016-041/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 3, 2017</div>
<div class="dt-authors">
<div class="dt-author">Derek S. Young</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Normal Tolerance Interval Procedures in the *tolerance* Package</h2>
<div class="dt-tags"></div>
<p>Statistical tolerance intervals are used for a broad range of applications, such as quality control, engineering design tests, environmental monitoring, and bioequivalence testing. *tolerance* is the only R package devoted to procedures for tolerance intervals and regions. Perhaps the most commonly-employed functions of the package involve normal tolerance intervals. A number of new procedures for this setting have been included in recent versions of *tolerance*. In this paper, we discuss and illustrate the functions that implement these normal tolerance interval procedures, one of which is a new, novel type of operating characteristic curve.</p>
</div>
</a>
<a href="articles/RJ-2016-054/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 3, 2017</div>
<div class="dt-authors">
<div class="dt-author">Patrick Roocks</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Computing Pareto Frontiers and Database Preferences with the rPref Package</h2>
<div class="dt-tags"></div>
<p>The concept of Pareto frontiers is well-known in economics. Within the database community there exist many different solutions for the specification and calculation of Pareto frontiers, also called Skyline queries in the database context. Slight generalizations like the combination of the Pareto operator with the lexicographical order have been established under the term database preferences. In this paper we present the *rPref* package which allows to efficiently deal with these concepts within R. With its help, database preferences can be specified in a very similar way as in a state-of-the-art database management system. Our package provides algorithms for an efficient calculation of the Pareto-optimal set and further functionalities for visualizing and analyzing the induced preference order.</p>
</div>
</a>
<a href="articles/RJ-2016-057/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 3, 2017</div>
<div class="dt-authors">
<div class="dt-author">Itziar Irigoien</div>
<div class="dt-author">Francesc Mestres</div>
<div class="dt-author">Concepcion Arenas</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Weighted Distance Based Discriminant Analysis: The R Package WeDiBaDis</h2>
<div class="dt-tags"></div>
<p>The *WeDiBaDis* package provides a user friendly environment to perform discriminant analysis (supervised classification). *WeDiBaDis* is an easy to use package addressed to the biological and medical communities, and in general, to researchers interested in applied studies. It can be suitable when the user is interested in the problem of constructing a discriminant rule on the basis of distances between a relatively small number of instances or units of known unbalanced-class membership measured on many (possibly thousands) features of any type. This is a current situation when analyzing genetic biomedical data. This discriminant rule can then be used both, as a means of explaining differences among classes, but also in the important task of assigning the class membership for new unlabeled units. Our package implements two discriminant analysis procedures in an R environment: the well-known distance-based discriminant analysis (DB-discriminant) and a weighted-distance-based discriminant (WDB-discriminant), a novel classifier rule that we introduce. This new procedure is based on an improvement of the DB rule taking into account the statistical depth of the units. This article presents both classifying procedures and describes the implementation of each in detail. We illustrate the use of the package using an ecological and a genetic experimental example. Finally, we illustrate the effectiveness of the new proposed procedure (WDB), as compared with DB. This comparison is carried out using thirty-eight, high-dimensional, class-unbalanced, cancer data sets, three of which include clinical features.</p>
</div>
</a>
<a href="articles/RJ-2016-059/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 3, 2017</div>
<div class="dt-authors">
<div class="dt-author">Luis Meira-Machado</div>
<div class="dt-author">Marta Sestelo</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>condSURV: An R Package for the Estimation of the Conditional Survival Function for Ordered Multivariate Failure Time Data</h2>
<div class="dt-tags"></div>
<p>One major goal in clinical applications of time-to-event data is the estimation of survival with censored data. The usual nonparametric estimator of the survival function is the time-honored Kaplan-Meier product-limit estimator. Though this estimator has been implemented in several R packages, the development of the *condSURV* R package has been motivated by recent contributions that allow the estimation of the survival function for ordered multivariate failure time data. The *condSURV* package provides three different approaches all based on the Kaplan-Meier estimator. In one of these approaches these quantities are estimated conditionally on current or past covariate measures. Illustration of the software usage is included using real data.</p>
</div>
</a>
<a href="articles/RJ-2016-042/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 23, 2016</div>
<div class="dt-authors">
<div class="dt-author">Dincer Goksuluk</div>
<div class="dt-author">Selcuk Korkmaz</div>
<div class="dt-author">Gokmen Zararsiz</div>
<div class="dt-author">A. Ergun Karaagaoglu</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>easyROC: An Interactive Web-tool for ROC Curve Analysis Using R Language Environment</h2>
<div class="dt-tags"></div>
<p>ROC curve analysis is a fundamental tool for evaluating the performance of a marker in a number of research areas, e.g., biomedicine, bioinformatics, engineering etc., and is frequently used for discriminating cases from controls. There are a number of analysis tools which are used to guide researchers through their analysis. Some of these tools are commercial and provide basic methods for ROC curve analysis while others offer advanced analysis techniques and a command-based user interface, such as the R environment. The R environmentg includes comprehensive tools for ROC curve analysis; however, using a command-based interface might be challenging and time consuming when a quick evaluation is desired; especially for non-R users, physicians etc. Hence, a quick, comprehensive, free and easy-to-use analysis tool is required. For this purpose, we developed a user-friendly web-tool based on the R language. This tool provides ROC statistics, graphical tools, optimal cutpoint calculation, comparison of several markers, and sample size estimation to support researchers in their decisions without writing R codes. easyROC can be used via any device with an internet connection independently of the operating system. The web interface of easyROC is constructed with the R package *shiny*. This tool is freely available through [www.biosoft.hacettepe.edu.tr/easyROC](http://www.biosoft.hacettepe.edu.tr/easyROC){.uri}.</p>
</div>
</a>
<a href="articles/RJ-2016-033/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 12, 2016</div>
<div class="dt-authors">
<div class="dt-author">Miguel R. Guevara</div>
<div class="dt-author">Dominik Hartmann</div>
<div class="dt-author">Marcelo Mendoza</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>diverse: an R Package to Analyze Diversity in Complex Systems</h2>
<div class="dt-tags"></div>
<p>The package *diverse* provides an easy-to-use interface to calculate and visualize different aspects of diversity in complex systems. In recent years, an increasing number of research projects in social and interdisciplinary sciences, including fields like innovation studies, scientometrics, economics, and network science have emphasized the role of diversification and sophistication of socioeconomic systems. However, so far no dedicated package exists that covers the needs of these emerging fields and interdisciplinary teams. Most packages about diversity tend to be created according to the demands and terminology of particular areas of natural and biological sciences. The package *diverse* uses interdisciplinary concepts of diversity---like variety, disparity and balance--- as well as ubiquity and revealed comparative advantages, that are relevant to many fields of science, but are in particular useful for interdisciplinary research on diversity in socioeconomic systems. The package *diverse* provides a toolkit for social scientists, interdisciplinary researcher, and beginners in ecology to (i) import data, (ii) calculate different data transformations and normalization like revealed comparative advantages, (iii) calculate different diversity measures, and (iv) connect *diverse* to other specialized R packages on similarity measures, data visualization techniques, and statistical significance tests. The comprehensiveness of the package, from matrix import and transformations options, over similarity and diversity measures, to data visualization methods, makes it a useful package to explore different dimensions of diversity in complex systems.</p>
</div>
</a>
<a href="articles/RJ-2016-037/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 12, 2016</div>
<div class="dt-authors">
<div class="dt-author">Marco Geraci</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Qtools: A Collection of Models and Tools for Quantile Inference</h2>
<div class="dt-tags"></div>
<p>Quantiles play a fundamental role in statistics. The quantile function defines the distribution of a random variable and, thus, provides a way to describe the data that is specular but equivalent to that given by the corresponding cumulative distribution function. There are many advantages in working with quantiles, starting from their properties. The renewed interest in their usage seen in the last years is due to the theoretical, methodological, and software contributions that have broadened their applicability. This paper presents the R package *Qtools*, a collection of utilities for unconditional and conditional quantiles.</p>
</div>
</a>
<a href="articles/RJ-2016-045/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 12, 2016</div>
<div class="dt-authors">
<div class="dt-author">Wanbitching E. Wansouw</div>
<div class="dt-author">Sobom M. Som</div>
<div class="dt-author">Clestin C. Kokonendji</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Ake: An R Package for Discrete and Continuous Associated Kernel Estimations</h2>
<div class="dt-tags"></div>
<p>Kernel estimation is an important technique in exploratory data analysis. Its utility relies on its ease of interpretation, especially based on graphical means. The *Ake* package is introduced for univariate density or probability mass function estimation and also for continuous and discrete regression functions using associated kernel estimators. These associated kernels have been proposed due to their specific features of variables of interest. The package focuses on associated kernel methods appropriate for continuous (bounded, positive) or discrete (count, categorical) data often found in applied settings. Furthermore, optimal bandwidths are selected by cross-validation for any associated kernel and by Bayesian methods for the binomial kernel. Other Bayesian methods for selecting bandwidths with other associated kernels will complete this package in its future versions; particularly, a Bayesian adaptive method for gamma kernel estimation of density functions is developed. Some practical and theoretical aspects of the normalizing constant in both density and probability mass functions estimations are given.</p>
</div>
</a>
<a href="articles/RJ-2016-051/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 12, 2016</div>
<div class="dt-authors">
<div class="dt-author">Guillermo Federico Olmedo</div>
<div class="dt-author">Samuel Ortega-Faras</div>
<div class="dt-author">Daniel de la Fuente-Siz</div>
<div class="dt-author">David Fonseca-Luengo</div>
<div class="dt-author">Fernando Fuentes-Peailillo</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>water: Tools and Functions to Estimate Actual Evapotranspiration Using Land Surface Energy Balance Models in R</h2>
<div class="dt-tags"></div>
<p>The crop water requirement is a key factor in the agricultural process. It is usually estimated throughout actual evapotranspiration ($ET_a$). This parameter is the key to develop irrigation strategies, to improve water use efficiency and to understand hydrological, climatic, and ecosystem processes. Currently, it is calculated with classical methods, which are difficult to extrapolate, or with land surface energy balance models (LSEB), such as METRIC and SEBAL, which are based on remote sensing data. This paper describes *water*, an open implementation of LSEB. The package provides several functions to estimate the parameters of the LSEB equation from satellite data and proposes a new object class to handle weather station data. One of the critical steps in METRIC is the selection of "cold" and "hot" pixels, which *water* solves with an automatic method. The *water* package can process a batch of satellite images and integrates most of the already published sub-models for METRIC. Although *water* implements METRIC, it will be expandable to SEBAL and others in the near future. Finally, two different procedures are demonstrated using data that is included in *water* package.</p>
</div>
</a>
<a href="articles/RJ-2016-061/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 12, 2016</div>
<div class="dt-authors">
<div class="dt-author">Edzer Pebesma</div>
<div class="dt-author">Thomas Mailund</div>
<div class="dt-author">James Hiebert</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Measurement Units in R</h2>
<div class="dt-tags"></div>
<p>We briefly review SI units, and discuss R packages that deal with measurement units, their compatibility and conversion. Built upon *udunits2* and the UNIDATA udunits library, we introduce the package *units* that provides a class for maintaining unit metadata. When used in expression, it automatically converts units, and simplifies units of results when possible; in case of incompatible units, errors are raised. The class flexibly allows expansion beyond predefined units. Using *units* may eliminate a whole class of potential scientific programming mistakes. We discuss the potential and limitations of computing with explicit units.</p>
</div>
</a>
<a href="articles/RJ-2016-062/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 12, 2016</div>
<div class="dt-authors">
<div class="dt-author">Muhammad Imdadullah</div>
<div class="dt-author">Muhammad Aslam</div>
<div class="dt-author">Saima Altaf</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>mctest: An R Package for Detection of Collinearity among Regressors</h2>
<div class="dt-tags"></div>
<p>It is common for linear regression models to be plagued with the problem of multicollinearity when two or more regressors are highly correlated. This problem results in unstable estimates of regression coefficients and causes some serious problems in validation and interpretation of the model. Different diagnostic measures are used to detect multicollinearity among regressors. Many statistical software and R packages provide few diagnostic measures for the judgment of multicollinearity. Most widely used diagnostic measures in these software are: coefficient of determination ($R^2$), variance inflation factor/tolerance limit (VIF/TOL), eigenvalues, condition number (CN) and condition index (CI) etc.In this manuscript, we present an R package, *mctest*, that computes popular and widely used multicollinearity diagnostic measures. The package also indicates which regressors may be the reason of collinearity among regressors.</p>
</div>
</a>
<a href="articles/RJ-2016-044/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 21, 2016</div>
<div class="dt-authors">
<div class="dt-author">Barret Schloerke</div>
<div class="dt-author">Hadley Wickham</div>
<div class="dt-author">Dianne Cook</div>
<div class="dt-author">Heike Hofmann</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Escape from Boxland</h2>
<div class="dt-tags"></div>
<p>A library of common geometric shapes can be used to train our brains for understanding data structure in high-dimensional Euclidean space. This article describes the methods for producing cubes, spheres, simplexes, and tori in multiple dimensions. It also describes new ways to define and generate high-dimensional tori. The algorithms are described, critical code chunks are given, and a large collection of generated data are provided. These are available in the R package *geozoo*, and selected movies and images, are available on the GeoZoo web site (&lt;http://schloerke.github.io/geozoo/&gt;).</p>
</div>
</a>
<a href="articles/RJ-2016-046/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 21, 2016</div>
<div class="dt-authors">
<div class="dt-author">Michael C Sachs</div>
<div class="dt-author">Erin E Gabriel</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>An Introduction to Principal Surrogate Evaluation with the pseval Package</h2>
<div class="dt-tags"></div>
<p>We describe a new package called *pseval* that implements the core methods for the evaluation of principal surrogates in a single clinical trial. It provides a flexible interface for defining models for the risk given treatment and the surrogate, the models for integration over the missing counterfactual surrogate responses, and the estimation methods. Estimated maximum likelihood and pseudo-score can be used for estimation, and the bootstrap for inference. A variety of post-estimation methods are provided, including print, summary, plot, and testing. We summarize the main statistical methods that are implemented in the package and illustrate its use from the perspective of a novice R user.</p>
</div>
</a>
<a href="articles/RJ-2016-052/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 21, 2016</div>
<div class="dt-authors">
<div class="dt-author">Michael Lipsitz</div>
<div class="dt-author">Alexandre Belloni</div>
<div class="dt-author">Victor Chernozhukov</div>
<div class="dt-author">Ivn Fernndez-Val</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>quantreg.nonpar: An R Package for Performing Nonparametric Series Quantile Regression</h2>
<div class="dt-tags"></div>
<p>The R package quantreg.nonpar implements nonparametric quantile regression methods to estimate and make inference on partially linear quantile models. quantreg.nonpar obtains point estimates of the conditional quantile function and its derivatives based on series approximations to the nonparametric part of the model. It also provides pointwise and uniform confidence intervals over a region of covariate values and/or quantile indices for the same functions using analytical and resampling methods. This paper serves as an introduction to the package and displays basic functionality of the functions contained within.</p>
</div>
</a>
<a href="articles/RJ-2016-053/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 21, 2016</div>
<div class="dt-authors">
<div class="dt-author">Sven Koitka</div>
<div class="dt-author">Christoph M. Friedrich</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>nmfgpu4R: GPU-Accelerated Computation of the Non-Negative Matrix Factorization (NMF) Using CUDA Capable Hardware</h2>
<div class="dt-tags"></div>
<p>In this work, a novel package called *nmfgpu4R* is presented, which offers the computation of *Non-negative Matrix Factorization (NMF)* on *Compute Unified Device Architecture (CUDA)* platforms within the R environment. Benchmarks show a remarkable speed-up in terms of time per iteration by utilizing the parallelization capabilities of modern graphics cards. Therefore the application of NMF gets more attractive for real-world sized problems because the time to compute a factorization is reduced by an order of magnitude.</p>
</div>
</a>
<a href="articles/RJ-2016-055/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 21, 2016</div>
<div class="dt-authors">
<div class="dt-author">Nuno Fachada</div>
<div class="dt-author">Joo Rodrigues</div>
<div class="dt-author">Vitor V. Lopes</div>
<div class="dt-author">Rui C. Martins</div>
<div class="dt-author">Agostinho C. Rosa</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>micompr: An R Package for Multivariate Independent Comparison of Observations</h2>
<div class="dt-tags"></div>
<p>The R package *micompr* implements a procedure for assessing if two or more multivariate samples are drawn from the same distribution. The procedure uses principal component analysis to convert multivariate observations into a set of linearly uncorrelated statistical measures, which are then compared using a number of statistical methods. This technique is independent of the distributional properties of samples and automatically selects features that best explain their differences. The procedure is appropriate for comparing samples of time series, images, spectrometric measures or similar high-dimension multivariate observations.</p>
</div>
</a>
<a href="articles/RJ-2016-032/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 21, 2016</div>
<div class="dt-authors">
<div class="dt-author">Marco Antoniotti,</div>
<div class="dt-author">Giulio Caravagna,</div>
<div class="dt-author">Luca De Sano,</div>
<div class="dt-author">Alex Graudenzi,</div>
<div class="dt-author">Giancarlo Mauri,</div>
<div class="dt-author">Bud Mishra,</div>
<div class="dt-author">Daniele Ramazzotti,</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Design of the TRONCO BioConductor Package for TRanslational ONCOlogy</h2>
<div class="dt-tags"></div>
<p>Models of cancer progression provide insights on the order of
accumulation of genetic alterations during cancer development.
Algorithms to infer such models from the currently available
mutational profiles collected from different cancer patients
(*cross-sectional data*) have been defined in the literature since
late the 90s. These algorithms differ in the way they extract a
*graphical model* of the events modelling the progression,
e.g.,somatic mutations or copy-number alterations.\
*TRONCO* is an [R]{.smallcaps} package for TRanslational ONcology
which provides a series of functions to assist the user in the
analysis of cross-sectional genomic data and, in particular, it
implements algorithms that aim to model cancer progression by means of
the notion of selective advantage. These algorithms are proved to
outperform the current state-of-the-art in the inference of cancer
progression models. *TRONCO* also provides functionalities to load
input cross-sectional data, set up the execution of the algorithms,
assess the statistical confidence in the results, and visualize the
models.  Availability.  Freely available at &lt;http://www.bioconductor.org/&gt; under GPL license;
project hosted at &lt;http://bimib.disco.unimib.it/&gt; and
&lt;https://github.com/BIMIB-DISCo/TRONCO&gt;.\
Contact. [tronco@disco.unimib.it](tronco@disco.unimib.it)</p>
</div>
</a>
<a href="articles/RJ-2016-039/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 21, 2016</div>
<div class="dt-authors">
<div class="dt-author">Rosaria Lombardo</div>
<div class="dt-author">Eric J. Beh</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Variants of Simple Correspondence Analysis</h2>
<div class="dt-tags"></div>
<p>This paper presents the R package *CAvariants* [@CAvariants]. The package performs six variants of correspondence analysis on a two-way contingency table. The main function that shares the same name as the package -- `CAvariants` -- allows the user to choose (via a series of input parameters) from six different correspondence analysis procedures. These include the classical approach to (symmetrical) correspondence analysis, singly ordered correspondence analysis, doubly ordered correspondence analysis, non symmetrical correspondence analysis, singly ordered non symmetrical correspondence analysis and doubly ordered non symmetrical correspondence analysis. The code provides the flexibility for constructing either a classical correspondence plot or a biplot graphical display. It also allows the user to consider other important features that allow to assess the reliability of the graphical representations, such as the inclusion of algebraically derived elliptical confidence regions. This paper provides R functions that elaborates more fully on the code presented in @behlom14.</p>
</div>
</a>
<a href="articles/RJ-2016-047/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 21, 2016</div>
<div class="dt-authors">
<div class="dt-author">Paul Deveau</div>
<div class="dt-author">Emmanuel Barillot</div>
<div class="dt-author">Valentina Boeva</div>
<div class="dt-author">Andrei Zinovyev</div>
<div class="dt-author">Eric Bonnet</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Calculating Biological Module Enrichment or Depletion and Visualizing Data on Large-scale Molecular Maps with ACSNMineR and Packages</h2>
<div class="dt-tags"></div>
<p>Biological pathways or modules represent sets of interactions or functional relationships occurring at the molecular level in living cells. A large body of knowledge on pathways is organized in public databases such as the KEGG, Reactome, or in more specialized repositories, the Atlas of Cancer Signaling Network (ACSN) being an example. All these open biological databases facilitate analyses, improving our understanding of cellular systems. We hereby describe *ACSNMineR* for calculation of enrichment or depletion of lists of genes of interest in biological pathways. *ACSNMineR* integrates ACSN molecular pathways gene sets, but can use any gene set encoded as a GMT file, for instance sets of genes available in the Molecular Signatures Database (MSigDB). We also present *RNaviCell*, that can be used in conjunction with *ACSNMineR* to visualize different data types on web-based, interactive ACSN maps. We illustrate the functionalities of the two packages with biological data taken from large-scale cancer datasets.</p>
</div>
</a>
<a href="articles/RJ-2016-049/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 21, 2016</div>
<div class="dt-authors">
<div class="dt-author">Maria Pitsillou</div>
<div class="dt-author">Konstantinos Fokianos</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>dCovTS: Distance Covariance/Correlation for Time Series</h2>
<div class="dt-tags"></div>
<p>The distance covariance function is a new measure of dependence between random vectors. We drop the assumption of iid data to introduce distance covariance for time series. The R package *dCovTS* provides functions that compute and plot distance covariance and correlation functions for both univariate and multivariate time series. Additionally it includes functions for testing serial independence based on distance covariance. This paper describes the theoretical background of distance covariance methodology in time series and discusses in detail the implementation of these methods with the R package *dCovTS*.</p>
</div>
</a>
<a href="articles/RJ-2016-050/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 21, 2016</div>
<div class="dt-authors">
<div class="dt-author">Marcel Schweiker</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>comf: An R Package for Thermal Comfort Studies</h2>
<div class="dt-tags"></div>
<p>The field of thermal comfort generated a number of thermal comfort indices. Their code implementation needs to be done by individual researchers. This paper presents the R package, *comf*, which includes functions for common and new thermal comfort indices. Additional functions allow comparisons between the predictive performance of these indices. This paper reviews existing thermal comfort indices and available code implementations. This is followed by the description of the R package and an example how to use the R package for the comparison of different thermal comfort indices on data from a thermal comfort study.</p>
</div>
</a>
<a href="articles/RJ-2016-056/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 21, 2016</div>
<div class="dt-authors">
<div class="dt-author">Xiang-Wei Zhu</div>
<div class="dt-author">Jian-Yi Chen</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>mixtox: An R Package for Mixture Toxicity Assessment</h2>
<div class="dt-tags"></div>
<p>Mixture toxicity assessment is indeed necessary for humans and ecosystems that are continually exposed to a variety of chemical mixtures. This paper describes an R package, called *mixtox*, which offers a general framework of curve fitting, mixture experimental design, and mixture toxicity prediction for practitioners in toxicology. The unique features of *mixtox* include: (1) constructing a uniform table for mixture experimental design; and (2) predicting toxicity of a mixture with multiple components based on reference models such as concentration addition, independent action, and generalized concentration addition. We describe the various functions of the package and provide examples to illustrate their use and show the collaboration of *mixtox* with other existing packages (e.g., *drc*) in predicting toxicity of chemical mixtures.</p>
</div>
</a>
<a href="articles/RJ-2016-060/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2016</div>
<div class="dt-authors">
<div class="dt-author">Yuan Tang</div>
<div class="dt-author">Masaaki Horikoshi</div>
<div class="dt-author">Wenxuan Li</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ggfortify: Unified Interface to Visualize Statistical Results of Popular R Packages</h2>
<div class="dt-tags"></div>
<p>The *ggfortify* package provides a unified interface that enables users to use one line of code to visualize statistical results of many R packages using *ggplot2* idioms. With the help of *ggfortify*, statisticians, data scientists, and researchers can avoid the sometimes repetitive work of using the *ggplot2* syntax to achieve what they need.</p>
</div>
</a>
<a href="articles/RJ-2016-031/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 9, 2016</div>
<div class="dt-authors">
<div class="dt-author">Christopher M. Moore</div>
<div class="dt-author">Christopher R. Stieha</div>
<div class="dt-author">Ben C. Nolting</div>
<div class="dt-author">Maria K. Cameron</div>
<div class="dt-author">Karen C. Abbott</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>QPot: An R Package for Stochastic Differential Equation Quasi-Potential Analysis</h2>
<div class="dt-tags"></div>
<p>QPot (pronounced $ky\overline{\textbf{o}o} + p\ddot{a}t$) is an R package for analyzing two-dimensional systems of stochastic differential equations. It provides users with a wide range of tools to simulate, analyze, and visualize the dynamics of these systems. One of *QPot's* key features is the computation of the quasi-potential, an important tool for studying stochastic systems. Quasi-potentials are particularly useful for comparing the relative stabilities of equilibria in systems with alternative stable states. This paper describes *QPot*'s primary functions, and explains how quasi-potentials can yield insights about the dynamics of stochastic systems. Three worked examples guide users through the application of *QPot*'s functions.</p>
</div>
</a>
<a href="articles/RJ-2016-034/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 9, 2016</div>
<div class="dt-authors">
<div class="dt-author">Anestis Touloumis</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Simulating Correlated Binary and Multinomial Responses under Marginal Model Specification: The SimCorMultRes Package</h2>
<div class="dt-tags"></div>
<p>We developed the R package **SimCorMultRes** to facilitate simulation of correlated categorical (binary and multinomial) responses under a desired marginal model specification. The simulated correlated categorical responses are obtained by applying threshold approaches to correlated continuous responses of underlying regression models and the dependence structure is parametrized in terms of the correlation matrix of the latent continuous responses. This article provides an elaborate introduction to **SimCorMultRes** the package demonstrating its design and usage via three examples. The package can be obtained via CRAN.</p>
</div>
</a>
<a href="articles/RJ-2016-035/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 9, 2016</div>
<div class="dt-authors">
<div class="dt-author">Loren Collingwood</div>
<div class="dt-author">Kassra Oskooii</div>
<div class="dt-author">Sergio Garcia-Rios</div>
<div class="dt-author">Matt A. Barreto</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>eiCompare: Comparing Ecological Inference Estimates across EI and EI:RxC</h2>
<div class="dt-tags"></div>
<p>Social scientists and statisticians often use aggregate data to predict individual-level behavior because the latter are not always available. Various statistical techniques have been developed to make inferences from one level (e.g., precinct) to another level (e.g., individual voter) that minimize errors associated with ecological inference. While ecological inference has been shown to be highly problematic in a wide array of scientific fields, many political scientists and analysis employ the techniques when studying voting patterns. Indeed, federal voting rights lawsuits now require such an analysis, yet expert reports are not consistent in which type of ecological inference is used. This is especially the case in the analysis of racially polarized voting when there are multiple candidates and multiple racial groups. The *eiCompare* package was developed to easily assess two of the more common ecological inference methods: EI and EI:R$\times$C. The package facilitates a seamless comparison between these methods so that scholars and legal practitioners can easily assess the two methods and whether they produce similar or disparate findings.</p>
</div>
</a>
<a href="articles/RJ-2016-038/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 9, 2016</div>
<div class="dt-authors">
<div class="dt-author">Silvia Bacci</div>
<div class="dt-author">Francesco Bartolucci</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Two-Tier Latent Class IRT Models in R</h2>
<div class="dt-tags"></div>
<p>In analyzing data deriving from the administration of a questionnaire to a group of individuals, Item Response Theory (IRT) models provide a flexible framework to account for several aspects involved in the response process, such as the existence of multiple latent traits. In this paper, we focus on a class of semi-parametric multidimensional IRT models, in which these traits are represented through one or more discrete latent variables; these models allow us to cluster individuals into homogeneous latent classes and, at the same time, to properly study item characteristics. In particular, we follow a within-item multidimensional formulation similar to that adopted in the two-tier models, with each item measuring one or two latent traits. The proposed class of models may be estimated through the package *MLCIRTwithin*, whose functioning is illustrated in this paper with examples based on data about quality-of-life measurement and about the propensity to commit a crime.</p>
</div>
</a>
<a href="articles/RJ-2016-040/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 9, 2016</div>
<div class="dt-authors">
<div class="dt-author">Victor Chernozhukov</div>
<div class="dt-author">Chris Hansen</div>
<div class="dt-author">Martin Spindler</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>hdm: High-Dimensional Metrics</h2>
<div class="dt-tags"></div>
<p>In this article the package High-dimensional Metrics *hdm* is introduced. It is a collection of statistical methods for estimation and quantification of uncertainty in high-dimensional approximately sparse models. It focuses on providing confidence intervals and significance testing for (possibly many) low-dimensional subcomponents of the high-dimensional parameter vector. Efficient estimators and uniformly valid confidence intervals for regression coefficients on target variables (e.g., treatment or policy variable) in a high-dimensional approximately sparse regression model, for average treatment effect (ATE) and average treatment effect for the treated (ATET), as well for extensions of these parameters to the endogenous setting are provided. Theory grounded, data-driven methods for selecting the penalization parameter in Lasso regressions under heteroscedastic and non-Gaussian errors are implemented. Moreover, joint/ simultaneous confidence intervals for regression coefficients of a high-dimensional sparse regression are implemented. Data sets which have been used in the literature and might be useful for classroom demonstration and for testing new estimators are included.</p>
</div>
</a>
<a href="articles/RJ-2016-048/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 9, 2016</div>
<div class="dt-authors">
<div class="dt-author">ngel M. Garca</div>
<div class="dt-author">Francisco Charte</div>
<div class="dt-author">Pedro Gonzlez</div>
<div class="dt-author">Cristbal J. Carmona</div>
<div class="dt-author">Mara J. del Jesus</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Subgroup Discovery with Evolutionary Fuzzy Systems in R: The SDEFSR Package</h2>
<div class="dt-tags"></div>
<p>Subgroup discovery is a data mining task halfway between descriptive and predictive data mining. Nowadays it is very relevant for researchers due to the fact that the knowledge extracted is simple and interesting. For this task, evolutionary fuzzy systems are well suited algorithms because they can find a good trade-off between multiple objectives in large search spaces. In fact, this paper presents the SDEFSR package, which contains all the evolutionary fuzzy systems for subgroup discovery presented throughout the literature. It is a package without dependencies on other software, providing functions with recommended default parameters. In addition, it brings a graphical user interface to avoid the user having to know all the parameters of the algorithms.</p>
</div>
</a>
<a href="articles/RJ-2016-058/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 9, 2016</div>
<div class="dt-authors">
<div class="dt-author">Usue Mori</div>
<div class="dt-author">Alexander Mendiburu</div>
<div class="dt-author">Jose A. Lozano</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Distance Measures for Time Series in R: The TSdist Package</h2>
<div class="dt-tags"></div>
<p>The definition of a distance measure between time series is crucial for many time series data mining tasks, such as clustering and classification. For this reason, a vast portfolio of time series distance measures has been published in the past few years. In this paper, the [*TSdist*](https://CRAN.R-project.org/package=TSdist) package is presented, a complete tool which provides a unified framework to calculate the largest variety of time series dissimilarity measures available in R at the moment, to the best of our knowledge. The package implements some popular distance measures which were not previously available in R, and moreover, it also provides wrappers for measures already included in other R packages. Additionally, the application of these distance measures to clustering and classification tasks is also supported in *TSdist*, directly enabling the evaluation and comparison of their performance within these two frameworks.</p>
</div>
</a>
<a href="articles/RJ-2016-030/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 11, 2016</div>
<div class="dt-authors">
<div class="dt-author">Nathalie C.Ster</div>
<div class="dt-author">Sven Ove Samuelsen</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>multipleNCC: Inverse Probability Weighting of Nested Case-Control Data</h2>
<div class="dt-tags"></div>
<p>Reuse of controls from nested case-control designs can increase efficiency in many situations, for instance with competing risks or in other multiple endpoints situations. The matching between cases and controls must be broken when controls are to be used for other endpoints. A weighted analysis can then be performed to take care of the biased sampling from the cohort. We present the R package *multipleNCC* for reuse of controls in nested case-control studies by inverse probability weighting of the partial likelihood. The package handles right-censored, left-truncated and additionally matched data, and varying numbers of sampled controls and the whole analysis is carried out using one simple command. Four weight estimators are presented and variance estimation is explained. The package is illustrated by analyzing health survey data from three counties in Norway for two causes of death: cardiovascular disease and death from alcohol abuse, liver disease, and accidents and violence. The data set is included in the package.</p>
</div>
</a>
<a href="articles/RJ-2016-043/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 11, 2016</div>
<div class="dt-authors">
<div class="dt-author">Kyle Walker</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>tigris: An R Package to Access and Work with Geographic Data from the US Census Bureau</h2>
<div class="dt-tags"></div>
<p>TIGER/Line shapefiles from the United States Census Bureau are commonly used for the mapping and analysis of US demographic trends. The *tigris* package provides a uniform interface for R users to download and work with these shapefiles. Functions in *tigris* allow R users to request Census geographic datasets using familiar geographic identifiers and return those datasets as objects of class `"Spatial*DataFrame"`. In turn, *tigris* ensures consistent and high-quality spatial data for R users' cartographic and spatial analysis projects that involve US Census data. This article provides an overview of the functionality of the *tigris* package, and concludes with an applied example of a geospatial workflow using data retrieved with *tigris*.</p>
</div>
</a>
<a href="articles/RJ-2016-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 28, 2016</div>
<div class="dt-authors">
<div class="dt-author">Patrick Brown</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Maps, Coordinate Reference Systems and Visualising Geographic Data with mapmisc</h2>
<div class="dt-tags"></div>
<p>The *mapmisc* package provides functions for visualising geospatial data, including fetching background map layers, producing colour scales and legends, and adding scale bars and orientation arrows to plots. Background maps are returned in the coordinate reference system of the dataset supplied, and inset maps and direction arrows reflect the map projection being plotted. This is a "light weight" package having an emphasis on simplicity and ease of use.</p>
</div>
</a>
<a href="articles/RJ-2016-024/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 27, 2016</div>
<div class="dt-authors">
<div class="dt-author">Giner</div>
<div class="dt-author">Gordon K. Smyth</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>statmod: Probability Calculations for the Inverse Gaussian Distribution</h2>
<div class="dt-tags"></div>
<p>The inverse Gaussian distribution (IGD) is a well known and often used probability distribution for which fully reliable numerical algorithms have not been available. We develop fast, reliable basic probability functions (`dinvgauss`, `pinvgauss`, `qinvgauss` and `rinvgauss`) for the IGD that work for all possible parameter values and which achieve close to full machine accuracy. The most challenging task is to compute quantiles for given cumulative probabilities and we develop a simple but elegant mathematical solution to this problem. We show that Newton's method for finding the quantiles of a IGD always converges monotonically when started from the mode of the distribution. Simple Taylor series expansions are used to improve accuracy on the log-scale. The IGD probability functions provide the same options and obey the same conventions as do probability functions provided in the *stats* package.</p>
</div>
</a>
<a href="articles/RJ-2016-027/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 27, 2016</div>
<div class="dt-authors">
<div class="dt-author">Jos Feys</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Nonparametric Tests for the Interaction in Two-way Factorial Designs Using R</h2>
<div class="dt-tags"></div>
<p>An increasing number of R packages include nonparametric tests for the interaction in two-way factorial designs. This paper briefly describes the different methods of testing and reports the resulting *p*-values of such tests on datasets for four types of designs: between, within, mixed, and pretest-posttest designs. Potential users are advised only to apply tests they are quite familiar with and not be guided by *p*-values for selecting packages and tests.</p>
</div>
</a>
<a href="articles/RJ-2016-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 23, 2016</div>
<div class="dt-authors">
<div class="dt-author">Kamil Wais</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Gender Prediction Methods Based on First Names with genderizeR</h2>
<div class="dt-tags"></div>
<p>In recent years, there has been increased interest in methods for gender prediction based on first names that employ various open data sources. These methods have applications from bibliometric studies to customizing commercial offers for web users. Analysis of gender disparities in science based on such methods are published in the most prestigious journals, although they could be improved by choosing the most suited prediction method with optimal parameters and performing validation studies using the best data source for a given purpose. There is also a need to monitor and report how well a given prediction method works in comparison to others. In this paper, the author recommends a set of tools (including one dedicated to gender prediction, the R package called *genderizeR*), data sources (including the genderize.io API), and metrics that could be fully reproduced and tested in order to choose the optimal approach suitable for different gender analyses.</p>
</div>
</a>
<a href="articles/RJ-2016-029/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 23, 2016</div>
<div class="dt-authors">
<div class="dt-author">Luke A Winslow</div>
<div class="dt-author">Scott Chamberlain</div>
<div class="dt-author">Alison P Appling</div>
<div class="dt-author">Jordan S Read</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>sbtools: A Package Connecting R to Cloud-based Data for Collaborative Online Research</h2>
<div class="dt-tags"></div>
<p>The adoption of high-quality tools for collaboration and reproducibile research such as R and Github is becoming more common in many research fields. While Github and other version management systems are excellent resources, they were originally designed to handle code and scale poorly to large text-based or binary datasets. A number of scientific data repositories are coming online and are often focused on dataset archival and publication. To handle collaborative workflows using large scientific datasets, there is increasing need to connect cloud-based online data storage to R. In this article, we describe how the new R package *sbtools* enables direct access to the advanced online data functionality provided by ScienceBase, the U.S. Geological Survey's online scientific data storage platform.</p>
</div>
</a>
<a href="articles/RJ-2016-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 13, 2016</div>
<div class="dt-authors">
<div class="dt-author">Ken J. Beath</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>metaplus: An R Package for the Analysis of Robust Meta-Analysis and Meta-Regression</h2>
<div class="dt-tags"></div>
<p>The *metaplus* package is described with examples of its use for fitting meta-analysis and meta-regression. For either meta-analysis or meta-regression it is possible to fit one of three models: standard normal random effect, $t$-distribution random effect or mixture of normal random effects. The latter two models allow for robustness by allowing for a random effect distribution with heavier tails than the normal distribution, and for both robust models the presence of outliers may be tested using the parametric bootstrap. For the mixture of normal random effects model the outlier studies may be identified through their posterior probability of membership in the outlier component of the mixture. Plots allow the results of the different models to be compared. The package is demonstrated on three examples: a meta-analysis with no outliers, a meta-analysis with an outlier and a meta-regression with an outlier.</p>
</div>
</a>
<a href="articles/RJ-2016-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 13, 2016</div>
<div class="dt-authors">
<div class="dt-author">Benedikt Grler</div>
<div class="dt-author">Edzer Pebesma</div>
<div class="dt-author">Gerard Heuvelink</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Spatio-Temporal Interpolation using gstat</h2>
<div class="dt-tags"></div>
<p>We present new spatio-temporal geostatistical modelling and interpolation capabilities of the R package *gstat*. Various spatio-temporal covariance models have been implemented, such as the separable, product-sum, metric and sum-metric models. In a real-world application we compare spatio-temporal interpolations using these models with a purely spatial kriging approach. The target variable of the application is the daily mean $\rm{PM}_{10}$ concentration measured at rural air quality monitoring stations across Germany in 2005. R code for variogram fitting and interpolation is presented in this paper to illustrate the workflow of spatio-temporal interpolation using *gstat*. We conclude that the system works properly and that the extension of *gstat* facilitates and eases spatio-temporal geostatistical modelling and prediction for R users.</p>
</div>
</a>
<a href="articles/RJ-2016-020/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 13, 2016</div>
<div class="dt-authors">
<div class="dt-author">Thomas J. Leeper</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Crowdsourced Data Preprocessing with R and Amazon Mechanical Turk</h2>
<div class="dt-tags"></div>
<p>This article introduces the use of the Amazon Mechanical Turk (MTurk) crowdsourcing platform as a resource for R users to leverage crowdsourced human intelligence for preprocessing "messy" data into a form easily analyzed within R. The article first describes MTurk and the *MTurkR* package, then outlines how to use *MTurkR* to gather and manage crowdsourced data with MTurk using some of the package's core functionality. Potential applications of *MTurkR* include construction of manually coded training sets, human transcription and translation, manual data scraping from scanned documents, content analysis, image classification, and the completion of online survey questionnaires, among others. As an example of massive data preprocessing, the article describes an image rating task involving 225 crowdsourced workers and more than 5500 images using just three *MTurkR* function calls.</p>
</div>
</a>
<a href="articles/RJ-2016-021/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 13, 2016</div>
<div class="dt-authors">
<div class="dt-author">Luca Scrucca</div>
<div class="dt-author">Michael Fop</div>
<div class="dt-author">T. Brendan Murphy</div>
<div class="dt-author">Adrian E. Raftery</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>mclust 5: Clustering, Classification and Density Estimation Using Gaussian Finite Mixture Models</h2>
<div class="dt-tags"></div>
<p>Finite mixture models are being used increasingly to model a wide variety of random phenomena for clustering, classification and density estimation. *mclust* is a powerful and popular package which allows modelling of data as a Gaussian finite mixture with different covariance structures and different numbers of mixture components, for a variety of purposes of analysis. Recently, version 5 of the package has been made available on CRAN. This updated version adds new covariance structures, dimension reduction capabilities for visualisation, model selection criteria, initialisation strategies for the EM algorithm, and bootstrap-based inference, making it a full-featured Rpackage for data analysis via finite mixture modelling.</p>
</div>
</a>
<a href="articles/RJ-2016-026/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 13, 2016</div>
<div class="dt-authors">
<div class="dt-author">Oliver Keyes</div>
<div class="dt-author">Bob Rudis</div>
<div class="dt-author">Jay Jacobs</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>R Packages to Aid in Handling Web Access Logs</h2>
<div class="dt-tags"></div>
<p>Web access logs contain information on HTTP(S) requests and form a key part of both industry and academic explorations of human behaviour on the internet. But the preparation (reading, parsing and manipulation) of that data is just unique enough to make generalized tools unfit for the task, both in programming time and processing time which are compounded when dealing with large data sets common with web access logs. In this paper we explain and demonstrate a series of packages designed to efficiently read in, parse and munge access log data, allowing researchers to handle URLs and IP addresses easily. These packages are substantially faster than existing R methods - from a 3-500% speedup for file reading to a 57,000% speedup in URL parsing.</p>
</div>
</a>
<a href="articles/RJ-2016-028/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 13, 2016</div>
<div class="dt-authors">
<div class="dt-author">Osman Dag</div>
<div class="dt-author">Ceylan Yozgatligil</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>GMDH: An R Package for Short Term Forecasting via GMDH-Type Neural Network Algorithms</h2>
<div class="dt-tags"></div>
<p>Group Method of Data Handling (GMDH)-type neural network algorithms are the heuristic self organization method for the modelling of complex systems. GMDH algorithms are utilized for a variety of purposes, examples include identification of physical laws, the extrapolation of physical fields, pattern recognition, clustering, the approximation of multidimensional processes, forecasting without models, etc. In this study, the R package *GMDH* is presented to make short term forecasting through GMDH-type neural network algorithms. The *GMDH* package has options to use different transfer functions (sigmoid, radial basis, polynomial, and tangent functions) simultaneously or separately. Data on cancer death rate of Pennsylvania from 1930 to 2000 are used to illustrate the features of the *GMDH* package. The results based on ARIMA models and exponential smoothing methods are included for comparison.</p>
</div>
</a>
<a href="articles/RJ-2016-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2016</div>
<div class="dt-authors">
<div class="dt-author">Weihua An</div>
<div class="dt-author">Yu-Hsin Liu</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>keyplayer: An R Package for Locating Key Players in Social Networks</h2>
<div class="dt-tags"></div>
<p>Interest in social network analysis has exploded in the past few years, partly thanks to the advancements in statistical methods and computing for network analysis. A wide range of the methods for network analysis is already covered by existent R packages. However, no comprehensive packages are available to calculate group centrality scores and to identify key players (i.e., those players who constitute the most central group) in a network. These functionalities are important because, for example, many social and health interventions rely on key players to facilitate the intervention. Identifying key players is challenging because players who are individually the most central are not necessarily the most central as a group due to redundancy in their connections. In this paper we develop methods and tools for computing group centrality scores and for identifying key players in social networks. We illustrate the methods using both simulated and empirical examples. The package *keyplayer* providing the presented methods is available from Comprehensive R Archive Network (CRAN).</p>
</div>
</a>
<a href="articles/RJ-2016-022/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2016</div>
<div class="dt-authors">
<div class="dt-author">Tibor Szkaliczki</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>clustering.sc.dp: Optimal Clustering with Sequential Constraint by Using Dynamic Programming</h2>
<div class="dt-tags"></div>
<p>The general clustering algorithms do not guarantee optimality because of the hardness of the problem. Polynomial-time methods can find the clustering corresponding to the exact optimum only in special cases. For example, the dynamic programming algorithm can solve the one-dimensional clustering problem, i.e., when the items to be clustered can be characterised by only one scalar number. Optimal one-dimensional clustering is provided by package *Ckmeans.1d.dp* in R. The paper shows a possible generalisation of the method implemented in this package to multidimensional data: the dynamic programming method can be applied to find the optimum clustering of vectors when only subsequent items may form a cluster. Sequential data are common in various fields including telecommunication, bioinformatics, marketing, transportation etc. The proposed algorithm can determine the optima for a range of cluster numbers in order to support the case when the number of clusters is not known in advance.</p>
</div>
</a>
<a href="articles/RJ-2016-023/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2016</div>
<div class="dt-authors">
<div class="dt-author">Chenyue W. Hu</div>
<div class="dt-author">Amina A. Qutub</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>progenyClust: an R package for Progeny Clustering</h2>
<div class="dt-tags"></div>
<p>Identifying the optimal number of clusters is a common problem faced by data scientists in various research fields and industry applications. Though many clustering evaluation techniques have been developed to solve this problem, the recently developed algorithm Progeny Clustering is a much faster alternative and one that is relevant to biomedical applications. In this paper, we introduce an R package *progenyClust* that implements and extends the original Progeny Clustering algorithm for evaluating clustering stability and identifying the optimal cluster number. We illustrate its applicability using two examples: a simulated test dataset for proof-of-concept, and a cell imaging dataset for demonstrating its application potential in biomedical research. The *progenyClust* package is versatile in that it offers great flexibility for picking methods and tuning parameters. In addition, the default parameter setting as well as the plot and summary methods offered in the package make the application of Progeny Clustering straightforward and coherent.</p>
</div>
</a>
<a href="articles/RJ-2016-025/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2016</div>
<div class="dt-authors">
<div class="dt-author">Erik S. Wright</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Using DECIPHER v2.0 to Analyze Big Biological Sequence Data in R</h2>
<div class="dt-tags"></div>
<p>In recent years, the cost of DNA sequencing has decreased at a rate that has outpaced improvements in memory capacity. It is now common to collect or have access to many gigabytes of biological sequences. This has created an urgent need for approaches that analyze sequences in subsets without requiring all of the sequences to be loaded into memory at one time. It has also opened opportunities to improve the organization and accessibility of information acquired in sequencing projects. The *DECIPHER* package offers solutions to these problems by assisting in the curation of large sets of biological sequences stored in compressed format inside a database. This approach has many practical advantages over standard bioinformatics workflows, and enables large analyses that would otherwise be prohibitively time consuming.</p>
</div>
</a>
<a href="articles/RJ-2016-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 20, 2016</div>
<div class="dt-authors">
<div class="dt-author">Marta Sestelo</div>
<div class="dt-author">Nora M. Villanueva</div>
<div class="dt-author">Luis Meira-MachadoAuthor</div>
<div class="dt-author">Javier Roca-Pardias</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>FWDselect: An R Package for Variable Selection in Regression Models</h2>
<div class="dt-tags"></div>
<p>In multiple regression models, when there are a large number ($p$) of explanatory variables which may or may not be relevant for predicting the response, it is useful to be able to reduce the model. To this end, it is necessary to determine the best subset of $q$ ($q\le p$) predictors which will establish the model with the best prediction capacity. *FWDselect* package introduces a new forward stepwise-based selection procedure to select the best model in different regression frameworks (parametric or nonparametric). The developed methodology, which can be equally applied to linear models, generalized linear models or generalized additive models, aims to introduce solutions to the following two topics: i) selection of the best combination of $q$ variables by using a step-by-step method; and, perhaps, most importantly, ii) search for the number of covariates to be included in the model based on bootstrap resampling techniques. The software is illustrated using real and simulated data.</p>
</div>
</a>
<a href="articles/RJ-2016-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 3, 2016</div>
<div class="dt-authors">
<div class="dt-author">Alexandre Brouste</div>
<div class="dt-author">Jacques Istas</div>
<div class="dt-author">Sophie Lambert-Lacroix</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Conditional Fractional Gaussian Fields with the Package FieldSim</h2>
<div class="dt-tags"></div>
<p>We propose an effective and fast method to simulate multidimensional [conditional fractional Gaussian fields]{style="color: black"} with the package *FieldSim*. Our method is valid not only for [conditional simulations]{style="color: black"} associated to fractional Brownian fields, but to any Gaussian field and on any (non regular) grid of points.</p>
</div>
</a>
<a href="articles/RJ-2016-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 3, 2016</div>
<div class="dt-authors">
<div class="dt-author">Loc Yengo</div>
<div class="dt-author">Julien Jacques</div>
<div class="dt-author">Christophe Biernacki</div>
<div class="dt-author">Mickael Canouil</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Variable Clustering in High-Dimensional Linear Regression: The R Package clere</h2>
<div class="dt-tags"></div>
<p>Dimension reduction is one of the biggest challenges in high-dimensional regression models. We recently introduced a new methodology based on variable clustering as a means to reduce dimensionality. We present here the R package *clere* that implements some refinements of this methodology. An overview of the package functionalities as well as examples to run an analysis are described. Numerical experiments on real data were performed to illustrate the good predictive performance of our parsimonious method compared to standard dimension reduction approaches.</p>
</div>
</a>
<a href="articles/RJ-2016-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 3, 2016</div>
<div class="dt-authors">
<div class="dt-author">Christopher Franck</div>
<div class="dt-author">Jason Osborne</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Exploring Interaction Effects in Two-Factor Studies using the hiddenf Package in R.</h2>
<div class="dt-tags"></div>
<p>In crossed, two-factor studies with one observation per factor-level combination, interaction effects between factors can be hard to detect and can make the choice of a suitable statistical model difficult. This article describes *hiddenf*, an R package that enables users to quantify and characterize a certain form of interaction in two-factor layouts. When effects of one factor (a) fall into two groups depending on the level of another factor, and (b) are constant within these groups, the interaction pattern is deemed \"hidden additivity\" because within groups, the effects of the two factors are additive, while between groups the factors are allowed to interact. The *hiddenf* software can be used to estimate, test, and report an appropriate factorial effects model corresponding to hidden additivity, which is intermediate between the unavailable full factorial model and the overly-simplistic additive model. Further, the software also conducts five statistical tests for interaction proposed between 1949 and 2014. A collection of 17 datasets is used for illustration.</p>
</div>
</a>
<a href="articles/RJ-2016-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 3, 2016</div>
<div class="dt-authors">
<div class="dt-author">Joshua N.Pritikin</div>
<div class="dt-author">Karen M.Schmidt</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Model Builder for Item Factor Analysis with OpenMx</h2>
<div class="dt-tags"></div>
<p>We introduce a shiny web application to facilitate the construction of Item Factor Analysis (a.k.a.Item Response Theory) models using the *OpenMx* package. The web application assists with importing data, outcome recoding, and model specification. However, the app does not conduct any analysis but, rather, generates an analysis script. Generated Rmarkdown output serves dual purposes: to analyze a data set and demonstrate good programming practices. The app can be used as a teaching tool or as a starting point for custom analysis scripts.</p>
</div>
</a>
<a href="articles/RJ-2016-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 3, 2016</div>
<div class="dt-authors">
<div class="dt-author">Marcus W Beck</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SWMPr: An R Package for Retrieving, Organizing, and Analyzing Environmental Data for Estuaries</h2>
<div class="dt-tags"></div>
<p>The System-Wide Monitoring Program (SWMP) was implemented in 1995 by the US National Estuarine Research Reserve System. This program has provided two decades of continuous monitoring data at over 140 fixed stations in 28 estuaries. However, the increasing quantity of data provided by the monitoring network has complicated broad-scale comparisons between systems and, in some cases, prevented simple trend analysis of water quality parameters at individual sites. This article describes the *SWMPr* package that provides several functions that facilitate data retrieval, organization, and analysis of time series data in the reserve estuaries. Previously unavailable functions for estuaries are also provided to estimate rates of ecosystem metabolism using the open-water method. The *SWMPr* package has facilitated a cross-reserve comparison of water quality trends and links quantitative information with analysis tools that have use for more generic applications to environmental time series.</p>
</div>
</a>
<a href="articles/RJ-2016-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 3, 2016</div>
<div class="dt-authors">
<div class="dt-author">Haydar Demirhan</div>
<div class="dt-author">Nihan Bitirim</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>CryptRndTest: An R Package for Testing the Cryptographic Randomness</h2>
<div class="dt-tags"></div>
<p>In this article, we introduce the R package *CryptRndTest* that performs eight statistical randomness tests on cryptographic random number sequences. The purpose of the package is to provide software implementing recently proposed cryptographic randomness tests utilizing goodness-of-fit tests superior to the usual chi-square test in terms of statistical performance. Most of the tests included in package *CryptRndTest* are not available in other software packages such as the R package *RDieHarder* or the C library TestU01. Chi-square, Anderson-Darling, Kolmogorov-Smirnov, and Jarque-Bera goodness-of-fit procedures are provided along with cryptographic randomness tests. *CryptRndTest* utilizes multiple precision floating numbers for sequences longer than 64-bit based on the package *Rmpfr*. By this way, included tests are applied precisely for higher bit-lengths. In addition *CryptRndTest* provides a user friendly interface to these cryptographic randomness tests. As an illustrative application, *CryptRndTest* is used to test available random number generators in R.</p>
</div>
</a>
<a href="articles/RJ-2016-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 3, 2016</div>
<div class="dt-authors">
<div class="dt-author">Michael J. North</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SchemaOnRead: A Package for Schema-on-Read in R</h2>
<div class="dt-tags"></div>
<p>SchemaOnRead is a CRAN package that provides an extensible mechanism for importing a wide range of file types into R as well as support for the emerging schema-on-read paradigm in R. The schema-on-read tools within the package include a single function call that recursively reads folders with text, comma separated value, raster image, R data, HDF5, NetCDF, spreadsheet, Weka, Epi Info, Pajek network, R network, HTML, SPSS, Systat, and Stata files. It also recursively reads folders (e.g., schemaOnRead(folder)), returning a nested list of the contained elements. The provided tools can be used as-is or easily customized to implement tool chains in R. This paper's contribution is that it introduces and describes the *SchemaOnRead* package and compares it to related R packages.</p>
</div>
</a>
<a href="articles/RJ-2016-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 2, 2016</div>
<div class="dt-authors">
<div class="dt-author">Haydar Demirhan</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>rTableICC: An R Package for Random Generation of 2x2xK and RxC Contingency Tables</h2>
<div class="dt-tags"></div>
<p>In this paper, we describe the R package *rTableICC* that provides an interface for random generation of 2$\times$`&lt;!-- --&gt;`{=html}2$\times$K and R$\times$C contingency tables constructed over either intraclass-correlated or uncorrelated individuals. Intraclass correlations arise in studies where sampling units include more than one individual and these individuals are correlated. The package implements random generation of contingency tables over individuals with or without intraclass correlations under various sampling plans. The package include two functions for the generation of K 2$\times$`&lt;!-- --&gt;`{=html}2 tables over product-multinomial sampling schemes and that of 2$\times$`&lt;!-- --&gt;`{=html}2$\times$K tables under Poisson or multinomial sampling plans. It also contains two functions that generate R$\times$C tables under product-multinomial, multinomial or Poisson sampling plans with or without intraclass correlations. The package also includes a function for random number generation from a given probability distribution. In addition to the contingency table format, the package also provides raw data required for further estimation purposes.</p>
</div>
</a>
<a href="articles/RJ-2016-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 22, 2015</div>
<div class="dt-authors">
<div class="dt-author">Maciej Eder</div>
<div class="dt-author">Jan Rybicki</div>
<div class="dt-author">Mike Kestemont</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Stylometry with R: A Package for Computational Text Analysis</h2>
<div class="dt-tags"></div>
<p>This software paper describes 'Stylometry with R' (*stylo*), a flexible R package for the high-level analysis of writing style in stylometry. Stylometry (computational stylistics) is concerned with the quantitative study of writing style, e.g.authorship verification, an application which has considerable potential in forensic contexts, as well as historical research. In this paper we introduce the possibilities of *stylo* for computational text analysis, via a number of dummy case studies from English and French literature. We demonstrate how the package is particularly useful in the exploratory statistical analysis of texts, e.g.with respect to authorial writing style. Because *stylo* provides an attractive graphical user interface for high-level exploratory analyses, it is especially suited for an audience of novices, without programming skills (e.g.from the Digital Humanities). More experienced users can benefit from our implementation of a series of standard pipelines for text processing, as well as a number of similarity metrics.</p>
</div>
</a>
<a href="articles/RJ-2015-035/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 10, 2015</div>
<div class="dt-authors">
<div class="dt-author">David Moria</div>
<div class="dt-author">Manuel Higueras</div>
<div class="dt-author">Pedro Puig</div>
<div class="dt-author">Mara Oliveira</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Generalized Hermite Distribution Modelling with the R Package hermite</h2>
<div class="dt-tags"></div>
<p>The Generalized Hermite distribution (and the Hermite distribution as a particular case) is often used for fitting count data in the presence of overdispersion or multimodality. Despite this, to our knowledge, no standard software packages have implemented specific functions to compute basic probabilities and make simple statistical inference based on these distributions. We present here a set of computational tools that allows the user to face these difficulties by modelling with the Generalized Hermite distribution using the R package *hermite*. The package can also be used to generate random deviates from a Generalized Hermite distribution and to use basic functions to compute probabilities (density, cumulative density and quantile functions are available), to estimate parameters using the maximum likelihood method and to perform the likelihood ratio test for Poisson assumption against a Generalized Hermite alternative. In order to improve the density and quantile functions performance when the parameters are large, Edgeworth and Cornish-Fisher expansions have been used. Hermite regression is also a useful tool for modeling inflated count data, so its inclusion to a commonly used software like R will make this tool available to a wide range of potential users. Some examples of usage in several fields of application are also given.</p>
</div>
</a>
<a href="articles/RJ-2015-034/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 28, 2015</div>
<div class="dt-authors">
<div class="dt-author">Michael C. Koohafkan</div>
<div class="dt-author">Bassam A. Younis</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Open-Channel Computation with R</h2>
<div class="dt-tags"></div>
<p>The *rivr* package provides a computational toolset for simulating steady and unsteady one-dimensional flows in open channels. It is designed primarily for use by instructors of undergraduate- and graduate-level open-channel hydrodynamics courses in such diverse fields as river engineering, physical geography and geophysics. The governing equations used to describe open-channel flows are briefly presented, followed by example applications. These include the computation of gradually-varied flows and two examples of unsteady flows in channels---namely, the tracking of the evolution of a flood wave in a channel and the prediction of extreme variation in the water-surface profile that results when a sluice gate is abruptly closed. Model results for the unsteady flow examples are validated against standard benchmarks. The article concludes with a discussion of potential modifications and extensions to the package.</p>
</div>
</a>
<a href="articles/RJ-2016-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 26, 2015</div>
<div class="dt-authors">
<div class="dt-author">Borja Calvo</div>
<div class="dt-author">Guzmn Santaf</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>scmamp: Statistical Comparison of Multiple Algorithms in Multiple Problems</h2>
<div class="dt-tags"></div>
<p>Comparing the results obtained by two or more algorithms in a set of problems is a central task in areas such as machine learning or optimization. Drawing conclusions from these comparisons may require the use of statistical tools such as hypothesis testing. There are some interesting papers that cover this topic. In this manuscript we present *scmamp*, an R package aimed at being a tool that simplifies the whole process of analyzing the results obtained when comparing algorithms, from loading the data to the production of plots and tables.</p>
</div>
</a>
<a href="articles/RJ-2015-022/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 18, 2015</div>
<div class="dt-authors">
<div class="dt-author">Robin K. S. Hankin</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Numerical Evaluation of the Gauss Hypergeometric Function with the hypergeo Package</h2>
<div class="dt-tags"></div>
<p>This paper introduces the *hypergeo* package of R routines for numerical calculation of hypergeometric functions. The package is focussed on efficient and accurate evaluation of the Gauss hypergeometric function over the whole of the complex plane within the constraints of fixed-precision arithmetic. The hypergeometric series is convergent only within the unit circle, so analytic continuation must be used to define the function outside the unit circle. This short document outlines the numerical and conceptual methods used in the package; and justifies the package philosophy, which is to maintain transparent and verifiable links between the software and@abramowitz1965. Most of the package functionality is accessed via the single function `hypergeo()`, which dispatches to one of several methods depending on the value of its arguments. The package is demonstrated in the context of game theory.</p>
</div>
</a>
<a href="articles/RJ-2015-036/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 18, 2015</div>
<div class="dt-authors">
<div class="dt-author">Angel Rubio</div>
<div class="dt-author">Fernando de Villar</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Code Profiling in R: A Review of Existing Methods and an Introduction to Package GUIProfiler</h2>
<div class="dt-tags"></div>
<p>Code analysis tools are crucial to understand program behavior.
Profile tools use the results of time measurements in the execution of
a program to gain this understanding and thus help in the optimization
of the code. In this paper, we review the different available packages
to profile R code and show the advantages and disadvantages of each of
them. In additon, we present *GUIProfiler*, a package that fulfills
some unmet needs.\
Package *GUIProfiler* generates an HTML report with the timing for
each code line and the relationships between different functions. This
package mimics the behavior of the MATLAB profiler. The HTML report
includes information on the time spent on each of the lines of the
profiled code (the slowest code is highlighted). If the package is
used within the RStudio environment, the user can navigate across the
bottlenecks in the code and open the editor to modify the lines of
code where more time is spent. It is also possible to edit the code
using Notepad++ (a free editor for Windows) by simply clicking on the
corresponding line. The graphical user interface makes it easy to
identify the specific lines which slow down the code.\
The integration in RStudio and the generation of an HTML report makes
*GUIProfiler* a very convenient tool to perform code optimization.</p>
</div>
</a>
<a href="articles/RJ-2015-024/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 10, 2015</div>
<div class="dt-authors">
<div class="dt-author">Ainhoa Vega-Bayo</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>An R Package for the Panel Approach Method for Program Evaluation: pampe</h2>
<div class="dt-tags"></div>
<p>The *pampe* package for R implements the panel data approach method for program evaluation designed to estimate the causal effects of political interventions or treatments. This procedure exploits the dependence among cross-sectional units to construct a counterfactual of the treated unit(s), and it is an appropriate method for research events that occur at an aggregate level like countries or regions and that affect only one or a small number of units. The implementation of the *pampe* package is illustrated using data from Hong Kong and 24 other units, by examining the economic impact of the political and economic integration of Hong Kong with mainland China in 1997 and 2004 respectively.</p>
</div>
</a>
<a href="articles/RJ-2015-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 8, 2015</div>
<div class="dt-authors">
<div class="dt-author">Robin Genuer</div>
<div class="dt-author">Jean-Michel Poggi</div>
<div class="dt-author">Christine Tuleau-Malot</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>VSURF: An R Package for Variable Selection Using Random Forests</h2>
<div class="dt-tags"></div>
<p>This paper describes the R package *VSURF*. Based on random forests, and for both regression and classification problems, it returns two subsets of variables. The first is a subset of important variables including some redundancy which can be relevant for interpretation, and the second one is a smaller subset corresponding to a model trying to avoid redundancy focusing more closely on the prediction objective. The two-stage strategy is based on a preliminary ranking of the explanatory variables using the random forests permutation-based score of importance and proceeds using a stepwise forward strategy for variable introduction. The two proposals can be obtained automatically using data-driven default values, good enough to provide interesting results, but strategy can also be tuned by the user. The algorithm is illustrated on a simulated example and its applications to real datasets are presented.</p>
</div>
</a>
<a href="articles/RJ-2016-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 8, 2015</div>
<div class="dt-authors">
<div class="dt-author">Daniel Linares</div>
<div class="dt-author">Joan Lpez-Moliner</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>quickpsy: An R Package to Fit Psychometric Functions for Multiple Groups</h2>
<div class="dt-tags"></div>
<p>*quickpsy* is a package to parametrically fit psychometric functions. In comparison with previous R packages, *quickpsy* was built to easily fit and plot data for multiple groups. Here, we describe the standard parametric model used to fit psychometric functions and the standard estimation of its parameters using maximum likelihood. We also provide examples of usage of *quickpsy*, including how allowing the lapse rate to vary can sometimes eliminate the bias in parameter estimation, but not in general. Finally, we describe some implementation details, such as how to avoid the problems associated to round-off errors in the maximisation of the likelihood or the use of closures and non-standard evaluation functions.</p>
</div>
</a>
<a href="articles/RJ-2016-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 4, 2015</div>
<div class="dt-authors">
<div class="dt-author">Mitchell Joblin</div>
<div class="dt-author">Wolfgang Mauerer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>An Interactive Survey Application for Validating Social Network Analysis Techniques</h2>
<div class="dt-tags"></div>
<p>Social network analysis is extremely well supported by the R community and is routinely used for studying the relationships between people engaged in collaborative activities. While there has been rapid development of new approaches and metrics in this field, the challenging question of validity (how well insights derived from social networks agree with reality) is often difficult to address. We propose the use of several R packages to generate interactive surveys that are specifically well suited for validating social network analyses. Using our web-based survey application, we were able to validate the results of applying community-detection algorithms to infer the organizational structure of software developers contributing to open-source projects.</p>
</div>
</a>
<a href="articles/RJ-2015-021/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 30, 2015</div>
<div class="dt-authors">
<div class="dt-author">Isabelle Charlier</div>
<div class="dt-author">Davy Paindaveine</div>
<div class="dt-author">Jrme Saracco</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>QuantifQuantile: An R Package for Performing Quantile Regression through Optimal Quantization</h2>
<div class="dt-tags"></div>
<p>In quantile regression, various quantiles of a response variable $Y$ are modelled as functions of covariates (rather than its mean). An important application is the construction of reference curves/surfaces and conditional prediction intervals for $Y$. Recently, a nonparametric quantile regression method based on the concept of optimal quantization was proposed. This method competes very well with $k$-nearest neighbor, kernel, and spline methods. In this paper, we describe an R package, called *QuantifQuantile*, that allows to perform quantization-based quantile regression. We describe the various functions of the package and provide examples.</p>
</div>
</a>
<a href="articles/RJ-2015-026/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 23, 2015</div>
<div class="dt-authors">
<div class="dt-author">Evelyne Vigneau</div>
<div class="dt-author">Mingkun Chen</div>
<div class="dt-author">El Mostafa Qannari</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ClustVarLV: An R Package for the Clustering of Variables Around Latent Variables</h2>
<div class="dt-tags"></div>
<p>The clustering of variables is a strategy for deciphering the underlying structure of a data set. Adopting an exploratory data analysis point of view, the Clustering of Variables around Latent Variables (CLV) approach has been proposed by @{Vigneau(2003)}. Based on a family of optimization criteria, the CLV approach is adaptable to many situations. In particular, constraints may be introduced in order to take account of additional information about the observations and/or the variables. In this paper, the CLV method is depicted and the R package *ClustVarLV* including a set of functions developed so far within this framework is introduced. Considering successively different types of situations, the underlying CLV criteria are detailed and the various functions of the package are illustrated using real case studies.</p>
</div>
</a>
<a href="articles/RJ-2016-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 14, 2015</div>
<div class="dt-authors">
<div class="dt-author">Jakob W. Messner</div>
<div class="dt-author">Georg J. Mayr</div>
<div class="dt-author">Achim Zeileis</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Heteroscedastic Censored and Truncated Regression with crch</h2>
<div class="dt-tags"></div>
<p>The *crch* package provides functions for maximum likelihood estimation of censored or truncated regression models with conditional heteroscedasticity along with suitable standard methods to summarize the fitted models and compute predictions, residuals, etc. The supported distributions include left- or right-censored or truncated Gaussian, logistic, or student-t distributions with potentially different sets of regressors for modeling the conditional location and scale. The models and their R implementation are introduced and illustrated by numerical weather prediction tasks using precipitation data for Innsbruck (Austria).</p>
</div>
</a>
<a href="articles/RJ-2015-031/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2015</div>
<div class="dt-authors">
<div class="dt-author">Juhui Wang</div>
<div class="dt-author">Robert Faivre</div>
<div class="dt-author">Herv Richard</div>
<div class="dt-author">Herv Monod</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>mtk: A General-Purpose and Extensible R Environment for Uncertainty and Sensitivity Analyses of Numerical Experiments</h2>
<div class="dt-tags"></div>
<p>Along with increased complexity of the models used for scientific
activities and engineering come diverse and greater uncertainties.
Today, effectively quantifying the uncertainties contained in a model
appears to be more important than ever. Scientific fellows know how
serious it is to calibrate their model in a robust way, and
decision-makers describe how critical it is to keep the best effort to
reduce the uncertainties about the model. Effectively accessing the
uncertainties about the model requires mastering all the tasks
involved in the numerical experiments, from optimizing the
experimental design to managing the very time consuming aspect of
model simulation and choosing the adequate indicators and analysis
methods.\
In this paper, we present an open framework for organizing the
complexity associated with numerical model simulation and analyses.
Named *mtk* (Mexico Toolkit), the developed system aims at providing
practitioners from different disciplines with a systematic and easy
way to compare and to find the best method to effectively uncover and
quantify the uncertainties contained in the model and further to
evaluate their impact on the performance of the model. Such
requirements imply that the system must be generic, universal,
homogeneous, and extensible. This paper discusses such an
implementation using the R scientific computing platform and
demonstrates its functionalities with examples from agricultural
modeling.\
The package *mtk* is of general purpose and easy to extend. Numerous
methods are already available in the actual release version, including
Fast, Sobol, Morris, Basic Monte-Carlo, Regression, LHS (Latin
Hypercube Sampling), PLMM (Polynomial Linear metamodel). Most of them
are compiled from available R packages with extension tools delivered
by package *mtk*.</p>
</div>
</a>
<a href="articles/RJ-2015-029/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 29, 2015</div>
<div class="dt-authors">
<div class="dt-author">Kangwon Seo</div>
<div class="dt-author">Rong Pan</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ALTopt: An R Package for Optimal Experimental Design of Accelerated Life Testing</h2>
<div class="dt-tags"></div>
<p>The R package *ALTopt* has been developed with the aim of creating and evaluating optimal experimental designs of censored accelerated life tests (ALTs). This package takes the generalized linear model approach to ALT planning, because this approach can easily handle censoring plans and derive information matrices for evaluating designs. Three types of optimality criteria are considered: *D*-optimality for model parameter estimation, *U*-optimality for reliability prediction at a single use condition, and *I*-optimality for reliability prediction over a region of use conditions. The Weibull distribution is assumed for failure time data and more than one stress factor can be specified in the package. Several graphical evaluation tools are also provided for the comparison of different ALT test plans.</p>
</div>
</a>
<a href="articles/RJ-2015-033/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 29, 2015</div>
<div class="dt-authors">
<div class="dt-author">Hideitsu Hino</div>
<div class="dt-author">Ken Takano</div>
<div class="dt-author">Noboru Murata</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>mmpp: A Package for Calculating Similarity and Distance Metrics for Simple and Marked Temporal Point Processes</h2>
<div class="dt-tags"></div>
<p>A simple temporal point process (SPP) is an important class of time series, where the sample realization of the process is solely composed of the times at which events occur. Particular examples of point process data are neuronal spike patterns or spike trains, and a large number of distance and similarity metrics for those data have been proposed. A marked point process (MPP) is an extension of a simple temporal point process, in which a certain vector valued mark is associated with each of the temporal points in the SPP. Analyses of MPPs are of practical importance because instances of MPPs include recordings of natural disasters such as earthquakes and tornadoes. In this paper, we introduce the R package *mmpp*, which implements a number of distance and similarity metrics for SPPs, and also extends those metrics for dealing with MPPs.</p>
</div>
</a>
<a href="articles/RJ-2015-027/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 16, 2015</div>
<div class="dt-authors">
<div class="dt-author">Francisco Charte</div>
<div class="dt-author">David Charte</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Working with Multilabel Datasets in R: The mldr Package</h2>
<div class="dt-tags"></div>
<p>Most classification algorithms deal with datasets which have a set of input features, the variables to be used as predictors, and only one output class, the variable to be predicted. However, in late years many scenarios in which the classifier has to work with several outputs have come to life. Automatic labeling of text documents, image annotation or protein classification are among them. Multilabel datasets are the product of these new needs, and they have many specific traits. The *mldr* package allows the user to load datasets of this kind, obtain their characteristics, produce specialized plots, and manipulate them. The goal is to provide the exploratory tools needed to analyze multilabel datasets, as well as the transformation and manipulation functions that will make possible to apply binary and multiclass classification models to this data or the development of new multilabel classifiers. Thanks to its integrated user interface, the exploratory functions will be available even to non-specialized R users.</p>
</div>
</a>
<a href="articles/RJ-2015-032/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 16, 2015</div>
<div class="dt-authors">
<div class="dt-author">Samuel E. Buttrey</div>
<div class="dt-author">Lyn R. Whitaker</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>treeClust: An R Package for Tree-Based Clustering Dissimilarities</h2>
<div class="dt-tags"></div>
<p>This paper describes *treeClust*, an R package that produces dissimilarities useful for clustering. These dissimilarities arise from a set of classification or regression trees, one with each variable in the data acting in turn as a the response, and all others as predictors. This use of trees produces dissimilarities that are insensitive to scaling, benefit from automatic variable selection, and appear to perform well. The software allows a number of options to be set, affecting the set of objects returned in the call; the user can also specify a clustering algorithm and, optionally, return only the clustering vector. The package can also generate a numeric data set whose inter-point distances relate to the *treeClust* ones; such a numeric data set can be much smaller than the vector of inter-point dissimilarities, a useful feature in big data sets.</p>
</div>
</a>
<a href="articles/RJ-2015-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 9, 2015</div>
<div class="dt-authors">
<div class="dt-author">Moudud Alam</div>
<div class="dt-author">Lars rd</div>
<div class="dt-author">Xia Shen</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Fitting Conditional and Simultaneous Autoregressive Spatial Models in hglm</h2>
<div class="dt-tags"></div>
<p>We present a new version ($\geqslant 2.0$) of the *hglm* package for fitting hierarchical generalized linear models (HGLMs) with spatially correlated random effects. `CAR()` and `SAR()` families for conditional and simultaneous autoregressive random effects were implemented. Eigen decomposition of the matrix describing the spatial structure (e.g., the neighborhood matrix) was used to transform the CAR/SAR random effects into an independent, but heteroscedastic, Gaussian random effect. A linear predictor is fitted for the random effect variance to estimate the parameters in the CAR and SAR models. This gives a computationally efficient algorithm for moderately sized problems.</p>
</div>
</a>
<a href="articles/RJ-2015-020/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 5, 2015</div>
<div class="dt-authors">
<div class="dt-author">Bent Nielsen</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>apc: An R Package for Age-Period-Cohort Analysis</h2>
<div class="dt-tags"></div>
<p>The *apc* package includes functions for age-period-cohort analysis based on the canonical parametrisation of @KuangNielsenNielsen2008a. The package includes functions for organizing the data, descriptive plots, a deviance table, estimation of (sub-models of) the age-period-cohort model, a plot for specification testing, plots of estimated parameters, and sub-sample analysis.</p>
</div>
</a>
<a href="articles/RJ-2015-025/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 5, 2015</div>
<div class="dt-authors">
<div class="dt-author">Kuo-Jung Lee</div>
<div class="dt-author">Ray-Bing Chen</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>BSGS: Bayesian Sparse Group Selection</h2>
<div class="dt-tags"></div>
<p>An R package *BSGS* is provided for the integration of Bayesian variable and sparse group selection separately proposed by @Chen:2011 and @Chen:2014 for variable selection problems, even in the cases of large $p$ and small $n$. This package is designed for variable selection problems including the identification of the important groups of variables and the active variables within the important groups. This article introduces the functions in the *BSGS* package that can be used to perform sparse group selection as well as variable selection through simulation studies and real data.</p>
</div>
</a>
<a href="articles/RJ-2015-023/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 29, 2015</div>
<div class="dt-authors">
<div class="dt-author">Pablo J. Villacorta</div>
<div class="dt-author">Jos A. Sez</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SRCS: Statistical Ranking Color Scheme for Visualizing Parameterized Multiple Pairwise Comparisons with R</h2>
<div class="dt-tags"></div>
<p>The problem of comparing a new solution method against existing ones to find statistically significant differences arises very often in sciences and engineering. When the problem instance being solved is defined by several parameters, assessing a number of methods with respect to many problem configurations simultaneously becomes a hard task. Some visualization technique is required for presenting a large number of statistical significance results in an easily interpretable way. Here we review an existing color-based approach called Statistical Ranking Color Scheme (SRCS) for displaying the results of multiple pairwise statistical comparisons between several methods assessed separately on a number of problem configurations. We introduce an R package implementing SRCS, which performs all the pairwise statistical tests from user data and generates customizable plots. We demonstrate its applicability on two examples from the areas of dynamic optimization and machine learning, in which several algorithms are compared on many problem instances, each defined by a combination of parameters.</p>
</div>
</a>
<a href="articles/RJ-2015-030/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 29, 2015</div>
<div class="dt-authors">
<div class="dt-author">Matthew A. Nunes</div>
<div class="dt-author">Dennis Prangle</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>abctools: An R Package for Tuning Approximate Bayesian Computation Analyses</h2>
<div class="dt-tags"></div>
<p>Approximate Bayesian computation (ABC) is a popular family of
algorithms which perform approximate parameter inference when
numerical evaluation of the likelihood function is not possible but
data can be simulated from the model. They return a sample of
parameter values which produce simulations close to the observed
dataset. A standard approach is to reduce the simulated and observed
datasets to vectors of *summary statistics* and accept when the
difference between these is below a specified threshold. ABC can also
be adapted to perform model choice.\
In this article, we present a new software package for R, *abctools*
which provides methods for tuning ABC algorithms. This includes recent
dimension reduction algorithms to tune the choice of summary
statistics, and coverage methods to tune the choice of threshold. We
provide several illustrations of these routines on applications taken
from the ABC literature.</p>
</div>
</a>
<a href="articles/RJ-2015-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 18, 2015</div>
<div class="dt-authors">
<div class="dt-author">Fang Liu</div>
<div class="dt-author">Yunchuan Kong</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>zoib: An R Package for Bayesian Inference for Beta Regression and Zero/One Inflated Beta Regression</h2>
<div class="dt-tags"></div>
<p>The beta distribution is a versatile function that accommodates a broad range of probability distribution shapes. Beta regression based on the beta distribution can be used to model a response variable $y$ that takes values in open unit interval $(0, 1)$. Zero/one inflated beta (ZOIB) regression models can be applied when $y$ takes values from closed unit interval $[0,1]$. The ZOIB model is based a piecewise distribution that accounts for the probability mass at 0 and 1, in addition to the probability density within $(0, 1)$. This paper introduces an R package -- *zoib* that provides Bayesian inferences for a class of ZOIB models. The statistical methodology underlying the *zoib* package is discussed, the functions covered by the package are outlined, and the usage of the package is illustrated with three examples of different data and model types. The package is comprehensive and versatile in that it can model data with or without inflation at 0 or 1, accommodate clustered and correlated data via latent variables, perform penalized regression as needed, and allow for model comparison via the computation of the DIC criterion.</p>
</div>
</a>
<a href="articles/RJ-2015-028/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 30, 2015</div>
<div class="dt-authors">
<div class="dt-author">Richard Valliant</div>
<div class="dt-author">Jill A. Dever</div>
<div class="dt-author">Frauke Kreuter</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>PracTools: Computations for Design of Finite Population Samples</h2>
<div class="dt-tags"></div>
<p>PracTools is an R package with functions that compute sample sizes for various types of finite population sampling designs when totals or means are estimated. One-, two-, and three-stage designs are covered as well as allocations for stratified sampling and probability proportional to size sampling. Sample allocations can be computed that minimize the variance of an estimator subject to a budget constraint or that minimize cost subject to a precision constraint. The package also contains some specialized functions for estimating variance components and design effects. Several finite populations are included that are useful for classroom instruction.</p>
</div>
</a>
<a href="articles/RJ-2015-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 25, 2015</div>
<div class="dt-authors">
<div class="dt-author">Stefan Rdiger</div>
<div class="dt-author">Micha Burdukiewicz</div>
<div class="dt-author">Konstantin Blagodatskikh</div>
<div class="dt-author">Michael Jahn</div>
<div class="dt-author">Peter Schierack</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>R as an Environment for Reproducible Analysis of DNA Amplification Experiments</h2>
<div class="dt-tags"></div>
<p>There is an ever-increasing number of applications, which use quantitative PCR (qPCR) or digital PCR (dPCR) to elicit fundamentals of biological processes. Moreover, quantitative isothermal amplification (qIA) methods have become more prominent in life sciences and point-of-care-diagnostics. Additionally, the analysis of melting data is essential during many experiments. Several software packages have been developed for the analysis of such datasets. In most cases, the software is either distributed as closed source software or as monolithic block with little freedom to perform highly customized analysis procedures. We argue, among others, that R is an excellent foundation for reproducible and transparent data analysis in a highly customizable cross-platform environment. However, for novices it is often challenging to master R or learn capabilities of the vast number of packages available. In the paper, we describe exemplary workflows for the analysis of qPCR, qIA or dPCR experiments including the analysis of melting curve data. Our analysis relies entirely on R packages available from public repositories. Additionally, we provide information related to standardized and reproducible research.</p>
</div>
</a>
<a href="articles/RJ-2015-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 24, 2015</div>
<div class="dt-authors">
<div class="dt-author">Shawn T. O'Neil</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Implementing Persistent O(1) Stacks and Queues in R</h2>
<div class="dt-tags"></div>
<p>True to their functional roots, most R functions are side-effect-free, and users expect datatypes to be persistent. However, these semantics complicate the creation of efficient and dynamic data structures. Here, we describe the implementation of stack and queue data structures satisfying these conditions in R, available in the CRAN package *rstackdeque*. Guided by important work in purely functional languages, we look at both partially- and fully-persistent versions of queues, comparing their performance characteristics. Finally, we illustrate the usefulness of such dynamic structures with examples of generating and solving mazes.</p>
</div>
</a>
<a href="articles/RJ-2015-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2015</div>
<div class="dt-authors">
<div class="dt-author">Isabel Molina</div>
<div class="dt-author">Yolanda Marhuenda</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>sae: An R Package for Small Area Estimation</h2>
<div class="dt-tags"></div>
<p>We describe the R package *sae* for small area estimation. This package can be used to obtain model-based estimates for small areas based on a variety of models at the area and unit levels, along with basic direct and indirect estimates. Mean squared errors are estimated by analytical approximations in simple models and applying bootstrap procedures in more complex models. We describe the package functions and show how to use them through examples.</p>
</div>
</a>
<a href="articles/RJ-2015-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2015</div>
<div class="dt-authors">
<div class="dt-author">Belchin Kostov</div>
<div class="dt-author">Mnica Bcue-Bertaut</div>
<div class="dt-author">Franois Husson</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Correspondence Analysis on Generalised Aggregated Lexical Tables (CA-GALT) in the FactoMineR Package</h2>
<div class="dt-tags"></div>
<p>Correspondence analysis on generalised aggregated lexical tables (CA-GALT) is a method that generalizes classical CA-ALT to the case of several quantitative, categorical and mixed variables. It aims to establish a typology of the external variables and a typology of the events from their mutual relationships. In order to do so, the influence of external variables on the lexical choices is untangled cancelling the associations among them, and to avoid the instability issued from multicollinearity, they are substituted by their principal components. The `CaGalt` function, implemented in the *FactoMineR* package, provides numerous numerical and graphical outputs. Confidence ellipses are also provided to validate and improve the representation of words and variables. Although this methodology was developed mainly to give an answer to the problem of analyzing open-ended questions, it can be applied to any kind of frequency/contingency table with external variables.</p>
</div>
</a>
<a href="articles/RJ-2015-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2015</div>
<div class="dt-authors">
<div class="dt-author">John Muschelli</div>
<div class="dt-author">Elizabeth Sweeney</div>
<div class="dt-author">Martin Lindquist</div>
<div class="dt-author">Ciprian Crainiceanu</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>fslr: Connecting the FSL Software with R</h2>
<div class="dt-tags"></div>
<p>We present the package *fslr*, a set of R functions that interface with FSL (FMRIB Software Library), a commonly-used open-source software package for processing and analyzing neuroimaging data. The *fslr* package performs operations on '`nifti`' image objects in R using command-line functions from FSL, and returns R objects back to the user. *fslr* allows users to develop image processing and analysis pipelines based on FSL functionality while interfacing with the functionality provided by R. We present an example of the analysis of structural magnetic resonance images, which demonstrates how R users can leverage the functionality of FSL without switching to shell commands.</p>
</div>
</a>
<a href="articles/RJ-2015-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 29, 2015</div>
<div class="dt-authors">
<div class="dt-author">Alexander Kowarik</div>
<div class="dt-author">Bernhard Meindl</div>
<div class="dt-author">Matthias Templ</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>sparkTable: Generating Graphical Tables for Websites and Documents with R</h2>
<div class="dt-tags"></div>
<p>Visual analysis of data is important to understand the main
characteristics, main trends and relationships in data sets and it can
be used to assess the data quality. Using the R package *sparkTable*,
statistical tables holding quantitative information can be enhanced by
including spark-type graphs such as sparklines
![image](figures/line.png){width="1.2cm" height="1em"} and sparkbars
![image](figures/bar.png){width="1.2cm" height="1em"}.\
These kind of graphics are well-known in literature and are considered
as simple, intense and illustrative graphs that are small enough to
fit in a single line. Thus, they can easily enrich tables and texts
with additional information in a comprehensive visual way.\
The R package *sparkTable* uses a clean S4 class design and provides
methods to create different types of sparkgraphs that can be used in
websites, presentations and documents. We also implemented an easy way
for non-experts to create highly complex tables. In this case,
graphical parameters can be interactively changed, variables can be
sorted, graphs can be added and removed in an interactive manner.
Thereby it is possible to produce custom-tailored graphical tables --
standard tables that are enriched with graphs -- that can be displayed
in a browser and exported to various formats.</p>
</div>
</a>
<a href="articles/RJ-2015-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 29, 2015</div>
<div class="dt-authors">
<div class="dt-author">Yixuan Qiu</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>showtext: Using System Fonts in R Graphics</h2>
<div class="dt-tags"></div>
<p>This article introduces the *showtext* package that makes it easy to use system fonts in R graphics. Unlike other methods to embed fonts into graphics, *showtext* converts text into raster images or polygons, and then adds them to the plot canvas. This method produces platform-independent image files that do not rely on the fonts that create them. It supports a large number of font formats and R graphics devices, and meanwhile provides convenient features such as using web fonts and integrating with *knitr*. This article provides an elaborate introduction to the *showtext* package, including its design, usage, and examples.</p>
</div>
</a>
<a href="articles/RJ-2015-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 11, 2015</div>
<div class="dt-authors">
<div class="dt-author">Russell V.Lenth</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Estimability Tools for Package Developers</h2>
<div class="dt-tags"></div>
<p>When a linear model is rank-deficient, then predictions based on that model become questionable because not all predictions are uniquely estimable. However, some of them are, and the *estimability* package provides tools that package developers can use to tell which is which. With the use of these tools, a model object's `predict` method could return estimable predictions as-is while flagging non-estimable ones in some way, so that the user can know which predictions to believe. The *estimability* package also provides, as a demonstration, an estimability-enhanced `epredict` method to use in place of `predict` for models fitted using the *stats* package.</p>
</div>
</a>
<a href="articles/RJ-2015-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 6, 2015</div>
<div class="dt-authors">
<div class="dt-author">Eric Hare</div>
<div class="dt-author">Andreas Buja</div>
<div class="dt-author">Heike Hofmann</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Manipulation of Discrete Random Variables with discreteRV</h2>
<div class="dt-tags"></div>
<p>A prominent issue in statistics education is the sometimes large disparity between the theoretical and the computational coursework. *discreteRV* is an R package for manipulation of discrete random variables which uses clean and familiar syntax similar to the mathematical notation in introductory probability courses. The package offers functions that are simple enough for users with little experience with statistical programming, but has more advanced features which are suitable for a large number of more complex applications. In this paper, we introduce and motivate *discreteRV*, describe its functionality, and provide reproducible examples illustrating its use.</p>
</div>
</a>
<a href="articles/RJ-2015-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 23, 2015</div>
<div class="dt-authors">
<div class="dt-author">Sebastian Calonico</div>
<div class="dt-author">Matias D. Cattaneo</div>
<div class="dt-author">Roco Titiunik</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>rdrobust: An R Package for Robust Nonparametric Inference in Regression-Discontinuity Designs</h2>
<div class="dt-tags"></div>
<p>This article describes the R package *rdrobust*, which provides data-driven graphical and inference procedures for RD designs. The package includes three main functions: `rdrobust`, `rdbwselect` and `rdplot`. The first function (`rdrobust`) implements conventional local-polynomial RD treatment effect point estimators and confidence intervals, as well as robust bias-corrected confidence intervals, for average treatment effects at the cutoff. This function covers sharp RD, sharp kink RD, fuzzy RD and fuzzy kink RD designs, among other possibilities. The second function (`rdbwselect`) implements several bandwidth selectors proposed in the RD literature. The third function (`rdplot`) provides data-driven optimal choices of evenly-spaced and quantile-spaced partition sizes, which are used to implement several data-driven RD plots.</p>
</div>
</a>
<a href="articles/RJ-2015-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 23, 2015</div>
<div class="dt-authors">
<div class="dt-author">Antonio Arcos</div>
<div class="dt-author">David Molina</div>
<div class="dt-author">Maria Giovanna Rannalli</div>
<div class="dt-author">Mara del Mar Rueda</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Frames2: A Package for Estimation in Dual Frame Surveys</h2>
<div class="dt-tags"></div>
<p>Data from complex survey designs require special consideration with regard to estimation of finite population parameters and corresponding variance estimation procedures, as a consequence of significant departures from the simple random sampling assumption. In the past decade a number of statistical software packages have been developed to facilitate the analysis of complex survey data. All these statistical software packages are able to treat samples selected from one sampling frame containing all population units. Dual frame surveys are very useful when it is not possible to guarantee a complete coverage of the target population and may result in considerable cost savings over a single frame design with comparable precision. There are several estimators available in the statistical literature but no existing software covers dual frame estimation procedures. This gap is now filled by package *Frames2*. In this paper we highlight the main features of the package. The package includes the main estimators in dual frame surveys and also provides interval confidence estimation.</p>
</div>
</a>
<a href="articles/RJ-2015-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 23, 2015</div>
<div class="dt-authors">
<div class="dt-author">Robin K. S. Hankin</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The Complex Multivariate Gaussian Distribution</h2>
<div class="dt-tags"></div>
<p>Here I introduce package *cmvnorm*, a complex generalization of the *mvtnorm* package. A complex generalization of the Gaussian process is suggested and numerical results presented using the package. An application in the context of approximating the Weierstrass $\sigma$-function using a complex Gaussian process is given.</p>
</div>
</a>
<a href="articles/RJ-2015-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 23, 2015</div>
<div class="dt-authors">
<div class="dt-author">Paul Murrell</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The gridGraphics Package</h2>
<div class="dt-tags"></div>
<p>The *gridGraphics* package provides a function, `grid.echo()`, that can be used to convert a plot drawn with the *graphics* package to a visually identical plot drawn using *grid*. This conversion provides access to a variety of *grid* tools for making customisations and additions to the plot that are not possible with the *graphics* package.</p>
</div>
</a>
<a href="articles/RJ-2015-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 7, 2015</div>
<div class="dt-authors">
<div class="dt-author">Guy J. Abel</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>fanplot: An R Package for Visualising Sequential Distributions</h2>
<div class="dt-tags"></div>
<p>Fan charts, first developed by the Bank of England in 1996, have become a standard method for visualising forecasts with uncertainty. Using shading fan charts focus the attention towards the whole distribution away from a single central measure. This article describes the basics of plotting fan charts using an R add-on package alongside some additional methods for displaying sequential distributions. Examples are based on distributions of both estimated parameters from a time series model and future values with uncertainty.</p>
</div>
</a>
<a href="articles/RJ-2015-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 30, 2015</div>
<div class="dt-authors">
<div class="dt-author">Michael Baumgartner</div>
<div class="dt-author">Alrik Thiem</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Identifying Complex Causal Dependencies in Configurational Data with Coincidence Analysis</h2>
<div class="dt-tags"></div>
<p>We present cna, a package for performing Coincidence Analysis (CNA). CNA is a configurational comparative method for the identification of complex causal dependencies---in particular, causal chains and common cause structures---in configurational data. After a brief introduction to the method's theoretical background and main algorithmic ideas, we demonstrate the use of the package by means of an artificial and a real-life data set. Moreover, we outline planned enhancements of the package that will further increase its applicability.</p>
</div>
</a>
<a href="articles/RJ-2015-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 4, 2015</div>
<div class="dt-authors">
<div class="dt-author">Daniel Osorio</div>
<div class="dt-author">Paola Rondn-Villarreal</div>
<div class="dt-author">Rodrigo Torres</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Peptides: A Package for Data Mining of Antimicrobial Peptides</h2>
<div class="dt-tags"></div>
<p>Antimicrobial peptides (AMP) are a promising source of antibiotics with a broad spectrum activity against bacteria and low incidence of developing resistance. The mechanism by which an AMP executes its function depends on a set of computable physicochemical properties from the amino acid sequence. The *Peptides* package was designed to allow the quick and easy computation of ten structural characteristics own of the antimicrobial peptides, with the aim of generating data to increase the accuracy in classification and design of new amino acid sequences. Moreover, the options to read and plot XVG output files from GROMACS molecular dynamics package are included.</p>
</div>
</a>
<a href="articles/RJ-2014-028/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 9, 2015</div>
<div class="dt-authors">
<div class="dt-author">Paola Rebora</div>
<div class="dt-author">Agus Salim</div>
<div class="dt-author">Marie Reilly</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>bshazard: A Flexible Tool for Nonparametric Smoothing of the Hazard Function</h2>
<div class="dt-tags"></div>
<p>The hazard function is a key component in the inferential process in survival analysis and relevant for describing the pattern of failures. However, it is rarely shown in research papers due to the difficulties in nonparametric estimation. We developed the *bshazard* package to facilitate the computation of a nonparametric estimate of the hazard function, with data-driven smoothing. The method accounts for left truncation, right censoring and possible covariates. B-splines are used to estimate the shape of the hazard within the generalized linear mixed models framework. Smoothness is controlled by imposing an autoregressive structure on the baseline hazard coefficients. This perspective allows an 'automatic' smoothing by avoiding the need to choose the smoothing parameter, which is estimated from the data as a dispersion parameter. A simulation study demonstrates the capability of our software and an application to estimate the hazard of Non-Hodgkin's lymphoma in Swedish population data shows its potential.</p>
</div>
</a>
<a href="articles/RJ-2014-030/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 9, 2015</div>
<div class="dt-authors">
<div class="dt-author">Rune Hoff</div>
<div class="dt-author">Jon Michael Gran</div>
<div class="dt-author">Daniel Farewell</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Farewell's Linear Increments Model for Missing Data: The FLIM Package</h2>
<div class="dt-tags"></div>
<p>Missing data is common in longitudinal studies. We present a package for Farewell's Linear Increments Model for Missing Data (the *FLIM* package), which can be used to fit linear models for observed increments of longitudinal processes and impute missing data. The method is valid for data with regular observation patterns. The end result is a list of fitted models and a hypothetical complete dataset corresponding to the data we might have observed had individuals not been missing. The *FLIM* package may also be applied to longitudinal studies for causal analysis, by considering counterfactual data as missing data - for instance to compare the effect of different treatments when only data from observational studies are available. The aim of this article is to give an introduction to the *FLIM* package and to demonstrate how the package can be applied.</p>
</div>
</a>
<a href="articles/RJ-2014-024/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 4, 2015</div>
<div class="dt-authors">
<div class="dt-author">Dane R. Van Domelen</div>
<div class="dt-author">W. Stephen Pittard</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Flexible R Functions for Processing Accelerometer Data, with Emphasis on NHANES 2003--2006</h2>
<div class="dt-tags"></div>
<p>Accelerometers are a valuable tool for measuring physical activity (PA) in epidemiological studies. However, considerable processing is needed to convert time-series accelerometer data into meaningful variables for statistical analysis. This article describes two recently developed R packages for processing accelerometer data. The package *accelerometry* contains functions for performing various data processing procedures, such as identifying periods of non-wear time and bouts of activity. The functions are flexible, computationally efficient, and compatible with uniaxial or triaxial data. The package *nhanesaccel* is specifically for processing data from the National Health and Nutrition Examination Survey (NHANES), years 2003--2006. Its primary function generates measures of PA volume, intensity, frequency, and patterns according to user-specified data processing methods. This function can process the NHANES 2003--2006 dataset in under one minute, which is a drastic improvement over existing software. This article highlights important features of packages *accelerometry* and *nhanesaccel* and demonstrates typical usage for PA researchers.</p>
</div>
</a>
<a href="articles/RJ-2014-026/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 4, 2015</div>
<div class="dt-authors">
<div class="dt-author">John Hughes</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ngspatial: A Package for Fitting the Centered Autologistic and Sparse Spatial Generalized Linear Mixed Models for Areal Data</h2>
<div class="dt-tags"></div>
<p>Two important recent advances in areal modeling are the centered autologistic model and the sparse spatial generalized linear mixed model (SGLMM), both of which are reparameterizations of traditional models. The reparameterizations improve regression inference by alleviating spatial confounding, and the sparse SGLMM also greatly speeds computing by reducing the dimension of the spatial random effects. Package *ngspatial* ('ng' = non-Gaussian) provides routines for fitting these new models. The package supports composite likelihood and Bayesian inference for the centered autologistic model, and Bayesian inference for the sparse SGLMM.</p>
</div>
</a>
<a href="articles/RJ-2014-029/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 4, 2015</div>
<div class="dt-authors">
<div class="dt-author">Ben Divide de Oliveira Batista</div>
<div class="dt-author">Daniel Furtado Ferreira</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SMR: An R Package for Computing the Externally Studentized Normal Midrange Distribution</h2>
<div class="dt-tags"></div>
<p>The main purpose of this paper is to present the main algorithms underlining the construction and implementation of the *SMR* package, whose aim is to compute studentized normal midrange distribution. Details on the externally studentized normal midrange and standardized normal midrange distributions are also given. The package follows the same structure as the probability functions implemented in R. That is: the probability density function (`dSMR`), the cumulative distribution function (`pSMR`), the quantile function (`qSMR`) and the random number generating function (`rSMR`). Pseudocode and illustrative examples of how to use the package are presented.</p>
</div>
</a>
<a href="articles/RJ-2014-031/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 4, 2015</div>
<div class="dt-authors">
<div class="dt-author">Selcuk Korkmaz</div>
<div class="dt-author">Dincer Goksuluk</div>
<div class="dt-author">Gokmen Zararsiz</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>MVN: An R Package for Assessing Multivariate Normality</h2>
<div class="dt-tags"></div>
<p>Assessing the assumption of multivariate normality is required by many parametric multivariate statistical methods, such as MANOVA, linear discriminant analysis, principal component analysis, canonical correlation, etc. It is important to assess multivariate normality in order to proceed with such statistical methods. There are many analytical methods proposed for checking multivariate normality. However, deciding which method to use is a challenging process, since each method may give different results under certain conditions. Hence, we may say that there is no best method, which is valid under any condition, for normality checking. In addition to numerical results, it is very useful to use graphical methods to decide on multivariate normality. Combining the numerical results from several methods with graphical approaches can be useful and provide more reliable decisions. Here, we present an R package, *MVN*, to assess multivariate normality. It contains the three most widely used multivariate normality tests, including Mardia's, Henze-Zirkler's and Royston's, and graphical approaches, including chi-square Q-Q, perspective and contour plots. It also includes two multivariate outlier detection methods, which are based on robust Mahalanobis distances. Moreover, this package offers functions to check the univariate normality of marginal distributions through both tests and plots. Furthermore, especially for non-R users, we provide a user-friendly web application of the package. This application is available at &lt;http://www.biosoft.hacettepe.edu.tr/MVN/&gt;.</p>
</div>
</a>
<a href="articles/RJ-2014-032/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 4, 2015</div>
<div class="dt-authors">
<div class="dt-author">Aiora Zabala</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>qmethod: A Package to Explore Human Perspectives Using Q Methodology</h2>
<div class="dt-tags"></div>
<p>Q is a methodology to explore the distinct subjective perspectives that exist within a group. It is used increasingly across disciplines. The methodology is semi-qualitative and the data are analysed using data reduction methods to discern the existing patterns of thought. This package is the first to perform Q analysis in R, and it provides many advantages to the existing software: namely, it is fully cross-platform, the algorithms can be transparently examined, it provides results in a clearly structured and tabulated form ready for further exploration and modelling, it produces a graphical summary of the results, and it generates a more concise report of the distinguishing and consensus statements. This paper introduces the methodology and explains how to use the package, its advantages as well as its limitations. I illustrate the main functions with a dataset on value patterns about democracy.</p>
</div>
</a>
<a href="articles/RJ-2014-033/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 4, 2015</div>
<div class="dt-authors">
<div class="dt-author">Fang Liu</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>gset: An R Package for Exact Sequential Test of Equivalence Hypothesis Based on Bivariate Non-Central t-Statistics</h2>
<div class="dt-tags"></div>
<p>The R package *gset* calculates equivalence and futility boundaries based on the exact bivariate non-central $t$ test statistics. It is the first R package that targets specifically at the group sequential test of equivalence hypotheses. The exact test approach adopted by *gset* neither assumes the large-sample normality of the test statistics nor ignores the contribution to the overall Type I error rate from rejecting one out of the two one-sided hypotheses under a null value. The features of *gset* include: error spending functions, computation of equivalence boundaries and futility boundaries, either binding or nonbinding, depiction of stagewise boundary plots, and operating characteristics of a given group sequential design including empirical Type I error rate, empirical power, expected sample size, and probability of stopping at an interim look due to equivalence or futility.</p>
</div>
</a>
<a href="articles/RJ-2014-027/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 24, 2014</div>
<div class="dt-authors">
<div class="dt-author">Irene Castro-Conde</div>
<div class="dt-author">Jacobo de Ua-lvarez</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>sgof: An R Package for Multiple Testing Problems</h2>
<div class="dt-tags"></div>
<p>In this paper we present a new R package called *sgof* for multiple hypothesis testing. The principal aim of this package is to implement SGoF-type multiple testing methods, known to be more powerful than the classical false discovery rate (FDR) and family-wise error rate (FWER) based methods in certain situations, particularly when the number of tests is large. This package includes Binomial and Conservative SGoF and the Bayesian and Beta-Binomial SGoF multiple testing procedures, which are adaptations of the original SGoF method to the Bayesian setting and to possibly correlated tests, respectively. The *sgof* package also implements the Benjamini-Hochberg and Benjamini-Yekutieli FDR controlling procedures. For each method the package provides (among other things) the number of rejected null hypotheses, estimation of the corresponding FDR, and the set of adjusted $p$values. Some automatic plots of interest are implemented too. Two real data examples are used to illustrate how *sgof* works.</p>
</div>
</a>
<a href="articles/RJ-2014-020/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 13, 2014</div>
<div class="dt-authors">
<div class="dt-author">Andrea Stocco</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Coordinate-Based Meta-Analysis of fMRI Studies with R</h2>
<div class="dt-tags"></div>
<p>This paper outlines how to conduct a simple meta-analysis of neuroimaging foci of activation in R. In particular, the first part of this paper reviews the nature of fMRI data, and presents a brief overview of the existing packages that can be used to analyze fMRI data in R. The second part illustrates how to handle fMRI data by showing how to visualize the results of different neuroimaging studies in a so-called orthographic view, where the spatial distribution of the foci of activation from different fMRI studies can be inspected visually.</p>
</div>
</a>
<a href="articles/RJ-2014-023/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 30, 2014</div>
<div class="dt-authors">
<div class="dt-author">Michael J. Grayling</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>phaseR: An R Package for Phase Plane Analysis of Autonomous ODE Systems</h2>
<div class="dt-tags"></div>
<p>When modelling physical systems, analysts will frequently be confronted by differential equations which cannot be solved analytically. In this instance, numerical integration will usually be the only way forward. However, for autonomous systems of ordinary differential equations (ODEs) in one or two dimensions, it is possible to employ an instructive qualitative analysis foregoing this requirement, using so-called phase plane methods. Moreover, this qualitative analysis can even prove to be highly useful for systems that can be solved analytically, or will be solved numerically anyway. The package *phaseR* allows the user to perform such phase plane analyses: determining the stability of any equilibrium points easily, and producing informative plots.</p>
</div>
</a>
<a href="articles/RJ-2014-025/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 30, 2014</div>
<div class="dt-authors">
<div class="dt-author">Kieran Alden</div>
<div class="dt-author">Mark Read</div>
<div class="dt-author">Paul Andrews</div>
<div class="dt-author">Jon Timmis</div>
<div class="dt-author">Mark Coles</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Applying spartan to Understand Parameter Uncertainty in Simulations</h2>
<div class="dt-tags"></div>
<p>In attempts to further understand the dynamics of complex systems, the application of computer simulation is becoming increasingly prevalent. Whereas a great deal of focus has been placed in the development of software tools that aid researchers develop simulations, similar focus has not been applied in the creation of tools that perform a rigorous statistical analysis of results generated through simulation: vital in understanding how these results offer an insight into the captured system. This encouraged us to develop *spartan*, a package of statistical techniques designed to assist researchers in understanding the relationship between their simulation and the real system. Previously we have described each technique within *spartan* in detail, with an accompanying immunology case study examining the development of lymphoid tissue. Here we provide a practical introduction to the package, demonstrating how each technique is run in R, to assist researchers in integrating this package alongside their chosen simulation platform.</p>
</div>
</a>
<a href="articles/RJ-2014-022/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 28, 2014</div>
<div class="dt-authors">
<div class="dt-author">Jonathan Zhang</div>
<div class="dt-author">Nancy Heckman</div>
<div class="dt-author">Davor Cubranic</div>
<div class="dt-author">Joel G. Kingsolver</div>
<div class="dt-author">J.S. Marron</div>
<div class="dt-author">Travis L. Gaydos</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Prinsimp</h2>
<div class="dt-tags"></div>
<p>Principal Components Analysis (PCA) is a common way to study the sources of variation in a high-dimensional data set. Typically, the leading principal components are used to understand the variation in the data or to reduce the dimension of the data for subsequent analysis. The remaining principal components are ignored since they explain little of the variation in the data. However, the space spanned by the low variation principal components may contain interesting structure, structure that PCA cannot find. *Prinsimp* is an R package that looks for interesting structure of low variability. "Interesting" is defined in terms of a simplicity measure. Looking for interpretable structure in a low variability space has particular importance in evolutionary biology, where such structure can signify the existence of a genetic constraint.</p>
</div>
</a>
<a href="articles/RJ-2014-021/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 26, 2014</div>
<div class="dt-authors">
<div class="dt-author">Jimmy Oh</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Automatic Conversion of Tables to LongForm Dataframes</h2>
<div class="dt-tags"></div>
<p>*TableToLongForm* automatically converts hierarchical Tables intended for a human reader into a simple LongForm dataframe that is machine readable, making it easier to access and use the data for analysis. It does this by recognising positional cues present in the hierarchical Table (which would normally be interpreted visually by the human brain) to decompose, then reconstruct the data into a LongForm dataframe. The article motivates the benefit of such a conversion with an example Table, followed by a short user manual, which includes a comparison between the simple one argument call to `TableToLongForm`, with code for an equivalent manual conversion. The article then explores the types of Tables the package can convert by providing a gallery of all recognised patterns. It finishes with a discussion of available diagnostic methods and future work.</p>
</div>
</a>
<a href="articles/RJ-2014-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 16, 2014</div>
<div class="dt-authors">
<div class="dt-author">Matthew A. Nunes</div>
<div class="dt-author">Sarah L. Taylor</div>
<div class="dt-author">Idris A. Eckley</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>A Multiscale Test of Spatial Stationarity for Textured Images in R</h2>
<div class="dt-tags"></div>
<p>The ability to automatically identify areas of homogeneous texture present within a greyscale image is an important feature of image processing algorithms. This article describes the R package ***LS2Wstat*** which employs a recent wavelet-based test of stationarity for locally stationary random fields to assess such spatial homogeneity. By embedding this test within a quadtree image segmentation procedure we are also able to identify texture regions within an image.</p>
</div>
</a>
<a href="articles/RJ-2014-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 16, 2014</div>
<div class="dt-authors">
<div class="dt-author">Nicola Lunardon</div>
<div class="dt-author">Giovanna Menardi</div>
<div class="dt-author">Nicola Torelli</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ROSE: A Package for Binary Imbalanced Learning</h2>
<div class="dt-tags"></div>
<p>The *ROSE* package provides functions to deal with binary classification problems in the presence of imbalanced classes. Artificial balanced samples are generated according to a smoothed bootstrap approach and allow for aiding both the phases of estimation and accuracy evaluation of a binary classifier in the presence of a rare class. Functions that implement more traditional remedies for the class imbalance and different metrics to evaluate accuracy are also provided. These are estimated by holdout, bootstrap, or cross-validation methods.</p>
</div>
</a>
<a href="articles/RJ-2014-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 10, 2014</div>
<div class="dt-authors">
<div class="dt-author">Patrick Mair</div>
<div class="dt-author">Scott Chamberlain</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Web Technologies Task View</h2>
<div class="dt-tags"></div>
<p>This article presents the CRAN Task View on Web Technologies. We describe the most important aspects of Web Technologies and Web Scraping and list some of the packages that are currently available on CRAN. Finally, we plot the network of Web Technology related package dependencies.</p>
</div>
</a>
<a href="articles/RJ-2014-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 3, 2014</div>
<div class="dt-authors">
<div class="dt-author">John Muschelli</div>
<div class="dt-author">Elizabeth Sweeney</div>
<div class="dt-author">Ciprian Crainiceanu</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>brainR: Interactive 3 and 4D Images of High Resolution Neuroimage Data</h2>
<div class="dt-tags"></div>
<p>We provide software tools for displaying and publishing interactive 3-dimensional (3D) and 4-dimensional (4D) figures to html webpages, with examples of high-resolution brain imaging. Our framework is based in the R statistical software using the *rgl* package, a 3D graphics library. We build on this package to allow manipulation of figures including rotation and translation, zooming, coloring of brain substructures, adjusting transparency levels, and addition/or removal of brain structures. The need for better visualization tools of ultra high dimensional data is ever present; we are providing a clean, simple, web-based option. We also provide a package (*brainR*) for users to readily implement these tools.</p>
</div>
</a>
<a href="articles/RJ-2014-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2014</div>
<div class="dt-authors">
<div class="dt-author">Paul Murrell</div>
<div class="dt-author">Simon Potter</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The gridSVG Package</h2>
<div class="dt-tags"></div>
<p>The *gridSVG* package can be used to generate a *grid*-based R plot in an SVG format, with the ability to add special effects to the plot. The special effects include animation, interactivity, and advanced graphical features, such as masks and filters. This article provides a basic introduction to important functions in the *gridSVG* package and discusses the advantages and disadvantages of *gridSVG* compared to similar R packages.</p>
</div>
</a>
<a href="articles/RJ-2014-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 27, 2014</div>
<div class="dt-authors">
<div class="dt-author">Hai Qian</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>PivotalR: A Package for Machine Learning on Big Data</h2>
<div class="dt-tags"></div>
<p>*PivotalR* is an R package that provides a front-end to PostgreSQL and all PostgreSQL-like databases such as Pivotal Inc.'s Greenplum Database (GPDB), HAWQ. When running on the products of Pivotal Inc., *PivotalR* utilizes the full power of parallel computation and distributive storage, and thus gives the normal R user access to big data. *PivotalR* also provides an R wrapper for MADlib. MADlib is an open-source library for scalable in-database analytics. It provides data-parallel implementations of mathematical, statistical and machine-learning algorithms for structured and unstructured data. Thus *PivotalR* also enables the user to apply machine learning algorithms on big data.</p>
</div>
</a>
<a href="articles/RJ-2014-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 27, 2014</div>
<div class="dt-authors">
<div class="dt-author">Brandon M. Greenwell</div>
<div class="dt-author">Christine M. Schubert Kabban</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>investr: An R Package for Inverse Estimation</h2>
<div class="dt-tags"></div>
<p>Inverse estimation is a classical and well-known problem in regression. In simple terms, it involves the use of an observed value of the response to make inference on the corresponding unknown value of the explanatory variable. To our knowledge, however, statistical software is somewhat lacking the capabilities for analyzing these types of problems. In this paper, we introduce *investr* (which stands for **inv**erse **est**imation in **R**), a package for solving inverse estimation problems in both linear and nonlinear regression models.[^1]</p>
</div>
</a>
<a href="articles/RJ-2014-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 27, 2014</div>
<div class="dt-authors">
<div class="dt-author">Daniel Bottomly</div>
<div class="dt-author">Beth Wilmot</div>
<div class="dt-author">Shannon K. McWeeney</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>oligoMask: A Framework for Assessing and Removing the Effect of Genetic Variants on Microarray Probes</h2>
<div class="dt-tags"></div>
<p>As expression microarrays are typically designed relative to a reference genome, any individual genetic variant that overlaps a probe's genomic position can possibly cause a reduction in hybridization due to the probe no longer being a perfect match to a given sample's mRNA at that locus. If the samples or groups used in a microarray study differ in terms of genetic variants, the results of the microarray experiment can be negatively impacted. The *oligoMask* package is an R/SQLite framework which can utilize publicly available genetic variants and works in conjunction with the *oligo* package to read in the expression data and remove microarray probes which are likely to impact a given microarray experiment prior to analysis. Tools are provided for creating an SQLite database containing the probe and variant annotations and for performing the commonly used RMA preprocessing procedure for Affymetrix microarrays. The *oligoMask* package is freely available at &lt;https://github.com/dbottomly/oligoMask&gt;.</p>
</div>
</a>
<a href="articles/RJ-2014-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 26, 2014</div>
<div class="dt-authors">
<div class="dt-author">Mark P.J. van der Loo</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The stringdist Package for Approximate String Matching</h2>
<div class="dt-tags"></div>
<p>Comparing text strings in terms of distance functions is a common and fundamental task in many statistical text-processing applications. Thus far, string distance functionality has been somewhat scattered around R and its extension packages, leaving users with inconistent interfaces and encoding handling. The *stringdist* package was designed to offer a low-level interface to several popular string distance algorithms which have been re-implemented in C for this purpose. The package offers distances based on counting $q$-grams, edit-based distances, and some lesser known heuristic distance functions. Based on this functionality, the package also offers inexact matching equivalents of R's native exact matching functions `match` and `%in%`.</p>
</div>
</a>
<a href="articles/RJ-2014-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 19, 2014</div>
<div class="dt-authors">
<div class="dt-author">Dominik Wabersich</div>
<div class="dt-author">Joachim Vandekerckhove</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The RWiener Package: an R Package Providing Distribution Functions for the Wiener Diffusion Model</h2>
<div class="dt-tags"></div>
<p>We present the *RWiener* package that provides R functions for the Wiener diffusion model. The core of the package are the four distribution functions `dwiener`, `pwiener`, `qwiener` and `rwiener`, which use up-to-date methods, implemented in C, and provide fast and accurate computation of the density, distribution, and quantile function, as well as a random number generator for the Wiener diffusion model. We used the typical Wiener diffusion model with four parameters: boundary separation, non-decision time, initial bias and drift rate parameter. Beyond the distribution functions, we provide extended likelihood-based functions that can be used for parameter estimation and model selection. The package can be obtained via CRAN.</p>
</div>
</a>
<a href="articles/RJ-2014-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 19, 2014</div>
<div class="dt-authors">
<div class="dt-author">Bryan Stanfill</div>
<div class="dt-author">Heike Hofmann</div>
<div class="dt-author">Ulrike Genschel</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>rotations: An R Package for SO(3) Data</h2>
<div class="dt-tags"></div>
<p>In this article we introduce the *rotations* package which provides users with the ability to simulate, analyze and visualize three-dimensional rotation data. More specifically it includes four commonly used distributions from which to simulate data, four estimators of the central orientation, six confidence region estimation procedures and two approaches to visualizing rotation data. All of these features are available for two different parameterizations of rotations: three-by-three matrices and quaternions. In addition, two datasets are included that illustrate the use of rotation data in practice.</p>
</div>
</a>
<a href="articles/RJ-2014-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 19, 2014</div>
<div class="dt-authors">
<div class="dt-author">Natalie A. Koziol</div>
<div class="dt-author">Christopher R. Bilder</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>MRCV: A Package for Analyzing Categorical Variables with Multiple Response Options</h2>
<div class="dt-tags"></div>
<p>Multiple response categorical variables (MRCVs), also known as "pick any" or "choose all that apply" variables, summarize survey questions for which respondents are allowed to select more than one category response option. Traditional methods for analyzing the association between categorical variables are not appropriate with MRCVs due to the within-subject dependence among responses. We have developed the ***MRCV*** package as the first R package available to correctly analyze MRCV data. Statistical methods offered by our package include counterparts to traditional Pearson chi-square tests for independence and loglinear models, where bootstrap methods and Rao-Scott adjustments are relied on to obtain valid inferences. We demonstrate the primary functions within the package by analyzing data from a survey assessing the swine waste management practices of Kansas farmers.</p>
</div>
</a>
<a href="articles/RJ-2014-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 19, 2014</div>
<div class="dt-authors">
<div class="dt-author">Luigi Lombardi</div>
<div class="dt-author">Massimiliano Pastore</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>sgr: A Package for Simulating Conditional Fake Ordinal Data</h2>
<div class="dt-tags"></div>
<p>Many self-report measures of attitudes, beliefs, personality, and pathology include items that can be easily manipulated by respondents. For example, an individual may deliberately attempt to manipulate or distort responses to simulate grossly exaggerated physical or psychological symptoms in order to reach specific goals such as, for example, obtaining financial compensation, avoiding being charged with a crime, avoiding military duty, or obtaining drugs. This article introduces the package *sgr* that can be used to perform fake data analysis according to the sample generation by replacement approach. The package includes functions for making simple inferences about discrete/ordinal fake data. The package allows to quantify uncertainty in inferences based on possible fake data as well as to study the implications of fake data for empirical results.</p>
</div>
</a>
<a href="articles/RJ-2014-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 17, 2014</div>
<div class="dt-authors">
<div class="dt-author">Maurits Kaptein</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>RStorm: Developing and Testing Streaming Algorithms in R</h2>
<div class="dt-tags"></div>
<p>Streaming data, consisting of indefinitely evolving sequences, are becoming ubiquitous in many branches of science and in various applications. Computer scientists have developed streaming applications such as Storm and the S4 distributed stream computing platform[^1] to deal with data streams. However, in current production packages testing and evaluating streaming algorithms is cumbersome. This paper presents *RStorm* for the development and evaluation of streaming algorithms analogous to these production packages, but implemented fully in R. *RStorm* allows developers of streaming algorithms to quickly test, iterate, and evaluate various implementations of streaming algorithms. The paper provides both a canonical computer science example, the streaming word count, and examples of several statistical applications of *RStorm*.</p>
</div>
</a>
<a href="articles/RJ-2014-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 3, 2014</div>
<div class="dt-authors">
<div class="dt-author">Carson Sievert</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Taming PITCHf/x Data with XML2R and pitchRx</h2>
<div class="dt-tags"></div>
<p>*XML2R* is a framework that reduces the effort required to transform XML content into tables in a way that preserves parent to child relationships. *pitchRx* applies *XML2R*'s grammar for XML manipulation to Major League Baseball Advanced Media (MLBAM)'s Gameday data. With *pitchRx*, one can easily obtain and store Gameday data in a remote database. The Gameday website hosts a wealth of XML data, but perhaps most interesting is PITCHf/x. Among other things, PITCHf/x data can be used to recreate a baseball's flight path from a pitcher's hand to home plate. With *pitchRx*, one can easily create animations and interactive 3D scatterplots of the baseball's flight path. PITCHf/x data is also commonly used to generate a static plot of baseball locations at the moment they cross home plate. These plots, sometimes called strike-zone plots, can also refer to a plot of event probabilities over the same region. *pitchRx* provides an easy and robust way to generate strike-zone plots using the *ggplot2* package.</p>
</div>
</a>
<a href="articles/RJ-2014-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 3, 2014</div>
<div class="dt-authors">
<div class="dt-author">Xiangdong Gu</div>
<div class="dt-author">David Shapiro</div>
<div class="dt-author">Michael D. Hughes</div>
<div class="dt-author">Raji Balasubramanian</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Stratified Weibull Regression Model for Interval-Censored Data</h2>
<div class="dt-tags"></div>
<p>Interval censored outcomes arise when a silent event of interest is known to have occurred within a specific time period determined by the times of the last negative and first positive diagnostic tests. There is a rich literature on parametric and non-parametric approaches for the analysis of interval-censored outcomes. A commonly used strategy is to use a proportional hazards (PH) model with the baseline hazard function parameterized. The proportional hazards assumption can be relaxed in stratified models by allowing the baseline hazard function to vary across strata defined by a subset of explanatory variables. In this paper, we describe and implement a new R package ***straweib***, for fitting a stratified Weibull model appropriate for interval censored outcomes. We illustrate the R package ***straweib*** by analyzing data from a longitudinal oral health study on the timing of the emergence of permanent teeth in 4430 children.</p>
</div>
</a>
<a href="articles/RJ-2014-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 3, 2014</div>
<div class="dt-authors">
<div class="dt-author">Julien Jacques</div>
<div class="dt-author">Quentin Grimonprez</div>
<div class="dt-author">Christophe Biernacki</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Rankcluster: An R Package for Clustering Multivariate Partial Rankings</h2>
<div class="dt-tags"></div>
<p>The ***Rankcluster*** package is the first R package proposing both modeling and clustering tools for ranking data, potentially multivariate and partial. Ranking data are modeled by the Insertion Sorting Rank ([isr]{.smallcaps}) model, which is a meaningful model parametrized by a central ranking and a dispersion parameter. A conditional independence assumption allows multivariate rankings to be taken into account, and clustering is performed by means of mixtures of multivariate [isr]{.smallcaps} models. The parameters of the cluster (central rankings and dispersion parameters) help the practitioners to interpret the clustering. Moreover, the ***Rankcluster*** package provides an estimate of the missing ranking positions when rankings are partial. After an overview of the mixture of multivariate [isr]{.smallcaps} models, the ***Rankcluster*** package is described and its use is illustrated through the analysis of two real datasets.</p>
</div>
</a>
<a href="articles/RJ-2014-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 3, 2014</div>
<div class="dt-authors">
<div class="dt-author">Thomas J. Leeper</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Archiving Reproducible Research with R and Dataverse</h2>
<div class="dt-tags"></div>
<p>Reproducible research and data archiving are increasingly important issues in research involving statistical analyses of quantitative data. This article introduces the [*dvn*](https://CRAN.R-project.org/package=dvn) package, which allows R users to publicly archive datasets, analysis files, codebooks, and associated metadata in Dataverse Network online repositories, an open-source data archiving project sponsored by Harvard University. In this article I review the importance of data archiving in the context of reproducible research, introduce the Dataverse Network, explain the implementation of the *dvn* package, and provide example code for archiving and releasing data using the package.</p>
</div>
</a>
<a href="articles/RJ-2014-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 3, 2014</div>
<div class="dt-authors">
<div class="dt-author">A. Jonathan R. Godfrey</div>
<div class="dt-author">Robert Erhardt</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Addendum to "Statistical Software from a Blind Person's Perspective"</h2>
<div class="dt-tags"></div>
<p>This short note explains a solution to a problem for blind users when using the R terminal under Windows Vista or Windows 7, as identified in [@GodfreyRJournal]. We note the way the solution was discovered and subsequent confirmatory experiments.</p>
</div>
</a>
<a href="articles/RJ-2013-029/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 27, 2013</div>
<div class="dt-authors">
<div class="dt-author">Stefan Bhringer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Dynamic Parallelization of R Functions</h2>
<div class="dt-tags"></div>
<p>R offers several extension packages that allow it to perform parallel computations. These operate on fixed points in the program flow and make it difficult to deal with nested parallelism and to organize parallelism in complex computations in general. In this article we discuss, first, of how to detect parallelism in functions, and second, how to minimize user intervention in that process. We present a solution that requires minimal code changes and enables to flexibly and dynamically choose the degree of parallelization in the resulting computation. An implementation is provided by the R package *parallelize.dynamic* and practical issues are discussed with the help of examples.</p>
</div>
</a>
<a href="articles/RJ-2013-034/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 23, 2013</div>
<div class="dt-authors">
<div class="dt-author">Genaro Sucarrat</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>betategarch: Simulation, Estimation and Forecasting of Beta-Skew-t-EGARCH Models</h2>
<div class="dt-tags"></div>
<p>This paper illustrates the usage of the *betategarch* package, a package for the simulation, estimation and forecasting of Beta-Skew-t-EGARCH models. The Beta-Skew-t-EGARCH model is a dynamic model of the scale or volatility of financial returns. The model is characterised by its robustness to jumps or outliers, and by its exponential specification of volatility. The latter enables richer dynamics, since parameters need not be restricted to be positive to ensure positivity of volatility. In addition, the model also allows for heavy tails and skewness in the conditional return (i.e.scaled return), and for leverage and a time-varying long-term component in the volatility specification. More generally, the model can be viewed as a model of the scale of the error in a dynamic regression.</p>
</div>
</a>
<a href="articles/RJ-2013-032/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 13, 2013</div>
<div class="dt-authors">
<div class="dt-author">Andr Dietrich, Sebastian Zug, and Kaiser</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The R in Robotics</h2>
<div class="dt-tags"></div>
<p>The aim of this contribution is to connect two previously separated worlds: robotic application development with the Robot Operating System (ROS) and statistical programming with R. This fruitful combination becomes apparent especially in the analysis and visualization of sensory data. We therefore introduce a new language extension for ROS that allows to implement nodes in pure R. All relevant aspects are described in a step-by-step development of a common sensor data transformation node. This includes the reception of raw sensory data via the ROS network, message interpretation, bag-file analysis, transformation and visualization, as well as the transmission of newly generated messages back into the ROS network.</p>
</div>
</a>
<a href="articles/RJ-2013-021/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 22, 2013</div>
<div class="dt-authors">
<div class="dt-author">David A. Armstrong II</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>factorplot: Improving Presentation of Simple Contrasts in Generalized Linear Models</h2>
<div class="dt-tags"></div>
<p>Recent statistical literature has paid attention to the presentation of pairwise comparisons either from the point of view of the reference category problem in generalized linear models (GLMs) or in terms of multiple comparisons. Both schools of thought are interested in the parsimonious presentation of sufficient information to enable readers to evaluate the significance of contrasts resulting from the inclusion of qualitative variables in GLMs. These comparisons also arise when trying to interpret multinomial models where one category of the dependent variable is omitted as a reference. While considerable advances have been made, opportunities remain to improve the presentation of this information, especially in graphical form. The *factorplot* package provides new functions for graphically and numerically presenting results of hypothesis tests related to pairwise comparisons resulting from qualitative covariates in GLMs or coefficients in multinomial logistic regression models.</p>
</div>
</a>
<a href="articles/RJ-2013-030/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 18, 2013</div>
<div class="dt-authors">
<div class="dt-author">S. Nadarajah</div>
<div class="dt-author">S. A. A. Bakar</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>CompLognormal: An R Package for Composite Lognormal Distributions</h2>
<div class="dt-tags"></div>
<p>In recent years, composite models based on the lognormal distribution have become popular in actuarial sciences and related areas. In this short note, we present a new R package for computing the probability density function, cumulative density function, and quantile function, and for generating random numbers of any composite model based on the lognormal distribution. The use of the package is illustrated using a real data set.</p>
</div>
</a>
<a href="articles/RJ-2013-031/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 18, 2013</div>
<div class="dt-authors">
<div class="dt-author">Simen Gaure</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>lfe: Linear Group Fixed Effects</h2>
<div class="dt-tags"></div>
<p>Linear models with fixed effects and many dummy variables are common in some fields. Such models are straightforward to estimate unless the factors have *too many* levels. The R package *lfe* solves this problem by implementing a generalization of the **within transformation** to multiple factors, tailored for large problems.</p>
</div>
</a>
<a href="articles/RJ-2013-033/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 4, 2013</div>
<div class="dt-authors">
<div class="dt-author">Marius Hofert</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>On Sampling from the Multivariate t Distribution</h2>
<div class="dt-tags"></div>
<p>The multivariate normal and the multivariate $t$ distributions belong to the most widely used multivariate distributions in statistics, quantitative risk management, and insurance. In contrast to the multivariate normal distribution, the parameterization of the multivariate $t$ distribution does not correspond to its moments. This, paired with a non-standard implementation in the [R]{.sans-serif}package [*mvtnorm*](https://CRAN.R-project.org/package=mvtnorm), provides traps for working with the multivariate $t$ distribution. In this paper, common traps are clarified and corresponding recent changes to *mvtnorm* are presented.</p>
</div>
</a>
<a href="articles/RJ-2013-027/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 25, 2013</div>
<div class="dt-authors">
<div class="dt-author">Yusuf K. Bilgic</div>
<div class="dt-author">Herbert Susmann</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>rlme: An R Package for Rank-Based Estimation and Prediction in Random Effects Nested Models</h2>
<div class="dt-tags"></div>
<p>There is a lack of robust statistical analyses for random effects linear models. In practice, statistical analyses, including estimation, prediction and inference, are not reliable when data are unbalanced, of small size, contain outliers, or not normally distributed. It is fortunate that rank-based regression analysis is a robust nonparametric alternative to likelihood and least squares analysis. We propose an R package that calculates rank-based statistical analyses for two- and three-level random effects nested designs. In this package, a new algorithm which recursively obtains robust predictions for both scale and random effects is used, along with three rank-based fitting methods.</p>
</div>
</a>
<a href="articles/RJ-2013-023/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 14, 2013</div>
<div class="dt-authors">
<div class="dt-author">Pavel Michna</div>
<div class="dt-author">Milton Woods</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>RNetCDF -- A Package for Reading and Writing NetCDF Datasets</h2>
<div class="dt-tags"></div>
<p>This paper describes the *RNetCDF* package (version 1.6), an interface for reading and writing files in Unidata NetCDF format, and gives an introduction to the NetCDF file format. NetCDF is a machine independent binary file format which allows storage of different types of array based data, along with short metadata descriptions. The package presented here allows access to the most important functions of the NetCDF C-interface for reading, writing, and modifying NetCDF datasets. In this paper, we present a short overview on the NetCDF file format and show usage examples of the package.</p>
</div>
</a>
<a href="articles/RJ-2013-022/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 27, 2013</div>
<div class="dt-authors">
<div class="dt-author">Luca Sartore</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>spMC: Modelling Spatial Random Fields with Continuous Lag Markov Chains</h2>
<div class="dt-tags"></div>
<p>Currently, a part of the R statistical software is developed in order to deal with spatial models. More specifically, some available packages allow the user to analyse categorical spatial random patterns. However, only the *spMC* package considers a viewpoint based on transition probabilities between locations. Through the use of this package it is possible to analyse the spatial variability of data, make inference, predict and simulate the categorical classes in unobserved sites. An example is presented by analysing the well-known Swiss Jura data set.</p>
</div>
</a>
<a href="articles/RJ-2013-035/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 27, 2013</div>
<div class="dt-authors">
<div class="dt-author">Paul Murrell</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Changes to grid for R 3.0.0</h2>
<div class="dt-tags"></div>
<p>From R 3.0.0, there is a new recommended way to develop new grob classes in *grid*. In a nutshell, two new "hook" functions, `makeContext()` and `makeContent()` have been added to *grid* to provide an alternative to the existing hook functions `preDrawDetails()`, `drawDetails()`, and `postDrawDetails()`. There is also a new function called `grid.force()`. This article discusses why these changes have been made, provides a simple demonstration of the use of the new functions, and discusses some of the implications for packages that build on *grid*.</p>
</div>
</a>
<a href="articles/RJ-2013-025/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 23, 2013</div>
<div class="dt-authors">
<div class="dt-author">Yang Lu</div>
<div class="dt-author">David Kane</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Performance Attribution for Equity Portfolios</h2>
<div class="dt-tags"></div>
<p>The *pa* package provides tools for conducting performance attribution for long-only, single currency equity portfolios. The package uses two methods: the Brinson-Hood-Beebower model (hereafter referred to as the Brinson model) and a regression-based analysis. The Brinson model takes an ANOVA-type approach and decomposes the active return of any portfolio into asset allocation, stock selection, and interaction effect. The regression-based analysis utilizes estimated coefficients, based on a regression model, to attribute active return to different factors.</p>
</div>
</a>
<a href="articles/RJ-2013-024/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 26, 2013</div>
<div class="dt-authors">
<div class="dt-author">Stefan </div>
<div class="dt-author">Alexander </div>
<div class="dt-author">Ingolf Schimke</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Surface Melting Curve Analysis with R</h2>
<div class="dt-tags"></div>
<p>Nucleic acid *Melting Curve Analysis* is a powerful method to investigate the interaction of double stranded nucleic acids. Many researchers rely on closed source software which is not ubiquitously available, and gives only little control over the computation and data presentation. R in contrast, is open source, highly adaptable and provides numerous utilities for data import, sophisticated statistical analysis and presentation in publication quality. This article covers methods, implemented in the *MBmca* package, for DNA Melting Curve Analysis on microbead surfaces. Particularly, the use of the second derivative melting peaks is suggested as an additional parameter to characterize the melting behavior of DNA duplexes. Examples of microbead surface Melting Curve Analysis on fragments of human genes are presented.</p>
</div>
</a>
<a href="articles/RJ-2013-028/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 26, 2013</div>
<div class="dt-authors">
<div class="dt-author">Christoph Sax</div>
<div class="dt-author">Peter Steiner</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Temporal Disaggregation of Time Series</h2>
<div class="dt-tags"></div>
<p>Temporal disaggregation methods are used to disaggregate low frequency time series to higher frequency series, where either the sum, the average, the first or the last value of the resulting high frequency series is consistent with the low frequency series. Temporal disaggregation can be performed with or without one or more high frequency indicator series. The package *tempdisagg* is a collection of several methods for temporal disaggregation.</p>
</div>
</a>
<a href="articles/RJ-2013-026/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 16, 2013</div>
<div class="dt-authors">
<div class="dt-author">Guogen Shan</div>
<div class="dt-author">Weizhen Wang</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ExactCIdiff: An R Package for Computing Exact Confidence Intervals for the Difference of Two Proportions</h2>
<div class="dt-tags"></div>
<p>Comparing two proportions through the difference is a basic problem in statistics and has applications in many fields. More than twenty confidence intervals [@Newcombe1998Improved; @Newcombe1998Interval] have been proposed. Most of them are approximate intervals with an asymptotic infimum coverage probability much less than the nominal level. In addition, large sample may be costly in practice. So exact optimal confidence intervals become critical for drawing valid statistical inference with accuracy and precision. Recently, [@Wang2010Construction; @Wang2012Inductive] derived the exact smallest (optimal) one-sided $1-\alpha$ confidence intervals for the difference of two paired or independent proportions. His intervals, however, are computer-intensive by nature. In this article, we provide an R package *ExactCIdiff* to implement the intervals when the sample size is not large. This would be the first available package in R to calculate the exact confidence intervals for the difference of proportions. Exact two-sided $1-\alpha$ interval can be easily obtained by taking the intersection of the lower and upper one-sided $1-\alpha/2$ intervals. Readers may jump to Examples 1 and 2 to obtain these intervals.</p>
</div>
</a>
<a href="articles/RJ-2013-020/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 17, 2013</div>
<div class="dt-authors">
<div class="dt-author">David S.LeBauer</div>
<div class="dt-author">Michael C.Dietze</div>
<div class="dt-author">Benjamin M.Bolker</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Translating Probability Density Functions: From R to BUGS and Back Again</h2>
<div class="dt-tags"></div>
<p>The ability to implement statistical models in the BUGS language facilitates Bayesian inference by automating MCMC algorithms. Software packages that interpret the BUGS language include OpenBUGS, WinBUGS, and JAGS. R packages that link BUGS software to the R environment, including [*rjags*](https://CRAN.R-project.org/package=rjags) and [*R2WinBUGS*](https://CRAN.R-project.org/package=R2WinBUGS), are widely used in Bayesian analysis. Indeed, many packages in the Bayesian task view on CRAN (&lt;http://cran.r-project.org/web/views/Bayesian.html&gt;) depend on this integration. However, the R and BUGS languages use different representations of common probability density functions, creating a potential for errors to occur in the implementation or interpretation of analyses that use both languages. Here we review different parameterizations used by the R and BUGS languages, describe how to translate between the languages, and provide an R function, `r2bugs.distributions`, that transforms parameterizations from R to BUGS and back again.</p>
</div>
</a>
<a href="articles/RJ-2013-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 4, 2013</div>
<div class="dt-authors">
<div class="dt-author">Paolo Zagaglia</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>PIN: Measuring Asymmetric Information in Financial Markets with R</h2>
<div class="dt-tags"></div>
<p>The package *PIN* computes a measure of asymmetric information in financial markets, the so-called probability of informed trading. This is obtained from a sequential trade model and is used to study the determinants of an asset price. Since the probability of informed trading depends on the number of buy- and sell-initiated trades during a trading day, this paper discusses the entire modelling cycle, from data handling to the computation of the probability of informed trading and the estimation of parameters for the underlying theoretical model.</p>
</div>
</a>
<a href="articles/RJ-2013-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 3, 2013</div>
<div class="dt-authors">
<div class="dt-author">Lee S.McDaniel</div>
<div class="dt-author">Nicholas C. Henderson</div>
<div class="dt-author">Paul J.Rathouz</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Fast Pure R Implementation of GEE: Application of the Matrix Package</h2>
<div class="dt-tags"></div>
<p>Generalized estimating equation solvers in R only allow for a few pre-determined options for the link and variance functions. We provide a package, *geeM*, which is implemented entirely in R and allows for user specified link and variance functions. The sparse matrix representations provided in the *Matrix* package enable a fast implementation. To gain speed, we make use of analytic inverses of the working correlation when possible and a trick to find quick numeric inverses when an analytic inverse is not available. Through three examples, we demonstrate the speed of *geeM*, which is not much worse than C implementations like *geepack* and *gee* on small data sets and faster on large data sets.</p>
</div>
</a>
<a href="articles/RJ-2013-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2013</div>
<div class="dt-authors">
<div class="dt-author">Timothy P. Jurka</div>
<div class="dt-author">Loren Collingwood</div>
<div class="dt-author">Amber E. Boydstun</div>
<div class="dt-author">Emiliano Grossman</div>
<div class="dt-author">Wouter van Atteveldt</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>RTextTools: A Supervised Learning Package for Text Classification</h2>
<div class="dt-tags"></div>
<p>Social scientists have long hand-labeled texts to create datasets useful for studying topics from congressional policymaking to media reporting. Many social scientists have begun to incorporate machine learning into their toolkits. [*RTextTools*](https://CRAN.R-project.org/package=RTextTools) was designed to make machine learning accessible by providing a start-to-finish product in less than 10 steps. After installing [*RTextTools*](https://CRAN.R-project.org/package=RTextTools), the initial step is to generate a document term matrix. Second, a container object is created, which holds all the objects needed for further analysis. Third, users can use up to nine algorithms to train their data. Fourth, the data are classified. Fifth, the classification is summarized. Sixth, functions are available for performance evaluation. Seventh, ensemble agreement is conducted. Eighth, users can cross-validate their data. Finally, users write their data to a spreadsheet, allowing for further manual coding if required.</p>
</div>
</a>
<a href="articles/RJ-2013-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2013</div>
<div class="dt-authors">
<div class="dt-author">Yang Xiang</div>
<div class="dt-author">Sylvain Gubian</div>
<div class="dt-author">Brian Suomela</div>
<div class="dt-author">Julia Hoeng</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Generalized Simulated Annealing for Global Optimization: The GenSA Package</h2>
<div class="dt-tags"></div>
<p>Many problems in statistics, finance, biology, pharmacology, physics, mathematics, economics, and chemistry involve determination of the global minimum of multidimensional functions. R packages for different stochastic methods such as genetic algorithms and differential evolution have been developed and successfully used in the R community. Based on Tsallis statistics, the R package GenSA was developed for generalized simulated annealing to process complicated non-linear objective functions with a large number of local minima. In this paper we provide a brief introduction to the R package and demonstrate its utility by solving a non-convex portfolio optimization problem in finance and the Thomson problem in physics. *GenSA* is useful and can serve as a complementary tool to, rather than a replacement for, other widely used R packages for optimization.</p>
</div>
</a>
<a href="articles/RJ-2013-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2013</div>
<div class="dt-authors">
<div class="dt-author">Belchin Kostov</div>
<div class="dt-author">Mnica Bcue-Bertaut</div>
<div class="dt-author">Franois Husson</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Multiple Factor Analysis for Contingency Tables in the *FactoMineR* Package</h2>
<div class="dt-tags"></div>
<p>We present multiple factor analysis for contingency tables (MFACT) and its implementation in the *FactoMineR* package. This method, through an option of the `MFA` function, allows us to deal with multiple contingency or frequency tables, in addition to the categorical and quantitative multiple tables already considered in previous versions of the package. Thanks to this revised function, either a multiple contingency table or a mixed multiple table integrating quantitative, categorical and frequency data can be tackled.</p>
</div>
</a>
<a href="articles/RJ-2013-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2013</div>
<div class="dt-authors">
<div class="dt-author">John Fox</div>
<div class="dt-author">Michael Friendly</div>
<div class="dt-author">Sanford Weisberg</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Hypothesis Tests for Multivariate Linear Models Using the car Package</h2>
<div class="dt-tags"></div>
<p>The multivariate linear model is $$\underset{(n\times m)}{\mathbf{Y}}=\underset{(n\times p)}{\mathbf{X}}\underset{(p\times m)}{\mathbf{B}}+\underset{(n\times m)}{\mathbf{E}}%$$ The multivariate linear model can be fit with the `lm` function in R, where the left-hand side of the model comprises a matrix of response variables, and the right-hand side is specified exactly as for a univariate linear model (i.e., with a single response variable). This paper explains how to use the `Anova` and `linearHypothesis` functions in the *car* package to perform convenient hypothesis tests for parameters in multivariate linear models, including models for repeated-measures data.</p>
</div>
</a>
<a href="articles/RJ-2013-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2013</div>
<div class="dt-authors">
<div class="dt-author">Manuel J. A. Eugster</div>
<div class="dt-author">Thomas Schlesinger</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>osmar: OpenStreetMap and R</h2>
<div class="dt-tags"></div>
<p>OpenStreetMap provides freely accessible and editable geographic data. The *osmar* package smoothly integrates the OpenStreetMap project into the R ecosystem. The *osmar* package provides infrastructure to access OpenStreetMap data from different sources, to enable working with the OSM data in the familiar R idiom, and to convert the data into objects based on classes provided by existing R packages. This paper explains the package's concept and shows how to use it. As an application we present a simple navigation device.</p>
</div>
</a>
<a href="articles/RJ-2013-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2013</div>
<div class="dt-authors">
<div class="dt-author">Han Lin Shang</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ftsa: An R Package for Analyzing Functional Time Series</h2>
<div class="dt-tags"></div>
<p>Recent advances in computer recording and storing technology have tremendously increased the presence of functional data, whose graphical representation can be infinite-dimensional curve, image, or shape. When the same functional object is observed over a period of time, such data are known as functional time series. This article makes first attempt to describe several techniques (centered around functional principal component analysis) for modeling and forecasting functional time series from a computational aspect, using a readily-available R addon package. These methods are demonstrated using age-specific Australian fertility rate data from 1921 to 2006, and monthly sea surface temperature data from January 1950 to December 2011.</p>
</div>
</a>
<a href="articles/RJ-2013-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2013</div>
<div class="dt-authors">
<div class="dt-author">A. Jonathan R. Godfrey</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Statistical Software from a Blind Person's Perspective</h2>
<div class="dt-tags"></div>
<p>Blind people have experienced access issues to many software applications since the advent of the Windows operating system; statistical software has proven to follow the rule and not be an exception. The ability to use R within minutes of download with next to no adaptation has opened doors for accessible production of statistical analyses for this author (himself blind) and blind students around the world. This article shows how little is required to make R the most accessible statistical software available today. There is any number of ramifications that this opportunity creates for blind students, especially in terms of their future research and employment prospects. There is potential for making R even better for blind users. The extensibility of R makes this possible through added functionality being made available in an add-on package called *BrailleR*. Functions in this package are intended to make graphical information available in text form.</p>
</div>
</a>
<a href="articles/RJ-2013-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2013</div>
<div class="dt-authors">
<div class="dt-author">Alrik Thiem</div>
<div class="dt-author">Adrian Dua</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>QCA: A Package for Qualitative Comparative Analysis</h2>
<div class="dt-tags"></div>
<p>We present *QCA*, a package for performing Qualitative Comparative Analysis (QCA). QCA is becoming increasingly popular with social scientists, but none of the existing software alternatives covers the full range of core procedures. This gap is now filled by *QCA*. After a mapping of the method's diffusion, we introduce some of the package's main capabilities, including the calibration of crisp and fuzzy sets, the analysis of necessity relations, the construction of truth tables and the derivation of complex, parsimonious and intermediate solutions.</p>
</div>
</a>
<a href="articles/RJ-2013-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2013</div>
<div class="dt-authors">
<div class="dt-author">Mathieu Collter</div>
<div class="dt-author">Jrme Guitton</div>
<div class="dt-author">Didier Gascuel</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>An Introduction to the EcoTroph R Package: Analyzing Aquatic Ecosystem Trophic Networks</h2>
<div class="dt-tags"></div>
<p>Recent advances in aquatic ecosystem modelling have particularly focused on trophic network analysis through trophodynamic models. We present here a R package devoted to a recently developed model, *EcoTroph*. This model enables the analysis of aquatic ecological networks and the related impacts of fisheries. It was available through a plug-in in the well-known Ecopath with Ecosim software or through implementations in Excel sheets. The R package we developed simplifies the access to the EcoTroph model and offers a new interfacing between two widely used software, Ecopath and R.</p>
</div>
</a>
<a href="articles/RJ-2013-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2013</div>
<div class="dt-authors">
<div class="dt-author">Matteo Dell'Omodarme</div>
<div class="dt-author">Giada Valle</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>stellaR: A Package to Manage Stellar Evolution Tracks and Isochrones</h2>
<div class="dt-tags"></div>
<p>We present the R package *stellaR*, which is designed to access and manipulate publicly available stellar evolutionary tracks and isochrones from the Pisa low-mass database. The procedures for extracting important stages in the evolution of a star from the database, for constructing isochrones from stellar tracks and for interpolating among tracks are discussed and demonstrated.</p>
</div>
</a>
<a href="articles/RJ-2013-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2013</div>
<div class="dt-authors">
<div class="dt-author">Antony R Unwin</div>
<div class="dt-author">Heike Hofmann</div>
<div class="dt-author">Dianne H Cook</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Let Graphics Tell the Story - Datasets in R</h2>
<div class="dt-tags"></div>
<p>Graphics are good for showing the information in datasets and for complementing modelling. Sometimes graphics show information models miss, sometimes graphics help to make model results more understandable, and sometimes models show whether information from graphics has statistical support or not. It is the interplay of the two approaches that is valuable. Graphics could be used a lot more in R examples and we explore this idea with some datasets available in R packages.</p>
</div>
</a>
<a href="articles/RJ-2013-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2013</div>
<div class="dt-authors">
<div class="dt-author">Stefan Wilhelm</div>
<div class="dt-author">Miguel Godinho de Matos</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Estimating Spatial Probit Models in R</h2>
<div class="dt-tags"></div>
<p>In this article we present the Bayesian estimation of spatial probit models in R and provide an implementation in the package *spatialprobit*. We show that large probit models can be estimated with sparse matrix representations and Gibbs sampling of a truncated multivariate normal distribution with the precision matrix. We present three examples and point to ways to achieve further performance gains through parallelization of the Markov Chain Monte Carlo approach.</p>
</div>
</a>
<a href="articles/RJ-2013-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2013</div>
<div class="dt-authors">
<div class="dt-author">David Kahle</div>
<div class="dt-author">Hadley Wickham</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ggmap: Spatial Visualization with ggplot2</h2>
<div class="dt-tags"></div>
<p>In spatial statistics the ability to visualize data and models superimposed with their basic social landmarks and geographic context is invaluable. *ggmap* is a new tool which enables such visualization by combining the spatial information of static maps from Google Maps, OpenStreetMap, Stamen Maps or CloudMade Maps with the layered grammar of graphics implementation of *ggplot2*. In addition, several new utility functions are introduced which allow the user to access the Google Geocoding, Distance Matrix, and Directions APIs. The result is an easy, consistent and modular framework for spatial graphics with several convenient tools for spatial data analysis.</p>
</div>
</a>
<a href="articles/RJ-2013-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2013</div>
<div class="dt-authors">
<div class="dt-author">David Kahle</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>mpoly: Multivariate Polynomials in R</h2>
<div class="dt-tags"></div>
<p>The *mpoly* package is a general purpose collection of tools for symbolic computing with multivariate polynomials in R. In addition to basic arithmetic, *mpoly* can take derivatives of polynomials, compute bases of collections of polynomials, and convert polynomials into a functional form to be evaluated. Among other things, it is hoped that *mpoly* will provide an R-based foundation for the computational needs of algebraic statisticians.</p>
</div>
</a>
<a href="articles/RJ-2013-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2013</div>
<div class="dt-authors">
<div class="dt-author">Anyiawung Chiara Forcheh</div>
<div class="dt-author">Geert Verbeke and Lieven Clement</div>
<div class="dt-author">Dan Lin and Ziv Shkedy</div>
<div class="dt-author">Adetayo Kasim</div>
<div class="dt-author">Willem Talloen and Hinrich W.H. </div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>beadarrayFilter: An R Package to Filter Beads</h2>
<div class="dt-tags"></div>
<p>Microarrays enable the expression levels of thousands of genes to be measured simultaneously. However, only a small fraction of these genes are expected to be expressed under different experimental conditions. Nowadays, filtering has been introduced as a step in the microarray pre-processing pipeline. Gene filtering aims at reducing the dimensionality of data by filtering redundant features prior to the actual statistical analysis. Previous filtering methods focus on the Affymetrix platform and can not be easily ported to the Illumina platform. As such, we developed a filtering method for Illumina bead arrays. We developed an R package, *beadarrayFilter*, to implement the latter method. In this paper, the main functions in the package are highlighted and using many examples, we illustrate how *beadarrayFilter* can be used to filter bead arrays.</p>
</div>
</a>
<a href="articles/RJ-2013-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2013</div>
<div class="dt-authors">
<div class="dt-author">Milan Bouchet-Valat</div>
<div class="dt-author">Gilles Bastin</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>RcmdrPlugin.temis, a Graphical Integrated Text Mining Solution in R</h2>
<div class="dt-tags"></div>
<p>We present the package *RcmdrPlugin.temis*, a graphical user interface for user-friendly text mining in R. Built as a plug-in to the R Commander provided by the *Rcmdr* package, it brings together several existing packages and provides new features streamlining the process of importing, managing and analyzing a corpus, in addition to saving results and plots to a report file. Beyond common file formats, automated import of corpora from the Dow Jones Factiva content provider and Twitter is supported. Featured analyses include vocabulary and dissimilarity tables, terms frequencies, terms specific of levels of a variable, term co-occurrences, time series, correspondence analysis and hierarchical clustering.</p>
</div>
</a>
<a href="articles/RJ-2013-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 2, 2013</div>
<div class="dt-authors">
<div class="dt-author">Jeroen Ooms</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Possible Directions for Improving Dependency Versioning in R</h2>
<div class="dt-tags"></div>
<p>One of the most powerful features of R is its infrastructure for contributed code. The built-in package manager and complementary repositories provide a great system for development and exchange of code, and have played an important role in the growth of the platform towards the de-facto standard in statistical computing that it is today. However, the number of packages on CRAN and other repositories has increased beyond what might have been foreseen, and is revealing some limitations of the current design. One such problem is the general lack of dependency versioning in the infrastructure. This paper explores this problem in greater detail, and suggests approaches taken by other open source communities that might work for R as well. Three use cases are defined that exemplify the issue, and illustrate how improving this aspect of package management could increase reliability while supporting further growth of the R community.</p>
</div>
</a>
<a href="articles/RJ-2012-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2012</div>
<div class="dt-authors">
<div class="dt-author">Il Do Ha</div>
<div class="dt-author">Maengseok Noh</div>
<div class="dt-author">Youngjo Lee</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>frailtyHL: A Package for Fitting Frailty Models with H-likelihood</h2>
<div class="dt-tags"></div>
<p>We present the *frailtyHL* package for fitting semi-parametric frailty models using h-likelihood. This package allows lognormal or gamma frailties for random-effect distribution, and it fits shared or multilevel frailty models for correlated survival data. Functions are provided to format and summarize the *frailtyHL* results. The estimates of fixed effects and frailty parameters and their standard errors are calculated. We illustrate the use of our package with three well-known data sets and compare our results with various alternative R-procedures.</p>
</div>
</a>
<a href="articles/RJ-2012-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2012</div>
<div class="dt-authors">
<div class="dt-author">Rense Nieuwenhuis</div>
<div class="dt-author">Manfred te Grotenhuis</div>
<div class="dt-author">Ben Pelzer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>influence.ME: Tools for Detecting Influential Data in Mixed Effects Models</h2>
<div class="dt-tags"></div>
<p>[*influence.ME*](https://CRAN.R-project.org/package=influence.ME) provides tools for detecting influential data in mixed effects models. The application of these models has become common practice, but the development of diagnostic tools has lagged behind. [*influence.ME*](https://CRAN.R-project.org/package=influence.ME) calculates standardized measures of influential data for the point estimates of generalized mixed effects models, such as DFBETAS, Cook's distance, as well as percentile change and a test for changing levels of significance. [*influence.ME*](https://CRAN.R-project.org/package=influence.ME) calculates these measures of influence while accounting for the nesting structure of the data. The package and measures of influential data are introduced, a practical example is given, and strategies for dealing with influential data are suggested.</p>
</div>
</a>
<a href="articles/RJ-2012-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2012</div>
<div class="dt-authors">
<div class="dt-author">Jeffrey S.Racine, Zhenghua Nie</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The crs Package: Nonparametric Regression Splines for Continuous and Categorical Predictors</h2>
<div class="dt-tags"></div>
<p>A new package *crs* is introduced for computing nonparametric regression (and quantile) splines in the presence of both continuous and categorical predictors. B-splines are employed in the regression model for the continuous predictors and kernel weighting is employed for the categorical predictors. We also develop a simple R interface to NOMAD, which is a mixed integer optimization solver used to compute optimal regression spline solutions.</p>
</div>
</a>
<a href="articles/RJ-2012-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2012</div>
<div class="dt-authors">
<div class="dt-author">Paul Murrell</div>
<div class="dt-author">Velvet Ly</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Debugging grid Graphics</h2>
<div class="dt-tags"></div>
<p>A graphical scene that has been produced using the *grid* graphics package consists of grobs (graphical objects) and viewports. This article describes functions that allow the exploration and inspection of the grobs and viewports in a *grid* scene, including several functions that are available in a new package called *gridDebug*. The ability to explore the grobs and viewports in a *grid* scene is useful for adding more drawing to a scene that was produced using *grid* and for understanding and debugging the *grid* code that produced a scene.</p>
</div>
</a>
<a href="articles/RJ-2012-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2012</div>
<div class="dt-authors">
<div class="dt-author">John D.Kloke</div>
<div class="dt-author">Joseph W.McKean</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Rfit: Rank-based Estimation for Linear Models</h2>
<div class="dt-tags"></div>
<p>In the nineteen seventies, Jurekov and Jaeckel proposed rank estimation for linear models. Since that time, several authors have developed inference and diagnostic methods for these estimators. These rank-based estimators and their associated inference are highly efficient and are robust to outliers in response space. The methods include estimation of standard errors, tests of general linear hypotheses, confidence intervals, diagnostic procedures including studentized residuals, and measures of influential cases. We have developed an R package, [*Rfit*](https://CRAN.R-project.org/package=Rfit), for computing of these robust procedures. In this paper we highlight the main features of the package. The package uses standard linear model syntax and includes many of the main inference and diagnostic functions.</p>
</div>
</a>
<a href="articles/RJ-2012-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2012</div>
<div class="dt-authors">
<div class="dt-author">Kayvan Sadeghi</div>
<div class="dt-author">Giovanni M.Marchetti</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Graphical Markov Models with Mixed Graphs in R</h2>
<div class="dt-tags"></div>
<p>In this paper we provide a short tutorial illustrating the new functions in the package *ggm* that deal with ancestral, summary and ribbonless graphs. These are mixed graphs (containing three types of edges) that are important because they capture the modified independence structure after marginalisation over, and conditioning on, nodes of directed acyclic graphs. We provide functions to verify whether a mixed graph implies that $A$ is independent of $B$ given $C$ for any disjoint sets of nodes and to generate maximal graphs inducing the same independence structure of non-maximal graphs. Finally, we provide functions to decide on the Markov equivalence of two graphs with the same node set but different types of edges.</p>
</div>
</a>
<a href="articles/RJ-2012-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2012</div>
<div class="dt-authors">
<div class="dt-author">Paul Murrell</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>What's in a Name?</h2>
<div class="dt-tags"></div>
<p>Any shape that is drawn using the [*grid*](https://CRAN.R-project.org/package=grid) graphics package can have a name associated with it. If a name is provided, it is possible to access, query, and modify the shape after it has been drawn. These facilities allow for very detailed customisations of plots and also for very general transformations of plots that are drawn by packages based on [*grid*](https://CRAN.R-project.org/package=grid).</p>
</div>
</a>
<a href="articles/RJ-2012-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2012</div>
<div class="dt-authors">
<div class="dt-author">Paul Murrell</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>It's Not What You Draw,\
It's What You Don't Draw</h2>
<div class="dt-tags"></div>
<p>The R graphics engine has new support for drawing complex paths via the functions `polypath()` and `grid.path()`. This article explains what is meant by a complex path and demonstrates the usefulness of complex paths in drawing non-trivial shapes, logos, customised data symbols, and maps.</p>
</div>
</a>
<a href="articles/RJ-2012-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2012</div>
<div class="dt-authors">
<div class="dt-author">Rasmus Bth</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The State of Naming Conventions in R</h2>
<div class="dt-tags"></div>
<p>Most programming language communities have naming conventions that are generally agreed upon, that is, a set of rules that governs how functions and variables are named. This is not the case with R, and a review of unofficial style guides and naming convention usage on CRAN shows that a number of different naming conventions are currently in use. Some naming conventions are, however, more popular than others and as a newcomer to the R community or as a developer of a new package this could be useful to consider when choosing what naming convention to adopt.</p>
</div>
</a>
<a href="articles/RJ-2012-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2012</div>
<div class="dt-authors">
<div class="dt-author">Adrian Barnett</div>
<div class="dt-author">Peter Baker</div>
<div class="dt-author">Annette Dobson</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Analysing Seasonal Data</h2>
<div class="dt-tags"></div>
<p>Many common diseases, such as the flu and cardiovascular disease, increase markedly in winter and dip in summer. These seasonal patterns have been part of life for millennia and were first noted in ancient Greece by both Hippocrates and Herodotus. Recent interest has focused on climate change, and the concern that seasons will become more extreme with harsher winter and summer weather. We describe a set of R functions designed to model seasonal patterns in disease. We illustrate some simple descriptive and graphical methods, a more complex method that is able to model non-stationary patterns, and the case-crossover to control for seasonal confounding.</p>
</div>
</a>
<a href="articles/RJ-2012-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2012</div>
<div class="dt-authors">
<div class="dt-author">Elizabeth E. Holmes</div>
<div class="dt-author">Eric J. Ward</div>
<div class="dt-author">Kellie Wills</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>MARSS: Multivariate Autoregressive State-space Models for Analyzing Time-series Data</h2>
<div class="dt-tags"></div>
<p>MARSS is a package for fitting multivariate autoregressive state-space models to time-series data. The MARSS package implements state-space models in a maximum likelihood framework. The core functionality of MARSS is based on likelihood maximization using the Kalman filter/smoother, combined with an EM algorithm. To make comparisons with other packages available, parameter estimation is also permitted via direct search routines available in 'optim'. The MARSS package allows data to contain missing values and allows a wide variety of model structures and constraints to be specified (such as fixed or shared parameters). In addition to model-fitting, the package provides bootstrap routines for simulating data and generating confidence intervals, and multiple options for calculating model selection criteria (such as AIC).</p>
</div>
</a>
<a href="articles/RJ-2012-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2012</div>
<div class="dt-authors">
<div class="dt-author">Karl Ropkins</div>
<div class="dt-author">David C. Carslaw</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>openair -- Data Analysis Tools for the Air Quality Community</h2>
<div class="dt-tags"></div>
<p>The [*openair*](https://CRAN.R-project.org/package=openair) package contains data analysis tools for the air quality community. This paper provides an overview of data importers, main functions, and selected utilities and workhorse functions within the package and the function output class, as of package version 0.4-14. It is intended as an explanation of the rationale for the package and a technical description for those wishing to work more interactively with the main functions or develop additional functions to support 'higher level' use of [*openair*](https://CRAN.R-project.org/package=openair) and R.</p>
</div>
</a>
<a href="articles/RJ-2012-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2012</div>
<div class="dt-authors">
<div class="dt-author">Daniel Adler</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Foreign Library Interface</h2>
<div class="dt-tags"></div>
<p>We present an improved Foreign Function Interface (FFI) for R to call arbitary native functions without the need for C wrapper code. Further we discuss a dynamic linkage framework for binding standard C libraries to R across platforms using a universal type information format. The package [*rdyncall*](https://CRAN.R-project.org/package=rdyncall) comprises the framework and an initial repository of cross-platform bindings for standard libraries such as (legacy and modern) *OpenGL*, the family of *SDL* libraries and *Expat*. The package enables system-level programming using the R language; sample applications are given in the article. We outline the underlying automation tool-chain that extracts cross-platform bindings from C headers, making the repository extendable and open for library developers.</p>
</div>
</a>
<a href="articles/RJ-2012-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2012</div>
<div class="dt-authors">
<div class="dt-author">John Lawson</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Vdgraph: A Package for Creating Variance Dispersion Graphs</h2>
<div class="dt-tags"></div>
<p>This article introduces the package [*Vdgraph*](https://CRAN.R-project.org/package=Vdgraph) that is used for making variance dispersion graphs of response surface designs. The package includes functions that make the variance dispersion graph of one design or compare variance dispersion graphs of two designs, which are stored in data frames or matrices. The package also contains several minimum run response surface designs (stored as matrices) that are not available in other R packages.</p>
</div>
</a>
<a href="articles/RJ-2012-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2012</div>
<div class="dt-authors">
<div class="dt-author">Sarah Anoke</div>
<div class="dt-author">Yuting Zhao</div>
<div class="dt-author">Rafael Jaeger</div>
<div class="dt-author">Nicholas J. Horton</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>xgrid and R: Parallel Distributed Processing Using Heterogeneous Groups of Apple Computers</h2>
<div class="dt-tags"></div>
<p>The Apple Xgrid system provides access to groups (or grids) of computers that can be used to facilitate parallel processing. We describe the *xgrid* package which facilitates access to this system to undertake independent simulations or other long-running jobs that can be divided into replicate runs within R. Detailed examples are provided to demonstrate the interface, along with results from a simulation study of the performance gains using a variety of grids. Use of the grid for "embarassingly parallel" independent jobs has the potential for major speedups in time to completion. Appendices provide guidance on setting up the workflow, utilizing add-on packages, and constructing grids using existing machines.</p>
</div>
</a>
<a href="articles/RJ-2012-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2012</div>
<div class="dt-authors">
<div class="dt-author">Timothy P. Jurka</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>maxent: An R Package for Low-memory Multinomial Logistic Regression with Support for Semi-automated Text Classification</h2>
<div class="dt-tags"></div>
<p>*maxent* is a package with tools for data classification using multinomial logistic regression, also known as maximum entropy. The focus of this maximum entropy classifier is to minimize memory consumption on very large datasets, particularly sparse document-term matrices represented by the *tm* text mining package.</p>
</div>
</a>
<a href="articles/RJ-2012-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2012</div>
<div class="dt-authors">
<div class="dt-author">Timothy T. Bergsma</div>
<div class="dt-author">Michael S. Smith</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Sumo: An Authenticating Web Application with an Embedded R Session</h2>
<div class="dt-tags"></div>
<p>Sumo is a web application intended as a template for developers. It is distributed as a Java `war` file that deploys automatically when placed in a Servlet container's `webapps` directory. If a user supplies proper credentials, Sumo creates a session-specific Secure Shell connection to the host and a user-specific R session over that connection. Developers may write dynamic server pages that make use of the persistent R session and user-specific file space. The supplied example plots a data set conditional on preferences indicated by the user; it also displays some static text. A companion server page allows the user to interact directly with the R session. Sumo's novel feature set complements previous efforts to supply R functionality over the internet.</p>
</div>
</a>
<a href="articles/RJ-2012-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2012</div>
<div class="dt-authors">
<div class="dt-author">Kurt Hornik</div>
<div class="dt-author">Duncan Murdoch</div>
<div class="dt-author">Achim Zeileis</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Who Did What? The Roles of R Package Authors and How to Refer to Them</h2>
<div class="dt-tags"></div>
<p>Computational infrastructure for representing persons and citations has been available inR for several years, but has been restructured through enhanced classes `"person"` and `"bibentry"` in recent versions ofR. The new features include support for the specification of the roles of package authors (e.g.maintainer, author, contributor, translator, etc.) and more flexible formatting/printing tools among various other improvements. Here, we introduce the new classes and their methods and indicate how this functionality is employed in the management of Rpackages. Specifically, we show how the authors of Rpackages can be specified along with their roles in package `DESCRIPTION` and/or `CITATION` files and the citations produced from it.</p>
</div>
</a>
<a href="articles/RJ-2011-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2011</div>
<div class="dt-authors">
<div class="dt-author">Thomas Baier,Erich Neuwirth</div>
<div class="dt-author">Michele De Meo</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Creating and Deploying an Application with (R)Excel and R</h2>
<div class="dt-tags"></div>
<p>We present some ways of using Rin Excel and build an example application using the package [*rpart*](https://CRAN.R-project.org/package=rpart). Starting with simple interactive use of [*rpart*](https://CRAN.R-project.org/package=rpart) in Excel, we eventually package the code into an Excel-based application, hiding all details (including R itself) from the end user. In the end, our application implements a service-oriented architecture (SOA) with a clean separation of presentation and computation layer.</p>
</div>
</a>
<a href="articles/RJ-2011-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2011</div>
<div class="dt-authors">
<div class="dt-author">Ian Marschner</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>glm2: Fitting Generalized Linear Models with Convergence Problems</h2>
<div class="dt-tags"></div>
<p>The R function `glm` uses step-halving to deal with certain types of convergence problems when using iteratively reweighted least squares to fit a generalized linear model. This works well in some circumstances but non-convergence remains a possibility, particularly with a non-standard link function. In some cases this is because step-halving is never invoked, despite a lack of convergence. In other cases step-halving is invoked but is unable to induce convergence. One remedy is to impose a stricter form of step-halving than is currently available in `glm`, so that the deviance is forced to decrease in every iteration. This has been implemented in the `glm2` function available in the [*glm2*](https://CRAN.R-project.org/package=glm2) package. Aside from a modified computational algorithm, `glm2` operates in exactly the same way as `glm` and provides improved convergence properties. These improvements are illustrated here with an identity link Poisson model, but are also relevant in other contexts.</p>
</div>
</a>
<a href="articles/RJ-2011-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2011</div>
<div class="dt-authors">
<div class="dt-author">Michael Lundholm</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Implementing the Compendium Concept with Sweave and DOCSTRIP</h2>
<div class="dt-tags"></div>
<p>This article suggests an implementation of the compendium concept by combining `Sweave` and the LaTeX literate programming environment `DOCSTRIP`.</p>
</div>
</a>
<a href="articles/RJ-2011-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2011</div>
<div class="dt-authors">
<div class="dt-author">Kurt Hornik</div>
<div class="dt-author">Duncan Murdoch</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Watch Your Spelling!</h2>
<div class="dt-tags"></div>
<p>We discuss the facilities in base R for spell checking via Aspell, Hunspell or Ispell, which are useful in particular for conveniently checking the spelling of natural language texts in package Rd files and vignettes. Spell checking performance is illustrated using the Rd files in package *stats*. This example clearly indicates the need for a domain-specific statistical dictionary. We analyze the results of spell checking all Rd files in all CRAN packages and show how these can be employed for building such a dictionary.</p>
</div>
</a>
<a href="articles/RJ-2011-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2011</div>
<div class="dt-authors">
<div class="dt-author">Mingzhou Song and Haizhou Wang</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2> Ckmeans.1d.dp: Optimal k-means Clustering in One Dimension by Dynamic Programming</h2>
<div class="dt-tags"></div>
<p>\
The heuristic $k$-means algorithm, widely used for cluster analysis,
does not guarantee optimality. We developed a dynamic programming
algorithm for optimal one-dimensional clustering. The algorithm is
implemented as an R package called
[*Ckmeans.1d.dp*](https://CRAN.R-project.org/package=Ckmeans.1d.dp).
We demonstrate its advantage in optimality and runtime over the
standard iterative $k$-means algorithm.</p>
</div>
</a>
<a href="articles/RJ-2011-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2011</div>
<div class="dt-authors">
<div class="dt-author">Taylor B. Arnold</div>
<div class="dt-author">John W. Emerson</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Nonparametric Goodness-of-Fit Tests for Discrete Null Distributions</h2>
<div class="dt-tags"></div>
<p>Methodology extending nonparametric goodness-of-fit tests to discrete null distributions has existed for several decades. However, modern statistical software has generally failed to provide this methodology to users. We offer a revision of R's `ks.test()` function and a new `cvm.test()` function that fill this need in the R language for two of the most popular nonparametric goodness-of-fit tests. This paper describes these contributions and provides examples of their usage. Particular attention is given to various numerical issues that arise in their implementation.</p>
</div>
</a>
<a href="articles/RJ-2011-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2011</div>
<div class="dt-authors">
<div class="dt-author">Markus Gesmann</div>
<div class="dt-author">Diego de Castillo</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Using the Google Visualisation API with R</h2>
<div class="dt-tags"></div>
<p>The [*googleVis*](https://CRAN.R-project.org/package=googleVis) package provides an interface between R and the Google Visualisation API to create interactive charts which can be embedded into web pages. The best known of these charts is probably the Motion Chart, popularised by Hans Rosling in his TED talks. With the [*googleVis*](https://CRAN.R-project.org/package=googleVis) package users can easily create web pages with interactive charts based on R data frames and display them either via the local R HTTP help server or within their own sites.</p>
</div>
</a>
<a href="articles/RJ-2011-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2011</div>
<div class="dt-authors">
<div class="dt-author">Maxime Herv</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>GrapheR: a Multiplatform GUI for Drawing Customizable Graphs in R</h2>
<div class="dt-tags"></div>
<p>This article presents [*GrapheR*](https://CRAN.R-project.org/package=GrapheR), a Graphical User Interface allowing the user to draw customizable and high-quality graphs without knowing any R commands. Six kinds of graph are available: histograms, box-and-whisker plots, bar plots, pie charts, curves and scatter plots. The complete process is described with the examples of a bar plot and a scatter plot illustrating the legendary puzzle of African and European swallows' migrations.</p>
</div>
</a>
<a href="articles/RJ-2011-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2011</div>
<div class="dt-authors">
<div class="dt-author">Han Lin Shang</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>rainbow: An R Package for Visualizing Functional Time Series</h2>
<div class="dt-tags"></div>
<p>Recent advances in computer technology have tremendously increased the use of functional data, whose graphical representation can be infinite-dimensional curves, images or shapes. This article describes four methods for visualizing functional time series using an R add-on package. These methods are demonstrated using age-specific Australian fertility data from 1921 to 2006 and monthly sea surface temperatures from January 1950 to December 2006.</p>
</div>
</a>
<a href="articles/RJ-2011-020/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2011</div>
<div class="dt-authors">
<div class="dt-author">Martyn Plummer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Portable C++ for R Packages</h2>
<div class="dt-tags"></div>
<p>Package checking errors are more common on Solaris than Linux. In many cases, these errors are due to non-portable C++ code. This article reviews some commonly recurring problems in C++ code found in R packages and suggests solutions.</p>
</div>
</a>
<a href="articles/RJ-2011-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2011</div>
<div class="dt-authors">
<div class="dt-author">Yohan Chalabi</div>
<div class="dt-author">Martin Mchler</div>
<div class="dt-author">Diethelm Wrtz</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Rmetrics - timeDate Package</h2>
<div class="dt-tags"></div>
<p>The management of time and holidays can prove crucial in applications that rely on historical data. A typical example is the aggregation of a data set recorded in different time zones and under different daylight saving time rules. Besides the time zone conversion function, which is well supported by default classes in R, one might need functions to handle special days or holidays. In this respect, the package [*timeDate*](https://CRAN.R-project.org/package=timeDate) enhances default date-time classes in R and brings new functionalities to time zone management and the creation of holiday calendars.</p>
</div>
</a>
<a href="articles/RJ-2011-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2011</div>
<div class="dt-authors">
<div class="dt-author">Hadley Wickham</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>testthat: Get Started with Testing</h2>
<div class="dt-tags"></div>
<p>Software testing is important, but many of us don't do it because it is frustrating and boring. *testthat* is a new testing framework for R that is easy learn and use, and integrates with your existing workflow. This paper shows how, with illustrations from existing packages.</p>
</div>
</a>
<a href="articles/RJ-2011-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2011</div>
<div class="dt-authors">
<div class="dt-author">Angela Bohn, Kurt Hornik, Patrick Mair</div>
<div class="dt-author">Ingo Feinerer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Content-Based Social Network Analysis of Mailing Lists</h2>
<div class="dt-tags"></div>
<p>Social Network Analysis (SNA) provides tools to examine relationships between people. Text Mining (TM) allows capturing the text they produce in Web 2.0 applications, for example, however it neglects their social structure. This paper applies an approach to combine the two methods named "content-based SNA". Using the R mailing lists, R-help and R-devel, we show how this combination can be used to describe people's interests and to find out if authors who have similar interests actually communicate. We find that the expected positive relationship between sharing interests and communicating gets stronger as the centrality scores of authors in the communication networks increase.</p>
</div>
</a>
<a href="articles/RJ-2011-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2011</div>
<div class="dt-authors">
<div class="dt-author">Timothe Poisot</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The digitize Package: Extracting Numerical Data from Scatterplots</h2>
<div class="dt-tags"></div>
<p>I present the small R package [*digitize*](https://CRAN.R-project.org/package=digitize), designed to extract data from scatterplots with a simple method and suited to small datasets. I present an application of this method to the extraction of data from a graph whose source is not available.</p>
</div>
</a>
<a href="articles/RJ-2011-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2011</div>
<div class="dt-authors">
<div class="dt-author">David Ardia</div>
<div class="dt-author">Kris Boudt</div>
<div class="dt-author">Peter Carl</div>
<div class="dt-author">Katharine M. Mullen</div>
<div class="dt-author">Brian G. Peterson</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Differential Evolution with DEoptim</h2>
<div class="dt-tags"></div>
<p>The R package [*DEoptim*](https://CRAN.R-project.org/package=DEoptim) implements the Differential Evolution algorithm. This algorithm is an evolutionary technique similar to classic genetic algorithms that is useful for the solution of global optimization problems. In this note we provide an introduction to the package and demonstrate its utility for financial applications by solving a non-convex portfolio optimization problem.</p>
</div>
</a>
<a href="articles/RJ-2011-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2011</div>
<div class="dt-authors">
<div class="dt-author">Andy South</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>rworldmap: A New R package for Mapping Global Data</h2>
<div class="dt-tags"></div>
<p>[*rworldmap*](https://CRAN.R-project.org/package=rworldmap) is a relatively new package available on CRAN for the mapping and visualisation of global data. The vision is to make the display of global data easier, to facilitate understanding and communication. The initial focus is on data referenced by country or grid due to the frequency of use of such data in global assessments. Tools to link data referenced by country (either name or code) to a map, and then to display the map are provided as are functions to map global gridded data. Country and gridded functions accept the same arguments to specify the nature of categories and colour and how legends are formatted. This package builds on the functionality of existing packages, particularly [*sp*](https://CRAN.R-project.org/package=sp), [*maptools*](https://CRAN.R-project.org/package=maptools) and [*fields*](https://CRAN.R-project.org/package=fields). Example code is provided to produce maps, to link with the packages [*classInt*](https://CRAN.R-project.org/package=classInt), [*RColorBrewer*](https://CRAN.R-project.org/package=RColorBrewer) and [*ncdf*](https://CRAN.R-project.org/package=ncdf), and to plot examples of publicly available country and gridded data.</p>
</div>
</a>
<a href="articles/RJ-2011-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2011</div>
<div class="dt-authors">
<div class="dt-author">Frdric Lafitte,Dirk Van Heule and Julien Van hamme</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Cryptographic Boolean Functions with R</h2>
<div class="dt-tags"></div>
<p>A new package called [*boolfun*](https://CRAN.R-project.org/package=boolfun) is available for R users. The package provides tools to handle Boolean functions, in particular for cryptographic purposes. This document guides the user through some (code) examples and gives a feel of what can be done with the package.</p>
</div>
</a>
<a href="articles/RJ-2011-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2011</div>
<div class="dt-authors">
<div class="dt-author">Chris Fraley, Adrian Raftery</div>
<div class="dt-author">Tilmann Gneiting</div>
<div class="dt-author">McLean Sloughter</div>
<div class="dt-author">Veronica Berrocal</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Probabilistic Weather Forecasting in R</h2>
<div class="dt-tags"></div>
<p>This article describes two R packages for probabilistic weather forecasting, [*ensembleBMA*](https://CRAN.R-project.org/package=ensembleBMA), which offers ensemble postprocessing via Bayesian model averaging (BMA), and [*ProbForecastGOP*](https://CRAN.R-project.org/package=ProbForecastGOP), which implements the geostatistical output perturbation (GOP) method. BMA forecasting models use mixture distributions, in which each component corresponds to an ensemble member, and the form of the component distribution depends on the weather parameter (temperature, quantitative precipitation or wind speed). The model parameters are estimated from training data. The GOP technique uses geostatistical methods to produce probabilistic forecasts of entire weather fields for temperature or pressure, based on a single numerical forecast on a spatial grid. Both packages include functions for evaluating predictive performance, in addition to model fitting and forecasting.</p>
</div>
</a>
<a href="articles/RJ-2011-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2011</div>
<div class="dt-authors">
<div class="dt-author">David Kane</div>
<div class="dt-author">Andrew Liu</div>
<div class="dt-author">Khanh Nguyen</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Analyzing an Electronic Limit Order Book</h2>
<div class="dt-tags"></div>
<p>The [*orderbook*](https://CRAN.R-project.org/package=orderbook) package provides facilities for exploring and visualizing the data associated with an order book: the electronic collection of the outstanding limit orders for a financial instrument. This article provides an overview of the [*orderbook*](https://CRAN.R-project.org/package=orderbook) package and examples of its use.</p>
</div>
</a>
<a href="articles/RJ-2010-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2010</div>
<div class="dt-authors">
<div class="dt-author">Lars rd</div>
<div class="dt-author">Xia Shen</div>
<div class="dt-author">Moudud Alam</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>hglm: A Package for Fitting Hierarchical Generalized Linear Models</h2>
<div class="dt-tags"></div>
<p>We present the [*hglm*](https://CRAN.R-project.org/package=hglm) package for fitting hierarchical generalized linear models. It can be used for linear mixed models and generalized linear mixed models with random effects for a variety of links and a variety of distributions for both the outcomes and the random effects. Fixed effects can also be fitted in the dispersion part of the model.</p>
</div>
</a>
<a href="articles/RJ-2010-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2010</div>
<div class="dt-authors">
<div class="dt-author">Duncan Murdoch</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Source References</h2>
<div class="dt-tags"></div>
<p>Since version 2.10.0, Rincludes expanded support for source references in Rcode and `.Rd` files. This paper describes the origin and purposes of source references, and current and future support for them.</p>
</div>
</a>
<a href="articles/RJ-2010-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2010</div>
<div class="dt-authors">
<div class="dt-author">Pter Slymos</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>dclone: Data Cloning in R</h2>
<div class="dt-tags"></div>
<p>The [*dclone*](https://CRAN.R-project.org/package=dclone) R package contains low level functions for implementing maximum likelihood estimating procedures for complex models using data cloning and Bayesian Markov Chain Monte Carlo methods with support for JAGS, WinBUGS and OpenBUGS.</p>
</div>
</a>
<a href="articles/RJ-2010-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2010</div>
<div class="dt-authors">
<div class="dt-author">Hadley Wickham</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>stringr: modern, consistent string processing</h2>
<div class="dt-tags"></div>
<p>String processing is not glamorous, but it is frequently used in data cleaning and preparation. The existing string functions in R are powerful, but not friendly. To remedy this, the [*stringr*](https://CRAN.R-project.org/package=stringr) package provides string functions that are simpler and more consistent, and also fixes some functionality that R is missing compared to other programming languages.</p>
</div>
</a>
<a href="articles/RJ-2010-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2010</div>
<div class="dt-authors">
<div class="dt-author">Karline Soetaert</div>
<div class="dt-author">Thomas Petzoldt</div>
<div class="dt-author">R. Woodrow Setzer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Solving Differential Equations in R</h2>
<div class="dt-tags"></div>
<p>Although R is still predominantly applied for statistical analysis and graphical representation, it is rapidly becoming more suitable for mathematical computing. One of the fields where considerable progress has been made recently is the solution of differential equations. Here we give a brief overview of differential equations that can now be solved by R.[^1]</p>
</div>
</a>
<a href="articles/RJ-2010-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2010</div>
<div class="dt-authors">
<div class="dt-author">David Ardia</div>
<div class="dt-author">Lennart F. Hoogerheide</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Bayesian Estimation of the GARCH(1,1) Model with Student-t Innovations</h2>
<div class="dt-tags"></div>
<p>This note presents the R package [*bayesGARCH*](https://CRAN.R-project.org/package=bayesGARCH) which provides functions for the Bayesian estimation of the parsimonious and effective GARCH(1,1) model with Student-$t$ innovations. The estimation procedure is fully automatic and thus avoids the tedious task of tuning an MCMC sampling algorithm. The usage of the package is shown in an empirical application to exchange rate log-returns.</p>
</div>
</a>
<a href="articles/RJ-2010-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2010</div>
<div class="dt-authors">
<div class="dt-author">Adelino Ferreira da Silva</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>cudaBayesreg: Bayesian Computation in CUDA</h2>
<div class="dt-tags"></div>
<p>Graphical processing units are rapidly gaining maturity as powerful general parallel computing devices. The package [*cudaBayesreg*](https://CRAN.R-project.org/package=cudaBayesreg) uses GPU--oriented procedures to improve the performance of Bayesian computations. The paper motivates the need for devising high-performance computing strategies in the context of fMRI data analysis. Some features of the package for Bayesian analysis of brain fMRI data are illustrated. Comparative computing performance figures between sequential and parallel implementations are presented as well.</p>
</div>
</a>
<a href="articles/RJ-2010-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2010</div>
<div class="dt-authors">
<div class="dt-author">Christopher R. Bilder</div>
<div class="dt-author">Boan Zhang</div>
<div class="dt-author">Frank Schaarschmidt</div>
<div class="dt-author">Joshua M. Tebbs</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>binGroup: A Package for Group Testing</h2>
<div class="dt-tags"></div>
<p>When the prevalence of a disease or of some other binary characteristic is small, group testing (also known as pooled testing) is frequently used to estimate the prevalence and/or to identify individuals as positive or negative. We have developed the *binGroup* package as the first package designed to address the estimation problem in group testing. We present functions to estimate an overall prevalence for a homogeneous population. Also, for this setting, we have functions to aid in the very important choice of the group size. When individuals come from a heterogeneous population, our group testing regression functions can be used to estimate an individual probability of disease positivity by using the group observations only. We illustrate our functions with data from a multiple vector transfer design experiment and a human infectious disease prevalence study.</p>
</div>
</a>
<a href="articles/RJ-2010-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2010</div>
<div class="dt-authors">
<div class="dt-author">Murat Sariyar</div>
<div class="dt-author">Andreas Borg</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The RecordLinkage Package: Detecting Errors in Data</h2>
<div class="dt-tags"></div>
<p>Record linkage deals with detecting homonyms and mainly synonyms in data. The package [*RecordLinkage*](https://CRAN.R-project.org/package=RecordLinkage) provides means to perform and evaluate different record linkage methods. A stochastic framework is implemented which calculates weights through an EM algorithm. The determination of the necessary thresholds in this model can be achieved by tools of extreme value theory. Furthermore, machine learning methods are utilized, including decision trees ([*rpart*](https://CRAN.R-project.org/package=rpart)), bootstrap aggregating ([*bagging*](https://CRAN.R-project.org/package=bagging)), ada boost ([*ada*](https://CRAN.R-project.org/package=ada)), neural nets ([*nnet*](https://CRAN.R-project.org/package=nnet)) and support vector machines ([*svm*](https://CRAN.R-project.org/package=svm)). The generation of record pairs and comparison patterns from single data items are provided as well. Comparison patterns can be chosen to be binary or based on some string metrics. In order to reduce computation time and memory usage, blocking can be used. Future development will concentrate on additional and refined methods, performance improvements and input/output facilities needed for real-world application.</p>
</div>
</a>
<a href="articles/RJ-2010-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2010</div>
<div class="dt-authors">
<div class="dt-author">Hemant Ishwaran</div>
<div class="dt-author">Udaya B. Kogalur</div>
<div class="dt-author">J. Sunil Rao</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>spikeslab: Prediction and Variable Selection Using Spike and Slab Regression</h2>
<div class="dt-tags"></div>
<p>Weighted generalized ridge regression offers unique advantages in correlated high-dimensional problems. Such estimators can be efficiently computed using Bayesian spike and slab models and are effective for prediction. For sparse variable selection, a generalization of the elastic net can be used in tandem with these Bayesian estimates. In this article, we describe the R-software package *spikeslab* for implementing this new spike and slab prediction and variable selection methodology.</p>
</div>
</a>
<a href="articles/RJ-2011-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2010</div>
<div class="dt-authors">
<div class="dt-author">Paul Murrell</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Raster Images in R Graphics</h2>
<div class="dt-tags"></div>
<p>The R graphics engine has new support for rendering raster images via the functions `rasterImage()` and `grid.raster()`. This leads to better scaling of raster images, faster rendering to screen, and smaller graphics files. Several examples of possible applications of these new features are described.</p>
</div>
</a>
<a href="articles/RJ-2010-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2010</div>
<div class="dt-authors">
<div class="dt-author">Setia Pramana, Dan Lin, Philippe Haldermans and Ziv Shkedy</div>
<div class="dt-author">Tobias Verbeke</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>IsoGene: An R Package for Analyzing Dose-response Studies in Microarray Experiments</h2>
<div class="dt-tags"></div>
<p>*IsoGene* is an R package for the analysis of dose-response microarray experiments to identify gene or subsets of genes with a monotone relationship between the gene expression and the doses. Several testing procedures (i.e., the likelihood ratio test, Williams, Marcus, the $M$, and Modified $M$), that take into account the order restriction of the means with respect to the increasing doses are implemented in the package. The inference is based on resampling methods, both permutations and the Significance Analysis of Microarrays (SAM).</p>
</div>
</a>
<a href="articles/RJ-2010-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2010</div>
<div class="dt-authors">
<div class="dt-author">Jean Thioulouse</div>
<div class="dt-author">Claire Valiente-Moro</div>
<div class="dt-author">Lionel Zenner</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Online Reproducible Research: An Application to Multivariate Analysis of Bacterial DNA Fingerprint Data</h2>
<div class="dt-tags"></div>
<p>This paper presents an example of online reproducible multivariate data analysis. This example is based on a web page providing an online computing facility on a server. HTML forms contain editable R code snippets that can be executed in any web browser thanks to the Rweb software. The example is based on the multivariate analysis of DNA fingerprints of the internal bacterial flora of the poultry red mite *Dermanyssus gallinae*. Several multivariate data analysis methods from the [*ade4*](https://CRAN.R-project.org/package=ade4) package are used to compare the fingerprints of mite pools coming from various poultry farms. All the computations and graphical displays can be redone interactively and further explored online, using only a web browser. Statistical methods are detailed in the duality diagram framework, and a discussion about online reproducibility is initiated.</p>
</div>
</a>
<a href="articles/RJ-2010-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2010</div>
<div class="dt-authors">
<div class="dt-author">Patrick Brown</div>
<div class="dt-author">Lutong Zhou</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>MCMC for Generalized Linear Mixed Models with glmmBUGS</h2>
<div class="dt-tags"></div>
<p>The *glmmBUGS* package is a bridging tool between Generalized Linear Mixed Models (GLMMs) in R and the BUGS language. It provides a simple way of performing Bayesian inference using Markov Chain Monte Carlo (MCMC) methods, taking a model formula and data frame in R and writing a BUGS model file, data file, and initial values files. Functions are provided to reformat and summarize the BUGS results. A key aim of the package is to provide files and objects that can be modified prior to calling BUGS, giving users a platform for customizing and extending the models to accommodate a wide variety of analyses.</p>
</div>
</a>
<a href="articles/RJ-2010-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2010</div>
<div class="dt-authors">
<div class="dt-author">Nils B. Weidmann</div>
<div class="dt-author">Kristian Skrede Gleditsch</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Mapping and Measuring Country Shapes</h2>
<div class="dt-tags"></div>
<p>The article introduces the [*cshapes*](https://CRAN.R-project.org/package=cshapes) R package, which includes our CShapes dataset of contemporary and historical country boundaries, as well as computational tools for computing geographical measures from these maps. We provide an overview of the need for considering spatial dependence in comparative research, how this requires appropriate historical maps, and detail how the [*cshapes*](https://CRAN.R-project.org/package=cshapes) associated R package [*cshapes*](https://CRAN.R-project.org/package=cshapes) can contribute to these ends. We illustrate the use of the package for drawing maps, computing spatial variables for countries, and generating weights matrices for spatial statistics.</p>
</div>
</a>
<a href="articles/RJ-2010-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2010</div>
<div class="dt-authors">
<div class="dt-author">Stefan Wilhelm</div>
<div class="dt-author">B. G. Manjunath</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>tmvtnorm: A Package for the Truncated Multivariate Normal Distribution</h2>
<div class="dt-tags"></div>
<p>In this article we present [*tmvtnorm*](https://CRAN.R-project.org/package=tmvtnorm), an R package implementation for the truncated multivariate normal distribution. We consider random number generation with rejection and Gibbs sampling, computation of marginal densities as well as computation of the mean and covariance of the truncated variables. This contribution brings together latest research in this field and provides useful methods for both scholars and practitioners when working with truncated normal variables.</p>
</div>
</a>
<a href="articles/RJ-2010-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2010</div>
<div class="dt-authors">
<div class="dt-author">Frauke Gnther</div>
<div class="dt-author">Stefan Fritsch</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>neuralnet: Training of Neural Networks</h2>
<div class="dt-tags"></div>
<p>Artificial neural networks are applied in many situations.
[*neuralnet*](https://CRAN.R-project.org/package=neuralnet) is built
to train multi-layer perceptrons in the context of regression
analyses, i.e.to approximate functional relationships between
covariates and response variables. Thus, neural networks are used as
extensions of generalized linear models.\
[*neuralnet*](https://CRAN.R-project.org/package=neuralnet) is a very
flexible package. The backpropagation algorithm and three versions of
resilient backpropagation are implemented and it provides a
custom-choice of activation and error function. An arbitrary number of
covariates and response variables as well as of hidden layers can
theoretically be included.\
The paper gives a brief introduction to multi-layer perceptrons and
resilient backpropagation and demonstrates the application of
[*neuralnet*](https://CRAN.R-project.org/package=neuralnet) using the
data set `infert`, which is contained in the R distribution.</p>
</div>
</a>
<a href="articles/RJ-2010-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2010</div>
<div class="dt-authors">
<div class="dt-author">Wiebke Werft</div>
<div class="dt-author">Axel Benner</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>glmperm: A Permutation of Regressor Residuals Test for Inference in Generalized Linear Models</h2>
<div class="dt-tags"></div>
<p>We introduce a new R package called [*glmperm*](https://CRAN.R-project.org/package=glmperm) for inference in generalized linear models especially for small and moderate-sized data sets. The inference is based on the permutation of regressor residuals test introduced by @Potter05. The implementation of [*glmperm*](https://CRAN.R-project.org/package=glmperm) outperforms currently available permutation test software as [*glmperm*](https://CRAN.R-project.org/package=glmperm) can be applied in situations where more than one covariate is involved.</p>
</div>
</a>
<a href="articles/RJ-2010-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2010</div>
<div class="dt-authors">
<div class="dt-author">Michael P. Fay</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Two-sided Exact Tests and Matching Confidence Intervals for Discrete Data</h2>
<div class="dt-tags"></div>
<p>There is an inherent relationship between two-sided hypothesis tests and confidence intervals. A series of two-sided hypothesis tests may be inverted to obtain the 100(1-$\alpha$)% confidence interval defined as the smallest interval that contains all point null parameter values that would not be rejected at the $\alpha$ level. Unfortunately, for discrete data there are several different ways of defining two-sided exact tests and the most commonly used two-sided exact tests are defined one way, while the most commonly used exact confidence intervals are inversions of tests defined another way. This can lead to inconsistencies where the exact test rejects but the exact confidence interval contains the null parameter value. The packages [*exactci*](https://CRAN.R-project.org/package=exactci) and [*exact2x2*](https://CRAN.R-project.org/package=exact2x2) provide several exact tests with the matching confidence intervals avoiding these inconsistencies as much as possible. Examples are given for binomial and Poisson parameters and both paired and unpaired $2 \times 2$ tables.</p>
</div>
</a>
<a href="articles/RJ-2009-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2009</div>
<div class="dt-authors">
<div class="dt-author">Pierre Lafaye de Micheaux</div>
<div class="dt-author">Benoit Liquet</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>ConvergenceConcepts: An R Package to InvestigateVariousModesofConvergence</h2>
<div class="dt-tags"></div>
<p>[*ConvergenceConcepts*](https://CRAN.R-project.org/package=ConvergenceConcepts) is an R package, built upon the [*tkrplot*](https://CRAN.R-project.org/package=tkrplot), [*tcltk*](https://CRAN.R-project.org/package=tcltk) and [*lattice*](https://CRAN.R-project.org/package=lattice) packages, designed to investigate the convergence of simulated sequences of random variables. Four classical modes of convergence may be studied, namely: almost sure convergence (*a.s.*), convergence in probability (*P*), convergence in law (*L*) and convergence in $r$-th mean (*r*). This investigation is performed through accurate graphical representations. This package may be used as a pedagogical tool. It may give students a better understanding of these notions and help them to visualize these difficult theoretical concepts. Moreover, some scholars could gain some insight into the behaviour of some random sequences they are interested in.</p>
</div>
</a>
<a href="articles/RJ-2009-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2009</div>
<div class="dt-authors">
<div class="dt-author">James Carpenter</div>
<div class="dt-author">Gerta Rcker</div>
<div class="dt-author">Guido Schwarzer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>copas: An R package for Fitting the Copas Selection Model</h2>
<div class="dt-tags"></div>
<p>This article describes the R package [*copas*](https://CRAN.R-project.org/package=copas) which is an add-on package to the R package [*meta*](https://CRAN.R-project.org/package=meta). The R package [*copas*](https://CRAN.R-project.org/package=copas) can be used to fit the Copas selection model to adjust for bias in meta-analysis. A clinical example is used to illustrate fitting and interpreting the Copas selection model.</p>
</div>
</a>
<a href="articles/RJ-2009-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2009</div>
<div class="dt-authors">
<div class="dt-author">Carolin Strobl</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Party on!</h2>
<div class="dt-tags"></div>
<p>Random forests are one of the most popular statistical learning algorithms, and a variety of methods for fitting random forests and related recursive partitioning approaches is available in R. This paper points out two important features of the random forest implementation `cforest` available in the *party* package: The resulting forests are unbiased and thus preferable to the `randomForest` implementation available in *randomForest* if predictor variables are of different types. Moreover, a conditional permutation importance measure has recently been added to the *party* package, which can help evaluate the importance of correlated predictor variables. The rationale of this new measure is illustrated and hands-on advice is given for the usage of recursive partitioning tools in R.</p>
</div>
</a>
<a href="articles/RJ-2009-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2009</div>
<div class="dt-authors">
<div class="dt-author">John Fox</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Aspects of the Social Organization and Trajectory of the R Project</h2>
<div class="dt-tags"></div>
<p>Based partly on interviews with members of the R Core team, this paper considers the development of the R Project in the context of open-source software development and, more generally, voluntary activities. The paper describes aspects of the social organization of the R Project, including the organization of the R Core team; describes the trajectory of the R Project; seeks to identify factors crucial to the success of R; and speculates about the prospects for R.</p>
</div>
</a>
<a href="articles/RJ-2009-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2009</div>
<div class="dt-authors">
<div class="dt-author">Jean-Franois CoeurJolly</div>
<div class="dt-author">Rmy Drouilhet</div>
<div class="dt-author">Pierre Lafaye de Micheaux</div>
<div class="dt-author">Jean-Franois Robineau</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>asympTest: A Simple R Package for Classical Parametric Statistical Tests and Confidence Intervals in Large Samples</h2>
<div class="dt-tags"></div>
<p>[*asympTest*](https://CRAN.R-project.org/package=asympTest) is an R package implementing large sample tests and confidence intervals. One and two sample mean and variance tests (differences and ratios) are considered. The test statistics are all expressed in the same form as the Student t-test, which facilitates their presentation in the classroom. This contribution also fills the gap of a robust (to non-normality) alternative to the chi-square single variance test for large samples, since no such procedure is implemented in standard statistical software.</p>
</div>
</a>
<a href="articles/RJ-2009-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2009</div>
<div class="dt-authors">
<div class="dt-author">Graham Williams</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Rattle: A Data Mining GUI for R</h2>
<div class="dt-tags"></div>
<p>Data mining delivers insights, patterns, and descriptive and predictive models from the large amounts of data available today in many organisations. The data miner draws heavily on methodologies, techniques and algorithms from statistics, machine learning, and computer science. R increasingly provides a powerful platform for data mining. However, scripting and programming is sometimes a challenge for data analysts moving into data mining. The Rattle package provides a graphical user interface specifically for data mining using R. It also provides a stepping stone toward using R as a programming language for data analysis.</p>
</div>
</a>
<a href="articles/RJ-2009-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2009</div>
<div class="dt-authors">
<div class="dt-author">Spencer Graves</div>
<div class="dt-author">Sundar Dorai-Raj</div>
<div class="dt-author">Romain Franois</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>sos: Searching Help Pages of R Packages</h2>
<div class="dt-tags"></div>
<p>The [*sos*](https://CRAN.R-project.org/package=sos) package provides a means to quickly and flexibly search the help pages of contributed packages, finding functions and datasets in seconds or minutes that could not be found in hours or days by any other means we know. Its `findFn` function accesses Jonathan Baron's *R Site Search* database and returns the matches in a data frame of class `"findFn"`, which can be further manipulated by other [*sos*](https://CRAN.R-project.org/package=sos) functions to produce, for example, an Excel file that starts with a summary sheet that makes it relatively easy to prioritize alternative packages for further study. As such, it provides a very powerful way to do a literature search for functions and packages relevant to a particular topic of interest and could become virtually mandatory for authors of new packages or papers in publications such as *The R Journal* and the *Journal of Statistical Software*.</p>
</div>
</a>
<a href="articles/RJ-2009-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2009</div>
<div class="dt-authors">
<div class="dt-author">Anthony Damico</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Transitioning to R: Replicating SAS, Stata, and SUDAAN Analysis Techniques in Health Policy Data</h2>
<div class="dt-tags"></div>
<p>Statistical, data manipulation, and presentation tools make R an ideal integrated package for research in the fields of health policy and healthcare management and evaluation. However, the technical documentation accompanying most data sets used by researchers in these fields does not include syntax examples for analysts to make the transition from another statistical package to R. This paper describes the steps required to import health policy data into R, to prepare that data for analysis using the two most common complex survey variance calculation techniques, and to produce the principal set of statistical estimates sought by health policy researchers. Using data from the Medical Expenditure Panel Survey Household Component (MEPS-HC), this paper outlines complex survey data analysis techniques in R, with side-by-side comparisons to the SAS, Stata, and SUDAAN statistical software packages.</p>
</div>
</a>
<a href="articles/RJ-2009-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2009</div>
<div class="dt-authors">
<div class="dt-author">Xuefei Mi</div>
<div class="dt-author">Tetsuhisa Miwa</div>
<div class="dt-author">Torsten Hothorn</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>New Numerical Algorithm for Multivariate Normal Probabilities in Package mvtnorm</h2>
<div class="dt-tags"></div>
<p>The 'New Numerical Algorithm for Multivariate Normal Probabilities in Package [*mvtnorm*](https://CRAN.R-project.org/package=mvtnorm)' article from the 2009-1 issue.</p>
</div>
</a>
<a href="articles/RJ-2009-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2009</div>
<div class="dt-authors">
<div class="dt-author">Donghoh Kim</div>
<div class="dt-author">Hee-Seok Oh</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>EMD: A Package for Empirical Mode Decomposition and Hilbert Spectrum</h2>
<div class="dt-tags"></div>
<p>The 'EMD: A Package for Empirical Mode Decomposition and Hilbert Spectrum' article from the 2009-1 issue.</p>
</div>
</a>
<a href="articles/RJ-2009-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2009</div>
<div class="dt-authors">
<div class="dt-author">David Ardia</div>
<div class="dt-author">Lennart F. Hoogerheide</div>
<div class="dt-author">Herman K. van Dijk</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>AdMit</h2>
<div class="dt-tags"></div>
<p>A package for constructing and using an adaptive mixture of Student-t distributions as a flexible candidate distribution for efficient simulation.</p>
</div>
</a>
<a href="articles/RJ-2009-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2009</div>
<div class="dt-authors">
<div class="dt-author">Jochen Knaus, Christine Porzelius, Harald Binder and Guido Schwarzer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Easier parallel computing in R with snowfall and sfCluster</h2>
<div class="dt-tags"></div>
<p>The 'Easier parallel computing in R with snowfall and sfCluster' article from the 2009-1 issue.</p>
</div>
</a>
<a href="articles/RJ-2009-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2009</div>
<div class="dt-authors">
<div class="dt-author">Vincent Goulet</div>
<div class="dt-author">Michel Jacques</div>
<div class="dt-author">Mathieu Pigeon</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>expert: Modeling Without Data Using Expert Opinion</h2>
<div class="dt-tags"></div>
<p>The [*expert*](https://CRAN.R-project.org/package=expert): Modeling Without Data Using Expert Opinion' article from the 2009-1 issue.</p>
</div>
</a>
<a href="articles/RJ-2009-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2009</div>
<div class="dt-authors">
<div class="dt-author">Paul Murrell</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Drawing Diagrams with R</h2>
<div class="dt-tags"></div>
<p>The 'Drawing Diagrams with R' article from the 2009-1 issue.</p>
</div>
</a>
<a href="articles/RJ-2009-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2009</div>
<div class="dt-authors">
<div class="dt-author">Stefan Theul</div>
<div class="dt-author">Achim Zeileis</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Collaborative Software Development Using R-Forge</h2>
<div class="dt-tags"></div>
<p>The 'Collaborative Software Development Using R-Forge' article from the 2009-1 issue.</p>
</div>
</a>
<a href="articles/RJ-2009-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2009</div>
<div class="dt-authors">
<div class="dt-author">John M. Chambers</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Facets of R</h2>
<div class="dt-tags"></div>
<p>The 'Facets of R' article from the 2009-1 issue.</p>
</div>
</a>
<a href="articles/RJ-2009-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2009</div>
<div class="dt-authors">
<div class="dt-author">Gregoire Pau</div>
<div class="dt-author">Wolfgang Huber</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The hwriter package : Composing HTML documents with R objects</h2>
<div class="dt-tags"></div>
<p>The 'The hwriter package : Composing HTML documents with R objects' article from the 2009-1 issue.</p>
</div>
</a>
<a href="articles/RJ-2009-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2009</div>
<div class="dt-authors">
<div class="dt-author">Alex Guazzelli, Michael Zeller, Wen-Ching Lin</div>
<div class="dt-author">Graham Williams</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>PMML: An Open Standard for Sharing Models</h2>
<div class="dt-tags"></div>
<p>The 'PMML: An Open Standard for Sharing Models' article from the 2009-1 issue.</p>
</div>
</a>
<a href="articles/RJ-2009-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2009</div>
<div class="dt-authors">
<div class="dt-author">Megan Orr</div>
<div class="dt-author">Peng Liu</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Sample Size Estimation while Controlling False Discovery Rate for Microarray Experiments Using the ssize.fdr Package</h2>
<div class="dt-tags"></div>
<p>Microarray experiments are becoming more and more popular and critical in many biological disciplines. As in any statistical experiment, appropriate experimental design is essential for reliable statistical inference, and sample size has a crucial role in experimental design. Because microarray experiments are rather costly, it is important to have an adequate sample size that will achieve a desired power without wasting resources.</p>
</div>
</a>
<a href="articles/RN-2008-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2008</div>
<div class="dt-authors">
<div class="dt-author">Hadley Wickham</div>
<div class="dt-author">Michael Lawrence</div>
<div class="dt-author">Duncan Temple Lang</div>
<div class="dt-author">Deborah F. Swayne</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2008-009/preview.png"/>
</div>
<div class="description">
<h2>An introduction to rggobi</h2>
<div class="dt-tags"></div>
<p>"An introduction to rggobi" published in R News.</p>
</div>
</a>
<a href="articles/RN-2008-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2008</div>
<div class="dt-authors">
<div class="dt-author">Carsten F. Dormann</div>
<div class="dt-author">Bernd Gruber</div>
<div class="dt-author">Jochen Frnd</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Introducing the bipartite package: Analysing ecological networks</h2>
<div class="dt-tags"></div>
<p>"Introducing the bipartite package: Analysing ecological networks" published in R News.</p>
</div>
</a>
<a href="articles/RN-2008-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2008</div>
<div class="dt-authors">
<div class="dt-author">Ioannis Kosmidis</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The profileModel R package: Profiling objectives for models with linear predictors</h2>
<div class="dt-tags"></div>
<p>"The profileModel R package: Profiling objectives for models with linear predictors" published in R News.</p>
</div>
</a>
<a href="articles/RN-2008-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2008</div>
<div class="dt-authors">
<div class="dt-author">Ingo Feinerer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>An introduction to text mining in R</h2>
<div class="dt-tags"></div>
<p>"An introduction to text mining in R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2008-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2008</div>
<div class="dt-authors">
<div class="dt-author">Yihui Xie</div>
<div class="dt-author">Xiaoyue Cheng</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Animation: A package for statistical animations</h2>
<div class="dt-tags"></div>
<p>"Animation: A package for statistical animations" published in R News.</p>
</div>
</a>
<a href="articles/RN-2008-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2008</div>
<div class="dt-authors">
<div class="dt-author">Thomas W. Yee</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The VGAM package</h2>
<div class="dt-tags"></div>
<p>"The VGAM package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2008-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2008</div>
<div class="dt-authors">
<div class="dt-author">Paul Murrell</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Comparing non-identical objects</h2>
<div class="dt-tags"></div>
<p>"Comparing non-identical objects" published in R News.</p>
</div>
</a>
<a href="articles/RN-2008-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2008</div>
<div class="dt-authors">
<div class="dt-author">A. Allignol</div>
<div class="dt-author">J. Beyersmann</div>
<div class="dt-author">M. Schumacher</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Mvna: An R package for the Nelson-Aalen estimator in multistate models</h2>
<div class="dt-tags"></div>
<p>"Mvna: An R package for the Nelson-Aalen estimator in multistate models" published in R News.</p>
</div>
</a>
<a href="articles/RN-2008-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2008</div>
<div class="dt-authors">
<div class="dt-author">Vince Carey</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Programmers Niche: The Y of R</h2>
<div class="dt-tags"></div>
<p>"Programmers Niche: The Y of R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2008-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2008</div>
<div class="dt-authors">
<div class="dt-author">Gregor Gorjanc</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Using Sweave with LyX</h2>
<div class="dt-tags"></div>
<p>"Using Sweave with LyX" published in R News.</p>
</div>
</a>
<a href="articles/RN-2008-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2008</div>
<div class="dt-authors">
<div class="dt-author">Jeff Enos</div>
<div class="dt-author">David Kane</div>
<div class="dt-author">Arjun Ravi Narayan</div>
<div class="dt-author">Aaron Schwartz</div>
<div class="dt-author">Daniel Suo</div>
<div class="dt-author">Luyi Zhao</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Trade costs</h2>
<div class="dt-tags"></div>
<p>"Trade costs" published in R News.</p>
</div>
</a>
<a href="articles/RN-2008-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2008</div>
<div class="dt-authors">
<div class="dt-author">Hormuzd A. Katki</div>
<div class="dt-author">Steven D. Mark</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Survival analysis for cohorts with missing covariate information</h2>
<div class="dt-tags"></div>
<p>"Survival analysis for cohorts with missing covariate information" published in R News.</p>
</div>
</a>
<a href="articles/RN-2008-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2008</div>
<div class="dt-authors">
<div class="dt-author">Vito M. R. Muggeo</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Segmented: An R package to fit regression models with broken-line relationships</h2>
<div class="dt-tags"></div>
<p>"Segmented: An R package to fit regression models with broken-line relationships" published in R News.</p>
</div>
</a>
<a href="articles/RN-2008-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2008</div>
<div class="dt-authors">
<div class="dt-author">Cathy W. S. Chen</div>
<div class="dt-author">Edward M. H. Lin</div>
<div class="dt-author">F. C. Liu</div>
<div class="dt-author">Richard Gerlach</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2008-005/preview.png"/>
</div>
<div class="description">
<h2>Bayesian estimation for parsimonious threshold autoregressive models in R</h2>
<div class="dt-tags"></div>
<p>"Bayesian estimation for parsimonious threshold autoregressive models in R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2008-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2008</div>
<div class="dt-authors">
<div class="dt-author">Vincent Goulet</div>
<div class="dt-author">Mathieu Pigeon</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Statistical modeling of loss distributions using actuar</h2>
<div class="dt-tags"></div>
<p>"Statistical modeling of loss distributions using actuar" published in R News.</p>
</div>
</a>
<a href="articles/RN-2008-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2008</div>
<div class="dt-authors">
<div class="dt-author">Robin K. S. Hankin</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Programmers Niche: Multivariate polynomials in r</h2>
<div class="dt-tags"></div>
<p>"Programmers Niche: Multivariate polynomials in r" published in R News.</p>
</div>
</a>
<a href="articles/RN-2008-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2008</div>
<div class="dt-authors">
<div class="dt-author">Uwe Ligges</div>
<div class="dt-author">John Fox</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>R Help Desk: How can I avoid this loop or make it faster?</h2>
<div class="dt-tags"></div>
<p>"R Help Desk: How can I avoid this loop or make it faster?" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-021/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Hee-Seok Oh</div>
<div class="dt-author">Donghoh Kim</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2007-021/preview.png"/>
</div>
<div class="description">
<h2>SpherWave: An R package for analyzing scattered spherical data by spherical wavelets</h2>
<div class="dt-tags"></div>
<p>"SpherWave: An R package for analyzing scattered spherical data by spherical wavelets" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-022/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Sebastin P. Luque</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2007-022/preview.png"/>
</div>
<div class="description">
<h2>Diving behaviour analysis in R</h2>
<div class="dt-tags"></div>
<p>"Diving behaviour analysis in R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-023/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Robin K. S. Hankin</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Very large numbers in R: Introducing package Brobdingnag</h2>
<div class="dt-tags"></div>
<p>"Very large numbers in R: Introducing package Brobdingnag" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-024/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Alejandro Jara</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Applied bayesian non- and semi-parametric inference using DPpackage</h2>
<div class="dt-tags"></div>
<p>"Applied bayesian non- and semi-parametric inference using DPpackage" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-025/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">John Verzani</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2007-025/preview.png"/>
</div>
<div class="description">
<h2>An introduction to gWidgets</h2>
<div class="dt-tags"></div>
<p>"An introduction to gWidgets" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-026/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Bill Alpert</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Financial journalism with R</h2>
<div class="dt-tags"></div>
<p>"Financial journalism with R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-027/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Sanford Weisberg</div>
<div class="dt-author">Hadley Wickham</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Need a hint?</h2>
<div class="dt-tags"></div>
<p>"Need a hint?" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-028/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Patrick Mair</div>
<div class="dt-author">Reinhold Hatzinger</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Psychometrics task view</h2>
<div class="dt-tags"></div>
<p>"Psychometrics task view" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-029/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Guido Schwarzer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Meta: An R package for meta-analysis</h2>
<div class="dt-tags"></div>
<p>"Meta: An R package for meta-analysis" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-030/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">John Fox</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2007-030/preview.png"/>
</div>
<div class="description">
<h2>Extending the R Commander by plug-in packages</h2>
<div class="dt-tags"></div>
<p>"Extending the R Commander by plug-in packages" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-031/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Sandra L. Taylor</div>
<div class="dt-author">Duncan Temple Lang</div>
<div class="dt-author">Katherine S. Pollard</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Improvements to the multiple testing package multtest</h2>
<div class="dt-tags"></div>
<p>"Improvements to the multiple testing package multtest" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Peter Dalgaard</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>New functions for multivariate analysis</h2>
<div class="dt-tags"></div>
<p>"New functions for multivariate analysis" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Heather Turner</div>
<div class="dt-author">David Firth</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Gnm: A package for generalized nonlinear models</h2>
<div class="dt-tags"></div>
<p>"Gnm: A package for generalized nonlinear models" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Jrg Polzehl</div>
<div class="dt-author">Karten Tabelow</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2007-013/preview.png"/>
</div>
<div class="description">
<h2>Fmri: A package for analyzing fmri data</h2>
<div class="dt-tags"></div>
<p>"Fmri: A package for analyzing fmri data" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Ben B. Hansen</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Optmatch: Flexible, optimal matching for observational studies</h2>
<div class="dt-tags"></div>
<p>"Optmatch: Flexible, optimal matching for observational studies" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Hemant Ishwaran</div>
<div class="dt-author">Udaya B. Kogalur</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Random survival forests for R</h2>
<div class="dt-tags"></div>
<p>"Random survival forests for R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Richard Newton</div>
<div class="dt-author">Lorenz Wernisch</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2007-016/preview.png"/>
</div>
<div class="description">
<h2>Rwui: A web application to create user friendly web interfaces for R scripts</h2>
<div class="dt-tags"></div>
<p>"Rwui: A web application to create user friendly web interfaces for R scripts" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Tristen Hayfield</div>
<div class="dt-author">Jeffrey S. Racine</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The np package: Kernel methods for categorical and continuous data</h2>
<div class="dt-tags"></div>
<p>"The np package: Kernel methods for categorical and continuous data" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Olivia Lau</div>
<div class="dt-author">Ryan T. Moore</div>
<div class="dt-author">Michael Kellermann</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>eiPack: {R} \times {C} ecological inferences and higher-dimension data management</h2>
<div class="dt-tags"></div>
<p>"eiPack: {R} \times {C} ecological inferences and higher-dimension data management" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Stphane Dray</div>
<div class="dt-author">Anne B. Dufour</div>
<div class="dt-author">Daniel Chessel</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The ade4 packageII: Two-table and {K}-table methods</h2>
<div class="dt-tags"></div>
<p>"The ade4 packageII: Two-table and {K}-table methods" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-020/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Friedrich Leisch</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Review of The R Book</h2>
<div class="dt-tags"></div>
<p>"Review of The R Book" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Paul Murrell</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Viewing binary files with the hexView package</h2>
<div class="dt-tags"></div>
<p>"Viewing binary files with the hexView package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Bettina Grn</div>
<div class="dt-author">Friedrich Leisch</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>FlexMix: An R package for finite mixture modelling</h2>
<div class="dt-tags"></div>
<p>"FlexMix: An R package for finite mixture modelling" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Andrea Onofri</div>
<div class="dt-author">Egidio Ciriciofolo</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Using R to perform the AMMI analysis on agriculture variety trials</h2>
<div class="dt-tags"></div>
<p>"Using R to perform the AMMI analysis on agriculture variety trials" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Gemechis Dilba</div>
<div class="dt-author">Frank Schaarschmidt</div>
<div class="dt-author">Ludwig A. Hothorn</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Inferences for ratios of normal means</h2>
<div class="dt-tags"></div>
<p>"Inferences for ratios of normal means" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Gregor Gorjanc</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Working with unknown values</h2>
<div class="dt-tags"></div>
<p>"Working with unknown values" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Jochen Einbeck</div>
<div class="dt-author">John Hinde</div>
<div class="dt-author">Ross Darnell</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>A new package for fitting random effect models</h2>
<div class="dt-tags"></div>
<p>"A new package for fitting random effect models" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Andrew Robinson</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Augmenting R with Unix tools</h2>
<div class="dt-tags"></div>
<p>"Augmenting R with Unix tools" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Mathieu Ribatet</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>POT: Modelling peaks over a threshold</h2>
<div class="dt-tags"></div>
<p>"POT: Modelling peaks over a threshold" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Kyle Campbell</div>
<div class="dt-author">Jeff Enos</div>
<div class="dt-author">Daniel Gerlanc</div>
<div class="dt-author">David Kane</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Backtests</h2>
<div class="dt-tags"></div>
<p>"Backtests" published in R News.</p>
</div>
</a>
<a href="articles/RN-2007-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">April 1, 2007</div>
<div class="dt-authors">
<div class="dt-author">Andy Liaw</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Review of John Verzanis book: Using R for Introductory Statistics</h2>
<div class="dt-tags"></div>
<p>"Review of John Verzanis book: Using R for Introductory Statistics" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-036/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Li Long</div>
<div class="dt-author">Vince Carey</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Graphs and networks: Tools in Bioconductor</h2>
<div class="dt-tags"></div>
<p>"Graphs and networks: Tools in Bioconductor" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-037/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Seth Falcon</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Modeling package dependencies using graphs</h2>
<div class="dt-tags"></div>
<p>"Modeling package dependencies using graphs" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-038/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Oleg Sklyar</div>
<div class="dt-author">Wolfgang Huber</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2006-038/preview.png"/>
</div>
<div class="description">
<h2>Image analysis for microscopy screens</h2>
<div class="dt-tags"></div>
<p>"Image analysis for microscopy screens" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-039/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Mark Dunning</div>
<div class="dt-author">Mike Smith</div>
<div class="dt-author">Natalie Thorne</div>
<div class="dt-author">Simon Tavar</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Beadarray: An R package to analyse Illumina BeadArrays</h2>
<div class="dt-tags"></div>
<p>"Beadarray: An R package to analyse Illumina BeadArrays" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-040/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Matthew Ritchie</div>
<div class="dt-author">Wolfgang Huber</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Transcript mapping with high-density tiling arrays</h2>
<div class="dt-tags"></div>
<p>"Transcript mapping with high-density tiling arrays" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-041/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Nolwenn Le Meur</div>
<div class="dt-author">Florian Hahne</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Analyzing flow cytometry data with Bioconductor</h2>
<div class="dt-tags"></div>
<p>"Analyzing flow cytometry data with Bioconductor" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-042/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Denise Scholtens</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Protein complex membership estimation using apComplex</h2>
<div class="dt-tags"></div>
<p>"Protein complex membership estimation using apComplex" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-043/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Vince Carey</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>SNP metadata access and use with Bioconductor</h2>
<div class="dt-tags"></div>
<p>"SNP metadata access and use with Bioconductor" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-044/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Steffen Durinck</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Integrating biological data resources into R with biomaRt</h2>
<div class="dt-tags"></div>
<p>"Integrating biological data resources into R with biomaRt" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-045/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Holger Schwender</div>
<div class="dt-author">Andreas Krause</div>
<div class="dt-author">Katja Ickstadt</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Identifying interesting genes with siggenes</h2>
<div class="dt-tags"></div>
<p>"Identifying interesting genes with siggenes" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-046/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Juliane Schfer</div>
<div class="dt-author">Rainer Opgen-Rhein</div>
<div class="dt-author">Korbinian Strimmer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Reverse engineering genetic networks using the GeneNet package</h2>
<div class="dt-tags"></div>
<p>"Reverse engineering genetic networks using the GeneNet package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-047/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Aedn C. Culhane</div>
<div class="dt-author">Jean Thioulouse</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>A multivariate approach to integrating datasets using made4 and ade4</h2>
<div class="dt-tags"></div>
<p>"A multivariate approach to integrating datasets using made4 and ade4" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-048/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Antoine Lucas</div>
<div class="dt-author">Sylvain Jasson</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Using amap and ctc packages for huge clustering</h2>
<div class="dt-tags"></div>
<p>"Using amap and ctc packages for huge clustering" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-049/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Chris Fraley</div>
<div class="dt-author">Adrian E. Raftery</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2006-049/preview.png"/>
</div>
<div class="description">
<h2>Model-based microarray image analysis</h2>
<div class="dt-tags"></div>
<p>"Model-based microarray image analysis" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-050/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Gregory R. Warnes</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Sample size estimation for microarray experiments using the ssize package</h2>
<div class="dt-tags"></div>
<p>"Sample size estimation for microarray experiments using the ssize package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-025/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Max Kuhn</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2006-025/preview.png"/>
</div>
<div class="description">
<h2>Sweave and the open document format  the odfWeave package</h2>
<div class="dt-tags"></div>
<p>"Sweave and the open document format  the odfWeave package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-026/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Jim Lemon</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Plotrix</h2>
<div class="dt-tags"></div>
<p>"Plotrix" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-027/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Adrian Bowman</div>
<div class="dt-author">Ewan Crawford</div>
<div class="dt-author">Richard Bowman</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2006-027/preview.png"/>
</div>
<div class="description">
<h2>Rpanel: Making graphs move with tcltk</h2>
<div class="dt-tags"></div>
<p>"Rpanel: Making graphs move with tcltk" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-028/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Matthew Pocernich</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Rs role in the climate change debate.</h2>
<div class="dt-tags"></div>
<p>"Rs role in the climate change debate." published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-029/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Roger D. Peng</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Interacting with data using the filehash package</h2>
<div class="dt-tags"></div>
<p>"Interacting with data using the filehash package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-030/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Robin K. S. Hankin</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Special functions in R: Introducing the gsl package</h2>
<div class="dt-tags"></div>
<p>"Special functions in R: Introducing the gsl package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-031/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Wolfgang Lederer</div>
<div class="dt-author">Helmut Kchenhoff</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>A short introduction to the SIMEX and MCSIMEX</h2>
<div class="dt-tags"></div>
<p>"A short introduction to the SIMEX and MCSIMEX" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-032/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Roger Koenker</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Parametric links for binary response</h2>
<div class="dt-tags"></div>
<p>"Parametric links for binary response" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-033/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Vctor Leiva</div>
<div class="dt-author">Hugo Hernndez</div>
<div class="dt-author">Marco Riquelme</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>A new package for the Birnbaum-Saunders distribution</h2>
<div class="dt-tags"></div>
<p>"A new package for the Birnbaum-Saunders distribution" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-034/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Susan Holmes</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Review of Fionn Murtaghs book:
correspondence analysis and data coding with Java and R</h2>
<div class="dt-tags"></div>
<p>"Review of Fionn Murtaghs book:
correspondence analysis and data coding with Java and R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-035/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Uwe Ligges</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>R Help Desk: Accessing the sources</h2>
<div class="dt-tags"></div>
<p>"R Help Desk: Accessing the sources" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-021/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Johannes Ranke</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2003-021/preview.png"/>
</div>
<div class="description">
<h2>Fitting dose-response curves from bioassays and toxicity testing</h2>
<div class="dt-tags"></div>
<p>"Fitting dose-response curves from bioassays and toxicity testing" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-020/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Peter Watkins</div>
<div class="dt-author">Bill Venables</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Non-linear regression for optimising the separation of carboxylic acids</h2>
<div class="dt-tags"></div>
<p>"Non-linear regression for optimising the separation of carboxylic acids" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-021/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Bjrn-Helge Mevik</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The pls package</h2>
<div class="dt-tags"></div>
<p>"The pls package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-022/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Chris Fraley</div>
<div class="dt-author">Adrian E. Raftery</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Some applications of model-based clustering in chemistry</h2>
<div class="dt-tags"></div>
<p>"Some applications of model-based clustering in chemistry" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-023/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Ron Wehrens</div>
<div class="dt-author">Egon Willighagen</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Mapping databases of X-ray powder patterns</h2>
<div class="dt-tags"></div>
<p>"Mapping databases of X-ray powder patterns" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-024/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Rajarshi Guha</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2006-024/preview.png"/>
</div>
<div class="description">
<h2>Generating, using and visualizing molecular information in R</h2>
<div class="dt-tags"></div>
<p>"Generating, using and visualizing molecular information in R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Peter Ruckdeschel</div>
<div class="dt-author">Matthias Kohl</div>
<div class="dt-author">Thomas Stabla</div>
<div class="dt-author">Florian Camphausen</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>S4 classes for distributions</h2>
<div class="dt-tags"></div>
<p>"S4 classes for distributions" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">David Clifford</div>
<div class="dt-author">Peter McCullagh</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The regress function</h2>
<div class="dt-tags"></div>
<p>"The regress function" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Lukasz Komsta</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Processing data for outliers</h2>
<div class="dt-tags"></div>
<p>"Processing data for outliers" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">David Kane</div>
<div class="dt-author">Jeff Enos</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Analysing equity portfolios in R</h2>
<div class="dt-tags"></div>
<p>"Analysing equity portfolios in R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Roman Pahl</div>
<div class="dt-author">Andreas Ziegler</div>
<div class="dt-author">Inke R. Knig</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2006-011/preview.png"/>
</div>
<div class="description">
<h2>GroupSeq: Designing clinical trials using group sequential designs</h2>
<div class="dt-tags"></div>
<p>"GroupSeq: Designing clinical trials using group sequential designs" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Sven Garbade</div>
<div class="dt-author">Peter Burgard</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2006-012/preview.png"/>
</div>
<div class="description">
<h2>Using R/Sweave in everyday clinical practice</h2>
<div class="dt-tags"></div>
<p>"Using R/Sweave in everyday clinical practice" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">M. Wangler</div>
<div class="dt-author">J. Beyersmann</div>
<div class="dt-author">M. Schumacher</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>changeLOS: An R-package for change in length of hospital stay based on the Aalen-Johansen estimator</h2>
<div class="dt-tags"></div>
<p>"changeLOS: An R-package for change in length of hospital stay based on the Aalen-Johansen estimator" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Nitin Jain</div>
<div class="dt-author">Gregory R. Warnes</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Balloon plot</h2>
<div class="dt-tags"></div>
<p>"Balloon plot" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Jing Hua Zhao</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Drawing pedigree diagrams with R and graphviz</h2>
<div class="dt-tags"></div>
<p>"Drawing pedigree diagrams with R and graphviz" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Paul Murrell</div>
<div class="dt-author">Brian Ripley</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2006-016/preview.png"/>
</div>
<div class="description">
<h2>Non-standard fonts in PostScript and PDF graphics</h2>
<div class="dt-tags"></div>
<p>"Non-standard fonts in PostScript and PDF graphics" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Sren Hjsgaard</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The doBy package</h2>
<div class="dt-tags"></div>
<p>"The doBy package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Robin K. S. Hankin</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Normed division algebras with R: Introducing the onion package</h2>
<div class="dt-tags"></div>
<p>"Normed division algebras with R: Introducing the onion package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Robin K. S. Hankin</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Electrical properties of resistor networks</h2>
<div class="dt-tags"></div>
<p>"Electrical properties of resistor networks" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Andrew D. Martin</div>
<div class="dt-author">Kevin M. Quinn</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Applied Bayesian inference in R using MCMCpack</h2>
<div class="dt-tags"></div>
<p>"Applied Bayesian inference in R using MCMCpack" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Martyn Plummer</div>
<div class="dt-author">Nicky Best</div>
<div class="dt-author">Kate Cowles</div>
<div class="dt-author">Karen Vines</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>CODA: Convergence diagnosis and output analysis for MCMC</h2>
<div class="dt-tags"></div>
<p>"CODA: Convergence diagnosis and output analysis for MCMC" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Samantha Cook</div>
<div class="dt-author">Andrew Gelman</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Bayesian software validation</h2>
<div class="dt-tags"></div>
<p>"Bayesian software validation" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Andrew Thomas</div>
<div class="dt-author">Bob OHara</div>
<div class="dt-author">Uwe Ligges</div>
<div class="dt-author">Sibylle Sturtz</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Making BUGS open</h2>
<div class="dt-tags"></div>
<p>"Making BUGS open" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Andrew Thomas</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The BUGS language</h2>
<div class="dt-tags"></div>
<p>"The BUGS language" published in R News.</p>
</div>
</a>
<a href="articles/RN-2006-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 1, 2006</div>
<div class="dt-authors">
<div class="dt-author">Jouni Kerman</div>
<div class="dt-author">Andrew Gelman</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Bayesian data analysis using R</h2>
<div class="dt-tags"></div>
<p>"Bayesian data analysis using R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2005-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2005</div>
<div class="dt-authors">
<div class="dt-author">Adrian E. Raftery</div>
<div class="dt-author">Ian S. Painter</div>
<div class="dt-author">Christopher T. Volinsky</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>BMA: An R package for Bayesian model averaging</h2>
<div class="dt-tags"></div>
<p>"BMA: An R package for Bayesian model averaging" published in R News.</p>
</div>
</a>
<a href="articles/RN-2005-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2005</div>
<div class="dt-authors">
<div class="dt-author">Edzer J. Pebesma</div>
<div class="dt-author">Roger S. Bivand</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Classes and methods for spatial data in R</h2>
<div class="dt-tags"></div>
<p>"Classes and methods for spatial data in R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2005-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2005</div>
<div class="dt-authors">
<div class="dt-author">Xianhong Xie</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Running long R jobs with Condor DAG</h2>
<div class="dt-tags"></div>
<p>"Running long R jobs with Condor DAG" published in R News.</p>
</div>
</a>
<a href="articles/RN-2005-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2005</div>
<div class="dt-authors">
<div class="dt-author">Pierre LEcuyer</div>
<div class="dt-author">Josef Leydold</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Rstream: Streams of random numbers for stochastic simulation</h2>
<div class="dt-tags"></div>
<p>"Rstream: Streams of random numbers for stochastic simulation" published in R News.</p>
</div>
</a>
<a href="articles/RN-2005-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2005</div>
<div class="dt-authors">
<div class="dt-author">Axel Benner</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Mfp: Multivariable fractional polynomials</h2>
<div class="dt-tags"></div>
<p>"Mfp: Multivariable fractional polynomials" published in R News.</p>
</div>
</a>
<a href="articles/RN-2005-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2005</div>
<div class="dt-authors">
<div class="dt-author">Oliver Sailer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Crossdes: A package for design and randomization in crossover studies</h2>
<div class="dt-tags"></div>
<p>"Crossdes: A package for design and randomization in crossover studies" published in R News.</p>
</div>
</a>
<a href="articles/RN-2005-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 1, 2005</div>
<div class="dt-authors">
<div class="dt-author">Uwe Ligges</div>
<div class="dt-author">Duncan Murdoch</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>R Help Desk: Make R CMD work under Windows  an example</h2>
<div class="dt-tags"></div>
<p>"R Help Desk: Make R CMD work under Windows  an example" published in R News.</p>
</div>
</a>
<a href="articles/RN-2005-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2005</div>
<div class="dt-authors">
<div class="dt-author">Brian D. Ripley</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2005-001/preview.png"/>
</div>
<div class="description">
<h2>Internationalization features of R 2.1.0</h2>
<div class="dt-tags"></div>
<p>"Internationalization features of R 2.1.0" published in R News.</p>
</div>
</a>
<a href="articles/RN-2005-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2005</div>
<div class="dt-authors">
<div class="dt-author">Brian D. Ripley</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2005-002/preview.png"/>
</div>
<div class="description">
<h2>Packages and their management in R 2.1.0</h2>
<div class="dt-tags"></div>
<p>"Packages and their management in R 2.1.0" published in R News.</p>
</div>
</a>
<a href="articles/RN-2005-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2005</div>
<div class="dt-authors">
<div class="dt-author">Paul Murrell</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Recent changes in grid graphics</h2>
<div class="dt-tags"></div>
<p>"Recent changes in grid graphics" published in R News.</p>
</div>
</a>
<a href="articles/RN-2005-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2005</div>
<div class="dt-authors">
<div class="dt-author">Alessandra Brazzale</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Hoa: An R package bundle for higher order likelihood inference</h2>
<div class="dt-tags"></div>
<p>"Hoa: An R package bundle for higher order likelihood inference" published in R News.</p>
</div>
</a>
<a href="articles/RN-2005-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2005</div>
<div class="dt-authors">
<div class="dt-author">Douglas Bates</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Fitting linear mixed models in R</h2>
<div class="dt-tags"></div>
<p>"Fitting linear mixed models in R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2005-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2005</div>
<div class="dt-authors">
<div class="dt-author">Ray Brownrigg</div>
<div class="dt-author">David Harte</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Using R for statistical seismology</h2>
<div class="dt-tags"></div>
<p>"Using R for statistical seismology" published in R News.</p>
</div>
</a>
<a href="articles/RN-2005-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2005</div>
<div class="dt-authors">
<div class="dt-author">Jonathan Rougier</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Literate programming for creating and maintaining packages</h2>
<div class="dt-tags"></div>
<p>"Literate programming for creating and maintaining packages" published in R News.</p>
</div>
</a>
<a href="articles/RN-2005-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2005</div>
<div class="dt-authors">
<div class="dt-author">Achim Zeileis</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>CRAN task views</h2>
<div class="dt-tags"></div>
<p>"CRAN task views" published in R News.</p>
</div>
</a>
<a href="articles/RN-2005-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2005</div>
<div class="dt-authors">
<div class="dt-author">Damian Betebenner</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Using control structures with Sweave</h2>
<div class="dt-tags"></div>
<p>"Using control structures with Sweave" published in R News.</p>
</div>
</a>
<a href="articles/RN-2005-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2005</div>
<div class="dt-authors">
<div class="dt-author">Bill Pikounis</div>
<div class="dt-author">Andy Liaw</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The value of R for preclinical statisticians</h2>
<div class="dt-tags"></div>
<p>"The value of R for preclinical statisticians" published in R News.</p>
</div>
</a>
<a href="articles/RN-2005-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2005</div>
<div class="dt-authors">
<div class="dt-author">Robin K. S. Hankin</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Recreational mathematics with R: Introducing the magic package</h2>
<div class="dt-tags"></div>
<p>"Recreational mathematics with R: Introducing the magic package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2005-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">May 1, 2005</div>
<div class="dt-authors">
<div class="dt-author">John Fox</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Programmers Niche: How do you spell that number?</h2>
<div class="dt-tags"></div>
<p>"Programmers Niche: How do you spell that number?" published in R News.</p>
</div>
</a>
<a href="articles/RN-2004-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 1, 2004</div>
<div class="dt-authors">
<div class="dt-author">Brian D. Ripley</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Lazy loading and packages in R 2.0.0</h2>
<div class="dt-tags"></div>
<p>"Lazy loading and packages in R 2.0.0" published in R News.</p>
</div>
</a>
<a href="articles/RN-2004-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 1, 2004</div>
<div class="dt-authors">
<div class="dt-author">Paul Murrell</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Fonts, lines, and transparency in R graphics</h2>
<div class="dt-tags"></div>
<p>"Fonts, lines, and transparency in R graphics" published in R News.</p>
</div>
</a>
<a href="articles/RN-2004-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 1, 2004</div>
<div class="dt-authors">
<div class="dt-author">Roger D. Peng</div>
<div class="dt-author">Leah J. Welty</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The NMMAPSdata package</h2>
<div class="dt-tags"></div>
<p>"The NMMAPSdata package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2004-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 1, 2004</div>
<div class="dt-authors">
<div class="dt-author">Jeff Gentry</div>
<div class="dt-author">Vincent Carey</div>
<div class="dt-author">Emden Gansner</div>
<div class="dt-author">Robert Gentleman</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Laying out pathways with Rgraphviz</h2>
<div class="dt-tags"></div>
<p>"Laying out pathways with Rgraphviz" published in R News.</p>
</div>
</a>
<a href="articles/RN-2004-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 1, 2004</div>
<div class="dt-authors">
<div class="dt-author">Jun Yan</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Fusing R and BUGS through Wine</h2>
<div class="dt-tags"></div>
<p>"Fusing R and BUGS through Wine" published in R News.</p>
</div>
</a>
<a href="articles/RN-2004-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 1, 2004</div>
<div class="dt-authors">
<div class="dt-author">Paul Gilbert</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>R package maintenance</h2>
<div class="dt-tags"></div>
<p>"R package maintenance" published in R News.</p>
</div>
</a>
<a href="articles/RN-2004-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2004</div>
<div class="dt-authors">
<div class="dt-author">Marc Schwartz</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The decision to use R</h2>
<div class="dt-tags"></div>
<p>"The decision to use R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2004-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2004</div>
<div class="dt-authors">
<div class="dt-author">Daniel Chessel</div>
<div class="dt-author">Anne B. Dufour</div>
<div class="dt-author">Jean Thioulouse</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The ade4 package  I: One-table methods</h2>
<div class="dt-tags"></div>
<p>"The ade4 package  I: One-table methods" published in R News.</p>
</div>
</a>
<a href="articles/RN-2004-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2004</div>
<div class="dt-authors">
<div class="dt-author">Luca Scrucca</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Qcc: An R package for quality control charting and statistical process control</h2>
<div class="dt-tags"></div>
<p>"Qcc: An R package for quality control charting and statistical process control" published in R News.</p>
</div>
</a>
<a href="articles/RN-2004-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2004</div>
<div class="dt-authors">
<div class="dt-author">Douglas Bates</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Least squares calculations in R</h2>
<div class="dt-tags"></div>
<p>"Least squares calculations in R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2004-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2004</div>
<div class="dt-authors">
<div class="dt-author">Jianhua Zhang</div>
<div class="dt-author">Robert Gentleman</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2004-005/preview.png"/>
</div>
<div class="description">
<h2>Tools for interactively exploring R packages</h2>
<div class="dt-tags"></div>
<p>"Tools for interactively exploring R packages" published in R News.</p>
</div>
</a>
<a href="articles/RN-2004-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2004</div>
<div class="dt-authors">
<div class="dt-author">Thomas Lumley</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The survival package</h2>
<div class="dt-tags"></div>
<p>"The survival package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2004-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2004</div>
<div class="dt-authors">
<div class="dt-author">Gabor Grothendieck</div>
<div class="dt-author">Thomas Petzoldt</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>R Help Desk: Date and time classes in R</h2>
<div class="dt-tags"></div>
<p>"R Help Desk: Date and time classes in R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2004-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2004</div>
<div class="dt-authors">
<div class="dt-author">Thomas Lumley</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Programmers Niche: A simple class, in S3 and S4</h2>
<div class="dt-tags"></div>
<p>"Programmers Niche: A simple class, in S3 and S4" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">Jonathan Edwards</div>
<div class="dt-author">Paul Oman</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Dimensional reduction for data mapping</h2>
<div class="dt-tags"></div>
<p>"Dimensional reduction for data mapping" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">Thomas Petzoldt</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2003-015/preview.png"/>
</div>
<div class="description">
<h2>R as a simulation platform in ecological modelling</h2>
<div class="dt-tags"></div>
<p>"R as a simulation platform in ecological modelling" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">J. R. Lockwood</div>
<div class="dt-author">Harold Doran</div>
<div class="dt-author">Daniel F. McCaffrey</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Using R for estimating longitudinal student achievement models</h2>
<div class="dt-tags"></div>
<p>"Using R for estimating longitudinal student achievement models" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">Rod Ball</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>lmeSplines</h2>
<div class="dt-tags"></div>
<p>"lmeSplines" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">Mark Bravington</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Debugging without (too many) tears</h2>
<div class="dt-tags"></div>
<p>"Debugging without (too many) tears" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">Eric Lecoutre</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The R2HTML package</h2>
<div class="dt-tags"></div>
<p>"The R2HTML package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-020/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">Uwe Ligges</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>R Help Desk: Package management</h2>
<div class="dt-tags"></div>
<p>"R Help Desk: Package management" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">Marc Schwartz</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>R Help Desk: An introduction to using Rs base graphics</h2>
<div class="dt-tags"></div>
<p>"R Help Desk: An introduction to using Rs base graphics" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">Paul Murrell</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Integrating grid graphics output with base graphics output</h2>
<div class="dt-tags"></div>
<p>"Integrating grid graphics output with base graphics output" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">Angelo Mineo</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>A new package for the general error distribution</h2>
<div class="dt-tags"></div>
<p>"A new package for the general error distribution" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">Colin A. Smith</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2003-012/preview.png"/>
</div>
<div class="description">
<h2>Web-based microarray analysis using Bioconductor</h2>
<div class="dt-tags"></div>
<p>"Web-based microarray analysis using Bioconductor" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">Friedrich Leisch</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Sweave, part II: Package vignettes</h2>
<div class="dt-tags"></div>
<p>"Sweave, part II: Package vignettes" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">Luke Tierney</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Name space management for R</h2>
<div class="dt-tags"></div>
<p>"Name space management for R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">Douglas Bates</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Converting packages to S4</h2>
<div class="dt-tags"></div>
<p>"Converting packages to S4" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">Gregory R. Warnes</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The genetics package</h2>
<div class="dt-tags"></div>
<p>"The genetics package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">Jrgen Gro</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Variance inflation factors</h2>
<div class="dt-tags"></div>
<p>"Variance inflation factors" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">Jun Yan</div>
<div class="dt-author">A. J. Rossini</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Building Microsoft Windows versions of R and R packages under Intel Linux</h2>
<div class="dt-tags"></div>
<p>"Building Microsoft Windows versions of R and R packages under Intel Linux" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">Thomas Lumley</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Analysing survey data in R</h2>
<div class="dt-tags"></div>
<p>"Analysing survey data in R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">Brett Carson</div>
<div class="dt-author">Robert Murison</div>
<div class="dt-author">Ian A. Mason</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Computational gains using RPVM on a Beowulf cluster</h2>
<div class="dt-tags"></div>
<p>"Computational gains using RPVM on a Beowulf cluster" published in R News.</p>
</div>
</a>
<a href="articles/RN-2003-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2003</div>
<div class="dt-authors">
<div class="dt-author">Uwe Ligges</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>R Help Desk: Getting help  Rs help facilities and manuals</h2>
<div class="dt-tags"></div>
<p>"R Help Desk: Getting help  Rs help facilities and manuals" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Angelo J. Canty</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2002-017/preview.png"/>
</div>
<div class="description">
<h2>Resampling methods in R: The boot package</h2>
<div class="dt-tags"></div>
<p>"Resampling methods in R: The boot package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Achim Zeileis</div>
<div class="dt-author">Torsten Hothorn</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Diagnostic checking in regression relationships</h2>
<div class="dt-tags"></div>
<p>"Diagnostic checking in regression relationships" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">David E. Brahm</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Delayed data packages</h2>
<div class="dt-tags"></div>
<p>"Delayed data packages" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-020/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Jun Yan</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Geepack: Yet another package for generalized estimating equations</h2>
<div class="dt-tags"></div>
<p>"Geepack: Yet another package for generalized estimating equations" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-021/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Frank Bretz</div>
<div class="dt-author">Torsten Hothorn</div>
<div class="dt-author">Peter Westfall</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>On multiple comparisons in R</h2>
<div class="dt-tags"></div>
<p>"On multiple comparisons in R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-022/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Andy Liaw</div>
<div class="dt-author">Matthew Wiener</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Classification and regression by randomForest</h2>
<div class="dt-tags"></div>
<p>"Classification and regression by randomForest" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-023/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Robert Gentleman</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Some strategies for dealing with genomic data</h2>
<div class="dt-tags"></div>
<p>"Some strategies for dealing with genomic data" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-024/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Peter Dalgaard</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Changes to the R-Tcl/Tk package</h2>
<div class="dt-tags"></div>
<p>"Changes to the R-Tcl/Tk package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-025/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Friedrich Leisch</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2002-025/preview.png"/>
</div>
<div class="description">
<h2>Sweave, part I: Mixing R and LaTeX</h2>
<div class="dt-tags"></div>
<p>"Sweave, part I: Mixing R and LaTeX" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-026/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Uwe Ligges</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>R Help Desk: Automation of mathematical annotation in plots</h2>
<div class="dt-tags"></div>
<p>"R Help Desk: Automation of mathematical annotation in plots" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Brian D. Ripley</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Time series in R 1.5.0</h2>
<div class="dt-tags"></div>
<p>"Time series in R 1.5.0" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">David Meyer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Naive time series forecasting methods</h2>
<div class="dt-tags"></div>
<p>"Naive time series forecasting methods" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Hao Yu</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Rmpi: Parallel statistical computing in R</h2>
<div class="dt-tags"></div>
<p>"Rmpi: Parallel statistical computing in R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Paul Murrell</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The grid graphics package</h2>
<div class="dt-tags"></div>
<p>"The grid graphics package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Deepayan Sarkar</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Lattice</h2>
<div class="dt-tags"></div>
<p>"Lattice" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Bill Venables</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Programmers Niche</h2>
<div class="dt-tags"></div>
<p>"Programmers Niche" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Ole F. Christensen</div>
<div class="dt-author">Paulo J. Ribeiro</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>geoRglm: A package for generalised linear spatial models</h2>
<div class="dt-tags"></div>
<p>"geoRglm: A package for generalised linear spatial models" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Robert Gentleman</div>
<div class="dt-author">Jeff Gentry</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Querying PubMed</h2>
<div class="dt-tags"></div>
<p>"Querying PubMed" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Alec Stephenson</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Evd: Extreme value distributions</h2>
<div class="dt-tags"></div>
<p>"Evd: Extreme value distributions" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Andrea Peters</div>
<div class="dt-author">Torsten Hothorn</div>
<div class="dt-author">Berthold Lausen</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Ipred: Improved predictors</h2>
<div class="dt-tags"></div>
<p>"Ipred: Improved predictors" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Duncan Murdoch</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Reading foreign files</h2>
<div class="dt-tags"></div>
<p>"Reading foreign files" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Torsten Hothorn</div>
<div class="dt-author">Berthold Lausen</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Maximally selected rank statistics in R</h2>
<div class="dt-tags"></div>
<p>"Maximally selected rank statistics in R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Gnther Sawitzki</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Quality control and early diagnostics for cDNA microarrays</h2>
<div class="dt-tags"></div>
<p>"Quality control and early diagnostics for cDNA microarrays" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Robert Gentleman</div>
<div class="dt-author">Vincent Carey</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Bioconductor</h2>
<div class="dt-tags"></div>
<p>"Bioconductor" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Jonathan Marchini</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>AnalyzeFMRI: An R package for the exploration and analysis of MRI and fMRI datasets</h2>
<div class="dt-tags"></div>
<p>"AnalyzeFMRI: An R package for the exploration and analysis of MRI and fMRI datasets" published in R News.</p>
</div>
</a>
<a href="articles/RN-2002-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">March 1, 2002</div>
<div class="dt-authors">
<div class="dt-author">Sandrine Dudoit</div>
<div class="dt-author">Yee Hwa Yang</div>
<div class="dt-author">Ben Bolstad</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2002-006/preview.png"/>
</div>
<div class="description">
<h2>Using R for the analysis of DNA microarray data</h2>
<div class="dt-tags"></div>
<p>"Using R for the analysis of DNA microarray data" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-018/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Jan Leeuw</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Porting R to Darwin/X11 and Mac OS X</h2>
<div class="dt-tags"></div>
<p>"Porting R to Darwin/X11 and Mac OS X" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-019/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Michael Na Li</div>
<div class="dt-author">A. J. Rossini</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>RPVM: Cluster statistical computing in R</h2>
<div class="dt-tags"></div>
<p>"RPVM: Cluster statistical computing in R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-020/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Achim Zeileis</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Strucchange: Testing for structural change in linear regression relationships</h2>
<div class="dt-tags"></div>
<p>"Strucchange: Testing for structural change in linear regression relationships" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-021/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Thomas Lumley</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Programmers Niche: Macros in R</h2>
<div class="dt-tags"></div>
<p>"Programmers Niche: Macros in R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-022/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Roger Bivand</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>More on spatial data</h2>
<div class="dt-tags"></div>
<p>"More on spatial data" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-023/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">John M. Chambers</div>
<div class="dt-author">Duncan Temple Lang</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Object-oriented programming in R</h2>
<div class="dt-tags"></div>
<p>"Object-oriented programming in R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-024/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Duncan Temple Lang</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>In search of C/C++ &amp; FORTRAN routines</h2>
<div class="dt-tags"></div>
<p>"In search of C/C++ &amp; FORTRAN routines" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-025/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">David Meyer</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Support vector machines</h2>
<div class="dt-tags"></div>
<p>"Support vector machines" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-026/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Peter Dalgaard</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2001-026/preview.png"/>
</div>
<div class="description">
<h2>A primer on the R-Tcl/Tk package</h2>
<div class="dt-tags"></div>
<p>"A primer on the R-Tcl/Tk package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-027/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Claudio Agostinelli</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Wle: A package for robust statistics using weighted likelihood</h2>
<div class="dt-tags"></div>
<p>"Wle: A package for robust statistics using weighted likelihood" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-011/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Brian D. Ripley</div>
<div class="dt-author">Kurt Hornik</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Date-time classes</h2>
<div class="dt-tags"></div>
<p>"Date-time classes" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-012/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Brian D. Ripley</div>
</div>
</div>
<div class="thumbnail">
<img data-src="articles/RN-2001-012/preview.png"/>
</div>
<div class="description">
<h2>Installing R under Windows</h2>
<div class="dt-tags"></div>
<p>"Installing R under Windows" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-013/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Paulo J. Ribeiro, Jr.</div>
<div class="dt-author">Peter J. Diggle</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>geoR: A package for geostatistical analysis</h2>
<div class="dt-tags"></div>
<p>"geoR: A package for geostatistical analysis" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-014/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Martin Schlather</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Simulation and analysis of random fields</h2>
<div class="dt-tags"></div>
<p>"Simulation and analysis of random fields" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-015/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Simon N. Wood</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Mgcv: GAMs and generalized ridge regression for R</h2>
<div class="dt-tags"></div>
<p>"Mgcv: GAMs and generalized ridge regression for R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-016/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Jonathan Rougier</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Whats the point of tensor?</h2>
<div class="dt-tags"></div>
<p>"Whats the point of tensor?" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-017/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">June 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Torsten Hothorn</div>
<div class="dt-author">Frank Bretz</div>
<div class="dt-author">Alan Genz</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>On multivariate t and Gau probabilities in R</h2>
<div class="dt-tags"></div>
<p>"On multivariate t and Gau probabilities in R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-001/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Luke Tierney</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Under new memory management</h2>
<div class="dt-tags"></div>
<p>"Under new memory management" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-002/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Torsten Hothorn</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>On exact rank tests in R</h2>
<div class="dt-tags"></div>
<p>"On exact rank tests in R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-003/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Stefano M. Iacus</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Porting R to the Macintosh</h2>
<div class="dt-tags"></div>
<p>"Porting R to the Macintosh" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-004/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Peter Dalgaard</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>The density of the non-central chi-squared distribution for large values of the noncentrality parameter</h2>
<div class="dt-tags"></div>
<p>"The density of the non-central chi-squared distribution for large values of the noncentrality parameter" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-005/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Brian D. Ripley</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Connections</h2>
<div class="dt-tags"></div>
<p>"Connections" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-006/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Brian D. Ripley</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Using databases with R</h2>
<div class="dt-tags"></div>
<p>"Using databases with R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-007/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">M. J. Ray</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Rcgi 4: Making web statistics even easier</h2>
<div class="dt-tags"></div>
<p>"Rcgi 4: Making web statistics even easier" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-008/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">John M. Chambers</div>
<div class="dt-author">Duncan Temple Lang</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Omegahat packages for R</h2>
<div class="dt-tags"></div>
<p>"Omegahat packages for R" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-009/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Duncan Temple Lang</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Using XML for statistics: The XML package</h2>
<div class="dt-tags"></div>
<p>"Using XML for statistics: The XML package" published in R News.</p>
</div>
</a>
<a href="articles/RN-2001-010/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 1, 2001</div>
<div class="dt-authors">
<div class="dt-author">Bill Venables</div>
</div>
</div>
<div class="thumbnail">
<img/>
</div>
<div class="description">
<h2>Programmers Niche</h2>
<div class="dt-tags"></div>
<p>"Programmers Niche" published in R News.</p>
</div>
</a>
</div>
<div class="posts-more">
<a href="#">More articles &raquo;</a>
</div>
</div>
<!--/radix_placeholder_article_listing-->

<div class="d-title">
<h1>All articles</h1>

<!--radix_placeholder_categories-->
<!--/radix_placeholder_categories-->
<p><p>All articles accepted into the R Journal.</p></p>
</div>


<div class="d-article">
<div class="sourceCode" id="cb1"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<div class="distill-site-nav distill-site-footer">
<p> The R Foundation, <a href="mailto:r-journal@r-project.org">web page
contact</a>.</p>
</div>
<!--/radix_placeholder_navigation_after_body-->


</body>

</html>
