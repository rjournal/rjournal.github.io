@article{Astrom1965,
title = "Optimal control of {M}arkov processes with incomplete state information",
journal = "Journal of Mathematical Analysis and Applications",
volume = "10",
number = "1",
pages = "174 - 205",
year = "1965",
issn = "0022-247X",
author = "K.J Åström"
}

@misc{APPL2022,
title = {{APPL}: {A}pproximate {POMDP} Planning Toolkit},
url = "https://bigbird.comp.nus.edu.sg/pmwiki/farm/appl/",
year = {2022},
author = {{APPL Team}},
}

@misc{ZMDP2009,
title = {{ZMDP}: {S}oftware for {POMDP} and {MDP} Planning},
url = "https://github.com/trey0/zmdp",
year = {2009},
author = {T. Smith},
}

@misc{pypomdp2013,
title = {{pyPOMDP:} {POMDP} implementation in {Python}},
url = "https://bitbucket.org/bami/pypomdp/src/master/",
year = {2013},
author = {Bastian Migge and Oliver Stollmann},
}

@misc{juliapomdp2022,
title = {{JuliaPOMDP:} {POMDP} packages for {Julia}},
url = "https://github.com/JuliaPOMDP",
year = {2022},
author = {{JuliaPOMDP Team}},
}

@misc{Cassandra2015,
title = {The {POMDP} Page},
url = "https://www.pomdp.org",
year = {2015},
 author = {Cassandra, Anthony R.},
}


@phdthesis{Cassandra1998,
 author = {Cassandra, Anthony R.},
 advisor = {Kaelbling, Leslie Pack},
 title = {Exact and Approximate Algorithms for Partially Observable Markov Decision Processes},
 year = {1998},
 isbn = {0-591-83322-0},
 note = {AAI9830418},
 publisher = {Brown University},
 address = {Providence, RI, USA},
} 

@article{Kaelbling1998,
title = "Planning and acting in partially observable stochastic domains",
journal = "Artificial Intelligence",
volume = "101",
number = "1",
pages = "99--134",
year = "1998",
issn = "0004-3702",
doi = "10.1016/S0004-3702(98)00023-X",
author = "Leslie Pack Kaelbling and Michael L. Littman and Anthony R. Cassandra",
}

@article{Littman2009,
title = "A tutorial on partially observable Markov decision processes",
journal = "Journal of Mathematical Psychology",
volume = "53",
number = "3",
pages = "119--125",
year = "2009",
note = "Special Issue: Dynamic Decision Making",
issn = "0022-2496",
doi = "10.1016/j.jmp.2009.01.005",
author = "Michael L. Littman",
}

@inproceedings{Cassandra1994,
        Address = {Seattle, WA},
        Author = {Anthony R. Cassandra and Leslie Pack Kaelbling and Michael L. Littman},
        Booktitle = {Proceedings of the Twelfth National Conference on Artificial Intelligence},
        Title = {Acting Optimally in Partially Observable Stochastic Domains},
        Year = {1994},
  note = {{AAAI} Classic Paper Award, 2013},
}

@phdthesis{Sondik1971,
  author = {Sondik, E. J.},
  school = {Stanford, California},
  title = {The Optimal Control of Partially Observable {M}arkov Decision Processes},
  year = 1971
}

@article{Smallwood1973,
    title = {The optimal control of partially observable {M}arkov decision processes over a finite horizon},
    author = {Smallwood, R.D. and Sondik, E.J.},
    year = 1973,
    journal = {Operations Research},
    volume = 21,
    number = 5,
    pages = {1071--88}
}


@techreport{Cassandra1998b,
    title = {A Survey of {POMDP} Applications},
    author = {Anthony R. Cassandra},
    number = {MCC-INSL-111-98},
    institution = {Microelectronics and Computer Technology Corporation (MCC)},
    year = {1998},
    note = {Presented at the {AAAI} Fall Symposium}
}


@inproceedings{Cassandra1997,
  title={Incremental Pruning: {A} Simple, Fast, Exact Method for Partially Observable {M}arkov Decision Processes},
  author={Anthony R. Cassandra and Michael L. Littman and Nevin Lianwen Zhang},
  booktitle={UAI'97: Proceedings of the Thirteenth conference on Uncertainty in artificial intelligence},
  month = {August},
  pages = {54-–61},
  year={1997}
}

@inproceedings{Littman1995,
author = {Littman, Michael L. and Cassandra, Anthony R. and Kaelbling, Leslie Pack},
title = {Learning Policies for Partially Observable Environments: {S}caling Up},
year = {1995},
isbn = {1558603778},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the Twelfth International Conference on International Conference on Machine Learning},
pages = {362–370},
numpages = {9},
location = {Tahoe City, California, USA},
series = {ICML’95}
}

@techreport{Littman1996,
    title = {Efficient dynamic-programming updates in partially observable Markov decision processes},
    author = {Littman, M. L. and Cassandra, A. R. and Kaelbling, L. P.},
    number = {CS-95-19},
    institution = {Brown University, Providence, RI},
    year = {1996}
}



@inproceedings{Pineau2003,
author = {Pineau, Joelle and Gordon, Geoff and Thrun, Sebastian},
title = {Point-Based Value Iteration: {A}n Anytime Algorithm for {POMDPs}},
year = {2003},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the 18th International Joint Conference on Artificial Intelligence},
pages = {1025–1030},
numpages = {6},
location = {Acapulco, Mexico},
series = {IJCAI’03}
}

@TECHREPORT{Zhang1996,
author = {Nevin L. Zhang and Wenju Liu},
title = {Planning in Stochastic Domains: {P}roblem Characteristics and Approximation},
institution = {Hong Kong University},
number = {HKUST-CS96-31},
year = {1996}
}

@INPROCEEDINGS{Kurniawati2008,
    author = {Hanna Kurniawati and David Hsu and Wee Sun Lee},
    title = {{SARSOP:} {E}fficient point-based POMDP planning by approximating optimally reachable belief spaces},
    booktitle = {In Proc. Robotics: Science and Systems},
    year = {2008}
}

@Manual{Bottiger2021,
   title = {sarsop: {A}pproximate {POMDP} Planning Software},
   author = {Carl Boettiger and Jeroen Ooms and Milad Memarzadeh},
   year = {2021},
   note = {{R} package version 0.6.9},
   url = {https://CRAN.R-project.org/package=sarsop}
}

@Manual{Hahsler2022,
    title = {pomdp: Infrastructure for Partially Observable Markov Decision Processes (POMDP)},
    author = {Michael Hahsler},
    note = {R package version 1.1.3},
    year = 2023,
    url = {https://github.com/mhahsler/pomdp},
}

@Manual{Hahsler2022b,
    title = {pomdpSolve: Interface to 'pomdp-solve' for Partially Observable Markov Decision Processes},
    author = {Michael Hahsler and Anthony R. Cassandra},
    year = {2022},
    note = {R package version 1.0.2},
    url = {https://github.com/mhahsler/pomdpSolve},
  }
  
@Manual{Bates2022,
    title = {Matrix: Sparse and Dense Matrix Classes and Methods},
    author = {Douglas Bates and Martin Maechler and Mikael Jagan},
    year = {2022},
    note = {R package version 1.5-3},
    url = {https://CRAN.R-project.org/package=Matrix},
}

@article{Monahan1982,
    author = {Monahan, G. E.},
    year = {1982},
    title = {A survey of partially observable {M}arkov decision processes: {T}heory, models, and algorithms},
    journal = {Management Science},
    volume = 28,
    number = 1,
    pages = {1--16}
}

@book{Sutton1998,
  author = {Sutton, Richard S. and Barto, Andrew G.},
  edition = {Second},
  publisher = {The MIT Press},
  title = {Reinforcement Learning: {A}n Introduction},
  year = 2018
}

@ARTICLE{hahsler:Kamalzadeh:2021, 
  AUTHOR = {Farzad Kamalzadeh and Vishal Ahuja and Michael Hahsler and Michael E. Bowen},
  TITLE = {An Analytics-Driven Approach For Optimal Individualized Diabetes Screening},
  JOURNAL = {Production and Operations Management},
  YEAR = {2021},
  MONTH = {September},
  VOLUME = {30},
  NUMBER = {9},
  PAGES = {3161--3191},
  doi = {10.1111/poms.13422},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/poms.13422},
  ISSN = {1937-5956}
}

@inproceedings{Puterman1994,
  title={Markov Decision Processes: {D}iscrete Stochastic Dynamic Programming},
  author={Martin L. Puterman},
  booktitle={Wiley Series in Probability and Statistics},
  year={1994}
}

@Manual{Proellochs2020,
    title = {ReinforcementLearning: {M}odel-Free Reinforcement Learning},
    author = {Nicolas Proellochs and Stefan Feuerriegel},
    year = {2020},
    note = {{R} package version 1.0.5},
    url = {https://CRAN.R-project.org/package=ReinforcementLearning},
}

@Manual{R2022,
    title = {R: {A} Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2022},
    url = {https://www.R-project.org/},
}

@Article{igraph2006,
    title = {The igraph software package for complex network research},
    author = {Gabor Csardi and Tamas Nepusz},
    journal = {InterJournal},
    volume = {Complex Systems},
    pages = {1695},
    year = {2006},
    url = {https://igraph.org},
}

@article{Jacomy2014,
  title = {ForceAtlas2, a Continuous Graph Layout Algorithm for Handy Network Visualization Designed for the {G}ephi Software},
  author = {Jacomy, Mathieu and Venturini, Tommaso and Heymann, Sebastien and Bastian, Mathieu},
  doi = {10.1371/journal.pone.0098679},
  journal = {PLOS ONE},
  month = {06},
  number = 6,
  pages = {1-12},
  publisher = {Public Library of Science},
  volume = 9,
  year = 2014
}

@article{Hauskrecht2000,
author = {Hauskrecht, Milos},
doi = {https://doi.org/10.1613/jair.678},
journal = {Journal Of Artificial Intelligence Research},
pages = {33--94},
title = {Value-Function Approximations for {POMDPs}},
volume = {13},
year = {2000}
}

@phdthesis{Cassandra1998c,
author = {Cassandra, Anthony Rocco},
advisor = {Kaelbling, Leslie Pack},
title = {Exact and Approximate Algorithms for Partially Observable {M}arkov Decision Processes},
year = {1998},
isbn = {0591833220},
publisher = {Brown University},
address = {USA}
}

@Book{Eddelbuettel2013,
  title = {Seamless {R} and {C++} Integration with {Rcpp}},
  author = {Dirk Eddelbuettel},
  publisher = {Springer},
  address = {New York},
  year = {2013},
  note = {ISBN 978-1-4614-6867-7},
  doi = {10.1007/978-1-4614-6868-4},
}

@Manual{Microsoft2022,
    title = {foreach: Provides Foreach Looping Construct},
    author = {{Microsoft} and Steve Weston},
    year = {2022},
    note = {R package version 1.5.2},
    url = {https://CRAN.R-project.org/package=foreach},
}

@Manual{Almende2022,
    title = {visNetwork: Network Visualization using 'vis.js' Library},
    author = {{Almende B.V. and Contributors} and Benoit Thieurmel},
    year = {2022},
    note = {R package version 2.1.2},
    url = {https://CRAN.R-project.org/package=visNetwork},
}

@Book{Wickham2016,
    author = {Hadley Wickham},
    title = {ggplot2: Elegant Graphics for Data Analysis},
    publisher = {Springer-Verlag New York},
    year = {2016},
    isbn = {978-3-319-24277-4},
    url = {https://ggplot2.tidyverse.org},
}

@article{Mundhenk2000,
author = {Mundhenk, Martin},
title = {The Complexity of Optimal Small Policies},
year = {2000},
issue_date = {February 2000},
publisher = {INFORMS},
address = {Linthicum, MD, USA},
volume = {25},
number = {1},
issn = {0364-765X},
abstract = {We investigate the complexity of problems concerned with partially-observable Markov decision processes which are run for a finite number of steps under small policies. The calculation of the expected sum of rewards of a process under a small policy is shown to be complete for the complexity class PP, a class which lies intermediate between NP and PSPACE. Optimal small policy computation is shown to be complete for NPPP. The latter contrasts results of Papadimitriou and Tsitsiklis Papadimitriou and Tsitsiklis 1987, who showed that this problem is PSPACE-complete, if no assumptions about the representability of the policy are made, and that it is P-complete for fully-observable processes.},
journal = {Math. Oper. Res.},
month = {feb},
pages = {118–129},
numpages = {12},
keywords = {computational complexity, partial observability, Markov decision processes, planning problems}
}