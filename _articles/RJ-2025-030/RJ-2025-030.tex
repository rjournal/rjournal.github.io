% !TeX root = RJwrapper.tex
\title{Exploring Image Analysis in R: Applications and Advancements}


\author{by Tim Brauckhoff, Julius Rublack, and Stefan Rödiger (corresponding author)}

\maketitle

\abstract{%
This review offers an overview of image processing packages in R, covering applications such as multiplex imaging, cell tracking, and general-purpose tools. We found 38 R packages for image analysis, with adimpro and EBImage being the oldest, published in 2006, and biopixR among the newest, released in 2024. Of these packages, over 90 \% are still active, with two-thirds receiving updates within the last 1.5 years. The pivotal role of bioimage informatics in life sciences is emphasized in this review, along with the ongoing advancements of R's functionality through novel code releases. It focuses on complete analysis pipelines for extracting valuable information from biological images and includes real-world examples. Demonstrating how researchers can use R to tackle new scientific challenges in image analysis, the review provides a comprehensive understanding of R's utility in this field.
}

\section{Introduction}\label{introduction}

Advancements in microscopy and computational tools have become pivotal to
biological research, facilitating detailed investigation of cellular and
molecular processes previously inaccessible. Consequently, imaging
methodologies, staining protocols, and fluorescent labeling --- particularly those
employing genetically encoded fluorescent proteins and immunofluorescence --- have
resulted in a substantial increase in the capacity to examine cellular
structures, dynamics, and functions \citep{Swedlow2009, Peng2012, Chessel2017, Moen2019, schneider_open_2019}.

As with any significant advance in today's world, software is required
to facilitate the acquisition, analysis, management, and visualization of image
data resulting from these techniques. The current techniques have allowed the
capture of biological phenomena with an unparalleled level of complexity and
resolution \citep{Eliceiri2012}. As a result, an ever-growing amount of image data
is being generated \citep{Peng2012}. Alongside the three spatial dimensions, images
now encompass additional dimensions like time and color channels. Biomedical
images exhibit this high level of complexity, as evidenced by the analysis of
dense cell turfs where cells may partially overlap \citep{Peng2008, Swedlow2009}.
The increase in complexity demands computational approaches. Nevertheless, the
challenge posed is not solely due to complexity. As imaging technology advances,
the volume of image data generated from experiments also sees a steep rise
\citep{Peng2008, Caicedo2017}.

The need for quantitative information from images to understand and develop new
biological concepts has led to the emergence of bioimage informatics as a
specialized field of study \citep{Eliceiri2012, Murphy2014}. Bioimage informatics
is primarily concerned with the extraction of quantitative information from
images to interpret biological concepts or develop new ones \citep{Chessel2017, Moen2019, schneider_open_2019}. Bioimage informatics focuses on the
automation of objective and reproducible image data analysis, while concurrently
developing tools for the visualization, storage, processing, and analysis of
such data \citep{Swedlow2009a, Peng2012}. Crucial advancements range from cell
phenotype screening, drug discovery, and cancer diagnosis to gene function,
metabolic pathways, and protein expression patterns. The basic operations in
bioimage informatics are feature extraction and selection, segmentation,
registration, clustering, classification, annotation, and visualization
\citep{Peng2008}.

Due to recent advancements, the utilization of microscopy in biology has evolved
into a quantitative approach, as opposed to solely a visual one. Thus, various
essential open-source platforms, applications, and languages have emerged, which
have now become well-established within the life science community
\citep{PaulGilloteaux2023}. Python, \texttt{R}, and MATLAB are among the most favored
programming languages in bioinformatics \citep{Giorgi2022}, with Python and \texttt{R} being
extensively used in biomedicine \citep{Roesch2023}. \texttt{R} plays a pivotal role in the
fields of statistics, bioinformatics, and data science. It is a versatile
statistical software that is used in various assays, for example, in gene
expression analyses \citep{rodiger_surface_2013, rodiger_r_2015, burdukiewicz_pcredux_2022, chilimoniuk_challenges_2024}. Furthermore, it is
one of the top ten most prevalent programming languages across the globe, with a
thriving community that has developed numerous extensions and packages for
various applications \citep{Giorgi2022}. Originally developed for statistical
analysis, \texttt{R} and its packages now offer robust capabilities for image analysis
and automation \citep{Chessel2017, Haase2022}. The growing demand for
automation and data-driven analysis underscores the necessity for flexible and
integrated computational tools. \texttt{R}'s expanding
ecosystem of packages, ranging from general-purpose image processing to
specialized, domain-specific workflows, facilitates the creation of customized
solutions tailored to diverse research needs. The extensible framework and
robust statistical capabilities support seamless integration of image analysis
with downstream data interpretation, promoting reproducibility and efficiency
across the entire analytical pipeline \citep{Roediger2015, Chessel2017, Giorgi2022, Haase2022}.

\texttt{R} can integrate with other programming languages through the use of packages
such as \texttt{reticulate} \citep{reticulate} for Python, which enables users to leverage
the strengths of multiple languages within their research workflows, enhancing
flexibility across diverse domains. Another example of this is
Bio7. Bio7 is an open-source platform designed for ecological modeling,
scientific image analysis, and statistical analysis. It provides an \texttt{R}
development environment and integration with the ImageJ application
\citep{austenfeld_graphical_2012}. ImageJ is a widely-used, public-domain
Java-based software suite specifically developed for biological image processing
and analysis, that supports various file formats, advanced image manipulation
techniques, and a vast array of plugins and scripts \citep{schneider_nih_2012}.

A common difficulty in bioinformatics is the large number of file formats, some
of which are proprietary. A lack of standardization means that general tools
must deal with this vast array of file formats. The open-source approach
provides access to the code of applications, packages, and extensions, thereby
facilitating modification and further development by the community. This
enhances reproducibility and validation, offering flexibility and adaptability
for scientific discovery. This makes open-source methods ideally suited to the diverse
and interdisciplinary field of biological imaging research \citep{Swedlow2009a, Roediger2015}. The Open Microscopy Environment (OME) offers a standardized,
open-source framework for the management, analysis, and exchange of biological
imaging data, with a particular focus on the integration and preservation of
rich metadata --- such as experimental conditions, cell types, acquisition
parameters, microscope specifications, and quantification methods
\citep{Goldberg2005}. A central objective of OME is to ensure lossless storage and
interoperability across diverse proprietary and non-proprietary platforms. This
objective addresses the common issue of metadata loss during format conversions
within image analysis pipelines. By establishing standardized formats and
protocols, OME fosters compatibility between proprietary systems and enhances
reproducibility. The widely adopted OME-TIFF format extends the traditional TIFF
structure by embedding metadata in XML, enabling efficient storage and retrieval
of large, multidimensional datasets commonly encountered in fluorescence imaging
\citep{Linkert2010, Leigh2016, Besson2019}. In addition, the OME-ZARR format,
developed under the Next-Generation File Format (NGFF) initiative, has been
optimized for scalable, cloud-based storage of large N-dimensional arrays, with
metadata stored in human-readable JSON. The system's capacity for partial data
access is a notable feature, contributing to enhanced performance in distributed
workflows by combining formats such as OME-TIFF, Hierarchical Data Format 5
(HDF5), and Zarr \citep{Moore2021, Moore2023}\footnote{\url{https://ngff.openmicroscopy.org/about/index.html}, accessed 07/13/2025}.
Increasing adoption of these formats by commercial imaging software vendors
further strengthens their relevance and sustainability \citep{Linkert2010}. In the
context of \texttt{R}-based workflows, the \texttt{RBioFormats} package provides a native
interface to the OME Bio-Formats Java library. This enables the reading of
proprietary file formats and associated metadata, output to OME-TIFF, and
seamless integration of image acquisition with downstream analysis
\citep{AndrzejOles2023}. This facilitates the establishment of flexible,
standardized, and reproducible image analysis pipelines within the \texttt{R} ecosystem.

The heterogeneous and dynamic nature of images presents a constant challenge for
image analysis. Capturing precise and high-quality images that accurately
represent the changing characteristics of an experiment can be difficult, even
for experienced researchers \citep{Swedlow2009}. Additionally, visualizing and
analyzing multi-gigabyte data sets requires substantial computational power. The
process of detailed analysis of image sequences, which involves identifying and
tracking objects, followed by the presentation of the resulting data and the
exploration of the underlying biological mechanisms, adds further complexity
\citep{Swedlow2009a}. To at least simplify the process of selecting the
appropriate software, this review provides an overview of \texttt{R} packages suitable
for image analysis and outlines their applications in biological laboratory
settings.

\section{Methods}\label{methods}

In this study, a review of the literature was conducted over the period
September 2023 to March 2024. The objective was to identify and analyze \texttt{R}
packages that are suitable for bioimage informatics applications. The primary
resources included the Comprehensive \texttt{R} Archive Network
(CRAN)\footnote{\url{https://cran.r-project.org/}, accessed 04/17/2025}, GitHub
repositories\footnote{\url{https://github.com/}, accessed 04/17/2025}, rOpenSci's
r-universe\footnote{\url{https://ropensci.r-universe.dev/builds}, accessed 04/17/2025}, the
Bioconductor repository\footnote{\url{https://www.bioconductor.org/}, accessed 04/17/2025},
OpenAlex database, PubMed, and Google Scholar. The chosen sources allowed for an
extensive coverage of \texttt{R} package repositories while also providing access to
relevant scientific literature. By combining these resources, the study aimed to
provide a comprehensive overview of available tools and techniques within the
domain of bioimage informatics using \texttt{R}.

The search strategy centered around pertinent keywords, including ``bioimage,''
``biomedical image analysis,'' ``imaging,'' ``microscopy,'' ``histology,'' and
``pathology'' and the following search strings:

\begin{itemize}
\item
  \url{https://openalex.org/works?page=1&filter=title_and_abstract.search\%3AR\%20packages\%20for\%20image\%20analysis}
\item
  \url{https://openalex.org/works?page=1&filter=title_and_abstract.search\%3Aimage\%20processing\%20in\%20R}
\item
  \url{https://openalex.org/works?page=1&filter=title_and_abstract.search\%3Amicroscopy\%20imaging\%20in\%20R\%20packages}
\item
  \url{https://pubmed.ncbi.nlm.nih.gov/?term=biomedical+image+analysis&filter=dates.1963\%2F1\%2F1-2025\%2F3\%2F26&filter=pubt.review&filter=other.excludepreprints}
\item
  \url{https://scholar.google.de/scholar?hl=de&as_sdt=0\%2C5&q=image+analysis+in+R&btnG=}
\item
  \url{https://scholar.google.de/scholar?hl=de&as_sdt=0\%2C5&q=bioimage+analysis+in+R&btnG=}
\item
  \url{https://scholar.google.de/scholar?hl=de&as_sdt=0\%2C5&q=microscopy+imaging+analysis+in+R&btnG=}
\end{itemize}

The identified packages were then subjected to an analysis to
understand their usage, dependencies on other libraries, repository hosting
platforms, and licensing terms.

The examples provided, along with this review, were created using \texttt{RMarkdown}. All
computations were performed using the \texttt{R} programming language, version 4.3.3, on
a 64-bit x86\_64-pc-linux-gnu platform with the Ubuntu 22.04.3 LTS operating
system. We utilized the RStudio Integrated Development Environment
(IDE, 2023.09.0+463 ``Desert Sunflower'', Ubuntu Jammy).

This review will examine a variety of \texttt{R} packages designed for image analysis,
including both general-purpose tools and those crafted for specific
applications. This overview aims to demonstrate the diverse capabilities and
adaptability of these tools within and beyond biological research contexts.
Given the significant interest in the localization of microplastics in cells and
the environment, our examples will primarily focus on the analysis of microbead
particles made of polymethylmethacrylate (PMMA), which measure approximately 12
µm and fall within the microplastic size range \citep{Geithe2024}. As microbeads
are round, spherical objects in images, they visually resemble other commonly
imaged objects such as seeds and cells.

\section{Dividing to conquer - advanced segmentation strategies}\label{seg}

Image segmentation is a crucial preliminary step in image analysis and
interpretation. It involves dividing an image into distinct regions by assigning
a label to each pixel. The primary objective is to delineate regions pertinent
to the specific task \citep{Peng2008, Ghosh2019, Niedballa2022}. This process
frequently employs features such as pixel intensity, gradient magnitude, or
texture measures. Based on these features, segmentation techniques can be
classified into three categories: region-based, edge-based, or
classification-based. Classification-based methods assign class labels to pixels
based on their feature values, whereas region-based and edge-based techniques
focus on within-region homogeneity and between-region contrast. One
straightforward method of segmentation is thresholding, which involves comparing
pixel values against one or more intensity thresholds. This process typically
separates the image into foreground and background regions \citep{Sonka2000, Jaehne2002}.

Another image segmentation method was proposed by \citet{Ren2003}. This approach
integrates a preprocessing step that segments the image into superpixels,
feature extraction based on Gestalt cues, evaluation of the extracted features,
and the training of a linear classifier. Superpixels are clusters of pixels that
are similar with respect to properties such as color and texture, resulting in
larger subregions of the image. The primary objective of this preprocessing step
is to simplify the image and reduce the number of regions considered for
segmentation. Previously, this involved evaluating every single pixel. The
division of the image into regions larger than pixels but smaller than objects
allows for the superpixels to encompass a greater quantity of information,
adhere to the boundaries of natural image objects, reduce the presence of noise and
outliers, and enhance the speed of the subsequent segmentation process. In
summary, this method can be described as segmentation based on low-level pixel
grouping \citep{Ren2003, Hossain2019, OpenImageR}.

However, segmentation is not limited to the differentiation of the foreground
and background. Pixel classification plays a critical role in a number of
applications, including visual question answering, object counting, and
tracking. In these applications, classification occurs not just spatially but
also temporally. These applications are diverse, encompassing fields such as
traffic analysis and surveillance, medical imaging, and cell biology
\citep{Ghosh2019}. While a relatively straightforward technique, thresholding has
inherent limitations in distinguishing between background, noise, and
foreground. Therefore, the next section will offer a more sophisticated approach,
by presenting a package that utilizes deep learning for image segmentation
\citep{Smith2021}.

\subsection{\texorpdfstring{\texttt{imageseg}: a deep learning package for forest structure analysis}{imageseg: a deep learning package for forest structure analysis}}\label{imageseg-a-deep-learning-package-for-forest-structure-analysis}

By venturing beyond the traditional laboratory setting, the \texttt{imageseg} package
offers a unique approach to analyzing forest structures through deep
learning-based image segmentation, utilizing TensorFlow
(\url{https://www.tensorflow.org/}). This \texttt{R} package employs the power of
convolutional neural networks with the U-Net architecture to streamline image
segmentation tasks \citep{Niedballa2022}. According to the authors, this \texttt{R}
package has been designed to be user-friendly, with pre-trained models that
require only input images, making it accessible even to those without specialist
knowledge. A comprehensive vignette accompanies the package, which provides
detailed instructions on how to set up the software and explains how to utilize
its functions effectively \citep{imageseg}. Developed primarily for forestry and
ecology applications, \texttt{imageseg} includes pre-trained data sets representing
various aspects of forest structure, such as canopy and understory vegetation
density. Its flexibility allows for customization with different training data,
enabling users to develop customized image segmentation workflows for other
fields such as microscopy and cell biology. The package supports both binary and
multiclass segmentation. For image processing within the \texttt{R} programming
environment, the \texttt{imageseg} package integrates with the \texttt{magick} package \citep{Niedballa2022}.

\subsection{\texorpdfstring{\texttt{EBImage}: specialized segmentation strategy for touching objects}{EBImage: specialized segmentation strategy for touching objects}}\label{ebimage-specialized-segmentation-strategy-for-touching-objects}

The segmentation of closely adjacent objects, which is particularly prevalent in
cell microscopy, represents a common challenge that is addressed by the
\texttt{EBImage} package, which is equipped with a variety of segmentation algorithms.
A typical approach involves the application of either global or adaptive
thresholding, followed by connected set labeling, with the objective of
distinguishing individual objects. To achieve more precise segmentation
of touching objects, techniques such as watershed transformation or Voronoi
segmentation are employed \citep{Pau2010}.

The watershed algorithm is employed to delineate touching microbeads (Figure
\ref{fig:EBIoriginal}A-C). Initially, the image is transformed into a binary
image by applying a threshold (Figure \ref{fig:EBIoriginal}B). After utilizing
the watershed function the result is visualized by assigning distinct colors to
the microbeads, effectively illustrating the algorithm's capacity to
differentiate between touching objects (Figure \ref{fig:EBIoriginal}C).



\begin{verbatim}
# Load necessary library
library(EBImage)

# Load the image from the specified path
image <- readImage("figures/beads.png")

# Display the original image
EBImage::display(image)

# Apply a threshold to the original image to create a binary image
img_thresh <- thresh(image, offset = 0.05)

# Read the binary image and display it
EBImage::display(img_thresh)

# Perform watershed segmentation on the distance map of the thresholded image
segmented <- EBImage::watershed(distmap(img_thresh))

# Color the labels of the segmented image
segmented_col <- colorLabels(segmented)

# Display the resulting image after watershed segmentation
EBImage::display(segmented_col)
\end{verbatim}

\begin{figure}[H]

{\centering \includegraphics[width=0.5\linewidth]{figures/EBImage1} \includegraphics[width=0.5\linewidth]{figures/EBImage2} \includegraphics[width=0.5\linewidth]{figures/EBImage3} 

}

\caption{\textbf{Watershed Segmentation in \texttt{EBImage}}: \textbf{A}) Original image used for watershed segmentation in \texttt{EBImage}. \textbf{B}) The \texttt{thresh()} function was employed to generate a binary image with the objective of effectively separating the foreground from the background. The binary representation of the image facilitates further segmentation processes by simplifying the image. \textbf{C}) Presents the result of the watershed segmentation, which is visually represented by the assignment of a distinct color to each object. This technique is particularly effective in differentiating touching objects, as evidenced by the clear separation of microbeads in the image.}\label{fig:EBIoriginal}
\end{figure}

\section{Unveiling the hidden - feature extraction}\label{extr}

The primary objective of feature extraction is to condense the original data
into significant objects that encapsulate crucial information pertinent to each
specific image \citep{JudeHemanth2012}. Feature extraction may be applied to a
predefined region of interest (ROI) or may involve the identification of the
ROI, a process often referred to as segmentation, which was reviewed in the
previous sections. Within any given ROI, a multitude of attributes typically exist,
representing different states of the object under analysis. These attributes, or
features, are of vital importance for the interpretation of the detected objects
and can enable applications such as disease diagnosis or the identification of
promising candidates. Features related to individual pixels may include aspects
such as neighborhood relationships, connectivity, and gradients, which are
one-dimensional descriptions. Nevertheless, more intelligible and interpretable
information is frequently derived from descriptions of regions or objects
\citep{Sonka2000, Shirazi2018}. Object-level features encompass a range of
characteristics, including size, shape, texture, intensity, and spatial
distribution. Shape features can be further categorized into specific
characteristics, including perimeter, radius, circularity, and area. It is
crucial to acknowledge that the successful extraction of object features is
dependent on the quality and accuracy of the image segmentation process
\citep{Shirazi2018}.

This section is devoted to an examination of \texttt{R} packages that enable the
automated extraction of quantitative features. The \texttt{biopixR} package offers
automated and interactive object detection strategies. The \texttt{pliman} package,
initially developed for the analysis of plant images, has the potential to be
adaptable to a range of different domains. The \texttt{FIELDimageR} package is capable
of supporting the analysis of drone-captured images from agricultural field
trials as well as images from pollen, which exhibit similar characteristics to
cellular images. These tools provide novel perspectives for interdisciplinary
research, facilitating the adaptation of methodologies across diverse fields.

\subsection{\texorpdfstring{\texttt{biopixR}: versatile biological image processing}{biopixR: versatile biological image processing}}\label{biopixr-versatile-biological-image-processing}

The \texttt{biopixR} package is a comprehensive toolbox developed primarily for
microbead analysis. It encompasses a range of functions, including image
importation, preprocessing, segmentation, feature extraction, and clustering.
The primary objective is to enable the detection of objects and the extraction
of quantitative data, including intensity values, shape, and texture
characteristics. These functionalities are integrated into user-friendly
pipelines that support batch processing, thereby enhancing accessibility. The
preprocessing capabilities include edge restoration and a variety of filter
functions \citep{biopixR}.

To illustrate the feature extraction process, the analysis focuses on a
microbead image (Figure \ref{fig:biobeads0}A). The image is initially converted to
grayscale. Afterwards the \texttt{objectDetection()} function is applied to detect image
objects. The extracted objects are then represented visually by plotting the
highlighted contours of the objects and enumerating the microbeads according to
their cluster IDs, thus distinguishing them as individual entities (Figure
\ref{fig:biobeads0}B).

\begin{verbatim}
# Loading necessary package
library(biopixR)

# Importing the image
beads <- importImage("figures/beads2.jpg")
\end{verbatim}

\begin{verbatim}
# Plot original image
beads |> plot(axes = FALSE)
\end{verbatim}

\begin{verbatim}
# Converting the image to grayscale
beads <- grayscale(beads)

# Detecting objects in the image using edge detection
objects <-
  objectDetection(beads,                # Image to process
                  method = 'edge',      # Method for object detection
                  alpha = 1,            # Threshold adjustment factor
                  sigma = 0)            # Smoothing factor

# Displaying internal visualization of object detection with marked contours 
# and centers
objects$marked_objects |> plot(axes = FALSE)

# Adding text annotations at the centers of detected objects
text(objects$centers$mx,     # x-coordinates of object centers
     objects$centers$my,     # y-coordinates of object centers
     objects$centers$value,  # Text to display (value of the object center)
     col = "green",          # Color of the text
     cex = 1.5)          
\end{verbatim}



\begin{figure}[H]

{\centering \includegraphics[width=0.66\linewidth]{figures/beads4} \includegraphics[width=0.66\linewidth]{figures/beads5} 

}

\caption{\textbf{Microbead Detection using \texttt{biopixR}}: \textbf{A}) The original image shows red fluorescent microbeads, with the majority appearing as isolated, round, spherical objects. Some microbeads are clustered together or overlapping, forming aggregated structures, while others are partially captured within the image frame. \textbf{B}) In the grayscale microbead image, edges of the microbeads are highlighted in purple, and the labeling ID (value) is displayed at the center of each object in green.}\label{fig:biobeads0}
\end{figure}

\subsection{\texorpdfstring{\texttt{pliman}: an \texttt{R} package for plant image analysis}{pliman: an R package for plant image analysis}}\label{pliman-an-r-package-for-plant-image-analysis}

\texttt{pliman} is designed to analyze plant images, particularly leaves and seeds, to
help identify disease states, lesion shapes, and quantify objects. It
supports various functions, including image transformation, binarization,
segmentation, and detailed analysis, all facilitated by a detailed
vignette.\footnote{\url{https://tiagoolivoto.github.io/pliman/index.html}, accessed
  07/11/2024} A key feature of \texttt{pliman} is its automation of quantitative feature
extraction (Figure \ref{fig:pliman1} and \ref{fig:pliman2}), which
traditionally requires manual, time-consuming, and error-prone methods. The
features of this package are versatile, encompassing a range of segmentation
strategies, the analysis of shape and contour characteristics of leaves and
seeds, the counting of objects, and the quantification of disease states from
leaf images. While the primary focus is on plant imaging, the techniques used
are applicable to other fields such as cellular imaging. This
cross-applicability is further emphasized by the package's batch processing
capabilities, which allow for autonomous analysis of multiple images, critical
for high-throughput phenotyping tasks \citep{Olivoto2022}.



\begin{verbatim}
# Loading necessary package
library(pliman)

# Import requires EBImage:
# Importing the main image
beads <- EBImage::readImage("figures/beads2.jpg")

# Importing additional images for background and foreground
foreground <- EBImage::readImage("figures/foreground.jpg")
background <- EBImage::readImage("figures/background.jpg")

# Displaying the microbead image
EBImage::display(beads)

# Combining the foreground and background images and arranging them in 2 rows
pliman::image_combine(foreground, background, nrow = 2, col = "transparent")
\end{verbatim}

\begin{figure}[H]

{\centering \includegraphics[width=0.49\linewidth]{RJ-2025-030_files/figure-latex/pliman1-1} \includegraphics[width=0.49\linewidth]{RJ-2025-030_files/figure-latex/pliman1-2} 

}

\caption{\textbf{Preparing Segmentation using \texttt{pliman}}: The image comprises two sections. On the left, an image of microbeads is displayed. On the right, a cropped view from the same image illustrates two states for segmentation: the microbead (foreground) in red, and the background is shown in black, emphasizing the clear division needed for segmentation analysis.}\label{fig:pliman1}
\end{figure}



\begin{verbatim}
# Performing segmentation based on provided background and foreground images
analyze_objects(
  img = beads,               # Main image of microbeads
  background = background,   # Background sample image
  foreground = foreground,   # Foreground sample image
  marker = "id",             # Displaying enumeration
  contour_col = "yellow"     # Color for the contour of the segmented objects
)
\end{verbatim}

\begin{figure}[H]

{\centering \includegraphics[width=0.69\linewidth]{RJ-2025-030_files/figure-latex/pliman2-1} 

}

\caption{\textbf{Segmentation Results using \texttt{pliman}}: The image depicts the segmentation results obtained via the \texttt{pliman} \texttt{analyze\_objects()} function. It displays the contours of the segmented objects, outlined in yellow. Each distinct object within the segmentation is numbered, facilitating its identification.}\label{fig:pliman2}
\end{figure}

\subsection{\texorpdfstring{\texttt{FIELDimageR}: an \texttt{R} package for the analysis of drone-captured images}{FIELDimageR: an R package for the analysis of drone-captured images}}\label{fieldimager-an-r-package-for-the-analysis-of-drone-captured-images}

The \texttt{FIELDimageR} package, is an \texttt{R} package designed for the specific purpose
of analyzing drone-captured images from agricultural field trials. The package
offers a variety of functions for ROI selection, the extraction of
foregrounds (Figure \ref{fig:FIELD1}), watershed segmentation, quantification
and shape analysis \citep{Matias2020}. The developers have applied this package to
analyze pollen, which visually resembles cells under a microscope. This suggests
that \texttt{FIELDimageR} may be applicable for use in microbiological image analysis.
For the spatial analysis, the package utilizes the \texttt{terra} package
\citep{Matias2020}.\footnote{\url{https://github.com/OpenDroneMap/FIELDimageR}, accessed 05/07/2024}

To showcase the functionalities of the \texttt{FIELDimageR} package and its parallels
with biological applications, the same microbead image is subjected to analysis.
The image is initially transformed into a `SpatRaster' object and then segmented
using an intensity threshold (Figure \ref{fig:FIELD1}). The microbeads are
correctly identified as the foreground objects by the \texttt{fieldMask()} function.
Subsequently, a distinct labeling ID is assigned to each microbead, as
illustrated by a color gradient. Moreover, the contours of each individual
object are displayed (Figure \ref{fig:FIELD2}). The results of the segmentation
and the extraction of shape-related information are presented in the interactive
\texttt{leaflet} interface (Figure \ref{fig:leafletPDF}). Presenting information like
cluster ID, size, perimeter and width of the detected objects.



\begin{verbatim}
# Loading necessary packages
library(FIELDimageR)
library(FIELDimageR.Extra)
library(terra)
library(sf)
library(leafsync)
library(mapview)

# Using the same image as imported in the previous example
# Creating a SpatRaster object using the 'terra' package
EX.P <- rast("figures/beads2.jpg")
EX.P <- imgLAB(EX.P)
\end{verbatim}

\begin{verbatim}
#> [1] "3 layers available"
\end{verbatim}

\begin{verbatim}
# Removing background based on a vegetation index
EX.P.R1 <-
  fieldMask(
    mosaic = EX.P,    # Input SpatRaster object
    index = "BIM",    # Index representing vegetation
    cropValue = 5,    # Threshold value for the index
    cropAbove = F     # Indicates to remove values below the threshold
  )

# Displaying the original, background, and foreground images
EX.P.R1$newMosaic
\end{verbatim}

\begin{figure}[H]

{\centering \includegraphics[width=1\linewidth]{figures/FIELDimageR1_1} 

}

\caption{\textbf{Displaying the original, background, and foreground Images}: The original image (left) shows the fluorescent microbeads. The middle image displays the background in white (TRUE) and all objects detected by segmentation in black (FALSE). The right image shows only the foreground (microbeads) after detection through segmentation using the \texttt{fieldMASK()} function.}\label{fig:FIELD1}
\end{figure}



\begin{verbatim}
# Labeling of all microbeads
EX.P.Total <- fieldCount(mosaic = EX.P.R1$mask, plot = T)
\end{verbatim}

\begin{figure}[H]

{\centering \includegraphics[width=1\linewidth]{figures/FIELDimageR2_1} 

}

\caption{\textbf{Labeling of Microbeads}: The \texttt{fieldCount()} function is used to label individual microbeads. This function utilizes the mask produced in the previous section to identify the objects. The left image displays the labeling with a color gradient indicating distinct objects. On the right, the object contours are shown. The output of the function includes more than just the labeling value (named ID in this package); it also provides information on area, perimeter, width, and geometry of the detected objects.}\label{fig:FIELD2}
\end{figure}

\begin{verbatim}
# Combining the 'FIELDimageR.Extra', 'mapview' and 'leafsync' to create an 
# interactive view
m1 <- fieldView(EX.P, r = 1, g = 2, b = 3)
m2 <- mapview(EX.P.Total)
sync(m1, m2)
\end{verbatim}



\begin{figure}[H]

{\centering \includegraphics[width=1\linewidth]{figures/FIELDimageR_shiny} 

}

\caption{\textbf{Displaying Results with an Interactive \texttt{leaflet} Tool}: The tool displays the original image on the left. For comparison, the cursor is mirrored to the corresponding image (only visible in HTML format). The left image provides detailed information interactively. Hovering over the objects reveals their labeling ID. Performing a left-click opens a detailed window providing information for the individual object, such as area, perimeter, width, and shape. The packages \texttt{FIELDimageR.Extra}, \texttt{mapview}, and \texttt{leafsync} are used to create the interactive display.}\label{fig:leafletPDF}
\end{figure}

In summary, packages such as \texttt{EBImage} and \texttt{biopixR} provide direct pipelines
for the extraction of features from images, including shape, size, radius, and
perimeter, as well as texture information through the calculation of Haralick
texture features \citep{Haralick1973, Pau2010, biopixR}. The \texttt{biopixR} package
employs the \texttt{imager} and \texttt{magick} packages for image processing \citep{biopixR},
whereas \texttt{pliman} and \texttt{FIELDimageR} rely on \texttt{EBImage} for direct image analysis,
with \texttt{FIELDimageR} also utilizing \texttt{terra} and \texttt{raster} for spatial data
exploration \citep{Matias2020, Olivoto2022}. In comparison to the other packages
discussed in this section, \texttt{biopixR} facilitates the process of object detection
by eliminating the necessity for the generation of masks or the provision of
representative sample images of the foreground and background. Nevertheless, in
contrast to the other packages, \texttt{biopixR} lacks the functionality of watershed
segmentation for the enhanced handling of touching objects (Figure
\ref{fig:biobeads0}B and Figure \ref{fig:pliman2}) \citep{Matias2020, Olivoto2022, biopixR}.

\section{Decoding complexity - clustering, classification and annotation}\label{clus}

The automation of measuring cellular phenomena and the effects of compounds,
which started in the late 1990s, is now increasingly significant owing to the
progress of machine learning (ML) algorithms and computing power. These
advancements are enhancing the field of bioinformatics' accessibility to these
techniques. Consequently, they are being more commonly employed with the aim of
gaining novel biological insights \citep{Murphy2014, Moen2019, Weiss2022}. One of the latest
methods of image analysis involves comparing the morphological characteristics
of cells from captured images with pre-classified training data that represent
a specific state \citep{Moen2019}. Bioimage informatics methods aim to generate
fully automated models for biological systems \citep{Murphy2014}.

A major challenge in handling new data sets is the need to label images, which is
critical to assigning meaning to the objects within them. This is particularly
important in medical imaging, where expert knowledge is essential for accurate
labeling \citep{Boom2012, Weiss2022}. In ML, two common techniques that can be
used to categorize data into distinct groups are clustering and classification.
Clustering, an unsupervised learning method, is used to discover underlying
structures or patterns in unlabeled data by assessing similarities between data
points \citep{Mostafa2019}. Classification, a form of supervised learning, involves
building a model from previously labeled training data to make predictions about
new data \citep{Mostafa2019, KumarDubey2022}. This requires prior labeling of the
data to determine the characteristics of each group, a process known as
annotation. However, manual annotation is time-consuming and labor-intensive,
requiring significant human effort to identify relevant details in an image
\citep{Yao2016, Weiss2022}. Because images often require multi-label annotation - the
assignment of multiple semantic concepts to a single image - there has been a
growing demand for automated image annotation systems that aim to reduce the
burden of manual labeling and increase the efficiency of data processing
\citep{Nasierding2009}.

To effectively analyze complex image data sets, researchers require advanced
pattern recognition techniques that can extract meaningful biological insights
from these images. This enables them to transform visual data into actionable
scientific knowledge \citep{Behura2021}. Some of the most widely used clustering
algorithms for this purpose include:

\begin{itemize}
\tightlist
\item
  k-means: is a centroid-based algorithm that partitions n observations into
  \emph{k} clusters by minimizing within-cluster sum of squares. It does require
  specifying the number of clusters beforehand \citep{Struyf1996}.
\item
  Partitioning Around Medoids (PAM): a k-means relative, seeks to identify \emph{k}
  representative objects from the data set,
  which are robust representations of the clusters' center and are also
  referred to as medoids. Clusters are formed by assigning each object to its
  nearest medoid, with the objective of optimizing within-cluster similarity
  \citep{Kaufman1990, VanderLaan2003}.
\item
  c-means: also known as Fuzzy C-Means (FCM), extends the concept of k-means
  to allow each data point to belong to more than one cluster \citep{Bezdek1984}.
\item
  Density-Based Spatial Clustering of Applications with Noise (DBSCAN): is a
  density-based clustering algorithm that groups together points that are
  closely packed together and separates them from points that lie alone in
  low-density regions. It does not require specifying the number of clusters
  beforehand \citep{Ester1996, Schubert2017}.
\item
  Self-Organizing Maps (SOM): are a type of neural network architecture that
  systematically organizes input features into a spatially coherent
  representation. This method can be utilized for clustering based on various
  object features, thereby facilitating the discovery of patterns within these
  objects \citep{Kohonen1990, Kohonen2013}.
\end{itemize}

\subsection{\texorpdfstring{\texttt{pixelclasser}: a simplified support vector machine approach for pixel classification}{pixelclasser: a simplified support vector machine approach for pixel classification}}\label{pixelclasser-a-simplified-support-vector-machine-approach-for-pixel-classification}

The \texttt{pixelclasser} package is a tool for classifying image pixels into
user-defined color categories using a simplified version of the Support Vector
Machine (SVM) technique. It includes functions that allow users to visualize
image pixels, define classification rules, classify pixels, and store the
resulting information.\footnote{\url{https://github.com/ropensci/pixelclasser}, accessed 07/11/2024} Users must
provide a test set that captures the variation between categories, as the
package requires manual placement of rules for each category - automatic rule
construction methods are not included. In addition, \texttt{pixelclasser} provides
quality control of the classifications and comes with a detailed vignette to
facilitate the use of this classification
tool.\footnote{\url{https://cloud.r-project.org/web/packages/pixelclasser/vignettes/pixelclasser.html}, accessed 07/11/2024}
The classification on the pixel-level can be used for image segmentation via
pixel clustering.

\subsection{\texorpdfstring{\texttt{biopixR}: pattern recognition of shape- and texture-related features}{biopixR: pattern recognition of shape- and texture-related features}}\label{biopixr-pattern-recognition-of-shape--and-texture-related-features}

The \texttt{biopixR} package incorporates two unsupervised ML clustering
algorithms: SOM and PAM. PAM organizes a distance matrix into clusters,
identifying medoids as robust representatives of each cluster, typically
specified with a predefined number of groups (\emph{k}) \citep{Kaufman1990, VanderLaan2003, Park2009}. This approach clusters Haralick texture features
extracted from multiple images within a directory, thereby enabling image
classification based on these features \citep{Haralick1973}. The optimal number of
clusters (\emph{k}) is automatically determined using silhouette analysis
\citep{Rousseeuw1987, biopixR}. SOM is used to cluster object features related to
object shape and intensity, thereby facilitating the identification of patterns
within these characteristics \citep{biopixR}.

The capacity for pattern recognition within the \texttt{biopixR} package is
demonstrated by the clustering of shape-related and pixel-intensity information
from an example image of microbeads (Figure \ref{fig:shapefeatures}A). The image
depicts both single and aggregated microbeads, wherein the former exhibit a
round, spherical shape, while the latter appear more oval. The extracted
features and the corresponding cluster are depicted in Figure
\ref{fig:shapefeatures}B, which showcases the identification of patterns within
these objects based on their shape characteristics.

\begin{verbatim}
# Load the 'biopixR' package
library(biopixR)

# Import an image from the specified path
img <- importImage("figures/beads.png")

# Set seed for reproducibility
set.seed(123)

# Extract shape features from the image
result <- shapeFeatures(
  img,    
  alpha = 0.8,
  sigma = 0.7,
  xdim = 2,
  ydim = 1,
  SOM = TRUE,
  visualize = FALSE
)

# Define colors for plotting points based on classes
colors <- c("darkgreen", "darkred")

# Plot the image without axes and add colored points representing the classes
img |> plot(axes = FALSE)
with(result,
     points(
       result$x,
       result$y,
       col = colors[factor(result$class)],
       pch = 19,
       cex = 1.2
     ))
text(c(471), c(354), c("A"), col = "darkred", cex = 5)

# Create a data frame with various shape features and the pixel-intensity
df <- data.frame(
  size = result$size,
  intensity = result$intensity,
  perimeter = result$perimeter,
  circularity = result$circularity,
  eccentricity = result$eccentricity,
  radius = result$mean_radius,
  aspectRatio = result$aspect_ratio
)

# Min-Max Normalization Function
min_max_norm <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}

# Applying the function to each column
df_normalized <- as.data.frame(lapply(df, min_max_norm))

# Create a boxplot of the normalized data
boxplot(
  df_normalized,
  ylab = "normalized values",
  xaxt = "n",
  cex.lab = 1.25,
  cex.axis = 1.25
)

# Add axis ticks and diagonal labels
axis(1, at = 1:ncol(df), labels = FALSE)  # Add axis ticks but no labels
text(
  cex = 1.2,
  x = seq_len(ncol(df_normalized)),
  y = -0.07,
  labels = colnames(df_normalized),
  adj = 0,
  srt = -45,
  xpd = TRUE
)

# Highlight specific rows based on class
highlight_rows <-
  which(result$class == 2)  # Example row indices to highlight

# Add points for the specific rows
# Adding points for each column
for (col in 1:ncol(df_normalized)) {
  points(
    rep(col, length(highlight_rows)),
    df_normalized[highlight_rows, col],
    col = "red",
    pch = 19,
    cex = 1.5
  )
}

text(c(0.5),
     c(0.98),
     c("B"),
     col = "darkred",
     cex = 5)
\end{verbatim}



\begin{figure}[H]

{\centering \includegraphics[width=0.85\linewidth]{figures/shape_test2} \includegraphics[width=0.85\linewidth]{figures/shape_test1} 

}

\caption{\textbf{Clustering Microbeads Based on Shape and Intensity Features}: \textbf{A}) The utilization of Self-Organizing Maps (SOM) enables the clustering of microbeads into two distinct groups based on shape and intensity features extracted using the \texttt{shapeFeatures()} function. This method enables the precise clustering of microbeads according to a range of properties, including intensity, area, perimeter, circularity, radius, and aspect ratio. This facilitates a deeper understanding of the morphological variations observed in the microbeads. \textbf{B}) The attributes utilized as input for the SOM algorithm are illustrated in this plot. To ensure comparability, the different parameters have been normalized using a min-max normalization procedure. The points highlighted in red represent the microbeads that are also highlighted in red in Figure A. Notably, these highlighted points differ from the most commonly occurring values in all attributes except for the intensity.}\label{fig:shapefeatures}
\end{figure}

\section{Harmonizing visions - techniques and approaches in image registration}\label{harmonizing-visions---techniques-and-approaches-in-image-registration}

The process of image registration plays a pivotal role in the analysis of
medical images, as it enables the comparison of multiple images representing
different conditions \citep{Jenkinson2001}. This process, which can be described as
image alignment, entails aligning a series of images within a single coordinate
system, thereby ensuring consistency across images \citep{Peng2008, Rittscher2010}. A variety of techniques are employed in image registration,
including mutual information registration, spline-based elastic registration,
and invariant moment feature-based registration, among others \citep{Peng2008}.
These methods are of particular significance in the field of medical imaging,
where they are employed to enhance the analysis of images obtained by techniques
such as computed tomography (CT) and magnetic resonance imaging (MRI)
\citep{Sonka2000}.

\subsection{\texorpdfstring{\texttt{RNiftyReg}: interface for the `NiftyReg' image registration tools}{RNiftyReg: interface for the `NiftyReg' image registration tools}}\label{rniftyreg-interface-for-the-niftyreg-image-registration-tools}

The \texttt{RNiftyReg} package provides an interface to the `NiftyReg' image
registration library, which supports both linear and non-linear registration in
two and three dimensions \citep{RNiftyReg}. This package has been utilized in
research on brain connectivity \citep{Clayden2013}, and it includes a comprehensive
README that introduces its features and
capabilities.\footnote{\url{https://github.com/jonclayden/RNiftyReg}, accessed 07/11/2024}

\section{\texorpdfstring{Jack of all trades - general purpose \texttt{R} packages for broad-spectrum analysis}{Jack of all trades - general purpose R packages for broad-spectrum analysis}}\label{jack-of-all-trades---general-purpose-r-packages-for-broad-spectrum-analysis}

Five principal image processing packages for \texttt{R} offer a broad range of
algorithms and capabilities for complete image analysis, rendering them
suitable as general-purpose tools. These packages are \texttt{imager}, \texttt{magick},
\texttt{EBImage}, \texttt{OpenImageR} and \texttt{SimpleITK}. This section will introduce each of
these key packages and their roles in image analysis.

\subsection{\texorpdfstring{\texttt{imager}: wrapper for the `CImg' C++ image processing library}{imager: wrapper for the `CImg' C++ image processing library}}\label{imager-wrapper-for-the-cimg-c-image-processing-library}

The \texttt{imager} \texttt{R} package, created by \citet{Barthelme2019}, integrates the
functionality of the `CImg' library, developed by David Tschumperlé, into
\texttt{R}.\footnote{\url{https://github.com/asgr/imager}, accessed 07/11/2024} This allows users
to edit and create images. The package uses two primary data structures: raster
images, known as \emph{cimg}, and pixel sets, referred to as \emph{pixelset}. These
structures, encoded as four-dimensional numeric or logical arrays, permit the
execution of basic \texttt{R} functions such as \texttt{plot()}, \texttt{print()}, or
\texttt{as.data.frame()}, as well as the processing of hyperspectral images and videos
\citep{Barthelme2019}. The 4D arrays encompass two spatial dimensions (width and
height), one temporal or depth dimension, and one color dimension \citep{imager}.
\texttt{imager} offers over 100 standard commands for tasks such as loading, saving,
resizing, and denoising of images.\footnote{\url{https://asgr.github.io/imager/}, accessed 07/11/2024}
The \texttt{imager} package supports the file formats JPEG, PNG,
and BMP and is available on CRAN \citep{imager}.

\subsection{\texorpdfstring{\texttt{EBImage}: image processing and analysis for biological imaging data in \texttt{R}}{EBImage: image processing and analysis for biological imaging data in R}}\label{ebimage-image-processing-and-analysis-for-biological-imaging-data-in-r}

The \texttt{EBImage} package, established in 2006, is one of the oldest image
processing tools available in \texttt{R} and can be accessed via the Bioconductor
repository. It is primarily written in \texttt{R} and C/C++ \citep{AndrzejOles2017}.
\texttt{EBImage} provides a suite of general tools for image processing and analysis,
particularly excelling in microscopy-based cell assays. It features specialized
commands for cell segmentation and the extraction of quantitative data from
images \citep{Pau2010}. The package employs the RGB color system for color
detection, which is based on pixel intensities. The incorporation of the
\texttt{EBImage} package into the \texttt{R} workflow facilitates the automation and objectivity
of the image analysis procedure \citep{Heineck2019}. Images in \texttt{EBImage} are
managed as an extension of \texttt{R}`s base \texttt{array}, specifically the package-specific
\texttt{Image} class. As images are treated as multidimensional arrays, algebraic
operations are possible. This class structure includes various slots, with the
\emph{.data} slot holding the numeric pixel intensity array and the \emph{colorMode} slot
managing the image's color information. Adjusting the \emph{colorMode} setting
changes the image's rendering mode \citep{AndrzejOles2017, Heineck2019}.
Typically, the first two dimensions of an image carry spatial information, while
additional dimensions are variable and can represent color channels, time
points, replicas, or depth. \texttt{EBImage} also features an interactive display
interface through GTK+, and offers a set of functions for
automated image-based phenotyping in biology, including cell segmentation,
feature extraction, statistical analysis, and visualization \citep{Pau2010}. It
supports a range of file formats, including JPEG, PNG, and TIFF, and can handle
additional formats through integration with the 'ImageMagick' image-processing
library \citep{Pau2010, AndrzejOles2017}.

\subsection{\texorpdfstring{\texttt{magick}: advanced image processing in \texttt{R} using `ImageMagick'}{magick: advanced image processing in R using `ImageMagick'}}\label{magick-advanced-image-processing-in-r-using-imagemagick}

This package is built upon `Magick++', the C++ API for the `ImageMagick' image
processing library.\footnote{\url{https://imagemagick.org/script/magick++.php},
  accessed 07/11/2024} The \texttt{R} package provides access to `ImageMagick'
functionalities, enabling both basic and complex image manipulations directly in
\texttt{R}. Notably, images in \texttt{magick} are automatically displayed in the RStudio
console, creating a dynamic and interactive editing environment. The wide
variety of functions made available through this package are impressive. The
possibilities range from functions that are rather `just for fun', such as
implosion or introduction of noise, to more advanced processing techniques,
including different segmentation techniques, edge detection, and a
toolbox for morphology operations. The \texttt{magick} package is compatible with a
diverse range of image formats and encompasses the functionalities required for
format conversion. This includes the conversion to the formats supported by the
\texttt{EBImage} package. It also handles multiple frames, facilitating the creation
and processing of animated graphics. Each operation in \texttt{magick} creates a new,
altered version of the image, preserving the original
\citep{magick}.\footnote{\url{https://www.imagemagick.org/Magick++/ImageDesign.html},
  accessed 07/11/2024} Recent developments include the introduction of a \texttt{shiny}
application that enables users to interactively perform basic image processing
tasks such as blurring and edge
detection.\footnote{\url{https://georgestagg.github.io/shinymagick/}, accessed 07/11/2024}
The \texttt{magick} package is compatible with a range of popular file formats,
including PNG, BMP, TIFF, PDF, SVG, and JPEG, and is available through the CRAN
repository \citep{magick}.\footnote{\url{https://imagemagick.org/}, accessed 07/11/2024}

\subsection{\texorpdfstring{\texttt{OpenImageR}: a general-purpose image processing library}{OpenImageR: a general-purpose image processing library}}\label{openimager-a-general-purpose-image-processing-library}

\texttt{OpenImageR} is a lesser known but highly versatile general-purpose image
processing library that integrates both the \texttt{R} and C++ programming languages.
This package offers a comprehensive array of functions for preprocessing,
filtering, and feature extraction. Images are treated as two- or
three-dimensional objects, represented by matrices, data frames, or arrays, with
the third dimension representing color information. The functionalities within
\texttt{OpenImageR} are organized into three main categories: basic functions, which
include importing, displaying, cropping, and thresholding; filter functions,
which feature augmentation and various edge detection algorithms; and image
recognition, which incorporates functions from the `ImageHash' Python library.
In recent updates, a number of new features have been incorporated, including
Gabor feature extraction, which was originally developed in MATLAB and based on
code by \citet{Haghighat2015}. The most recent version incorporates image segmentation
techniques that utilize superpixels and clustering. Images can be visualized
through the \texttt{shiny} application or the grid package. \texttt{OpenImageR} is capable of
handling a multitude of image formats, including PNG, TIFF, and JPG
\citep{OpenImageR}.\footnote{\url{https://github.com/mlampros/OpenImageR}, accessed 07/11/2024} \footnote{\url{https://mlampros.github.io/OpenImageR/index.html}, accessed 07/11/2024}

\subsection{\texorpdfstring{\texttt{SimpleITK}: a streamlined wrapper for ITK in biomedical image analysis}{SimpleITK: a streamlined wrapper for ITK in biomedical image analysis}}\label{simpleitk-a-streamlined-wrapper-for-itk-in-biomedical-image-analysis}

The following section will introduce a prominent tool in biomedical image
analysis, the wrapper for the Insight Segmentation and Registration Toolkit
(ITK), known as \texttt{SimpleITK} \citep{Rittscher2010}. \texttt{SimpleITK} represents a
streamlined version of the original ITK, an open-source C++ library that
features a wide array of imaging algorithms and frameworks
\citep{Lowekamp2013, Yaniv2017}. This library has been in development for
approximately two decades and is particularly favored in the medical image
analysis community \citep{Lowekamp2013, Beare2018}.
The objective of \texttt{SimpleITK} is to simplify the accessibility of ITK algorithms
by reducing their complexity, thereby making these sophisticated tools more
approachable for a broader audience \citep{Lowekamp2013}. Adapted for the \texttt{R}
programming language through SWIG, \texttt{SimpleITK} offers over 250 image processing
algorithms that function across various scripting and prototyping environments
\citep{Lowekamp2013, Yaniv2017, Beare2018}. In contrast to other general-purpose
image processing packages, which treat images as mere arrays, \texttt{SimpleITK} treats
images as objects within a physical space, thereby providing a set
of metadata about image and voxel geometry in world coordinates \citep{Lowekamp2013, Yaniv2017, Beare2018}. This nuanced representation is of particular
importance for specific medical imaging applications. Additionally, \texttt{SimpleITK}
incorporates metadata such as the origin, pixel spacing, and a matrix defining
the physical orientation of image axes \citep{Yaniv2017}. However, the complexity
of the underlying ITK library may impede customization and necessitate
familiarity with C++. Another challenge for \texttt{R} developers arises from the fact
that the documentation is also based on C++ \citep{Beare2018}. To facilitate the
learning process, \citet{Yaniv2017} has developed a series of Jupyter notebooks that
provide an introduction to the package and its capabilities for both Python and
\texttt{R} users. These notebooks serve as educational tools and a resource for research,
providing full coverage of the entire spectrum of image analysis
processes
\citep{Beare2018}.\footnote{\url{https://github.com/InsightSoftwareConsortium/SimpleITK-Notebooks}, accessed 07/11/2024}
In combination with \texttt{R}, \texttt{SimpleITK} enables detailed image processing and
facilitates the subsequent statistical evaluation of quantified data. The
software is compatible with a range of digital image formats, including JPEG,
BMP, PNG, and TIFF, and is capable of analyzing 2D and 3D images
\citep{Beare2018}. The package is obtained through the GitHub
repository.\footnote{\url{https://github.com/SimpleITK/SimpleITKRInstaller}, accessed 07/11/2024}

In summary, these packages and their associated libraries offer a vast array of
algorithms that can be accessed in \texttt{R}. This includes features from the `CImg',
`ImageMagick' and ITK libraries, along with the diverse algorithms encoded in the
\texttt{EBImage} package. These flexible packages provide the foundation for the
development of numerous tailored applications.

\section{\texorpdfstring{Exploring the facets of complexity - multiplexed imaging in \texttt{R}}{Exploring the facets of complexity - multiplexed imaging in R}}\label{multi}

Multiplexed imaging is a crucial technology for analyzing complex biological
processes at the single-cell level, especially in tissue-based cancers and
autoimmune diseases \citep{Harris2022}. This technique enables the simultaneous
assessment of multiple protein and DNA molecules, overcoming limitations that
hinder advancements in understanding biological interactions and phenomena
\citep{Gerdes2013, Goltsev2018}. Multiplex imaging is the result of a multiplex
experiment, in which multiple species \citep{Aherne2024}, biomolecules
\citep{Damond2019}, or cell types \citep{Creed2021} are labeled with different probes,
dyes, or antibodies simultaneously. This technique allows for the
differentiation of components within the resulting image \citep{Eling2020}. In
comparison to standard immunofluorescence experiments, the number of distinct
targets is significantly increased, reaching up to 50 different target molecules
\citep{Damond2019, Einhaus2023}. This can be used to distinguish between species
in a biofilm \citep{Aherne2024}, or to obtain an overview of the biomarker
distribution or tissue composition in a sample \citep{Damond2019, Yang2020}. The
technique has the capacity to reveal the positions and interactions of
individual cells, provide insight into the activities of biomolecules, and holds
the potential for the reconstruction of the three-dimensional tissue
architecture of a given sample \citep{Harris2022a, Cho2023, Zhao2023}. Several
imaging techniques are used to obtain detailed insights into the spatial
interactions between cells, including Co-Detection by indEXing (CODEX)
\citep{Goltsev2018}, Multiplex Ion Beam Imaging (MIBI) \citep{Angelo2014}, and
Multiplexed Immunofluorescence Imaging (MxIF) \citep{Gerdes2013, Harris2022, Feng2023}. These methods generate vast amounts of imaging data, often
terabytes across hundreds of slides, which necessitates sophisticated image
analysis pipelines \citep{Harris2022a}.

\subsection{\texorpdfstring{\texttt{mxnorm}: normalize multiplexed imaging data}{mxnorm: normalize multiplexed imaging data}}\label{mxnorm-normalize-multiplexed-imaging-data}

Managing technical variability within these pipelines is crucial, and intensity
normalization is one approach to address this issue \citep{Harris2022a}. The \texttt{R}
package \texttt{mxnorm} addresses this by providing tools for implementing, evaluating,
and visualizing various normalization techniques \citep{mxnorm}. These tools aid in
measuring technical variability and evaluating the efficacy of various
normalization methods. They enable users to apply customized methods to improve
image consistency by reducing technical variations while preserving biological
signals. \texttt{mxnorm} provides an analysis pipeline for multiplex
images, incorporating normalization algorithms inspired by the ComBat paper,
the \texttt{fda} package, and the tidyverse framework \citep{Harris2022}. For researchers
who want to effectively standardize multiplexed imaging data, these features
make \texttt{mxnorm} a powerful resource \citep{mxnorm}.

\subsection{\texorpdfstring{\texttt{DIMPLE}: manipulation and exploration of multiplex images}{DIMPLE: manipulation and exploration of multiplex images}}\label{dimple-manipulation-and-exploration-of-multiplex-images}

To assess patient outcomes, understand disease mechanisms, and develop effective
cancer therapies, the \texttt{DIMPLE} \texttt{R} package is designed to extract critical
information from the tumor microenvironment (TME). \texttt{DIMPLE} facilitates
quantification and visualization of cellular interactions within the TME using
spatial data. It also enables correlation of these interactions and phenotypic
data with patient outcomes through sophisticated statistical modeling. \texttt{DIMPLE}
provides researchers with an extensive toolkit to analyze cellular
interactions and transform raw multiplex imaging data into actionable biological
insights, potentially identifying prognostic indicators for cancer research and
therapy development. To support the analysis process, a \texttt{shiny} application is
provided \citep{Masotti2023}.\footnote{\url{https://github.com/nateosher/DIMPLE}, accessed 07/11/2024}

\subsection{\texorpdfstring{\texttt{cytomapper}: visualization of multiplex images and cell-level information}{cytomapper: visualization of multiplex images and cell-level information}}\label{cytomapper-visualization-of-multiplex-images-and-cell-level-information}

The \texttt{cytomapper} package is designed to visualize multiplexed read-outs and
cell-level information obtained by multiplex imaging
technologies \citep{cytomapper}. It offers various
functions to view pixel-level information across multiple channels and display
expression data for individual cells. Additionally, \texttt{cytomapper} includes
features to gate cells based on their expression values, enhancing the analysis
of complex data sets. It is compatible with data from various multiplex imaging
technologies and requires single-cell read-outs, multi-channel TIFF stacks,
and segmentation masks. The \texttt{cytomapper} package is a versatile tool for
researchers working with advanced imaging data sets to explore cellular behaviors
and properties \citep{Eling2020}.

\subsection{\texorpdfstring{\texttt{SPIAT}: analyzing spatial properties of tissues}{SPIAT: analyzing spatial properties of tissues}}\label{spiat-analyzing-spatial-properties-of-tissues}

The \texttt{SPIAT} package, standing for \textbf{Sp}atial \textbf{I}mage \textbf{A}nalysis of
\textbf{T}issues, is among the most comprehensive tools for multiplex image analysis
\citep{AnnaTrigos2022}. Developed with compatibility for multiplex imaging
technologies like CODEX and MIBI, \texttt{SPIAT} facilitates the analysis of spatial
data by using X and Y coordinates of cells, their marker intensities, and
phenotypes. It features six analysis modules that support a variety of functions
including visualization, cell co-localization, distance measurements between cell
types, categorization of the immune microenvironment in relation to tumor areas,
analysis of cellular neighborhoods and clusters, and quantification of spatial
heterogeneity \citep{Yang2020, AnnaTrigos2022}. To use \texttt{SPIAT}, images must be
pre-segmented and cells phenotyped, typically using external software like HALO
and InForm to prepare the correct input format \citep{Yang2020}. The package
provides a \texttt{shiny} application that assists the user in formatting spatial data
from the aforementioned sources in a manner that ensures compatibility with the
functions of the \texttt{SPIAT} package.\footnote{\url{https://github.com/TrigosTeam/SPIAT-shiny}, accessed 07/11/2024}
\texttt{SPIAT} is designed to be user-friendly, making complex spatial analysis
accessible to researchers with varying computational skills \citep{Feng2023}.

\subsection{\texorpdfstring{\texttt{Seurat}: spatially resolved transcriptomics (SRT)}{Seurat: spatially resolved transcriptomics (SRT)}}\label{seurat-spatially-resolved-transcriptomics-srt}

Spatially resolved transcriptomics (SRT) is a commonly used approach for the
quantification of gene expression levels in tissue sections while preserving
positional information \citep{larsson_semla_2023}. The \texttt{Seurat} package
\citep{hao_dictionary_2024} is a package for spatial transcriptomics and multiplexed
imaging analysis. It shares some similarities with the \texttt{SPIAT} and \texttt{spatialTIME}
packages. For assays with cell segmentation, \texttt{Seurat} facilitates the
visualization of individual cell boundaries or centroids, thereby enabling more
precise mapping of molecular signals to cells. In contrast to other reviewed
packages, \texttt{Seurat}'s unique feature is its integration of spatial and molecular
data for spatial data analysis. In particular, it enables the joint analysis of
spatially-resolved gene expression data alongside traditional single-cell
RNA-seq, allowing researchers to map cell types and states within their native
tissue context, along with metadata. Notably, \texttt{Seurat} supports the analysis and
visualization of spatial omics data at both single-cell and subcellular
resolution. \texttt{Seurat} deliberately supports a broad range of spatial
technologies, including the Akoya CODEX/Phenocycler\texttrademark{} platform and
sequencing-based platforms such as Visium Spatial Gene Expression, 10x Genomics
and Slide-seq. To achieve these capabilities, \texttt{Seurat} offers statistical
methods to identify genes or features with spatially structured expression
patterns, which facilitate the uncovering of region-specific biological
processes. Since its first publication in 2015 \citep{satija_spatial_2015}, its
functionality has expanded to include support for image-based spatial
transcriptomics (highly multiplexed imaging technologies). \texttt{Seurat} uses image
data (e.g., raw, masked, processed images, 10X Genomics Visium Image).

\subsection{\texorpdfstring{\texttt{spatialTIME}: spatial analysis of Vectra immunofluorescence data}{spatialTIME: spatial analysis of Vectra immunofluorescence data}}\label{spatialtime-spatial-analysis-of-vectra-immunofluorescence-data}

The \texttt{spatialTIME} package has been designed for the analysis of
immunofluorescence data with the objective of identifying spatial patterns
within the TME. The package appears to be designed to work with data acquired by
the Vectra Polaris™ imaging
system.\footnote{\url{https://web.archive.org/web/20250125194642/https://www.akoyabio.com/wp-content/uploads/2021/11/Vectra_Polaris_Product_Note_with_MOTiF_Akoya.pdf}, accessed 07/14/2025}
It facilitates the spatial analysis of multiplex
immunofluorescence data, enabling spatial characterization and architectural
reconstruction. Additionally, the package includes a \texttt{shiny} application,
\texttt{iTIME}, which offers a user-friendly point-and-click interface that mirrors
many of the capabilities found in \texttt{spatialTIME}
\citep{Creed2021}.\footnote{\url{https://fridleylab.shinyapps.io/iTIME/}, accessed 07/11/2024}
The package also comes with a detailed vignette to help users get started with
its features \citep{spatialTime}.

In summary, \texttt{R} offers a range of tools for analyzing multiplex imaging data.
However, it is important to note that these packages, except for the
\texttt{cytomapper} package, require image preprocessing and use the resulting data
frames as input for analysis.

\section{\texorpdfstring{Tracing the dance - \texttt{R} packages for analyzing cellular movement dynamics}{Tracing the dance - R packages for analyzing cellular movement dynamics}}\label{tracing-the-dance---r-packages-for-analyzing-cellular-movement-dynamics}

Cellular migration is essential for various physiological and pathological
functions, including development, immune responses, wound healing, and tumor
progression \citep{Bise2011, Yamada2019, Hossian2020}, making it a crucial field
in disciplines such as neuroscience, oncology, and regenerative medicine
\citep{Kaiser2004, Hu2023}. To gain insight into these biological processes,
researchers can track cell movement by manually tracing their positions in
sequential images for 2D coordinates or by incorporating the z coordinate for 3D
analysis \citep{Hu2023}. By studying cell migration at multiple levels - from the
molecular components and the behavior of individual cells to the dynamics of
cell populations - researchers can unravel the complex interactions that
influence the movement of cells \citep{Maheshwari1998}. Such wide studies
are crucial in advancing our understanding of phenomena such as cancer
metastasis, which could lead to new therapeutic strategies \citep{Um2017}.

\subsection{\texorpdfstring{\texttt{celltrackR}: analyzing motion in two or three dimensions}{celltrackR: analyzing motion in two or three dimensions}}\label{celltrackr-analyzing-motion-in-two-or-three-dimensions}

The \texttt{celltrackR} package is intended for analyzing motion in two or three
dimensions, primarily using data from time-lapse microscopy or x-y-(z)
coordinates. It is useful in both biological settings for tracking cells and in
non-biological contexts for object tracking \citep{celltrackR}. Additionally, the
package provides a web user interface to facilitate the analysis
process.\footnote{\url{https://github.com/ingewortel/celltrackR}, accessed 07/11/2024} The package contains
standard analytical tools, such as mean square displacement and autocorrelation,
as well as algorithms for simulating artificial tracks using various models,
such as Brownian motion and the Beauchemin model of lymphocyte migration
\citep{celltrackR}. Furthermore, \texttt{celltrackR} provides a complete pipeline for
track analysis, including data management, quality control, and methods for
detecting tracking errors, such as track interpolation and drift correction
\citep{Wortel2021}. The package is well-documented, providing detailed vignettes that
guide users through the migration analysis process \citep{celltrackR}.

\section{Mapping the unseen - exploring spatial properties in bioimage data}\label{mapping-the-unseen---exploring-spatial-properties-in-bioimage-data}

In this section, we explore the use of \texttt{R} tools for analyzing spatial
properties in applications such as transcriptomics. One notable package is the
\texttt{MoleculeExperiment} package \citep{noauthor_moleculeexperiment_nodate}, which
can be used to analyze molecular data within image-based data sets. This package
builds upon other popular packages like \texttt{EBImage}, focusing on raster analysis,
and \texttt{terra} \citep{terra} for handling geographic information systems (GIS) tasks.
Raster or gridded data are spatial data structures that divide regions into
rectangles called cells or pixels, storing one or more values. These grids
contrast with vector data representing points, lines, and polygons in GIS
contexts. Each pixel represents an area on a surface, making color image rasters
unique due to their multiple bands containing reflectance values for specific
colors or light spectra.

The \texttt{terra} package (formerly known as \texttt{raster/sp}) offers fast operations
through optimized back-end C++ code. Users can perform various raster tasks such
as creating objects, executing spatial/geometric functions like re-projections
and resampling, filtering, and conducting calculations. Functions within the
package facilitate extracting essential statistics from entire SpatRaster
data sets, including mean values, maximum values, value ranges, or counts of NA
cells. In addition to these analytical capabilities, \texttt{terra} provides
functionality for visualizing data and interacting with rasters, enhancing user
experience when working with gridded spatial information. This versatility makes
the package an essential tool in analyzing transcriptomic data within
image-based data sets using \texttt{R} tools \citep{Hijmans2020}.

\section{Numbers game - simplifying scientific image data representation}\label{numbers-game---simplifying-scientific-image-data-representation}

The \texttt{R} environment offers multiple additional tools for
the extraction of information from data, with a particular focus on the
extraction of measuring points in scientific diagrams. This task is of
particular significance when data is available exclusively in image format, for
instance from publications or other sources.

\subsection{\texorpdfstring{\texttt{digitize}: use data from published plots or images}{digitize: use data from published plots or images}}\label{digitize-use-data-from-published-plots-or-images}

The \texttt{digitize} package is a well-established and mature tool that simplifies
importing data from digital images by providing a user-friendly interface for
calibration and point location. It leverages the \texttt{readbitmap} package to read
various bitmap formats such as BMP, JPEG, PNG, and TIFF. When reading these
image files, digitize relies on the magic number embedded within each file
rather than solely relying on the file extension. For seamless integration with
JPEG and PNG images, this package depends on external libraries like `libjpg'
and `libpng' \citep{poisot_digitize_2011}. Interestingly, the packages can be
used for other purposes as well. For example, Figure \ref{fig:digitize}
demonstrates that the \texttt{digitize} package can quantify certain structures in
images. This example illustrates how fluorescent objects in an image can be
identified by their position and subsequently quantified by their number.



\begin{figure}[H]

{\centering \includegraphics[width=0.89\linewidth]{RJ-2025-030_files/figure-latex/digitize-1} 

}

\caption{\textbf{Counting using \texttt{digitize}}: The figure provided to \texttt{digitize}, consists of cells with DNA damage (similar to \citet{Roediger2018}). The nucleus is colored with DAPI (blue) and the \(\gamma\)H2AX histone, a marker for DNA double strand breaks, is stained with a specific antibody. The \texttt{digitize} package is used to interactively extract the coordinates (shown in the console) by using the cursor to define the region of interest (blue cross) and tag the objects within it (red circles). In the screenshot it is displayed how \texttt{digitize} is invoked in RKWard (0.7.5z+0.7.6+devel3, Linux, TUXEDO OS 2, \citep{Roediger2012}).}\label{fig:digitize}
\end{figure}

\subsection{\texorpdfstring{\texttt{juicr}: extraction of numerical data from scientific images}{juicr: extraction of numerical data from scientific images}}\label{juicr-extraction-of-numerical-data-from-scientific-images}

\texttt{juicr} is a tool designed to automate the extraction of numerical data from
scientific images. It offers users a Tcl/Tk graphical user interface (GUI) that
simplifies point-and-click manual extraction with advanced features such as
image zooming, calibration capabilities, and classification options.
Additionally, \texttt{juicr} provides semi-automated tools for fine-tuning extraction
attempts. To ensure optimal performance, this package depends on
the \texttt{EBImage} package, which must be installed and loaded
prior to utilization. Once data is extracted using \texttt{juicr}, users can choose to
save their results in various formats including comma-separated values (CSV)
files or postscript (EPS) files for easy import into other software. Moreover,
extractions can also be saved as fully-embedded and standalone HTML files, that
preserve all extraction details, setup configurations, and image modifications.
These HTML files provide a means of storing data while ensuring long-term
accessibility and replicability for future reference and analysis purposes
\citep{juicr}.

\subsection{\texorpdfstring{\texttt{image2data}: transforming images into data sets}{image2data: transforming images into data sets}}\label{image2data-transforming-images-into-data-sets}

In recent years, the conversion of images into data sets has emerged as an
essential tool in various fields such as computer vision, healthcare, and
geospatial analysis. The \texttt{image2data} \texttt{R} package provides functionality to
convert images into data sets \citep{caron_image2data_2022}. The primary function \texttt{image2data()} takes
an image file with extensions like .png, .tiff, .jpeg or .bmp as input and
converts it into a data set. Each row of the resulting data set represents a pixel
(or subject), while columns represent variables such as x-coordinate,
y-coordinate, and hex color code. The \texttt{image2data()} function offers
methods for reducing data sets, yielding results akin to pixelated images with
adjustable precision values. Higher precision leads to more data points, while
lower precision yields fewer. This example showcases a pixelated representation
of a pixel-based image in PNG format, highlighting its unique visual attributes.
Users have the ability to customize and modify various elements by adjusting
their corresponding hex color codes for precise control over hues, saturation
levels, and brightness.



\begin{verbatim}
# Loading the required packages
library(image2data)
library(data.table)

# Path to the image file
image <- "figures/test3.png"
img <- EBImage::readImage(image)

# Subsampling the image data
beads_subsample <- image2data(
  path = image,                    # Path to the image file
  reduce = .2,                     # Reduction factor for subsampling 
                                   # (20 % of original number of pixels)
  seed = 42,                       # Seed for random number generation by
                                   # return (for reproducibility)
  showplot = FALSE                 # Whether to show a plot of the subsampled data
) |> as.data.table()               # Converting the result to a data.table

# Display a part of the subsampled data
beads_subsample
\end{verbatim}

\begin{verbatim}
#>                 x          y       g
#>             <num>      <num>  <char>
#>     1:  0.1022393 -0.9263444 #2F5C61
#>     2: -0.1022393  0.4006978 #121D11
#>     3:  1.2449136 -0.5213380 #121B10
#>     4:  0.4871401 -1.6588028 #151E1C
#>     5: -0.3548305 -1.5381626 #0D1B0D
#>    ---                              
#> 23151: -1.1486884  1.1159219 #352B5E
#> 23152: -0.6074216  0.1508003 #252E60
#> 23153:  1.4975048  0.5988925 #14180B
#> 23154: -1.3651952  0.2025032 #2A306B
#> 23155:  0.3428023 -0.3231434 #112048
\end{verbatim}

\begin{verbatim}
EBImage::display(img)

# Plotting the subsampled data
plot(beads_subsample$x,            # x-coordinates
     beads_subsample$y,            # y-coordinates
     col = beads_subsample$g,      # Color based on hex code extracted by image2data()
     pch = 19,                     # Plotting character (solid circle)
     xlab = "",
     ylab = "")
\end{verbatim}

\begin{figure}[H]

{\centering \includegraphics[width=0.65\linewidth]{RJ-2025-030_files/figure-latex/img2data-1} \includegraphics[width=0.65\linewidth]{RJ-2025-030_files/figure-latex/img2data-2} 

}

\caption{\textbf{Application Example of the \texttt{image2data} Package}: The image displays nuclei stained with DAPI (blue) and a quantitative marker for DNA double strand breaks, was labeled with a specific antibody (green). The \texttt{image2data} package extracted 20\% of the pixels from the original image (top), creating a table with x\textbar y coordinates and corresponding hex color codes. This data was then used to reassemble the image using \texttt{R}'s base plot (bottom).}\label{fig:img2data}
\end{figure}

\section{Engaging insights - interactive approaches to image analysis}\label{inter}

The analysis and processing of images to extract useful information can be a
challenging endeavor. Consequently, the implementation of interactive approaches
accompanied by immediate visual feedback regarding parameter alterations
represents a significant aid in simplifying image analysis. Therefore, this
section will focus on interactive tools and functions from packages that
facilitate the exploration of images and the extraction of useful insights.

\subsection{\texorpdfstring{\texttt{cytomapper}: a shiny application for hierarchical gating and visualization of multiplex images}{cytomapper: a shiny application for hierarchical gating and visualization of multiplex images}}\label{cytomapper-a-shiny-application-for-hierarchical-gating-and-visualization-of-multiplex-images}

The \texttt{cytomapper} package, designed for processing multiplex images, includes a
\texttt{shiny} application that facilitates the hierarchical gating of cells using
specific markers and allows for the visualization of selected cells. The
graphical user interface (GUI) of this \texttt{shiny} application is designed to assist in
the process of cell labeling. Furthermore, the data from the selected cells can
be saved as a \emph{SingleCellExperiment}, thereby enabling various downstream
processing methods \citep{Eling2020, cytomapper}. The \texttt{cytomapper} package offers
comparable functionality for feature extraction as described in the beginning,
providing an algorithm for extracting morphological and intensity
features from multiplex images \citep{cytomapper}.

\subsection{\texorpdfstring{\texttt{colocr}: interactive ROI selection in image analysis through shiny app}{colocr: interactive ROI selection in image analysis through shiny app}}\label{colocr-interactive-roi-selection-in-image-analysis-through-shiny-app}

The \texttt{colocr} package, which facilitates the exploration of fluorescent
microscopic images, features a GUI accessible through a \texttt{shiny} app. This GUI
can be invoked locally or accessed online. The process of image analysis
frequently necessitates the input of manual labor, particularly in the selection
of ROIs. This package streamlines the process of selecting ROIs by
semi-automating it, thereby allowing users to review and interactively select
one or more ROIs. Moreover, the app offers the option to interactively adjust
parameters such as threshold, tolerance, denoising, and hole filling, thereby
enhancing user control and precision in image analysis by providing immediate
feedback \citep{Ahmed2019, colocr}.\footnote{\url{https://mahshaaban.shinyapps.io/colocr_app2/}, accessed 07/11/2024}



\begin{figure}[H]

{\centering \includegraphics[width=0.69\linewidth]{figures/colocr_gui} 

}

\caption{\textbf{Shiny Application of the \texttt{colocr} Package}: The figure depicts an interactive image analysis graphical user interface (GUI), invoked locally from the RStudio integrated development environment (IDE). It comprises multiple sliders for real-time parameter adjustments and supports the selection of multiple distinct regions of interest (ROIs). Users can interactively select ROIs and extract characteristics such as pixel intensity. Furthermore, the tool offers functionalities to compute co-localization, providing comprehensive analysis capabilities. Available at: \url{https://mahshaaban.shinyapps.io/colocr_app2/} or run: \texttt{colocr::colocr\_app()}.}\label{fig:colocrGUI}
\end{figure}

\subsection{\texorpdfstring{\texttt{magick}: shiny and Tcl/Tk tools for interactive image exploration}{magick: shiny and Tcl/Tk tools for interactive image exploration}}\label{magick-shiny-and-tcltk-tools-for-interactive-image-exploration}

A basic demo version of an interactive web interface for the \texttt{magick} \texttt{R} package
is available via a \texttt{shiny} app. While it remains a demonstration version and
does not encompass all the functionalities of the full package, it is not
suitable for in-depth analysis of large-scale imaging data. In contrast, the app
provides fundamental tools for image processing, including blurring, imploding,
rotating, and more. This tool is designed to facilitate basic image
processing tasks in an interactive
environment.\footnote{\url{https://github.com/jeroen/shinymagick}, accessed 07/11/2024}
Additionally, a distinct package is available that provides the functionality of
\texttt{magick} in an interactive manner. This package, called \texttt{magickGUI}, was
developed by \citet{magickGUI}. The interactive features are based on the Tcl/Tk
wrapper for \texttt{R} and include functions for thresholding, edge detection, noise
reduction, and many more.

\subsection{\texorpdfstring{\texttt{biopixR}: interactive Tcl/Tk function for feature extraction}{biopixR: interactive Tcl/Tk function for feature extraction}}\label{biopixr-interactive-tcltk-function-for-feature-extraction}

In the \texttt{biopixR} package, the \texttt{tcltk} package --- which enables Tcl/Tk integration
in \texttt{R} --- was employed to create an interactive function. This function initiates
the launch of a GUI that streamlines the process of feature extraction by
facilitating object detection and enabling users to select between edge
detection and thresholding for segmentation. The GUI displays the currently
detected edges (when using edge detector) or all detected coordinates (when
using threshold) and the object centers within an image. The application
includes sliders that allow users to adjust parameters and magnify the image.
This interactive function is designed to facilitate the parameter selection
process, as the chosen parameters affect the quality of image segmentation
\citep{biopixR}.

\section{\texorpdfstring{Tailored tools - specialized \texttt{R} packages for image processing}{Tailored tools - specialized R packages for image processing}}\label{tailored-tools---specialized-r-packages-for-image-processing}

In contrast to the previously mentioned general-purpose tools, some packages
have been designed with a specific focus on particular research areas. These
specialized tools address the unique challenges encountered in those fields and
offer versatile solutions for analyzing the data collected in those domains.
While a complete survey of the available packages is outside the scope of
this article, a concise overview of the most pertinent packages and their
applications will be presented.

\subsection{\texorpdfstring{\texttt{fslr}: analysis of neuroimage data}{fslr: analysis of neuroimage data}}\label{fslr-analysis-of-neuroimage-data}

The \texttt{fslr} package serves as a wrapper for the FSL software, enabling the use
of the `FMRIB' Software Library within the \texttt{R} environment. The
FSL software is a widely utilized tool for the analysis and processing of
neuroimaging data, including MRI. The package employs the use of \texttt{NIfTI} images
to facilitate the execution of processing tasks, thereby introducing
capabilities such as brain extraction and tissue segmentation, which were
previously unavailable in \texttt{R} \citep{Muschelli2015, fslr}.

\subsection{\texorpdfstring{\texttt{colocr}: co-localization analysis of fluorescence microscopy images}{colocr: co-localization analysis of fluorescence microscopy images}}\label{colocr-co-localization-analysis-of-fluorescence-microscopy-images}

A common application derived from fluorescence microscopy, which is extensively
utilized in biological research, is co-localization analysis. This analysis
assesses the distribution of signals across different color channels to
determine whether the positioning of objects is correlated \citep{Dunn2011, Ahmed2019}. The objective of this software is to streamline the analysis
process by providing tools for loading
images, selecting regions of interest, and calculating co-localization
statistics \citep{Ahmed2019, colocr}. It incorporates methods outlined by
\citet{Dunn2011}.\footnote{\url{https://github.com/ropensci/colocr}, accessed 07/11/2024}

CRAN offers a list of packages tailored to medical image
analysis, accompanied by detailed descriptions of their applications. This list
can be accessed via the following URL:

\phantom{x}\hspace{0.5cm}\url{https://cran.r-project.org/web/views/MedicalImaging.html}

Moreover, the Bioconductor repository contains a number of packages focused on
single-cell analysis, as detailed by \citet{Amezquita2019}. The Bioconductor project is
an initiative dedicated to the collaborative development and the use of scalable
software for computational biology and bioinformatics. Its objective is to
reduce the entry barriers to interdisciplinary research and to improve the
remote reproducibility of scientific findings \citep{Gentleman2004}. Other packages
identified during the course of our research, though not explored in depth, are
acknowledged in the forthcoming summary:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.3081}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2121}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0758}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1061}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1263}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1717}}@{}}
\caption{\label{tab:overview1}Overview of \texttt{R} packages for tailored applications in image processing. This table summarizes key aspects such as general application, repository (Repo) hosting (CRAN, Bioconductor (Bioc), GitLab), linked libraries, and package dependencies. It also includes information on licensing and current status. The current status is divided into the date of first publication on the corresponding repository (*). Active repository status is indicated by a circle, with the date of the latest update (°). Some packages that are no longer maintained are marked as archived (†).}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Application
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Repo
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
based on
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
License
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Status
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Application
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Repo
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
based on
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
License
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Status
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{adimpro} \newline by \citet{Polzehl2007} & Adaptive Smoothing & \href{https://CRAN.R-project.org/package=adimpro}{CRAN} & Image Magick & GPL \newline (\(\geq\) 2) & *2006-10-27 \newline °2023-09-06 \\
\textbf{phenopix} \newline by \citet{Filippa2016} & Vegetation phenology & \href{https://CRAN.R-project.org/package=phenopix}{CRAN} & jpeg & GPL-2 & *2017-06-16 \newline °2024-01-19 \\
\textbf{gitter} \newline by \citet{Wagih2014} & Pinned Microbial Cultures & \href{https://CRAN.R-project.org/package=gitter}{CRAN-archived} & EBImage & LGPL & *2013-06-29 \newline †2020-01-16 \\
\textbf{TCIApathfinder} \newline by \citet{Russell2018} & Cancer Imaging & \href{https://CRAN.R-project.org/package=TCIApathfinder}{CRAN} & Rnifti & MIT & *2017-08-20 \newline °2019-09-21 \\
\textbf{SPUTNIK} \newline by \citet{Inglese2018} & Mass Spectrometry Imaging & \href{https://CRAN.R-project.org/package=SPUTNIK}{CRAN} & imager & GPL \newline (\(\geq\) 3) & *2018-02-19 \newline °2024-04-16 \\
\textbf{SAFARI} \newline by \citet{Fernandez2022} & Shape analysis & \href{https://CRAN.R-project.org/package=SAFARI}{CRAN} & EBImage & GPL \newline (\(\geq\) 3) & *2021-02-25 \\
\textbf{pavo} \newline by \citet{Maia2019} & Spectral and Spatial analysis & \href{https://CRAN.R-project.org/package=pavo}{CRAN} & magick \& imager & GPL \newline (\(\geq\) 2) & *2012-12-05 \newline °2023-09-24 \\
\textbf{miet} \newline by \citet{Combes2020} & Magnetic Resonance images & \href{https://gitlab.inria.fr/miet/miet}{gitlab} & Rnifti & MIT & *2019-09-06 \newline °2023-12-20 \\
\textbf{scalpel} \newline by \citet{Petersen2017} & Calcium imaging & \href{https://CRAN.R-project.org/package=scalpel}{CRAN} & - & GPL \newline (\(\geq\) 2) & *2017-03-14 \newline °2021-02-03 \\
\textbf{ProFit} \newline by \citet{Robotham2016} & Galaxy images & \href{https://CRAN.R-project.org/package=ProFit}{CRAN-archived} & EBImage & LGPL-3 & *2016-09-29 \newline †2022-08-08 \\
\textbf{fsbrain} \newline by \citet{Schaefer2020} \& \citet{Schaefer2024} & Neuroimaging & \href{https://CRAN.R-project.org/package=fsbrain}{CRAN} & magick & MIT & *2019-10-30 \newline °2024-02-03 \\
\textbf{geomorph} \newline by \citet{Adams2013} & Geometric morphometric shape analysis & \href{https://CRAN.R-project.org/package=geomorph}{CRAN} & jpeg & GPL \newline (\(\geq\) 3) & *2012-10-26 \newline °2024-03-05 \\
\textbf{imbibe} & Medical images & \href{https://CRAN.R-project.org/package=imbibe}{CRAN} & Rnifti & BSD-3-clause & *2020-10-26 \newline °2022-11-09 \\
\textbf{opencv} \newline by \citet{opencv} & edge, body, face detection & \href{https://CRAN.R-project.org/package=opencv}{CRAN} & OpenCV & MIT & *2019-04-01 \newline °2023-10-29 \\
\textbf{DRIP} & jump regression, denoising, deblurring & \href{https://CRAN.R-project.org/package=DRIP}{CRAN} & - & GPL \newline (\(\geq\) 2) & *2015-09-22 \newline °2024-02-05 \\
\textbf{imagefluency} \newline by \citet{imagefluency} & image statistics based on fluency theory & \href{https://CRAN.R-project.org/package=imagefluency}{CRAN} & magick \& OpenImageR & GPL-3 & *2019-09-27 \newline °2024-02-22 \\
\textbf{mand} \newline by \citet{mand} & Neuroimaging & \href{https://CRAN.R-project.org/package=mand}{CRAN} & imager & GPL-2 \newline GPL-3 & *2020-05-06 \newline °2023-09-12 \\
\textbf{recolorize} \newline by \citet{recolorize} & Segmentation & \href{https://CRAN.R-project.org/package=recolorize}{CRAN} & imager & CC BY 4.0 & *2021-12-07 \\
\textbf{MaxContrastProjection} \newline by \citet{MaxContrastProjection} & maximum contrast projection & \href{https://bioconductor.org/packages/MaxContrastProjection/}{Bioc} & EBImage & Artistic-2.0 & *2017-04-25 \newline †2020-04-28 \\
\end{longtable}

\section{Combining forces - making use of the open-source approach}\label{combining-forces---making-use-of-the-open-source-approach}

The majority of the aforementioned packages are designed to encompass all facets
of image analysis, including preprocessing, quantification, and visualization.
This integration is typically achieved through the utilization of one or more
general-purpose packages (Table \ref{tab:overview1} and \ref{tab:overview2}).
The combination of existing packages or libraries with new code facilitates the
development of specialized packages. \texttt{R}, as a package-based language, provides a
convenient means of combining these specialized packages to meet the specific
needs of the individual user. The following section illustrates the combination of
packages to perform statistical analysis on quantified image data.

\subsection{\texorpdfstring{\texttt{biopixR} and \texttt{countfitteR}: quantitative analysis of DNA double strand breaks}{biopixR and countfitteR: quantitative analysis of DNA double strand breaks}}\label{biopixr-and-countfitter-quantitative-analysis-of-dna-double-strand-breaks}

DNA double strand breaks (DSBs) represent a particularly severe form of DNA
damage, frequently resulting in apoptotic cell death in the absence of repair.
The extent of DNA damage can be quantified through immunofluorescence
staining, which employs antibodies against the phosphorylated histone protein
H2AX (\(\gamma\)H2AX). The staining process results in the formation of
\(\gamma\)H2AX foci, which serve as a quantitative representation of the number of
DNA DSBs. It has been proposed that the number of DNA DSBs is indicative of the
efficacy of an anti-tumor agent, thereby enabling the assessment of individual
patient responses to therapies and the evaluation of the general cytotoxic
effects of treatments \emph{in vivo}. This enables more precise modulation of therapy
according to the patient's individual needs \citep{Roediger2018, Ruhe2019, schneider_open_2019}.

In the following example, the \texttt{biopixR} package was employed to quantify DNA
double-strand breaks, resulting in an output of foci per cell (Figure
\ref{fig:DSB}). To achieve this objective, the green fluorescent foci were
extracted by applying the \texttt{objectDetection()} function to the green color
channel of the image (Figure \ref{fig:DSB}A). The result of the foci extraction
is illustrated in Figure \ref{fig:DSB}B using the \texttt{changePixelColor()} function,
whereby each of the distinct foci is highlighted in a different color. The DAPI-stained
nuclei were extracted through the application of thresholding on the blue color
channel. Subsequently, the resulting data frame was subjected to size filtering
in order to eliminate any detected noise. The final quantification of foci per
cell was achieved by comparing the coordinates of nuclei and foci in the
obtained data frames. This result can then be further analyzed using the
\texttt{countfitteR} package, which provides an automated evaluation of
distribution models for count data \citep{Burdukiewicz2019, Chilimoniuk2021}. The
resulting distribution is presented in Figure \ref{fig:countfitteR}.

\begin{verbatim}
# Load the 'biopixR' package
library(biopixR)

# Import image from specified path
DSB_img <- importImage("figures/tim_242602_c_s3c1+2+3m4.tif")

# Extract the blue color channel representing the nuclei and
# the green color channel representing yH2AX foci
core <- as.cimg(DSB_img[, , , 3])
yH2AX <- as.cimg(DSB_img[, , , 2])

# Process the nuclei: thresholding, labeling, and converting to a data frame
cores <-
  threshold(core) |> label() |> as.data.frame() |> subset(value > 0)

# Calculate the center and size for the nuclei
DT <- as.data.table(cores)
cores_center <-
  DT[, list(mx = mean(x),
            my = mean(y),
            size = length(x)), by = value]

# Filter the nuclei based on size, to discard noise
cores_clean <-
  sizeFilter(cores_center,
             cores,
             lowerlimit = 150,
             upperlimit = Inf)

# Detect objects yH2AX foci in green color channel
DSB <- objectDetection(yH2AX, alpha = 1.1, sigma = 0)

# Function to compare coordinates from two data frames and count matches
compareCoordinates <- function(df1, df2) {
  # Create a single identifier for each coordinate pair
  df1$coord_id <- paste(round(df1$mx), round(df1$my), sep = ",")
  df2$coord_id <- paste(df2$x, df2$y, sep = ",")

  # Find matches by checking if coordinates from df2 exist in df1
  matches <- df2$coord_id %in% df1$coord_id

  # Convert df2 to a data table and add a column indicating matches
  DT <- data.table(df2)
  DT$DSB <- matches

  # Summarize the results
  result <-
    DT[, list(count = length(which(DSB == TRUE))), by = value]

  return(result)
}

# Compare coordinates between detected DSB centers and cleaned nuclei coordinates
count <- compareCoordinates(DSB$centers, cores_clean$coordinates)

# Extract the count column for further analysis
to_analyze <- count[, 2]
\end{verbatim}



\begin{figure}[H]

{\centering \includegraphics[width=0.95\linewidth]{figures/fig_DSB} 

}

\caption{\textbf{Quantification of DNA Double Strand Breaks}: \textbf{A}) The image displays cells with nuclei stained using DAPI. The quantitative marker for DNA double strand breaks, \(\gamma\)H2AX, targeted with a specific antibody, is visible as green fluorescent foci. The experimental procedure follows the method described by \citet{Roediger2018}. \textbf{B}) The \(\gamma\)H2AX foci are quantified using the \texttt{biopixR} package. The detected foci are highlighted in different colors using the \texttt{changePixelColor()} function.}\label{fig:DSB}
\end{figure}



\begin{figure}[H]

{\centering \includegraphics[width=0.89\linewidth]{figures/count_distr} 

}

\caption{\textbf{Analyzing Count Data with the \texttt{countfitteR} Package}: The data representing the number of foci per cell obtained from the \texttt{biopixR} analysis were imported into the interactive \texttt{shiny} interface of the \texttt{countfitteR} package. This package analyzed the distribution and summarized the results. One outcome is illustrated in this figure, which shows the frequency distribution of a specific count of foci per cell.}\label{fig:countfitteR}
\end{figure}

\section{\texorpdfstring{Exploring the blank spot - z-stack imaging in \texttt{R}}{Exploring the blank spot - z-stack imaging in R}}\label{exploring-the-blank-spot---z-stack-imaging-in-r}

Z-stack imaging refers to the capture of images that possess a third dimension,
specifically image depth, which enables the spatial capture of molecules or the
reconstruction of the three-dimensional architecture of tissues. One method for
achieving z-stacking involves capturing multiple two-dimensional images at
uniform intervals over the depth of an object by changing the focal plane. The
individual 2D images are then reconstructed to create a 3D model \citep{Trivedi2020, Kim2022}.

The only packages currently available in the \texttt{R} programming language for
dealing with z-stack imaging are \texttt{spatialTIME} and \texttt{MaxContrastProjection}.
However, the \texttt{spatialTIME} package necessitates preprocessing and is therefore
unable to handle the images directly \citep{Creed2021}. The other package,
\texttt{MaxContrastProjection}, has unfortunately been removed from Bioconductor. The
package is capable of performing maximum contrast projection, whereby the
z-stacks of a 3D image are merged into a 2D image \citep{MaxContrastProjection}. To
the best of our knowledge, these are the only packages in \texttt{R} that address the
topic of z-stack imaging.

\section{Scaling new heights - high throughput analysis in the era of small and big data?}\label{scaling-new-heights---high-throughput-analysis-in-the-era-of-small-and-big-data}

The exponential growth of data, which reached levels of zettabytes (\(10^{21}\)
bytes) as early as 2012 \citep{Sagiroglu2013}, is accompanied by a significant
increase in image generation due to advancements in imaging technologies such as
microscopy. High-resolution images produced in a single experiment can result in
data sets exceeding terabytes \citep{Peng2012, Eliceiri2012}. This surge in data
generation across various fields has initiated the era of Big Data, which
presents considerable challenges in the handling and interpretation of massive
data sets \citep{Cui2015}. In automated microscopy, the rapid acquisition of large
image volumes facilitates extensive screening processes but complicates the
conversion of image stacks into actionable information and discoveries, resulting in
a critical need for analytical pipelines that can efficiently identify regions
of interest, compute relevant features, and perform statistical analysis,
ensuring reproducibility and reliability \citep{Wollman2007}.

The extraction of quantitative information from images is a common practice, but
it is becoming increasingly complex and error-prone when performed manually.
This complexity requires the implementation of high-throughput methods capable
of autonomously processing multiple images \citep{Olivoto2022}. These developments
are crucial not only in specialized fields such as immunohistochemistry,
fluorescence \emph{in situ} hybridization \citep{Ollion2013}, drug discovery, and cell
biology \citep{Shariff2010}, but also in promoting a data-driven approach to
biological research, thereby accelerating tasks and enhancing research
productivity \citep{Rittscher2010}.

The \texttt{R} programming language has limitations in handling large data sets. Since
\texttt{R} places temporary copies of data in the random access memory (RAM) to access
objects, it can lead to memory overload when processing data sets that exceed
the available RAM. Additionally, \texttt{R} uses RAM to store generated data, so large
lists of imported images can easily overwhelm the RAM. Moreover, \texttt{R} typically
executes code on a single thread, not utilizing the full capabilities of the
central processing unit (CPU). Several packages address issues such as
file-based access and parallel computing, thereby enhancing \texttt{R}`s capability to
handle big data. One approach is to combine \texttt{R} with the 'Hadoop' library
\citep{Prajapati2013, Oussous2018}. Another effective method for managing big data
is the use of the HDF5, which efficiently manages
data storage and access, provides multicore reading and writing, and is
well-suited for organizing complex data collections. The \texttt{cytomapper} package
utilizes HDF5 to optimize file management \citep{cytomapper, Folk2011, Koranne2011}.

Other packages, such as \texttt{pliman}, \texttt{biopixR}, and \texttt{FIELDimageR}, include features
for optimized batch processing, such as parallel processing, by utilizing the
\texttt{foreach} package for multi-core processing \citep{Olivoto2022, biopixR, Matias2020}. However, these packages are not fully optimized for big data. The
\texttt{biopixR} package simplifies image processing by providing a pipeline that scans
entire directories and verifies image uniqueness using Message Digest 5 (MD5)
sums. It enables the application of specific filters to batches of images and
generates an \texttt{RMarkdown} log file detailing the operations performed. The results
are saved in a manageable CSV format, enhancing the
efficiency of handling whole image directories \citep{biopixR}.

In conclusion, while \texttt{R} offers a range of options for handling big data, these
options are not widely implemented in image processing packages. Consequently,
the optimization and creation of workflows capable of handling big data is left
to the end-user.

\section{Summary}\label{summary}

In conclusion, we present a summary of the major \texttt{R} packages previously
discussed. This summary provides an overview of the general applications,
published repositories, and licensing information associated with these
packages. Furthermore, it includes a list of the dependencies or libraries that
these packages rely on. The status column indicates both the initial publication
date and the date of the most recent update, thereby demonstrating the ongoing
commitment to maintaining these packages (Table \ref{tab:overview2}).

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2581}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1742}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0516}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1290}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1677}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2194}}@{}}
\caption{\label{tab:overview2}Summary of key characteristics of major \texttt{R} packages for image processing. The table details general applications, repository (Repo) sources (CRAN, Bioconductor (Bioc), and GitHub), primary package or library dependencies, and licensing information. The status column indicates the date of first publication (*) and the most recent update (°) for each package.}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Application
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Repo
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
based on
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
License
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Status
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Application
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Repo
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
based on
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
License
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Status
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{imager} \newline by \citet{Barthelme2019} & general purpose & \href{https://CRAN.R-project.org/package=imager}{CRAN} & Cimg & LGPL-3 & *2015-08-26 \newline °2024-04-26 \\
\textbf{magick} \newline by \citet{magick_ropensci} & general purpose & \href{https://CRAN.R-project.org/package=magick}{CRAN} & Image Magick & MIT & *2016-07-24 \newline °2024-02-18 \\
\textbf{EBImage} \newline by \citet{Pau2010} & general purpose & \href{https://bioconductor.org/packages/EBImage/}{Bioc} & - & LGPL & *2006-04-27 \newline °2024-05-01 \\
\textbf{biopixR} \newline by \citet{biopixR} & bioimages & \href{https://CRAN.R-project.org/package=biopixR}{CRAN} & imager \& magick & LGPL \newline (\(\geq\) 3) & *2024-03-25 \newline °2024-11-11 \\
\textbf{pliman} \newline by \citet{Olivoto2022} & plant images & \href{https://CRAN.R-project.org/package=pliman}{CRAN} & EBImage & GPL \newline (\(\geq\) 3) & *2021-05-15 \newline °2023-10-14 \\
\textbf{mxnorm} \newline by \citet{Harris2022} & multiplex images & \href{https://CRAN.R-project.org/package=mxnorm}{CRAN} & - & MIT & *2022-02-22 \newline °2023-05-01 \\
\textbf{DIMPLE} \newline by \citet{Masotti2023} & multiplex images & \href{https://github.com/nateosher/DIMPLE}{GitHub} & - & MIT & *2023-09-07 \\
\textbf{cytomapper} \newline by \citet{Eling2020} & multiplex images & \href{https://bioconductor.org/packages/cytomapper/}{Bioc} & EBImage & GPL \newline (\(\geq\) 2) & *2020-10-28 \newline °2024-05-01 \\
\textbf{SPIAT} \newline by \citet{Yang2020} & spatial data & \href{https://bioconductor.org/packages/SPIAT/}{Bioc} & Spatial Experiment & Artistic-2.0 & *2022-11-02 \newline °2024-05-01 \\
\textbf{spatialTIME} \newline by \citet{Creed2021} & spatial data & \href{https://CRAN.R-project.org/package=spatialTIME}{CRAN} & - & MIT & *2021-05-14 \newline °2024-03-11 \\
\textbf{celltrackR} \newline by \citet{Wortel2021} & motion analysis & \href{https://CRAN.R-project.org/package=celltrackR}{CRAN} & - & GPL-2 & *2020-03-31 \newline °2024-03-26 \\
\textbf{FIELDimageR} \newline by \citet{Matias2020} & agricultural field trails & \href{https://github.com/OpenDroneMap/FIELDimageR}{GitHub} & EBImage & GPL-3 & *2019-11-01 \newline °2024-05-03 \\
\textbf{fslr} \newline by \citet{Muschelli2015} & MRI of the brain & \href{https://CRAN.R-project.org/package=fslr}{CRAN} & FMRIB library & GPL-3 & *2014-06-13 \newline °2022-08-25 \\
\textbf{colocr} \newline by \citet{Ahmed2019} & fluorescence microscopy & \href{https://CRAN.R-project.org/package=colocr}{CRAN} & imager \& magick & GPL-3 & *2019-05-31 \newline °2020-05-08 \\
\textbf{imageseg} \newline by \citet{Niedballa2022} & image segmentation & \href{https://CRAN.R-project.org/package=imageseg}{CRAN} & magick & MIT & *2021-12-09 \newline °2022-05-29 \\
\textbf{SimpleITK} \newline by \citet{Beare2018} & general purpose & \href{https://github.com/SimpleITK/SimpleITKRInstaller}{GitHub} & Simple ITK & Apache 2.0 & *2015-11-16 \newline °2020-09-17 \\
\textbf{pixelclasser} \newline by \citet{Real2024} & image segmentation & \href{https://CRAN.R-project.org/package=pixelclasser}{CRAN} & jpeg \& tiff & GPL-3 & *2021-10-21 \newline °2023-10-18 \\
\textbf{OpenImageR} & general purpose & \href{https://CRAN.R-project.org/package=OpenImageR}{CRAN} & Rcpp & GPL-3 & *2016-07-09 \newline °2023-07-08 \\
\textbf{RniftyReg} & image registration & \href{https://CRAN.R-project.org/package=RNiftyReg}{CRAN} & Rcpp \& Rnifti & GPL-2 & *2010-09-06 \newline °2023-07-18 \\
\end{longtable}

The packages outlined in Table \ref{tab:overview2} are examined in terms of
their individual dependencies. A minimal number of dependencies is essential for
ensuring long-term stability and functionality. The packages are organized
according to their dependencies and imports, which were extracted from the
\texttt{DESCRIPTION} files to facilitate the identification of similarities between the
packages. The relationships between the packages are illustrated in the form of
a dendrogram (Figure \ref{fig:dendro}).



\begin{figure}[H]

{\centering \includegraphics[width=0.79\linewidth]{RJ-2025-030_files/figure-latex/dendro-1} 

}

\caption{\textbf{Dendrogram of Hierarchically Clustered Package Dependencies}: The dendrogram depicts the outcomes of a hierarchical clustering of various image analysis packages, based on their named dependencies and imports, as extracted from their respective \texttt{DESCRIPTION} files. Each branch represents a distinct package, and the proximity between branches reflects the degree of similarity in their dependencies and imports. The required distance matrix was calculated using the binary method, also known as Jaccard distance. To perform the hierarchical clustering, the complete linkage clustering method was employed \citep{R_Core_Team}.}\label{fig:dendro}
\end{figure}

\section{Conclusion}\label{conclusion}

The Tables \ref{tab:overview1} and \ref{tab:overview2} highlight an array of \texttt{R}
packages employed within bioimage informatics. These tools cater to diverse
applications such as adaptive smoothing, vegetation phenology analysis,
microbial culture imaging, cancer imaging, mass spectrometry imaging, shape
analysis, spectral and spatial analysis, magnetic resonance image processing,
calcium imaging, galaxy image analysis, neuroimaging, geometric morphometric
shape analysis, medical image processing, edge detection, body and face
recognition, jump regression, denoising, and deblurring.

Many of these packages rely on common image processing libraries such as
`ImageMagick' and `CImg' or specialized libraries like `RNifti' for neuroimaging
data and OpenCV for computer vision tasks. Some notable examples include
\texttt{adimpro}, \texttt{gitter}, \texttt{SAFARI}, \texttt{pavo}, \texttt{rental}, \texttt{scalpel}, \texttt{ProFit}, and \texttt{fsbrain}.

The majority of these packages are hosted on CRAN, which serves as the primary
repository for \texttt{R} packages. Notably, one package, rental, is hosted on GitLab,
indicating that some packages may also be developed and distributed through
alternative platforms. \texttt{R} is an open-source, free, and cross-platform
programming language that extends these values to its packages
\citep{R_Core_Team}. The CRAN Repository Policy states that package authors
``should make all reasonable efforts to provide cross-platform portable code,''
typically requiring packages to run on at least two major \texttt{R}
platforms.\footnote{\url{https://cran.r-project.org/web/packages/policies.html}, accessed 06/10/2024} Similarly,
the standard tests employed by Bioconductor encompass evaluations on all major
platforms, including Linux, macOS, and
Windows.\footnote{\url{https://contributions.bioconductor.org/bioconductor-package-submissions.html}, accessed 06/10/2024}
Thus, it can be concluded that the majority of packages in these repositories
are compatible across multiple platforms.

The most commonly used license in this domain is the GNU General Public License
(GPL), particularly versions 2 and 3. Other licenses employed include the Lesser
GNU General Public License (LGPL), MIT, Apache License 2.0, and others. The
prevalence of open-source licenses reflects the collaborative nature of \texttt{R}
package development. It's essential to ensure compatibility when combining code
from different packages with varying licenses; otherwise, legal considerations
might arise.

As previously outlined, the most fundamental image processing packages in \texttt{R} are
\texttt{imager}, \texttt{magick}, \texttt{EBImage}, \texttt{OpenImageR}, and \texttt{SimpleITK}. Primarily,
\texttt{imager}, \texttt{magick}, and \texttt{EBImage} form the foundation for the majority of the
specialized packages reviewed. These packages support various formats, with JPEG
and PNG being the most common and supported by all five packages. BMP and TIFF
are also widely supported, while PDF and SVG formats are exclusively supported
by \texttt{magick}.

\begin{longtable}[]{@{}lccccc@{}}
\caption{\label{tab:unnamed-chunk-75}Supported File Formats by Main Image Processing Packages}\tabularnewline
\toprule\noalign{}
& \texttt{imager} & \texttt{magick} & \texttt{EBImage} & \texttt{OpenImageR} & \texttt{SimpleITK} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
& \texttt{imager} & \texttt{magick} & \texttt{EBImage} & \texttt{OpenImageR} & \texttt{SimpleITK} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
JPEG & + & + & + & + & + \\
PNG & + & + & + & + & + \\
BMP & + & + & - & - & + \\
TIFF & - & + & + & + & + \\
PDF & - & + & - & - & - \\
SVG & - & + & - & - & - \\
\end{longtable}

The ongoing development of new code by the \texttt{R} community
significantly enhances the capabilities of image analysis, fostering both growth
and adaptability within the community. This ensures that \texttt{R} remains
well-equipped to address emerging challenges effectively. The result is a
diverse range of image processing packages, including versatile general-purpose
tools and specialized pipelines designed for intricate analyses of biological
images. This extensive array of tools in \texttt{R} not only demonstrates the versatility
and applicability of these packages across different scientific disciplines but
also solidifies \texttt{R}'s position as an invaluable resource for researchers
interested in leveraging image analysis to uncover novel insights. This review
provides a concise overview of the current landscape of image processing
packages available in \texttt{R}, emphasizing the pivotal role these tools play in
advancing scientific research and discovery. The comprehensive toolkit, \texttt{R},
empowers researchers to drive forward innovations and enrich the scientific
community. Finally, it is noteworthy that 92\% of the 38 discovered packages are
active in their respective repositories and thus considered up to date.
Furthermore, 66\% of these packages have been actively maintained with updates
in the past 1.5 years. Among the identified packages, 14 provide users with GUIs
or interactive functions. These packages include: \texttt{FIELDimageR}, \texttt{cytomapper},
\texttt{colocr}, \texttt{biopixR}, \texttt{EBImage}, \texttt{magick}, \texttt{imager}, \texttt{pavo}, \texttt{pliman},
\texttt{imagefluency}, \texttt{geomorph}, \texttt{fsbrain}, \texttt{scalpel}, and \texttt{adimpro}. The majority of
the 38 packages identified during the research can be considered autonomous,
offering all the necessary features for extensive image data analysis,
including image import, processing, and visualization. However, some packages
related to multiplex imaging necessitate preprocessing, rendering them unable to
provide a complete analysis within the \texttt{R} environment.

All mentioned packages are open source and available either on CRAN,
Bioconductor or GitHub.

Predicting the future is challenging, yet here we provide some opinions on
trends in bioimage informatics, which ultimately will also be seen in \texttt{R}.
Publications and conferences in the fields of image processing and computer
vision show that advances are driven by artificial intelligence (AI), deep
learning (particularly Convolutional Neural Networks (CNNs), Large Language
Models (LLMs), and Vision Transformer models (VTs)), and data visualization
\citep{ye_generative_2024, belcher_demystifying_2023, rabbani_review_2021, hameed_content-based_2021, van_der_velden_explainable_2022}.
One example of deep learning is \texttt{imageseg}, which is using a CNN (U-Net and U-Net++
architectures) for general purpose image segmentation \citep{niedballa_imageseg_2022}. Another
development is the deeper integration of \texttt{R} with advanced deep learning
frameworks, which will enable users to build and deploy models, with
applications like image classification, segmentation, and object detection. An example of
such integration is \texttt{ellmer}, which makes various LLMs accessible from \texttt{R} for
output streaming, tool calling, and structured data extraction.

The question arises: Is AI merely a buzzword, or is it here to stay? Given that
AI is grounded in science and we already see applications in \texttt{R},
the latter is more probable. Consequently, \texttt{R}
bioimage packages will be developed that combine image data with other
multimodal data types, such as text and sensor data. Generative AI and advanced
visualization techniques are also one topic due to the availability of
generative models like diffusion models and Generative Adversarial Networks
(GANs). These technologies open new possibilities for image augmentation and
enhanced data visualization. It is important that such technologies stick to
one of \texttt{R}'s strengths, which is explainability, in particular focusing on transparent,
understandable, and explainable AI (xAI).

\pagebreak

\subsection{Session Info}\label{session-info}

\begin{verbatim}
#> R version 4.5.1 (2025-06-13)
#> Platform: x86_64-pc-linux-gnu
#> Running under: Pop!_OS 24.04 LTS
#> 
#> Matrix products: default
#> BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.12.0 
#> LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.12.0  LAPACK version 3.12.0
#> 
#> locale:
#>  [1] LC_CTYPE=en_AU.UTF-8       LC_NUMERIC=C              
#>  [3] LC_TIME=en_AU.UTF-8        LC_COLLATE=en_AU.UTF-8    
#>  [5] LC_MONETARY=en_AU.UTF-8    LC_MESSAGES=en_AU.UTF-8   
#>  [7] LC_PAPER=en_AU.UTF-8       LC_NAME=C                 
#>  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
#> [11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C       
#> 
#> time zone: Australia/Melbourne
#> tzcode source: system (glibc)
#> 
#> attached base packages:
#> [1] stats4    stats     graphics  grDevices utils     datasets  methods  
#> [8] base     
#> 
#> other attached packages:
#>  [1] RNiftyReg_2.8.4             OpenImageR_1.3.0           
#>  [3] pixelclasser_1.1.1          SimpleITK_2.5.2            
#>  [5] imageseg_0.5.0              colocr_0.1.1               
#>  [7] fslr_2.27.0                 neurobase_1.34.0           
#>  [9] oro.nifti_0.11.4            celltrackR_1.2.2           
#> [11] spatialTIME_1.3.4-5         SPIAT_1.9.1                
#> [13] SpatialExperiment_1.18.1    cytomapper_1.20.0          
#> [15] SingleCellExperiment_1.30.1 SummarizedExperiment_1.38.1
#> [17] Biobase_2.68.0              GenomicRanges_1.60.0       
#> [19] GenomeInfoDb_1.44.3         IRanges_2.42.0             
#> [21] S4Vectors_0.46.0            BiocGenerics_0.54.1        
#> [23] generics_0.1.4              MatrixGenerics_1.20.0      
#> [25] matrixStats_1.5.0           DIMPLE_1.0.0               
#> [27] mxnorm_1.1.0                kableExtra_1.4.0           
#> [29] data.table_1.17.8           image2data_1.0.1           
#> [31] mapview_2.11.4              leafsync_0.1.0             
#> [33] sf_1.0-21                   terra_1.8-70               
#> [35] FIELDimageR.Extra_0.0.5     nlme_3.1-168               
#> [37] FIELDimageR_0.6.2           pliman_3.1.1               
#> [39] EBImage_4.50.0              biopixR_1.2.0              
#> [41] magick_2.9.0                imager_1.0.5               
#> [43] magrittr_2.0.4              knitr_1.50                 
#> [45] cluster_2.1.8.1            
#> 
#> loaded via a namespace (and not attached):
#>   [1] R.methodsS3_1.8.2       dichromat_2.0-0.1       gld_2.6.8              
#>   [4] tiff_0.1-12             nnet_7.3-20             goftest_1.2-3          
#>   [7] HDF5Array_1.36.0        vctrs_0.6.5             spatstat.random_3.4-2  
#>  [10] digest_0.6.37           png_0.1-8               proxy_0.4-27           
#>  [13] Exact_3.3               tfruns_1.5.4            deldir_2.0-4           
#>  [16] parallelly_1.45.1       MASS_7.3-65             reshape2_1.4.4         
#>  [19] httpuv_1.6.16           foreach_1.5.2           withr_3.0.2            
#>  [22] xfun_0.53               survival_3.8-3          ggbeeswarm_0.7.2       
#>  [25] fuzzyjoin_0.1.6.1       systemfonts_1.3.1       lwgeom_0.2-14          
#>  [28] R.oo_1.27.1             RNifti_1.8.0            promises_1.3.3         
#>  [31] httr_1.4.7              globals_0.18.0          rhdf5filters_1.20.0    
#>  [34] rhdf5_2.52.1            rstudioapi_0.17.1       UCSC.utils_1.4.0       
#>  [37] units_1.0-0             miniUI_0.1.2            base64enc_0.1-3        
#>  [40] stars_0.6-8             fields_17.1             leafpop_0.1.0          
#>  [43] h5mread_1.0.1           leafem_0.2.5            polyclip_1.10-7        
#>  [46] GenomeInfoDbData_1.2.14 SparseArray_1.8.1       fftwtools_0.9-11       
#>  [49] xtable_1.8-4            stringr_1.5.2           evaluate_1.0.5         
#>  [52] S4Arrays_1.8.1          tmaptools_3.3           hms_1.1.4              
#>  [55] bookdown_0.45           reticulate_1.43.0       readxl_1.4.5           
#>  [58] spatstat.data_3.1-9     shinyWidgets_0.9.0      readr_2.1.5            
#>  [61] later_1.4.4             viridis_0.6.5           lattice_0.22-7         
#>  [64] spatstat.geom_3.6-0     future.apply_1.20.0     XML_3.99-0.19          
#>  [67] class_7.3-23            svgPanZoom_0.3.4        pillar_1.11.1          
#>  [70] iterators_1.0.14        compiler_4.5.1          stringi_1.8.7          
#>  [73] gower_1.0.2             DescTools_0.99.60       tensor_1.5.1           
#>  [76] minqa_1.2.8             lubridate_1.9.4         plyr_1.8.9             
#>  [79] crayon_1.5.3            abind_1.4-8             locfit_1.5-9.12        
#>  [82] haven_2.5.5             sp_2.2-0                rootSolve_1.8.2.4      
#>  [85] dplyr_1.1.4             whisker_0.4.1           codetools_0.2-20       
#>  [88] textshaping_1.0.4       recipes_1.3.1           crosstalk_1.2.2        
#>  [91] bslib_0.9.0             leaflet_2.2.3           e1071_1.7-16           
#>  [94] lmom_3.2                satellite_1.0.6         mime_0.13              
#>  [97] splines_4.5.1           Rcpp_1.1.0              cellranger_1.1.0       
#> [100] brew_1.0-10             lme4_1.1-37             fs_1.6.6               
#> [103] listenv_0.9.1           nnls_1.6                Rdpack_2.6.4           
#> [106] expm_1.0-0              tibble_3.3.0            Matrix_1.7-4           
#> [109] tzdb_0.5.0              svglite_2.2.1           pkgconfig_2.0.3        
#> [112] tools_4.5.1             cachem_1.1.0            rbibutils_2.3          
#> [115] viridisLite_0.4.2       DBI_1.2.3               fastmap_1.2.0          
#> [118] rmarkdown_2.30          scales_1.4.0            grid_4.5.1             
#> [121] readbitmap_0.1.5        shinydashboard_0.7.3    sass_0.4.10            
#> [124] BiocManager_1.30.26     dotCall64_1.2           rpart_4.1.24           
#> [127] yesno_0.1.3             farver_2.1.2            reformulas_0.4.1       
#> [130] rjtools_1.0.21          yaml_2.3.10             bmp_0.3.1              
#> [133] cli_3.6.5               purrr_1.1.0             lifecycle_1.0.4        
#> [136] caret_7.0-1             mvtnorm_1.3-3           lava_1.8.1             
#> [139] BiocParallel_1.42.2     timechange_0.3.0        gtable_0.3.6           
#> [142] rjson_0.2.23            parallel_4.5.1          pROC_1.19.0.1          
#> [145] jsonlite_2.0.0          bitops_1.0-9            ggplot2_4.0.0.9000     
#> [148] spatstat.utils_3.2-0    jquerylib_0.1.4         zeallot_0.2.0          
#> [151] hunspell_3.0.6          spatstat.univar_3.1-4   R.utils_2.13.0         
#> [154] timeDate_4041.110       shiny_1.11.1            htmltools_0.5.8.1      
#> [157] tinytex_0.57            glue_1.8.0              tcltk_4.5.1            
#> [160] spam_2.11-1             XVector_0.48.0          RCurl_1.98-1.17        
#> [163] classInt_0.4-11         mapedit_0.7.0           jpeg_0.1-11            
#> [166] gridExtra_2.3           keras_2.16.0            boot_1.3-32            
#> [169] igraph_2.1.4            R6_2.6.1                tidyr_1.3.1            
#> [172] forcats_1.0.1           Rhdf5lib_1.30.0         ipred_0.9-15           
#> [175] nloptr_2.2.1            DelayedArray_0.34.1     tidyselect_1.2.1       
#> [178] vipor_0.4.7             maps_3.4.3              xml2_1.4.0             
#> [181] raster_3.6-32           future_1.67.0           ModelMetrics_1.2.2.2   
#> [184] KernSmooth_2.23-26      S7_0.2.0                exactextractr_0.10.0   
#> [187] htmlwidgets_1.6.4       RColorBrewer_1.1-3      rlang_1.1.6            
#> [190] spatstat.sparse_3.1-0   tensorflow_2.20.0       spatstat.explore_3.5-3 
#> [193] uuid_1.2-1              hardhat_1.4.2           beeswarm_0.4.0         
#> [196] prodlim_2025.04.28
\end{verbatim}

\section{Funding}\label{funding}

This review was partially funded by the project Rubin: NeuroMiR (03RU1U051A,
federal ministry of education and research, Germany).

\section{Conflict of interest}\label{conflict-of-interest}

The authors declare no conflict of interest.

\section{Acknowledgements}\label{acknowledgements}

We would like to express our gratitude to Dr.~Coline Kieffer for providing the
microbead images used in this review. We thank Robert M Flight at codeberg.org
for reading and improving the manuscript.

\bibliography{RImageReview.bib}

\address{%
Tim Brauckhoff\\
Brandenburg University of Technology Cottbus - Senftenberg\\%
Institute of Biotechnology\\ Senftenberg, Germany\\ Eberhard Karls Universität Tübingen\\ Department of Computer Science\\ Tübingen, Germany\\
%
%
\textit{ORCiD: \href{https://orcid.org/0009-0002-0142-7017}{0009-0002-0142-7017}}\\%
\href{mailto:brauctile@disroot.org}{\nolinkurl{brauctile@disroot.org}}%
}

\address{%
Julius Rublack\\
University of Münster\\%
Faculty of Biology\\ Münster, Germany\\
%
%
%
\href{mailto:juliusrublack@web.de}{\nolinkurl{juliusrublack@web.de}}%
}

\address{%
Stefan Rödiger (corresponding author)\\
Brandenburg University of Technology Cottbus - Senftenberg\\%
Institute of Biotechnology\\ Senftenberg, Germany\\
%
%
\textit{ORCiD: \href{https://orcid.org/0000-0002-1441-6512}{0000-0002-1441-6512}}\\%
\href{mailto:stefan.roediger@b-tu.de}{\nolinkurl{stefan.roediger@b-tu.de}}%
}
