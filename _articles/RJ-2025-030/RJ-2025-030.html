<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { color: #00769e; background-color: #f1f3f5; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #00769e; } /* Normal */
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #657422; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #00769e; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #00769e; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #00769e; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #5e5e5e; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

<style>
  div.csl-bib-body { }
  div.csl-entry {
    clear: both;
      margin-bottom: 0em;
    }
  .hanging div.csl-entry {
    margin-left:2em;
    text-indent:-2em;
  }
  div.csl-left-margin {
    min-width:2em;
    float:left;
  }
  div.csl-right-inline {
    margin-left:2em;
    padding-left:1em;
  }
  div.csl-indent {
    margin-left: 2em;
  }
</style>

  <!--radix_placeholder_meta_tags-->
  <title>Exploring Image Analysis in R: Applications and Advancements</title>

  <meta property="description" itemprop="description" content="This review offers an overview of image processing packages in R, covering applications such as multiplex imaging, cell tracking, and general-purpose tools. We found 38 R packages for image analysis, with adimpro and EBImage being the oldest, published in 2006, and biopixR among the newest, released in 2024. Of these packages, over 90 % are still active, with two-thirds receiving updates within the last 1.5 years. The pivotal role of bioimage informatics in life sciences is emphasized in this review, along with the ongoing advancements of R&#39;s functionality through novel code releases. It focuses on complete analysis pipelines for extracting valuable information from biological images and includes real-world examples. Demonstrating how researchers can use R to tackle new scientific challenges in image analysis, the review provides a comprehensive understanding of R&#39;s utility in this field."/>

  <link rel="license" href="https://creativecommons.org/licenses/by/4.0/"/>

  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2025-10-22"/>
  <meta property="article:created" itemprop="dateCreated" content="2025-10-22"/>
  <meta name="article:author" content="Tim Brauckhoff"/>
  <meta name="article:author" content="Julius Rublack"/>
  <meta name="article:author" content="Stefan Rödiger"/>

  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Exploring Image Analysis in R: Applications and Advancements"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="This review offers an overview of image processing packages in R, covering applications such as multiplex imaging, cell tracking, and general-purpose tools. We found 38 R packages for image analysis, with adimpro and EBImage being the oldest, published in 2006, and biopixR among the newest, released in 2024. Of these packages, over 90 % are still active, with two-thirds receiving updates within the last 1.5 years. The pivotal role of bioimage informatics in life sciences is emphasized in this review, along with the ongoing advancements of R&#39;s functionality through novel code releases. It focuses on complete analysis pipelines for extracting valuable information from biological images and includes real-world examples. Demonstrating how researchers can use R to tackle new scientific challenges in image analysis, the review provides a comprehensive understanding of R&#39;s utility in this field."/>
  <meta property="og:locale" content="en_US"/>

  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Exploring Image Analysis in R: Applications and Advancements"/>
  <meta property="twitter:description" content="This review offers an overview of image processing packages in R, covering applications such as multiplex imaging, cell tracking, and general-purpose tools. We found 38 R packages for image analysis, with adimpro and EBImage being the oldest, published in 2006, and biopixR among the newest, released in 2024. Of these packages, over 90 % are still active, with two-thirds receiving updates within the last 1.5 years. The pivotal role of bioimage informatics in life sciences is emphasized in this review, along with the ongoing advancements of R&#39;s functionality through novel code releases. It focuses on complete analysis pipelines for extracting valuable information from biological images and includes real-world examples. Demonstrating how researchers can use R to tackle new scientific challenges in image analysis, the review provides a comprehensive understanding of R&#39;s utility in this field."/>

  <!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
  <meta name="citation_title" content="Exploring Image Analysis in R: Applications and Advancements"/>
  <meta name="citation_fulltext_html_url" content="https://doi.org/10.32614/RJ-2025-030"/>
  <meta name="citation_pdf_url" content="RJ-2025-030.pdf"/>
  <meta name="citation_volume" content="17"/>
  <meta name="citation_issue" content="3"/>
  <meta name="citation_doi" content="10.32614/RJ-2025-030"/>
  <meta name="citation_journal_title" content="The R Journal"/>
  <meta name="citation_issn" content="2073-4859"/>
  <meta name="citation_firstpage" content="212"/>
  <meta name="citation_lastpage" content="260"/>
  <meta name="citation_fulltext_world_readable" content=""/>
  <meta name="citation_online_date" content="2025/10/22"/>
  <meta name="citation_publication_date" content="2025/10/22"/>
  <meta name="citation_author" content="Tim Brauckhoff"/>
  <meta name="citation_author_institution" content="Brandenburg University of Technology Cottbus - Senftenberg"/>
  <meta name="citation_author" content="Julius Rublack"/>
  <meta name="citation_author_institution" content="University of Münster"/>
  <meta name="citation_author" content="Stefan Rödiger"/>
  <meta name="citation_author_institution" content="Brandenburg University of Technology Cottbus - Senftenberg"/>
  <!--/radix_placeholder_meta_tags-->
  
  <!--radix_placeholder_rmarkdown_metadata-->

  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","date","description","draft","author","type","output","always_allow_html","bibliography","header-includes","date_received","volume","issue","slug","journal","pdf_url","citation_url","doi","creative_commons","packages","CTV","csl"]}},"value":[{"type":"character","attributes":{},"value":["Exploring Image Analysis in R: Applications and Advancements"]},{"type":"character","attributes":{},"value":["2025-10-22"]},{"type":"character","attributes":{},"value":["This review offers an overview of image processing packages in R, covering applications such as multiplex imaging, cell tracking, and general-purpose tools. We found 38 R packages for image analysis, with adimpro and EBImage being the oldest, published in 2006, and biopixR among the newest, released in 2024. Of these packages, over 90 % are still active, with two-thirds receiving updates within the last 1.5 years. The pivotal role of bioimage informatics in life sciences is emphasized in this review, along with the ongoing advancements of R's functionality through novel code releases. It focuses on complete analysis pipelines for extracting valuable information from biological images and includes real-world examples. Demonstrating how researchers can use R to tackle new scientific challenges in image analysis, the review provides a comprehensive understanding of R's utility in this field."]},{"type":"logical","attributes":{},"value":[false]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation","address","orcid_id","email"]}},"value":[{"type":"character","attributes":{},"value":["Tim Brauckhoff"]},{"type":"character","attributes":{},"value":["Brandenburg University of Technology Cottbus - Senftenberg"]},{"type":"character","attributes":{},"value":["Institute of Biotechnology","Senftenberg, Germany","Eberhard Karls Universität Tübingen","Department of Computer Science","Tübingen, Germany"]},{"type":"character","attributes":{},"value":["0009-0002-0142-7017"]},{"type":"character","attributes":{},"value":["brauctile@disroot.org"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation","address","email"]}},"value":[{"type":"character","attributes":{},"value":["Julius Rublack"]},{"type":"character","attributes":{},"value":["University of Münster"]},{"type":"character","attributes":{},"value":["Faculty of Biology","Münster, Germany"]},{"type":"character","attributes":{},"value":["juliusrublack@web.de"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation","address","email","orcid_id"]}},"value":[{"type":"character","attributes":{},"value":["Stefan Rödiger"]},{"type":"character","attributes":{},"value":["Brandenburg University of Technology Cottbus - Senftenberg"]},{"type":"character","attributes":{},"value":["Institute of Biotechnology","Senftenberg, Germany"]},{"type":"character","attributes":{},"value":["stefan.roediger@b-tu.de"]},{"type":"character","attributes":{},"value":["0000-0002-1441-6512"]}]}]},{"type":"character","attributes":{},"value":["package"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["RImageReview.bib"]},{"type":"character","attributes":{},"value":["\\usepackage{float}"]},{"type":"character","attributes":{},"value":["2025-05-30"]},{"type":"integer","attributes":{},"value":[17]},{"type":"integer","attributes":{},"value":[3]},{"type":"character","attributes":{},"value":["RJ-2025-030"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","issn","firstpage","lastpage"]}},"value":[{"type":"character","attributes":{},"value":["The R Journal"]},{"type":"character","attributes":{},"value":["2073-4859"]},{"type":"integer","attributes":{},"value":[212]},{"type":"integer","attributes":{},"value":[260]}]},{"type":"character","attributes":{},"value":["RJ-2025-030.pdf"]},{"type":"character","attributes":{},"value":["https://doi.org/10.32614/RJ-2025-030"]},{"type":"character","attributes":{},"value":["10.32614/RJ-2025-030"]},{"type":"character","attributes":{},"value":["CC BY"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["cran","bioc"]}},"value":[{"type":"list","attributes":{},"value":[]},{"type":"list","attributes":{},"value":[]}]},{"type":"list","attributes":{},"value":[]},{"type":"character","attributes":{},"value":["/home/mitchell/R/x86_64-pc-linux-gnu-library/4.5/rjtools/rjournal.csl"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["data/Dependency.csv","data/honorable_mention","data/honorable_mentions_html.csv","data/honorable_mentions_pdf.csv","data/honorable_mentions.csv","data/package_matrix (copy).ods","data/package_matrix.ods","data/package_matrixIII.csv","data/package_matrixIII.ods","data/package_summary_html.csv","data/package_summary_pdf.csv","data/supported_formats.csv","data/to_analyze_in_countfitteR (copy).csv","data/to_analyze_in_countfitteR.csv","data/to_analyze.csv","figures/background.jpg","figures/beads.jpg","figures/beads.png","figures/beads2.jpg","figures/beads4.png","figures/beads5.png","figures/colocr_gui.png","figures/count_distr.png","figures/digitize.png","figures/distr_barplot.png","figures/distr_barplot.svg","figures/EBImage1.png","figures/EBImage2.png","figures/EBImage3.png","figures/FIELDimageR_shiny.png","figures/FIELDimageR1_1.png","figures/FIELDimageR1.png","figures/FIELDimageR2_1.png","figures/FIELDimageR2.png","figures/fig_DSB.png","figures/flax_grains.jpg","figures/foreground.jpg","figures/shape_test1.png","figures/shape_test2.png","figures/shapefeatures.png","figures/shapefeatures1.png","figures/shapefeatures2.png","figures/shapefeatures3.png","figures/test3.png","figures/tim_242602_c_s3c1+2+3m3.tif","figures/tim_242602_c_s3c1+2+3m4.tif","figures/tim_242602_c_s6c1+2+3m3.tif","motivation-letter/motivation-letter.md","RImageReview.bib","RJ-2025-030_files/anchor-4.2.2/anchor.min.js","RJ-2025-030_files/bowser-1.9.3/bowser.min.js","RJ-2025-030_files/chromajs-2.1.0/chroma.min.js","RJ-2025-030_files/clipboard-0.0.1/setClipboardText.js","RJ-2025-030_files/distill-2.2.21/template.v2.js","RJ-2025-030_files/EX_P_Total-CSS-0.0.1/EX_P_Total_home-button.css","RJ-2025-030_files/figure-html5/dendro-1.png","RJ-2025-030_files/figure-html5/digitize-1.png","RJ-2025-030_files/figure-html5/img2data-1.png","RJ-2025-030_files/figure-html5/img2data-2.png","RJ-2025-030_files/figure-html5/pliman1-1.png","RJ-2025-030_files/figure-html5/pliman1-2.png","RJ-2025-030_files/figure-html5/pliman2-1.png","RJ-2025-030_files/file2846a60d314d9-0.0.1/file2846a60d314d9_layer.tif","RJ-2025-030_files/file371c65bf9dc-0.0.1/file371c65bf9dc_layer.tif","RJ-2025-030_files/file3d20712d03a07-0.0.1/file3d20712d03a07_layer.tif","RJ-2025-030_files/file41c9674e8001f-0.0.1/file41c9674e8001f_layer.tif","RJ-2025-030_files/GeoRaster-0.0.1/geoblaze.js","RJ-2025-030_files/GeoRaster-0.0.1/georaster-binding.js","RJ-2025-030_files/GeoRaster-0.0.1/georaster-layer-for-leaflet.min.js","RJ-2025-030_files/GeoRaster-0.0.1/georaster.min.js","RJ-2025-030_files/GeoRaster-0.0.1/georasterUtils.js","RJ-2025-030_files/GeoRaster-0.0.1/mathjs.min.js","RJ-2025-030_files/GeoRaster-0.0.1/proj4-src.js","RJ-2025-030_files/header-attrs-2.30/header-attrs.js","RJ-2025-030_files/HomeButton-0.0.1/easy-button-src.min.js","RJ-2025-030_files/HomeButton-0.0.1/glyphicons-21-home.png","RJ-2025-030_files/HomeButton-0.0.1/home-button.js","RJ-2025-030_files/HomeButton-0.0.1/LICENSE","RJ-2025-030_files/htmltools-fill-0.5.8.1/fill.css","RJ-2025-030_files/htmlwidgets-1.6.4/htmlwidgets.js","RJ-2025-030_files/jquery-3.6.0/jquery-3.6.0.js","RJ-2025-030_files/jquery-3.6.0/jquery-3.6.0.min.js","RJ-2025-030_files/jquery-3.6.0/jquery-3.6.0.min.map","RJ-2025-030_files/leaflet-1.3.1/images/layers-2x.png","RJ-2025-030_files/leaflet-1.3.1/images/layers.png","RJ-2025-030_files/leaflet-1.3.1/images/marker-icon-2x.png","RJ-2025-030_files/leaflet-1.3.1/images/marker-icon.png","RJ-2025-030_files/leaflet-1.3.1/images/marker-shadow.png","RJ-2025-030_files/leaflet-1.3.1/leaflet.css","RJ-2025-030_files/leaflet-1.3.1/leaflet.js","RJ-2025-030_files/leaflet-binding-2.2.3/leaflet.js","RJ-2025-030_files/leaflet-providers-2.0.0/leaflet-providers_2.0.0.js","RJ-2025-030_files/leaflet-providers-plugin-2.2.3/leaflet-providers-plugin.js","RJ-2025-030_files/Leaflet.Sync-0.0.5/bower.json","RJ-2025-030_files/Leaflet.Sync-0.0.5/L.Map.Sync.js","RJ-2025-030_files/Leaflet.Sync-0.0.5/LICENSE","RJ-2025-030_files/leafletfix-1.0.0/leafletfix.css","RJ-2025-030_files/mapviewCSS-0.0.1/mapview-popup.css","RJ-2025-030_files/mapviewCSS-0.0.1/mapview.css","RJ-2025-030_files/popper-2.6.0/popper.min.js","RJ-2025-030_files/proj4-2.6.2/proj4.min.js","RJ-2025-030_files/Proj4Leaflet-1.0.1/proj4leaflet.js","RJ-2025-030_files/rstudio_leaflet-1.3.1/images/1px.png","RJ-2025-030_files/rstudio_leaflet-1.3.1/rstudio_leaflet.css","RJ-2025-030_files/tippy-6.2.7/tippy-bundle.umd.min.js","RJ-2025-030_files/tippy-6.2.7/tippy-light-border.css","RJ-2025-030_files/tippy-6.2.7/tippy.css","RJ-2025-030_files/tippy-6.2.7/tippy.umd.min.js","RJ-2025-030_files/webcomponents-2.0.0/webcomponents.js","RJ-2025-030.fdb_latexmk","RJ-2025-030.fls","RJ-2025-030.log","RJ-2025-030.pdf","RJ-2025-030.tex","RJ-2025-030.zip","RJournal.sty","RJwrapper.bbl","RJwrapper.blg","RJwrapper.fdb_latexmk","RJwrapper.fls","RJwrapper.log","RJwrapper.out","RJwrapper.tex"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

  <style type="text/css">

  body {
    background-color: white;
  }

  .pandoc-table {
    width: 100%;
  }

  .pandoc-table>caption {
    margin-bottom: 10px;
  }

  .pandoc-table th:not([align]) {
    text-align: left;
  }

  .pagedtable-footer {
    font-size: 15px;
  }

  d-byline .byline {
    grid-template-columns: 2fr 2fr;
  }

  d-byline .byline h3 {
    margin-block-start: 1.5em;
  }

  d-byline .byline .authors-affiliations h3 {
    margin-block-start: 0.5em;
  }

  .authors-affiliations .orcid-id {
    width: 16px;
    height:16px;
    margin-left: 4px;
    margin-right: 4px;
    vertical-align: middle;
    padding-bottom: 2px;
  }

  d-title .dt-tags {
    margin-top: 1em;
    grid-column: text;
  }

  .dt-tags .dt-tag {
    text-decoration: none;
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0em 0.4em;
    margin-right: 0.5em;
    margin-bottom: 0.4em;
    font-size: 70%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  d-article table.gt_table td,
  d-article table.gt_table th {
    border-bottom: none;
    font-size: 100%;
  }

  .html-widget {
    margin-bottom: 2.0em;
  }

  .l-screen-inset {
    padding-right: 16px;
  }

  .l-screen .caption {
    margin-left: 10px;
  }

  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .shaded-content {
    background: white;
  }

  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }

  .hidden {
    display: none !important;
  }

  hr.section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    margin: 0px;
  }


  d-byline {
    border-top: none;
  }

  d-article {
    padding-top: 2.5rem;
    padding-bottom: 30px;
    border-top: none;
  }

  d-appendix {
    padding-top: 30px;
  }

  d-article>p>img {
    width: 100%;
  }

  d-article h2 {
    margin: 1rem 0 1.5rem 0;
  }

  d-article h3 {
    margin-top: 1.5rem;
  }

  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }

  /* Tweak code blocks */

  d-article div.sourceCode code,
  d-article pre code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: auto;
  }

  d-article div.sourceCode {
    background-color: white;
  }

  d-article div.sourceCode pre {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }

  d-article pre {
    font-size: 12px;
    color: black;
    background: none;
    margin-top: 0;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  d-article pre a {
    border-bottom: none;
  }

  d-article pre a:hover {
    border-bottom: none;
    text-decoration: underline;
  }

  d-article details {
    grid-column: text;
    margin-bottom: 0.8em;
  }

  @media(min-width: 768px) {

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: visible !important;
  }

  d-article div.sourceCode pre {
    padding-left: 18px;
    font-size: 14px;
  }

  /* tweak for Pandoc numbered line within distill */
  d-article pre.numberSource code > span {
      left: -2em;
  }

  d-article pre {
    font-size: 14px;
  }

  }

  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  /* CSS for d-contents */

  .d-contents {
    grid-column: text;
    color: rgba(0,0,0,0.8);
    font-size: 0.9em;
    padding-bottom: 1em;
    margin-bottom: 1em;
    padding-bottom: 0.5em;
    margin-bottom: 1em;
    padding-left: 0.25em;
    justify-self: start;
  }

  @media(min-width: 1000px) {
    .d-contents.d-contents-float {
      height: 0;
      grid-column-start: 1;
      grid-column-end: 4;
      justify-self: center;
      padding-right: 3em;
      padding-left: 2em;
    }
  }

  .d-contents nav h3 {
    font-size: 18px;
    margin-top: 0;
    margin-bottom: 1em;
  }

  .d-contents li {
    list-style-type: none
  }

  .d-contents nav > ul {
    padding-left: 0;
  }

  .d-contents ul {
    padding-left: 1em
  }

  .d-contents nav ul li {
    margin-top: 0.6em;
    margin-bottom: 0.2em;
  }

  .d-contents nav a {
    font-size: 13px;
    border-bottom: none;
    text-decoration: none
    color: rgba(0, 0, 0, 0.8);
  }

  .d-contents nav a:hover {
    text-decoration: underline solid rgba(0, 0, 0, 0.6)
  }

  .d-contents nav > ul > li > a {
    font-weight: 600;
  }

  .d-contents nav > ul > li > ul {
    font-weight: inherit;
  }

  .d-contents nav > ul > li > ul > li {
    margin-top: 0.2em;
  }


  .d-contents nav ul {
    margin-top: 0;
    margin-bottom: 0.25em;
  }

  .d-article-with-toc h2:nth-child(2) {
    margin-top: 0;
  }


  /* Figure */

  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }

  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }

  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }

  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }

  /* Citations */

  d-article .citation {
    color: inherit;
    cursor: inherit;
  }

  div.hanging-indent{
    margin-left: 1em; text-indent: -1em;
  }

  /* Citation hover box */

  .tippy-box[data-theme~=light-border] {
    background-color: rgba(250, 250, 250, 0.95);
  }

  .tippy-content > p {
    margin-bottom: 0;
    padding: 2px;
  }


  /* Tweak 1000px media break to show more text */

  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }

    .grid {
      grid-column-gap: 16px;
    }

    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }

  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }

    .grid {
      grid-column-gap: 32px;
    }
  }


  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */

  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  /* Include appendix styles here so they can be overridden */

  d-appendix {
    contain: layout style;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-top: 60px;
    margin-bottom: 0;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    color: rgba(0,0,0,0.5);
    padding-top: 60px;
    padding-bottom: 48px;
  }

  d-appendix h3 {
    grid-column: page-start / text-start;
    font-size: 15px;
    font-weight: 500;
    margin-top: 1em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.65);
  }

  d-appendix h3 + * {
    margin-top: 1em;
  }

  d-appendix ol {
    padding: 0 0 0 15px;
  }

  @media (min-width: 768px) {
    d-appendix ol {
      padding: 0 0 0 30px;
      margin-left: -30px;
    }
  }

  d-appendix li {
    margin-bottom: 1em;
  }

  d-appendix a {
    color: rgba(0, 0, 0, 0.6);
  }

  d-appendix > * {
    grid-column: text;
  }

  d-appendix > d-footnote-list,
  d-appendix > d-citation-list,
  d-appendix > distill-appendix {
    grid-column: screen;
  }

  /* Include footnote styles here so they can be overridden */

  d-footnote-list {
    contain: layout style;
  }

  d-footnote-list > * {
    grid-column: text;
  }

  d-footnote-list a.footnote-backlink {
    color: rgba(0,0,0,0.3);
    padding-left: 0.5em;
  }



  /* Anchor.js */

  .anchorjs-link {
    /*transition: all .25s linear; */
    text-decoration: none;
    border-bottom: none;
  }
  *:hover > .anchorjs-link {
    margin-left: -1.125em !important;
    text-decoration: none;
    border-bottom: none;
  }

  /* Social footer */

  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }

  .disqus-comments {
    margin-right: 30px;
  }

  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }

  #disqus_thread {
    margin-top: 30px;
  }

  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }

  .article-sharing a:hover {
    border-bottom: none;
  }

  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }

  .subscribe p {
    margin-bottom: 0.5em;
  }


  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }


  .sidebar-section.custom {
    font-size: 12px;
    line-height: 1.6em;
  }

  .custom p {
    margin-bottom: 0.5em;
  }

  /* Styles for listing layout (hide title) */
  .layout-listing d-title, .layout-listing .d-title {
    display: none;
  }

  /* Styles for posts lists (not auto-injected) */


  .posts-with-sidebar {
    padding-left: 45px;
    padding-right: 45px;
  }

  .posts-list .description h2,
  .posts-list .description p {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  }

  .posts-list .description h2 {
    font-weight: 700;
    border-bottom: none;
    padding-bottom: 0;
  }

  .posts-list h2.post-tag {
    border-bottom: 1px solid rgba(0, 0, 0, 0.2);
    padding-bottom: 12px;
  }
  .posts-list {
    margin-top: 60px;
    margin-bottom: 24px;
  }

  .posts-list .post-preview {
    text-decoration: none;
    overflow: hidden;
    display: block;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
    padding: 24px 0;
  }

  .post-preview-last {
    border-bottom: none !important;
  }

  .posts-list .posts-list-caption {
    grid-column: screen;
    font-weight: 400;
  }

  .posts-list .post-preview h2 {
    margin: 0 0 6px 0;
    line-height: 1.2em;
    font-style: normal;
    font-size: 24px;
  }

  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.4em;
    font-size: 16px;
  }

  .posts-list .post-preview .thumbnail {
    box-sizing: border-box;
    margin-bottom: 24px;
    position: relative;
    max-width: 500px;
  }
  .posts-list .post-preview img {
    width: 100%;
    display: block;
  }

  .posts-list .metadata {
    font-size: 12px;
    line-height: 1.4em;
    margin-bottom: 18px;
  }

  .posts-list .metadata > * {
    display: inline-block;
  }

  .posts-list .metadata .publishedDate {
    margin-right: 2em;
  }

  .posts-list .metadata .dt-authors {
    display: block;
    margin-top: 0.3em;
    margin-right: 2em;
  }

  .posts-list .dt-tags {
    display: block;
    line-height: 1em;
  }

  .posts-list .dt-tags .dt-tag {
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0.3em 0.4em;
    margin-right: 0.2em;
    margin-bottom: 0.4em;
    font-size: 60%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  .posts-list img {
    opacity: 1;
  }

  .posts-list img[data-src] {
    opacity: 0;
  }

  .posts-more {
    clear: both;
  }


  .posts-sidebar {
    font-size: 16px;
  }

  .posts-sidebar h3 {
    font-size: 16px;
    margin-top: 0;
    margin-bottom: 0.5em;
    font-weight: 400;
    text-transform: uppercase;
  }

  .sidebar-section {
    margin-bottom: 30px;
  }

  .categories ul {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }

  .categories li {
    color: rgba(0, 0, 0, 0.8);
    margin-bottom: 0;
  }

  .categories li>a {
    border-bottom: none;
  }

  .categories li>a:hover {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  }

  .categories .active {
    font-weight: 600;
  }

  .categories .category-count {
    color: rgba(0, 0, 0, 0.4);
  }


  @media(min-width: 768px) {
    .posts-list .post-preview h2 {
      font-size: 26px;
    }
    .posts-list .post-preview .thumbnail {
      float: right;
      width: 30%;
      margin-bottom: 0;
    }
    .posts-list .post-preview .description {
      float: left;
      width: 45%;
    }
    .posts-list .post-preview .metadata {
      float: left;
      width: 20%;
      margin-top: 8px;
    }
    .posts-list .post-preview p {
      margin: 0 0 12px 0;
      line-height: 1.5em;
      font-size: 16px;
    }
    .posts-with-sidebar .posts-list {
      float: left;
      width: 75%;
    }
    .posts-with-sidebar .posts-sidebar {
      float: right;
      width: 20%;
      margin-top: 60px;
      padding-top: 24px;
      padding-bottom: 24px;
    }
  }


  /* Improve display for browsers without grid (IE/Edge <= 15) */

  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }

  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }

  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }

  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }

  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }

  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }

  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }


  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }

  .downlevel .footnotes ol {
    padding-left: 13px;
  }

  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }

  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }

  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }

  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  .downlevel .posts-list .post-preview {
    color: inherit;
  }



  </style>

  <script type="application/javascript">

  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }

  // show body when load is complete
  function on_load_complete() {

    // add anchors
    if (window.anchors) {
      window.anchors.options.placement = 'left';
      window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
    }


    // set body to visible
    document.body.style.visibility = 'visible';

    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }

    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }

  function init_distill() {

    init_common();

    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);

    // create d-title
    $('.d-title').changeElementType('d-title');

    // separator
    var separator = '<hr class="section-separator" style="clear: both"/>';
    // prepend separator above appendix
    $('.d-byline').before(separator);
    $('.d-article').before(separator);

    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);

    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();

    // move posts container into article
    $('.posts-container').appendTo($('d-article'));

    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');

    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;

    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();

    // move refs into #references-listing
    $('#references-listing').replaceWith($('#refs'));

    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-contents a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });

    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');

    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {

      // capture layout
      var layout = $(this).attr('data-layout');

      // apply layout to markdown level block elements
      var elements = $(this).children().not('details, div.sourceCode, pre, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });


      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });

    // remove code block used to force  highlighting css
    $('.distill-force-highlighting-css').parent().remove();

    // remove empty line numbers inserted by pandoc when using a
    // custom syntax highlighting theme, except when numbering line
    // in code chunk
    $('pre:not(.numberLines) code.sourceCode a:empty').remove();

    // load distill framework
    load_distill_framework();

    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {

      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;

      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');

      // article with toc class
      $('.d-contents').parent().addClass('d-article-with-toc');

      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

      // add orcid ids
      $('.authors-affiliations').find('.author').each(function(i, el) {
        var orcid_id = front_matter.authors[i].orcidID;
        var author_name = front_matter.authors[i].author
        if (orcid_id) {
          var a = $('<a></a>');
          a.attr('href', 'https://orcid.org/' + orcid_id);
          var img = $('<img></img>');
          img.addClass('orcid-id');
          img.attr('alt', author_name ? 'ORCID ID for ' + author_name : 'ORCID ID');
          img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
          a.append(img);
          $(this).append(a);
        }
      });

      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }

      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");

      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }

       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }

      // remove d-appendix and d-footnote-list local styles
      $('d-appendix > style:first-child').remove();
      $('d-footnote-list > style:first-child').remove();

      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();

      // hoverable references
      $('span.citation[data-cites]').each(function() {
        const citeChild = $(this).children()[0]
        // Do not process if @xyz has been used without escaping and without bibliography activated
        // https://github.com/rstudio/distill/issues/466
        if (citeChild === undefined) return true

        if (citeChild.nodeName == "D-FOOTNOTE") {
          var fn = citeChild
          $(this).html(fn.shadowRoot.querySelector("sup"))
          $(this).id = fn.id
          fn.remove()
        }
        var refs = $(this).attr('data-cites').split(" ");
        var refHtml = refs.map(function(ref) {
          // Could use CSS.escape too here, we insure backward compatibility in navigator
          return "<p>" + $('div[id="ref-' + ref + '"]').html() + "</p>";
        }).join("\n");
        window.tippy(this, {
          allowHTML: true,
          content: refHtml,
          maxWidth: 500,
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        });
      });

      // fix footnotes in tables (#411)
      // replacing broken distill.pub feature
      $('table d-footnote').each(function() {
        // we replace internal showAtNode methode which is triggered when hovering a footnote
        this.hoverBox.showAtNode = function(node) {
          // ported from https://github.com/distillpub/template/pull/105/files
          calcOffset = function(elem) {
              let x = elem.offsetLeft;
              let y = elem.offsetTop;
              // Traverse upwards until an `absolute` element is found or `elem`
              // becomes null.
              while (elem = elem.offsetParent && elem.style.position != 'absolute') {
                  x += elem.offsetLeft;
                  y += elem.offsetTop;
              }

              return { left: x, top: y };
          }
          // https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement/offsetTop
          const bbox = node.getBoundingClientRect();
          const offset = calcOffset(node);
          this.show([offset.left + bbox.width, offset.top + bbox.height]);
        }
      })

      // clear polling timer
      clearInterval(tid);

      // show body now that everything is ready
      on_load_complete();
    }

    var tid = setInterval(distill_post_process, 50);
    distill_post_process();

  }

  function init_downlevel() {

    init_common();

     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));

    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;

    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();

    // remove toc
    $('.d-contents').remove();

    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });


    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);

    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();

    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });

    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));

    $('body').addClass('downlevel');

    on_load_complete();
  }


  function init_common() {

    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};

        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });

        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);

    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});

    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      // ignore leaflet img layers (#106)
      figures = figures.filter(':not(img[class*="leaflet"])')
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });

      }
    });

    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });

    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace(/^index[.]html/, "./"));
      });
    }

    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');

    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");

    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();

    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }

  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });

  </script>

  <!--/radix_placeholder_distill-->
  <script src="RJ-2025-030_files/header-attrs-2.30/header-attrs.js"></script>
  <link href="RJ-2025-030_files/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
  <script src="RJ-2025-030_files/htmlwidgets-1.6.4/htmlwidgets.js"></script>
  <script src="RJ-2025-030_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
  <link href="RJ-2025-030_files/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
  <script src="RJ-2025-030_files/leaflet-1.3.1/leaflet.js"></script>
  <link href="RJ-2025-030_files/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
  <script src="RJ-2025-030_files/proj4-2.6.2/proj4.min.js"></script>
  <script src="RJ-2025-030_files/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
  <link href="RJ-2025-030_files/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
  <script src="RJ-2025-030_files/leaflet-binding-2.2.3/leaflet.js"></script>
  <script src="RJ-2025-030_files/leaflet-providers-2.0.0/leaflet-providers_2.0.0.js"></script>
  <script src="RJ-2025-030_files/leaflet-providers-plugin-2.2.3/leaflet-providers-plugin.js"></script>
  <script src="RJ-2025-030_files/clipboard-0.0.1/setClipboardText.js"></script>
  <link id="file4330b702e5ec8-1-attachment" rel="attachment" href="RJ-2025-030_files/file4330b702e5ec8-0.0.1/file4330b702e5ec8_layer.tif"/>
  <script src="RJ-2025-030_files/GeoRaster-0.0.1/georaster.min.js"></script>
  <script src="RJ-2025-030_files/GeoRaster-0.0.1/geoblaze.js"></script>
  <script src="RJ-2025-030_files/GeoRaster-0.0.1/georaster-layer-for-leaflet.min.js"></script>
  <script src="RJ-2025-030_files/GeoRaster-0.0.1/georaster-binding.js"></script>
  <script src="RJ-2025-030_files/GeoRaster-0.0.1/georasterUtils.js"></script>
  <script src="RJ-2025-030_files/GeoRaster-0.0.1/mathjs.min.js"></script>
  <script src="RJ-2025-030_files/GeoRaster-0.0.1/proj4-src.js"></script>
  <script src="RJ-2025-030_files/chromajs-2.1.0/chroma.min.js"></script>
  <script src="RJ-2025-030_files/HomeButton-0.0.1/home-button.js"></script>
  <script src="RJ-2025-030_files/HomeButton-0.0.1/easy-button-src.min.js"></script>
  <link href="RJ-2025-030_files/EX_P_Total-CSS-0.0.1/EX_P_Total_home-button.css" rel="stylesheet" />
  <link href="RJ-2025-030_files/mapviewCSS-0.0.1/mapview-popup.css" rel="stylesheet" />
  <link href="RJ-2025-030_files/mapviewCSS-0.0.1/mapview.css" rel="stylesheet" />
  <script src="RJ-2025-030_files/Leaflet.Sync-0.0.5/L.Map.Sync.js"></script>
  <script src="RJ-2025-030_files/popper-2.6.0/popper.min.js"></script>
  <link href="RJ-2025-030_files/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="RJ-2025-030_files/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="RJ-2025-030_files/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="RJ-2025-030_files/anchor-4.2.2/anchor.min.js"></script>
  <script src="RJ-2025-030_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="RJ-2025-030_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="RJ-2025-030_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->
  <script>
    $(function() {
      console.log("Starting...")

      // Mathjax config (add automatic linebreaks when supported)
      // MathJax = {
      //    tex: {
      //        inlineMath: [['$', '$'], ['\\(', '\\)']],
      //        displayMath: [['$$', '$$'], ['\\[', '\\]']],
      //        tags: 'ams',
      //        multline: true,
      //    },
      //    options: {
      //        linebreaks: { automatic: true },
      //    },
      // };

      // Always show Published - distill hides it if not set
      function show_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'visible');
      }

      show_byline_column('Published')

      // tweak function
      var rmd_meta = JSON.parse($("#radix-rmarkdown-metadata").html());
      function get_meta(name, meta) {
        var ind = meta.attributes.names.value.findIndex((e) => e == name)
        var val = meta.value[ind]
        if (val.type != 'list') {
          return val.value.toString()
        }
        return val
      }

      // tweak description
      // Add clickable tags
      const slug = get_meta('slug', rmd_meta)
      const cite_url = get_meta('citation_url', rmd_meta)

      var title = $("d-title").text

      const buttons = $('<div class="dt-tags" style="grid-column: page;">')
      buttons.append('<a href="#citation" class="dt-tag"><i class="fas fa-quote-left"></i> Cite</a>')
      buttons.append('<a href="' + slug + '.pdf" class="dt-tag"><i class="fas fa-file-pdf"></i> PDF</a>')
      
      // Conditionally add supplementary files button
      if (document.getElementById('supplementary-materials')) {
        // create element safely
        const btn_suppl = document.createElement('a');
        btn_suppl.href = slug + '.zip';
        btn_suppl.className = 'dt-tag';
        btn_suppl.innerHTML = '<i class="fas fa-file-zipper"></i> Supplement';
        buttons.append(btn_suppl);
      }

      // adds Abstract: in front of the first <p> in the title section --
      // unless it happens to be the subtitle (FIXME: this is a bad hack - can't distill do this?)
      var tpar = $("d-title p:not(:empty)").filter(function() {
        return !$(this).hasClass("subtitle");
      }).first();
      if (tpar) {
        const abstract = $('<d-abstract>')
        abstract.append('<b>Abstract:</b><br>')
        abstract.append(tpar) // Move description to d-abstract
        $("d-title p:empty").remove() // Remove empty paragraphs after title
        abstract.append(buttons)
        abstract.insertAfter($('d-title')) // Add abstract section after title */
      }

      // tweak by-line
      var byline = $("d-byline div.byline")
      ind = rmd_meta.attributes.names.value.findIndex((e) => e == "journal")
      const journal = get_meta('journal', rmd_meta)
      const volume = get_meta('volume', rmd_meta)
      const issue = get_meta('issue', rmd_meta)
      const jrtitle = get_meta('title', journal)
      const year = ((jrtitle == "R News") ? 2000 : 2008) + parseInt(volume)
      const firstpage = get_meta('firstpage', journal)
      const lastpage = get_meta('lastpage', journal)
      byline.append('<div class="rjournal grid">')
      $('div.rjournal').append('<h3>Volume</h3>')
      $('div.rjournal').append('<h3>Pages</h3>')
      $('div.rjournal').append('<a class="volume" href="../../issues/'+year+'-'+issue+'">'+volume+'/'+issue+'</a>')
      $('div.rjournal').append('<p class="pages">'+firstpage+' - '+lastpage+'</p>')

      const received_date = new Date(get_meta('date_received', rmd_meta))
      byline.find('h3:contains("Published")').parent().append('<h3>Received</h3><p>'+received_date.toLocaleDateString('en-US', {month: 'short'})+' '+received_date.getDate()+', '+received_date.getFullYear()+'</p>')

    })
  </script>

  <style>
      /*
    .nav-dropdown-content .nav-dropdown-header {
      text-transform: lowercase;
    }
    */

    d-byline .byline {
      grid-template-columns: 2fr 2fr 2fr 2fr;
    }

    d-byline .rjournal {
      grid-column-end: span 2;
      grid-template-columns: 1fr 1fr;
      margin-bottom: 0;
    }

    d-title h1, d-title p, d-title figure,
    d-abstract p, d-abstract b {
      grid-column: page;
    }

    d-title .dt-tags {
      grid-column: page;
    }

    .dt-tags .dt-tag {
      text-transform: lowercase;
    }

    d-article h1 {
      line-height: 1.1em;
    }

    d-abstract p, d-article p {
      text-align: justify;
    }

    @media(min-width: 1000px) {
      .d-contents.d-contents-float {
        justify-self: end;
      }

      nav.toc {
        border-right: 1px solid rgba(0, 0, 0, 0.1);
        border-right-width: 1px;
        border-right-style: solid;
        border-right-color: rgba(0, 0, 0, 0.1);
      }
    }

    .posts-list .dt-tags .dt-tag {
      text-transform: lowercase;
    }

    @keyframes highlight-target {
      0% {
        background-color: #ffa;
      }
      66% {
        background-color: #ffa;
      }
      100% {
        background-color: none;
      }
    }

    d-article :target, d-appendix :target {
       animation: highlight-target 3s;
    }

    .header-section-number {
      margin-right: 0.5em;
    }
    
    d-appendix .citation-appendix,
    .d-appendix .citation-appendix {
      color: rgb(60, 60, 60);
    }

    d-article h2 {
      border-bottom: 0px solid rgba(0, 0, 0, 0.1);
      padding-bottom: 0rem;
    }
    d-article h3 {
      font-size: 20px;
    }
    d-article h4 {
      font-size: 18px;
      text-transform: none;
    }

    @media (min-width: 1024px) {
      d-article h2 {
        font-size: 32px;
      }
      d-article h3 {
        font-size: 24px;
      }
      d-article h4 {
        font-size: 20px;
      }
    }
  </style>


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Exploring Image Analysis in R: Applications and Advancements","description":"This review offers an overview of image processing packages in R, covering applications such as multiplex imaging, cell tracking, and general-purpose tools. We found 38 R packages for image analysis, with adimpro and EBImage being the oldest, published in 2006, and biopixR among the newest, released in 2024. Of these packages, over 90 % are still active, with two-thirds receiving updates within the last 1.5 years. The pivotal role of bioimage informatics in life sciences is emphasized in this review, along with the ongoing advancements of R's functionality through novel code releases. It focuses on complete analysis pipelines for extracting valuable information from biological images and includes real-world examples. Demonstrating how researchers can use R to tackle new scientific challenges in image analysis, the review provides a comprehensive understanding of R's utility in this field.","doi":"10.32614/RJ-2025-030","authors":[{"author":"Tim Brauckhoff","authorURL":"#","affiliation":"Brandenburg University of Technology Cottbus - Senftenberg","affiliationURL":"#","orcidID":"0009-0002-0142-7017"},{"author":"Julius Rublack","authorURL":"#","affiliation":"University of Münster","affiliationURL":"#","orcidID":""},{"author":"Stefan Rödiger","authorURL":"#","affiliation":"Brandenburg University of Technology Cottbus - Senftenberg","affiliationURL":"#","orcidID":"0000-0002-1441-6512"}],"publishedDate":"2025-10-22T00:00:00.000+11:00","citationText":"Brauckhoff, et al., 2025"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Exploring Image Analysis in R: Applications and Advancements</h1>

<!--radix_placeholder_categories-->
<!--/radix_placeholder_categories-->
<p>This review offers an overview of image processing packages in R, covering applications such as multiplex imaging, cell tracking, and general-purpose tools. We found 38 R packages for image analysis, with adimpro and EBImage being the oldest, published in 2006, and biopixR among the newest, released in 2024. Of these packages, over 90 % are still active, with two-thirds receiving updates within the last 1.5 years. The pivotal role of bioimage informatics in life sciences is emphasized in this review, along with the ongoing advancements of R’s functionality through novel code releases. It focuses on complete analysis pipelines for extracting valuable information from biological images and includes real-world examples. Demonstrating how researchers can use R to tackle new scientific challenges in image analysis, the review provides a comprehensive understanding of R’s utility in this field.</p>
</div>

<div class="d-byline">
  Tim Brauckhoff  (Brandenburg University of Technology Cottbus - Senftenberg)
  
,   Julius Rublack  (University of Münster)
  
,   Stefan Rödiger  (Brandenburg University of Technology Cottbus - Senftenberg)
  
<br/>2025-10-22
</div>

<div class="d-article">
<h2 data-number="1" id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>Advancements in microscopy and computational tools have become pivotal to
biological research, facilitating detailed investigation of cellular and
molecular processes previously inaccessible. Consequently, imaging
methodologies, staining protocols, and fluorescent labeling — particularly those
employing genetically encoded fluorescent proteins and immunofluorescence — have
resulted in a substantial increase in the capacity to examine cellular
structures, dynamics, and functions <span class="citation" data-cites="Swedlow2009 Peng2012 Chessel2017 Moen2019 schneider_open_2019">(<a href="#ref-Swedlow2009" role="doc-biblioref">Swedlow et al. 2009</a>; <a href="#ref-Peng2012" role="doc-biblioref">Peng et al. 2012</a>; <a href="#ref-Chessel2017" role="doc-biblioref">Chessel 2017</a>; <a href="#ref-schneider_open_2019" role="doc-biblioref">Schneider et al. 2019</a>; <a href="#ref-Moen2019" role="doc-biblioref">Moen et al. 2019</a>)</span>.</p>
<p>As with any significant advance in today’s world, software is required
to facilitate the acquisition, analysis, management, and visualization of image
data resulting from these techniques. The current techniques have allowed the
capture of biological phenomena with an unparalleled level of complexity and
resolution <span class="citation" data-cites="Eliceiri2012">(<a href="#ref-Eliceiri2012" role="doc-biblioref">Eliceiri et al. 2012</a>)</span>. As a result, an ever-growing amount of image data
is being generated <span class="citation" data-cites="Peng2012">(<a href="#ref-Peng2012" role="doc-biblioref">Peng et al. 2012</a>)</span>. Alongside the three spatial dimensions, images
now encompass additional dimensions like time and color channels. Biomedical
images exhibit this high level of complexity, as evidenced by the analysis of
dense cell turfs where cells may partially overlap <span class="citation" data-cites="Peng2008 Swedlow2009">(<a href="#ref-Peng2008" role="doc-biblioref">Peng 2008</a>; <a href="#ref-Swedlow2009" role="doc-biblioref">Swedlow et al. 2009</a>)</span>.
The increase in complexity demands computational approaches. Nevertheless, the
challenge posed is not solely due to complexity. As imaging technology advances,
the volume of image data generated from experiments also sees a steep rise
<span class="citation" data-cites="Peng2008 Caicedo2017">(<a href="#ref-Peng2008" role="doc-biblioref">Peng 2008</a>; <a href="#ref-Caicedo2017" role="doc-biblioref">Caicedo et al. 2017</a>)</span>.</p>
<p>The need for quantitative information from images to understand and develop new
biological concepts has led to the emergence of bioimage informatics as a
specialized field of study <span class="citation" data-cites="Eliceiri2012 Murphy2014">(<a href="#ref-Eliceiri2012" role="doc-biblioref">Eliceiri et al. 2012</a>; <a href="#ref-Murphy2014" role="doc-biblioref">Murphy 2014</a>)</span>. Bioimage informatics
is primarily concerned with the extraction of quantitative information from
images to interpret biological concepts or develop new ones <span class="citation" data-cites="Chessel2017 Moen2019 schneider_open_2019">(<a href="#ref-Chessel2017" role="doc-biblioref">Chessel 2017</a>; <a href="#ref-schneider_open_2019" role="doc-biblioref">Schneider et al. 2019</a>; <a href="#ref-Moen2019" role="doc-biblioref">Moen et al. 2019</a>)</span>. Bioimage informatics focuses on the
automation of objective and reproducible image data analysis, while concurrently
developing tools for the visualization, storage, processing, and analysis of
such data <span class="citation" data-cites="Swedlow2009a Peng2012">(<a href="#ref-Swedlow2009a" role="doc-biblioref">Swedlow and Eliceiri 2009</a>; <a href="#ref-Peng2012" role="doc-biblioref">Peng et al. 2012</a>)</span>. Crucial advancements range from cell
phenotype screening, drug discovery, and cancer diagnosis to gene function,
metabolic pathways, and protein expression patterns. The basic operations in
bioimage informatics are feature extraction and selection, segmentation,
registration, clustering, classification, annotation, and visualization
<span class="citation" data-cites="Peng2008">(<a href="#ref-Peng2008" role="doc-biblioref">Peng 2008</a>)</span>.</p>
<p>Due to recent advancements, the utilization of microscopy in biology has evolved
into a quantitative approach, as opposed to solely a visual one. Thus, various
essential open-source platforms, applications, and languages have emerged, which
have now become well-established within the life science community
<span class="citation" data-cites="PaulGilloteaux2023">(<a href="#ref-PaulGilloteaux2023" role="doc-biblioref">Paul-Gilloteaux 2023</a>)</span>. Python, <code>R</code>, and MATLAB are among the most favored
programming languages in bioinformatics <span class="citation" data-cites="Giorgi2022">(<a href="#ref-Giorgi2022" role="doc-biblioref">Giorgi et al. 2022</a>)</span>, with Python and <code>R</code> being
extensively used in biomedicine <span class="citation" data-cites="Roesch2023">(<a href="#ref-Roesch2023" role="doc-biblioref">Roesch et al. 2023</a>)</span>. <code>R</code> plays a pivotal role in the
fields of statistics, bioinformatics, and data science. It is a versatile
statistical software that is used in various assays, for example, in gene
expression analyses <span class="citation" data-cites="rodiger_surface_2013 rodiger_r_2015 burdukiewicz_pcredux_2022 chilimoniuk_challenges_2024">(<a href="#ref-rodiger_surface_2013" role="doc-biblioref">Rödiger et al. 2013</a>, <a href="#ref-rodiger_r_2015" role="doc-biblioref">2015a</a>; <a href="#ref-burdukiewicz_pcredux_2022" role="doc-biblioref">Burdukiewicz et al. 2022</a>; <a href="#ref-chilimoniuk_challenges_2024" role="doc-biblioref">Chilimoniuk et al. 2024</a>)</span>. Furthermore, it is
one of the top ten most prevalent programming languages across the globe, with a
thriving community that has developed numerous extensions and packages for
various applications <span class="citation" data-cites="Giorgi2022">(<a href="#ref-Giorgi2022" role="doc-biblioref">Giorgi et al. 2022</a>)</span>. Originally developed for statistical
analysis, <code>R</code> and its packages now offer robust capabilities for image analysis
and automation <span class="citation" data-cites="Chessel2017 Haase2022">(<a href="#ref-Chessel2017" role="doc-biblioref">Chessel 2017</a>; <a href="#ref-Haase2022" role="doc-biblioref">Haase et al. 2022</a>)</span>. The growing demand for
automation and data-driven analysis underscores the necessity for flexible and
integrated computational tools. <code>R</code>’s expanding
ecosystem of packages, ranging from general-purpose image processing to
specialized, domain-specific workflows, facilitates the creation of customized
solutions tailored to diverse research needs. The extensible framework and
robust statistical capabilities support seamless integration of image analysis
with downstream data interpretation, promoting reproducibility and efficiency
across the entire analytical pipeline <span class="citation" data-cites="Roediger2015 Chessel2017 Giorgi2022 Haase2022">(<a href="#ref-Roediger2015" role="doc-biblioref">Rödiger et al. 2015b</a>; <a href="#ref-Chessel2017" role="doc-biblioref">Chessel 2017</a>; <a href="#ref-Giorgi2022" role="doc-biblioref">Giorgi et al. 2022</a>; <a href="#ref-Haase2022" role="doc-biblioref">Haase et al. 2022</a>)</span>.</p>
<p><code>R</code> can integrate with other programming languages through the use of packages
such as <code>reticulate</code> <span class="citation" data-cites="reticulate">(<a href="#ref-reticulate" role="doc-biblioref">Ushey et al. 2024</a>)</span> for Python, which enables users to leverage
the strengths of multiple languages within their research workflows, enhancing
flexibility across diverse domains. Another example of this is
Bio7. Bio7 is an open-source platform designed for ecological modeling,
scientific image analysis, and statistical analysis. It provides an <code>R</code>
development environment and integration with the ImageJ application
<span class="citation" data-cites="austenfeld_graphical_2012">(<a href="#ref-austenfeld_graphical_2012" role="doc-biblioref">Austenfeld and Beyschlag 2012</a>)</span>. ImageJ is a widely-used, public-domain
Java-based software suite specifically developed for biological image processing
and analysis, that supports various file formats, advanced image manipulation
techniques, and a vast array of plugins and scripts <span class="citation" data-cites="schneider_nih_2012">(<a href="#ref-schneider_nih_2012" role="doc-biblioref">Schneider et al. 2012</a>)</span>.</p>
<p>A common difficulty in bioinformatics is the large number of file formats, some
of which are proprietary. A lack of standardization means that general tools
must deal with this vast array of file formats. The open-source approach
provides access to the code of applications, packages, and extensions, thereby
facilitating modification and further development by the community. This
enhances reproducibility and validation, offering flexibility and adaptability
for scientific discovery. This makes open-source methods ideally suited to the diverse
and interdisciplinary field of biological imaging research <span class="citation" data-cites="Swedlow2009a Roediger2015">(<a href="#ref-Swedlow2009a" role="doc-biblioref">Swedlow and Eliceiri 2009</a>; <a href="#ref-Roediger2015" role="doc-biblioref">Rödiger et al. 2015b</a>)</span>. The Open Microscopy Environment (OME) offers a standardized,
open-source framework for the management, analysis, and exchange of biological
imaging data, with a particular focus on the integration and preservation of
rich metadata — such as experimental conditions, cell types, acquisition
parameters, microscope specifications, and quantification methods
<span class="citation" data-cites="Goldberg2005">(<a href="#ref-Goldberg2005" role="doc-biblioref">Goldberg et al. 2005</a>)</span>. A central objective of OME is to ensure lossless storage and
interoperability across diverse proprietary and non-proprietary platforms. This
objective addresses the common issue of metadata loss during format conversions
within image analysis pipelines. By establishing standardized formats and
protocols, OME fosters compatibility between proprietary systems and enhances
reproducibility. The widely adopted OME-TIFF format extends the traditional TIFF
structure by embedding metadata in XML, enabling efficient storage and retrieval
of large, multidimensional datasets commonly encountered in fluorescence imaging
<span class="citation" data-cites="Linkert2010 Leigh2016 Besson2019">(<a href="#ref-Linkert2010" role="doc-biblioref">Linkert et al. 2010</a>; <a href="#ref-Leigh2016" role="doc-biblioref">Leigh et al. 2016</a>; <a href="#ref-Besson2019" role="doc-biblioref">Besson et al. 2019</a>)</span>. In addition, the OME-ZARR format,
developed under the Next-Generation File Format (NGFF) initiative, has been
optimized for scalable, cloud-based storage of large N-dimensional arrays, with
metadata stored in human-readable JSON. The system’s capacity for partial data
access is a notable feature, contributing to enhanced performance in distributed
workflows by combining formats such as OME-TIFF, Hierarchical Data Format 5
(HDF5), and Zarr <span class="citation" data-cites="Moore2021 Moore2023">(<a href="#ref-Moore2021" role="doc-biblioref">Moore et al. 2021</a>, <a href="#ref-Moore2023" role="doc-biblioref">2023</a>)</span><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.
Increasing adoption of these formats by commercial imaging software vendors
further strengthens their relevance and sustainability <span class="citation" data-cites="Linkert2010">(<a href="#ref-Linkert2010" role="doc-biblioref">Linkert et al. 2010</a>)</span>. In the
context of <code>R</code>-based workflows, the <code>RBioFormats</code> package provides a native
interface to the OME Bio-Formats Java library. This enables the reading of
proprietary file formats and associated metadata, output to OME-TIFF, and
seamless integration of image acquisition with downstream analysis
<span class="citation" data-cites="AndrzejOles2023">(<a href="#ref-AndrzejOles2023" role="doc-biblioref">Andrzej Oleś, John Lee 2023</a>)</span>. This facilitates the establishment of flexible,
standardized, and reproducible image analysis pipelines within the <code>R</code> ecosystem.</p>
<p>The heterogeneous and dynamic nature of images presents a constant challenge for
image analysis. Capturing precise and high-quality images that accurately
represent the changing characteristics of an experiment can be difficult, even
for experienced researchers <span class="citation" data-cites="Swedlow2009">(<a href="#ref-Swedlow2009" role="doc-biblioref">Swedlow et al. 2009</a>)</span>. Additionally, visualizing and
analyzing multi-gigabyte data sets requires substantial computational power. The
process of detailed analysis of image sequences, which involves identifying and
tracking objects, followed by the presentation of the resulting data and the
exploration of the underlying biological mechanisms, adds further complexity
<span class="citation" data-cites="Swedlow2009a">(<a href="#ref-Swedlow2009a" role="doc-biblioref">Swedlow and Eliceiri 2009</a>)</span>. To at least simplify the process of selecting the
appropriate software, this review provides an overview of <code>R</code> packages suitable
for image analysis and outlines their applications in biological laboratory
settings.</p>
<h2 data-number="2" id="methods"><span class="header-section-number">2</span> Methods</h2>
<p>In this study, a review of the literature was conducted over the period
September 2023 to March 2024. The objective was to identify and analyze <code>R</code>
packages that are suitable for bioimage informatics applications. The primary
resources included the Comprehensive <code>R</code> Archive Network
(CRAN)<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, GitHub
repositories<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, rOpenSci’s
r-universe<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>, the
Bioconductor repository<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>,
OpenAlex database, PubMed, and Google Scholar. The chosen sources allowed for an
extensive coverage of <code>R</code> package repositories while also providing access to
relevant scientific literature. By combining these resources, the study aimed to
provide a comprehensive overview of available tools and techniques within the
domain of bioimage informatics using <code>R</code>.</p>
<p>The search strategy centered around pertinent keywords, including “bioimage,”
“biomedical image analysis,” “imaging,” “microscopy,” “histology,” and
“pathology” and the following search strings:</p>
<ul>
<li><p><a href="https://openalex.org/works?page=1&amp;filter=title_and_abstract.search%3AR%20packages%20for%20image%20analysis" class="uri">https://openalex.org/works?page=1&amp;filter=title_and_abstract.search%3AR%20packages%20for%20image%20analysis</a></p></li>
<li><p><a href="https://openalex.org/works?page=1&amp;filter=title_and_abstract.search%3Aimage%20processing%20in%20R" class="uri">https://openalex.org/works?page=1&amp;filter=title_and_abstract.search%3Aimage%20processing%20in%20R</a></p></li>
<li><p><a href="https://openalex.org/works?page=1&amp;filter=title_and_abstract.search%3Amicroscopy%20imaging%20in%20R%20packages" class="uri">https://openalex.org/works?page=1&amp;filter=title_and_abstract.search%3Amicroscopy%20imaging%20in%20R%20packages</a></p></li>
<li><p><a href="https://pubmed.ncbi.nlm.nih.gov/?term=biomedical+image+analysis&amp;filter=dates.1963%2F1%2F1-2025%2F3%2F26&amp;filter=pubt.review&amp;filter=other.excludepreprints" class="uri">https://pubmed.ncbi.nlm.nih.gov/?term=biomedical+image+analysis&amp;filter=dates.1963%2F1%2F1-2025%2F3%2F26&amp;filter=pubt.review&amp;filter=other.excludepreprints</a></p></li>
<li><p><a href="https://scholar.google.de/scholar?hl=de&amp;as_sdt=0%2C5&amp;q=image+analysis+in+R&amp;btnG=" class="uri">https://scholar.google.de/scholar?hl=de&amp;as_sdt=0%2C5&amp;q=image+analysis+in+R&amp;btnG=</a></p></li>
<li><p><a href="https://scholar.google.de/scholar?hl=de&amp;as_sdt=0%2C5&amp;q=bioimage+analysis+in+R&amp;btnG=" class="uri">https://scholar.google.de/scholar?hl=de&amp;as_sdt=0%2C5&amp;q=bioimage+analysis+in+R&amp;btnG=</a></p></li>
<li><p><a href="https://scholar.google.de/scholar?hl=de&amp;as_sdt=0%2C5&amp;q=microscopy+imaging+analysis+in+R&amp;btnG=" class="uri">https://scholar.google.de/scholar?hl=de&amp;as_sdt=0%2C5&amp;q=microscopy+imaging+analysis+in+R&amp;btnG=</a></p></li>
</ul>
<p>The identified packages were then subjected to an analysis to
understand their usage, dependencies on other libraries, repository hosting
platforms, and licensing terms.</p>
<p>The examples provided, along with this review, were created using <code>RMarkdown</code>. All
computations were performed using the <code>R</code> programming language, version 4.3.3, on
a 64-bit x86_64-pc-linux-gnu platform with the Ubuntu 22.04.3 LTS operating
system. We utilized the RStudio Integrated Development Environment
(IDE, 2023.09.0+463 “Desert Sunflower”, Ubuntu Jammy).</p>
<p>This review will examine a variety of <code>R</code> packages designed for image analysis,
including both general-purpose tools and those crafted for specific
applications. This overview aims to demonstrate the diverse capabilities and
adaptability of these tools within and beyond biological research contexts.
Given the significant interest in the localization of microplastics in cells and
the environment, our examples will primarily focus on the analysis of microbead
particles made of polymethylmethacrylate (PMMA), which measure approximately 12
µm and fall within the microplastic size range <span class="citation" data-cites="Geithe2024">(<a href="#ref-Geithe2024" role="doc-biblioref">Geithe et al. 2024</a>)</span>. As microbeads
are round, spherical objects in images, they visually resemble other commonly
imaged objects such as seeds and cells.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<h2 data-number="3" id="seg"><span class="header-section-number">3</span> Dividing to conquer - advanced segmentation strategies</h2>
<p>Image segmentation is a crucial preliminary step in image analysis and
interpretation. It involves dividing an image into distinct regions by assigning
a label to each pixel. The primary objective is to delineate regions pertinent
to the specific task <span class="citation" data-cites="Peng2008 Ghosh2019 Niedballa2022">(<a href="#ref-Peng2008" role="doc-biblioref">Peng 2008</a>; <a href="#ref-Ghosh2019" role="doc-biblioref">Ghosh et al. 2019</a>; <a href="#ref-Niedballa2022" role="doc-biblioref">Niedballa et al. 2022a</a>)</span>. This process
frequently employs features such as pixel intensity, gradient magnitude, or
texture measures. Based on these features, segmentation techniques can be
classified into three categories: region-based, edge-based, or
classification-based. Classification-based methods assign class labels to pixels
based on their feature values, whereas region-based and edge-based techniques
focus on within-region homogeneity and between-region contrast. One
straightforward method of segmentation is thresholding, which involves comparing
pixel values against one or more intensity thresholds. This process typically
separates the image into foreground and background regions <span class="citation" data-cites="Sonka2000 Jaehne2002">(<a href="#ref-Sonka2000" role="doc-biblioref">Sonka and Fitzpatrick 2000</a>; <a href="#ref-Jaehne2002" role="doc-biblioref">Jähne 2002</a>)</span>.</p>
<p>Another image segmentation method was proposed by <span class="citation" data-cites="Ren2003">Ren and Malik (<a href="#ref-Ren2003" role="doc-biblioref">2003</a>)</span>. This approach
integrates a preprocessing step that segments the image into superpixels,
feature extraction based on Gestalt cues, evaluation of the extracted features,
and the training of a linear classifier. Superpixels are clusters of pixels that
are similar with respect to properties such as color and texture, resulting in
larger subregions of the image. The primary objective of this preprocessing step
is to simplify the image and reduce the number of regions considered for
segmentation. Previously, this involved evaluating every single pixel. The
division of the image into regions larger than pixels but smaller than objects
allows for the superpixels to encompass a greater quantity of information,
adhere to the boundaries of natural image objects, reduce the presence of noise and
outliers, and enhance the speed of the subsequent segmentation process. In
summary, this method can be described as segmentation based on low-level pixel
grouping <span class="citation" data-cites="Ren2003 Hossain2019 OpenImageR">(<a href="#ref-Ren2003" role="doc-biblioref">Ren and Malik 2003</a>; <a href="#ref-Hossain2019" role="doc-biblioref">Hossain and Chen 2019</a>; <a href="#ref-OpenImageR" role="doc-biblioref">Mouselimis et al. 2023</a>)</span>.</p>
<p>However, segmentation is not limited to the differentiation of the foreground
and background. Pixel classification plays a critical role in a number of
applications, including visual question answering, object counting, and
tracking. In these applications, classification occurs not just spatially but
also temporally. These applications are diverse, encompassing fields such as
traffic analysis and surveillance, medical imaging, and cell biology
<span class="citation" data-cites="Ghosh2019">(<a href="#ref-Ghosh2019" role="doc-biblioref">Ghosh et al. 2019</a>)</span>. While a relatively straightforward technique, thresholding has
inherent limitations in distinguishing between background, noise, and
foreground. Therefore, the next section will offer a more sophisticated approach,
by presenting a package that utilizes deep learning for image segmentation
<span class="citation" data-cites="Smith2021">(<a href="#ref-Smith2021" role="doc-biblioref">Smith et al. 2021</a>)</span>.</p>
<h3 data-number="3.1" id="imageseg-a-deep-learning-package-for-forest-structure-analysis"><span class="header-section-number">3.1</span> <code>imageseg</code>: a deep learning package for forest structure analysis</h3>
<p>By venturing beyond the traditional laboratory setting, the <code>imageseg</code> package
offers a unique approach to analyzing forest structures through deep
learning-based image segmentation, utilizing TensorFlow
(<a href="https://www.tensorflow.org/" class="uri">https://www.tensorflow.org/</a>). This <code>R</code> package employs the power of
convolutional neural networks with the U-Net architecture to streamline image
segmentation tasks <span class="citation" data-cites="Niedballa2022">(<a href="#ref-Niedballa2022" role="doc-biblioref">Niedballa et al. 2022a</a>)</span>. According to the authors, this <code>R</code>
package has been designed to be user-friendly, with pre-trained models that
require only input images, making it accessible even to those without specialist
knowledge. A comprehensive vignette accompanies the package, which provides
detailed instructions on how to set up the software and explains how to utilize
its functions effectively <span class="citation" data-cites="imageseg">(<a href="#ref-imageseg" role="doc-biblioref">Niedballa et al. 2022c</a>)</span>. Developed primarily for forestry and
ecology applications, <code>imageseg</code> includes pre-trained data sets representing
various aspects of forest structure, such as canopy and understory vegetation
density. Its flexibility allows for customization with different training data,
enabling users to develop customized image segmentation workflows for other
fields such as microscopy and cell biology. The package supports both binary and
multiclass segmentation. For image processing within the <code>R</code> programming
environment, the <code>imageseg</code> package integrates with the <code>magick</code> package <span class="citation" data-cites="Niedballa2022">(<a href="#ref-Niedballa2022" role="doc-biblioref">Niedballa et al. 2022a</a>)</span>.</p>
<h3 data-number="3.2" id="ebimage-specialized-segmentation-strategy-for-touching-objects"><span class="header-section-number">3.2</span> <code>EBImage</code>: specialized segmentation strategy for touching objects</h3>
<p>The segmentation of closely adjacent objects, which is particularly prevalent in
cell microscopy, represents a common challenge that is addressed by the
<code>EBImage</code> package, which is equipped with a variety of segmentation algorithms.
A typical approach involves the application of either global or adaptive
thresholding, followed by connected set labeling, with the objective of
distinguishing individual objects. To achieve more precise segmentation
of touching objects, techniques such as watershed transformation or Voronoi
segmentation are employed <span class="citation" data-cites="Pau2010">(<a href="#ref-Pau2010" role="doc-biblioref">Pau et al. 2010</a>)</span>.</p>
<p>The watershed algorithm is employed to delineate touching microbeads (Figure
<a href="#fig:EBIoriginal">1</a>A-C). Initially, the image is transformed into a binary
image by applying a threshold (Figure <a href="#fig:EBIoriginal">1</a>B). After utilizing
the watershed function the result is visualized by assigning distinct colors to
the microbeads, effectively illustrating the algorithm’s capacity to
differentiate between touching objects (Figure <a href="#fig:EBIoriginal">1</a>C).</p>

<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># Load necessary library</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/aoles/EBImage'>EBImage</a></span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Load the image from the specified path</span></span>
<span><span class='va'>image</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/EBImage/man/io.html'>readImage</a></span><span class='op'>(</span><span class='st'>"figures/beads.png"</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Display the original image</span></span>
<span><span class='fu'>EBImage</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/EBImage/man/display.html'>display</a></span><span class='op'>(</span><span class='va'>image</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Apply a threshold to the original image to create a binary image</span></span>
<span><span class='va'>img_thresh</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/EBImage/man/thresh.html'>thresh</a></span><span class='op'>(</span><span class='va'>image</span>, offset <span class='op'>=</span> <span class='fl'>0.05</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Read the binary image and display it</span></span>
<span><span class='fu'>EBImage</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/EBImage/man/display.html'>display</a></span><span class='op'>(</span><span class='va'>img_thresh</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Perform watershed segmentation on the distance map of the thresholded image</span></span>
<span><span class='va'>segmented</span> <span class='op'>&lt;-</span> <span class='fu'>EBImage</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/EBImage/man/watershed.html'>watershed</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/pkg/EBImage/man/distmap.html'>distmap</a></span><span class='op'>(</span><span class='va'>img_thresh</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Color the labels of the segmented image</span></span>
<span><span class='va'>segmented_col</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/EBImage/man/colorLabels.html'>colorLabels</a></span><span class='op'>(</span><span class='va'>segmented</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Display the resulting image after watershed segmentation</span></span>
<span><span class='fu'>EBImage</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/EBImage/man/display.html'>display</a></span><span class='op'>(</span><span class='va'>segmented_col</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:EBIoriginal"></span>
<img src="figures/EBImage1.png" alt="Watershed Segmentation in EBImage: A) Original image used for watershed segmentation in EBImage. B) The thresh() function was employed to generate a binary image with the objective of effectively separating the foreground from the background. The binary representation of the image facilitates further segmentation processes by simplifying the image. C) Presents the result of the watershed segmentation, which is visually represented by the assignment of a distinct color to each object. This technique is particularly effective in differentiating touching objects, as evidenced by the clear separation of microbeads in the image." width="50%" /><img src="figures/EBImage2.png" alt="Watershed Segmentation in EBImage: A) Original image used for watershed segmentation in EBImage. B) The thresh() function was employed to generate a binary image with the objective of effectively separating the foreground from the background. The binary representation of the image facilitates further segmentation processes by simplifying the image. C) Presents the result of the watershed segmentation, which is visually represented by the assignment of a distinct color to each object. This technique is particularly effective in differentiating touching objects, as evidenced by the clear separation of microbeads in the image." width="50%" /><img src="figures/EBImage3.png" alt="Watershed Segmentation in EBImage: A) Original image used for watershed segmentation in EBImage. B) The thresh() function was employed to generate a binary image with the objective of effectively separating the foreground from the background. The binary representation of the image facilitates further segmentation processes by simplifying the image. C) Presents the result of the watershed segmentation, which is visually represented by the assignment of a distinct color to each object. This technique is particularly effective in differentiating touching objects, as evidenced by the clear separation of microbeads in the image." width="50%" />
<p class="caption">
Figure 1: <strong>Watershed Segmentation in <code>EBImage</code></strong>: <strong>A</strong>) Original image used for watershed segmentation in <code>EBImage</code>. <strong>B</strong>) The <code>thresh()</code> function was employed to generate a binary image with the objective of effectively separating the foreground from the background. The binary representation of the image facilitates further segmentation processes by simplifying the image. <strong>C</strong>) Presents the result of the watershed segmentation, which is visually represented by the assignment of a distinct color to each object. This technique is particularly effective in differentiating touching objects, as evidenced by the clear separation of microbeads in the image.
</p>
</div>
</div>
<h2 data-number="4" id="extr"><span class="header-section-number">4</span> Unveiling the hidden - feature extraction</h2>
<p>The primary objective of feature extraction is to condense the original data
into significant objects that encapsulate crucial information pertinent to each
specific image <span class="citation" data-cites="JudeHemanth2012">(<a href="#ref-JudeHemanth2012" role="doc-biblioref">Jude Hemanth and Anitha 2012</a>)</span>. Feature extraction may be applied to a
predefined region of interest (ROI) or may involve the identification of the
ROI, a process often referred to as segmentation, which was reviewed in the
previous sections. Within any given ROI, a multitude of attributes typically exist,
representing different states of the object under analysis. These attributes, or
features, are of vital importance for the interpretation of the detected objects
and can enable applications such as disease diagnosis or the identification of
promising candidates. Features related to individual pixels may include aspects
such as neighborhood relationships, connectivity, and gradients, which are
one-dimensional descriptions. Nevertheless, more intelligible and interpretable
information is frequently derived from descriptions of regions or objects
<span class="citation" data-cites="Sonka2000 Shirazi2018">(<a href="#ref-Sonka2000" role="doc-biblioref">Sonka and Fitzpatrick 2000</a>; <a href="#ref-Shirazi2018" role="doc-biblioref">Shirazi et al. 2018</a>)</span>. Object-level features encompass a range of
characteristics, including size, shape, texture, intensity, and spatial
distribution. Shape features can be further categorized into specific
characteristics, including perimeter, radius, circularity, and area. It is
crucial to acknowledge that the successful extraction of object features is
dependent on the quality and accuracy of the image segmentation process
<span class="citation" data-cites="Shirazi2018">(<a href="#ref-Shirazi2018" role="doc-biblioref">Shirazi et al. 2018</a>)</span>.</p>
<p>This section is devoted to an examination of <code>R</code> packages that enable the
automated extraction of quantitative features. The <code>biopixR</code> package offers
automated and interactive object detection strategies. The <code>pliman</code> package,
initially developed for the analysis of plant images, has the potential to be
adaptable to a range of different domains. The <code>FIELDimageR</code> package is capable
of supporting the analysis of drone-captured images from agricultural field
trials as well as images from pollen, which exhibit similar characteristics to
cellular images. These tools provide novel perspectives for interdisciplinary
research, facilitating the adaptation of methodologies across diverse fields.</p>
<h3 data-number="4.1" id="biopixr-versatile-biological-image-processing"><span class="header-section-number">4.1</span> <code>biopixR</code>: versatile biological image processing</h3>
<p>The <code>biopixR</code> package is a comprehensive toolbox developed primarily for
microbead analysis. It encompasses a range of functions, including image
importation, preprocessing, segmentation, feature extraction, and clustering.
The primary objective is to enable the detection of objects and the extraction
of quantitative data, including intensity values, shape, and texture
characteristics. These functionalities are integrated into user-friendly
pipelines that support batch processing, thereby enhancing accessibility. The
preprocessing capabilities include edge restoration and a variety of filter
functions <span class="citation" data-cites="biopixR">(<a href="#ref-biopixR" role="doc-biblioref">Brauckhoff et al. 2024</a>)</span>.</p>
<p>To illustrate the feature extraction process, the analysis focuses on a
microbead image (Figure <a href="#fig:biobeads0">2</a>A). The image is initially converted to
grayscale. Afterwards the <code>objectDetection()</code> function is applied to detect image
objects. The extracted objects are then represented visually by plotting the
highlighted contours of the objects and enumerating the microbeads according to
their cluster IDs, thus distinguishing them as individual entities (Figure
<a href="#fig:biobeads0">2</a>B).</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># Loading necessary package</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/Brauckhoff/biopixR'>biopixR</a></span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Importing the image</span></span>
<span><span class='va'>beads</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/biopixR/man/importImage.html'>importImage</a></span><span class='op'>(</span><span class='st'>"figures/beads2.jpg"</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># Plot original image</span></span>
<span><span class='va'>beads</span> <span class='op'>|&gt;</span> <span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span>axes <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># Converting the image to grayscale</span></span>
<span><span class='va'>beads</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/imager/man/grayscale.html'>grayscale</a></span><span class='op'>(</span><span class='va'>beads</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Detecting objects in the image using edge detection</span></span>
<span><span class='va'>objects</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/pkg/biopixR/man/objectDetection.html'>objectDetection</a></span><span class='op'>(</span><span class='va'>beads</span>,                <span class='co'># Image to process</span></span>
<span>                  method <span class='op'>=</span> <span class='st'>'edge'</span>,      <span class='co'># Method for object detection</span></span>
<span>                  alpha <span class='op'>=</span> <span class='fl'>1</span>,            <span class='co'># Threshold adjustment factor</span></span>
<span>                  sigma <span class='op'>=</span> <span class='fl'>0</span><span class='op'>)</span>            <span class='co'># Smoothing factor</span></span>
<span></span>
<span><span class='co'># Displaying internal visualization of object detection with marked contours </span></span>
<span><span class='co'># and centers</span></span>
<span><span class='va'>objects</span><span class='op'>$</span><span class='va'>marked_objects</span> <span class='op'>|&gt;</span> <span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span>axes <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Adding text annotations at the centers of detected objects</span></span>
<span><span class='fu'><a href='https://rdrr.io/r/graphics/text.html'>text</a></span><span class='op'>(</span><span class='va'>objects</span><span class='op'>$</span><span class='va'>centers</span><span class='op'>$</span><span class='va'>mx</span>,     <span class='co'># x-coordinates of object centers</span></span>
<span>     <span class='va'>objects</span><span class='op'>$</span><span class='va'>centers</span><span class='op'>$</span><span class='va'>my</span>,     <span class='co'># y-coordinates of object centers</span></span>
<span>     <span class='va'>objects</span><span class='op'>$</span><span class='va'>centers</span><span class='op'>$</span><span class='va'>value</span>,  <span class='co'># Text to display (value of the object center)</span></span>
<span>     col <span class='op'>=</span> <span class='st'>"green"</span>,          <span class='co'># Color of the text</span></span>
<span>     cex <span class='op'>=</span> <span class='fl'>1.5</span><span class='op'>)</span>          </span></code></pre>
</div>
</div>

<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:biobeads0"></span>
<img src="figures/beads4.png" alt="Microbead Detection using biopixR: A) The original image shows red fluorescent microbeads, with the majority appearing as isolated, round, spherical objects. Some microbeads are clustered together or overlapping, forming aggregated structures, while others are partially captured within the image frame. B) In the grayscale microbead image, edges of the microbeads are highlighted in purple, and the labeling ID (value) is displayed at the center of each object in green." width="66%" /><img src="figures/beads5.png" alt="Microbead Detection using biopixR: A) The original image shows red fluorescent microbeads, with the majority appearing as isolated, round, spherical objects. Some microbeads are clustered together or overlapping, forming aggregated structures, while others are partially captured within the image frame. B) In the grayscale microbead image, edges of the microbeads are highlighted in purple, and the labeling ID (value) is displayed at the center of each object in green." width="66%" />
<p class="caption">
Figure 2: <strong>Microbead Detection using <code>biopixR</code></strong>: <strong>A</strong>) The original image shows red fluorescent microbeads, with the majority appearing as isolated, round, spherical objects. Some microbeads are clustered together or overlapping, forming aggregated structures, while others are partially captured within the image frame. <strong>B</strong>) In the grayscale microbead image, edges of the microbeads are highlighted in purple, and the labeling ID (value) is displayed at the center of each object in green.
</p>
</div>
</div>
<h3 data-number="4.2" id="pliman-an-r-package-for-plant-image-analysis"><span class="header-section-number">4.2</span> <code>pliman</code>: an <code>R</code> package for plant image analysis</h3>
<p><code>pliman</code> is designed to analyze plant images, particularly leaves and seeds, to
help identify disease states, lesion shapes, and quantify objects. It
supports various functions, including image transformation, binarization,
segmentation, and detailed analysis, all facilitated by a detailed
vignette.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> A key feature of <code>pliman</code> is its automation of quantitative feature
extraction (Figure <a href="#fig:pliman1">3</a> and <a href="#fig:pliman2">4</a>), which
traditionally requires manual, time-consuming, and error-prone methods. The
features of this package are versatile, encompassing a range of segmentation
strategies, the analysis of shape and contour characteristics of leaves and
seeds, the counting of objects, and the quantification of disease states from
leaf images. While the primary focus is on plant imaging, the techniques used
are applicable to other fields such as cellular imaging. This
cross-applicability is further emphasized by the package’s batch processing
capabilities, which allow for autonomous analysis of multiple images, critical
for high-throughput phenotyping tasks <span class="citation" data-cites="Olivoto2022">(<a href="#ref-Olivoto2022" role="doc-biblioref">Olivoto 2022</a>)</span>.</p>

<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># Loading necessary package</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://nepem-ufsc.github.io/pliman/'>pliman</a></span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Import requires EBImage:</span></span>
<span><span class='co'># Importing the main image</span></span>
<span><span class='va'>beads</span> <span class='op'>&lt;-</span> <span class='fu'>EBImage</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/EBImage/man/io.html'>readImage</a></span><span class='op'>(</span><span class='st'>"figures/beads2.jpg"</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Importing additional images for background and foreground</span></span>
<span><span class='va'>foreground</span> <span class='op'>&lt;-</span> <span class='fu'>EBImage</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/EBImage/man/io.html'>readImage</a></span><span class='op'>(</span><span class='st'>"figures/foreground.jpg"</span><span class='op'>)</span></span>
<span><span class='va'>background</span> <span class='op'>&lt;-</span> <span class='fu'>EBImage</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/EBImage/man/io.html'>readImage</a></span><span class='op'>(</span><span class='st'>"figures/background.jpg"</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Displaying the microbead image</span></span>
<span><span class='fu'>EBImage</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/EBImage/man/display.html'>display</a></span><span class='op'>(</span><span class='va'>beads</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Combining the foreground and background images and arranging them in 2 rows</span></span>
<span><span class='fu'>pliman</span><span class='fu'>::</span><span class='fu'><a href='https://nepem-ufsc.github.io/pliman/reference/image_combine.html'>image_combine</a></span><span class='op'>(</span><span class='va'>foreground</span>, <span class='va'>background</span>, nrow <span class='op'>=</span> <span class='fl'>2</span>, col <span class='op'>=</span> <span class='st'>"transparent"</span><span class='op'>)</span></span></code></pre>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pliman1"></span>
<img src="RJ-2025-030_files/figure-html5/pliman1-1.png" alt="Preparing Segmentation using pliman: The image comprises two sections. On the left, an image of microbeads is displayed. On the right, a cropped view from the same image illustrates two states for segmentation: the microbead (foreground) in red, and the background is shown in black, emphasizing the clear division needed for segmentation analysis." width="49%" /><img src="RJ-2025-030_files/figure-html5/pliman1-2.png" alt="Preparing Segmentation using pliman: The image comprises two sections. On the left, an image of microbeads is displayed. On the right, a cropped view from the same image illustrates two states for segmentation: the microbead (foreground) in red, and the background is shown in black, emphasizing the clear division needed for segmentation analysis." width="49%" />
<p class="caption">
Figure 3: <strong>Preparing Segmentation using <code>pliman</code></strong>: The image comprises two sections. On the left, an image of microbeads is displayed. On the right, a cropped view from the same image illustrates two states for segmentation: the microbead (foreground) in red, and the background is shown in black, emphasizing the clear division needed for segmentation analysis.
</p>
</div>
</div>

<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># Performing segmentation based on provided background and foreground images</span></span>
<span><span class='fu'><a href='https://nepem-ufsc.github.io/pliman/reference/analyze_objects.html'>analyze_objects</a></span><span class='op'>(</span></span>
<span>  img <span class='op'>=</span> <span class='va'>beads</span>,               <span class='co'># Main image of microbeads</span></span>
<span>  background <span class='op'>=</span> <span class='va'>background</span>,   <span class='co'># Background sample image</span></span>
<span>  foreground <span class='op'>=</span> <span class='va'>foreground</span>,   <span class='co'># Foreground sample image</span></span>
<span>  marker <span class='op'>=</span> <span class='st'>"id"</span>,             <span class='co'># Displaying enumeration</span></span>
<span>  contour_col <span class='op'>=</span> <span class='st'>"yellow"</span>     <span class='co'># Color for the contour of the segmented objects</span></span>
<span><span class='op'>)</span></span></code></pre>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pliman2"></span>
<img src="RJ-2025-030_files/figure-html5/pliman2-1.png" alt="Segmentation Results using pliman: The image depicts the segmentation results obtained via the pliman analyze_objects() function. It displays the contours of the segmented objects, outlined in yellow. Each distinct object within the segmentation is numbered, facilitating its identification." width="69%" />
<p class="caption">
Figure 4: <strong>Segmentation Results using <code>pliman</code></strong>: The image depicts the segmentation results obtained via the <code>pliman</code> <code>analyze_objects()</code> function. It displays the contours of the segmented objects, outlined in yellow. Each distinct object within the segmentation is numbered, facilitating its identification.
</p>
</div>
</div>
<h3 data-number="4.3" id="fieldimager-an-r-package-for-the-analysis-of-drone-captured-images"><span class="header-section-number">4.3</span> <code>FIELDimageR</code>: an <code>R</code> package for the analysis of drone-captured images</h3>
<p>The <code>FIELDimageR</code> package, is an <code>R</code> package designed for the specific purpose
of analyzing drone-captured images from agricultural field trials. The package
offers a variety of functions for ROI selection, the extraction of
foregrounds (Figure <a href="#fig:FIELD1">5</a>), watershed segmentation, quantification
and shape analysis <span class="citation" data-cites="Matias2020">(<a href="#ref-Matias2020" role="doc-biblioref">Matias et al. 2020</a>)</span>. The developers have applied this package to
analyze pollen, which visually resembles cells under a microscope. This suggests
that <code>FIELDimageR</code> may be applicable for use in microbiological image analysis.
For the spatial analysis, the package utilizes the <code>terra</code> package
<span class="citation" data-cites="Matias2020">(<a href="#ref-Matias2020" role="doc-biblioref">Matias et al. 2020</a>)</span>.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<p>To showcase the functionalities of the <code>FIELDimageR</code> package and its parallels
with biological applications, the same microbead image is subjected to analysis.
The image is initially transformed into a ‘SpatRaster’ object and then segmented
using an intensity threshold (Figure <a href="#fig:FIELD1">5</a>). The microbeads are
correctly identified as the foreground objects by the <code>fieldMask()</code> function.
Subsequently, a distinct labeling ID is assigned to each microbead, as
illustrated by a color gradient. Moreover, the contours of each individual
object are displayed (Figure <a href="#fig:FIELD2">6</a>). The results of the segmentation
and the extraction of shape-related information are presented in the interactive
<code>leaflet</code> interface (Figure <a href="#fig:leafletPDF"><strong>??</strong></a>). Presenting information like
cluster ID, size, perimeter and width of the detected objects.</p>

<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># Loading necessary packages</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>FIELDimageR</span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/filipematias23/FIELDimageR.Extra'>FIELDimageR.Extra</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://rspatial.org/'>terra</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://r-spatial.github.io/sf/'>sf</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/r-spatial/leafsync'>leafsync</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/r-spatial/mapview'>mapview</a></span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Using the same image as imported in the previous example</span></span>
<span><span class='co'># Creating a SpatRaster object using the 'terra' package</span></span>
<span><span class='va'>EX.P</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rspatial.github.io/terra/reference/rast.html'>rast</a></span><span class='op'>(</span><span class='st'>"figures/beads2.jpg"</span><span class='op'>)</span></span>
<span><span class='va'>EX.P</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/FIELDimageR/man/imgLAB.html'>imgLAB</a></span><span class='op'>(</span><span class='va'>EX.P</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<pre><code>[1] &quot;3 layers available&quot;</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># Removing background based on a vegetation index</span></span>
<span><span class='va'>EX.P.R1</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/pkg/FIELDimageR/man/fieldMask.html'>fieldMask</a></span><span class='op'>(</span></span>
<span>    mosaic <span class='op'>=</span> <span class='va'>EX.P</span>,    <span class='co'># Input SpatRaster object</span></span>
<span>    index <span class='op'>=</span> <span class='st'>"BIM"</span>,    <span class='co'># Index representing vegetation</span></span>
<span>    cropValue <span class='op'>=</span> <span class='fl'>5</span>,    <span class='co'># Threshold value for the index</span></span>
<span>    cropAbove <span class='op'>=</span> <span class='cn'>F</span>     <span class='co'># Indicates to remove values below the threshold</span></span>
<span>  <span class='op'>)</span></span>
<span></span>
<span><span class='co'># Displaying the original, background, and foreground images</span></span>
<span><span class='va'>EX.P.R1</span><span class='op'>$</span><span class='va'>newMosaic</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:FIELD1"></span>
<img src="figures/FIELDimageR1_1.png" alt="Displaying the original, background, and foreground Images: The original image (left) shows the fluorescent microbeads. The middle image displays the background in white (TRUE) and all objects detected by segmentation in black (FALSE). The right image shows only the foreground (microbeads) after detection through segmentation using the fieldMASK() function." width="100%" />
<p class="caption">
Figure 5: <strong>Displaying the original, background, and foreground Images</strong>: The original image (left) shows the fluorescent microbeads. The middle image displays the background in white (TRUE) and all objects detected by segmentation in black (FALSE). The right image shows only the foreground (microbeads) after detection through segmentation using the <code>fieldMASK()</code> function.
</p>
</div>
</div>

<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># Labeling of all microbeads</span></span>
<span><span class='va'>EX.P.Total</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/FIELDimageR/man/fieldCount.html'>fieldCount</a></span><span class='op'>(</span>mosaic <span class='op'>=</span> <span class='va'>EX.P.R1</span><span class='op'>$</span><span class='va'>mask</span>, plot <span class='op'>=</span> <span class='cn'>T</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:FIELD2"></span>
<img src="figures/FIELDimageR2_1.png" alt="Labeling of Microbeads: The fieldCount() function is used to label individual microbeads. This function utilizes the mask produced in the previous section to identify the objects. The left image displays the labeling with a color gradient indicating distinct objects. On the right, the object contours are shown. The output of the function includes more than just the labeling value (named ID in this package); it also provides information on area, perimeter, width, and geometry of the detected objects." width="100%" />
<p class="caption">
Figure 6: <strong>Labeling of Microbeads</strong>: The <code>fieldCount()</code> function is used to label individual microbeads. This function utilizes the mask produced in the previous section to identify the objects. The left image displays the labeling with a color gradient indicating distinct objects. On the right, the object contours are shown. The output of the function includes more than just the labeling value (named ID in this package); it also provides information on area, perimeter, width, and geometry of the detected objects.
</p>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># Combining the 'FIELDimageR.Extra', 'mapview' and 'leafsync' to create an </span></span>
<span><span class='co'># interactive view</span></span>
<span><span class='va'>m1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/FIELDimageR.Extra/man/fieldView.html'>fieldView</a></span><span class='op'>(</span><span class='va'>EX.P</span>, r <span class='op'>=</span> <span class='fl'>1</span>, g <span class='op'>=</span> <span class='fl'>2</span>, b <span class='op'>=</span> <span class='fl'>3</span><span class='op'>)</span></span>
<span><span class='va'>m2</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://r-spatial.github.io/mapview/reference/mapView.html'>mapview</a></span><span class='op'>(</span><span class='va'>EX.P.Total</span><span class='op'>)</span></span>
<span><span class='fu'><a href='https://rdrr.io/pkg/leafsync/man/latticeView.html'>sync</a></span><span class='op'>(</span><span class='va'>m1</span>, <span class='va'>m2</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<!-- (ref:leafletPDF) **Displaying Results with an Interactive `leaflet` Tool**: The tool displays the original image on the left. For comparison, the cursor is mirrored to the corresponding image (only visible in HTML format). The left image provides detailed information interactively. Hovering over the objects reveals their labeling ID. Performing a left-click opens a detailed window providing information for the individual object, such as area, perimeter, width, and shape. The packages `FIELDimageR.Extra`, `mapview`, and `leafsync` are used to create the interactive display. -->
<div class="layout-chunk" data-layout="l-body">
<p>[1] “Starting analysis …”
[1] “End!”</p>
<div style="display:inline;width:49%;float:left;border-style:solid;border-color:#BEBEBE;border-width:1px 1px 1px 1px;">
<div class="leaflet html-widget html-fill-item" id="htmlwidget-7215" style="width:100%;height:400px;"></div>
<script type="application/json" data-for="htmlwidget-7215">{"x":{"options":{"minZoom":1,"maxZoom":52,"crs":{"crsClass":"L.CRS.EPSG3857","code":null,"proj4def":null,"projectedBounds":null,"options":{}},"preferCanvas":false,"bounceAtZoomLimits":false,"maxBounds":[[[-90,-370]],[[90,370]]]},"calls":[{"method":"addProviderTiles","args":["CartoDB.Positron","CartoDB.Positron","CartoDB.Positron",{"errorTileUrl":"","noWrap":false,"detectRetina":false,"pane":"tilePane"}]},{"method":"addProviderTiles","args":["CartoDB.DarkMatter","CartoDB.DarkMatter","CartoDB.DarkMatter",{"errorTileUrl":"","noWrap":false,"detectRetina":false,"pane":"tilePane"}]},{"method":"addProviderTiles","args":["OpenStreetMap","OpenStreetMap","OpenStreetMap",{"errorTileUrl":"","noWrap":false,"detectRetina":false,"pane":"tilePane"}]},{"method":"addProviderTiles","args":["Esri.WorldImagery","Esri.WorldImagery","Esri.WorldImagery",{"errorTileUrl":"","noWrap":false,"detectRetina":false,"pane":"tilePane"}]},{"method":"addProviderTiles","args":["OpenTopoMap","OpenTopoMap","OpenTopoMap",{"errorTileUrl":"","noWrap":false,"detectRetina":false,"pane":"tilePane"}]},{"method":"addLayersControl","args":[["CartoDB.Positron","CartoDB.DarkMatter","OpenStreetMap","Esri.WorldImagery","OpenTopoMap"],[],{"collapsed":true,"autoZIndex":true,"position":"topleft"}]},{"method":"addScaleBar","args":[{"maxWidth":100,"metric":true,"imperial":true,"updateWhenIdle":true,"position":"bottomleft"}]},{"method":"addGeotiff","args":[null,"file4330b702e5ec8","file4330b702e5ec8",96,[0,1,2],null,0.8,{"minZoom":0,"maxZoom":18,"tileSize":256,"subdomains":"abc","errorTileUrl":"","tms":false,"noWrap":false,"zoomOffset":0,"zoomReverse":false,"opacity":1,"zIndex":1,"detectRetina":false},{"palette":null,"breaks":null,"domain":null,"na.color":"#bebebe22"},true,"",true,{"className":"info legend","position":"topright","type":"mousemove","digits":null,"prefix":"Layer","noData":"NoData Value","imagequery":true}]}],"setView":[[50.814772,8.770861999999999],18,[]]},"evals":["calls.7.args.10"],"jsHooks":{"render":[{"code":"function(el, x, data) {\n  return (\n      function(el, x, data) {\n      // get the leaflet map\n      var map = this; //HTMLWidgets.find('#' + el.id);\n      // we need a new div element because we have to handle\n      // the mouseover output separately\n      // debugger;\n      function addElement () {\n      // generate new div Element\n      var newDiv = $(document.createElement('div'));\n      // append at end of leaflet htmlwidget container\n      $(el).append(newDiv);\n      //provide ID and style\n      newDiv.addClass('lnlt');\n      newDiv.css({\"position\":\"relative\",\"bottomleft\":\"0px\",\"background-color\":\"rgba(255, 255, 255, 0.7)\",\"box-shadow\":\"0 0 2px #bbb\",\"background-clip\":\"padding-box\",\"margin\":\"0\",\"padding-left\":\"5px\",\"padding-right\":\"5px\",\"color\":\"#333\",\"font-size\":\"9px\",\"font-family\":\"\\\"Helvetica Neue\\\", Arial, Helvetica, sans-serif\",\"text-align\":\"left\",\"z-index\":\"700\"});\n      return newDiv;\n      }\n\n\n      // check for already existing lnlt class to not duplicate\n      var lnlt = $(el).find('.lnlt');\n\n      if(!lnlt.length) {\n      lnlt = addElement();\n\n      // grab the special div we generated in the beginning\n      // and put the mousmove output there\n\n      map.on('mousemove', function (e) {\n      if (e.originalEvent.ctrlKey) {\n      if (document.querySelector('.lnlt') === null) lnlt = addElement();\n      lnlt.text(\n                           ' lon: ' + (e.latlng.lng).toFixed(5) +\n                           ' | lat: ' + (e.latlng.lat).toFixed(5) +\n                           ' | zoom: ' + map.getZoom() +\n                           ' | x: ' + L.CRS.EPSG3857.project(e.latlng).x.toFixed(0) +\n                           ' | y: ' + L.CRS.EPSG3857.project(e.latlng).y.toFixed(0) +\n                           ' | epsg: 3857 ' +\n                           ' | proj4: +proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +no_defs ');\n      } else {\n      if (document.querySelector('.lnlt') === null) lnlt = addElement();\n      lnlt.text(\n                      ' lon: ' + (e.latlng.lng).toFixed(5) +\n                      ' | lat: ' + (e.latlng.lat).toFixed(5) +\n                      ' | zoom: ' + map.getZoom() + ' ');\n      }\n      });\n\n      // remove the lnlt div when mouse leaves map\n      map.on('mouseout', function (e) {\n      var strip = document.querySelector('.lnlt');\n      if( strip !==null) strip.remove();\n      });\n\n      };\n\n      //$(el).keypress(67, function(e) {\n      map.on('preclick', function(e) {\n      if (e.originalEvent.ctrlKey) {\n      if (document.querySelector('.lnlt') === null) lnlt = addElement();\n      lnlt.text(\n                      ' lon: ' + (e.latlng.lng).toFixed(5) +\n                      ' | lat: ' + (e.latlng.lat).toFixed(5) +\n                      ' | zoom: ' + map.getZoom() + ' ');\n      var txt = document.querySelector('.lnlt').textContent;\n      console.log(txt);\n      //txt.innerText.focus();\n      //txt.select();\n      setClipboardText('\"' + txt + '\"');\n      }\n      });\n\n      }\n      ).call(this.getMap(), el, x, data);\n}","data":null},{"code":"function(el, x, data) {\n  return (function(el,x,data){\n           var map = this;\n\n           map.on('keypress', function(e) {\n               console.log(e.originalEvent.code);\n               var key = e.originalEvent.code;\n               if (key === 'KeyE') {\n                   var bb = this.getBounds();\n                   var txt = JSON.stringify(bb);\n                   console.log(txt);\n\n                   setClipboardText('\\'' + txt + '\\'');\n               }\n           })\n        }).call(this.getMap(), el, x, data);\n}","data":null}]}}</script>
</div>
<div style="display:inline;width:49%;float:left;border-style:solid;border-color:#BEBEBE;border-width:1px 1px 1px 1px;">
<div class="leaflet html-widget html-fill-item" id="htmlwidget-8208" style="width:100%;height:400px;"></div>
<script type="application/json" data-for="htmlwidget-8208">{"x":{"options":{"minZoom":1,"maxZoom":52,"crs":{"crsClass":"L.CRS.EPSG3857","code":null,"proj4def":null,"projectedBounds":null,"options":{}},"preferCanvas":false,"bounceAtZoomLimits":false,"maxBounds":[[[-90,-370]],[[90,370]]]},"calls":[{"method":"addProviderTiles","args":["CartoDB.Positron","CartoDB.Positron","CartoDB.Positron",{"errorTileUrl":"","noWrap":false,"detectRetina":false,"pane":"tilePane"}]},{"method":"addProviderTiles","args":["CartoDB.DarkMatter","CartoDB.DarkMatter","CartoDB.DarkMatter",{"errorTileUrl":"","noWrap":false,"detectRetina":false,"pane":"tilePane"}]},{"method":"addProviderTiles","args":["OpenStreetMap","OpenStreetMap","OpenStreetMap",{"errorTileUrl":"","noWrap":false,"detectRetina":false,"pane":"tilePane"}]},{"method":"addProviderTiles","args":["Esri.WorldImagery","Esri.WorldImagery","Esri.WorldImagery",{"errorTileUrl":"","noWrap":false,"detectRetina":false,"pane":"tilePane"}]},{"method":"addProviderTiles","args":["OpenTopoMap","OpenTopoMap","OpenTopoMap",{"errorTileUrl":"","noWrap":false,"detectRetina":false,"pane":"tilePane"}]},{"method":"createMapPane","args":["polygon",420]},{"method":"addPolygons","args":[[[[{"lng":[-28.01189290324126,-28.0118903499322,-28.01187256034289,-28.01187511364705,-28.01189290324126],"lat":[60.200279932531,60.20027107692592,60.20027234795408,60.20028120355953,60.200279932531]}]],[[{"lng":[-28.01144816295493,-28.01144560976844,-28.01146339939223,-28.01145318664104,-28.01143539703685,-28.01143029067968,-28.01141250108387,-28.01140994791234,-28.01139215832,-28.01138960515481,-28.01128286759997,-28.01128542073574,-28.01124984152949,-28.011257500916,-28.01123971129601,-28.01125247694442,-28.01144816295493],"lat":[60.20031170749737,60.20030285188302,60.20030158091461,60.20026615845909,60.20026742942602,60.20024971819778,60.20025098916147,60.20024213354702,60.20024340450786,60.2002345488931,60.20024217460352,60.20025103022051,60.20025357210481,60.20028013895824,60.20028140989776,60.20032568798955,60.20031170749737]}]],[[{"lng":[-28.01171747727359,-28.01171492401727,-28.0117505031586,-28.01174794989392,-28.01176573945753,-28.01176318618938,-28.01178097574665,-28.01177586920486,-28.01179365875088,-28.01177833913058,-28.01176054961397,-28.01175799635385,-28.01174020684071,-28.01173765358693,-28.01171986407725,-28.01171731082982,-28.01169952132361,-28.0116969680825,-28.01159023104448,-28.01159278425617,-28.0115572052222,-28.01156231163026,-28.01154452210131,-28.01154962850531,-28.01153183896512,-28.01154460497577,-28.01156239454047,-28.0115675009646,-28.01158529053767,-28.01158784375679,-28.01160563333333,-28.01160818655879,-28.01164376571737,-28.01164631895406,-28.01171747727359],"lat":[60.20023823804831,60.20022938244015,60.20022684042562,60.20021798481825,60.20021671380762,60.20020785820066,60.20020658718791,60.20018887597486,60.20018760496036,60.20013447132445,60.20013574233671,60.20012688673052,60.20012815773992,60.20011930213338,60.20012057313992,60.20011171753306,60.20011298853674,60.20010413292954,60.20011175889712,60.20012061450655,60.20012315647656,60.20014086769699,60.20014213867901,60.20015984990038,60.20016112088065,60.20020539893666,60.20020412795454,60.20022183917651,60.20022056819115,60.20022942380182,60.20022815281361,60.20023700842395,60.20023446643931,60.20024332204896,60.20023823804831]}]],[[{"lng":[-28.01238811956793,-28.01238556614365,-28.01240335554335,-28.01239824868929,-28.01241603807775,-28.01241348464797,-28.01243127403009,-28.01241850687826,-28.01240071752066,-28.01239561067979,-28.01237782133056,-28.01237526791718,-28.0123396892242,-28.01233713582207,-28.012248189089,-28.01225074246662,-28.01221516375352,-28.01222027049346,-28.01220248112496,-28.01220503449217,-28.01218724511732,-28.01220001195048,-28.01221780134984,-28.01222290810296,-28.01224069751069,-28.01224325089431,-28.01227882971527,-28.01228138311013,-28.01238811956793],"lat":[60.19998244611765,60.1999735905257,60.19997231942612,60.19995460824308,60.19995333714176,60.19994448155067,60.19994321044722,60.19989893249429,60.19990020359587,60.19988249241425,60.1998837635126,60.19987490792148,60.19987745010997,60.19986859451814,60.19987494994395,60.19988380553762,60.19988634769124,60.19990405888019,60.19990532995403,60.19991418554893,60.19991545662064,60.19995973459771,60.19995846352415,60.19997617471454,60.19997490363774,60.19998375923264,60.19998121707084,60.19999007266503,60.19998244611765]}]],[[{"lng":[-28.01184677693434,-28.01184422366146,-28.01187980251623,-28.01187724923497,-28.0118950386553,-28.01189248537058,-28.01191027478457,-28.01190772149639,-28.01192551090403,-28.01191019117568,-28.01189240179745,-28.01188984851933,-28.01187205914456,-28.01186950587278,-28.01185171650148,-28.01184916323604,-28.0118313738682,-28.0118288206091,-28.0117398737729,-28.01174242700749,-28.01172463763104,-28.01172719086216,-28.01170940147937,-28.01171195470703,-28.0116941653179,-28.01169671854209,-28.01167892914662,-28.01169424849255,-28.01171203791744,-28.01171459115169,-28.01173238058004,-28.01173493382064,-28.01175272325246,-28.01175527649939,-28.01179085536853,-28.0117934086267,-28.01184677693434],"lat":[60.19999401114892,60.19998515554595,60.19998261349596,60.19997375789378,60.19997248686542,60.19996363126364,60.19996236023316,60.19995350463181,60.19995223359919,60.1998990999942,60.19990037102458,60.19989151542352,60.19989278645104,60.19988393084966,60.19988520187432,60.19987634627261,60.1998776172944,60.19986876169236,60.19987511676212,60.19988397236601,60.19988524337288,60.19989409897718,60.1998953699819,60.19990422558663,60.19990549658924,60.19991435219438,60.19991562319487,60.19996875682882,60.19996748582609,60.19997634143154,60.19997507042595,60.19998392603107,60.19998265502262,60.19999151062739,60.19998896860229,60.19999782420636,60.19999401114892]}]],[[{"lng":[-28.01300802264675,-28.01300546906263,-28.01302325833561,-28.01301815116186,-28.0130359404236,-28.01301806532643,-28.01300027609901,-28.01299772252435,-28.01297993330039,-28.01297737973207,-28.01295959051158,-28.0129570369496,-28.01301040459206,-28.01300785101681,-28.01304342942812,-28.01303832226233,-28.01305611145602,-28.01304845070339,-28.01306623988094,-28.01306368629471,-28.01304589712205,-28.01303823638668,-28.0130204472273,-28.01301789365662,-28.0130001045007,-28.01299755093636,-28.01292639431795,-28.01292384077466,-28.01290605162137,-28.01289583748217,-28.01291362661585,-28.01291107307974,-28.01289328395096,-28.01288562336596,-28.01286783425045,-28.0128652807299,-28.01284749161786,-28.01284493810364,-28.01280935988505,-28.01280680638208,-28.01275343905812,-28.01275599254639,-28.01272041431343,-28.01272296779333,-28.01270517866979,-28.01270773214623,-28.01268994301634,-28.01269504996371,-28.0126772608226,-28.01268492123972,-28.01270271039555,-28.01271037084032,-28.01272816000942,-28.01273071349878,-28.01274850267135,-28.01275105616706,-28.01276884534309,-28.01277395234861,-28.01275616316278,-28.01275871666279,-28.01274092747062,-28.01274348096717,-28.01272569176866,-28.01274101274873,-28.01275880197666,-28.01276135548327,-28.01277914471467,-28.01278169822762,-28.01279948746248,-28.01280204098178,-28.01281983022011,-28.01282493727281,-28.01280714802467,-28.01281991565705,-28.0128377049297,-28.01284025846539,-28.01285804774151,-28.01286060128354,-28.01287839056312,-28.01288094411149,-28.01289873339453,-28.01290128694924,-28.01300802264675],"lat":[60.19980258009252,60.19979372451493,60.1997924533288,60.1997747421745,60.19977347098661,60.19971148195054,60.19971275313583,60.19970389755904,60.19970516874145,60.19969631316435,60.1996975843439,60.19968872876647,60.19968491522142,60.19967605964514,60.19967351727007,60.19965580611912,60.1996545349286,60.19962796820359,60.19962669701169,60.19961784143715,60.19961911262869,60.1995925459042,60.19959381709214,60.19958496151701,60.19958623270207,60.19957737712663,60.19958246184052,60.19957360626363,60.19957487743552,60.19953945512692,60.19953818395653,60.19952932837986,60.19953059954988,60.19950403281901,60.19950530398542,60.19949644840818,60.19949771957174,60.19948886399418,60.19949140631307,60.19948255073479,60.19948636419334,60.19949521977272,60.19949776206672,60.19950661764689,60.19950788879053,60.1995167443711,60.19951801551262,60.19953572667465,60.19953699781442,60.19956356455891,60.19956229341802,60.19958886016178,60.19958758901731,60.19959644459828,60.19959517345092,60.19960402903156,60.19960275788136,60.19962046904203,60.19962174019297,60.19963059577374,60.19963186692257,60.19964072250376,60.19964199365046,60.19969512714067,60.19969385599174,60.19970271157321,60.19970144042141,60.19971029600258,60.19970902484791,60.19971788042874,60.19971660927122,60.19973432043226,60.19973559159052,60.19977986949571,60.19977859833558,60.19978745391639,60.19978618275341,60.19979503833387,60.19979376716802,60.19980262274816,60.19980135157945,60.19981020715927,60.19980258009252]}]],[[{"lng":[-28.01332567575646,-28.01332312208552,-28.01334091132773,-28.01333835765333,-28.0133561468892,-28.01335359321133,-28.01337138244087,-28.01335606037441,-28.01333827117429,-28.01333571750648,-28.01331792830983,-28.01331537464836,-28.01329758545517,-28.01329503180004,-28.01325945341917,-28.01325689977528,-28.01323911058759,-28.01324166422657,-28.01318829664017,-28.01319085026588,-28.01317306106263,-28.01317561468488,-28.0131578254753,-28.01316037909408,-28.01314258987815,-28.01316046521556,-28.0131782544658,-28.01318080809608,-28.01321638660206,-28.01321894024359,-28.01332567575646],"lat":[60.19977084278354,60.19976198721267,60.19976071598209,60.19975186041166,60.19975058917894,60.19974173360892,60.19974046237409,60.19968732895704,60.19968860018965,60.19967974461991,60.19968101584964,60.19967216027957,60.19967343150644,60.19966457593607,60.19966711838158,60.19965826281051,60.19965953402916,60.19966838960062,60.19967220324278,60.19968105881539,60.19968233002482,60.19969118559786,60.19969245680518,60.19970131237864,60.19970258358384,60.19976457260173,60.19976330139393,60.19977215696771,60.1997696145439,60.19977847011697,60.19977084278354]}]],[[{"lng":[-28.01477161889632,-28.01476906483055,-28.01482243212575,-28.01481987804672,-28.01483766713734,-28.01483511305483,-28.01485290213912,-28.01483757764484,-28.01481978858997,-28.01481468044652,-28.01479689140002,-28.01479433733535,-28.01475875924784,-28.01475620519441,-28.01470283806707,-28.01470539210579,-28.01466981400391,-28.01467236803426,-28.01465457897626,-28.01465713300314,-28.0146393439388,-28.01464445198707,-28.01462666291149,-28.01463432497998,-28.01465211407027,-28.01465722213292,-28.01467501123158,-28.01467756526997,-28.01469535437209,-28.01469790841681,-28.01473348662655,-28.01473604068252,-28.01477161889632],"lat":[60.19962231587426,60.19961346033406,60.19960964602787,60.19960079048883,60.19959951904882,60.19959066351019,60.19958939206807,60.19953625883941,60.19953753027931,60.19951981920268,60.19952109063937,60.19951223510073,60.19951477796586,60.19950592242654,60.19950973670443,60.19951859224486,60.19952113508508,60.19952999062629,60.19953126204304,60.19954011758466,60.19954138899929,60.19955910008343,60.19956037149629,60.19958693812393,60.19958566670994,60.1996033777945,60.19960210637726,60.19961096191924,60.19960969049915,60.1996185460408,60.1996160031924,60.19962485873337,60.19962231587426]}]],[[{"lng":[-28.01503590117722,-28.01503334703935,-28.01506892518466,-28.01506381689362,-28.01508160595431,-28.01507394351382,-28.01514509968339,-28.01514254551983,-28.01517812358619,-28.01517556941425,-28.01519335844038,-28.01518569591849,-28.01520348492847,-28.01519582240481,-28.01517803340954,-28.01517292507743,-28.01515513609053,-28.01515258193153,-28.0151347929481,-28.01513223879544,-28.01509666083406,-28.01509410669265,-28.01504073975451,-28.01504329388122,-28.01500771590547,-28.0150102700238,-28.01499248102887,-28.01499503514374,-28.01497724614246,-28.01498235436672,-28.0149645653542,-28.01496711946358,-28.01494933044473,-28.01495188455064,-28.01489851747074,-28.01490107156338,-28.01488328252897,-28.01488583661815,-28.0148680475774,-28.01487315575027,-28.01485536669827,-28.01486558304165,-28.01488337211326,-28.01488848030338,-28.01490626938335,-28.01490882348547,-28.0149444016509,-28.01494695576426,-28.01503590117722],"lat":[60.19959438857901,60.19958553304442,60.19958299010217,60.19956527903459,60.19956400756048,60.19953744096056,60.19953235504362,60.19952349951189,60.19952095653922,60.19951210100828,60.19951082951857,60.19948426292712,60.19948299143605,60.19945642484606,60.19945769633603,60.19943998527552,60.19944125676226,60.19943240123168,60.19943367271555,60.19942481718466,60.19942736014416,60.19941850461258,60.19942231903207,60.19943117456477,60.19943371749939,60.19944257303288,60.19944384449683,60.19945270003073,60.19945397149255,60.19947168256122,60.19947295402132,60.19948180955608,60.19948308101404,60.19949193654923,60.19949575090929,60.19950460644563,60.19950587789439,60.19951473343114,60.19951600487775,60.19953371595216,60.19953498739703,60.19957040954781,60.19956913810145,60.19958684917635,60.19958557772676,60.1995944332639,60.19959189035649,60.19960074589294,60.19959438857901]}]],[[{"lng":[-28.01175757984114,-28.01175502660824,-28.01179060526284,-28.01178549878173,-28.01180328809707,-28.01178796865883,-28.01177017937291,-28.01176762614313,-28.01174983686068,-28.01174728363724,-28.01172949435825,-28.01172694114116,-28.01162020546647,-28.01162275865414,-28.0116049693651,-28.01160752254931,-28.01158973325392,-28.01159483961685,-28.01157705031022,-28.01158981621818,-28.01160760554932,-28.01161015874013,-28.01162794807474,-28.01163050127189,-28.01164829060996,-28.01165084381345,-28.01175757984114],"lat":[60.19981058552082,60.19980172991801,60.19979918789355,60.19978147668953,60.19978020567432,60.19972707206555,60.19972834307855,60.19971948747686,60.199720758487,60.19971190288499,60.19971317389226,60.19970431828991,60.19971194427902,60.19972079988359,60.19972207087342,60.19973092647842,60.19973219746612,60.19974990867696,60.19975117966293,60.19979545769262,60.19979418670478,60.19980304231048,60.1998017713198,60.19981062692516,60.19980935593161,60.19981821153664,60.19981058552082]}]],[[{"lng":[-28.0120142064669,-28.0120116531662,-28.01202944245306,-28.0120268891489,-28.0120446784294,-28.01204212512178,-28.01205991439595,-28.01204204124848,-28.01202425200863,-28.01202169871249,-28.01200390947611,-28.01200135618631,-28.01198356695339,-28.01198101366995,-28.01187427827166,-28.01187683152569,-28.0118412530383,-28.01184635953107,-28.01182857027541,-28.01183623001063,-28.01181844073883,-28.01182099398187,-28.01183878325858,-28.01184899626475,-28.01186678555963,-28.01186933881966,-28.01190491741492,-28.0119074706862,-28.0120142064669],"lat":[60.19975609770034,60.19974724210326,60.19974597105642,60.19973711545975,60.1997358444108,60.19972698881456,60.19972571776346,60.19966372859356,60.19966499964205,60.19965614404614,60.19965741509178,60.19964855949554,60.19964983053831,60.19964097494176,60.19964860114383,60.19965745674261,60.19965999879079,60.19967770998997,60.19967898101107,60.19970554781128,60.199706818831,60.19971567443152,60.19971440341143,60.19974982581248,60.19974855478842,60.19975741038842,60.19975486833206,60.19976372393135,60.19975609770034]}]],[[{"lng":[-28.01224538286552,-28.01224282950625,-28.01229619719918,-28.01229364382663,-28.01231143304983,-28.01230887967382,-28.01232666889068,-28.01231900875655,-28.01233679795727,-28.01233169119857,-28.01231390200766,-28.01230879526451,-28.01229100608197,-28.01228589935437,-28.0122681101802,-28.01226555682346,-28.01215882177766,-28.01216137510499,-28.01212579673509,-28.01212835005404,-28.01211056086203,-28.01211822081281,-28.01210043160466,-28.01210553823589,-28.01212332745385,-28.01213098742618,-28.01214877665741,-28.0121513299893,-28.01216911922399,-28.01217167256222,-28.01222504027239,-28.01222759362677,-28.01224538286552],"lat":[60.19967631367045,60.19966745807888,60.19966364483408,60.19965478924365,60.19965351815745,60.19964466256744,60.19964339147911,60.19961682471047,60.19961555362077,60.19959784244264,60.19959911353159,60.19958140235288,60.19958267343861,60.19956496225934,60.19956623334183,60.19955737775189,60.19956500419234,60.19957385978452,60.19957640191217,60.19958525750512,60.19958652856558,60.19961309534583,60.19961436640491,60.1996320775927,60.19963080653287,60.19965737331376,60.19965610225034,60.19966495784369,60.1996636867774,60.19967254237042,60.1996687291555,60.19967758474745,60.19967631367045]}]],[[{"lng":[-28.01440790871423,-28.0144053547663,-28.01442314377292,-28.01442058982152,-28.01443837882179,-28.01443327091351,-28.01445105990254,-28.01443573618276,-28.01441794722315,-28.01441539327979,-28.01439760432363,-28.01439505038661,-28.01437726143393,-28.01437470750324,-28.01428576274277,-28.01428831664894,-28.01425273872488,-28.01425529262269,-28.0142375036536,-28.01424261144371,-28.01422482246339,-28.0142375919393,-28.01425538094414,-28.01425793484854,-28.01427572385685,-28.01427827776759,-28.01429606677936,-28.01429862069644,-28.01431640971168,-28.01431896363509,-28.01440790871423],"lat":[60.19943139675455,60.19942254120906,60.1994212698274,60.19941241428234,60.19941114289854,60.19939343180926,60.19939216042373,60.19933902715917,60.19934029854248,60.19933144299816,60.19933271437861,60.19932385883396,60.19932513021154,60.19931627466657,60.19932263151527,60.1993314870621,60.1993340297849,60.19934288533253,60.19934415669056,60.19936186778666,60.19936313914294,60.19940741688579,60.19940614552765,60.19941500107597,60.19941372971498,60.19942258526298,60.19942131389912,60.19943016944678,60.19942889808006,60.19943775362739,60.19943139675455]}]],[[{"lng":[-28.01482462834016,-28.01482207428032,-28.01483986323283,-28.01483475510765,-28.01485254404891,-28.01483721967846,-28.01481943076661,-28.0148168767148,-28.01479908780642,-28.01479653376095,-28.01477874485603,-28.0147761908169,-28.01468724629526,-28.01468980030987,-28.01465422248135,-28.01465933049529,-28.01464154156907,-28.01464664957894,-28.01462886064148,-28.0146339686473,-28.01465175759457,-28.0146594196288,-28.01467720858934,-28.01467976260852,-28.01469755157252,-28.01470010559805,-28.01482462834016],"lat":[60.19936546075235,60.19935660521595,60.19935533377601,60.19933762270408,60.19933635126238,60.19928321804984,60.19928448948929,60.19927563395365,60.19927690539024,60.19926804985427,60.19926932128801,60.19926046575171,60.19926682288118,60.19927567841935,60.19927822125445,60.19929593233239,60.19929720374694,60.1993149148258,60.19931618623861,60.19933389731838,60.19933262590483,60.19935919252367,60.19935792110652,60.19936677664585,60.19936550522582,60.19937436076484,60.19936546075235]}]],[[{"lng":[-28.01587162001871,-28.01586906567106,-28.01588685453385,-28.01588430018274,-28.01590208903919,-28.0158842085873,-28.01586641976517,-28.01586131108737,-28.0158257334584,-28.01582317913146,-28.01573423505838,-28.01573678936081,-28.01571900053697,-28.01572155483593,-28.01570376600576,-28.01570632030126,-28.01568853146474,-28.01570385723849,-28.01572164610442,-28.01572675471697,-28.01576233246412,-28.01576488678235,-28.01587162001871],"lat":[60.19928158599912,60.19927273048468,60.1992714588982,60.19926260338416,60.19926133179557,60.19919934320108,60.19920061478707,60.19918290375972,60.19918544692277,60.19917659140841,60.19918294927057,60.19919180478679,60.19919307635212,60.19920193186874,60.19920320343196,60.19921205894899,60.19921333051009,60.19926646361547,60.19926519205214,60.19928290308685,60.19928035995125,60.19928921546794,60.19928158599912]}]],[[{"lng":[-28.01059065369055,-28.01058810080786,-28.01060589003088,-28.01060333714472,-28.0106211263614,-28.01061857347176,-28.01063636268211,-28.01062104534509,-28.01060325616417,-28.01059815040647,-28.01058036123391,-28.01057780836211,-28.01043549496917,-28.01043804780174,-28.01042025861625,-28.01042536427591,-28.01040757507918,-28.0104228920632,-28.01044068128934,-28.01044323412994,-28.01046102335955,-28.01046357620649,-28.01048136543957,-28.01048391829285,-28.01059065369055],"lat":[60.19954147229888,60.19953261667546,60.19953134582835,60.19952249020536,60.19952121935614,60.19951236373356,60.1995110928822,60.19945795914985,60.19945922999897,60.19944151875445,60.19944278960033,60.19943393397777,60.19944410065223,60.19945295627777,60.19945422710125,60.19947193835317,60.19947320917491,60.19952634293399,60.19952507211004,60.19953392773635,60.19953265690953,60.19954151253548,60.1995402417058,60.19954909733144,60.19954147229888]}]],[[{"lng":[-28.00987389850927,-28.00987134583071,-28.00992471353118,-28.00992216083935,-28.00993995006506,-28.00993739736977,-28.00995518658914,-28.00995008119305,-28.00996787040119,-28.0099653177004,-28.00994752849716,-28.00993731772798,-28.00991952854292,-28.00991697585912,-28.00989918667754,-28.00989663400008,-28.00987884482195,-28.00987629215083,-28.00978734626318,-28.00982053078116,-28.00987389850927],"lat":[60.19951133266884,60.19950247703134,60.19949866478391,60.19948980914757,60.19948853839382,60.19947968275789,60.19947841200202,60.19946070073102,60.19945942997342,60.19945057433835,60.1994518450956,60.19941642255432,60.19941769330761,60.19940883767201,60.19941010842243,60.19940125278652,60.19940252353407,60.19939366789783,60.1994000215964,60.19951514489499,60.19951133266884]}]],[[{"lng":[-28.01356381467697,-28.01356126098441,-28.01359683881584,-28.01359428511491,-28.01361207402357,-28.01360696661621,-28.01371369997916,-28.01371114624822,-28.01372893513211,-28.0137263813977,-28.01376195915137,-28.0137594054086,-28.01377719427838,-28.01376697930205,-28.01378476815077,-28.01377966066143,-28.01379744949892,-28.01379234200551,-28.01381013083176,-28.0137922546158,-28.01377446582388,-28.01377191208939,-28.01375412330093,-28.01375156957279,-28.01371599200136,-28.01371343828446,-28.01366007193124,-28.01366262563343,-28.01360925925258,-28.01361181294151,-28.01359402414011,-28.01359913151247,-28.01358134269983,-28.01358645006813,-28.01346192827079,-28.01346448192278,-28.01342890424366,-28.01343401153234,-28.01341622268081,-28.01341877632241,-28.01340098746454,-28.01339843382786,-28.01336285611762,-28.01336030249218,-28.01328914707408,-28.01329170067992,-28.0132739118169,-28.01327646541928,-28.01325867654992,-28.01326123014882,-28.01324344127313,-28.01324854846545,-28.01323075957851,-28.01323842036306,-28.01325620926471,-28.0132613164714,-28.01327910538141,-28.01328421260366,-28.01331979043899,-28.01332234406208,-28.0133934997351,-28.01339605337923,-28.0134138422988,-28.01341894960118,-28.01345452745561,-28.01345708111876,-28.01356381467697],"lat":[60.19921154144162,60.19920268588151,60.19920014335284,60.1991912877935,60.19919001652579,60.199172305408,60.19916467775398,60.19915582219737,60.19915455091335,60.19914569535715,60.19914315278239,60.19913429722699,60.19913302593624,60.19909760371652,60.19909633242477,60.1990786213159,60.19907735002241,60.19905963891445,60.19905836761919,60.19899637874531,60.19899765003796,60.19898879448434,60.19899006577412,60.19898121022019,60.19898375279153,60.19897489723689,60.19897871107413,60.19898756662987,60.19899138044583,60.19900023600272,60.1990015072701,60.1990192183848,60.19902048965043,60.19903820076603,60.19904709956087,60.19905595512135,60.1990584976125,60.19907620873504,60.19907747997763,60.19908633553933,60.1990876067798,60.19907875121772,60.19908129369042,60.19907243812764,60.19907752304171,60.19908637860597,60.19908764982863,60.19909650539331,60.19909777661385,60.19910663217894,60.19910790339736,60.19912561452844,60.1991268857451,60.19915345244313,60.19915218122534,60.19916989235682,60.1991686211358,60.19918633226672,60.19918378981571,60.19919264538049,60.19918756044711,60.19919641601047,60.19919514477053,60.19921285589658,60.19921031340776,60.1992191689701,60.19921154144162]}]],[[{"lng":[-28.0109131677351,-28.01091061477818,-28.01094619296633,-28.01094364000105,-28.01096142908806,-28.01095887611931,-28.01097666519999,-28.01095879442462,-28.01094100537827,-28.01093589946518,-28.01090032138777,-28.01089776844319,-28.01080882324902,-28.01081137616908,-28.01079358712104,-28.01079614003764,-28.01077835098325,-28.01078090389639,-28.01076311483566,-28.01078098523352,-28.01079877432856,-28.01080132725319,-28.0108191163517,-28.01082166928267,-28.01085724748519,-28.0108598004274,-28.0109131677351],"lat":[60.19933767167478,60.19932881606001,60.19932627427358,60.1993174186596,60.19931614776303,60.19930729214946,60.19930602125076,60.19924403195962,60.19924530285572,60.19922759162935,60.19923013341259,60.19922127779871,60.19922763221142,60.19923648782714,60.19923775870259,60.19924661431873,60.19924788519205,60.19925674080861,60.19925801167981,60.19932000099953,60.19931873012573,60.19932758574262,60.19932631486596,60.19933517048254,60.199332628721,60.19934148433686,60.19933767167478]}]],[[{"lng":[-28.01193727342283,-28.01193472018587,-28.01197029817792,-28.01196774493259,-28.01198553392156,-28.01198298067277,-28.0120007696554,-28.01198289691974,-28.01196510797142,-28.01196255473412,-28.01194476578927,-28.01194221255831,-28.01190663467412,-28.0119040814544,-28.01183292568837,-28.01183547888848,-28.01179990098703,-28.01180245417877,-28.01178466522099,-28.01178977159898,-28.01177198262996,-28.01178474857556,-28.01180253756909,-28.0118076439672,-28.0118254329691,-28.01182798617521,-28.01186356418451,-28.01186611740186,-28.01193727342283],"lat":[60.19923738902325,60.19922853343014,60.1992259913571,60.19921713576478,60.19921586472489,60.19920700913298,60.19920573809097,60.19914374895144,60.19914501999084,60.19913616439928,60.19913743543583,60.19912857984393,60.19913112190882,60.19912226631624,60.19912735041463,60.19913620600872,60.19913874804371,60.19914760363857,60.19914887465271,60.19916658584331,60.19916785685569,60.19921213483478,60.19921086382053,60.19922857501173,60.19922730399424,60.19923615958954,60.19923361754638,60.19924247314094,60.19923738902325]}]],[[{"lng":[-28.01304010292968,-28.01303754939391,-28.01307312713627,-28.01306802004943,-28.01308580890866,-28.01307304119222,-28.01305525235751,-28.0130501452908,-28.01303235646446,-28.01302980293817,-28.0130120141153,-28.01300946059534,-28.01297388295509,-28.01297132944638,-28.01291796298993,-28.01292051648394,-28.01288493882932,-28.01288749231496,-28.01286970348059,-28.01287481044638,-28.01285702160077,-28.0128723425032,-28.01289013137823,-28.0128926848719,-28.01291047375039,-28.0129130272504,-28.01293081613235,-28.01293336963871,-28.01304010292968],"lat":[60.19909531992718,60.19908646435777,60.19908392197617,60.19906621083895,60.19906493964516,60.1990206618047,60.19902193299664,60.19900422186002,60.19900549304873,60.1989966374801,60.19899790866592,60.19898905309697,60.19899159546045,60.19898273989079,60.1989865534162,60.19899540898696,60.19899795132553,60.19900680689707,60.19900807806299,60.19902578920696,60.19902706037112,60.19908019380627,60.19907892263986,60.19908777821217,60.19908650704291,60.19909536261491,60.19909409144277,60.19910294701442,60.19909531992718]}]],[[{"lng":[-28.01163222397309,-28.01162967082606,-28.01164745980658,-28.01164490665609,-28.01166269563027,-28.01165758932379,-28.01167537828672,-28.01166261252116,-28.01164482358274,-28.01163971729638,-28.01162192836633,-28.01161937523021,-28.0115837973756,-28.01158124425071,-28.01152787747273,-28.0115304305829,-28.01147706377727,-28.01147961687418,-28.01146182793119,-28.01146948721581,-28.01145169825668,-28.01146191063667,-28.01147969961541,-28.01148480582384,-28.01152038379662,-28.0115254900304,-28.01163222397309],"lat":[60.19918688046388,60.19917802486518,60.1991767538727,60.19916789827442,60.19916662727983,60.19914891608413,60.19914764508779,60.19910336710115,60.19910463809563,60.19908692690052,60.19908819789178,60.19907934229391,60.19908188426821,60.19907302866964,60.19907684161129,60.19908569721095,60.19908951013131,60.19909836573213,60.19909963670096,60.19912620350482,60.19912747447228,60.19916289687949,60.19916162591056,60.19917933711368,60.19917679516682,60.19919450636863,60.19918688046388]}]],[[{"lng":[-28.01335510873463,-28.01335255511865,-28.01338813271815,-28.01338302547089,-28.01340081425868,-28.0133982606323,-28.01341604941376,-28.01340328127893,-28.01338549252198,-28.01338038528792,-28.01336259653935,-28.01336004292937,-28.01334225418427,-28.01333970058063,-28.01325075685807,-28.01325331043719,-28.0132177329283,-28.01322028649905,-28.01320249773755,-28.01320760487357,-28.01318981610082,-28.01320258394151,-28.01322037273876,-28.01322292631611,-28.01324071511684,-28.01324326870053,-28.01326105750471,-28.01326361109475,-28.01329918870862,-28.01330174230989,-28.01335510873463],"lat":[60.19899146683316,60.19898261127118,60.19898006880164,60.1989623576793,60.19896108644154,60.19895223088081,60.19895095964093,60.19890668183974,60.19890795307775,60.19889024195684,60.19889151319162,60.19888265763085,60.19888392886278,60.19887507330169,60.19888142942211,60.19889028498506,60.19889282741654,60.19890168298026,60.19890295419265,60.19892066532098,60.19892193653162,60.19896621435509,60.1989649431426,60.19897379870706,60.19897252749171,60.19898138305583,60.19898011183762,60.19898896740142,60.19898642495679,60.19899528051989,60.19899146683316]}]],[[{"lng":[-28.01430548665384,-28.01430293277888,-28.01435629888431,-28.01435374499608,-28.01437153369011,-28.01436897979842,-28.01438676848612,-28.01438421459095,-28.0144020032723,-28.01438923379354,-28.0143714451367,-28.01436633736506,-28.01434854871658,-28.01434599483782,-28.0143282061928,-28.01432565232038,-28.01429007503585,-28.01428752117467,-28.01421636660797,-28.01421892044954,-28.01420113179937,-28.01420368563748,-28.01418589698097,-28.01418845081561,-28.01417066215276,-28.0141783236506,-28.01416053497161,-28.01416564263421,-28.01418343132301,-28.01419109284241,-28.01420888154447,-28.01421143539205,-28.01422922409758,-28.0142317779515,-28.01428514407419,-28.01428769794424,-28.01430548665384],"lat":[60.19888739447258,60.19887853893082,60.19887472482388,60.19886586928327,60.1988645979097,60.1988557423695,60.19885447099379,60.19884561545402,60.1988443440762,60.1988000663798,60.19880133775577,60.19878362667676,60.19878489804951,60.19877604250969,60.19877731387957,60.19876845833944,60.19877100107098,60.19876214553015,60.19876723096185,60.19877608650417,60.19877735785624,60.19878621339898,60.19878748474893,60.19879634029209,60.19879761163993,60.19882417827074,60.1988254496172,60.19884316070537,60.19884188935816,60.19886845598961,60.1988671846388,60.19887604018234,60.19887476882867,60.19888362437187,60.19887981029482,60.19888866583695,60.19888739447258]}]],[[{"lng":[-28.01513389207144,-28.01513133797037,-28.01514912659137,-28.01514657248684,-28.01516436110149,-28.01515925288694,-28.01517704149035,-28.01517193327174,-28.01515414467815,-28.01514648237573,-28.0151286937954,-28.01512613970237,-28.0151083511255,-28.01510579703881,-28.01508800846541,-28.01508545438507,-28.01499651152101,-28.01499906557684,-28.01496348841135,-28.01496604245882,-28.01494825386902,-28.01495591600534,-28.0149381273994,-28.01494323548766,-28.01496102410341,-28.0149686862613,-28.01498647489032,-28.01498902895073,-28.01500681758321,-28.01500937164996,-28.01513389207144],"lat":[60.19880107096573,60.19879221544154,60.19879094395915,60.19878208843537,60.19878081695086,60.19876310590419,60.19876183441793,60.19874412337216,60.1987453948577,60.19871882828826,60.19872009977018,60.19871124424675,60.19871251572582,60.19870366020207,60.19870493167826,60.19869607615418,60.19870243349597,60.1987112890219,60.19871383194193,60.19872268746867,60.19872395892531,60.19875052550686,60.19875179696214,60.19876950801746,60.19876823656143,60.19879480314363,60.19879353168401,60.19880238721111,60.19880111574864,60.19880997127542,60.19880107096573]}]],[[{"lng":[-28.01400536873529,-28.01400281495771,-28.01403839220692,-28.01403328463645,-28.0140510732491,-28.01404596567458,-28.01406375427598,-28.01405353912457,-28.01403575054278,-28.01403319676342,-28.01405098534032,-28.01404843155749,-28.01406622012804,-28.01406366634176,-28.01409924346875,-28.01409668967409,-28.01411447823052,-28.01410937063573,-28.01412715918092,-28.01411949778479,-28.0139060353241,-28.01391880403069,-28.01390101545845,-28.01390356919918,-28.01386799204058,-28.01387054577294,-28.01385275718658,-28.01385531091547,-28.01383752232277,-28.01385539843097,-28.01387318705798,-28.01387574079837,-28.01389352942885,-28.01389608317559,-28.01393166044204,-28.01393421420002,-28.01400536873529],"lat":[60.19872808241612,60.19871922687002,60.19871668421912,60.19869897312851,60.19869770180007,60.19867999071041,60.19867871938021,60.19864329720285,60.19864456853156,60.19863571298696,60.19863444165862,60.19862558611442,60.19862431478398,60.19861545924019,60.19861291657257,60.19860406102958,60.19860278969239,60.19858507860728,60.19858380726836,60.19855724064213,60.19857249653155,60.19861677426443,60.19861804557421,60.1986269011213,60.19862944373416,60.19863829928201,60.19863957058507,60.19864842613335,60.19864969743429,60.19871168627601,60.19871041497246,60.19871927052108,60.19871799921466,60.19872685476296,60.19872431214194,60.19873316768952,60.19872808241612]}]],[[{"lng":[-28.01011464951307,-28.01011209681142,-28.0101476746381,-28.01014512192808,-28.01016291083436,-28.01016035812087,-28.01017814702081,-28.01016027803229,-28.01014248916666,-28.01013738376411,-28.01010180604816,-28.01009925335883,-28.00999252020591,-28.00999507286581,-28.00997728399706,-28.0099798366535,-28.00996204777841,-28.00996715308579,-28.00994936419946,-28.00996212746854,-28.00997991637938,-28.00998246904241,-28.01000025795672,-28.01000536329689,-28.01004094114081,-28.01004349382286,-28.01011464951307],"lat":[60.1989608936017,60.19895203797489,60.19894949641331,60.19894064078731,60.19893937000315,60.19893051437755,60.19892924359129,60.19886725421583,60.1988685249995,60.198850813749,60.19885335530739,60.19884449968148,60.19885212429464,60.1988609799228,60.19886225068332,60.19887110631187,60.19887237707028,60.19889008832828,60.19889135908492,60.19893563723251,60.198934366474,60.19894322210327,60.1989419513419,60.19895966259985,60.19895712106815,60.19896597669645,60.1989608936017]}]]],null,"EX.P.Total",{"crs":{"crsClass":"L.CRS.EPSG3857","code":null,"proj4def":null,"projectedBounds":null,"options":{}},"pane":"polygon","stroke":true,"color":"#333333","weight":0.5,"opacity":0.9,"fill":true,"fillColor":"#6666FF","fillOpacity":0.6,"smoothFactor":1,"noClip":false},["<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>1&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td> 1&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>  0.9935388&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td>  4&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td> 1.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>2&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td> 2&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td> 93.3926525&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 42&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td> 9.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>3&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td> 3&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>164.9274124&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 58&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>14.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>4&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td> 4&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>135.1211522&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 52&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>13.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>5&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td> 5&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>139.0953167&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 54&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>13.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>6&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td> 6&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>451.0658994&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td>130&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>19.35703&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>7&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td> 7&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>122.2050995&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 50&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>12.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>8&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td> 8&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>115.2502982&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 50&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>12.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>9&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td> 9&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>229.5070023&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 78&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>13.55815&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>10&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td>10&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>119.2244964&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 48&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>12.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>11&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td>11&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>135.1210754&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 52&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>13.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>12&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td>12&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>122.2050547&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 52&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>12.96534&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>13&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td>13&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>124.1920600&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 50&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>12.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>14&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td>14&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>115.2502146&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 48&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>12.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>15&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td>15&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>112.2695794&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 46&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>11.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>16&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td>16&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>123.1985530&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 48&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>12.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>17&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td>17&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td> 90.4118387&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 44&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td> 9.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>18&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td>18&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>499.7484745&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td>120&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>20.44600&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>19&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td>19&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>117.2372705&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 48&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>11.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>20&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td>20&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>125.1855244&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 50&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>12.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>21&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td>21&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>124.1919423&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 50&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>12.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>22&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td>22&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>122.2049047&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 50&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>12.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>23&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td>23&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>120.2177672&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 50&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>12.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>24&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td>24&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>131.1466077&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 54&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>13.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>25&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td>25&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>119.2241748&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 50&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>12.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>26&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td>26&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>191.7521579&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 72&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>12.96919&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>","<div class='scrollableContainer'><table class=mapview-popup id='popup'><tr class='coord'><td><\/td><th><b>Feature ID&emsp;<\/b><\/th><td>27&emsp;<\/td><\/tr><tr><td>1<\/td><th>ID&emsp;<\/th><td>27&emsp;<\/td><\/tr><tr><td>2<\/td><th>area&emsp;<\/th><td>127.1725083&emsp;<\/td><\/tr><tr><td>3<\/td><th>perimeter&emsp;<\/th><td> 50&emsp;<\/td><\/tr><tr><td>4<\/td><th>width&emsp;<\/th><td>12.00000&emsp;<\/td><\/tr><tr><td>5<\/td><th>geometry&emsp;<\/th><td>sfc_POLYGON&emsp;<\/td><\/tr><\/table><\/div>"],{"maxWidth":800,"minWidth":50,"autoPan":true,"keepInView":false,"closeButton":true,"closeOnClick":true,"className":""},["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27"],{"interactive":false,"permanent":false,"direction":"auto","opacity":1,"offset":[0,0],"textsize":"10px","textOnly":false,"className":"","sticky":true},{"stroke":true,"weight":1,"opacity":0.9,"fillOpacity":0.84,"bringToFront":false,"sendToBack":false}]},{"method":"addScaleBar","args":[{"maxWidth":100,"metric":true,"imperial":true,"updateWhenIdle":true,"position":"bottomleft"}]},{"method":"addHomeButton","args":[-28.01590208903919,60.19855724064213,-28.00978734626318,60.20032568798955,true,"EX_P_Total","Zoom to EX_P_Total","<strong> EX_P_Total <\/strong>","bottomright"]},{"method":"addLayersControl","args":[["CartoDB.Positron","CartoDB.DarkMatter","OpenStreetMap","Esri.WorldImagery","OpenTopoMap"],"EX.P.Total",{"collapsed":true,"autoZIndex":true,"position":"topleft"}]},{"method":"addLegend","args":[{"colors":["#6666FF"],"labels":["EX.P.Total"],"na_color":null,"na_label":"NA","opacity":1,"position":"topright","type":"factor","title":"","extra":null,"layerId":null,"className":"info legend","group":"EX.P.Total"}]}],"limits":{"lat":[60.19855724064213,60.20032568798955],"lng":[-28.01590208903919,-28.00978734626318]},"fitBounds":[60.19855724064213,-28.01590208903919,60.20032568798955,-28.00978734626318,[]]},"evals":[],"jsHooks":{"render":[{"code":"function(el, x, data) {\n  return (\n      function(el, x, data) {\n      // get the leaflet map\n      var map = this; //HTMLWidgets.find('#' + el.id);\n      // we need a new div element because we have to handle\n      // the mouseover output separately\n      // debugger;\n      function addElement () {\n      // generate new div Element\n      var newDiv = $(document.createElement('div'));\n      // append at end of leaflet htmlwidget container\n      $(el).append(newDiv);\n      //provide ID and style\n      newDiv.addClass('lnlt');\n      newDiv.css({\"position\":\"relative\",\"bottomleft\":\"0px\",\"background-color\":\"rgba(255, 255, 255, 0.7)\",\"box-shadow\":\"0 0 2px #bbb\",\"background-clip\":\"padding-box\",\"margin\":\"0\",\"padding-left\":\"5px\",\"padding-right\":\"5px\",\"color\":\"#333\",\"font-size\":\"9px\",\"font-family\":\"\\\"Helvetica Neue\\\", Arial, Helvetica, sans-serif\",\"text-align\":\"left\",\"z-index\":\"700\"});\n      return newDiv;\n      }\n\n\n      // check for already existing lnlt class to not duplicate\n      var lnlt = $(el).find('.lnlt');\n\n      if(!lnlt.length) {\n      lnlt = addElement();\n\n      // grab the special div we generated in the beginning\n      // and put the mousmove output there\n\n      map.on('mousemove', function (e) {\n      if (e.originalEvent.ctrlKey) {\n      if (document.querySelector('.lnlt') === null) lnlt = addElement();\n      lnlt.text(\n                           ' lon: ' + (e.latlng.lng).toFixed(5) +\n                           ' | lat: ' + (e.latlng.lat).toFixed(5) +\n                           ' | zoom: ' + map.getZoom() +\n                           ' | x: ' + L.CRS.EPSG3857.project(e.latlng).x.toFixed(0) +\n                           ' | y: ' + L.CRS.EPSG3857.project(e.latlng).y.toFixed(0) +\n                           ' | epsg: 3857 ' +\n                           ' | proj4: +proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +no_defs ');\n      } else {\n      if (document.querySelector('.lnlt') === null) lnlt = addElement();\n      lnlt.text(\n                      ' lon: ' + (e.latlng.lng).toFixed(5) +\n                      ' | lat: ' + (e.latlng.lat).toFixed(5) +\n                      ' | zoom: ' + map.getZoom() + ' ');\n      }\n      });\n\n      // remove the lnlt div when mouse leaves map\n      map.on('mouseout', function (e) {\n      var strip = document.querySelector('.lnlt');\n      if( strip !==null) strip.remove();\n      });\n\n      };\n\n      //$(el).keypress(67, function(e) {\n      map.on('preclick', function(e) {\n      if (e.originalEvent.ctrlKey) {\n      if (document.querySelector('.lnlt') === null) lnlt = addElement();\n      lnlt.text(\n                      ' lon: ' + (e.latlng.lng).toFixed(5) +\n                      ' | lat: ' + (e.latlng.lat).toFixed(5) +\n                      ' | zoom: ' + map.getZoom() + ' ');\n      var txt = document.querySelector('.lnlt').textContent;\n      console.log(txt);\n      //txt.innerText.focus();\n      //txt.select();\n      setClipboardText('\"' + txt + '\"');\n      }\n      });\n\n      }\n      ).call(this.getMap(), el, x, data);\n}","data":null},{"code":"function(el, x, data) {\n  return (function(el,x,data){\n           var map = this;\n\n           map.on('keypress', function(e) {\n               console.log(e.originalEvent.code);\n               var key = e.originalEvent.code;\n               if (key === 'KeyE') {\n                   var bb = this.getBounds();\n                   var txt = JSON.stringify(bb);\n                   console.log(txt);\n\n                   setClipboardText('\\'' + txt + '\\'');\n               }\n           })\n        }).call(this.getMap(), el, x, data);\n}","data":null}]}}</script>
</div>
<script>
HTMLWidgets.addPostRenderHandler(function() {
var leaf_widgets = {};
                Array.prototype.map.call(
                 document.querySelectorAll(".leaflet"),
                   function(ldiv){
                     if (HTMLWidgets.find("#" + ldiv.id) && HTMLWidgets.find("#" + ldiv.id).getMap()) {
                        leaf_widgets[ldiv.id] = HTMLWidgets.find("#" + ldiv.id).getMap();
                     }
                   }
                );
               

leaf_widgets['htmlwidget-8208'].sync(leaf_widgets['htmlwidget-7215'],{syncCursor: true, noInitialSync: true});
leaf_widgets['htmlwidget-7215'].sync(leaf_widgets['htmlwidget-8208'],{syncCursor: true, noInitialSync: true});

});
</script>
</div>
<p>In summary, packages such as <code>EBImage</code> and <code>biopixR</code> provide direct pipelines
for the extraction of features from images, including shape, size, radius, and
perimeter, as well as texture information through the calculation of Haralick
texture features <span class="citation" data-cites="Haralick1973 Pau2010 biopixR">(<a href="#ref-Haralick1973" role="doc-biblioref">Haralick et al. 1973</a>; <a href="#ref-Pau2010" role="doc-biblioref">Pau et al. 2010</a>; <a href="#ref-biopixR" role="doc-biblioref">Brauckhoff et al. 2024</a>)</span>. The <code>biopixR</code> package
employs the <code>imager</code> and <code>magick</code> packages for image processing <span class="citation" data-cites="biopixR">(<a href="#ref-biopixR" role="doc-biblioref">Brauckhoff et al. 2024</a>)</span>,
whereas <code>pliman</code> and <code>FIELDimageR</code> rely on <code>EBImage</code> for direct image analysis,
with <code>FIELDimageR</code> also utilizing <code>terra</code> and <code>raster</code> for spatial data
exploration <span class="citation" data-cites="Matias2020 Olivoto2022">(<a href="#ref-Matias2020" role="doc-biblioref">Matias et al. 2020</a>; <a href="#ref-Olivoto2022" role="doc-biblioref">Olivoto 2022</a>)</span>. In comparison to the other packages
discussed in this section, <code>biopixR</code> facilitates the process of object detection
by eliminating the necessity for the generation of masks or the provision of
representative sample images of the foreground and background. Nevertheless, in
contrast to the other packages, <code>biopixR</code> lacks the functionality of watershed
segmentation for the enhanced handling of touching objects (Figure
<a href="#fig:biobeads0">2</a>B and Figure <a href="#fig:pliman2">4</a>) <span class="citation" data-cites="Matias2020 Olivoto2022 biopixR">(<a href="#ref-Matias2020" role="doc-biblioref">Matias et al. 2020</a>; <a href="#ref-Olivoto2022" role="doc-biblioref">Olivoto 2022</a>; <a href="#ref-biopixR" role="doc-biblioref">Brauckhoff et al. 2024</a>)</span>.</p>
<h2 data-number="5" id="clus"><span class="header-section-number">5</span> Decoding complexity - clustering, classification and annotation</h2>
<p>The automation of measuring cellular phenomena and the effects of compounds,
which started in the late 1990s, is now increasingly significant owing to the
progress of machine learning (ML) algorithms and computing power. These
advancements are enhancing the field of bioinformatics’ accessibility to these
techniques. Consequently, they are being more commonly employed with the aim of
gaining novel biological insights <span class="citation" data-cites="Murphy2014 Moen2019 Weiss2022">(<a href="#ref-Murphy2014" role="doc-biblioref">Murphy 2014</a>; <a href="#ref-Moen2019" role="doc-biblioref">Moen et al. 2019</a>; <a href="#ref-Weiss2022" role="doc-biblioref">Weiss et al. 2022</a>)</span>. One of the latest
methods of image analysis involves comparing the morphological characteristics
of cells from captured images with pre-classified training data that represent
a specific state <span class="citation" data-cites="Moen2019">(<a href="#ref-Moen2019" role="doc-biblioref">Moen et al. 2019</a>)</span>. Bioimage informatics methods aim to generate
fully automated models for biological systems <span class="citation" data-cites="Murphy2014">(<a href="#ref-Murphy2014" role="doc-biblioref">Murphy 2014</a>)</span>.</p>
<p>A major challenge in handling new data sets is the need to label images, which is
critical to assigning meaning to the objects within them. This is particularly
important in medical imaging, where expert knowledge is essential for accurate
labeling <span class="citation" data-cites="Boom2012 Weiss2022">(<a href="#ref-Boom2012" role="doc-biblioref">Boom et al. 2012</a>; <a href="#ref-Weiss2022" role="doc-biblioref">Weiss et al. 2022</a>)</span>. In ML, two common techniques that can be
used to categorize data into distinct groups are clustering and classification.
Clustering, an unsupervised learning method, is used to discover underlying
structures or patterns in unlabeled data by assessing similarities between data
points <span class="citation" data-cites="Mostafa2019">(<a href="#ref-Mostafa2019" role="doc-biblioref">Mostafa and Amano 2019</a>)</span>. Classification, a form of supervised learning, involves
building a model from previously labeled training data to make predictions about
new data <span class="citation" data-cites="Mostafa2019 KumarDubey2022">(<a href="#ref-Mostafa2019" role="doc-biblioref">Mostafa and Amano 2019</a>; <a href="#ref-KumarDubey2022" role="doc-biblioref">Kumar Dubey et al. 2022</a>)</span>. This requires prior labeling of the
data to determine the characteristics of each group, a process known as
annotation. However, manual annotation is time-consuming and labor-intensive,
requiring significant human effort to identify relevant details in an image
<span class="citation" data-cites="Yao2016 Weiss2022">(<a href="#ref-Yao2016" role="doc-biblioref">Yao et al. 2016</a>; <a href="#ref-Weiss2022" role="doc-biblioref">Weiss et al. 2022</a>)</span>. Because images often require multi-label annotation - the
assignment of multiple semantic concepts to a single image - there has been a
growing demand for automated image annotation systems that aim to reduce the
burden of manual labeling and increase the efficiency of data processing
<span class="citation" data-cites="Nasierding2009">(<a href="#ref-Nasierding2009" role="doc-biblioref">Nasierding et al. 2009</a>)</span>.</p>
<p>To effectively analyze complex image data sets, researchers require advanced
pattern recognition techniques that can extract meaningful biological insights
from these images. This enables them to transform visual data into actionable
scientific knowledge <span class="citation" data-cites="Behura2021">(<a href="#ref-Behura2021" role="doc-biblioref">Behura 2021</a>)</span>. Some of the most widely used clustering
algorithms for this purpose include:</p>
<ul>
<li>k-means: is a centroid-based algorithm that partitions n observations into
<em>k</em> clusters by minimizing within-cluster sum of squares. It does require
specifying the number of clusters beforehand <span class="citation" data-cites="Struyf1996">(<a href="#ref-Struyf1996" role="doc-biblioref">Struyf et al. 1996</a>)</span>.</li>
<li>Partitioning Around Medoids (PAM): a k-means relative, seeks to identify <em>k</em>
representative objects from the data set,
which are robust representations of the clusters’ center and are also
referred to as medoids. Clusters are formed by assigning each object to its
nearest medoid, with the objective of optimizing within-cluster similarity
<span class="citation" data-cites="Kaufman1990 VanderLaan2003">(<a href="#ref-Kaufman1990" role="doc-biblioref">Kaufman and Rousseeuw 1990</a>; <a href="#ref-VanderLaan2003" role="doc-biblioref">Van der Laan et al. 2003</a>)</span>.</li>
<li>c-means: also known as Fuzzy C-Means (FCM), extends the concept of k-means
to allow each data point to belong to more than one cluster <span class="citation" data-cites="Bezdek1984">(<a href="#ref-Bezdek1984" role="doc-biblioref">Bezdek et al. 1984</a>)</span>.</li>
<li>Density-Based Spatial Clustering of Applications with Noise (DBSCAN): is a
density-based clustering algorithm that groups together points that are
closely packed together and separates them from points that lie alone in
low-density regions. It does not require specifying the number of clusters
beforehand <span class="citation" data-cites="Ester1996 Schubert2017">(<a href="#ref-Ester1996" role="doc-biblioref">Ester et al. 1996</a>; <a href="#ref-Schubert2017" role="doc-biblioref">Schubert et al. 2017</a>)</span>.</li>
<li>Self-Organizing Maps (SOM): are a type of neural network architecture that
systematically organizes input features into a spatially coherent
representation. This method can be utilized for clustering based on various
object features, thereby facilitating the discovery of patterns within these
objects <span class="citation" data-cites="Kohonen1990 Kohonen2013">(<a href="#ref-Kohonen1990" role="doc-biblioref">Kohonen 1990</a>, <a href="#ref-Kohonen2013" role="doc-biblioref">2013</a>)</span>.</li>
</ul>
<h3 data-number="5.1" id="pixelclasser-a-simplified-support-vector-machine-approach-for-pixel-classification"><span class="header-section-number">5.1</span> <code>pixelclasser</code>: a simplified support vector machine approach for pixel classification</h3>
<p>The <code>pixelclasser</code> package is a tool for classifying image pixels into
user-defined color categories using a simplified version of the Support Vector
Machine (SVM) technique. It includes functions that allow users to visualize
image pixels, define classification rules, classify pixels, and store the
resulting information.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> Users must
provide a test set that captures the variation between categories, as the
package requires manual placement of rules for each category - automatic rule
construction methods are not included. In addition, <code>pixelclasser</code> provides
quality control of the classifications and comes with a detailed vignette to
facilitate the use of this classification
tool.<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>
The classification on the pixel-level can be used for image segmentation via
pixel clustering.</p>
<h3 data-number="5.2" id="biopixr-pattern-recognition-of-shape--and-texture-related-features"><span class="header-section-number">5.2</span> <code>biopixR</code>: pattern recognition of shape- and texture-related features</h3>
<p>The <code>biopixR</code> package incorporates two unsupervised ML clustering
algorithms: SOM and PAM. PAM organizes a distance matrix into clusters,
identifying medoids as robust representatives of each cluster, typically
specified with a predefined number of groups (<em>k</em>) <span class="citation" data-cites="Kaufman1990 VanderLaan2003 Park2009">(<a href="#ref-Kaufman1990" role="doc-biblioref">Kaufman and Rousseeuw 1990</a>; <a href="#ref-VanderLaan2003" role="doc-biblioref">Van der Laan et al. 2003</a>; <a href="#ref-Park2009" role="doc-biblioref">Park and Jun 2009</a>)</span>. This approach clusters Haralick texture features
extracted from multiple images within a directory, thereby enabling image
classification based on these features <span class="citation" data-cites="Haralick1973">(<a href="#ref-Haralick1973" role="doc-biblioref">Haralick et al. 1973</a>)</span>. The optimal number of
clusters (<em>k</em>) is automatically determined using silhouette analysis
<span class="citation" data-cites="Rousseeuw1987 biopixR">(<a href="#ref-Rousseeuw1987" role="doc-biblioref">Rousseeuw 1987</a>; <a href="#ref-biopixR" role="doc-biblioref">Brauckhoff et al. 2024</a>)</span>. SOM is used to cluster object features related to
object shape and intensity, thereby facilitating the identification of patterns
within these characteristics <span class="citation" data-cites="biopixR">(<a href="#ref-biopixR" role="doc-biblioref">Brauckhoff et al. 2024</a>)</span>.</p>
<p>The capacity for pattern recognition within the <code>biopixR</code> package is
demonstrated by the clustering of shape-related and pixel-intensity information
from an example image of microbeads (Figure <a href="#fig:shapefeatures">7</a>A). The image
depicts both single and aggregated microbeads, wherein the former exhibit a
round, spherical shape, while the latter appear more oval. The extracted
features and the corresponding cluster are depicted in Figure
<a href="#fig:shapefeatures">7</a>B, which showcases the identification of patterns within
these objects based on their shape characteristics.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># Load the 'biopixR' package</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/Brauckhoff/biopixR'>biopixR</a></span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Import an image from the specified path</span></span>
<span><span class='va'>img</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/biopixR/man/importImage.html'>importImage</a></span><span class='op'>(</span><span class='st'>"figures/beads.png"</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Set seed for reproducibility</span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>123</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Extract shape features from the image</span></span>
<span><span class='va'>result</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/biopixR/man/shapeFeatures.html'>shapeFeatures</a></span><span class='op'>(</span></span>
<span>  <span class='va'>img</span>,    </span>
<span>  alpha <span class='op'>=</span> <span class='fl'>0.8</span>,</span>
<span>  sigma <span class='op'>=</span> <span class='fl'>0.7</span>,</span>
<span>  xdim <span class='op'>=</span> <span class='fl'>2</span>,</span>
<span>  ydim <span class='op'>=</span> <span class='fl'>1</span>,</span>
<span>  SOM <span class='op'>=</span> <span class='cn'>TRUE</span>,</span>
<span>  visualize <span class='op'>=</span> <span class='cn'>FALSE</span></span>
<span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Define colors for plotting points based on classes</span></span>
<span><span class='va'>colors</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"darkgreen"</span>, <span class='st'>"darkred"</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Plot the image without axes and add colored points representing the classes</span></span>
<span><span class='va'>img</span> <span class='op'>|&gt;</span> <span class='fu'><a href='https://rspatial.github.io/terra/reference/plot.html'>plot</a></span><span class='op'>(</span>axes <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/with.html'>with</a></span><span class='op'>(</span><span class='va'>result</span>,</span>
<span>     <span class='fu'><a href='https://rspatial.github.io/terra/reference/lines.html'>points</a></span><span class='op'>(</span></span>
<span>       <span class='va'>result</span><span class='op'>$</span><span class='va'>x</span>,</span>
<span>       <span class='va'>result</span><span class='op'>$</span><span class='va'>y</span>,</span>
<span>       col <span class='op'>=</span> <span class='va'>colors</span><span class='op'>[</span><span class='fu'><a href='https://rdrr.io/r/base/factor.html'>factor</a></span><span class='op'>(</span><span class='va'>result</span><span class='op'>$</span><span class='va'>class</span><span class='op'>)</span><span class='op'>]</span>,</span>
<span>       pch <span class='op'>=</span> <span class='fl'>19</span>,</span>
<span>       cex <span class='op'>=</span> <span class='fl'>1.2</span></span>
<span>     <span class='op'>)</span><span class='op'>)</span></span>
<span><span class='fu'><a href='https://rspatial.github.io/terra/reference/text.html'>text</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>471</span><span class='op'>)</span>, <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>354</span><span class='op'>)</span>, <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"A"</span><span class='op'>)</span>, col <span class='op'>=</span> <span class='st'>"darkred"</span>, cex <span class='op'>=</span> <span class='fl'>5</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Create a data frame with various shape features and the pixel-intensity</span></span>
<span><span class='va'>df</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span><span class='op'>(</span></span>
<span>  size <span class='op'>=</span> <span class='va'>result</span><span class='op'>$</span><span class='va'>size</span>,</span>
<span>  intensity <span class='op'>=</span> <span class='va'>result</span><span class='op'>$</span><span class='va'>intensity</span>,</span>
<span>  perimeter <span class='op'>=</span> <span class='va'>result</span><span class='op'>$</span><span class='va'>perimeter</span>,</span>
<span>  circularity <span class='op'>=</span> <span class='va'>result</span><span class='op'>$</span><span class='va'>circularity</span>,</span>
<span>  eccentricity <span class='op'>=</span> <span class='va'>result</span><span class='op'>$</span><span class='va'>eccentricity</span>,</span>
<span>  radius <span class='op'>=</span> <span class='va'>result</span><span class='op'>$</span><span class='va'>mean_radius</span>,</span>
<span>  aspectRatio <span class='op'>=</span> <span class='va'>result</span><span class='op'>$</span><span class='va'>aspect_ratio</span></span>
<span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Min-Max Normalization Function</span></span>
<span><span class='va'>min_max_norm</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  <span class='op'>(</span><span class='va'>x</span> <span class='op'>-</span> <span class='fu'><a href='https://rdrr.io/r/base/Extremes.html'>min</a></span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>/</span> <span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/Extremes.html'>max</a></span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span> <span class='op'>-</span> <span class='fu'><a href='https://rdrr.io/r/base/Extremes.html'>min</a></span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='co'># Applying the function to each column</span></span>
<span><span class='va'>df_normalized</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rspatial.github.io/terra/reference/as.data.frame.html'>as.data.frame</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/lapply.html'>lapply</a></span><span class='op'>(</span><span class='va'>df</span>, <span class='va'>min_max_norm</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Create a boxplot of the normalized data</span></span>
<span><span class='fu'><a href='https://rspatial.github.io/terra/reference/boxplot.html'>boxplot</a></span><span class='op'>(</span></span>
<span>  <span class='va'>df_normalized</span>,</span>
<span>  ylab <span class='op'>=</span> <span class='st'>"normalized values"</span>,</span>
<span>  xaxt <span class='op'>=</span> <span class='st'>"n"</span>,</span>
<span>  cex.lab <span class='op'>=</span> <span class='fl'>1.25</span>,</span>
<span>  cex.axis <span class='op'>=</span> <span class='fl'>1.25</span></span>
<span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Add axis ticks and diagonal labels</span></span>
<span><span class='fu'><a href='https://rdrr.io/r/graphics/axis.html'>axis</a></span><span class='op'>(</span><span class='fl'>1</span>, at <span class='op'>=</span> <span class='fl'>1</span><span class='op'>:</span><span class='fu'><a href='https://rspatial.github.io/terra/reference/dimensions.html'>ncol</a></span><span class='op'>(</span><span class='va'>df</span><span class='op'>)</span>, labels <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span>  <span class='co'># Add axis ticks but no labels</span></span>
<span><span class='fu'><a href='https://rspatial.github.io/terra/reference/text.html'>text</a></span><span class='op'>(</span></span>
<span>  cex <span class='op'>=</span> <span class='fl'>1.2</span>,</span>
<span>  x <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/seq.html'>seq_len</a></span><span class='op'>(</span><span class='fu'><a href='https://rspatial.github.io/terra/reference/dimensions.html'>ncol</a></span><span class='op'>(</span><span class='va'>df_normalized</span><span class='op'>)</span><span class='op'>)</span>,</span>
<span>  y <span class='op'>=</span> <span class='op'>-</span><span class='fl'>0.07</span>,</span>
<span>  labels <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/colnames.html'>colnames</a></span><span class='op'>(</span><span class='va'>df_normalized</span><span class='op'>)</span>,</span>
<span>  adj <span class='op'>=</span> <span class='fl'>0</span>,</span>
<span>  srt <span class='op'>=</span> <span class='op'>-</span><span class='fl'>45</span>,</span>
<span>  xpd <span class='op'>=</span> <span class='cn'>TRUE</span></span>
<span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Highlight specific rows based on class</span></span>
<span><span class='va'>highlight_rows</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/which.html'>which</a></span><span class='op'>(</span><span class='va'>result</span><span class='op'>$</span><span class='va'>class</span> <span class='op'>==</span> <span class='fl'>2</span><span class='op'>)</span>  <span class='co'># Example row indices to highlight</span></span>
<span></span>
<span><span class='co'># Add points for the specific rows</span></span>
<span><span class='co'># Adding points for each column</span></span>
<span><span class='kw'>for</span> <span class='op'>(</span><span class='va'>col</span> <span class='kw'>in</span> <span class='fl'>1</span><span class='op'>:</span><span class='fu'><a href='https://rspatial.github.io/terra/reference/dimensions.html'>ncol</a></span><span class='op'>(</span><span class='va'>df_normalized</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  <span class='fu'><a href='https://rspatial.github.io/terra/reference/lines.html'>points</a></span><span class='op'>(</span></span>
<span>    <span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span><span class='op'>(</span><span class='va'>col</span>, <span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>highlight_rows</span><span class='op'>)</span><span class='op'>)</span>,</span>
<span>    <span class='va'>df_normalized</span><span class='op'>[</span><span class='va'>highlight_rows</span>, <span class='va'>col</span><span class='op'>]</span>,</span>
<span>    col <span class='op'>=</span> <span class='st'>"red"</span>,</span>
<span>    pch <span class='op'>=</span> <span class='fl'>19</span>,</span>
<span>    cex <span class='op'>=</span> <span class='fl'>1.5</span></span>
<span>  <span class='op'>)</span></span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='fu'><a href='https://rspatial.github.io/terra/reference/text.html'>text</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0.5</span><span class='op'>)</span>,</span>
<span>     <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0.98</span><span class='op'>)</span>,</span>
<span>     <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"B"</span><span class='op'>)</span>,</span>
<span>     col <span class='op'>=</span> <span class='st'>"darkred"</span>,</span>
<span>     cex <span class='op'>=</span> <span class='fl'>5</span><span class='op'>)</span></span></code></pre>
</div>
</div>

<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:shapefeatures"></span>
<img src="figures/shape_test2.png" alt="Clustering Microbeads Based on Shape and Intensity Features: A) The utilization of Self-Organizing Maps (SOM) enables the clustering of microbeads into two distinct groups based on shape and intensity features extracted using the shapeFeatures() function. This method enables the precise clustering of microbeads according to a range of properties, including intensity, area, perimeter, circularity, radius, and aspect ratio. This facilitates a deeper understanding of the morphological variations observed in the microbeads. B) The attributes utilized as input for the SOM algorithm are illustrated in this plot. To ensure comparability, the different parameters have been normalized using a min-max normalization procedure. The points highlighted in red represent the microbeads that are also highlighted in red in Figure A. Notably, these highlighted points differ from the most commonly occurring values in all attributes except for the intensity." width="85%" /><img src="figures/shape_test1.png" alt="Clustering Microbeads Based on Shape and Intensity Features: A) The utilization of Self-Organizing Maps (SOM) enables the clustering of microbeads into two distinct groups based on shape and intensity features extracted using the shapeFeatures() function. This method enables the precise clustering of microbeads according to a range of properties, including intensity, area, perimeter, circularity, radius, and aspect ratio. This facilitates a deeper understanding of the morphological variations observed in the microbeads. B) The attributes utilized as input for the SOM algorithm are illustrated in this plot. To ensure comparability, the different parameters have been normalized using a min-max normalization procedure. The points highlighted in red represent the microbeads that are also highlighted in red in Figure A. Notably, these highlighted points differ from the most commonly occurring values in all attributes except for the intensity." width="85%" />
<p class="caption">
Figure 7: <strong>Clustering Microbeads Based on Shape and Intensity Features</strong>: <strong>A</strong>) The utilization of Self-Organizing Maps (SOM) enables the clustering of microbeads into two distinct groups based on shape and intensity features extracted using the <code>shapeFeatures()</code> function. This method enables the precise clustering of microbeads according to a range of properties, including intensity, area, perimeter, circularity, radius, and aspect ratio. This facilitates a deeper understanding of the morphological variations observed in the microbeads. <strong>B</strong>) The attributes utilized as input for the SOM algorithm are illustrated in this plot. To ensure comparability, the different parameters have been normalized using a min-max normalization procedure. The points highlighted in red represent the microbeads that are also highlighted in red in Figure A. Notably, these highlighted points differ from the most commonly occurring values in all attributes except for the intensity.
</p>
</div>
</div>
<h2 data-number="6" id="harmonizing-visions---techniques-and-approaches-in-image-registration"><span class="header-section-number">6</span> Harmonizing visions - techniques and approaches in image registration</h2>
<p>The process of image registration plays a pivotal role in the analysis of
medical images, as it enables the comparison of multiple images representing
different conditions <span class="citation" data-cites="Jenkinson2001">(<a href="#ref-Jenkinson2001" role="doc-biblioref">Jenkinson and Smith 2001</a>)</span>. This process, which can be described as
image alignment, entails aligning a series of images within a single coordinate
system, thereby ensuring consistency across images <span class="citation" data-cites="Peng2008 Rittscher2010">(<a href="#ref-Peng2008" role="doc-biblioref">Peng 2008</a>; <a href="#ref-Rittscher2010" role="doc-biblioref">Rittscher 2010</a>)</span>. A variety of techniques are employed in image registration,
including mutual information registration, spline-based elastic registration,
and invariant moment feature-based registration, among others <span class="citation" data-cites="Peng2008">(<a href="#ref-Peng2008" role="doc-biblioref">Peng 2008</a>)</span>.
These methods are of particular significance in the field of medical imaging,
where they are employed to enhance the analysis of images obtained by techniques
such as computed tomography (CT) and magnetic resonance imaging (MRI)
<span class="citation" data-cites="Sonka2000">(<a href="#ref-Sonka2000" role="doc-biblioref">Sonka and Fitzpatrick 2000</a>)</span>.</p>
<h3 data-number="6.1" id="rniftyreg-interface-for-the-niftyreg-image-registration-tools"><span class="header-section-number">6.1</span> <code>RNiftyReg</code>: interface for the ‘NiftyReg’ image registration tools</h3>
<p>The <code>RNiftyReg</code> package provides an interface to the ‘NiftyReg’ image
registration library, which supports both linear and non-linear registration in
two and three dimensions <span class="citation" data-cites="RNiftyReg">(<a href="#ref-RNiftyReg" role="doc-biblioref">Clayden et al. 2023</a>)</span>. This package has been utilized in
research on brain connectivity <span class="citation" data-cites="Clayden2013">(<a href="#ref-Clayden2013" role="doc-biblioref">Clayden et al. 2013</a>)</span>, and it includes a comprehensive
README that introduces its features and
capabilities.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<h2 data-number="7" id="jack-of-all-trades---general-purpose-r-packages-for-broad-spectrum-analysis"><span class="header-section-number">7</span> Jack of all trades - general purpose <code>R</code> packages for broad-spectrum analysis</h2>
<p>Five principal image processing packages for <code>R</code> offer a broad range of
algorithms and capabilities for complete image analysis, rendering them
suitable as general-purpose tools. These packages are <code>imager</code>, <code>magick</code>,
<code>EBImage</code>, <code>OpenImageR</code> and <code>SimpleITK</code>. This section will introduce each of
these key packages and their roles in image analysis.</p>
<h3 data-number="7.1" id="imager-wrapper-for-the-cimg-c-image-processing-library"><span class="header-section-number">7.1</span> <code>imager</code>: wrapper for the ‘CImg’ C++ image processing library</h3>
<p>The <code>imager</code> <code>R</code> package, created by <span class="citation" data-cites="Barthelme2019">Barthelmé and Tschumperlé (<a href="#ref-Barthelme2019" role="doc-biblioref">2019</a>)</span>, integrates the
functionality of the ‘CImg’ library, developed by David Tschumperlé, into
<code>R</code>.<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> This allows users
to edit and create images. The package uses two primary data structures: raster
images, known as <em>cimg</em>, and pixel sets, referred to as <em>pixelset</em>. These
structures, encoded as four-dimensional numeric or logical arrays, permit the
execution of basic <code>R</code> functions such as <code>plot()</code>, <code>print()</code>, or
<code>as.data.frame()</code>, as well as the processing of hyperspectral images and videos
<span class="citation" data-cites="Barthelme2019">(<a href="#ref-Barthelme2019" role="doc-biblioref">Barthelmé and Tschumperlé 2019</a>)</span>. The 4D arrays encompass two spatial dimensions (width and
height), one temporal or depth dimension, and one color dimension <span class="citation" data-cites="imager">(<a href="#ref-imager" role="doc-biblioref">Barthelme et al. 2024</a>)</span>.
<code>imager</code> offers over 100 standard commands for tasks such as loading, saving,
resizing, and denoising of images.<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>
The <code>imager</code> package supports the file formats JPEG, PNG,
and BMP and is available on CRAN <span class="citation" data-cites="imager">(<a href="#ref-imager" role="doc-biblioref">Barthelme et al. 2024</a>)</span>.</p>
<h3 data-number="7.2" id="ebimage-image-processing-and-analysis-for-biological-imaging-data-in-r"><span class="header-section-number">7.2</span> <code>EBImage</code>: image processing and analysis for biological imaging data in <code>R</code></h3>
<p>The <code>EBImage</code> package, established in 2006, is one of the oldest image
processing tools available in <code>R</code> and can be accessed via the Bioconductor
repository. It is primarily written in <code>R</code> and C/C++ <span class="citation" data-cites="AndrzejOles2017">(<a href="#ref-AndrzejOles2017" role="doc-biblioref">Andrzej Oleś 2017</a>)</span>.
<code>EBImage</code> provides a suite of general tools for image processing and analysis,
particularly excelling in microscopy-based cell assays. It features specialized
commands for cell segmentation and the extraction of quantitative data from
images <span class="citation" data-cites="Pau2010">(<a href="#ref-Pau2010" role="doc-biblioref">Pau et al. 2010</a>)</span>. The package employs the RGB color system for color
detection, which is based on pixel intensities. The incorporation of the
<code>EBImage</code> package into the <code>R</code> workflow facilitates the automation and objectivity
of the image analysis procedure <span class="citation" data-cites="Heineck2019">(<a href="#ref-Heineck2019" role="doc-biblioref">Heineck et al. 2019</a>)</span>. Images in <code>EBImage</code> are
managed as an extension of <code>R</code>‘s base <code>array</code>, specifically the package-specific
<code>Image</code> class. As images are treated as multidimensional arrays, algebraic
operations are possible. This class structure includes various slots, with the
<em>.data</em> slot holding the numeric pixel intensity array and the <em>colorMode</em> slot
managing the image’s color information. Adjusting the <em>colorMode</em> setting
changes the image’s rendering mode <span class="citation" data-cites="AndrzejOles2017 Heineck2019">(<a href="#ref-AndrzejOles2017" role="doc-biblioref">Andrzej Oleś 2017</a>; <a href="#ref-Heineck2019" role="doc-biblioref">Heineck et al. 2019</a>)</span>.
Typically, the first two dimensions of an image carry spatial information, while
additional dimensions are variable and can represent color channels, time
points, replicas, or depth. <code>EBImage</code> also features an interactive display
interface through GTK+, and offers a set of functions for
automated image-based phenotyping in biology, including cell segmentation,
feature extraction, statistical analysis, and visualization <span class="citation" data-cites="Pau2010">(<a href="#ref-Pau2010" role="doc-biblioref">Pau et al. 2010</a>)</span>. It
supports a range of file formats, including JPEG, PNG, and TIFF, and can handle
additional formats through integration with the ’ImageMagick’ image-processing
library <span class="citation" data-cites="Pau2010 AndrzejOles2017">(<a href="#ref-Pau2010" role="doc-biblioref">Pau et al. 2010</a>; <a href="#ref-AndrzejOles2017" role="doc-biblioref">Andrzej Oleś 2017</a>)</span>.</p>
<h3 data-number="7.3" id="magick-advanced-image-processing-in-r-using-imagemagick"><span class="header-section-number">7.3</span> <code>magick</code>: advanced image processing in <code>R</code> using ‘ImageMagick’</h3>
<p>This package is built upon ‘Magick++’, the C++ API for the ‘ImageMagick’ image
processing library.<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a> The <code>R</code> package provides access to ‘ImageMagick’
functionalities, enabling both basic and complex image manipulations directly in
<code>R</code>. Notably, images in <code>magick</code> are automatically displayed in the RStudio
console, creating a dynamic and interactive editing environment. The wide
variety of functions made available through this package are impressive. The
possibilities range from functions that are rather ‘just for fun’, such as
implosion or introduction of noise, to more advanced processing techniques,
including different segmentation techniques, edge detection, and a
toolbox for morphology operations. The <code>magick</code> package is compatible with a
diverse range of image formats and encompasses the functionalities required for
format conversion. This includes the conversion to the formats supported by the
<code>EBImage</code> package. It also handles multiple frames, facilitating the creation
and processing of animated graphics. Each operation in <code>magick</code> creates a new,
altered version of the image, preserving the original
<span class="citation" data-cites="magick">(<a href="#ref-magick" role="doc-biblioref">Ooms 2024a</a>)</span>.<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> Recent developments include the introduction of a <code>shiny</code>
application that enables users to interactively perform basic image processing
tasks such as blurring and edge
detection.<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>
The <code>magick</code> package is compatible with a range of popular file formats,
including PNG, BMP, TIFF, PDF, SVG, and JPEG, and is available through the CRAN
repository <span class="citation" data-cites="magick">(<a href="#ref-magick" role="doc-biblioref">Ooms 2024a</a>)</span>.<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a></p>
<h3 data-number="7.4" id="openimager-a-general-purpose-image-processing-library"><span class="header-section-number">7.4</span> <code>OpenImageR</code>: a general-purpose image processing library</h3>
<p><code>OpenImageR</code> is a lesser known but highly versatile general-purpose image
processing library that integrates both the <code>R</code> and C++ programming languages.
This package offers a comprehensive array of functions for preprocessing,
filtering, and feature extraction. Images are treated as two- or
three-dimensional objects, represented by matrices, data frames, or arrays, with
the third dimension representing color information. The functionalities within
<code>OpenImageR</code> are organized into three main categories: basic functions, which
include importing, displaying, cropping, and thresholding; filter functions,
which feature augmentation and various edge detection algorithms; and image
recognition, which incorporates functions from the ‘ImageHash’ Python library.
In recent updates, a number of new features have been incorporated, including
Gabor feature extraction, which was originally developed in MATLAB and based on
code by <span class="citation" data-cites="Haghighat2015">Haghighat et al. (<a href="#ref-Haghighat2015" role="doc-biblioref">2015</a>)</span>. The most recent version incorporates image segmentation
techniques that utilize superpixels and clustering. Images can be visualized
through the <code>shiny</code> application or the grid package. <code>OpenImageR</code> is capable of
handling a multitude of image formats, including PNG, TIFF, and JPG
<span class="citation" data-cites="OpenImageR">(<a href="#ref-OpenImageR" role="doc-biblioref">Mouselimis et al. 2023</a>)</span>.<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a> <a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a></p>
<h3 data-number="7.5" id="simpleitk-a-streamlined-wrapper-for-itk-in-biomedical-image-analysis"><span class="header-section-number">7.5</span> <code>SimpleITK</code>: a streamlined wrapper for ITK in biomedical image analysis</h3>
<p>The following section will introduce a prominent tool in biomedical image
analysis, the wrapper for the Insight Segmentation and Registration Toolkit
(ITK), known as <code>SimpleITK</code> <span class="citation" data-cites="Rittscher2010">(<a href="#ref-Rittscher2010" role="doc-biblioref">Rittscher 2010</a>)</span>. <code>SimpleITK</code> represents a
streamlined version of the original ITK, an open-source C++ library that
features a wide array of imaging algorithms and frameworks
<span class="citation" data-cites="Lowekamp2013 Yaniv2017">(<a href="#ref-Lowekamp2013" role="doc-biblioref">Lowekamp et al. 2013</a>; <a href="#ref-Yaniv2017" role="doc-biblioref">Yaniv et al. 2017</a>)</span>. This library has been in development for
approximately two decades and is particularly favored in the medical image
analysis community <span class="citation" data-cites="Lowekamp2013 Beare2018">(<a href="#ref-Lowekamp2013" role="doc-biblioref">Lowekamp et al. 2013</a>; <a href="#ref-Beare2018" role="doc-biblioref">Beare et al. 2018</a>)</span>.
The objective of <code>SimpleITK</code> is to simplify the accessibility of ITK algorithms
by reducing their complexity, thereby making these sophisticated tools more
approachable for a broader audience <span class="citation" data-cites="Lowekamp2013">(<a href="#ref-Lowekamp2013" role="doc-biblioref">Lowekamp et al. 2013</a>)</span>. Adapted for the <code>R</code>
programming language through SWIG, <code>SimpleITK</code> offers over 250 image processing
algorithms that function across various scripting and prototyping environments
<span class="citation" data-cites="Lowekamp2013 Yaniv2017 Beare2018">(<a href="#ref-Lowekamp2013" role="doc-biblioref">Lowekamp et al. 2013</a>; <a href="#ref-Yaniv2017" role="doc-biblioref">Yaniv et al. 2017</a>; <a href="#ref-Beare2018" role="doc-biblioref">Beare et al. 2018</a>)</span>. In contrast to other general-purpose
image processing packages, which treat images as mere arrays, <code>SimpleITK</code> treats
images as objects within a physical space, thereby providing a set
of metadata about image and voxel geometry in world coordinates <span class="citation" data-cites="Lowekamp2013 Yaniv2017 Beare2018">(<a href="#ref-Lowekamp2013" role="doc-biblioref">Lowekamp et al. 2013</a>; <a href="#ref-Yaniv2017" role="doc-biblioref">Yaniv et al. 2017</a>; <a href="#ref-Beare2018" role="doc-biblioref">Beare et al. 2018</a>)</span>. This nuanced representation is of particular
importance for specific medical imaging applications. Additionally, <code>SimpleITK</code>
incorporates metadata such as the origin, pixel spacing, and a matrix defining
the physical orientation of image axes <span class="citation" data-cites="Yaniv2017">(<a href="#ref-Yaniv2017" role="doc-biblioref">Yaniv et al. 2017</a>)</span>. However, the complexity
of the underlying ITK library may impede customization and necessitate
familiarity with C++. Another challenge for <code>R</code> developers arises from the fact
that the documentation is also based on C++ <span class="citation" data-cites="Beare2018">(<a href="#ref-Beare2018" role="doc-biblioref">Beare et al. 2018</a>)</span>. To facilitate the
learning process, <span class="citation" data-cites="Yaniv2017">Yaniv et al. (<a href="#ref-Yaniv2017" role="doc-biblioref">2017</a>)</span> has developed a series of Jupyter notebooks that
provide an introduction to the package and its capabilities for both Python and
<code>R</code> users. These notebooks serve as educational tools and a resource for research,
providing full coverage of the entire spectrum of image analysis
processes
<span class="citation" data-cites="Beare2018">(<a href="#ref-Beare2018" role="doc-biblioref">Beare et al. 2018</a>)</span>.<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a>
In combination with <code>R</code>, <code>SimpleITK</code> enables detailed image processing and
facilitates the subsequent statistical evaluation of quantified data. The
software is compatible with a range of digital image formats, including JPEG,
BMP, PNG, and TIFF, and is capable of analyzing 2D and 3D images
<span class="citation" data-cites="Beare2018">(<a href="#ref-Beare2018" role="doc-biblioref">Beare et al. 2018</a>)</span>. The package is obtained through the GitHub
repository.<a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a></p>
<p>In summary, these packages and their associated libraries offer a vast array of
algorithms that can be accessed in <code>R</code>. This includes features from the ‘CImg’,
‘ImageMagick’ and ITK libraries, along with the diverse algorithms encoded in the
<code>EBImage</code> package. These flexible packages provide the foundation for the
development of numerous tailored applications.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<h2 data-number="8" id="multi"><span class="header-section-number">8</span> Exploring the facets of complexity - multiplexed imaging in <code>R</code></h2>
<p>Multiplexed imaging is a crucial technology for analyzing complex biological
processes at the single-cell level, especially in tissue-based cancers and
autoimmune diseases <span class="citation" data-cites="Harris2022">(<a href="#ref-Harris2022" role="doc-biblioref">Harris et al. 2022b</a>)</span>. This technique enables the simultaneous
assessment of multiple protein and DNA molecules, overcoming limitations that
hinder advancements in understanding biological interactions and phenomena
<span class="citation" data-cites="Gerdes2013 Goltsev2018">(<a href="#ref-Gerdes2013" role="doc-biblioref">Gerdes et al. 2013</a>; <a href="#ref-Goltsev2018" role="doc-biblioref">Goltsev et al. 2018</a>)</span>. Multiplex imaging is the result of a multiplex
experiment, in which multiple species <span class="citation" data-cites="Aherne2024">(<a href="#ref-Aherne2024" role="doc-biblioref">Aherne et al. 2024</a>)</span>, biomolecules
<span class="citation" data-cites="Damond2019">(<a href="#ref-Damond2019" role="doc-biblioref">Damond et al. 2019</a>)</span>, or cell types <span class="citation" data-cites="Creed2021">(<a href="#ref-Creed2021" role="doc-biblioref">Creed et al. 2021</a>)</span> are labeled with different probes,
dyes, or antibodies simultaneously. This technique allows for the
differentiation of components within the resulting image <span class="citation" data-cites="Eling2020">(<a href="#ref-Eling2020" role="doc-biblioref">Eling et al. 2020</a>)</span>. In
comparison to standard immunofluorescence experiments, the number of distinct
targets is significantly increased, reaching up to 50 different target molecules
<span class="citation" data-cites="Damond2019 Einhaus2023">(<a href="#ref-Damond2019" role="doc-biblioref">Damond et al. 2019</a>; <a href="#ref-Einhaus2023" role="doc-biblioref">Einhaus et al. 2023</a>)</span>. This can be used to distinguish between species
in a biofilm <span class="citation" data-cites="Aherne2024">(<a href="#ref-Aherne2024" role="doc-biblioref">Aherne et al. 2024</a>)</span>, or to obtain an overview of the biomarker
distribution or tissue composition in a sample <span class="citation" data-cites="Damond2019 Yang2020">(<a href="#ref-Damond2019" role="doc-biblioref">Damond et al. 2019</a>; <a href="#ref-Yang2020" role="doc-biblioref">Yang et al. 2020</a>)</span>. The
technique has the capacity to reveal the positions and interactions of
individual cells, provide insight into the activities of biomolecules, and holds
the potential for the reconstruction of the three-dimensional tissue
architecture of a given sample <span class="citation" data-cites="Harris2022a Cho2023 Zhao2023">(<a href="#ref-Harris2022a" role="doc-biblioref">Harris et al. 2022a</a>; <a href="#ref-Cho2023" role="doc-biblioref">Cho et al. 2023</a>; <a href="#ref-Zhao2023" role="doc-biblioref">Zhao and Germain 2023</a>)</span>. Several
imaging techniques are used to obtain detailed insights into the spatial
interactions between cells, including Co-Detection by indEXing (CODEX)
<span class="citation" data-cites="Goltsev2018">(<a href="#ref-Goltsev2018" role="doc-biblioref">Goltsev et al. 2018</a>)</span>, Multiplex Ion Beam Imaging (MIBI) <span class="citation" data-cites="Angelo2014">(<a href="#ref-Angelo2014" role="doc-biblioref">Angelo et al. 2014</a>)</span>, and
Multiplexed Immunofluorescence Imaging (MxIF) <span class="citation" data-cites="Gerdes2013 Harris2022 Feng2023">(<a href="#ref-Gerdes2013" role="doc-biblioref">Gerdes et al. 2013</a>; <a href="#ref-Harris2022" role="doc-biblioref">Harris et al. 2022b</a>; <a href="#ref-Feng2023" role="doc-biblioref">Feng et al. 2023</a>)</span>. These methods generate vast amounts of imaging data, often
terabytes across hundreds of slides, which necessitates sophisticated image
analysis pipelines <span class="citation" data-cites="Harris2022a">(<a href="#ref-Harris2022a" role="doc-biblioref">Harris et al. 2022a</a>)</span>.</p>
<h3 data-number="8.1" id="mxnorm-normalize-multiplexed-imaging-data"><span class="header-section-number">8.1</span> <code>mxnorm</code>: normalize multiplexed imaging data</h3>
<p>Managing technical variability within these pipelines is crucial, and intensity
normalization is one approach to address this issue <span class="citation" data-cites="Harris2022a">(<a href="#ref-Harris2022a" role="doc-biblioref">Harris et al. 2022a</a>)</span>. The <code>R</code>
package <code>mxnorm</code> addresses this by providing tools for implementing, evaluating,
and visualizing various normalization techniques <span class="citation" data-cites="mxnorm">(<a href="#ref-mxnorm" role="doc-biblioref">Harris 2023</a>)</span>. These tools aid in
measuring technical variability and evaluating the efficacy of various
normalization methods. They enable users to apply customized methods to improve
image consistency by reducing technical variations while preserving biological
signals. <code>mxnorm</code> provides an analysis pipeline for multiplex
images, incorporating normalization algorithms inspired by the ComBat paper,
the <code>fda</code> package, and the tidyverse framework <span class="citation" data-cites="Harris2022">(<a href="#ref-Harris2022" role="doc-biblioref">Harris et al. 2022b</a>)</span>. For researchers
who want to effectively standardize multiplexed imaging data, these features
make <code>mxnorm</code> a powerful resource <span class="citation" data-cites="mxnorm">(<a href="#ref-mxnorm" role="doc-biblioref">Harris 2023</a>)</span>.</p>
<h3 data-number="8.2" id="dimple-manipulation-and-exploration-of-multiplex-images"><span class="header-section-number">8.2</span> <code>DIMPLE</code>: manipulation and exploration of multiplex images</h3>
<p>To assess patient outcomes, understand disease mechanisms, and develop effective
cancer therapies, the <code>DIMPLE</code> <code>R</code> package is designed to extract critical
information from the tumor microenvironment (TME). <code>DIMPLE</code> facilitates
quantification and visualization of cellular interactions within the TME using
spatial data. It also enables correlation of these interactions and phenotypic
data with patient outcomes through sophisticated statistical modeling. <code>DIMPLE</code>
provides researchers with an extensive toolkit to analyze cellular
interactions and transform raw multiplex imaging data into actionable biological
insights, potentially identifying prognostic indicators for cancer research and
therapy development. To support the analysis process, a <code>shiny</code> application is
provided <span class="citation" data-cites="Masotti2023">(<a href="#ref-Masotti2023" role="doc-biblioref">Masotti et al. 2023</a>)</span>.<a href="#fn21" class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a></p>
<h3 data-number="8.3" id="cytomapper-visualization-of-multiplex-images-and-cell-level-information"><span class="header-section-number">8.3</span> <code>cytomapper</code>: visualization of multiplex images and cell-level information</h3>
<p>The <code>cytomapper</code> package is designed to visualize multiplexed read-outs and
cell-level information obtained by multiplex imaging
technologies <span class="citation" data-cites="cytomapper">(<a href="#ref-cytomapper" role="doc-biblioref">Nils Eling, Nicolas Damond, Tobias Hoch 2020</a>)</span>. It offers various
functions to view pixel-level information across multiple channels and display
expression data for individual cells. Additionally, <code>cytomapper</code> includes
features to gate cells based on their expression values, enhancing the analysis
of complex data sets. It is compatible with data from various multiplex imaging
technologies and requires single-cell read-outs, multi-channel TIFF stacks,
and segmentation masks. The <code>cytomapper</code> package is a versatile tool for
researchers working with advanced imaging data sets to explore cellular behaviors
and properties <span class="citation" data-cites="Eling2020">(<a href="#ref-Eling2020" role="doc-biblioref">Eling et al. 2020</a>)</span>.</p>
<h3 data-number="8.4" id="spiat-analyzing-spatial-properties-of-tissues"><span class="header-section-number">8.4</span> <code>SPIAT</code>: analyzing spatial properties of tissues</h3>
<p>The <code>SPIAT</code> package, standing for <strong>Sp</strong>atial <strong>I</strong>mage <strong>A</strong>nalysis of
<strong>T</strong>issues, is among the most comprehensive tools for multiplex image analysis
<span class="citation" data-cites="AnnaTrigos2022">(<a href="#ref-AnnaTrigos2022" role="doc-biblioref">Trigos et al. 2022</a>)</span>. Developed with compatibility for multiplex imaging
technologies like CODEX and MIBI, <code>SPIAT</code> facilitates the analysis of spatial
data by using X and Y coordinates of cells, their marker intensities, and
phenotypes. It features six analysis modules that support a variety of functions
including visualization, cell co-localization, distance measurements between cell
types, categorization of the immune microenvironment in relation to tumor areas,
analysis of cellular neighborhoods and clusters, and quantification of spatial
heterogeneity <span class="citation" data-cites="Yang2020 AnnaTrigos2022">(<a href="#ref-Yang2020" role="doc-biblioref">Yang et al. 2020</a>; <a href="#ref-AnnaTrigos2022" role="doc-biblioref">Trigos et al. 2022</a>)</span>. To use <code>SPIAT</code>, images must be
pre-segmented and cells phenotyped, typically using external software like HALO
and InForm to prepare the correct input format <span class="citation" data-cites="Yang2020">(<a href="#ref-Yang2020" role="doc-biblioref">Yang et al. 2020</a>)</span>. The package
provides a <code>shiny</code> application that assists the user in formatting spatial data
from the aforementioned sources in a manner that ensures compatibility with the
functions of the <code>SPIAT</code> package.<a href="#fn22" class="footnote-ref" id="fnref22" role="doc-noteref"><sup>22</sup></a>
<code>SPIAT</code> is designed to be user-friendly, making complex spatial analysis
accessible to researchers with varying computational skills <span class="citation" data-cites="Feng2023">(<a href="#ref-Feng2023" role="doc-biblioref">Feng et al. 2023</a>)</span>.</p>
<h3 data-number="8.5" id="seurat-spatially-resolved-transcriptomics-srt"><span class="header-section-number">8.5</span> <code>Seurat</code>: spatially resolved transcriptomics (SRT)</h3>
<p>Spatially resolved transcriptomics (SRT) is a commonly used approach for the
quantification of gene expression levels in tissue sections while preserving
positional information <span class="citation" data-cites="larsson_semla_2023">(<a href="#ref-larsson_semla_2023" role="doc-biblioref">Larsson et al. 2023</a>)</span>. The <code>Seurat</code> package
<span class="citation" data-cites="hao_dictionary_2024">(<a href="#ref-hao_dictionary_2024" role="doc-biblioref">Hao et al. 2024</a>)</span> is a package for spatial transcriptomics and multiplexed
imaging analysis. It shares some similarities with the <code>SPIAT</code> and <code>spatialTIME</code>
packages. For assays with cell segmentation, <code>Seurat</code> facilitates the
visualization of individual cell boundaries or centroids, thereby enabling more
precise mapping of molecular signals to cells. In contrast to other reviewed
packages, <code>Seurat</code>’s unique feature is its integration of spatial and molecular
data for spatial data analysis. In particular, it enables the joint analysis of
spatially-resolved gene expression data alongside traditional single-cell
RNA-seq, allowing researchers to map cell types and states within their native
tissue context, along with metadata. Notably, <code>Seurat</code> supports the analysis and
visualization of spatial omics data at both single-cell and subcellular
resolution. <code>Seurat</code> deliberately supports a broad range of spatial
technologies, including the Akoya CODEX/Phenocycler platform and
sequencing-based platforms such as Visium Spatial Gene Expression, 10x Genomics
and Slide-seq. To achieve these capabilities, <code>Seurat</code> offers statistical
methods to identify genes or features with spatially structured expression
patterns, which facilitate the uncovering of region-specific biological
processes. Since its first publication in 2015 <span class="citation" data-cites="satija_spatial_2015">(<a href="#ref-satija_spatial_2015" role="doc-biblioref">Satija et al. 2015</a>)</span>, its
functionality has expanded to include support for image-based spatial
transcriptomics (highly multiplexed imaging technologies). <code>Seurat</code> uses image
data (e.g., raw, masked, processed images, 10X Genomics Visium Image).</p>
<h3 data-number="8.6" id="spatialtime-spatial-analysis-of-vectra-immunofluorescence-data"><span class="header-section-number">8.6</span> <code>spatialTIME</code>: spatial analysis of Vectra immunofluorescence data</h3>
<p>The <code>spatialTIME</code> package has been designed for the analysis of
immunofluorescence data with the objective of identifying spatial patterns
within the TME. The package appears to be designed to work with data acquired by
the Vectra Polaris™ imaging
system.<a href="#fn23" class="footnote-ref" id="fnref23" role="doc-noteref"><sup>23</sup></a>
It facilitates the spatial analysis of multiplex
immunofluorescence data, enabling spatial characterization and architectural
reconstruction. Additionally, the package includes a <code>shiny</code> application,
<code>iTIME</code>, which offers a user-friendly point-and-click interface that mirrors
many of the capabilities found in <code>spatialTIME</code>
<span class="citation" data-cites="Creed2021">(<a href="#ref-Creed2021" role="doc-biblioref">Creed et al. 2021</a>)</span>.<a href="#fn24" class="footnote-ref" id="fnref24" role="doc-noteref"><sup>24</sup></a>
The package also comes with a detailed vignette to help users get started with
its features <span class="citation" data-cites="spatialTime">(<a href="#ref-spatialTime" role="doc-biblioref">Creed et al. 2024</a>)</span>.</p>
<p>In summary, <code>R</code> offers a range of tools for analyzing multiplex imaging data.
However, it is important to note that these packages, except for the
<code>cytomapper</code> package, require image preprocessing and use the resulting data
frames as input for analysis.</p>
<h2 data-number="9" id="tracing-the-dance---r-packages-for-analyzing-cellular-movement-dynamics"><span class="header-section-number">9</span> Tracing the dance - <code>R</code> packages for analyzing cellular movement dynamics</h2>
<p>Cellular migration is essential for various physiological and pathological
functions, including development, immune responses, wound healing, and tumor
progression <span class="citation" data-cites="Bise2011 Yamada2019 Hossian2020">(<a href="#ref-Bise2011" role="doc-biblioref">Bise et al. 2011</a>; <a href="#ref-Yamada2019" role="doc-biblioref">Yamada and Sixt 2019</a>; <a href="#ref-Hossian2020" role="doc-biblioref">Hossian and Mattheolabakis 2020</a>)</span>, making it a crucial field
in disciplines such as neuroscience, oncology, and regenerative medicine
<span class="citation" data-cites="Kaiser2004 Hu2023">(<a href="#ref-Kaiser2004" role="doc-biblioref">Kaiser and Bruinink 2004</a>; <a href="#ref-Hu2023" role="doc-biblioref">Hu et al. 2023</a>)</span>. To gain insight into these biological processes,
researchers can track cell movement by manually tracing their positions in
sequential images for 2D coordinates or by incorporating the z coordinate for 3D
analysis <span class="citation" data-cites="Hu2023">(<a href="#ref-Hu2023" role="doc-biblioref">Hu et al. 2023</a>)</span>. By studying cell migration at multiple levels - from the
molecular components and the behavior of individual cells to the dynamics of
cell populations - researchers can unravel the complex interactions that
influence the movement of cells <span class="citation" data-cites="Maheshwari1998">(<a href="#ref-Maheshwari1998" role="doc-biblioref">Maheshwari and Lauffenburger 1998</a>)</span>. Such wide studies
are crucial in advancing our understanding of phenomena such as cancer
metastasis, which could lead to new therapeutic strategies <span class="citation" data-cites="Um2017">(<a href="#ref-Um2017" role="doc-biblioref">Um et al. 2017</a>)</span>.</p>
<h3 data-number="9.1" id="celltrackr-analyzing-motion-in-two-or-three-dimensions"><span class="header-section-number">9.1</span> <code>celltrackR</code>: analyzing motion in two or three dimensions</h3>
<p>The <code>celltrackR</code> package is intended for analyzing motion in two or three
dimensions, primarily using data from time-lapse microscopy or x-y-(z)
coordinates. It is useful in both biological settings for tracking cells and in
non-biological contexts for object tracking <span class="citation" data-cites="celltrackR">(<a href="#ref-celltrackR" role="doc-biblioref">Textor et al. 2024</a>)</span>. Additionally, the
package provides a web user interface to facilitate the analysis
process.<a href="#fn25" class="footnote-ref" id="fnref25" role="doc-noteref"><sup>25</sup></a> The package contains
standard analytical tools, such as mean square displacement and autocorrelation,
as well as algorithms for simulating artificial tracks using various models,
such as Brownian motion and the Beauchemin model of lymphocyte migration
<span class="citation" data-cites="celltrackR">(<a href="#ref-celltrackR" role="doc-biblioref">Textor et al. 2024</a>)</span>. Furthermore, <code>celltrackR</code> provides a complete pipeline for
track analysis, including data management, quality control, and methods for
detecting tracking errors, such as track interpolation and drift correction
<span class="citation" data-cites="Wortel2021">(<a href="#ref-Wortel2021" role="doc-biblioref">Wortel et al. 2021</a>)</span>. The package is well-documented, providing detailed vignettes that
guide users through the migration analysis process <span class="citation" data-cites="celltrackR">(<a href="#ref-celltrackR" role="doc-biblioref">Textor et al. 2024</a>)</span>.</p>
<h2 data-number="10" id="mapping-the-unseen---exploring-spatial-properties-in-bioimage-data"><span class="header-section-number">10</span> Mapping the unseen - exploring spatial properties in bioimage data</h2>
<p>In this section, we explore the use of <code>R</code> tools for analyzing spatial
properties in applications such as transcriptomics. One notable package is the
<code>MoleculeExperiment</code> package <span class="citation" data-cites="noauthor_moleculeexperiment_nodate">(<a href="#ref-noauthor_moleculeexperiment_nodate" role="doc-biblioref"><span>MoleculeExperiment</span> 2024</a>)</span>, which
can be used to analyze molecular data within image-based data sets. This package
builds upon other popular packages like <code>EBImage</code>, focusing on raster analysis,
and <code>terra</code> <span class="citation" data-cites="terra">(<a href="#ref-terra" role="doc-biblioref">Hijmans 2024</a>)</span> for handling geographic information systems (GIS) tasks.
Raster or gridded data are spatial data structures that divide regions into
rectangles called cells or pixels, storing one or more values. These grids
contrast with vector data representing points, lines, and polygons in GIS
contexts. Each pixel represents an area on a surface, making color image rasters
unique due to their multiple bands containing reflectance values for specific
colors or light spectra.</p>
<p>The <code>terra</code> package (formerly known as <code>raster/sp</code>) offers fast operations
through optimized back-end C++ code. Users can perform various raster tasks such
as creating objects, executing spatial/geometric functions like re-projections
and resampling, filtering, and conducting calculations. Functions within the
package facilitate extracting essential statistics from entire SpatRaster
data sets, including mean values, maximum values, value ranges, or counts of NA
cells. In addition to these analytical capabilities, <code>terra</code> provides
functionality for visualizing data and interacting with rasters, enhancing user
experience when working with gridded spatial information. This versatility makes
the package an essential tool in analyzing transcriptomic data within
image-based data sets using <code>R</code> tools <span class="citation" data-cites="Hijmans2020">(<a href="#ref-Hijmans2020" role="doc-biblioref">Hijmans 2020</a>)</span>.</p>
<h2 data-number="11" id="numbers-game---simplifying-scientific-image-data-representation"><span class="header-section-number">11</span> Numbers game - simplifying scientific image data representation</h2>
<p>The <code>R</code> environment offers multiple additional tools for
the extraction of information from data, with a particular focus on the
extraction of measuring points in scientific diagrams. This task is of
particular significance when data is available exclusively in image format, for
instance from publications or other sources.</p>
<h3 data-number="11.1" id="digitize-use-data-from-published-plots-or-images"><span class="header-section-number">11.1</span> <code>digitize</code>: use data from published plots or images</h3>
<p>The <code>digitize</code> package is a well-established and mature tool that simplifies
importing data from digital images by providing a user-friendly interface for
calibration and point location. It leverages the <code>readbitmap</code> package to read
various bitmap formats such as BMP, JPEG, PNG, and TIFF. When reading these
image files, digitize relies on the magic number embedded within each file
rather than solely relying on the file extension. For seamless integration with
JPEG and PNG images, this package depends on external libraries like ‘libjpg’
and ‘libpng’ <span class="citation" data-cites="poisot_digitize_2011">(<a href="#ref-poisot_digitize_2011" role="doc-biblioref">Poisot 2011</a>)</span>. Interestingly, the packages can be
used for other purposes as well. For example, Figure <a href="#fig:digitize">8</a>
demonstrates that the <code>digitize</code> package can quantify certain structures in
images. This example illustrates how fluorescent objects in an image can be
identified by their position and subsequently quantified by their number.</p>
<div class="layout-chunk" data-layout="l-body">

</div>

<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:digitize"></span>
<img src="RJ-2025-030_files/figure-html5/digitize-1.png" alt="Counting using digitize: The figure provided to digitize, consists of cells with DNA damage (similar to Rödiger et al. (2018)). The nucleus is colored with DAPI (blue) and the \(\gamma\)H2AX histone, a marker for DNA double strand breaks, is stained with a specific antibody. The digitize package is used to interactively extract the coordinates (shown in the console) by using the cursor to define the region of interest (blue cross) and tag the objects within it (red circles). In the screenshot it is displayed how digitize is invoked in RKWard (0.7.5z+0.7.6+devel3, Linux, TUXEDO OS 2, (Rödiger et al. 2012))." width="89%" />
<p class="caption">
Figure 8: <strong>Counting using <code>digitize</code></strong>: The figure provided to <code>digitize</code>, consists of cells with DNA damage (similar to <span class="citation" data-cites="Roediger2018">Rödiger et al. (<a href="#ref-Roediger2018" role="doc-biblioref">2018</a>)</span>). The nucleus is colored with DAPI (blue) and the <span class="math inline">\(\gamma\)</span>H2AX histone, a marker for DNA double strand breaks, is stained with a specific antibody. The <code>digitize</code> package is used to interactively extract the coordinates (shown in the console) by using the cursor to define the region of interest (blue cross) and tag the objects within it (red circles). In the screenshot it is displayed how <code>digitize</code> is invoked in RKWard (0.7.5z+0.7.6+devel3, Linux, TUXEDO OS 2, <span class="citation" data-cites="Roediger2012">(<a href="#ref-Roediger2012" role="doc-biblioref">Rödiger et al. 2012</a>)</span>).
</p>
</div>
</div>
<h3 data-number="11.2" id="juicr-extraction-of-numerical-data-from-scientific-images"><span class="header-section-number">11.2</span> <code>juicr</code>: extraction of numerical data from scientific images</h3>
<p><code>juicr</code> is a tool designed to automate the extraction of numerical data from
scientific images. It offers users a Tcl/Tk graphical user interface (GUI) that
simplifies point-and-click manual extraction with advanced features such as
image zooming, calibration capabilities, and classification options.
Additionally, <code>juicr</code> provides semi-automated tools for fine-tuning extraction
attempts. To ensure optimal performance, this package depends on
the <code>EBImage</code> package, which must be installed and loaded
prior to utilization. Once data is extracted using <code>juicr</code>, users can choose to
save their results in various formats including comma-separated values (CSV)
files or postscript (EPS) files for easy import into other software. Moreover,
extractions can also be saved as fully-embedded and standalone HTML files, that
preserve all extraction details, setup configurations, and image modifications.
These HTML files provide a means of storing data while ensuring long-term
accessibility and replicability for future reference and analysis purposes
<span class="citation" data-cites="juicr">(<a href="#ref-juicr" role="doc-biblioref">Lajeunesse 2021</a>)</span>.</p>
<h3 data-number="11.3" id="image2data-transforming-images-into-data-sets"><span class="header-section-number">11.3</span> <code>image2data</code>: transforming images into data sets</h3>
<p>In recent years, the conversion of images into data sets has emerged as an
essential tool in various fields such as computer vision, healthcare, and
geospatial analysis. The <code>image2data</code> <code>R</code> package provides functionality to
convert images into data sets <span class="citation" data-cites="caron_image2data_2022">(<a href="#ref-caron_image2data_2022" role="doc-biblioref">Caron and Dufresne 2022</a>)</span>. The primary function <code>image2data()</code> takes
an image file with extensions like .png, .tiff, .jpeg or .bmp as input and
converts it into a data set. Each row of the resulting data set represents a pixel
(or subject), while columns represent variables such as x-coordinate,
y-coordinate, and hex color code. The <code>image2data()</code> function offers
methods for reducing data sets, yielding results akin to pixelated images with
adjustable precision values. Higher precision leads to more data points, while
lower precision yields fewer. This example showcases a pixelated representation
of a pixel-based image in PNG format, highlighting its unique visual attributes.
Users have the ability to customize and modify various elements by adjusting
their corresponding hex color codes for precise control over hues, saturation
levels, and brightness.</p>

<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># Loading the required packages</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>image2data</span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://r-datatable.com'>data.table</a></span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Path to the image file</span></span>
<span><span class='va'>image</span> <span class='op'>&lt;-</span> <span class='st'>"figures/test3.png"</span></span>
<span><span class='va'>img</span> <span class='op'>&lt;-</span> <span class='fu'>EBImage</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/EBImage/man/io.html'>readImage</a></span><span class='op'>(</span><span class='va'>image</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Subsampling the image data</span></span>
<span><span class='va'>beads_subsample</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/image2data/man/image2data.html'>image2data</a></span><span class='op'>(</span></span>
<span>  path <span class='op'>=</span> <span class='va'>image</span>,                    <span class='co'># Path to the image file</span></span>
<span>  reduce <span class='op'>=</span> <span class='fl'>.2</span>,                     <span class='co'># Reduction factor for subsampling </span></span>
<span>                                   <span class='co'># (20 % of original number of pixels)</span></span>
<span>  seed <span class='op'>=</span> <span class='fl'>42</span>,                       <span class='co'># Seed for random number generation by</span></span>
<span>                                   <span class='co'># return (for reproducibility)</span></span>
<span>  showplot <span class='op'>=</span> <span class='cn'>FALSE</span>                 <span class='co'># Whether to show a plot of the subsampled data</span></span>
<span><span class='op'>)</span> <span class='op'>|&gt;</span> <span class='fu'><a href='https://rdatatable.gitlab.io/data.table/reference/as.data.table.html'>as.data.table</a></span><span class='op'>(</span><span class='op'>)</span>               <span class='co'># Converting the result to a data.table</span></span>
<span></span>
<span><span class='co'># Display a part of the subsampled data</span></span>
<span><span class='va'>beads_subsample</span></span></code></pre>
</div>
<pre><code>                x          y       g
            &lt;num&gt;      &lt;num&gt;  &lt;char&gt;
    1:  0.1022393 -0.9263444 #2F5C61
    2: -0.1022393  0.4006978 #121D11
    3:  1.2449136 -0.5213380 #121B10
    4:  0.4871401 -1.6588028 #151E1C
    5: -0.3548305 -1.5381626 #0D1B0D
   ---                              
23151: -1.1486884  1.1159219 #352B5E
23152: -0.6074216  0.1508003 #252E60
23153:  1.4975048  0.5988925 #14180B
23154: -1.3651952  0.2025032 #2A306B
23155:  0.3428023 -0.3231434 #112048</code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'>EBImage</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/EBImage/man/display.html'>display</a></span><span class='op'>(</span><span class='va'>img</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Plotting the subsampled data</span></span>
<span><span class='fu'><a href='https://rspatial.github.io/terra/reference/plot.html'>plot</a></span><span class='op'>(</span><span class='va'>beads_subsample</span><span class='op'>$</span><span class='va'>x</span>,            <span class='co'># x-coordinates</span></span>
<span>     <span class='va'>beads_subsample</span><span class='op'>$</span><span class='va'>y</span>,            <span class='co'># y-coordinates</span></span>
<span>     col <span class='op'>=</span> <span class='va'>beads_subsample</span><span class='op'>$</span><span class='va'>g</span>,      <span class='co'># Color based on hex code extracted by image2data()</span></span>
<span>     pch <span class='op'>=</span> <span class='fl'>19</span>,                     <span class='co'># Plotting character (solid circle)</span></span>
<span>     xlab <span class='op'>=</span> <span class='st'>""</span>,</span>
<span>     ylab <span class='op'>=</span> <span class='st'>""</span><span class='op'>)</span></span></code></pre>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:img2data"></span>
<img src="RJ-2025-030_files/figure-html5/img2data-1.png" alt="Application Example of the image2data Package: The image displays nuclei stained with DAPI (blue) and a quantitative marker for DNA double strand breaks, was labeled with a specific antibody (green). The image2data package extracted 20% of the pixels from the original image (top), creating a table with x|y coordinates and corresponding hex color codes. This data was then used to reassemble the image using R’s base plot (bottom)." width="65%" /><img src="RJ-2025-030_files/figure-html5/img2data-2.png" alt="Application Example of the image2data Package: The image displays nuclei stained with DAPI (blue) and a quantitative marker for DNA double strand breaks, was labeled with a specific antibody (green). The image2data package extracted 20% of the pixels from the original image (top), creating a table with x|y coordinates and corresponding hex color codes. This data was then used to reassemble the image using R’s base plot (bottom)." width="65%" />
<p class="caption">
Figure 9: <strong>Application Example of the <code>image2data</code> Package</strong>: The image displays nuclei stained with DAPI (blue) and a quantitative marker for DNA double strand breaks, was labeled with a specific antibody (green). The <code>image2data</code> package extracted 20% of the pixels from the original image (top), creating a table with x|y coordinates and corresponding hex color codes. This data was then used to reassemble the image using <code>R</code>’s base plot (bottom).
</p>
</div>
</div>
<h2 data-number="12" id="inter"><span class="header-section-number">12</span> Engaging insights - interactive approaches to image analysis</h2>
<p>The analysis and processing of images to extract useful information can be a
challenging endeavor. Consequently, the implementation of interactive approaches
accompanied by immediate visual feedback regarding parameter alterations
represents a significant aid in simplifying image analysis. Therefore, this
section will focus on interactive tools and functions from packages that
facilitate the exploration of images and the extraction of useful insights.</p>
<h3 data-number="12.1" id="cytomapper-a-shiny-application-for-hierarchical-gating-and-visualization-of-multiplex-images"><span class="header-section-number">12.1</span> <code>cytomapper</code>: a shiny application for hierarchical gating and visualization of multiplex images</h3>
<p>The <code>cytomapper</code> package, designed for processing multiplex images, includes a
<code>shiny</code> application that facilitates the hierarchical gating of cells using
specific markers and allows for the visualization of selected cells. The
graphical user interface (GUI) of this <code>shiny</code> application is designed to assist in
the process of cell labeling. Furthermore, the data from the selected cells can
be saved as a <em>SingleCellExperiment</em>, thereby enabling various downstream
processing methods <span class="citation" data-cites="Eling2020 cytomapper">(<a href="#ref-cytomapper" role="doc-biblioref">Nils Eling, Nicolas Damond, Tobias Hoch 2020</a>; <a href="#ref-Eling2020" role="doc-biblioref">Eling et al. 2020</a>)</span>. The <code>cytomapper</code> package offers
comparable functionality for feature extraction as described in the beginning,
providing an algorithm for extracting morphological and intensity
features from multiplex images <span class="citation" data-cites="cytomapper">(<a href="#ref-cytomapper" role="doc-biblioref">Nils Eling, Nicolas Damond, Tobias Hoch 2020</a>)</span>.</p>
<h3 data-number="12.2" id="colocr-interactive-roi-selection-in-image-analysis-through-shiny-app"><span class="header-section-number">12.2</span> <code>colocr</code>: interactive ROI selection in image analysis through shiny app</h3>
<p>The <code>colocr</code> package, which facilitates the exploration of fluorescent
microscopic images, features a GUI accessible through a <code>shiny</code> app. This GUI
can be invoked locally or accessed online. The process of image analysis
frequently necessitates the input of manual labor, particularly in the selection
of ROIs. This package streamlines the process of selecting ROIs by
semi-automating it, thereby allowing users to review and interactively select
one or more ROIs. Moreover, the app offers the option to interactively adjust
parameters such as threshold, tolerance, denoising, and hole filling, thereby
enhancing user control and precision in image analysis by providing immediate
feedback <span class="citation" data-cites="Ahmed2019 colocr">(<a href="#ref-Ahmed2019" role="doc-biblioref">Ahmed et al. 2019</a>; <a href="#ref-colocr" role="doc-biblioref">Ahmed 2020</a>)</span>.<a href="#fn26" class="footnote-ref" id="fnref26" role="doc-noteref"><sup>26</sup></a></p>

<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:colocrGUI"></span>
<img src="figures/colocr_gui.png" alt="Shiny Application of the colocr Package: The figure depicts an interactive image analysis graphical user interface (GUI), invoked locally from the RStudio integrated development environment (IDE). It comprises multiple sliders for real-time parameter adjustments and supports the selection of multiple distinct regions of interest (ROIs). Users can interactively select ROIs and extract characteristics such as pixel intensity. Furthermore, the tool offers functionalities to compute co-localization, providing comprehensive analysis capabilities. Available at: https://mahshaaban.shinyapps.io/colocr_app2/ or run: colocr::colocr_app()." width="69%" />
<p class="caption">
Figure 10: <strong>Shiny Application of the <code>colocr</code> Package</strong>: The figure depicts an interactive image analysis graphical user interface (GUI), invoked locally from the RStudio integrated development environment (IDE). It comprises multiple sliders for real-time parameter adjustments and supports the selection of multiple distinct regions of interest (ROIs). Users can interactively select ROIs and extract characteristics such as pixel intensity. Furthermore, the tool offers functionalities to compute co-localization, providing comprehensive analysis capabilities. Available at: <a href="https://mahshaaban.shinyapps.io/colocr_app2/" class="uri">https://mahshaaban.shinyapps.io/colocr_app2/</a> or run: <code>colocr::colocr_app()</code>.
</p>
</div>
</div>
<h3 data-number="12.3" id="magick-shiny-and-tcltk-tools-for-interactive-image-exploration"><span class="header-section-number">12.3</span> <code>magick</code>: shiny and Tcl/Tk tools for interactive image exploration</h3>
<p>A basic demo version of an interactive web interface for the <code>magick</code> <code>R</code> package
is available via a <code>shiny</code> app. While it remains a demonstration version and
does not encompass all the functionalities of the full package, it is not
suitable for in-depth analysis of large-scale imaging data. In contrast, the app
provides fundamental tools for image processing, including blurring, imploding,
rotating, and more. This tool is designed to facilitate basic image
processing tasks in an interactive
environment.<a href="#fn27" class="footnote-ref" id="fnref27" role="doc-noteref"><sup>27</sup></a>
Additionally, a distinct package is available that provides the functionality of
<code>magick</code> in an interactive manner. This package, called <code>magickGUI</code>, was
developed by <span class="citation" data-cites="magickGUI">Ochi (<a href="#ref-magickGUI" role="doc-biblioref">2023</a>)</span>. The interactive features are based on the Tcl/Tk
wrapper for <code>R</code> and include functions for thresholding, edge detection, noise
reduction, and many more.</p>
<h3 data-number="12.4" id="biopixr-interactive-tcltk-function-for-feature-extraction"><span class="header-section-number">12.4</span> <code>biopixR</code>: interactive Tcl/Tk function for feature extraction</h3>
<p>In the <code>biopixR</code> package, the <code>tcltk</code> package — which enables Tcl/Tk integration
in <code>R</code> — was employed to create an interactive function. This function initiates
the launch of a GUI that streamlines the process of feature extraction by
facilitating object detection and enabling users to select between edge
detection and thresholding for segmentation. The GUI displays the currently
detected edges (when using edge detector) or all detected coordinates (when
using threshold) and the object centers within an image. The application
includes sliders that allow users to adjust parameters and magnify the image.
This interactive function is designed to facilitate the parameter selection
process, as the chosen parameters affect the quality of image segmentation
<span class="citation" data-cites="biopixR">(<a href="#ref-biopixR" role="doc-biblioref">Brauckhoff et al. 2024</a>)</span>.</p>
<h2 data-number="13" id="tailored-tools---specialized-r-packages-for-image-processing"><span class="header-section-number">13</span> Tailored tools - specialized <code>R</code> packages for image processing</h2>
<p>In contrast to the previously mentioned general-purpose tools, some packages
have been designed with a specific focus on particular research areas. These
specialized tools address the unique challenges encountered in those fields and
offer versatile solutions for analyzing the data collected in those domains.
While a complete survey of the available packages is outside the scope of
this article, a concise overview of the most pertinent packages and their
applications will be presented.</p>
<h3 data-number="13.1" id="fslr-analysis-of-neuroimage-data"><span class="header-section-number">13.1</span> <code>fslr</code>: analysis of neuroimage data</h3>
<p>The <code>fslr</code> package serves as a wrapper for the FSL software, enabling the use
of the ‘FMRIB’ Software Library within the <code>R</code> environment. The
FSL software is a widely utilized tool for the analysis and processing of
neuroimaging data, including MRI. The package employs the use of <code>NIfTI</code> images
to facilitate the execution of processing tasks, thereby introducing
capabilities such as brain extraction and tissue segmentation, which were
previously unavailable in <code>R</code> <span class="citation" data-cites="Muschelli2015 fslr">(<a href="#ref-Muschelli2015" role="doc-biblioref">Muschelli et al. 2015</a>; <a href="#ref-fslr" role="doc-biblioref">Muschelli 2022</a>)</span>.</p>
<h3 data-number="13.2" id="colocr-co-localization-analysis-of-fluorescence-microscopy-images"><span class="header-section-number">13.2</span> <code>colocr</code>: co-localization analysis of fluorescence microscopy images</h3>
<p>A common application derived from fluorescence microscopy, which is extensively
utilized in biological research, is co-localization analysis. This analysis
assesses the distribution of signals across different color channels to
determine whether the positioning of objects is correlated <span class="citation" data-cites="Dunn2011 Ahmed2019">(<a href="#ref-Dunn2011" role="doc-biblioref">Dunn et al. 2011</a>; <a href="#ref-Ahmed2019" role="doc-biblioref">Ahmed et al. 2019</a>)</span>. The objective of this software is to streamline the analysis
process by providing tools for loading
images, selecting regions of interest, and calculating co-localization
statistics <span class="citation" data-cites="Ahmed2019 colocr">(<a href="#ref-Ahmed2019" role="doc-biblioref">Ahmed et al. 2019</a>; <a href="#ref-colocr" role="doc-biblioref">Ahmed 2020</a>)</span>. It incorporates methods outlined by
<span class="citation" data-cites="Dunn2011">Dunn et al. (<a href="#ref-Dunn2011" role="doc-biblioref">2011</a>)</span>.<a href="#fn28" class="footnote-ref" id="fnref28" role="doc-noteref"><sup>28</sup></a></p>
<p>CRAN offers a list of packages tailored to medical image
analysis, accompanied by detailed descriptions of their applications. This list
can be accessed via the following URL:</p>
<p><a href="https://cran.r-project.org/web/views/MedicalImaging.html" class="uri">https://cran.r-project.org/web/views/MedicalImaging.html</a></p>
<p>Moreover, the Bioconductor repository contains a number of packages focused on
single-cell analysis, as detailed by <span class="citation" data-cites="Amezquita2019">Amezquita et al. (<a href="#ref-Amezquita2019" role="doc-biblioref">2019</a>)</span>. The Bioconductor project is
an initiative dedicated to the collaborative development and the use of scalable
software for computational biology and bioinformatics. Its objective is to
reduce the entry barriers to interdisciplinary research and to improve the
remote reproducibility of scientific findings <span class="citation" data-cites="Gentleman2004">(<a href="#ref-Gentleman2004" role="doc-biblioref">Gentleman et al. 2004</a>)</span>. Other packages
identified during the course of our research, though not explored in depth, are
acknowledged in the forthcoming summary:</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<table>
<caption><span id="tab:overview1">Table 1: </span>Overview of <code>R</code> packages for tailored applications in image processing. This table summarizes key aspects such as general application, repository (Repo) hosting (CRAN, Bioconductor (Bioc), GitLab), linked libraries, and package dependencies. It also includes information on licensing and current status. The current status is divided into the date of first publication on the corresponding repository (*). Active repository status is indicated by a circle, with the date of the latest update (°). Some packages that are no longer maintained are marked as archived (†).</caption>
<colgroup>
<col style="width: 30%" />
<col style="width: 23%" />
<col style="width: 8%" />
<col style="width: 11%" />
<col style="width: 10%" />
<col style="width: 15%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: center;">Application</th>
<th style="text-align: center;">Repo</th>
<th style="text-align: center;">based on</th>
<th style="text-align: center;">License</th>
<th style="text-align: center;">Status</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>adimpro</strong><br>by <span class="citation" data-cites="Polzehl2007">Polzehl and Tabelow (<a href="#ref-Polzehl2007" role="doc-biblioref">2007</a>)</span></td>
<td style="text-align: center;">Adaptive Smoothing</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=adimpro">CRAN</a></td>
<td style="text-align: center;">Image Magick</td>
<td style="text-align: center;">GPL<br>(<span class="math inline">\(\geq\)</span> 2)</td>
<td style="text-align: center;">*2006-10-27<br>°2023-09-06</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>phenopix</strong><br>by <span class="citation" data-cites="Filippa2016">Filippa et al. (<a href="#ref-Filippa2016" role="doc-biblioref">2016</a>)</span></td>
<td style="text-align: center;">Vegetation phenology</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=phenopix">CRAN</a></td>
<td style="text-align: center;">jpeg</td>
<td style="text-align: center;">GPL-2</td>
<td style="text-align: center;">*2017-06-16<br>°2024-01-19</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>gitter</strong><br>by <span class="citation" data-cites="Wagih2014">Wagih and Parts (<a href="#ref-Wagih2014" role="doc-biblioref">2014</a>)</span></td>
<td style="text-align: center;">Pinned Microbial Cultures</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=gitter">CRAN-archived</a></td>
<td style="text-align: center;">EBImage</td>
<td style="text-align: center;">LGPL</td>
<td style="text-align: center;">*2013-06-29<br>†2020-01-16</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>TCIApathfinder</strong><br>by <span class="citation" data-cites="Russell2018">Russell et al. (<a href="#ref-Russell2018" role="doc-biblioref">2018</a>)</span></td>
<td style="text-align: center;">Cancer Imaging</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=TCIApathfinder">CRAN</a></td>
<td style="text-align: center;">Rnifti</td>
<td style="text-align: center;">MIT</td>
<td style="text-align: center;">*2017-08-20<br>°2019-09-21</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>SPUTNIK</strong><br>by <span class="citation" data-cites="Inglese2018">Inglese et al. (<a href="#ref-Inglese2018" role="doc-biblioref">2018</a>)</span></td>
<td style="text-align: center;">Mass Spectrometry Imaging</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=SPUTNIK">CRAN</a></td>
<td style="text-align: center;">imager</td>
<td style="text-align: center;">GPL<br>(<span class="math inline">\(\geq\)</span> 3)</td>
<td style="text-align: center;">*2018-02-19<br>°2024-04-16</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>SAFARI</strong><br>by <span class="citation" data-cites="Fernandez2022">Fernández et al. (<a href="#ref-Fernandez2022" role="doc-biblioref">2022</a>)</span></td>
<td style="text-align: center;">Shape analysis</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=SAFARI">CRAN</a></td>
<td style="text-align: center;">EBImage</td>
<td style="text-align: center;">GPL<br>(<span class="math inline">\(\geq\)</span> 3)</td>
<td style="text-align: center;">*2021-02-25</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>pavo</strong><br>by <span class="citation" data-cites="Maia2019">Maia et al. (<a href="#ref-Maia2019" role="doc-biblioref">2019</a>)</span></td>
<td style="text-align: center;">Spectral and Spatial analysis</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=pavo">CRAN</a></td>
<td style="text-align: center;">magick &amp; imager</td>
<td style="text-align: center;">GPL<br>(<span class="math inline">\(\geq\)</span> 2)</td>
<td style="text-align: center;">*2012-12-05<br>°2023-09-24</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>miet</strong><br>by <span class="citation" data-cites="Combes2020">Combès (<a href="#ref-Combes2020" role="doc-biblioref">2020</a>)</span></td>
<td style="text-align: center;">Magnetic Resonance images</td>
<td style="text-align: center;"><a href="https://gitlab.inria.fr/miet/miet">gitlab</a></td>
<td style="text-align: center;">Rnifti</td>
<td style="text-align: center;">MIT</td>
<td style="text-align: center;">*2019-09-06<br>°2023-12-20</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>scalpel</strong><br>by <span class="citation" data-cites="Petersen2017">Petersen et al. (<a href="#ref-Petersen2017" role="doc-biblioref">2017</a>)</span></td>
<td style="text-align: center;">Calcium imaging</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=scalpel">CRAN</a></td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">GPL<br>(<span class="math inline">\(\geq\)</span> 2)</td>
<td style="text-align: center;">*2017-03-14<br>°2021-02-03</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>ProFit</strong><br>by <span class="citation" data-cites="Robotham2016">Robotham et al. (<a href="#ref-Robotham2016" role="doc-biblioref">2016</a>)</span></td>
<td style="text-align: center;">Galaxy images</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=ProFit">CRAN-archived</a></td>
<td style="text-align: center;">EBImage</td>
<td style="text-align: center;">LGPL-3</td>
<td style="text-align: center;">*2016-09-29<br>†2022-08-08</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>fsbrain</strong><br>by <span class="citation" data-cites="Schaefer2020">Schäfer and Ecker (<a href="#ref-Schaefer2020" role="doc-biblioref">2020</a>)</span> <span class="citation" data-cites="Schaefer2024">Schaefer (<a href="#ref-Schaefer2024" role="doc-biblioref">2024</a>)</span></td>
<td style="text-align: center;">Neuroimaging</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=fsbrain">CRAN</a></td>
<td style="text-align: center;">magick</td>
<td style="text-align: center;">MIT</td>
<td style="text-align: center;">*2019-10-30<br>°2024-02-03</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>geomorph</strong><br>by <span class="citation" data-cites="Adams2013">Adams and Otárola‐Castillo (<a href="#ref-Adams2013" role="doc-biblioref">2013</a>)</span></td>
<td style="text-align: center;">Geometric morphometric shape analysis</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=geomorph">CRAN</a></td>
<td style="text-align: center;">jpeg</td>
<td style="text-align: center;">GPL<br>(<span class="math inline">\(\geq\)</span> 3)</td>
<td style="text-align: center;">*2012-10-26<br>°2024-03-05</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>imbibe</strong></td>
<td style="text-align: center;">Medical images</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=imbibe">CRAN</a></td>
<td style="text-align: center;">Rnifti</td>
<td style="text-align: center;">BSD-3-clause</td>
<td style="text-align: center;">*2020-10-26<br>°2022-11-09</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>opencv</strong><br>by <span class="citation" data-cites="opencv">Ooms and Wijffels (<a href="#ref-opencv" role="doc-biblioref">2024</a>)</span></td>
<td style="text-align: center;">edge, body, face detection</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=opencv">CRAN</a></td>
<td style="text-align: center;">OpenCV</td>
<td style="text-align: center;">MIT</td>
<td style="text-align: center;">*2019-04-01<br>°2023-10-29</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>DRIP</strong></td>
<td style="text-align: center;">jump regression, denoising, deblurring</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=DRIP">CRAN</a></td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">GPL<br>(<span class="math inline">\(\geq\)</span> 2)</td>
<td style="text-align: center;">*2015-09-22<br>°2024-02-05</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>imagefluency</strong><br>by <span class="citation" data-cites="imagefluency">Mayer (<a href="#ref-imagefluency" role="doc-biblioref">2024</a>)</span></td>
<td style="text-align: center;">image statistics based on fluency theory</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=imagefluency">CRAN</a></td>
<td style="text-align: center;">magick &amp; OpenImageR</td>
<td style="text-align: center;">GPL-3</td>
<td style="text-align: center;">*2019-09-27<br>°2024-02-22</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>mand</strong><br>by <span class="citation" data-cites="mand">Kawaguchi (<a href="#ref-mand" role="doc-biblioref">2021</a>)</span></td>
<td style="text-align: center;">Neuroimaging</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=mand">CRAN</a></td>
<td style="text-align: center;">imager</td>
<td style="text-align: center;">GPL-2<br>GPL-3</td>
<td style="text-align: center;">*2020-05-06<br>°2023-09-12</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>recolorize</strong><br>by <span class="citation" data-cites="recolorize">Weller et al. (<a href="#ref-recolorize" role="doc-biblioref">2024</a>)</span></td>
<td style="text-align: center;">Segmentation</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=recolorize">CRAN</a></td>
<td style="text-align: center;">imager</td>
<td style="text-align: center;">CC BY 4.0</td>
<td style="text-align: center;">*2021-12-07</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>MaxContrastProjection</strong><br>by <span class="citation" data-cites="MaxContrastProjection">Jan Sauer (<a href="#ref-MaxContrastProjection" role="doc-biblioref">2017</a>)</span></td>
<td style="text-align: center;">maximum contrast projection</td>
<td style="text-align: center;"><a href="https://bioconductor.org/packages/MaxContrastProjection/">Bioc</a></td>
<td style="text-align: center;">EBImage</td>
<td style="text-align: center;">Artistic-2.0</td>
<td style="text-align: center;">*2017-04-25<br>†2020-04-28</td>
</tr>
</tbody>
</table>
</div>
<div class="sourceCode" id="cb5"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<h2 data-number="14" id="combining-forces---making-use-of-the-open-source-approach"><span class="header-section-number">14</span> Combining forces - making use of the open-source approach</h2>
<p>The majority of the aforementioned packages are designed to encompass all facets
of image analysis, including preprocessing, quantification, and visualization.
This integration is typically achieved through the utilization of one or more
general-purpose packages (Table <a href="#tab:overview1">1</a> and <a href="#tab:overview2">2</a>).
The combination of existing packages or libraries with new code facilitates the
development of specialized packages. <code>R</code>, as a package-based language, provides a
convenient means of combining these specialized packages to meet the specific
needs of the individual user. The following section illustrates the combination of
packages to perform statistical analysis on quantified image data.</p>
<h3 data-number="14.1" id="biopixr-and-countfitter-quantitative-analysis-of-dna-double-strand-breaks"><span class="header-section-number">14.1</span> <code>biopixR</code> and <code>countfitteR</code>: quantitative analysis of DNA double strand breaks</h3>
<p>DNA double strand breaks (DSBs) represent a particularly severe form of DNA
damage, frequently resulting in apoptotic cell death in the absence of repair.
The extent of DNA damage can be quantified through immunofluorescence
staining, which employs antibodies against the phosphorylated histone protein
H2AX (<span class="math inline">\(\gamma\)</span>H2AX). The staining process results in the formation of
<span class="math inline">\(\gamma\)</span>H2AX foci, which serve as a quantitative representation of the number of
DNA DSBs. It has been proposed that the number of DNA DSBs is indicative of the
efficacy of an anti-tumor agent, thereby enabling the assessment of individual
patient responses to therapies and the evaluation of the general cytotoxic
effects of treatments <em>in vivo</em>. This enables more precise modulation of therapy
according to the patient’s individual needs <span class="citation" data-cites="Roediger2018 Ruhe2019 schneider_open_2019">(<a href="#ref-Roediger2018" role="doc-biblioref">Rödiger et al. 2018</a>; <a href="#ref-schneider_open_2019" role="doc-biblioref">Schneider et al. 2019</a>; <a href="#ref-Ruhe2019" role="doc-biblioref">Ruhe et al. 2019</a>)</span>.</p>
<p>In the following example, the <code>biopixR</code> package was employed to quantify DNA
double-strand breaks, resulting in an output of foci per cell (Figure
<a href="#fig:DSB">11</a>). To achieve this objective, the green fluorescent foci were
extracted by applying the <code>objectDetection()</code> function to the green color
channel of the image (Figure <a href="#fig:DSB">11</a>A). The result of the foci extraction
is illustrated in Figure <a href="#fig:DSB">11</a>B using the <code>changePixelColor()</code> function,
whereby each of the distinct foci is highlighted in a different color. The DAPI-stained
nuclei were extracted through the application of thresholding on the blue color
channel. Subsequently, the resulting data frame was subjected to size filtering
in order to eliminate any detected noise. The final quantification of foci per
cell was achieved by comparing the coordinates of nuclei and foci in the
obtained data frames. This result can then be further analyzed using the
<code>countfitteR</code> package, which provides an automated evaluation of
distribution models for count data <span class="citation" data-cites="Burdukiewicz2019 Chilimoniuk2021">(<a href="#ref-Burdukiewicz2019" role="doc-biblioref">Burdukiewicz 2019</a>; <a href="#ref-Chilimoniuk2021" role="doc-biblioref">Chilimoniuk et al. 2021</a>)</span>. The
resulting distribution is presented in Figure <a href="#fig:countfitteR">12</a>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># Load the 'biopixR' package</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/Brauckhoff/biopixR'>biopixR</a></span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Import image from specified path</span></span>
<span><span class='va'>DSB_img</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/biopixR/man/importImage.html'>importImage</a></span><span class='op'>(</span><span class='st'>"figures/tim_242602_c_s3c1+2+3m4.tif"</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Extract the blue color channel representing the nuclei and</span></span>
<span><span class='co'># the green color channel representing yH2AX foci</span></span>
<span><span class='va'>core</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/imager/man/as.cimg.html'>as.cimg</a></span><span class='op'>(</span><span class='va'>DSB_img</span><span class='op'>[</span>, , , <span class='fl'>3</span><span class='op'>]</span><span class='op'>)</span></span>
<span><span class='va'>yH2AX</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/imager/man/as.cimg.html'>as.cimg</a></span><span class='op'>(</span><span class='va'>DSB_img</span><span class='op'>[</span>, , , <span class='fl'>2</span><span class='op'>]</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Process the nuclei: thresholding, labeling, and converting to a data frame</span></span>
<span><span class='va'>cores</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/pkg/imager/man/threshold.html'>threshold</a></span><span class='op'>(</span><span class='va'>core</span><span class='op'>)</span> <span class='op'>|&gt;</span> <span class='fu'><a href='https://rdrr.io/pkg/imager/man/label.html'>label</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>|&gt;</span> <span class='fu'><a href='https://rspatial.github.io/terra/reference/as.data.frame.html'>as.data.frame</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>|&gt;</span> <span class='fu'><a href='https://rspatial.github.io/terra/reference/subset.html'>subset</a></span><span class='op'>(</span><span class='va'>value</span> <span class='op'>&gt;</span> <span class='fl'>0</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Calculate the center and size for the nuclei</span></span>
<span><span class='va'>DT</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdatatable.gitlab.io/data.table/reference/as.data.table.html'>as.data.table</a></span><span class='op'>(</span><span class='va'>cores</span><span class='op'>)</span></span>
<span><span class='va'>cores_center</span> <span class='op'>&lt;-</span></span>
<span>  <span class='va'>DT</span><span class='op'>[</span>, <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span>mx <span class='op'>=</span> <span class='fu'><a href='https://rspatial.github.io/terra/reference/summarize-generics.html'>mean</a></span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span>,</span>
<span>            my <span class='op'>=</span> <span class='fu'><a href='https://rspatial.github.io/terra/reference/summarize-generics.html'>mean</a></span><span class='op'>(</span><span class='va'>y</span><span class='op'>)</span>,</span>
<span>            size <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span><span class='op'>)</span>, by <span class='op'>=</span> <span class='va'>value</span><span class='op'>]</span></span>
<span></span>
<span><span class='co'># Filter the nuclei based on size, to discard noise</span></span>
<span><span class='va'>cores_clean</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/pkg/biopixR/man/sizeFilter.html'>sizeFilter</a></span><span class='op'>(</span><span class='va'>cores_center</span>,</span>
<span>             <span class='va'>cores</span>,</span>
<span>             lowerlimit <span class='op'>=</span> <span class='fl'>150</span>,</span>
<span>             upperlimit <span class='op'>=</span> <span class='cn'>Inf</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Detect objects yH2AX foci in green color channel</span></span>
<span><span class='va'>DSB</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/biopixR/man/objectDetection.html'>objectDetection</a></span><span class='op'>(</span><span class='va'>yH2AX</span>, alpha <span class='op'>=</span> <span class='fl'>1.1</span>, sigma <span class='op'>=</span> <span class='fl'>0</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Function to compare coordinates from two data frames and count matches</span></span>
<span><span class='va'>compareCoordinates</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>df1</span>, <span class='va'>df2</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  <span class='co'># Create a single identifier for each coordinate pair</span></span>
<span>  <span class='va'>df1</span><span class='op'>$</span><span class='va'>coord_id</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/paste.html'>paste</a></span><span class='op'>(</span><span class='fu'><a href='https://rspatial.github.io/terra/reference/math-generics.html'>round</a></span><span class='op'>(</span><span class='va'>df1</span><span class='op'>$</span><span class='va'>mx</span><span class='op'>)</span>, <span class='fu'><a href='https://rspatial.github.io/terra/reference/math-generics.html'>round</a></span><span class='op'>(</span><span class='va'>df1</span><span class='op'>$</span><span class='va'>my</span><span class='op'>)</span>, sep <span class='op'>=</span> <span class='st'>","</span><span class='op'>)</span></span>
<span>  <span class='va'>df2</span><span class='op'>$</span><span class='va'>coord_id</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/paste.html'>paste</a></span><span class='op'>(</span><span class='va'>df2</span><span class='op'>$</span><span class='va'>x</span>, <span class='va'>df2</span><span class='op'>$</span><span class='va'>y</span>, sep <span class='op'>=</span> <span class='st'>","</span><span class='op'>)</span></span>
<span></span>
<span>  <span class='co'># Find matches by checking if coordinates from df2 exist in df1</span></span>
<span>  <span class='va'>matches</span> <span class='op'>&lt;-</span> <span class='va'>df2</span><span class='op'>$</span><span class='va'>coord_id</span> <span class='op'><a href='https://rspatial.github.io/terra/reference/match.html'>%in%</a></span> <span class='va'>df1</span><span class='op'>$</span><span class='va'>coord_id</span></span>
<span></span>
<span>  <span class='co'># Convert df2 to a data table and add a column indicating matches</span></span>
<span>  <span class='va'>DT</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdatatable.gitlab.io/data.table/reference/data.table.html'>data.table</a></span><span class='op'>(</span><span class='va'>df2</span><span class='op'>)</span></span>
<span>  <span class='va'>DT</span><span class='op'>$</span><span class='va'>DSB</span> <span class='op'>&lt;-</span> <span class='va'>matches</span></span>
<span></span>
<span>  <span class='co'># Summarize the results</span></span>
<span>  <span class='va'>result</span> <span class='op'>&lt;-</span></span>
<span>    <span class='va'>DT</span><span class='op'>[</span>, <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span>count <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/which.html'>which</a></span><span class='op'>(</span><span class='va'>DSB</span> <span class='op'>==</span> <span class='cn'>TRUE</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span>, by <span class='op'>=</span> <span class='va'>value</span><span class='op'>]</span></span>
<span></span>
<span>  <span class='kw'><a href='https://rdrr.io/r/base/function.html'>return</a></span><span class='op'>(</span><span class='va'>result</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='co'># Compare coordinates between detected DSB centers and cleaned nuclei coordinates</span></span>
<span><span class='va'>count</span> <span class='op'>&lt;-</span> <span class='fu'>compareCoordinates</span><span class='op'>(</span><span class='va'>DSB</span><span class='op'>$</span><span class='va'>centers</span>, <span class='va'>cores_clean</span><span class='op'>$</span><span class='va'>coordinates</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># Extract the count column for further analysis</span></span>
<span><span class='va'>to_analyze</span> <span class='op'>&lt;-</span> <span class='va'>count</span><span class='op'>[</span>, <span class='fl'>2</span><span class='op'>]</span></span></code></pre>
</div>
</div>

<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:DSB"></span>
<img src="figures/fig_DSB.png" alt="Quantification of DNA Double Strand Breaks: A) The image displays cells with nuclei stained using DAPI. The quantitative marker for DNA double strand breaks, \(\gamma\)H2AX, targeted with a specific antibody, is visible as green fluorescent foci. The experimental procedure follows the method described by Rödiger et al. (2018). B) The \(\gamma\)H2AX foci are quantified using the biopixR package. The detected foci are highlighted in different colors using the changePixelColor() function." width="95%" />
<p class="caption">
Figure 11: <strong>Quantification of DNA Double Strand Breaks</strong>: <strong>A</strong>) The image displays cells with nuclei stained using DAPI. The quantitative marker for DNA double strand breaks, <span class="math inline">\(\gamma\)</span>H2AX, targeted with a specific antibody, is visible as green fluorescent foci. The experimental procedure follows the method described by <span class="citation" data-cites="Roediger2018">Rödiger et al. (<a href="#ref-Roediger2018" role="doc-biblioref">2018</a>)</span>. <strong>B</strong>) The <span class="math inline">\(\gamma\)</span>H2AX foci are quantified using the <code>biopixR</code> package. The detected foci are highlighted in different colors using the <code>changePixelColor()</code> function.
</p>
</div>
</div>

<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:countfitteR"></span>
<img src="figures/count_distr.png" alt="Analyzing Count Data with the countfitteR Package: The data representing the number of foci per cell obtained from the biopixR analysis were imported into the interactive shiny interface of the countfitteR package. This package analyzed the distribution and summarized the results. One outcome is illustrated in this figure, which shows the frequency distribution of a specific count of foci per cell." width="89%" />
<p class="caption">
Figure 12: <strong>Analyzing Count Data with the <code>countfitteR</code> Package</strong>: The data representing the number of foci per cell obtained from the <code>biopixR</code> analysis were imported into the interactive <code>shiny</code> interface of the <code>countfitteR</code> package. This package analyzed the distribution and summarized the results. One outcome is illustrated in this figure, which shows the frequency distribution of a specific count of foci per cell.
</p>
</div>
</div>
<h2 data-number="15" id="exploring-the-blank-spot---z-stack-imaging-in-r"><span class="header-section-number">15</span> Exploring the blank spot - z-stack imaging in <code>R</code></h2>
<p>Z-stack imaging refers to the capture of images that possess a third dimension,
specifically image depth, which enables the spatial capture of molecules or the
reconstruction of the three-dimensional architecture of tissues. One method for
achieving z-stacking involves capturing multiple two-dimensional images at
uniform intervals over the depth of an object by changing the focal plane. The
individual 2D images are then reconstructed to create a 3D model <span class="citation" data-cites="Trivedi2020 Kim2022">(<a href="#ref-Trivedi2020" role="doc-biblioref">Trivedi and Mills 2020</a>; <a href="#ref-Kim2022" role="doc-biblioref">Kim et al. 2022</a>)</span>.</p>
<p>The only packages currently available in the <code>R</code> programming language for
dealing with z-stack imaging are <code>spatialTIME</code> and <code>MaxContrastProjection</code>.
However, the <code>spatialTIME</code> package necessitates preprocessing and is therefore
unable to handle the images directly <span class="citation" data-cites="Creed2021">(<a href="#ref-Creed2021" role="doc-biblioref">Creed et al. 2021</a>)</span>. The other package,
<code>MaxContrastProjection</code>, has unfortunately been removed from Bioconductor. The
package is capable of performing maximum contrast projection, whereby the
z-stacks of a 3D image are merged into a 2D image <span class="citation" data-cites="MaxContrastProjection">(<a href="#ref-MaxContrastProjection" role="doc-biblioref">Jan Sauer 2017</a>)</span>. To
the best of our knowledge, these are the only packages in <code>R</code> that address the
topic of z-stack imaging.</p>
<h2 data-number="16" id="scaling-new-heights---high-throughput-analysis-in-the-era-of-small-and-big-data"><span class="header-section-number">16</span> Scaling new heights - high throughput analysis in the era of small and big data?</h2>
<p>The exponential growth of data, which reached levels of zettabytes (<span class="math inline">\(10^{21}\)</span>
bytes) as early as 2012 <span class="citation" data-cites="Sagiroglu2013">(<a href="#ref-Sagiroglu2013" role="doc-biblioref">Sagiroglu and Sinanc 2013</a>)</span>, is accompanied by a significant
increase in image generation due to advancements in imaging technologies such as
microscopy. High-resolution images produced in a single experiment can result in
data sets exceeding terabytes <span class="citation" data-cites="Peng2012 Eliceiri2012">(<a href="#ref-Peng2012" role="doc-biblioref">Peng et al. 2012</a>; <a href="#ref-Eliceiri2012" role="doc-biblioref">Eliceiri et al. 2012</a>)</span>. This surge in data
generation across various fields has initiated the era of Big Data, which
presents considerable challenges in the handling and interpretation of massive
data sets <span class="citation" data-cites="Cui2015">(<a href="#ref-Cui2015" role="doc-biblioref">Cui et al. 2015</a>)</span>. In automated microscopy, the rapid acquisition of large
image volumes facilitates extensive screening processes but complicates the
conversion of image stacks into actionable information and discoveries, resulting in
a critical need for analytical pipelines that can efficiently identify regions
of interest, compute relevant features, and perform statistical analysis,
ensuring reproducibility and reliability <span class="citation" data-cites="Wollman2007">(<a href="#ref-Wollman2007" role="doc-biblioref">Wollman and Stuurman 2007</a>)</span>.</p>
<p>The extraction of quantitative information from images is a common practice, but
it is becoming increasingly complex and error-prone when performed manually.
This complexity requires the implementation of high-throughput methods capable
of autonomously processing multiple images <span class="citation" data-cites="Olivoto2022">(<a href="#ref-Olivoto2022" role="doc-biblioref">Olivoto 2022</a>)</span>. These developments
are crucial not only in specialized fields such as immunohistochemistry,
fluorescence <em>in situ</em> hybridization <span class="citation" data-cites="Ollion2013">(<a href="#ref-Ollion2013" role="doc-biblioref">Ollion et al. 2013</a>)</span>, drug discovery, and cell
biology <span class="citation" data-cites="Shariff2010">(<a href="#ref-Shariff2010" role="doc-biblioref">Shariff et al. 2010</a>)</span>, but also in promoting a data-driven approach to
biological research, thereby accelerating tasks and enhancing research
productivity <span class="citation" data-cites="Rittscher2010">(<a href="#ref-Rittscher2010" role="doc-biblioref">Rittscher 2010</a>)</span>.</p>
<p>The <code>R</code> programming language has limitations in handling large data sets. Since
<code>R</code> places temporary copies of data in the random access memory (RAM) to access
objects, it can lead to memory overload when processing data sets that exceed
the available RAM. Additionally, <code>R</code> uses RAM to store generated data, so large
lists of imported images can easily overwhelm the RAM. Moreover, <code>R</code> typically
executes code on a single thread, not utilizing the full capabilities of the
central processing unit (CPU). Several packages address issues such as
file-based access and parallel computing, thereby enhancing <code>R</code>‘s capability to
handle big data. One approach is to combine <code>R</code> with the ’Hadoop’ library
<span class="citation" data-cites="Prajapati2013 Oussous2018">(<a href="#ref-Prajapati2013" role="doc-biblioref">Prajapati 2013</a>; <a href="#ref-Oussous2018" role="doc-biblioref">Oussous et al. 2018</a>)</span>. Another effective method for managing big data
is the use of the HDF5, which efficiently manages
data storage and access, provides multicore reading and writing, and is
well-suited for organizing complex data collections. The <code>cytomapper</code> package
utilizes HDF5 to optimize file management <span class="citation" data-cites="cytomapper Folk2011 Koranne2011">(<a href="#ref-Koranne2011" role="doc-biblioref">Koranne 2011</a>; <a href="#ref-Folk2011" role="doc-biblioref">Folk et al. 2011</a>; <a href="#ref-cytomapper" role="doc-biblioref">Nils Eling, Nicolas Damond, Tobias Hoch 2020</a>)</span>.</p>
<p>Other packages, such as <code>pliman</code>, <code>biopixR</code>, and <code>FIELDimageR</code>, include features
for optimized batch processing, such as parallel processing, by utilizing the
<code>foreach</code> package for multi-core processing <span class="citation" data-cites="Olivoto2022 biopixR Matias2020">(<a href="#ref-Matias2020" role="doc-biblioref">Matias et al. 2020</a>; <a href="#ref-Olivoto2022" role="doc-biblioref">Olivoto 2022</a>; <a href="#ref-biopixR" role="doc-biblioref">Brauckhoff et al. 2024</a>)</span>. However, these packages are not fully optimized for big data. The
<code>biopixR</code> package simplifies image processing by providing a pipeline that scans
entire directories and verifies image uniqueness using Message Digest 5 (MD5)
sums. It enables the application of specific filters to batches of images and
generates an <code>RMarkdown</code> log file detailing the operations performed. The results
are saved in a manageable CSV format, enhancing the
efficiency of handling whole image directories <span class="citation" data-cites="biopixR">(<a href="#ref-biopixR" role="doc-biblioref">Brauckhoff et al. 2024</a>)</span>.</p>
<p>In conclusion, while <code>R</code> offers a range of options for handling big data, these
options are not widely implemented in image processing packages. Consequently,
the optimization and creation of workflows capable of handling big data is left
to the end-user.</p>
<h2 data-number="17" id="summary"><span class="header-section-number">17</span> Summary</h2>
<p>In conclusion, we present a summary of the major <code>R</code> packages previously
discussed. This summary provides an overview of the general applications,
published repositories, and licensing information associated with these
packages. Furthermore, it includes a list of the dependencies or libraries that
these packages rely on. The status column indicates both the initial publication
date and the date of the most recent update, thereby demonstrating the ongoing
commitment to maintaining these packages (Table <a href="#tab:overview2">2</a>).</p>
<div class="layout-chunk" data-layout="l-body">
<table>
<caption><span id="tab:overview2">Table 2: </span>Summary of key characteristics of major <code>R</code> packages for image processing. The table details general applications, repository (Repo) sources (CRAN, Bioconductor (Bioc), and GitHub), primary package or library dependencies, and licensing information. The status column indicates the date of first publication (*) and the most recent update (°) for each package.</caption>
<colgroup>
<col style="width: 24%" />
<col style="width: 19%" />
<col style="width: 5%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: center;">Application</th>
<th style="text-align: center;">Repo</th>
<th style="text-align: center;">based on</th>
<th style="text-align: center;">License</th>
<th style="text-align: center;">Status</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>imager</strong><br>by <span class="citation" data-cites="Barthelme2019">Barthelmé and Tschumperlé (<a href="#ref-Barthelme2019" role="doc-biblioref">2019</a>)</span></td>
<td style="text-align: center;">general purpose</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=imager">CRAN</a></td>
<td style="text-align: center;">Cimg</td>
<td style="text-align: center;">LGPL-3</td>
<td style="text-align: center;">*2015-08-26<br>°2024-04-26</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>magick</strong><br>by <span class="citation" data-cites="magick_ropensci">Ooms (<a href="#ref-magick_ropensci" role="doc-biblioref">2024b</a>)</span></td>
<td style="text-align: center;">general purpose</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=magick">CRAN</a></td>
<td style="text-align: center;">Image Magick</td>
<td style="text-align: center;">MIT</td>
<td style="text-align: center;">*2016-07-24<br>°2024-02-18</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>EBImage</strong><br>by <span class="citation" data-cites="Pau2010">Pau et al. (<a href="#ref-Pau2010" role="doc-biblioref">2010</a>)</span></td>
<td style="text-align: center;">general purpose</td>
<td style="text-align: center;"><a href="https://bioconductor.org/packages/EBImage/">Bioc</a></td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">LGPL</td>
<td style="text-align: center;">*2006-04-27<br>°2024-05-01</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>biopixR</strong><br>by <span class="citation" data-cites="biopixR">Brauckhoff et al. (<a href="#ref-biopixR" role="doc-biblioref">2024</a>)</span></td>
<td style="text-align: center;">bioimages</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=biopixR">CRAN</a></td>
<td style="text-align: center;">imager &amp; magick</td>
<td style="text-align: center;">LGPL<br>(<span class="math inline">\(\geq\)</span> 3)</td>
<td style="text-align: center;">*2024-03-25<br>°2024-11-11</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>pliman</strong><br>by <span class="citation" data-cites="Olivoto2022">Olivoto (<a href="#ref-Olivoto2022" role="doc-biblioref">2022</a>)</span></td>
<td style="text-align: center;">plant images</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=pliman">CRAN</a></td>
<td style="text-align: center;">EBImage</td>
<td style="text-align: center;">GPL<br>(<span class="math inline">\(\geq\)</span> 3)</td>
<td style="text-align: center;">*2021-05-15<br>°2023-10-14</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>mxnorm</strong><br>by <span class="citation" data-cites="Harris2022">Harris et al. (<a href="#ref-Harris2022" role="doc-biblioref">2022b</a>)</span></td>
<td style="text-align: center;">multiplex images</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=mxnorm">CRAN</a></td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">MIT</td>
<td style="text-align: center;">*2022-02-22<br>°2023-05-01</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>DIMPLE</strong><br>by <span class="citation" data-cites="Masotti2023">Masotti et al. (<a href="#ref-Masotti2023" role="doc-biblioref">2023</a>)</span></td>
<td style="text-align: center;">multiplex images</td>
<td style="text-align: center;"><a href="https://github.com/nateosher/DIMPLE">GitHub</a></td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">MIT</td>
<td style="text-align: center;">*2023-09-07</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>cytomapper</strong><br>by <span class="citation" data-cites="Eling2020">Eling et al. (<a href="#ref-Eling2020" role="doc-biblioref">2020</a>)</span></td>
<td style="text-align: center;">multiplex images</td>
<td style="text-align: center;"><a href="https://bioconductor.org/packages/cytomapper/">Bioc</a></td>
<td style="text-align: center;">EBImage</td>
<td style="text-align: center;">GPL<br>(<span class="math inline">\(\geq\)</span> 2)</td>
<td style="text-align: center;">*2020-10-28<br>°2024-05-01</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>SPIAT</strong><br>by <span class="citation" data-cites="Yang2020">Yang et al. (<a href="#ref-Yang2020" role="doc-biblioref">2020</a>)</span></td>
<td style="text-align: center;">spatial data</td>
<td style="text-align: center;"><a href="https://bioconductor.org/packages/SPIAT/">Bioc</a></td>
<td style="text-align: center;">Spatial Experiment</td>
<td style="text-align: center;">Artistic-2.0</td>
<td style="text-align: center;">*2022-11-02<br>°2024-05-01</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>spatialTIME</strong><br>by <span class="citation" data-cites="Creed2021">Creed et al. (<a href="#ref-Creed2021" role="doc-biblioref">2021</a>)</span></td>
<td style="text-align: center;">spatial data</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=spatialTIME">CRAN</a></td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">MIT</td>
<td style="text-align: center;">*2021-05-14<br>°2024-03-11</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>celltrackR</strong><br>by <span class="citation" data-cites="Wortel2021">Wortel et al. (<a href="#ref-Wortel2021" role="doc-biblioref">2021</a>)</span></td>
<td style="text-align: center;">motion analysis</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=celltrackR">CRAN</a></td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">GPL-2</td>
<td style="text-align: center;">*2020-03-31<br>°2024-03-26</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>FIELDimageR</strong><br>by <span class="citation" data-cites="Matias2020">Matias et al. (<a href="#ref-Matias2020" role="doc-biblioref">2020</a>)</span></td>
<td style="text-align: center;">agricultural field trails</td>
<td style="text-align: center;"><a href="https://github.com/OpenDroneMap/FIELDimageR">GitHub</a></td>
<td style="text-align: center;">EBImage</td>
<td style="text-align: center;">GPL-3</td>
<td style="text-align: center;">*2019-11-01<br>°2024-05-03</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>fslr</strong><br>by <span class="citation" data-cites="Muschelli2015">Muschelli et al. (<a href="#ref-Muschelli2015" role="doc-biblioref">2015</a>)</span></td>
<td style="text-align: center;">MRI of the brain</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=fslr">CRAN</a></td>
<td style="text-align: center;">FMRIB library</td>
<td style="text-align: center;">GPL-3</td>
<td style="text-align: center;">*2014-06-13<br>°2022-08-25</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>colocr</strong><br>by <span class="citation" data-cites="Ahmed2019">Ahmed et al. (<a href="#ref-Ahmed2019" role="doc-biblioref">2019</a>)</span></td>
<td style="text-align: center;">fluorescence microscopy</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=colocr">CRAN</a></td>
<td style="text-align: center;">imager &amp; magick</td>
<td style="text-align: center;">GPL-3</td>
<td style="text-align: center;">*2019-05-31<br>°2020-05-08</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>imageseg</strong><br>by <span class="citation" data-cites="Niedballa2022">Niedballa et al. (<a href="#ref-Niedballa2022" role="doc-biblioref">2022a</a>)</span></td>
<td style="text-align: center;">image segmentation</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=imageseg">CRAN</a></td>
<td style="text-align: center;">magick</td>
<td style="text-align: center;">MIT</td>
<td style="text-align: center;">*2021-12-09<br>°2022-05-29</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>SimpleITK</strong><br>by <span class="citation" data-cites="Beare2018">Beare et al. (<a href="#ref-Beare2018" role="doc-biblioref">2018</a>)</span></td>
<td style="text-align: center;">general purpose</td>
<td style="text-align: center;"><a href="https://github.com/SimpleITK/SimpleITKRInstaller">GitHub</a></td>
<td style="text-align: center;">Simple ITK</td>
<td style="text-align: center;">Apache 2.0</td>
<td style="text-align: center;">*2015-11-16<br>°2020-09-17</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>pixelclasser</strong><br>by <span class="citation" data-cites="Real2024">Real (<a href="#ref-Real2024" role="doc-biblioref">2024</a>)</span></td>
<td style="text-align: center;">image segmentation</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=pixelclasser">CRAN</a></td>
<td style="text-align: center;">jpeg &amp; tiff</td>
<td style="text-align: center;">GPL-3</td>
<td style="text-align: center;">*2021-10-21<br>°2023-10-18</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>OpenImageR</strong></td>
<td style="text-align: center;">general purpose</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=OpenImageR">CRAN</a></td>
<td style="text-align: center;">Rcpp</td>
<td style="text-align: center;">GPL-3</td>
<td style="text-align: center;">*2016-07-09<br>°2023-07-08</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>RniftyReg</strong></td>
<td style="text-align: center;">image registration</td>
<td style="text-align: center;"><a href="https://CRAN.R-project.org/package=RNiftyReg">CRAN</a></td>
<td style="text-align: center;">Rcpp &amp; Rnifti</td>
<td style="text-align: center;">GPL-2</td>
<td style="text-align: center;">*2010-09-06<br>°2023-07-18</td>
</tr>
</tbody>
</table>
</div>
<p>The packages outlined in Table <a href="#tab:overview2">2</a> are examined in terms of
their individual dependencies. A minimal number of dependencies is essential for
ensuring long-term stability and functionality. The packages are organized
according to their dependencies and imports, which were extracted from the
<code>DESCRIPTION</code> files to facilitate the identification of similarities between the
packages. The relationships between the packages are illustrated in the form of
a dendrogram (Figure <a href="#fig:dendro">13</a>).</p>

<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:dendro"></span>
<img src="RJ-2025-030_files/figure-html5/dendro-1.png" alt="Dendrogram of Hierarchically Clustered Package Dependencies: The dendrogram depicts the outcomes of a hierarchical clustering of various image analysis packages, based on their named dependencies and imports, as extracted from their respective DESCRIPTION files. Each branch represents a distinct package, and the proximity between branches reflects the degree of similarity in their dependencies and imports. The required distance matrix was calculated using the binary method, also known as Jaccard distance. To perform the hierarchical clustering, the complete linkage clustering method was employed (R Core Team 2023)." width="79%" />
<p class="caption">
Figure 13: <strong>Dendrogram of Hierarchically Clustered Package Dependencies</strong>: The dendrogram depicts the outcomes of a hierarchical clustering of various image analysis packages, based on their named dependencies and imports, as extracted from their respective <code>DESCRIPTION</code> files. Each branch represents a distinct package, and the proximity between branches reflects the degree of similarity in their dependencies and imports. The required distance matrix was calculated using the binary method, also known as Jaccard distance. To perform the hierarchical clustering, the complete linkage clustering method was employed <span class="citation" data-cites="R_Core_Team">(<a href="#ref-R_Core_Team" role="doc-biblioref">R Core Team 2023</a>)</span>.
</p>
</div>
</div>
<div class="sourceCode" id="cb6"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<h2 data-number="18" id="conclusion"><span class="header-section-number">18</span> Conclusion</h2>
<p>The Tables <a href="#tab:overview1">1</a> and <a href="#tab:overview2">2</a> highlight an array of <code>R</code>
packages employed within bioimage informatics. These tools cater to diverse
applications such as adaptive smoothing, vegetation phenology analysis,
microbial culture imaging, cancer imaging, mass spectrometry imaging, shape
analysis, spectral and spatial analysis, magnetic resonance image processing,
calcium imaging, galaxy image analysis, neuroimaging, geometric morphometric
shape analysis, medical image processing, edge detection, body and face
recognition, jump regression, denoising, and deblurring.</p>
<p>Many of these packages rely on common image processing libraries such as
‘ImageMagick’ and ‘CImg’ or specialized libraries like ‘RNifti’ for neuroimaging
data and OpenCV for computer vision tasks. Some notable examples include
<code>adimpro</code>, <code>gitter</code>, <code>SAFARI</code>, <code>pavo</code>, <code>rental</code>, <code>scalpel</code>, <code>ProFit</code>, and <code>fsbrain</code>.</p>
<p>The majority of these packages are hosted on CRAN, which serves as the primary
repository for <code>R</code> packages. Notably, one package, rental, is hosted on GitLab,
indicating that some packages may also be developed and distributed through
alternative platforms. <code>R</code> is an open-source, free, and cross-platform
programming language that extends these values to its packages
<span class="citation" data-cites="R_Core_Team">(<a href="#ref-R_Core_Team" role="doc-biblioref">R Core Team 2023</a>)</span>. The CRAN Repository Policy states that package authors
“should make all reasonable efforts to provide cross-platform portable code,”
typically requiring packages to run on at least two major <code>R</code>
platforms.<a href="#fn29" class="footnote-ref" id="fnref29" role="doc-noteref"><sup>29</sup></a> Similarly,
the standard tests employed by Bioconductor encompass evaluations on all major
platforms, including Linux, macOS, and
Windows.<a href="#fn30" class="footnote-ref" id="fnref30" role="doc-noteref"><sup>30</sup></a>
Thus, it can be concluded that the majority of packages in these repositories
are compatible across multiple platforms.</p>
<p>The most commonly used license in this domain is the GNU General Public License
(GPL), particularly versions 2 and 3. Other licenses employed include the Lesser
GNU General Public License (LGPL), MIT, Apache License 2.0, and others. The
prevalence of open-source licenses reflects the collaborative nature of <code>R</code>
package development. It’s essential to ensure compatibility when combining code
from different packages with varying licenses; otherwise, legal considerations
might arise.</p>
<p>As previously outlined, the most fundamental image processing packages in <code>R</code> are
<code>imager</code>, <code>magick</code>, <code>EBImage</code>, <code>OpenImageR</code>, and <code>SimpleITK</code>. Primarily,
<code>imager</code>, <code>magick</code>, and <code>EBImage</code> form the foundation for the majority of the
specialized packages reviewed. These packages support various formats, with JPEG
and PNG being the most common and supported by all five packages. BMP and TIFF
are also widely supported, while PDF and SVG formats are exclusively supported
by <code>magick</code>.</p>
<div class="layout-chunk" data-layout="l-body">
<table>
<caption><span id="tab:unnamed-chunk-75">Table 3: </span>Supported File Formats by Main Image Processing Packages</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: center;"><code>imager</code></th>
<th style="text-align: center;"><code>magick</code></th>
<th style="text-align: center;"><code>EBImage</code></th>
<th style="text-align: center;"><code>OpenImageR</code></th>
<th style="text-align: center;"><code>SimpleITK</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">JPEG</td>
<td style="text-align: center;">+</td>
<td style="text-align: center;">+</td>
<td style="text-align: center;">+</td>
<td style="text-align: center;">+</td>
<td style="text-align: center;">+</td>
</tr>
<tr class="even">
<td style="text-align: left;">PNG</td>
<td style="text-align: center;">+</td>
<td style="text-align: center;">+</td>
<td style="text-align: center;">+</td>
<td style="text-align: center;">+</td>
<td style="text-align: center;">+</td>
</tr>
<tr class="odd">
<td style="text-align: left;">BMP</td>
<td style="text-align: center;">+</td>
<td style="text-align: center;">+</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">+</td>
</tr>
<tr class="even">
<td style="text-align: left;">TIFF</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">+</td>
<td style="text-align: center;">+</td>
<td style="text-align: center;">+</td>
<td style="text-align: center;">+</td>
</tr>
<tr class="odd">
<td style="text-align: left;">PDF</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">+</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr class="even">
<td style="text-align: left;">SVG</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">+</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
</tbody>
</table>
</div>
<p>The ongoing development of new code by the <code>R</code> community
significantly enhances the capabilities of image analysis, fostering both growth
and adaptability within the community. This ensures that <code>R</code> remains
well-equipped to address emerging challenges effectively. The result is a
diverse range of image processing packages, including versatile general-purpose
tools and specialized pipelines designed for intricate analyses of biological
images. This extensive array of tools in <code>R</code> not only demonstrates the versatility
and applicability of these packages across different scientific disciplines but
also solidifies <code>R</code>’s position as an invaluable resource for researchers
interested in leveraging image analysis to uncover novel insights. This review
provides a concise overview of the current landscape of image processing
packages available in <code>R</code>, emphasizing the pivotal role these tools play in
advancing scientific research and discovery. The comprehensive toolkit, <code>R</code>,
empowers researchers to drive forward innovations and enrich the scientific
community. Finally, it is noteworthy that 92% of the 38 discovered packages are
active in their respective repositories and thus considered up to date.
Furthermore, 66% of these packages have been actively maintained with updates
in the past 1.5 years. Among the identified packages, 14 provide users with GUIs
or interactive functions. These packages include: <code>FIELDimageR</code>, <code>cytomapper</code>,
<code>colocr</code>, <code>biopixR</code>, <code>EBImage</code>, <code>magick</code>, <code>imager</code>, <code>pavo</code>, <code>pliman</code>,
<code>imagefluency</code>, <code>geomorph</code>, <code>fsbrain</code>, <code>scalpel</code>, and <code>adimpro</code>. The majority of
the 38 packages identified during the research can be considered autonomous,
offering all the necessary features for extensive image data analysis,
including image import, processing, and visualization. However, some packages
related to multiplex imaging necessitate preprocessing, rendering them unable to
provide a complete analysis within the <code>R</code> environment.</p>
<p>All mentioned packages are open source and available either on CRAN,
Bioconductor or GitHub.</p>
<p>Predicting the future is challenging, yet here we provide some opinions on
trends in bioimage informatics, which ultimately will also be seen in <code>R</code>.
Publications and conferences in the fields of image processing and computer
vision show that advances are driven by artificial intelligence (AI), deep
learning (particularly Convolutional Neural Networks (CNNs), Large Language
Models (LLMs), and Vision Transformer models (VTs)), and data visualization
<span class="citation" data-cites="ye_generative_2024 belcher_demystifying_2023 rabbani_review_2021 hameed_content-based_2021 van_der_velden_explainable_2022">(<a href="#ref-rabbani_review_2021" role="doc-biblioref">Rabbani et al. 2021</a>; <a href="#ref-hameed_content-based_2021" role="doc-biblioref">Hameed et al. 2021</a>; <a href="#ref-van_der_velden_explainable_2022" role="doc-biblioref">Velden et al. 2022</a>; <a href="#ref-belcher_demystifying_2023" role="doc-biblioref">Belcher et al. 2023</a>; <a href="#ref-ye_generative_2024" role="doc-biblioref">Ye et al. 2024</a>)</span>.
One example of deep learning is <code>imageseg</code>, which is using a CNN (U-Net and U-Net++
architectures) for general purpose image segmentation <span class="citation" data-cites="niedballa_imageseg_2022">(<a href="#ref-niedballa_imageseg_2022" role="doc-biblioref">Niedballa et al. 2022b</a>)</span>. Another
development is the deeper integration of <code>R</code> with advanced deep learning
frameworks, which will enable users to build and deploy models, with
applications like image classification, segmentation, and object detection. An example of
such integration is <code>ellmer</code>, which makes various LLMs accessible from <code>R</code> for
output streaming, tool calling, and structured data extraction.</p>
<p>The question arises: Is AI merely a buzzword, or is it here to stay? Given that
AI is grounded in science and we already see applications in <code>R</code>,
the latter is more probable. Consequently, <code>R</code>
bioimage packages will be developed that combine image data with other
multimodal data types, such as text and sensor data. Generative AI and advanced
visualization techniques are also one topic due to the availability of
generative models like diffusion models and Generative Adversarial Networks
(GANs). These technologies open new possibilities for image augmentation and
enhanced data visualization. It is important that such technologies stick to
one of <code>R</code>’s strengths, which is explainability, in particular focusing on transparent,
understandable, and explainable AI (xAI).</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<h2 data-number="19" id="funding"><span class="header-section-number">19</span> Funding</h2>
<p>This review was partially funded by the project Rubin: NeuroMiR (03RU1U051A,
federal ministry of education and research, Germany).</p>
<h2 data-number="20" id="conflict-of-interest"><span class="header-section-number">20</span> Conflict of interest</h2>
<p>The authors declare no conflict of interest.</p>
<h2 data-number="21" id="acknowledgements"><span class="header-section-number">21</span> Acknowledgements</h2>
<p>We would like to express our gratitude to Dr. Coline Kieffer for providing the
microbead images used in this review. We thank Robert M Flight at codeberg.org
for reading and improving the manuscript.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<h3 class="appendix" data-number="21.1" id="supplementary-materials"><span class="header-section-number">21.1</span> Supplementary materials</h3>
<p>Supplementary materials are available in addition to this article. It can be downloaded at
<a href="RJ-2025-030.zip">RJ-2025-030.zip</a></p>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Adams2013" class="csl-entry" role="listitem">
D. C. Adams and E. Otárola‐Castillo. Geomorph: An <span>R</span> package for the collection and analysis of geometric morphometric shape data. <em>Methods in Ecology and Evolution</em>, 4(4): 393–399, 2013. DOI <a href="https://doi.org/10.1111/2041-210x.12035">10.1111/2041-210x.12035</a>.
</div>
<div id="ref-Aherne2024" class="csl-entry" role="listitem">
O. Aherne, M. Mørch, R. Ortiz, O. Shannon and J. R. Davies. A novel multiplex fluorescent-labeling method for the visualization of mixed-species biofilms in vitro. <em>Microbiology Spectrum</em>, 2024. DOI <a href="https://doi.org/10.1128/spectrum.00253-24">10.1128/spectrum.00253-24</a>.
</div>
<div id="ref-colocr" class="csl-entry" role="listitem">
M. Ahmed. Colocr: Conduct co-localization analysis of fluorescence microscopy images. <em>Comprehensive <span>R</span> Archive Network</em>, 2020. URL <a href="https://CRAN.R-project.org/package=colocr">https://CRAN.R-project.org/package=colocr</a>. R package version 0.1.1.
</div>
<div id="ref-Ahmed2019" class="csl-entry" role="listitem">
M. Ahmed, T. H. Lai and D. R. Kim. Colocr: An <span>R</span> package for conducting co-localization analysis on fluorescence microscopy images. <em><span>PeerJ</span></em>, 7: e7255, 2019. DOI <a href="https://doi.org/10.7717/peerj.7255">10.7717/peerj.7255</a>.
</div>
<div id="ref-Amezquita2019" class="csl-entry" role="listitem">
R. A. Amezquita, A. T. L. Lun, E. Becht, V. J. Carey, L. N. Carpp, L. Geistlinger, F. Marini, K. Rue-Albrecht, D. Risso, C. Soneson, et al. Orchestrating single-cell analysis with bioconductor. <em>Nature Methods</em>, 17(2): 137–145, 2019. DOI <a href="https://doi.org/10.1038/s41592-019-0654-x">10.1038/s41592-019-0654-x</a>.
</div>
<div id="ref-AndrzejOles2017" class="csl-entry" role="listitem">
G. P. Andrzej Oleś. EBImage. 2017. DOI <a href="https://doi.org/10.18129/B9.BIOC.EBIMAGE">10.18129/B9.BIOC.EBIMAGE</a>.
</div>
<div id="ref-AndrzejOles2023" class="csl-entry" role="listitem">
Andrzej Oleś, John Lee. RBioFormats. 2023. DOI <a href="https://doi.org/10.18129/B9.BIOC.RBIOFORMATS">10.18129/B9.BIOC.RBIOFORMATS</a>.
</div>
<div id="ref-Angelo2014" class="csl-entry" role="listitem">
M. Angelo, S. C. Bendall, R. Finck, M. B. Hale, C. Hitzman, A. D. Borowsky, R. M. Levenson, J. B. Lowe, S. D. Liu, S. Zhao, et al. Multiplexed ion beam imaging of human breast tumors. <em>Nature Medicine</em>, 20(4): 436–442, 2014. DOI <a href="https://doi.org/10.1038/nm.3488">10.1038/nm.3488</a>.
</div>
<div id="ref-austenfeld_graphical_2012" class="csl-entry" role="listitem">
M. Austenfeld and W. Beyschlag. A graphical user interface for <span>R</span> in a rich client platform for ecological modeling. <em>Journal of Statistical Software</em>, 49: 1–19, 2012. URL <a href="https://doi.org/10.18637/jss.v049.i04">https://doi.org/10.18637/jss.v049.i04</a> [online; last accessed May 4, 2024].
</div>
<div id="ref-imager" class="csl-entry" role="listitem">
S. Barthelme, D. Tschumperle, J. Wijffels, H. E. Assemlal, S. Ochi, A. Robotham and R. Tobar. Imager: Image processing library based on ’CImg’. <em>Comprehensive <span>R</span> Archive Network</em>, 2024. URL <a href="https://CRAN.R-project.org/package=imager">https://CRAN.R-project.org/package=imager</a>. R package version 1.0.1.
</div>
<div id="ref-Barthelme2019" class="csl-entry" role="listitem">
S. Barthelmé and D. Tschumperlé. Imager: An <span>R</span> package for image processing based on <span>CImg</span>. <em>Journal of Open Source Software</em>, 4(38): 1012, 2019. DOI <a href="https://doi.org/10.21105/joss.01012">10.21105/joss.01012</a>.
</div>
<div id="ref-Beare2018" class="csl-entry" role="listitem">
R. Beare, B. Lowekamp and Z. Yaniv. Image segmentation, registration and characterization in <span>R</span> with SimpleITK. <em>Journal of Statistical Software</em>, 86(8): 2018. DOI <a href="https://doi.org/10.18637/jss.v086.i08">10.18637/jss.v086.i08</a>.
</div>
<div id="ref-Behura2021" class="csl-entry" role="listitem">
A. Behura. The cluster analysis and feature selection: Perspective of machine learning and image processing. <em>Data Analytics in Bioinformatics</em>, 249–280, 2021. DOI <a href="https://doi.org/10.1002/9781119785620.ch10">10.1002/9781119785620.ch10</a>.
</div>
<div id="ref-belcher_demystifying_2023" class="csl-entry" role="listitem">
B. T. Belcher, E. H. Bower, B. Burford, M. R. Celis, A. K. Fahimipour, I. L. Guevara, K. Katija, Z. Khokhar, A. Manjunath, S. Nelson, et al. Demystifying image-based machine learning: A practical guide to automated analysis of field imagery using modern machine learning tools. <em>Frontiers in Marine Science</em>, 10: 2023. URL <a href="https://www.frontiersin.org/journals/marine-science/articles/10.3389/fmars.2023.1157370/full">https://www.frontiersin.org/journals/marine-science/articles/10.3389/fmars.2023.1157370/full</a> [online; last accessed July 13, 2025]. Publisher: Frontiers.
</div>
<div id="ref-Besson2019" class="csl-entry" role="listitem">
S. Besson, R. Leigh, M. Linkert, C. Allan, J.-M. Burel, M. Carroll, D. Gault, R. Gozim, S. Li, D. Lindner, et al. Bringing open data to whole slide imaging. In <em>Digital pathology</em>, pages. 3–10 2019. Springer International Publishing. ISBN 9783030239374. DOI <a href="https://doi.org/10.1007/978-3-030-23937-4_1">10.1007/978-3-030-23937-4_1</a>.
</div>
<div id="ref-Bezdek1984" class="csl-entry" role="listitem">
J. C. Bezdek, R. Ehrlich and W. Full. FCM: The fuzzy c-means clustering algorithm. <em>Computers &amp; Geosciences</em>, 10(2–3): 191–203, 1984. DOI <a href="https://doi.org/10.1016/0098-3004(84)90020-7">10.1016/0098-3004(84)90020-7</a>.
</div>
<div id="ref-Bise2011" class="csl-entry" role="listitem">
R. Bise, T. Kanade, Z. Yin and S. Huh. Automatic cell tracking applied to analysis of cell migration in wound healing assay. In <em>2011 annual international conference of the IEEE engineering in medicine and biology society</em>, 2011. IEEE. DOI <a href="https://doi.org/10.1109/iembs.2011.6091525">10.1109/iembs.2011.6091525</a>.
</div>
<div id="ref-Boom2012" class="csl-entry" role="listitem">
B. J. Boom, P. X. Huang, J. He and R. B. Fisher. <em>Supporting ground-truth annotation of image datasets using clustering: International conference on pattern recognition.</em> Piscataway, NJ: IEEE, 2012. URL <a href="https://ieeexplore.ieee.org/abstract/document/6460437">https://ieeexplore.ieee.org/abstract/document/6460437</a>. Includes bibliographical references and author index.
</div>
<div id="ref-biopixR" class="csl-entry" role="listitem">
T. Brauckhoff, C. Kieffer and S. Rödiger. biopixR: Extracting insights from biological images. <em>Journal of Open Source Software</em>, 9(102): 7074, 2024. DOI <a href="https://doi.org/10.21105/joss.07074">10.21105/joss.07074</a>.
</div>
<div id="ref-Burdukiewicz2019" class="csl-entry" role="listitem">
M. Burdukiewicz. countfitteR: Comprehensive automatized evaluation of distribution models for count data. <em>CRAN: Contributed Packages</em>, 2019. DOI <a href="https://doi.org/10.32614/cran.package.countfitter">10.32614/cran.package.countfitter</a>.
</div>
<div id="ref-burdukiewicz_pcredux_2022" class="csl-entry" role="listitem">
M. Burdukiewicz, A.-N. Spiess, D. Rafacz, K. Blagodatskikh and S. Rödiger. <span>PCRedux</span>: A quantitative <span>PCR</span> machine learning toolkit. <em>Journal of Open Source Software</em>, 7(76): 4407, 2022. URL <a href="https://joss.theoj.org/papers/10.21105/joss.04407">https://joss.theoj.org/papers/10.21105/joss.04407</a> [online; last accessed August 21, 2022]. Number: 76.
</div>
<div id="ref-Caicedo2017" class="csl-entry" role="listitem">
J. C. Caicedo, S. Cooper, F. Heigwer, S. Warchal, P. Qiu, C. Molnar, A. S. Vasilevich, J. D. Barry, H. S. Bansal, O. Kraus, et al. Data-analysis strategies for image-based cell profiling. <em>Nature Methods</em>, 14(9): 849–863, 2017. DOI <a href="https://doi.org/10.1038/nmeth.4397">10.1038/nmeth.4397</a>.
</div>
<div id="ref-caron_image2data_2022" class="csl-entry" role="listitem">
P.-O. Caron and A. Dufresne. image2data: <span>An</span> <span>R</span> package to turn images in data sets. <em>The Quantitative Methods for Psychology</em>, 18(2): 186–195, 2022. URL <a href="http://www.tqmp.org/RegularArticles/vol18-2/p186">http://www.tqmp.org/RegularArticles/vol18-2/p186</a> [online; last accessed May 6, 2024].
</div>
<div id="ref-Chessel2017" class="csl-entry" role="listitem">
A. Chessel. An overview of data science uses in bioimage informatics. <em>Methods</em>, 115: 110–118, 2017. DOI <a href="https://doi.org/10.1016/j.ymeth.2016.12.014">10.1016/j.ymeth.2016.12.014</a>.
</div>
<div id="ref-chilimoniuk_challenges_2024" class="csl-entry" role="listitem">
J. Chilimoniuk, A. Erol, S. Rödiger and M. Burdukiewicz. Challenges and opportunities in processing <span>NanoString</span> <span class="nocase">nCounter</span> data. <em>Computational and Structural Biotechnology Journal</em>, 23: 1951–1958, 2024. URL <a href="https://www.sciencedirect.com/science/article/pii/S2001037024001454">https://www.sciencedirect.com/science/article/pii/S2001037024001454</a> [online; last accessed May 6, 2024].
</div>
<div id="ref-Chilimoniuk2021" class="csl-entry" role="listitem">
J. Chilimoniuk, A. Gosiewska, J. Słowik, R. Weiss, P. M. Deckert, S. Rödiger and M. Burdukiewicz. <span class="nocase">countfitteR</span>: Efficient selection of count distributions to assess <span>DNA</span> damage. <em>Annals of Translational Medicine</em>, 9(7): 528–528, 2021. DOI <a href="https://doi.org/10.21037/atm-20-6363">10.21037/atm-20-6363</a>.
</div>
<div id="ref-Cho2023" class="csl-entry" role="listitem">
W. Cho, S. Kim and Y.-G. Park. Towards multiplexed immunofluorescence of 3D tissues. <em>Molecular Brain</em>, 16(1): 2023. DOI <a href="https://doi.org/10.1186/s13041-023-01027-9">10.1186/s13041-023-01027-9</a>.
</div>
<div id="ref-Clayden2013" class="csl-entry" role="listitem">
J. D. Clayden, M. Dayan and C. A. Clark. Principal networks. <em>PLoS ONE</em>, 8(4): e60997, 2013. DOI <a href="https://doi.org/10.1371/journal.pone.0060997">10.1371/journal.pone.0060997</a>.
</div>
<div id="ref-RNiftyReg" class="csl-entry" role="listitem">
J. Clayden, M. Modat, B. Presles, T. Anthopoulos and P. Daga. RNiftyReg: Image registration using the ’NiftyReg’ library. <em>Comprehensive <span>R</span> Archive Network</em>, 2023. URL <a href="https://CRAN.R-project.org/package=RNiftyReg">https://CRAN.R-project.org/package=RNiftyReg</a>. R package version 2.8.1.
</div>
<div id="ref-Combes2020" class="csl-entry" role="listitem">
B. Combès. Miet: An <span>R</span> package for region of interest analysis from magnetic reasonance images. <em>Journal of Open Source Software</em>, 5(45): 1862, 2020. DOI <a href="https://doi.org/10.21105/joss.01862">10.21105/joss.01862</a>.
</div>
<div id="ref-Creed2021" class="csl-entry" role="listitem">
J. H. Creed, C. M. Wilson, A. C. Soupir, C. M. Colin-Leitzinger, G. J. Kimmel, O. E. Ospina, N. H. Chakiryan, J. Markowitz, L. C. Peres, A. Coghill, et al. spatialTIME and iTIME: <span>R</span> package and shiny application for visualization and analysis of immunofluorescence data. <em>Bioinformatics</em>, 37(23): 4584–4586, 2021. DOI <a href="https://doi.org/10.1093/bioinformatics/btab757">10.1093/bioinformatics/btab757</a>.
</div>
<div id="ref-spatialTime" class="csl-entry" role="listitem">
J. Creed, R. Thapa, C. Wilson, A. Soupir, O. Ospina, J. Wrobel, B. Fridley and F. Lab. spatialTIME: Spatial analysis of vectra immunoflourescent data. <em>Comprehensive <span>R</span> Archive Network</em>, 2024. URL <a href="https://CRAN.R-project.org/package=spatialTIME">https://CRAN.R-project.org/package=spatialTIME</a>. R package version 1.3.4-3.
</div>
<div id="ref-Cui2015" class="csl-entry" role="listitem">
S. Cui, G. Schwarz and M. Datcu. Remote sensing image classification: No features, no clustering. <em>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</em>, 8(11): 5158–5170, 2015. DOI <a href="https://doi.org/10.1109/jstars.2015.2495267">10.1109/jstars.2015.2495267</a>.
</div>
<div id="ref-Damond2019" class="csl-entry" role="listitem">
N. Damond, S. Engler, V. R. T. Zanotelli, D. Schapiro, C. H. Wasserfall, I. Kusmartseva, H. S. Nick, F. Thorel, P. L. Herrera, M. A. Atkinson, et al. A map of human type 1 diabetes progression by imaging mass cytometry. <em>Cell Metabolism</em>, 29(3): 755–768.e5, 2019. DOI <a href="https://doi.org/10.1016/j.cmet.2018.11.014">10.1016/j.cmet.2018.11.014</a>.
</div>
<div id="ref-Dunn2011" class="csl-entry" role="listitem">
K. W. Dunn, M. M. Kamocka and J. H. McDonald. A practical guide to evaluating colocalization in biological microscopy. <em>American Journal of Physiology-Cell Physiology</em>, 300(4): C723–C742, 2011. DOI <a href="https://doi.org/10.1152/ajpcell.00462.2010">10.1152/ajpcell.00462.2010</a>.
</div>
<div id="ref-Einhaus2023" class="csl-entry" role="listitem">
J. Einhaus, A. Rochwarger, S. Mattern, B. Gaudillière and C. M. Schürch. High-multiplex tissue imaging in routine pathology—are we there yet? <em>Virchows Archiv</em>, 482(5): 801–812, 2023. DOI <a href="https://doi.org/10.1007/s00428-023-03509-6">10.1007/s00428-023-03509-6</a>.
</div>
<div id="ref-Eliceiri2012" class="csl-entry" role="listitem">
K. W. Eliceiri, M. R. Berthold, I. G. Goldberg, L. Ibáñez, B. S. Manjunath, M. E. Martone, R. F. Murphy, H. Peng, A. L. Plant, B. Roysam, et al. Biological imaging software tools. <em>Nature Methods</em>, 9(7): 697–710, 2012. DOI <a href="https://doi.org/10.1038/nmeth.2084">10.1038/nmeth.2084</a>.
</div>
<div id="ref-Eling2020" class="csl-entry" role="listitem">
N. Eling, N. Damond, T. Hoch and B. Bodenmiller. Cytomapper: An r/bioconductor package for visualization of highly multiplexed imaging data. <em>Bioinformatics</em>, 36(24): 5706–5708, 2020. DOI <a href="https://doi.org/10.1093/bioinformatics/btaa1061">10.1093/bioinformatics/btaa1061</a>.
</div>
<div id="ref-Ester1996" class="csl-entry" role="listitem">
M. Ester, H.-P. Kriegel, J. Sander, X. Xu, et al. A density-based algorithm for discovering clusters in large spatial databases with noise. In <em>Kdd</em>, pages. 226–231 1996. URL <a href="https://dl.acm.org/doi/10.5555/3001460.3001507">https://dl.acm.org/doi/10.5555/3001460.3001507</a>.
</div>
<div id="ref-Feng2023" class="csl-entry" role="listitem">
Y. Feng, T. Yang, J. Zhu, M. Li, M. Doyle, V. Ozcoban, G. T. Bass, A. Pizzolla, L. Cain, S. Weng, et al. Spatial analysis with <span>SPIAT</span> and <span class="nocase">spaSim</span> to characterize and simulate tissue microenvironments. <em>Nature Communications</em>, 14(1): 2023. DOI <a href="https://doi.org/10.1038/s41467-023-37822-0">10.1038/s41467-023-37822-0</a>.
</div>
<div id="ref-Fernandez2022" class="csl-entry" role="listitem">
E. Fernández, S. Yang, S. H. Chiou, C. Moon, C. Zhang, B. Yao, G. Xiao and Q. Li. SAFARI: Shape analysis for AI-segmented images. <em>BMC Medical Imaging</em>, 22(1): 2022. DOI <a href="https://doi.org/10.1186/s12880-022-00849-8">10.1186/s12880-022-00849-8</a>.
</div>
<div id="ref-Filippa2016" class="csl-entry" role="listitem">
G. Filippa, E. Cremonese, M. Migliavacca, M. Galvagno, M. Forkel, L. Wingate, E. Tomelleri, U. Morra di Cella and A. D. Richardson. Phenopix: A <span>R</span> package for image-based vegetation phenology. <em>Agricultural and Forest Meteorology</em>, 220: 141–150, 2016. DOI <a href="https://doi.org/10.1016/j.agrformet.2016.01.006">10.1016/j.agrformet.2016.01.006</a>.
</div>
<div id="ref-Folk2011" class="csl-entry" role="listitem">
M. Folk, G. Heber, Q. Koziol, E. Pourmal and D. Robinson. An overview of the HDF5 technology suite and its applications. In <em>Proceedings of the EDBT/ICDT 2011 workshop on array databases</em>, 2011. ACM. DOI <a href="https://doi.org/10.1145/1966895.1966900">10.1145/1966895.1966900</a>.
</div>
<div id="ref-Geithe2024" class="csl-entry" role="listitem">
C. Geithe, B. Zeng, C. Schmidt, F. Dinter, D. Roggenbuck, W. Lehmann, G. Dame, P. Schierack, K. Hanack and S. Rödiger. A multiplex microchamber diffusion assay for the antibody-based detection of microRNAs on randomly ordered microbeads. <em>Biosensors and Bioelectronics: X</em>, 18: 100484, 2024. DOI <a href="https://doi.org/10.1016/j.biosx.2024.100484">10.1016/j.biosx.2024.100484</a>.
</div>
<div id="ref-Gentleman2004" class="csl-entry" role="listitem">
R. C. Gentleman, V. J. Carey, D. M. Bates, B. Bolstad, M. Dettling, S. Dudoit, B. Ellis, L. Gautier, Y. Ge, J. Gentry, et al. Bioconductor: Open software development for computational biology and bioinformatics. <em>Genome Biology</em>, 5(10): R80, 2004. DOI <a href="https://doi.org/10.1186/gb-2004-5-10-r80">10.1186/gb-2004-5-10-r80</a>.
</div>
<div id="ref-Gerdes2013" class="csl-entry" role="listitem">
M. J. Gerdes, C. J. Sevinsky, A. Sood, S. Adak, M. O. Bello, A. Bordwell, A. Can, A. Corwin, S. Dinn, R. J. Filkins, et al. Highly multiplexed single-cell analysis of formalin-fixed, paraffin-embedded cancer tissue. <em>Proceedings of the National Academy of Sciences</em>, 110(29): 11982–11987, 2013. DOI <a href="https://doi.org/10.1073/pnas.1300136110">10.1073/pnas.1300136110</a>.
</div>
<div id="ref-Ghosh2019" class="csl-entry" role="listitem">
S. Ghosh, N. Das, I. Das and U. Maulik. Understanding deep learning techniques for image segmentation. <em>ACM Computing Surveys</em>, 52(4): 1–35, 2019. DOI <a href="https://doi.org/10.1145/3329784">10.1145/3329784</a>.
</div>
<div id="ref-Giorgi2022" class="csl-entry" role="listitem">
F. M. Giorgi, C. Ceraolo and D. Mercatelli. The <span>R</span> language: An engine for bioinformatics and data science. <em>Life</em>, 12(5): 648, 2022. DOI <a href="https://doi.org/10.3390/life12050648">10.3390/life12050648</a>.
</div>
<div id="ref-Goldberg2005" class="csl-entry" role="listitem">
I. G. Goldberg, C. Allan, J.-M. Burel, D. Creager, A. Falconi, H. Hochheiser, J. Johnston, J. Mellen, P. K. Sorger and J. R. Swedlow. The open microscopy environment (OME) data model and XML file: Open tools for informatics and quantitative analysis in biological imaging. <em>Genome Biology</em>, 6(5): 2005. DOI <a href="https://doi.org/10.1186/gb-2005-6-5-r47">10.1186/gb-2005-6-5-r47</a>.
</div>
<div id="ref-Goltsev2018" class="csl-entry" role="listitem">
Y. Goltsev, N. Samusik, J. Kennedy-Darling, S. Bhate, M. Hale, G. Vazquez, S. Black and G. P. Nolan. Deep profiling of mouse splenic architecture with CODEX multiplexed imaging. <em>Cell</em>, 174(4): 968–981.e15, 2018. DOI <a href="https://doi.org/10.1016/j.cell.2018.07.010">10.1016/j.cell.2018.07.010</a>.
</div>
<div id="ref-Haase2022" class="csl-entry" role="listitem">
R. Haase, E. Fazeli, D. Legland, M. Doube, S. Culley, I. Belevich, E. Jokitalo, M. Schorb, A. Klemm and C. Tischer. A hitchhiker<span></span>s guide through the bio-image analysis software universe. <em><span>FEBS</span> Letters</em>, 596(19): 2472–2485, 2022. DOI <a href="https://doi.org/10.1002/1873-3468.14451">10.1002/1873-3468.14451</a>.
</div>
<div id="ref-Haghighat2015" class="csl-entry" role="listitem">
M. Haghighat, S. Zonouz and M. Abdel-Mottaleb. CloudID: Trustworthy cloud-based and cross-enterprise biometric identification. <em>Expert Systems with Applications</em>, 42(21): 7905–7916, 2015. DOI <a href="https://doi.org/10.1016/j.eswa.2015.06.025">10.1016/j.eswa.2015.06.025</a>.
</div>
<div id="ref-hameed_content-based_2021" class="csl-entry" role="listitem">
I. M. Hameed, S. H. Abdulhussain and B. M. Mahmmod. Content-based image retrieval: <span>A</span> review of recent trends. <em>Cogent Engineering</em>, 8(1): 1927469, 2021. URL <a href="https://doi.org/10.1080/23311916.2021.1927469">https://doi.org/10.1080/23311916.2021.1927469</a> [online; last accessed July 13, 2025]. Publisher: Cogent OA _eprint: https://doi.org/10.1080/23311916.2021.1927469.
</div>
<div id="ref-hao_dictionary_2024" class="csl-entry" role="listitem">
Y. Hao, T. Stuart, M. H. Kowalski, S. Choudhary, P. Hoffman, A. Hartman, A. Srivastava, G. Molla, S. Madad, C. Fernandez-Granda, et al. Dictionary learning for integrative, multimodal and scalable single-cell analysis. <em>Nature Biotechnology</em>, 42(2): 293–304, 2024. URL <a href="https://www.nature.com/articles/s41587-023-01767-y">https://www.nature.com/articles/s41587-023-01767-y</a> [online; last accessed July 13, 2025]. Publisher: Nature Publishing Group.
</div>
<div id="ref-Haralick1973" class="csl-entry" role="listitem">
R. M. Haralick, K. Shanmugam and I. Dinstein. Textural features for image classification. <em>IEEE Transactions on Systems, Man, and Cybernetics</em>, SMC-3(6): 610–621, 1973. DOI <a href="https://doi.org/10.1109/tsmc.1973.4309314">10.1109/tsmc.1973.4309314</a>.
</div>
<div id="ref-mxnorm" class="csl-entry" role="listitem">
C. Harris. Mxnorm: Apply normalization methods to multiplexed images. <em>Comprehensive <span>R</span> Archive Network</em>, 2023. URL <a href="https://cran.r-project.org/package=mxnorm">https://cran.r-project.org/package=mxnorm</a>. R package version 1.0.3.
</div>
<div id="ref-Harris2022a" class="csl-entry" role="listitem">
C. R. Harris, E. T. McKinley, J. T. Roland, Q. Liu, M. J. Shrubsole, K. S. Lau, R. J. Coffey, J. Wrobel and S. N. Vandekar. Quantifying and correcting slide-to-slide variation in multiplexed immunofluorescence images. <em>Bioinformatics</em>, 38(6): 1700–1707, 2022a. DOI <a href="https://doi.org/10.1093/bioinformatics/btab877">10.1093/bioinformatics/btab877</a>.
</div>
<div id="ref-Harris2022" class="csl-entry" role="listitem">
C. Harris, J. Wrobel and S. Vandekar. Mxnorm: An <span>R</span> package to normalize multiplexed imaging data. <em>Journal of Open Source Software</em>, 7(71): 4180, 2022b. DOI <a href="https://doi.org/10.21105/joss.04180">10.21105/joss.04180</a>.
</div>
<div id="ref-Heineck2019" class="csl-entry" role="listitem">
G. C. Heineck, I. G. McNish, J. M. Jungers, E. Gilbert and E. Watkins. Using r-based image analysis to quantify rusts on perennial ryegrass. <em>The Plant Phenome Journal</em>, 2(1): 1–10, 2019. DOI <a href="https://doi.org/10.2135/tppj2018.12.0010">10.2135/tppj2018.12.0010</a>.
</div>
<div id="ref-terra" class="csl-entry" role="listitem">
R. J. Hijmans. <em>Terra: Spatial data analysis.</em> 2024. URL <a href="https://CRAN.R-project.org/package=terra">https://CRAN.R-project.org/package=terra</a>. R package version 1.7-71.
</div>
<div id="ref-Hijmans2020" class="csl-entry" role="listitem">
R. J. Hijmans. Terra: Spatial data analysis. <em>CRAN: Contributed Packages</em>, 2020. DOI <a href="https://doi.org/10.32614/cran.package.terra">10.32614/cran.package.terra</a>.
</div>
<div id="ref-Hossain2019" class="csl-entry" role="listitem">
M. D. Hossain and D. Chen. Segmentation for object-based image analysis (OBIA): A review of algorithms and challenges from remote sensing perspective. <em>ISPRS Journal of Photogrammetry and Remote Sensing</em>, 150: 115–134, 2019. DOI <a href="https://doi.org/10.1016/j.isprsjprs.2019.02.009">10.1016/j.isprsjprs.2019.02.009</a>.
</div>
<div id="ref-Hossian2020" class="csl-entry" role="listitem">
A. K. M. N. Hossian and G. Mattheolabakis. Cellular migration assay: An in vitro technique to simulate the wound repair mechanism. In <em>Wound regeneration</em>, pages. 77–83 2020. Springer US. ISBN "9781071608456". DOI <a href="https://doi.org/10.1007/978-1-0716-0845-6_8">10.1007/978-1-0716-0845-6_8</a>.
</div>
<div id="ref-Hu2023" class="csl-entry" role="listitem">
Y. Hu, M. L. Becker and R. K. Willits. Quantification of cell migration: Metrics selection to model application. <em>Frontiers in Cell and Developmental Biology</em>, 11: 2023. DOI <a href="https://doi.org/10.3389/fcell.2023.1155882">10.3389/fcell.2023.1155882</a>.
</div>
<div id="ref-Inglese2018" class="csl-entry" role="listitem">
P. Inglese, G. Correia, Z. Takats, J. K. Nicholson and R. C. Glen. SPUTNIK: An <span>R</span> package for filtering of spatially related peaks in mass spectrometry imaging data. <em>Bioinformatics</em>, 35(1): 178–180, 2018. DOI <a href="https://doi.org/10.1093/bioinformatics/bty622">10.1093/bioinformatics/bty622</a>.
</div>
<div id="ref-Jaehne2002" class="csl-entry" role="listitem">
B. Jähne. <em>Digital image processing.</em> 5., rev. and extended ed. Berlin: Springer, 2002. DOI <a href="https://doi.org/10.1088/0957-0233/13/9/711">10.1088/0957-0233/13/9/711</a>. Dt. Ausg. u.d.T.: Digitale Bildverarbeitung. - CD-ROM-Ausg. u.d.T.: Digital image processing, idn 10527414.
</div>
<div id="ref-MaxContrastProjection" class="csl-entry" role="listitem">
B. F. Jan Sauer. MaxContrastProjection. 2017. DOI <a href="https://doi.org/10.18129/B9.BIOC.MAXCONTRASTPROJECTION">10.18129/B9.BIOC.MAXCONTRASTPROJECTION</a>.
</div>
<div id="ref-Jenkinson2001" class="csl-entry" role="listitem">
M. Jenkinson and S. Smith. A global optimisation method for robust affine registration of brain images. <em>Medical Image Analysis</em>, 5(2): 143–156, 2001. DOI <a href="https://doi.org/10.1016/s1361-8415(01)00036-6">10.1016/s1361-8415(01)00036-6</a>.
</div>
<div id="ref-JudeHemanth2012" class="csl-entry" role="listitem">
D. Jude Hemanth and J. Anitha. Image pre-processing and feature extraction techniques for magnetic resonance brain image analysis. In <em>Computer applications for communication, networking, and digital contents</em>, pages. 349–356 2012. Springer Berlin Heidelberg. ISBN "9783642355943". DOI <a href="https://doi.org/10.1007/978-3-642-35594-3_47">10.1007/978-3-642-35594-3_47</a>.
</div>
<div id="ref-Kaiser2004" class="csl-entry" role="listitem">
J.-P. Kaiser and A. Bruinink. Investigating cell–material interactions by monitoring and analysing cell migration. <em>Journal of Materials Science: Materials in Medicine</em>, 15(4): 429–435, 2004. DOI <a href="https://doi.org/10.1023/b:jmsm.0000021115.55254.a8">10.1023/b:jmsm.0000021115.55254.a8</a>.
</div>
<div id="ref-Kaufman1990" class="csl-entry" role="listitem">
L. Kaufman and P. J. Rousseeuw. <em>Finding groups in data: An introduction to cluster analysis.</em> Wiley, 1990. DOI <a href="https://doi.org/10.1002/9780470316801">10.1002/9780470316801</a>.
</div>
<div id="ref-mand" class="csl-entry" role="listitem">
A. Kawaguchi. <em>Multivariate analysis for neuroimaging data.</em> Milton: CRC Press, 2021. DOI <a href="https://doi.org/10.1201/9780429289606">https://doi.org/10.1201/9780429289606</a>. Description based on publisher supplied metadata and other sources.
</div>
<div id="ref-Kim2022" class="csl-entry" role="listitem">
D. Kim, R. Burkhardt, S. A. Alperstein, H. N. Gokozan, A. Goyal, J. J. Heymann, A. Patel and M. T. Siddiqui. Evaluating the role of z‐stack to improve the morphologic evaluation of urine cytology whole slide images for high‐grade urothelial carcinoma: Results and review of a pilot study. <em>Cancer Cytopathology</em>, 130(8): 630–639, 2022. DOI <a href="https://doi.org/10.1002/cncy.22595">10.1002/cncy.22595</a>.
</div>
<div id="ref-Kohonen2013" class="csl-entry" role="listitem">
T. Kohonen. Essentials of the self-organizing map. <em>Neural Networks</em>, 37: 52–65, 2013. DOI <a href="https://doi.org/10.1016/j.neunet.2012.09.018">10.1016/j.neunet.2012.09.018</a>.
</div>
<div id="ref-Kohonen1990" class="csl-entry" role="listitem">
T. Kohonen. The self-organizing map. <em>Proceedings of the IEEE</em>, 78(9): 1464–1480, 1990. DOI <a href="https://doi.org/10.1109/5.58325">10.1109/5.58325</a>.
</div>
<div id="ref-Koranne2011" class="csl-entry" role="listitem">
S. Koranne. <em>Handbook of open source tools.</em> 1st ed Boston, MA: Springer US, 2011. DOI <a href="https://doi.org/10.1007/978-1-4419-7719-9">https://doi.org/10.1007/978-1-4419-7719-9</a>.
</div>
<div id="ref-KumarDubey2022" class="csl-entry" role="listitem">
A. Kumar Dubey, U. Gupta and S. Jain. Medical data clustering and classification using TLBO and machine learning algorithms. <em>Computers, Materials &amp; Continua</em>, 70(3): 4523–4543, 2022. DOI <a href="https://doi.org/10.32604/cmc.2022.021148">10.32604/cmc.2022.021148</a>.
</div>
<div id="ref-juicr" class="csl-entry" role="listitem">
M. J. Lajeunesse. <em>Juicr: Automated and manual extraction of numerical data from scientific images.</em> 2021. URL <a href="https://CRAN.R-project.org/package=juicr">https://CRAN.R-project.org/package=juicr</a>. R package version 0.1.
</div>
<div id="ref-larsson_semla_2023" class="csl-entry" role="listitem">
L. Larsson, L. Franzén, P. L. Ståhl and J. Lundeberg. Semla: A versatile toolkit for spatially resolved transcriptomics analysis and visualization. <em>Bioinformatics</em>, 39(10): btad626, 2023. URL <a href="https://doi.org/10.1093/bioinformatics/btad626">https://doi.org/10.1093/bioinformatics/btad626</a> [online; last accessed July 14, 2025].
</div>
<div id="ref-Leigh2016" class="csl-entry" role="listitem">
R. Leigh, D. Gault, M. Linkert, J.-M. Burel, J. Moore, S. Besson and J. R. Swedlow. OME files - an open source reference library for the OME-XML metadata model and the OME-TIFF file format. 2016. DOI <a href="https://doi.org/10.1101/088740">10.1101/088740</a>.
</div>
<div id="ref-Linkert2010" class="csl-entry" role="listitem">
M. Linkert, C. T. Rueden, C. Allan, J.-M. Burel, W. Moore, A. Patterson, B. Loranger, J. Moore, C. Neves, D. MacDonald, et al. Metadata matters: Access to image data in the real world. <em>Journal of Cell Biology</em>, 189(5): 777–782, 2010. DOI <a href="https://doi.org/10.1083/jcb.201004104">10.1083/jcb.201004104</a>.
</div>
<div id="ref-Lowekamp2013" class="csl-entry" role="listitem">
B. C. Lowekamp, D. T. Chen, L. Ibáñez and D. Blezek. The design of <span>SimpleITK</span>. <em>Frontiers in Neuroinformatics</em>, 7: 2013. DOI <a href="https://doi.org/10.3389/fninf.2013.00045">10.3389/fninf.2013.00045</a>.
</div>
<div id="ref-Maheshwari1998" class="csl-entry" role="listitem">
G. Maheshwari and D. A. Lauffenburger. Deconstructing (and reconstructing) cell migration. <em>Microscopy Research and Technique</em>, 43(5): 358–368, 1998. DOI <a href="https://doi.org/10.1002/(sici)1097-0029(19981201)43:5&lt;358::aid-jemt2&gt;3.0.co;2-d">10.1002/(sici)1097-0029(19981201)43:5&lt;358::aid-jemt2&gt;3.0.co;2-d</a>.
</div>
<div id="ref-Maia2019" class="csl-entry" role="listitem">
R. Maia, H. Gruson, J. A. Endler and T. E. White. pavo2: New tools for the spectral and spatial analysis of colour in <span>R</span>. <em>Methods in Ecology and Evolution</em>, 10(7): 1097–1107, 2019. DOI <a href="https://doi.org/10.1111/2041-210x.13174">10.1111/2041-210x.13174</a>.
</div>
<div id="ref-Masotti2023" class="csl-entry" role="listitem">
M. Masotti, N. Osher, J. Eliason, A. Rao and V. Baladandayuthapani. DIMPLE: An <span>R</span> package to quantify, visualize, and model spatial cellular interactions from multiplex imaging with distance matrices. <em>Patterns</em>, 4(12): 100879, 2023. DOI <a href="https://doi.org/10.1016/j.patter.2023.100879">10.1016/j.patter.2023.100879</a>.
</div>
<div id="ref-Matias2020" class="csl-entry" role="listitem">
F. I. Matias, M. V. Caraza‐Harter and J. B. Endelman. FIELDimageR: An <span>R</span> package to analyze orthomosaic images from agricultural field trials. <em>The Plant Phenome Journal</em>, 3(1): 2020. DOI <a href="https://doi.org/10.1002/ppj2.20005">10.1002/ppj2.20005</a>.
</div>
<div id="ref-imagefluency" class="csl-entry" role="listitem">
S. Mayer. Stm/imagefluency: Imagefluency 0.2.5. 2024. DOI <a href="https://doi.org/10.5281/ZENODO.10652374">10.5281/ZENODO.10652374</a>.
</div>
<div id="ref-Moen2019" class="csl-entry" role="listitem">
E. Moen, D. Bannon, T. Kudo, W. Graf, M. Covert and D. V. Valen. Deep learning for cellular image analysis. <em>Nature Methods</em>, 16(12): 1233–1246, 2019. DOI <a href="https://doi.org/10.1038/s41592-019-0403-1">10.1038/s41592-019-0403-1</a>.
</div>
<div id="ref-noauthor_moleculeexperiment_nodate" class="csl-entry" role="listitem">
<span class="smallcaps"><span>MoleculeExperiment</span></span>. <em>Bioconductor</em>, 2024. URL <a href="http://bioconductor.org/packages/MoleculeExperiment/">http://bioconductor.org/packages/MoleculeExperiment/</a> [online; last accessed May 6, 2024].
</div>
<div id="ref-Moore2021" class="csl-entry" role="listitem">
J. Moore, C. Allan, S. Besson, J.-M. Burel, E. Diel, D. Gault, K. Kozlowski, D. Lindner, M. Linkert, T. Manz, et al. OME-NGFF: A next-generation file format for expanding bioimaging data-access strategies. <em>Nature Methods</em>, 18(12): 1496–1498, 2021. DOI <a href="https://doi.org/10.1038/s41592-021-01326-w">10.1038/s41592-021-01326-w</a>.
</div>
<div id="ref-Moore2023" class="csl-entry" role="listitem">
J. Moore, D. Basurto-Lozada, S. Besson, J. Bogovic, J. Bragantini, E. M. Brown, J.-M. Burel, X. Casas Moreno, G. de Medeiros, E. E. Diel, et al. OME-zarr: A cloud-optimized bioimaging file format with international community support. <em>Histochemistry and Cell Biology</em>, 160(3): 223–251, 2023. DOI <a href="https://doi.org/10.1007/s00418-023-02209-1">10.1007/s00418-023-02209-1</a>.
</div>
<div id="ref-Mostafa2019" class="csl-entry" role="listitem">
S. M. Mostafa and H. Amano. Effect of clustering data in improving machine learning model accuracy. <em>Journal of Theoretical and Applied Information Technology</em>, 97(21): 2973–2981, 2019. URL <a href="https://www.jatit.org/volumes/Vol97No21/7Vol97No21.pdf">https://www.jatit.org/volumes/Vol97No21/7Vol97No21.pdf</a>.
</div>
<div id="ref-OpenImageR" class="csl-entry" role="listitem">
L. Mouselimis, S. Machine, J. Buchner, M. Haghighat, R. Achanta and O. Onyshchak. OpenImageR: An image processing toolkit. <em>Comprehensive <span>R</span> Archive Network</em>, 2023. URL <a href="https://CRAN.R-project.org/package=OpenImageR">https://CRAN.R-project.org/package=OpenImageR</a>. R package version 1.3.0.
</div>
<div id="ref-Murphy2014" class="csl-entry" role="listitem">
R. F. Murphy. A new era in bioimage informatics. <em>Bioinformatics</em>, 30(10): 1353–1353, 2014. DOI <a href="https://doi.org/10.1093/bioinformatics/btu158">10.1093/bioinformatics/btu158</a>.
</div>
<div id="ref-fslr" class="csl-entry" role="listitem">
J. Muschelli. Fslr: Wrapper functions for ’FSL’ (’FMRIB’ software library) from functional MRI of the brain (’FMRIB’). <em>Comprehensive <span>R</span> Archive Network</em>, 2022. URL <a href="https://CRAN.R-project.org/package=fslr">https://CRAN.R-project.org/package=fslr</a>. R package version 2.25.2.
</div>
<div id="ref-Muschelli2015" class="csl-entry" role="listitem">
J. Muschelli, E. Sweeney, M. Lindquist and C. Crainiceanu. Fslr: Connecting the <span>FSL</span> software with <span>R</span>. <em>The <span>R</span> Journal</em>, 7(1): 163, 2015. DOI <a href="https://doi.org/10.32614/rj-2015-013">10.32614/rj-2015-013</a>.
</div>
<div id="ref-Nasierding2009" class="csl-entry" role="listitem">
G. Nasierding, G. Tsoumakas and A. Z. Kouzani. Clustering based multi-label classification for image annotation and retrieval. In <em>2009 IEEE international conference on systems, man and cybernetics</em>, 2009. IEEE. DOI <a href="https://doi.org/10.1109/icsmc.2009.5346902">10.1109/icsmc.2009.5346902</a>.
</div>
<div id="ref-Niedballa2022" class="csl-entry" role="listitem">
J. Niedballa, J. Axtner, T. F. Döbert, A. Tilker, A. Nguyen, S. T. Wong, C. Fiderer, M. Heurich and A. Wilting. Imageseg: An <span>R</span> package for deep learning-based image segmentation. <em>Methods in Ecology and Evolution</em>, 13(11): 2363–2371, 2022a. DOI <a href="https://doi.org/10.1111/2041-210x.13984">10.1111/2041-210x.13984</a>.
</div>
<div id="ref-niedballa_imageseg_2022" class="csl-entry" role="listitem">
J. Niedballa, J. Axtner, T. F. Döbert, A. Tilker, A. Nguyen, S. T. Wong, C. Fiderer, M. Heurich and A. Wilting. Imageseg: <span>An</span> <span>R</span> package for deep learning-based image segmentation. <em>Methods in Ecology and Evolution</em>, 13(11): 2363–2371, 2022b. URL <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13984">https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13984</a> [online; last accessed July 13, 2025]. _eprint: https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13984.
</div>
<div id="ref-imageseg" class="csl-entry" role="listitem">
J. Niedballa, J. Axtner, L. I. for Zoo and W. Research. Imageseg: Deep learning models for image segmentation. <em>Comprehensive <span>R</span> Archive Network</em>, 2022c. URL <a href="https://CRAN.R-project.org/package=imageseg">https://CRAN.R-project.org/package=imageseg</a>. R package version 0.5.0.
</div>
<div id="ref-cytomapper" class="csl-entry" role="listitem">
Nils Eling, Nicolas Damond, Tobias Hoch. Cytomapper. 2020. DOI <a href="https://doi.org/10.18129/B9.BIOC.CYTOMAPPER">10.18129/B9.BIOC.CYTOMAPPER</a>.
</div>
<div id="ref-magickGUI" class="csl-entry" role="listitem">
S. Ochi. magickGUI: GUI tools for interactive image processing with ’magick’. <em>Comprehensive <span>R</span> Archive Network</em>, 2023. URL <a href="https://CRAN.R-project.org/package=magickGUI">https://CRAN.R-project.org/package=magickGUI</a>. R package version 1.3.1.
</div>
<div id="ref-Olivoto2022" class="csl-entry" role="listitem">
T. Olivoto. Lights, camera, pliman! An <span>R</span> package for plant image analysis. <em>Methods in Ecology and Evolution</em>, 13(4): 789–798, 2022. DOI <a href="https://doi.org/10.1111/2041-210x.13803">10.1111/2041-210x.13803</a>.
</div>
<div id="ref-Ollion2013" class="csl-entry" role="listitem">
J. Ollion, J. Cochennec, F. Loll, C. Escudé and T. Boudier. <span>TANGO</span>: A generic tool for high-throughput 3D image analysis for studying nuclear organization. <em>Bioinformatics</em>, 29(14): 1840–1841, 2013. DOI <a href="https://doi.org/10.1093/bioinformatics/btt276">10.1093/bioinformatics/btt276</a>.
</div>
<div id="ref-magick" class="csl-entry" role="listitem">
J. Ooms. <em>Magick: Advanced graphics and image-processing in <span>R</span>.</em> 2024a. URL <a href="https://docs.ropensci.org/magick/">https://docs.ropensci.org/magick/</a>. R package version 2.8.3, <a href="https://CRAN.R-project.org/package=magick/" class="uri">https://CRAN.R-project.org/package=magick/</a>, <a href="https://github.com/ropensci/magick" class="uri">https://github.com/ropensci/magick</a> and <a href="https://ropensci.r-universe.dev/magick/" class="uri">https://ropensci.r-universe.dev/magick/</a>.
</div>
<div id="ref-magick_ropensci" class="csl-entry" role="listitem">
J. Ooms. <em>Magick: Advanced graphics and image-processing in <span>R</span>.</em> 2024b. URL <a href="https://ropensci.r-universe.dev/magick">https://ropensci.r-universe.dev/magick</a>. R package version 2.8.3.
</div>
<div id="ref-opencv" class="csl-entry" role="listitem">
J. Ooms and J. Wijffels. <em>Opencv: Bindings to ’OpenCV’ computer vision library.</em> 2024. URL <a href="https://ropensci.r-universe.dev/opencv">https://ropensci.r-universe.dev/opencv</a>. R package version 0.4.9001.
</div>
<div id="ref-Oussous2018" class="csl-entry" role="listitem">
A. Oussous, F.-Z. Benjelloun, A. Ait Lahcen and S. Belfkih. Big data technologies: A survey. <em>Journal of King Saud University - Computer and Information Sciences</em>, 30(4): 431–448, 2018. DOI <a href="https://doi.org/10.1016/j.jksuci.2017.06.001">10.1016/j.jksuci.2017.06.001</a>.
</div>
<div id="ref-Park2009" class="csl-entry" role="listitem">
H.-S. Park and C.-H. Jun. A simple and fast algorithm for k-medoids clustering. <em>Expert Systems with Applications</em>, 36(2): 3336–3341, 2009. DOI <a href="https://doi.org/10.1016/j.eswa.2008.01.039">10.1016/j.eswa.2008.01.039</a>.
</div>
<div id="ref-Pau2010" class="csl-entry" role="listitem">
G. Pau, F. Fuchs, O. Sklyar, M. Boutros and W. Huber. <span>EBImage</span> — an <span>R</span> package for image processing with applications to cellular phenotypes. <em>Bioinformatics</em>, 26(7): 979–981, 2010. DOI <a href="https://doi.org/10.1093/bioinformatics/btq046">10.1093/bioinformatics/btq046</a>.
</div>
<div id="ref-PaulGilloteaux2023" class="csl-entry" role="listitem">
P. Paul-Gilloteaux. Bioimage informatics: Investing in software usability is essential. <em><span>PLOS</span> Biology</em>, 21(7): e3002213, 2023. DOI <a href="https://doi.org/10.1371/journal.pbio.3002213">10.1371/journal.pbio.3002213</a>.
</div>
<div id="ref-Peng2008" class="csl-entry" role="listitem">
H. Peng. Bioimage informatics: A new area of engineering biology. <em>Bioinformatics</em>, 24(17): 1827–1836, 2008. DOI <a href="https://doi.org/10.1093/bioinformatics/btn346">10.1093/bioinformatics/btn346</a>.
</div>
<div id="ref-Peng2012" class="csl-entry" role="listitem">
H. Peng, A. Bateman, A. Valencia and J. D. Wren. Bioimage informatics: A new category in bioinformatics. <em>Bioinformatics</em>, 28(8): 1057–1057, 2012. DOI <a href="https://doi.org/10.1093/bioinformatics/bts111">10.1093/bioinformatics/bts111</a>.
</div>
<div id="ref-Petersen2017" class="csl-entry" role="listitem">
A. Petersen, N. Simon and D. Witten. SCALPEL: Extracting neurons from calcium imaging data. 2017. DOI <a href="https://doi.org/10.48550/ARXIV.1703.06946">10.48550/ARXIV.1703.06946</a>.
</div>
<div id="ref-poisot_digitize_2011" class="csl-entry" role="listitem">
T. ee Poisot. The <span class="nocase">digitize</span> package: Extracting numerical data from scatterplots. <em>The R Journal</em>, 3(1): 25–26, 2011. URL <a href="http://journal.r-project.org/archive/2011-1/RJournal_2011-1_Poisot.pdf">http://journal.r-project.org/archive/2011-1/RJournal_2011-1_Poisot.pdf</a>. Number: 1.
</div>
<div id="ref-Polzehl2007" class="csl-entry" role="listitem">
J. Polzehl and K. Tabelow. Adaptive smoothing of digital images: The <span>R</span> package adimpro. <em>Journal of Statistical Software</em>, 19(1): 2007. DOI <a href="https://doi.org/10.18637/jss.v019.i01">10.18637/jss.v019.i01</a>.
</div>
<div id="ref-Prajapati2013" class="csl-entry" role="listitem">
V. Prajapati. <em>Big data analytics with r and hadoop.</em> Online-Ausg. Birmingham: Packt Publishing, 2013. URL <a href="https://api.pageplace.de/preview/DT0400.9781782163299_A24165845/preview-9781782163299_A24165845.pdf">https://api.pageplace.de/preview/DT0400.9781782163299_A24165845/preview-9781782163299_A24165845.pdf</a>. Includes index. - Description based on online resource; title from PDF (ebrary, viewed December 30, 2013).
</div>
<div id="ref-R_Core_Team" class="csl-entry" role="listitem">
R Core Team. <span>R</span>: A language and environment for statistical computing. 2023. URL <a href="https://www.R-project.org/">https://www.R-project.org/</a>.
</div>
<div id="ref-rabbani_review_2021" class="csl-entry" role="listitem">
A. Rabbani, A. M. Fernando, R. Shams, A. Singh, P. Mostaghimi and M. Babaei. Review of data science trends and issues in porous media research with a focus on image-based techniques. <em>Water Resources Research</em>, 57(10): e2020WR029472, 2021. URL <a href="https://onlinelibrary.wiley.com/doi/abs/10.1029/2020WR029472">https://onlinelibrary.wiley.com/doi/abs/10.1029/2020WR029472</a> [online; last accessed July 13, 2025]. _eprint: https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2020WR029472.
</div>
<div id="ref-Real2024" class="csl-entry" role="listitem">
C. Real. <em>Pixelclasser: Classifies image pixels by colour.</em> 2024. URL <a href="https://github.com/ropensci/pixelclasser">https://github.com/ropensci/pixelclasser</a>. R package version 1.0.0.
</div>
<div id="ref-Ren2003" class="csl-entry" role="listitem">
Ren and Malik. Learning a classification model for segmentation. In <em>Proceedings ninth IEEE international conference on computer vision</em>, 2003. IEEE. DOI <a href="https://doi.org/10.1109/iccv.2003.1238308">10.1109/iccv.2003.1238308</a>.
</div>
<div id="ref-Rittscher2010" class="csl-entry" role="listitem">
J. Rittscher. Characterization of biological processes through automated image analysis. <em>Annual Review of Biomedical Engineering</em>, 12(1): 315–344, 2010. DOI <a href="https://doi.org/10.1146/annurev-bioeng-070909-105235">10.1146/annurev-bioeng-070909-105235</a>.
</div>
<div id="ref-Robotham2016" class="csl-entry" role="listitem">
A. S. G. Robotham, D. S. Taranu, R. Tobar, A. Moffett and S. P. Driver. ProFit: Bayesian profile fitting of galaxy images. <em>Monthly Notices of the Royal Astronomical Society</em>, 466(2): 1513–1541, 2016. DOI <a href="https://doi.org/10.1093/mnras/stw3039">10.1093/mnras/stw3039</a>.
</div>
<div id="ref-rodiger_surface_2013" class="csl-entry" role="listitem">
S. Rödiger, A. Böhm and I. Schimke. Surface melting curve analysis with <span>R</span>. <em>The <span>R</span> Journal</em>, 5(2): 37–53, 2013. URL <a href="https://journal.r-project.org/archive/2013-2/roediger-bohm-schimke.pdf">https://journal.r-project.org/archive/2013-2/roediger-bohm-schimke.pdf</a>. Number: 2 00011.
</div>
<div id="ref-rodiger_r_2015" class="csl-entry" role="listitem">
S. Rödiger, M. Burdukiewicz, K. A. Blagodatskikh and P. Schierack. <span>R</span> as an environment for the reproducible analysis of <span>DNA</span> amplification experiments. <em>The <span>R</span> Journal</em>, 7(2): 127–150, 2015a. URL <a href="https://journal.r-project.org/archive/2015-1/RJ-2015-1.pdf">https://journal.r-project.org/archive/2015-1/RJ-2015-1.pdf</a>. Number: 2 00015.
</div>
<div id="ref-Roediger2015" class="csl-entry" role="listitem">
S. Rödiger, M. Burdukiewicz, K. Blagodatskikh, M. Jahn and P. Schierack. <span>R</span> as an environment for reproducible analysis of <span>DNA</span> amplification experiments. <em>The <span>R</span> Journal</em>, 7(1): 127, 2015b. DOI <a href="https://doi.org/10.32614/rj-2015-011">10.32614/rj-2015-011</a>.
</div>
<div id="ref-Roediger2012" class="csl-entry" role="listitem">
S. Rödiger, T. Friedrichsmeier, P. Kapat and M. Michalke. <span>RKWard</span>: A comprehensive graphical user interface and integrated development environment for statistical analysis with <span>R</span>. <em>Journal of Statistical Software</em>, 49(9): 1–34, 2012. URL <a href="https://www.jstatsoft.org/article/view/v049i09/v49i09.pdf">https://www.jstatsoft.org/article/view/v049i09/v49i09.pdf</a>. Number: 9 00058.
</div>
<div id="ref-Roediger2018" class="csl-entry" role="listitem">
S. Rödiger, M. Liefold, M. Ruhe, M. Reinwald, E. Beck and P. M. Deckert. Quantification of DNA double-strand breaks in peripheral blood mononuclear cells from healthy donors exposed to bendamustine by an automated <span class="math inline">\(\gamma\)</span>H2AX assay—an exploratory study. <em>Journal of Laboratory and Precision Medicine</em>, 3: 47–47, 2018. DOI <a href="https://doi.org/10.21037/jlpm.2018.04.10">10.21037/jlpm.2018.04.10</a>.
</div>
<div id="ref-Roesch2023" class="csl-entry" role="listitem">
E. Roesch, J. G. Greener, A. L. MacLean, H. Nassar, C. Rackauckas, T. E. Holy and M. P. H. Stumpf. Julia for biologists. <em>Nature Methods</em>, 20(5): 655–664, 2023. DOI <a href="https://doi.org/10.1038/s41592-023-01832-z">10.1038/s41592-023-01832-z</a>.
</div>
<div id="ref-Rousseeuw1987" class="csl-entry" role="listitem">
P. J. Rousseeuw. Silhouettes: A graphical aid to the interpretation and validation of cluster analysis. <em>Journal of Computational and Applied Mathematics</em>, 20: 53–65, 1987. DOI <a href="https://doi.org/10.1016/0377-0427(87)90125-7">10.1016/0377-0427(87)90125-7</a>.
</div>
<div id="ref-Ruhe2019" class="csl-entry" role="listitem">
M. Ruhe, W. Dammermann, S. Lüth, M. Sowa, P. Schierack, P. M. Deckert and S. Rödiger. Effect of cryopreservation on the formation of DNA double strand breaks in human peripheral blood mononuclear cells. <em>Journal of Cellular Biotechnology</em>, 4(1–2): 67–73, 2019. DOI <a href="https://doi.org/10.3233/jcb-189006">10.3233/jcb-189006</a>.
</div>
<div id="ref-Russell2018" class="csl-entry" role="listitem">
P. Russell, K. Fountain, D. Wolverton and D. Ghosh. TCIApathfinder: An <span>R</span> client for the cancer imaging archive REST API. <em>Cancer Research</em>, 78(15): 4424–4426, 2018. DOI <a href="https://doi.org/10.1158/0008-5472.can-18-0678">10.1158/0008-5472.can-18-0678</a>.
</div>
<div id="ref-Sagiroglu2013" class="csl-entry" role="listitem">
S. Sagiroglu and D. Sinanc. Big data: A review. In <em>2013 international conference on collaboration technologies and systems (CTS)</em>, 2013. IEEE. DOI <a href="https://doi.org/10.1109/cts.2013.6567202">10.1109/cts.2013.6567202</a>.
</div>
<div id="ref-satija_spatial_2015" class="csl-entry" role="listitem">
R. Satija, J. A. Farrell, D. Gennert, A. F. Schier and A. Regev. Spatial reconstruction of single-cell gene expression data. <em>Nature Biotechnology</em>, 33(5): 495–502, 2015. URL <a href="https://www.nature.com/articles/nbt.3192">https://www.nature.com/articles/nbt.3192</a> [online; last accessed July 14, 2025]. Publisher: Nature Publishing Group.
</div>
<div id="ref-Schaefer2024" class="csl-entry" role="listitem">
T. Schaefer. Fsbrain: An <span>R</span> package for the visualization of structural neuroimaging data. 2024. DOI <a href="https://doi.org/10.5281/ZENODO.10613234">10.5281/ZENODO.10613234</a>.
</div>
<div id="ref-Schaefer2020" class="csl-entry" role="listitem">
T. Schäfer and C. Ecker. Fsbrain: An <span>R</span> package for the visualization of structural neuroimaging data. 2020. DOI <a href="https://doi.org/10.1101/2020.09.18.302935">10.1101/2020.09.18.302935</a>.
</div>
<div id="ref-schneider_nih_2012" class="csl-entry" role="listitem">
C. A. Schneider, W. S. Rasband and K. W. Eliceiri. <span>NIH</span> <span>Image</span> to <span>ImageJ</span>: 25 years of image analysis. <em>Nature Methods</em>, 9(7): 671–675, 2012. DOI <a href="https://doi.org/10.1038/nmeth.2089">10.1038/nmeth.2089</a>.
</div>
<div id="ref-schneider_open_2019" class="csl-entry" role="listitem">
J. Schneider, R. Weiss, M. Ruhe, T. Jung, D. Roggenbuck, R. Stohwasser, P. Schierack and S. Rödiger. Open source bioimage informatics tools for the analysis of <span>DNA</span> damage and associated biomarkers. <em>Journal of Laboratory and Precision Medicine</em>, 4(0): 1–27, 2019. URL <a href="http://jlpm.amegroups.com/article/view/5008">http://jlpm.amegroups.com/article/view/5008</a>. Number: 0.
</div>
<div id="ref-Schubert2017" class="csl-entry" role="listitem">
E. Schubert, J. Sander, M. Ester, H. P. Kriegel and X. Xu. DBSCAN revisited, revisited: Why and how you should (still) use DBSCAN. <em>ACM Transactions on Database Systems</em>, 42(3): 1–21, 2017. DOI <a href="https://doi.org/10.1145/3068335">10.1145/3068335</a>.
</div>
<div id="ref-Shariff2010" class="csl-entry" role="listitem">
A. Shariff, J. Kangas, L. P. Coelho, S. Quinn and R. F. Murphy. Automated image analysis for high-content screening and analysis. <em>SLAS Discovery</em>, 15(7): 726–734, 2010. DOI <a href="https://doi.org/10.1177/1087057110370894">10.1177/1087057110370894</a>.
</div>
<div id="ref-Shirazi2018" class="csl-entry" role="listitem">
S. H. Shirazi, S. Naz, M. I. Razzak, A. I. Umar and A. Zaib. Automated pathology image analysis. In <em>Soft computing based medical image analysis</em>, pages. 13–29 2018. Elsevier. DOI <a href="https://doi.org/10.1016/b978-0-12-813087-2.00026-9">10.1016/b978-0-12-813087-2.00026-9</a>.
</div>
<div id="ref-Smith2021" class="csl-entry" role="listitem">
B. Smith, M. Hermsen, E. Lesser, D. Ravichandar and W. Kremers. Developing image analysis pipelines of whole-slide images: Pre- and post-processing. <em>Journal of Clinical and Translational Science</em>, 5(1): e38, 2021. DOI <a href="https://doi.org/10.1017/cts.2020.531">10.1017/cts.2020.531</a>.
</div>
<div id="ref-Sonka2000" class="csl-entry" role="listitem">
<span class="smallcaps">M. Sonka and J. M. Fitzpatrick, eds</span>. <em>Handbook of medical imaging.</em> Bellingham, Wash.: SPIE Press, 2000. DOI <a href="https://doi.org/10.1117/3.831079">https://doi.org/10.1117/3.831079</a>. Includes bibliographical references and index. - Print version record.
</div>
<div id="ref-Struyf1996" class="csl-entry" role="listitem">
A. Struyf, M. Hubert and P. Rousseeuw. Clustering in an object-oriented environment. <em>Journal of Statistical Software</em>, 1(4): 1996. DOI <a href="https://doi.org/10.18637/jss.v001.i04">10.18637/jss.v001.i04</a>.
</div>
<div id="ref-Swedlow2009a" class="csl-entry" role="listitem">
J. R. Swedlow and K. W. Eliceiri. Open source bioimage informatics for cell biology. <em>Trends in Cell Biology</em>, 19(11): 656–660, 2009. DOI <a href="https://doi.org/10.1016/j.tcb.2009.08.007">10.1016/j.tcb.2009.08.007</a>.
</div>
<div id="ref-Swedlow2009" class="csl-entry" role="listitem">
J. R. Swedlow, I. G. Goldberg and K. W. Eliceiri. Bioimage informatics for experimental biology. <em>Annual Review of Biophysics</em>, 38(1): 327–346, 2009. DOI <a href="https://doi.org/10.1146/annurev.biophys.050708.133641">10.1146/annurev.biophys.050708.133641</a>.
</div>
<div id="ref-celltrackR" class="csl-entry" role="listitem">
J. Textor, K. Dannenberg, J. Berry, G. Burger, A. Liu, M. Miller and I. Wortel. celltrackR: Motion trajectory analysis. <em>Comprehensive <span>R</span> Archive Network</em>, 2024. URL <a href="https://CRAN.R-project.org/package=celltrackR">https://CRAN.R-project.org/package=celltrackR</a>. R package version 1.2.0.
</div>
<div id="ref-AnnaTrigos2022" class="csl-entry" role="listitem">
A. Trigos, Y. Feng, T. Yang, M. Li, J. Zhu, V. Ozcoban and M. Doyle. SPIAT. 2022. DOI <a href="https://doi.org/10.18129/B9.BIOC.SPIAT">10.18129/B9.BIOC.SPIAT</a>.
</div>
<div id="ref-Trivedi2020" class="csl-entry" role="listitem">
M. M. Trivedi and J. K. Mills. Centroid calculation of the blastomere from 3D z-stack image data of a 2-cell mouse embryo. <em>Biomedical Signal Processing and Control</em>, 57: 101726, 2020. DOI <a href="https://doi.org/10.1016/j.bspc.2019.101726">10.1016/j.bspc.2019.101726</a>.
</div>
<div id="ref-Um2017" class="csl-entry" role="listitem">
E. Um, J. M. Oh, S. Granick and Y.-K. Cho. Cell migration in microengineered tumor environments. <em>Lab on a Chip</em>, 17(24): 4171–4185, 2017. DOI <a href="https://doi.org/10.1039/c7lc00555e">10.1039/c7lc00555e</a>.
</div>
<div id="ref-reticulate" class="csl-entry" role="listitem">
K. Ushey, J. J. Allaire and Y. Tang. Reticulate: Interface to ’python’. 2024. URL <a href="https://CRAN.R-project.org/package=reticulate">https://CRAN.R-project.org/package=reticulate</a>. R package version 1.36.1.
</div>
<div id="ref-VanderLaan2003" class="csl-entry" role="listitem">
M. Van der Laan, K. Pollard and J. Bryan. A new partitioning around medoids algorithm. <em>Journal of Statistical Computation and Simulation</em>, 73(8): 575–584, 2003. DOI <a href="https://doi.org/10.1080/0094965031000136012">10.1080/0094965031000136012</a>.
</div>
<div id="ref-van_der_velden_explainable_2022" class="csl-entry" role="listitem">
B. H. M. van der Velden, H. J. Kuijf, K. G. A. Gilhuijs and M. A. Viergever. Explainable artificial intelligence (<span>XAI</span>) in deep learning-based medical image analysis. <em>Medical Image Analysis</em>, 79: 102470, 2022. URL <a href="https://www.sciencedirect.com/science/article/pii/S1361841522001177">https://www.sciencedirect.com/science/article/pii/S1361841522001177</a> [online; last accessed July 13, 2025].
</div>
<div id="ref-Wagih2014" class="csl-entry" role="listitem">
O. Wagih and L. Parts. Gitter: A robust and accurate method for quantification of colony sizes from plate images. <em>G3 Genes<span class="math inline">\(\vert\)</span>Genomes<span class="math inline">\(\vert\)</span>Genetics</em>, 4(3): 547–552, 2014. DOI <a href="https://doi.org/10.1534/g3.113.009431">10.1534/g3.113.009431</a>.
</div>
<div id="ref-Weiss2022" class="csl-entry" role="listitem">
R. Weiss, S. Karimijafarbigloo, D. Roggenbuck and S. Rödiger. Applications of neural networks in biomedical data analysis. <em>Biomedicines</em>, 10(7): 1469, 2022. DOI <a href="https://doi.org/10.3390/biomedicines10071469">10.3390/biomedicines10071469</a>.
</div>
<div id="ref-recolorize" class="csl-entry" role="listitem">
H. I. Weller, A. E. Hiller, N. P. Lord and S. M. Van Belleghem. Recolorize: An <span>R</span> package for flexible colour segmentation of biological images. <em>Ecology Letters</em>, 27(2): 2024. DOI <a href="https://doi.org/10.1111/ele.14378">10.1111/ele.14378</a>.
</div>
<div id="ref-Wollman2007" class="csl-entry" role="listitem">
R. Wollman and N. Stuurman. High throughput microscopy: From raw images to discoveries. <em>Journal of Cell Science</em>, 120(21): 3715–3722, 2007. DOI <a href="https://doi.org/10.1242/jcs.013623">10.1242/jcs.013623</a>.
</div>
<div id="ref-Wortel2021" class="csl-entry" role="listitem">
I. M. N. Wortel, A. Y. Liu, K. Dannenberg, J. C. Berry, M. J. Miller and J. Textor. <span>CelltrackR</span>: An <span>R</span> package for fast and flexible analysis of immune cell migration data. <em><span>ImmunoInformatics</span></em>, 1-2: 100003, 2021. URL <a href="https://ingewortel.github.io/celltrackR/">https://ingewortel.github.io/celltrackR/</a>.
</div>
<div id="ref-Yamada2019" class="csl-entry" role="listitem">
K. M. Yamada and M. Sixt. Mechanisms of 3D cell migration. <em>Nature Reviews Molecular Cell Biology</em>, 20(12): 738–752, 2019. DOI <a href="https://doi.org/10.1038/s41580-019-0172-9">10.1038/s41580-019-0172-9</a>.
</div>
<div id="ref-Yang2020" class="csl-entry" role="listitem">
T. Yang, V. Ozcoban, A. Pasam, N. Kocovski, A. Pizzolla, Y.-K. Huang, G. Bass, S. P. Keam, P. J. Neeson, S. K. Sandhu, et al. <span>SPIAT</span>: An <span>R</span> package for the spatial image analysis of cells in tissues. 2020. DOI <a href="https://doi.org/10.1101/2020.05.28.122614">10.1101/2020.05.28.122614</a>.
</div>
<div id="ref-Yaniv2017" class="csl-entry" role="listitem">
Z. Yaniv, B. C. Lowekamp, H. J. Johnson and R. Beare. <span>SimpleITK</span> image-analysis notebooks: A collaborative environment for education and reproducible research. <em>Journal of Digital Imaging</em>, 31(3): 290–303, 2017. DOI <a href="https://doi.org/10.1007/s10278-017-0037-8">10.1007/s10278-017-0037-8</a>.
</div>
<div id="ref-Yao2016" class="csl-entry" role="listitem">
W. Yao, C. O. Dumitru, O. Loffeld and M. Datcu. Semi-supervised hierarchical clustering for semantic SAR image annotation. <em>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</em>, 9(5): 1993–2008, 2016. DOI <a href="https://doi.org/10.1109/jstars.2016.2537548">10.1109/jstars.2016.2537548</a>.
</div>
<div id="ref-ye_generative_2024" class="csl-entry" role="listitem">
Y. Ye, J. Hao, Y. Hou, Z. Wang, S. Xiao, Y. Luo and W. Zeng. Generative <span>AI</span> for visualization: <span>State</span> of the art and future directions. <em>Visual Informatics</em>, 8(2): 43–66, 2024. URL <a href="https://www.sciencedirect.com/science/article/pii/S2468502X24000160">https://www.sciencedirect.com/science/article/pii/S2468502X24000160</a> [online; last accessed July 13, 2025].
</div>
<div id="ref-Zhao2023" class="csl-entry" role="listitem">
C. Zhao and R. N. Germain. Multiplex imaging in immuno-oncology. <em>Journal for ImmunoTherapy of Cancer</em>, 11(10): e006923, 2023. DOI <a href="https://doi.org/10.1136/jitc-2023-006923">10.1136/jitc-2023-006923</a>.
</div>
</div>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p><a href="https://ngff.openmicroscopy.org/about/index.html" class="uri">https://ngff.openmicroscopy.org/about/index.html</a>, accessed 07/13/2025<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><a href="https://cran.r-project.org/" class="uri">https://cran.r-project.org/</a>, accessed 04/17/2025<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><a href="https://github.com/" class="uri">https://github.com/</a>, accessed 04/17/2025<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><a href="https://ropensci.r-universe.dev/builds" class="uri">https://ropensci.r-universe.dev/builds</a>, accessed 04/17/2025<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p><a href="https://www.bioconductor.org/" class="uri">https://www.bioconductor.org/</a>, accessed 04/17/2025<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p><a href="https://tiagoolivoto.github.io/pliman/index.html" class="uri">https://tiagoolivoto.github.io/pliman/index.html</a>, accessed
07/11/2024<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p><a href="https://github.com/OpenDroneMap/FIELDimageR" class="uri">https://github.com/OpenDroneMap/FIELDimageR</a>, accessed 05/07/2024<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p><a href="https://github.com/ropensci/pixelclasser" class="uri">https://github.com/ropensci/pixelclasser</a>, accessed 07/11/2024<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p><a href="https://cloud.r-project.org/web/packages/pixelclasser/vignettes/pixelclasser.html" class="uri">https://cloud.r-project.org/web/packages/pixelclasser/vignettes/pixelclasser.html</a>, accessed 07/11/2024<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p><a href="https://github.com/jonclayden/RNiftyReg" class="uri">https://github.com/jonclayden/RNiftyReg</a>, accessed 07/11/2024<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p><a href="https://github.com/asgr/imager" class="uri">https://github.com/asgr/imager</a>, accessed 07/11/2024<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p><a href="https://asgr.github.io/imager/" class="uri">https://asgr.github.io/imager/</a>, accessed 07/11/2024<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p><a href="https://imagemagick.org/script/magick++.php" class="uri">https://imagemagick.org/script/magick++.php</a>,
accessed 07/11/2024<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p><a href="https://www.imagemagick.org/Magick++/ImageDesign.html" class="uri">https://www.imagemagick.org/Magick++/ImageDesign.html</a>,
accessed 07/11/2024<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p><a href="https://georgestagg.github.io/shinymagick/" class="uri">https://georgestagg.github.io/shinymagick/</a>, accessed 07/11/2024<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p><a href="https://imagemagick.org/" class="uri">https://imagemagick.org/</a>, accessed 07/11/2024<a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p><a href="https://github.com/mlampros/OpenImageR" class="uri">https://github.com/mlampros/OpenImageR</a>, accessed 07/11/2024<a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p><a href="https://mlampros.github.io/OpenImageR/index.html" class="uri">https://mlampros.github.io/OpenImageR/index.html</a>, accessed 07/11/2024<a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn19"><p><a href="https://github.com/InsightSoftwareConsortium/SimpleITK-Notebooks" class="uri">https://github.com/InsightSoftwareConsortium/SimpleITK-Notebooks</a>, accessed 07/11/2024<a href="#fnref19" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20"><p><a href="https://github.com/SimpleITK/SimpleITKRInstaller" class="uri">https://github.com/SimpleITK/SimpleITKRInstaller</a>, accessed 07/11/2024<a href="#fnref20" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn21"><p><a href="https://github.com/nateosher/DIMPLE" class="uri">https://github.com/nateosher/DIMPLE</a>, accessed 07/11/2024<a href="#fnref21" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn22"><p><a href="https://github.com/TrigosTeam/SPIAT-shiny" class="uri">https://github.com/TrigosTeam/SPIAT-shiny</a>, accessed 07/11/2024<a href="#fnref22" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn23"><p><a href="https://web.archive.org/web/20250125194642/https://www.akoyabio.com/wp-content/uploads/2021/11/Vectra_Polaris_Product_Note_with_MOTiF_Akoya.pdf" class="uri">https://web.archive.org/web/20250125194642/https://www.akoyabio.com/wp-content/uploads/2021/11/Vectra_Polaris_Product_Note_with_MOTiF_Akoya.pdf</a>, accessed 07/14/2025<a href="#fnref23" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn24"><p><a href="https://fridleylab.shinyapps.io/iTIME/" class="uri">https://fridleylab.shinyapps.io/iTIME/</a>, accessed 07/11/2024<a href="#fnref24" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn25"><p><a href="https://github.com/ingewortel/celltrackR" class="uri">https://github.com/ingewortel/celltrackR</a>, accessed 07/11/2024<a href="#fnref25" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn26"><p><a href="https://mahshaaban.shinyapps.io/colocr_app2/" class="uri">https://mahshaaban.shinyapps.io/colocr_app2/</a>, accessed 07/11/2024<a href="#fnref26" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn27"><p><a href="https://github.com/jeroen/shinymagick" class="uri">https://github.com/jeroen/shinymagick</a>, accessed 07/11/2024<a href="#fnref27" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn28"><p><a href="https://github.com/ropensci/colocr" class="uri">https://github.com/ropensci/colocr</a>, accessed 07/11/2024<a href="#fnref28" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn29"><p><a href="https://cran.r-project.org/web/packages/policies.html" class="uri">https://cran.r-project.org/web/packages/policies.html</a>, accessed 06/10/2024<a href="#fnref29" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn30"><p><a href="https://contributions.bioconductor.org/bioconductor-package-submissions.html" class="uri">https://contributions.bioconductor.org/bioconductor-package-submissions.html</a>, accessed 06/10/2024<a href="#fnref30" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
<h3 id="references">References</h3>
<div id="references-listing"></div>
<h3 id="reuse">Reuse</h3>
<p>Text and figures are licensed under Creative Commons Attribution <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>. The figures that have been reused from other sources don't fall under this license and can be recognized by a note in their caption: "Figure from ...".</p>
<h3 id="citation">Citation</h3>
<p>For attribution, please cite this work as</p>
<pre class="citation-appendix short">Brauckhoff, et al., "Exploring Image Analysis in R: Applications and Advancements", The R Journal, 2025</pre>
<p>BibTeX citation</p>
<pre class="citation-appendix long">@article{RJ-2025-030,
  author = {Brauckhoff, Tim and Rublack, Julius and Rödiger, Stefan},
  title = {Exploring Image Analysis in R: Applications and Advancements},
  journal = {The R Journal},
  year = {2025},
  note = {https://doi.org/10.32614/RJ-2025-030},
  doi = {10.32614/RJ-2025-030},
  volume = {17},
  issue = {3},
  issn = {2073-4859},
  pages = {212-260}
}</pre>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
