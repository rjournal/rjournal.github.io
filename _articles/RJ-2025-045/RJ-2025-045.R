# Generated by `rjournal_pdf_article()` using `knitr::purl()`: do not edit by hand
# Please edit RJ-2025-045.Rmd to modify this file

## ----setup, include=FALSE-----------------------------------------------------
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.path = "figures/", cache = TRUE, fig.align = "center", fig.pos = "ht")
library(ASML)
library(knitr)
library(kableExtra)
library(ggplot2)
library(viridisLite)
library(caret)
library(aslib)
library(llama)
library(rvest)
library(dplyr)
library(reshape2)
set.seed(1234)


## ----ASkerschke, include=TRUE,  out.width = "100%",fig.align="center",  fig.cap = "Schematic overview of the interplay between problem instance features (top left), algorithm performance data (bottom left), selector construction (center), and the assessment of selector performance (bottom right). Adapted from Kerschke et al. (2019).", echo=FALSE----
if (knitr::is_html_output()) {
  knitr::include_graphics("figures/AS_kerschke_drawio.png")
} else if (knitr::is_latex_output()) {
  knitr::include_graphics("figures/AS_kerschke_drawio.pdf")
}


## ----rice, include=TRUE,  out.width = "80%",fig.align="center",  fig.cap = "Scheme of the algorithm selection problem by Rice (1976).", echo=FALSE----
knitr::include_graphics("figures/ASP_Rice.png")


## ----ASMLvsllama, echo=FALSE, message=FALSE-----------------------------------
library(knitr)
library(kableExtra)

if (knitr::is_latex_output()) {
  check <- "\\ding{51}"
  cross <- "\\ding{55}"
  br <- "\\hspace{4cm}"
} else {
  check <- "&#10003;" # HTML ✓
  cross <- "&#10007;" # HTML ✗
  br <- "<br>" # salto de línea en HTML
}

checklist <- data.frame(
  Aspect = c(
    "Input data",
    "Normalized KPIs",
    "ML backend",
    "Hyperparameter tuning",
    "Parallelization",
    "Results summary",
    "Visualization",
    "Model interpretability tools",
    "ASlib integration",
    "Latest release"
  ),
  ASML = c(
    paste0("features", br, " KPIs", br, "split by families supported"),
    paste0(check),
    paste0("caret"),
    paste0("ASML::AStrain()", br, "supports arguments passed to caret (trainControl(), tuneGrid)"),
    paste0(check, br, " with snow"),
    paste0(
      "Per algorithm", br,
      "Best overall and per instance", br,
      "ML-selected"
    ),
    paste0(
      "Boxplots (per algorithm and ML-selected)", br,
      "Ranking plots", br,
      "Barplots (best vs ML-selected)"
    ),
    paste0(check, br, " with DALEX"),
    paste0("basic support"),
    "CRAN 1.1.0 (2025)"
  ),
  llama = c(
    paste0("features", br, " KPIs", br, "feature costs supported"),
    paste0(cross),
    paste0("mlr"),
    paste0("llama::cvFolds", br, "llama::tuneModel"),
    paste0(check, br, " with parallelMap"),
    paste0(
      "Virtual best and single best per instance", br,
      "Aggregated scores (PAR, count, successes)"
    ),
    paste0("Scatter plots comparing two algorithm selectors"),
    paste0(cross),
    paste0("extended support"),
    "CRAN 0.10.1 (2021)"
  ),
  stringsAsFactors = FALSE
)

is_latex <- knitr::is_latex_output()
if (knitr::is_latex_output()) {
  fs <- 9
} else {
  fs <- NULL
}
tbl <- kbl(
  checklist,
  caption = "Comparative overview of ASML and llama for algorithm selection.",
  escape = FALSE,
  booktabs = TRUE,
  align = "lcc"
)

if (is_latex) {
  tbl %>%
    kable_styling(latex_options = c("hold_position", "striped"), font_size = fs) %>%
    kableExtra::row_spec(0, bold = TRUE) %>%
    column_spec(1, latex_column_spec = ">{\\\\raggedright\\\\arraybackslash}m{3cm}") %>%
    column_spec(2, latex_column_spec = ">{\\\\centering\\\\arraybackslash}m{4.5cm}") %>%
    column_spec(3, latex_column_spec = ">{\\\\centering\\\\arraybackslash}m{4.5cm}")
} else {
  tbl %>%
    kable_styling(
      bootstrap_options = c("striped", "hover", "condensed"),
      full_width = FALSE
    ) %>%
    column_spec(1, width = "25%") %>%
    column_spec(2:3, width = "35%")
}


## ----preparedata, echo=FALSE, eval=TRUE---------------------------------------
data(branching)
datap <- branching
features.complete <- datap$x
featcol <- c(
  "number_of_variables",
  "percentage_of_variables_degree_one",
  "percentage_of_variables_degree_two",
  "mean_variable_ranges",
  "variance_variable_ranges",
  "q50_variable_ranges",
  "variance_variable_densities_RLT_variables",
  "mean_percentage_of_constraints_and_objfun_in_which_each_variable_appears",
  "variance_percentage_of_constraints_and_objfun_in_which_each_variable_appears",
  "number_of_constraints",
  "number_of_equality_constraints_:_number_of_constraints",
  "number_of_linear_constraints_:_number_of_constraints",
  "number_of_quadratic_constraints_:_number_of_constraints",
  "degree",
  "number_of_monomials",
  "density",
  "number_of_linear_monomials_:_number_of_monomials",
  "number_of_quadratic_monomials_:_number_of_monomials",
  "number_of_linear_rlt_variables_:_number_of_rlt_variables",
  "number_of_quadratic_rlt_variables_:_number_of_rlt_variables",
  "mean_percentage_of_monomials_in_each_constraint_and_objfun",
  "mean_coefficients",
  "variance_coefficients",
  "number_of_variables_:_number_of_constraints_and_objfun",
  "number_of_variables_:_degree",
  "number_of_monomials_:_number_of_constraints_and_objfun",
  "number_of_rlt_variables_:_number_of_constraints_and_objfun",
  "intersection_graph_density",
  "alternative_graph_density",
  "intersection_greedy_max_modularity",
  "alternative_greedy_max_modularity",
  "intersection_graph_treewidth",
  "alternative_graph_treewidth"
)
Description <- c(
  "Number of variables",
  "Pct. of variables not present in any monomial with degree greater than one",
  "Pct. of variables not present in any monomial with degree greater than two",
  "Average  of the ranges of the variables",
  "Variance of the ranges of the variables",
  "Median of the ranges of the variables",
  "Variance of the density of the variables",
  "Average of the no. of appearances of each variable",
  "Variance of the no. of appearances of each variable",
  "Number of constraints",
  "Pct. of equality constraints",
  "Pct. of linear constraints",
  "Pct. of quadratic constraints",
  "Degree",
  "Number of monomials",
  "Density",
  "Pct. of linear monomials",
  "Pct. of quadratic monomials ",
  "Pct. of linear RLT variables",
  "Pct. of quadratic RLT variables",
  "Average pct. of monomials in each constraint and in the objective function",
  "Average of the coefficients",
  "Variance of the coefficients",
  "Number of variables divided by number of constrains",
  "Number of variables divided by degree",
  "Number of monomials divided by number of constrains",
  "Number of RLT variables divided by number of constrains",
  "Density of VIG",
  "Density of  CMIG",
  "Modularity of VIG",
  "Modularity of  CMIG",
  "Treewidth of VIG",
  "Treewidth of  CMIG"
)
features <- features.complete[, which(names(features.complete) %in% featcol)]


## ----optsum-------------------------------------------------------------------
aux <- paste(table(branching$x[, 1]), " (", names(table(branching$x[, 1])), ")", sep = "", collapse = ", ")
C1 <- c("Algorithms", "KPI", "Number of instances", "Number of instances per library", "Number of features")
C2 <- c("max, sum, dual, range, eig-VI, eig-CMI", "pace", nrow(features), aux, ncol(features))
df <- data.frame(C1, C2)
df$C2[1:2] <- kableExtra::cell_spec(df$C2[1:2], monospace = TRUE)
colnames(df) <- NULL
if (knitr::is_latex_output()) {
  fs <- 9
} else {
  fs <- NULL
}
kableExtra::kbl(df, escape = FALSE, booktabs = TRUE, caption = "Summary of the branching rule selection problem.") %>%
  kableExtra::row_spec(1, extra_css = "border-top: 1px solid") %>%
  kableExtra::row_spec(nrow(df), extra_css = "border-bottom: 1px solid") %>%
  kableExtra::kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position", font_size = fs)


## ----featsum------------------------------------------------------------------
# Filtrar las columnas que están en featcol
filtered_columns <- names(datap$x)[names(datap$x) %in% featcol]
filtered_indices <- which(names(datap$x) %in% filtered_columns)
# Obtener las descripciones en el orden de las columnas de datap$x
filtered_descriptions <- Description[match(filtered_columns, featcol)]
df <- data.frame(filtered_indices, filtered_descriptions)
df[, 1] <- cell_spec(df[, 1], monospace = TRUE)
colnames(df) <- c("Index", "Description")
kableExtra::kbl(df, escape = FALSE, booktabs = TRUE, caption = "Features from the branching dataset.") %>%
  kableExtra::row_spec(0, bold = TRUE) %>%
  kableExtra::kable_styling(full_width = FALSE, position = "center", ) %>%
  kableExtra::footnote(general = "Index refers to columns of branching$x.")


## ----ASMLcall, echo = TRUE, tidy=TRUE-----------------------------------------
set.seed(1234)
library(ASML)
data(branching)
features <- branching$x
KPI <- branching$y
lab_rules <- c("max", "sum", "dual", "range", "eig-VI", "eig-CMI")


## ----ASMLpre, echo = TRUE, tidy=TRUE------------------------------------------
data <- partition_and_normalize(features, KPI, family_column = 1, split_by_family = TRUE, better_smaller = TRUE)
names(data)


## ----partitionPLOT, echo = FALSE, tidy=TRUE, out.width = ifelse(knitr::is_latex_output(), "70%" , "100%"), fig.cap="Train/Test partition preserving the percentage of instances for each library.", fig.alt = "Train/Test partition preserving the percentage of instances for each library."----
library(ggplot2)
library(viridisLite)
data_plot <- rbind(
  data.frame(
    Family = data$families.train[[1]],
    Dataset = "Train"
  ),
  data.frame(
    Family = data$families.test[[1]],
    Dataset = "Test"
  )
)
data_plot$Dataset <- factor(data_plot$Dataset, levels = c("Train", "Test"))
ggplot(data_plot, aes(x = Dataset, fill = Family)) +
  geom_bar(position = "fill") +
  labs(
    title = "Train/Test Partition",
    y = "Proportion"
  ) +
  scale_fill_viridis_d(name = "Library") +
  theme_minimal() +
  scale_x_discrete(labels = c(
    "Train" = paste0("Train (n=", nrow(data$families.train), ")"),
    "Test" = paste0("Test (n=", nrow(data$families.test), ")")
  ))


## ----splitPLOT, echo = TRUE, tidy=TRUE, out.width = ifelse(knitr::is_latex_output(), "70%" , "100%"), fig.cap="Boxplots of instance-normalized KPI for each algorithm across instances in the train set.", fig.alt = "Boxplots of instance-normalized KPI for each algorithm across instances in the train set."----
boxplots(data, test = FALSE, by_families = FALSE, labels = lab_rules)


## ----rank, echo = TRUE, tidy=TRUE, out.width = ifelse(knitr::is_latex_output(), "70%" , "100%"), fig.cap="Ranking of algorithms based on the instance-normalized KPI for the training sample, categorized by family. The bars represent the percentage of times each algorithm appeared in different ranking positions, with the numbers indicating the mean value of the KPI.", fig.alt = "Ranking of algorithms based on the instance-normalized KPI for the training sample, categorized by family. The bars represent the percentage of times each algorithm appeared in different ranking positions, with the numbers indicating the mean value of the KPI."----
ranking(data, test = FALSE, by_families = TRUE, labels = lab_rules)


## ----precaret, echo = TRUE, tidy=TRUE-----------------------------------------
preProcValues <- caret::preProcess(data$x.train, method = "YeoJohnson")
data$x.train <- predict(preProcValues, data$x.train)
data$x.test <- predict(preProcValues, data$x.test)


## ----AMSLtrain, echo = TRUE, tidy=TRUE----------------------------------------
library(quantregForest)
tune_grid <- expand.grid(mtry = 10)
training <- AStrain(data, method = "qrf", tuneGrid = tune_grid)


## ----AMSLpred, echo = TRUE, tidy=TRUE-----------------------------------------
predict_test <- ASpredict(training, newdata = data$x.test)


## ----AMSLtab, echo = TRUE, tidy=TRUE, eval=FALSE------------------------------
# KPI_table(data, predictions = predict_test)


## ----AMSLtab2, echo = FALSE, tidy=TRUE, eval=TRUE-----------------------------
KPItab <- KPI_table(data, predictions = predict_test)
KPItab <- round(KPItab, 3)
rownames(KPItab) <- c("ML", "max", "sum", "dual", "range", "eig-VI", "eig-CMI")
rownames(KPItab) <- kableExtra::cell_spec(rownames(KPItab), monospace = TRUE)
# Define column names based on the output format
if (knitr::is_html_output()) {
  col_names <- c("Arithmetic mean\ninst-norm KPI", "Geometric mean\n inst-norm KPI", "Arithmetic mean\nnon-norm KPI", "Geometric mean\nnon-norm KPI")
  wi <- "3.3cm"
} else {
  col_names <- c("Arith. mean\\newline inst-norm KPI", "Geom. mean\\newline inst-norm KPI", "Arith. mean\\newline non-norm KPI", "Geom. mean\\newline non-norm KPI")
  wi <- "2.5cm"
}
if (knitr::is_latex_output()) {
  fs <- 9
} else {
  fs <- NULL
}
kableExtra::kbl(KPItab,
  escape = F, caption = "Arithmetic and geometric mean of the KPI (both instance-normalized and non-normalized) for each algorithm on the test set, along with the results for the algorithm selected by the learning model (first row).",
  col.names = col_names,
  booktabs = TRUE, 
) %>%
  kableExtra::kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position", font_size = fs) %>%
  column_spec(column = 2:5, width = wi)


## ----AMSLtabsum, echo = TRUE, tidy=TRUE, eval=FALSE---------------------------
# KPI_summary_table(data, predictions = predict_test)


## ----AMSLtabsum2, echo = FALSE, tidy=TRUE, eval=TRUE--------------------------
KPItab <- KPI_summary_table(data, predictions = predict_test)
KPItab <- round(KPItab, 3)
rownames(KPItab) <- c("single best", "ML", "optimal")
rownames(KPItab) <- kableExtra::cell_spec(rownames(KPItab), monospace = TRUE)
# Define column names based on the output format
if (knitr::is_html_output()) {
  col_names <- c("Arithmetic mean\nnon-norm KPI", "Geometric mean\nnon-norm KPI")
  wi <- "3.3cm"
} else {
  col_names <- c("Arith. mean\\newline non-norm KPI", "Geom. mean\\newline non-norm KPI")
  wi <- "2.5cm"
}
if (knitr::is_latex_output()) {
  fs <- 9
} else {
  fs <- NULL
}
kableExtra::kbl(KPItab,
  escape = F, caption = "Arithmetic and geometric mean of the non-normalized KPI for single best choice, ML choice, and optimal choice.",
  col.names = col_names,
  booktabs = TRUE, 
) %>%
  kableExtra::kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position", font_size = fs) %>%
  column_spec(column = 2:3, width = wi)


## ----ASMLplot, echo = TRUE, tidy=TRUE, eval=FALSE-----------------------------
# boxplots(data, predictions = predict_test, labels = c(lab_rules, "ML"))
# boxplots(data, predictions = predict_test, labels = c(lab_rules, "ML"), by_families = TRUE)
# ranking(data, predictions = predict_test, labels = c("ML", lab_rules), by_families = TRUE)
# figure_comparison(data, predictions = predict_test, by_families = FALSE, labels = lab_rules)


## ----ASMLplot1, echo = FALSE, tidy=TRUE, out.width = ifelse(knitr::is_latex_output(), "70%" , "100%"), fig.cap="Boxplots of instance-normalized KPI for each algorithm, including the ML algorithm, across instances in the test set.", fig.alt = "Boxplots of instance-normalized KPI for each algorithm, including the ML algorithm, across instances in the test set."----
boxplots(data, predictions = predict_test, labels = c(lab_rules, "ML"))


## ----ASMLplot2, echo = FALSE, tidy=TRUE, out.width = ifelse(knitr::is_latex_output(), "70%" , "100%"), fig.cap="Boxplots of instance-normalized KPI for each algorithm, including the ML algorithm, across instances in the test set, categorized by family.", fig.alt = "Boxplots of instance-normalized KPI for each algorithm, including the ML algorithm, across instances in the test set, categorized by family."----
boxplots(data, predictions = predict_test, labels = c(lab_rules, "ML"), by_families = TRUE)


## ----ASMLplot3, echo = FALSE, tidy=TRUE, out.width = ifelse(knitr::is_latex_output(), "70%" , "100%"), fig.cap="Ranking of algorithms, including the ML algorithm, based on the instance-normalized KPI for the test sample, categorized by family. The bars represent the percentage of times each algorithm appeared in different ranking positions, with the numbers indicating the mean value of the normalized KPI.", fig.alt = "Ranking of algorithms, including the ML algorithm, based on the instance-normalized KPI for the test sample, categorized by family. The bars represent the percentage of times each algorithm appeared in different ranking positions, with the numbers indicating the mean value of the normalized KPI."----
ranking(data, predictions = predict_test, labels = c("ML", lab_rules), by_families = TRUE)


## ----ASMLplot4, echo = FALSE, tidy=TRUE, out.width = ifelse(knitr::is_latex_output(), "70%" , "100%"), fig.cap="Comparison of the best-performing rules: The right stack shows the proportion of times each of the original rules is identified as the best-performing option, while the left stack presents the frequency of selection by ML.", fig.alt = "Comparison of the best-performing rules: The right stack shows the proportion of times each of the original rules is identified as the best-performing option, while the left stack presents the frequency of selection by ML."----
figure_comparison(data, predictions = predict_test, by_families = FALSE, labels = lab_rules)


## ----AMSLtrain2, echo = TRUE, tidy=TRUE, eval=FALSE---------------------------
# qrf_q_predict <- function(modelFit, newdata, what = 0.5, submodels = NULL) {
#   out <- predict(modelFit$finalModel, newdata, what = what)
#   if (is.matrix(out)) {
#     out <- out[, 1]
#   }
#   out
# }
# 
# predict_test_Q1 <- ASpredict(training, newdata = data$x.test, f = "qrf_q_predict", what = 0.25)
# KPI_summary_table(data, predictions = predict_test_Q1)


## ----inline = TRUE, results='asis'--------------------------------------------
if (knitr::is_html_output()) {
  knitr::asis_output("The results are summarized in Table \\@ref(tab:AMSLtabsum22).")
}


## ----AMSLtabsum22, echo = FALSE, tidy=TRUE, eval=TRUE-------------------------
if (knitr::is_html_output()) {
  .GlobalEnv$qrf_q_predict <- function(modelFit, newdata, what = 0.5, submodels = NULL) {
    out <- predict(modelFit$finalModel, newdata, what = what)
    if (is.matrix(out)) {
      out <- out[, 1]
    }
    out
  }
  predict_test_Q1 <- ASML::ASpredict(training, newdata = data$x.test, f = "qrf_q_predict", what = 0.25)
  KPItab <- KPI_summary_table(data, predictions = predict_test_Q1)
  KPItab <- round(KPItab, 3)
  rownames(KPItab) <- c("single best", "ML", "optimal")
  rownames(KPItab) <- kableExtra::cell_spec(rownames(KPItab), monospace = TRUE)
  # Define column names based on the output format
  if (knitr::is_html_output()) {
    col_names <- c("Arithmetic mean\nnon-norm KPI", "Geometric mean\nnon-norm KPI")
    wi <- "3.3cm"
  } else {
    col_names <- c("Arith. mean\\newline non-norm KPI", "Geom. mean\\newline non-norm KPI")
    wi <- "2.5cm"
  }
  # kableExtra::kbl(KPItab, escape = F, caption=paste0("Arithmetic and geometric mean of the non-normalized KPI #for single best choice, ML choice, and optimal choice. The ML choice  is based on the predictions of the",
  #                                                  bquote(alpha),
  #                                                  "-conditional quantile for ",
  #                                                  bquote(alpha),
  #   "=0.25.") ,
  if (knitr::is_latex_output()) {
    fs <- 9
  } else {
    fs <- NULL
  }
  kableExtra::kbl(KPItab,
    escape = F, caption = "Arithmetic and geometric mean of the non-normalized KPI for single best choice, ML choice, and optimal choice. The ML choice  is based on the predictions of the alpha-conditional quantile for alpha=0.25.",booktabs = TRUE, 
    col.names = col_names
  ) %>%
    kableExtra::kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position", font_size = fs) %>%
    column_spec(column = 2:3, width = wi)
} else {
  cat("")
}


## ----ASML_DALEX, echo = TRUE, tidy=TRUE, eval=FALSE---------------------------
# # Create DALEX explainers for each trained model
# explainers_qrf <- ASexplainer(training, data = data$x.test, y = data$y.test, labels = lab_rules)
# # Compute model performance metrics for each explainer
# mp_qrf <- lapply(explainers_qrf, DALEX::model_performance)
# # Plot the performance metrics
# do.call(plot, unname(mp_qrf))


## ----DALEX1, echo = FALSE, tidy=TRUE, out.width = ifelse(knitr::is_latex_output(), "70%" , "100%"), fig.cap="Reversed empirical cumulative distribution function of the absolute residuals of the trained models.", fig.alt = "Reversed empirical cumulative distribution function of the absolute residuals of the trained model."----
explainers_qrf <- ASexplainer(training, data = data$x.test, y = data$y.test, labels = lab_rules, verbose = FALSE)
mp_qrf <- lapply(explainers_qrf, DALEX::model_performance)
do.call(plot, unname(mp_qrf))


## ----ASML_DALEX2, echo = TRUE, tidy=TRUE, eval=FALSE--------------------------
# # Compute feature importance for each model in the explainers list
# vi_qrf <- lapply(explainers_qrf, DALEX::model_parts)
# # Plot the top 5 most important variables for each model
# do.call(plot, c(unname(vi_qrf), list(max_vars = 5)))
# # Compute PDP for the variable "degree" for each model
# pdp_qrf <- lapply(explainers_qrf, DALEX::model_profile, variable = "degree", type = "partial")
# # Plot the PDPs generated
# do.call(plot, unname(pdp_qrf))


## ----AMSLtimes, echo = FALSE, tidy=TRUE, eval=TRUE----------------------------
library(kableExtra)
set.seed(1234)
# Tabla con valores fijos
general_times <- data.frame(
  Function = c("ASML::partition_and_normalize", "caret::preProcess"),
  Time_sec = c(0.03, 1.55) # valores ya obtenidos
)

# Nombres de columna
col_names <- c("Stage", "Execution time (seconds)")

# Ancho opcional de la columna de tiempo
wi <- "10em"

# Crear tabla elegante
if (knitr::is_latex_output()) {
  fs <- 9
} else {
  fs <- NULL
}
kableExtra::kbl(
  general_times,
  escape = TRUE,
  caption = "Execution times (in seconds) on the SpMVformat  dataset for the main preprocessing stages.",
  col.names = col_names,booktabs = TRUE, 
) %>%
  kableExtra::kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position", font_size = fs) %>%
  kableExtra::column_spec(column = 2, width = wi)


## ----AMSLtimes2, echo = FALSE, tidy=TRUE, eval=TRUE---------------------------
library(kableExtra)

# Crear tabla con valores fijos
train_times <- data.frame(
  Method = c("nnet", "svmRadial", "rf"),
  `parallel \\= FALSE` = c(236.58, 881.03, 4753.00),
  `parallel \\= TRUE` = c(50.75, 263.60, 1289.68)
)

# Ancho opcional de columnas
wi <- "10em"

# Crear tabla elegante compatible con PDF
if (knitr::is_latex_output()) {
  fs <- 9
} else {
  fs <- NULL
}
kableExtra::kbl(
  train_times,
  escape = TRUE, # ya escapamos manualmente en los nombres
  caption = "Training times (in seconds) on the SpMVformat  dataset for different methods using ASML::AStrain. The first column shows execution without parallelization (parallel = FALSE) and the second column shows execution with parallelization (parallel = TRUE).",
  col.names = c("Method", "parallel = FALSE", "parallel = TRUE"), booktabs = TRUE, 
) %>%
  kableExtra::kable_styling(latex_options = c("hold_position"), font_size = fs) %>%
  kableExtra::column_spec(column = 2:3, width = wi) %>%
  kableExtra::add_header_above(c(" " = 1, "Execution times (in seconds) of ASML::AStrain" = 2))


## ----ASMLnnet, echo = TRUE, tidy=TRUE, eval=FALSE-----------------------------
# set.seed(1234)
# data(SpMVformat)
# features <- SpMVformat$x
# KPI <- SpMVformat$y
# data <- partition_and_normalize(features, KPI, better_smaller = FALSE)
# preProcValues <- caret::preProcess(data$x.train, method = "YeoJohnson")
# data$x.train <- predict(preProcValues, data$x.train)
# data$x.test <- predict(preProcValues, data$x.test)
# training <- AStrain(data, method = "nnet", parallel = TRUE)
# pred <- ASpredict(training, newdata = data$x.test)
# ranking(data, predictions = pred)


## ----ASMLnnet1, echo = FALSE, tidy=TRUE, out.width = ifelse(knitr::is_latex_output(), "70%" , "100%"), fig.cap="Ranking of storage formats, including the ML selected, based on the instance-normalized KPI for the test sample. The bars represent the percentage of times each storage format appeared in different ranking positions, with the numbers indicating the mean value of the normalized KPI.", fig.alt = "Ranking of storage formats, including the ML selected, based on the instance-normalized KPI for the test sample. The bars represent the percentage of times each storage format appeared in different ranking positions, with the numbers indicating the mean value of the normalized KPI."----
data(SpMVformat)
features <- SpMVformat$x
KPI <- SpMVformat$y
data <- partition_and_normalize(features, KPI, better_smaller = FALSE)
preProcValues <- caret::preProcess(data$x.train, method = "YeoJohnson")
data$x.train <- predict(preProcValues, data$x.train)
data$x.test <- predict(preProcValues, data$x.test)
training <- AStrain(data, method = "nnet", parallel = TRUE)
pred <- ASpredict(training, newdata = data$x.test)
ranking(data, predictions = pred)


## ----echo = TRUE, tidy=TRUE, eval=TRUE----------------------------------------
set.seed(1234)
library(tidyverse)
library(rvest)
scen <- "CPMP-2015"
url <- paste0("https://coseal.github.io/aslib-r/scenario-pages/", scen, "/data_files")
page <- read_html(paste0(url, ".html"))
file_links <- page %>%
  html_nodes("a") %>%
  html_attr("href")

# Create directory for downloaded files
dir_data <- paste0(scen, "_data")
dir.create(dir_data, showWarnings = FALSE)

# Download files
for (link in file_links) {
  full_link <- ifelse(grepl("^http", link), link, paste0(url, "/", link))
  file_name <- basename(link)
  dest_file <- file.path(dir_data, file_name)
  if (!is.na(full_link)) {
    download.file(full_link, dest_file, mode = "wb", quiet = TRUE)
  }
}


## ----echo = TRUE, tidy=TRUE, eval=TRUE----------------------------------------
library(aslib)
ASScen <- aslib::parseASScenario(dir_data)
llamaScen <- aslib::convertToLlama(ASScen)
folds <- llama::cvFolds(llamaScen)


## ----echo = TRUE, tidy=TRUE, eval=TRUE----------------------------------------
KPI <- folds$data[, folds$performance]
features <- folds$data[, folds$features]
cutoff <- ASScen$desc$algorithm_cutoff_time
is.timeout <- ASScen$algo.runstatus[, -c(1, 2)] != "ok"
KPI_pen <- KPI * ifelse(is.timeout, 10, 1)
nins <- length(getInstanceNames(ASScen))
ID <- 1:nins


## ----echo = TRUE, tidy=TRUE, eval=TRUE----------------------------------------
data <- partition_and_normalize(x = features, y = KPI, x.test = features, y.test = KPI, better_smaller = TRUE)
train_control <- caret::trainControl(index = folds$train, savePredictions = "final")
training <- AStrain(data, method = "qrf", trControl = train_control)


## ----echo = TRUE, tidy=TRUE, eval=TRUE----------------------------------------
pred_list <- lapply(training, function(model) {
  model$pred %>%
    arrange(rowIndex) %>%
    pull(pred)
})

pred <- do.call(cbind, pred_list)
alg_sel <- apply(pred, 1, which.max)

succ <- mean(!is.timeout[cbind(ID, alg_sel)])
par10 <- mean(KPI_pen[cbind(ID, alg_sel)])
mcp <- mean(KPI[cbind(ID, alg_sel)] - apply(KPI, 1, min))


## ----AMSLtabASLIB, echo = FALSE, tidy=TRUE, eval=TRUE-------------------------
results_table <- data.frame(Model = "ASML qrf", succ = format(succ, nsmall = 3, digits = 3), par10 = format(par10, nsmall = 3, digits = 3), mcp = format(mcp, nsmall = 3, digits = 3))

# Add manually defined rows
manual_rows <- data.frame(
  Model = c("baseline vbs", "baseline singleBest", "regr.lm", "regr.rpart", "regr.randomForest"),
  succ = format(c(1.000, 0.812, 0.843, 0.843, 0.846), nsmall = 3, digits = 3),
  par10 = format(c(227.605, 7002.907, 5887.326, 5916.120, 5748.065), nsmall = 3, digits = 3),
  mcp = format(c(0.000, 688.774, 556.875, 585.669, 540.574), nsmall = 3, digits = 3)
)

# Combine with the results table
results_table <- rbind(manual_rows, results_table)

# Update column names if necessary
colnames(results_table) <- kableExtra::cell_spec(colnames(results_table), monospace = TRUE)

# Create the table
if (knitr::is_latex_output()) {
  fs <- 9
} else {
  fs <- NULL
}
if (knitr::is_html_output()) {
  results_table %>%
    kableExtra::kbl(
      escape = FALSE, caption = "Performance results of various models on the CPMP-2015 dataset. The last row represents the performance of the quantile random forest model based on instance-normalized KPI using the \\CRANpkg{ASML} package.
                The preceding rows detail the results (all taken from original ASlib study^[Available at: https://coseal.github.io/aslib-r/scenario-pages/CPMP-2015/llama.html (Accessed October 25, 2024).]) of the virtual best solver (vbs), single best solver (singleBest), and the considered regression methods (linear model, regression trees and regression random forest).",
      align = "lrrr"
    ) %>%
    kableExtra::kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position", font_size = fs) %>%
    kableExtra::row_spec(0, bold = TRUE) %>% # Encabezado en negrita
    kableExtra::row_spec(c(1, 2), background = "#E6F2FA") %>% # Color para la primera fila
    kableExtra::row_spec(3:5, background = "#B3D8E5") %>% # Color para la segunda fila
    kableExtra::row_spec(nrow(results_table), background = "#99C4DE") # Color para la última fila
} else {
  results_table %>%
    kableExtra::kbl(
      escape = FALSE, caption = "Performance results of various models on the CPMP-2015 dataset. The last row represents the performance of the quantile random forest model based on instance-normalized KPI using the \\CRANpkg{ASML} package.
                The preceding rows detail the results (all taken from original ASlib study) of the virtual best solver (vbs), single best solver (singleBest), and the considered regression methods (linear model, regression trees and regression random forest).", booktabs = TRUE, 
      align = "lrrr"
    ) %>%
    kableExtra::kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position", font_size = fs) %>%
    kableExtra::row_spec(0, bold = TRUE)
}


## ----AMSLtabASLIB_OLD, echo = FALSE, tidy=TRUE, eval=FALSE--------------------
# results_table <- cbind(succ, par10, mcp)
# colnames(results_table) <- kableExtra::cell_spec(colnames(results_table), monospace = TRUE)
# if (knitr::is_latex_output()) {
#   fs <- 9
# } else {
#   fs <- NULL
# }
# kableExtra::kbl(results_table, escape = F, booktabs = TRUE, caption = "Performance results of quantile random forest on the CPMP-2015 dataset based on instance-normalized KPI.") %>%
#   kableExtra::kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position", font_size = fs)

