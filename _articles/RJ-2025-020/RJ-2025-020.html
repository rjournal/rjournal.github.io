<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { color: #00769e; background-color: #f1f3f5; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #00769e; } /* Normal */
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #657422; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #00769e; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #00769e; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #00769e; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #5e5e5e; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

<style>
  div.csl-bib-body { }
  div.csl-entry {
    clear: both;
      margin-bottom: 0em;
    }
  .hanging div.csl-entry {
    margin-left:2em;
    text-indent:-2em;
  }
  div.csl-left-margin {
    min-width:2em;
    float:left;
  }
  div.csl-right-inline {
    margin-left:2em;
    padding-left:1em;
  }
  div.csl-indent {
    margin-left: 2em;
  }
</style>

  <!--radix_placeholder_meta_tags-->
  <title>MSmix: An R Package for clustering partial rankings via mixtures of Mallows Models with Spearman distance</title>

  <meta property="description" itemprop="description" content="MSmix is a recently developed R package&#10;implementing maximum likelihood estimation of finite mixtures of&#10;Mallows models with Spearman distance for full and partial rankings.&#10;The package is designed to implement computationally tractable&#10;estimation routines, with the ability to handle arbitrary forms of&#10;partial rankings and a large number of items. The frequentist&#10;estimation task is accomplished via Expectation-Maximization&#10;algorithms, integrating data augmentation strategies to recover the&#10;unobserved heterogeneity and the missing ranks. The package also&#10;provides functionalities for uncertainty quantification of the&#10;parameter estimates, via diverse bootstrap methods and asymptotic&#10;confidence intervals. Generic methods for S3 class objects are&#10;constructed for more effectively managing the output of the main&#10;routines. The usefulness of the package and its computational&#10;performance compared with competing software is illustrated via&#10;applications to both simulated and original real ranking datasets."/>

  <link rel="license" href="https://creativecommons.org/licenses/by/4.0/"/>

  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2025-09-25"/>
  <meta property="article:created" itemprop="dateCreated" content="2025-09-25"/>
  <meta name="article:author" content="Marta Crispino"/>
  <meta name="article:author" content="Cristina Mollica"/>
  <meta name="article:author" content="Lucia Modugno"/>

  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="MSmix: An R Package for clustering partial rankings via mixtures of Mallows Models with Spearman distance"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="MSmix is a recently developed R package&#10;implementing maximum likelihood estimation of finite mixtures of&#10;Mallows models with Spearman distance for full and partial rankings.&#10;The package is designed to implement computationally tractable&#10;estimation routines, with the ability to handle arbitrary forms of&#10;partial rankings and a large number of items. The frequentist&#10;estimation task is accomplished via Expectation-Maximization&#10;algorithms, integrating data augmentation strategies to recover the&#10;unobserved heterogeneity and the missing ranks. The package also&#10;provides functionalities for uncertainty quantification of the&#10;parameter estimates, via diverse bootstrap methods and asymptotic&#10;confidence intervals. Generic methods for S3 class objects are&#10;constructed for more effectively managing the output of the main&#10;routines. The usefulness of the package and its computational&#10;performance compared with competing software is illustrated via&#10;applications to both simulated and original real ranking datasets."/>
  <meta property="og:locale" content="en_US"/>

  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="MSmix: An R Package for clustering partial rankings via mixtures of Mallows Models with Spearman distance"/>
  <meta property="twitter:description" content="MSmix is a recently developed R package&#10;implementing maximum likelihood estimation of finite mixtures of&#10;Mallows models with Spearman distance for full and partial rankings.&#10;The package is designed to implement computationally tractable&#10;estimation routines, with the ability to handle arbitrary forms of&#10;partial rankings and a large number of items. The frequentist&#10;estimation task is accomplished via Expectation-Maximization&#10;algorithms, integrating data augmentation strategies to recover the&#10;unobserved heterogeneity and the missing ranks. The package also&#10;provides functionalities for uncertainty quantification of the&#10;parameter estimates, via diverse bootstrap methods and asymptotic&#10;confidence intervals. Generic methods for S3 class objects are&#10;constructed for more effectively managing the output of the main&#10;routines. The usefulness of the package and its computational&#10;performance compared with competing software is illustrated via&#10;applications to both simulated and original real ranking datasets."/>

  <!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
  <meta name="citation_title" content="MSmix: An R Package for clustering partial rankings via mixtures of Mallows Models with Spearman distance"/>
  <meta name="citation_fulltext_html_url" content="https://doi.org/10.32614/RJ-2025-020"/>
  <meta name="citation_pdf_url" content="RJ-2025-020.pdf"/>
  <meta name="citation_volume" content="17"/>
  <meta name="citation_issue" content="2"/>
  <meta name="citation_doi" content="10.32614/RJ-2025-020"/>
  <meta name="citation_journal_title" content="The R Journal"/>
  <meta name="citation_issn" content="2073-4859"/>
  <meta name="citation_firstpage" content="206"/>
  <meta name="citation_lastpage" content="230"/>
  <meta name="citation_fulltext_world_readable" content=""/>
  <meta name="citation_online_date" content="2025/09/25"/>
  <meta name="citation_publication_date" content="2025/09/25"/>
  <meta name="citation_author" content="Marta Crispino"/>
  <meta name="citation_author_institution" content="Department of Economics, Statistics and Research,Bank of Italy Rome,&#10;Italy"/>
  <meta name="citation_author" content="Cristina Mollica"/>
  <meta name="citation_author_institution" content="Department of Statistical Sciences, Sapienza University of Rome"/>
  <meta name="citation_author" content="Lucia Modugno"/>
  <meta name="citation_author_institution" content="Department of Economics, Statistics and Research, Bank of Italy"/>
  <!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=Statistical methods for ranking data;citation_publisher=Springer;citation_author=Mayer Alvo;citation_author=Philip L. H. Yu"/>
  <meta name="citation_reference" content="citation_title=BayesMallows: An R Package for the Bayesian Mallows Model;citation_volume=12;citation_author= Sørensen;citation_author=Marta Crispino;citation_author=Qinghua Liu;citation_author=Valeria Vitelli"/>
  <meta name="citation_reference" content="citation_title=Maximum likelihood estimation in Mallows’s model using partially ranked data;citation_publisher=Springer New York;citation_author=L. A. Beckett"/>
  <meta name="citation_reference" content="citation_title=Rank Analysis of Incomplete Block Designs: I. The Method of Paired Comparisons;citation_publisher=JSTOR;citation_volume=39;citation_author=Ralph Allan Bradley;citation_author=Milton E Terry"/>
  <meta name="citation_reference" content="citation_title=Efficient and accurate inference for mixtures of Mallows models with spearman distance;citation_volume=98;citation_author=Marta Crispino;citation_author=Cristina Mollica;citation_author=Valerio Astuti;citation_author=Luca Tardella"/>
  <meta name="citation_reference" content="citation_title=The Mallows model with respondents’ covariates for the analysis of preference rankings;citation_author=M Crispino;citation_author=L Modugno;citation_author=L Mollica"/>
  <meta name="citation_reference" content="citation_title=Metric methods for analyzing partially ranked data;citation_publisher=Lecture Notes in Statistics No. 34, Springer New York;citation_author=Douglas E. Critchlow"/>
  <meta name="citation_reference" content="citation_title=Probability Models on Rankings;citation_volume=35;citation_author=Douglas E Critchlow;citation_author=M. A. Fligner;citation_author=J. S. Verducci"/>
  <meta name="citation_reference" content="citation_title=Group representations in probability and statistics;citation_publisher=Institute of Mathematical Statistics;citation_volume=11;citation_author=P. Diaconis"/>
  <meta name="citation_reference" content="citation_title=The Jackknife, the Bootstrap and Other Resampling Plans;citation_publisher=SIAM;citation_author=Bradley Efron"/>
  <meta name="citation_reference" content="citation_title=An extended Mallows model for ranked data aggregation;citation_publisher=Taylor &amp; Francis;citation_volume=115;citation_author=Han Li;citation_author=Minxuan Xu;citation_author=Jun S. Liu;citation_author=Xiaodan Fan"/>
  <meta name="citation_reference" content="citation_title=ExtMallows: An extended Mallows model and its hierarchical version for ranked data aggregation;citation_author=Han Li;citation_author=Minxuan Xu;citation_author=Jun S. Liu;citation_author=Xiaodan Fan"/>
  <meta name="citation_reference" content="citation_title=ggplot2: Elegant graphics for data analysis;citation_publisher=Springer-Verlag New York;citation_author=Hadley Wickham"/>
  <meta name="citation_reference" content="citation_title=Analysis of Irish Third-Level College Applications Data;citation_publisher=Wiley Online Library;citation_volume=169;citation_author=I. C. Gormley;citation_author=T. B. Murphy"/>
  <meta name="citation_reference" content="citation_title=A Mixture of Experts Model for Rank Data with Applications in Election Studies;citation_publisher=Institute of Mathematical Statistics;citation_volume=2;citation_author=Isobel Claire Gormley;citation_author=Thomas Brendan Murphy"/>
  <meta name="citation_reference" content="citation_title=Adaptive Mixtures of Local Experts;citation_publisher=MIT Press;citation_volume=3;citation_author=Robert A Jacobs;citation_author=Michael I Jordan;citation_author=Steven J Nowlan;citation_author=Geoffrey E Hinton"/>
  <meta name="citation_reference" content="citation_title=Model-Based Clustering for Multivariate Partial Ranking Data;citation_volume=149;citation_author=J. Jacques;citation_author=C. Biernacki"/>
  <meta name="citation_reference" content="citation_title=Hierarchical Mixtures of Experts and the EM Algorithm;citation_publisher=MIT Press;citation_volume=6;citation_author=Michael I Jordan;citation_author=Robert A Jacobs"/>
  <meta name="citation_reference" content="citation_title=Mixtures of Weighted Distance-Based Models for Ranking Data with Applications in Political Studies;citation_publisher=Elsevier;citation_volume=56;citation_author=Paul H Lee;citation_author=Philip L H Yu"/>
  <meta name="citation_reference" content="citation_title=Calibrated Bayes, for Statistics in General, and Missing Data in Particular;citation_publisher=Institute of Mathematical Statistics;citation_volume=26;citation_author=R. Little"/>
  <meta name="citation_reference" content="citation_title=Statistical Analysis with Missing Data;citation_publisher=John Wiley &amp; Sons;citation_author=Roderick JA Little;citation_author=Donald B Rubin"/>
  <meta name="citation_reference" content="citation_title=Model-Based Learning from Preference Data;citation_volume=6;citation_doi=10.1146/annurev-statistics-031017-100213;citation_author=Qinghua Liu;citation_author=Marta Crispino;citation_author=Ida Scheel;citation_author=Valeria Vitelli;citation_author=Arnoldo Frigessi"/>
  <meta name="citation_reference" content="citation_title=Individual Choice Behavior: A Theoretical Analysis;citation_publisher=Wiley;citation_author=R. D. Luce"/>
  <meta name="citation_reference" content="citation_title=Non-Null Ranking Models. I;citation_volume=44;citation_author=C. L. Mallows"/>
  <meta name="citation_reference" content="citation_title=Analyzing and modeling rank data;citation_publisher=Chapman &amp; Hall;citation_volume=64;citation_author=J. I. Marden"/>
  <meta name="citation_reference" content="citation_title=Finite mixture models;citation_publisher=New York: Wiley;citation_author=G. Mclachlan;citation_author=David Peel"/>
  <meta name="citation_reference" content="citation_title=Bayesian Plackett-Luce Mixture Models for Partially Ranked Data;citation_volume=82;citation_author=Cristina Mollica;citation_author=Luca Tardella"/>
  <meta name="citation_reference" content="citation_title=PLMIX: An R Package for Modelling and Clustering Partially Ranked Data;citation_publisher=Taylor &amp; Francis;citation_volume=90;citation_author=Cristina Mollica;citation_author=Luca Tardella"/>
  <meta name="citation_reference" content="citation_title=Mixtures of Distance-Based Models for Ranking Data;citation_volume=41;citation_author=T. B. Murphy;citation_author=D. Martin"/>
  <meta name="citation_reference" content="citation_title=The clustered Mallows model;citation_publisher=Springer;citation_volume=35;citation_author=Luiza SC Piancastelli;citation_author=Nial Friel"/>
  <meta name="citation_reference" content="citation_title=Time series analysis of rankings: A GARCH-type approach;citation_author=Luiza Piancastelli;citation_author=Wagner Barreto-Souza"/>
  <meta name="citation_reference" content="citation_title=The Analysis of Permutations;citation_volume=24;citation_author=R. L. Plackett"/>
  <meta name="citation_reference" content="citation_title=An R Package for Analyzing and Modeling Ranking Data;citation_volume=3;citation_author=Paul H Lee;citation_author=Philip L H Yu"/>
  <meta name="citation_reference" content="citation_title=prefmod: Utilities to Fit Paired Comparison Models for Preferences;citation_author=Reinhold Hatzinger;citation_author=Marco Johannes Maier"/>
  <meta name="citation_reference" content="citation_title=prefmod: An R Package for Modeling Preferences Based on Paired Comparisons, Rankings, or Ratings;citation_volume=48;citation_author=Reinhold Hatzinger;citation_author=Regina Dittrich"/>
  <meta name="citation_reference" content="citation_title=Rankcluster: An R Package for Clustering Multivariate Partial Rankings;citation_volume=6;citation_author=J. Jacques;citation_author=Q. Grimonprez;citation_author=C. Biernacki"/>
  <meta name="citation_reference" content="citation_title=Weighted Distance-Based Models for Ranking Data Using the R Package rankdist;citation_volume=90;citation_author=Zhaozhi Qian;citation_author=Philip L. H. Yu"/>
  <meta name="citation_reference" content="citation_title=RMallow: Fit multi-modal Mallows’ models to ranking data;citation_author=Erik Gregory"/>
  <meta name="citation_reference" content="citation_title=Inference and Missing Data;citation_publisher=Oxford University Press;citation_volume=63;citation_author=Donald B Rubin"/>
  <meta name="citation_reference" content="citation_title=StatRank: Statistical rank aggregation: Inference, evaluation, and visualization;citation_author=Hossein Azari Soufiani;citation_author=William Chen"/>
  <meta name="citation_reference" content="citation_title=Bootstrap validation of the estimated parameters in mixture models used for clustering;citation_volume=160;citation_author=Zhivko Taushanov;citation_author=André Berchtold"/>
  <meta name="citation_reference" content="citation_title=A Law of Comparative Judgment;citation_volume=34;citation_doi=10.1037/h0070288;citation_author=L. L. Thurstone"/>
  <meta name="citation_reference" content="citation_title=Modelling Rankings in R: the PlackettLuce package;citation_volume=35;citation_doi=10.1007/s00180-020-00959-3;citation_author=Heather L. Turner;citation_author=Jacob Etten;citation_author=David Firth;citation_author=Ioannis Kosmidis"/>
  <meta name="citation_reference" content="citation_title=A Monte Carlo implementation of the EM algorithm and the poor man’s data augmentation algorithms;citation_publisher=[American Statistical Association, Taylor &amp; Francis, Ltd.];citation_volume=85;citation_author=Greg C. G. Wei;citation_author=Martin A. Tanner"/>
  <meta name="citation_reference" content="citation_title=Mallows permutation models with ${L}^1$ and ${L}^2$ distances I: Hit and run algorithms and mixing times;citation_author=Chenyang Zhong"/>
  <meta name="citation_reference" content="citation_title=Partition–Mallows model and its inference for rank aggregation;citation_publisher=Taylor &amp; Francis;citation_volume=118;citation_author=Wanchuang Zhu;citation_author=Yingkai Jiang;citation_author=Jun S. Liu;citation_author=Ke Deng"/>
  <!--radix_placeholder_rmarkdown_metadata-->

  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","date_received","journal","volume","issue","slug","citation_url","packages","preview","bibliography","CTV","legacy_pdf","legacy_converted","output","draft","pdf_url","doi","creative_commons","csl"]}},"value":[{"type":"character","attributes":{},"value":["MSmix: An R Package for clustering partial rankings via mixtures of Mallows Models with Spearman distance"]},{"type":"character","attributes":{},"value":["MSmix is a recently developed R package\nimplementing maximum likelihood estimation of finite mixtures of\nMallows models with Spearman distance for full and partial rankings.\nThe package is designed to implement computationally tractable\nestimation routines, with the ability to handle arbitrary forms of\npartial rankings and a large number of items. The frequentist\nestimation task is accomplished via Expectation-Maximization\nalgorithms, integrating data augmentation strategies to recover the\nunobserved heterogeneity and the missing ranks. The package also\nprovides functionalities for uncertainty quantification of the\nparameter estimates, via diverse bootstrap methods and asymptotic\nconfidence intervals. Generic methods for S3 class objects are\nconstructed for more effectively managing the output of the main\nroutines. The usefulness of the package and its computational\nperformance compared with competing software is illustrated via\napplications to both simulated and original real ranking datasets.\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation","address"]}},"value":[{"type":"character","attributes":{},"value":["Marta Crispino"]},{"type":"character","attributes":{},"value":["Department of Economics, Statistics and Research,Bank of Italy Rome,\nItaly"]},{"type":"character","attributes":{},"value":["[marta.crispino@bancaditalia.it](marta.crispino@bancaditalia.it){.uri}\n"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation","address"]}},"value":[{"type":"character","attributes":{},"value":["Cristina Mollica"]},{"type":"character","attributes":{},"value":["Department of Statistical Sciences, Sapienza University of Rome"]},{"type":"character","attributes":{},"value":["Italy","[cristina.mollica@uniroma1.it](cristina.mollica@uniroma1.it){.uri}\n"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation","address"]}},"value":[{"type":"character","attributes":{},"value":["Lucia Modugno"]},{"type":"character","attributes":{},"value":["Department of Economics, Statistics and Research, Bank of Italy"]},{"type":"character","attributes":{},"value":["Rome, Italy","[lucia.modugno@bancaditalia.it](lucia.modugno@bancaditalia.it){.uri}\n"]}]}]},{"type":"character","attributes":{},"value":["2025-09-25"]},{"type":"character","attributes":{},"value":["2024-07-16"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","issn","firstpage","lastpage"]}},"value":[{"type":"character","attributes":{},"value":["The R Journal"]},{"type":"character","attributes":{},"value":["2073-4859"]},{"type":"integer","attributes":{},"value":[206]},{"type":"integer","attributes":{},"value":[230]}]},{"type":"integer","attributes":{},"value":[17]},{"type":"integer","attributes":{},"value":[2]},{"type":"character","attributes":{},"value":["RJ-2025-020"]},{"type":"character","attributes":{},"value":["https://doi.org/10.32614/RJ-2025-020"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["cran","bioc"]}},"value":[{"type":"list","attributes":{},"value":[]},{"type":"list","attributes":{},"value":[]}]},{"type":"character","attributes":{},"value":["preview.png"]},{"type":"character","attributes":{},"value":["RJ2025_paper.bib"]},{"type":"list","attributes":{},"value":[]},{"type":"logical","attributes":{},"value":[true]},{"type":"logical","attributes":{},"value":[true]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc","mathjax","md_extension"]}},"value":[{"type":"logical","attributes":{},"value":[true]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"]},{"type":"character","attributes":{},"value":["-tex_math_single_backslash"]}]}]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["RJ-2025-020.pdf"]},{"type":"character","attributes":{},"value":["10.32614/RJ-2025-020"]},{"type":"character","attributes":{},"value":["CC BY"]},{"type":"character","attributes":{},"value":["/home/mitchell/R/x86_64-pc-linux-gnu-library/4.5/rjtools/rjournal.csl"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["figures/RJ2025_paper_boot1.pdf","figures/RJ2025_paper_boot1.png","figures/RJ2025_paper_boot2.pdf","figures/RJ2025_paper_boot2.png","figures/RJ2025_paper_cons.pdf","figures/RJ2025_paper_cons.png","figures/RJ2025_paper_descr_beers.pdf","figures/RJ2025_paper_descr_beers.png","figures/RJ2025_paper_dist1_new.png","figures/RJ2025_paper_dist2_new.png","figures/RJ2025_paper_heat.pdf","figures/RJ2025_paper_heat.png","figures/RJ2025_paper_plotsanti.png","figures/RJ2025_paper_scatter_beers.png","figures/RJ2025_paper_zeta.pdf","figures/RJ2025_paper_zeta.png","RJ-2025-020_files/anchor-4.2.2/anchor.min.js","RJ-2025-020_files/bowser-1.9.3/bowser.min.js","RJ-2025-020_files/distill-2.2.21/template.v2.js","RJ-2025-020_files/header-attrs-2.29/header-attrs.js","RJ-2025-020_files/jquery-3.6.0/jquery-3.6.0.js","RJ-2025-020_files/jquery-3.6.0/jquery-3.6.0.min.js","RJ-2025-020_files/jquery-3.6.0/jquery-3.6.0.min.map","RJ-2025-020_files/popper-2.6.0/popper.min.js","RJ-2025-020_files/tippy-6.2.7/tippy-bundle.umd.min.js","RJ-2025-020_files/tippy-6.2.7/tippy-light-border.css","RJ-2025-020_files/tippy-6.2.7/tippy.css","RJ-2025-020_files/tippy-6.2.7/tippy.umd.min.js","RJ-2025-020_files/webcomponents-2.0.0/webcomponents.js","RJ-2025-020.pdf","RJ2025_paper.bib","RJ2025_paper.tex","RJournal.sty","RJwrapper.log","RJwrapper.tex","Sweave.sty"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

  <style type="text/css">

  body {
    background-color: white;
  }

  .pandoc-table {
    width: 100%;
  }

  .pandoc-table>caption {
    margin-bottom: 10px;
  }

  .pandoc-table th:not([align]) {
    text-align: left;
  }

  .pagedtable-footer {
    font-size: 15px;
  }

  d-byline .byline {
    grid-template-columns: 2fr 2fr;
  }

  d-byline .byline h3 {
    margin-block-start: 1.5em;
  }

  d-byline .byline .authors-affiliations h3 {
    margin-block-start: 0.5em;
  }

  .authors-affiliations .orcid-id {
    width: 16px;
    height:16px;
    margin-left: 4px;
    margin-right: 4px;
    vertical-align: middle;
    padding-bottom: 2px;
  }

  d-title .dt-tags {
    margin-top: 1em;
    grid-column: text;
  }

  .dt-tags .dt-tag {
    text-decoration: none;
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0em 0.4em;
    margin-right: 0.5em;
    margin-bottom: 0.4em;
    font-size: 70%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  d-article table.gt_table td,
  d-article table.gt_table th {
    border-bottom: none;
    font-size: 100%;
  }

  .html-widget {
    margin-bottom: 2.0em;
  }

  .l-screen-inset {
    padding-right: 16px;
  }

  .l-screen .caption {
    margin-left: 10px;
  }

  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .shaded-content {
    background: white;
  }

  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }

  .hidden {
    display: none !important;
  }

  hr.section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    margin: 0px;
  }


  d-byline {
    border-top: none;
  }

  d-article {
    padding-top: 2.5rem;
    padding-bottom: 30px;
    border-top: none;
  }

  d-appendix {
    padding-top: 30px;
  }

  d-article>p>img {
    width: 100%;
  }

  d-article h2 {
    margin: 1rem 0 1.5rem 0;
  }

  d-article h3 {
    margin-top: 1.5rem;
  }

  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }

  /* Tweak code blocks */

  d-article div.sourceCode code,
  d-article pre code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: auto;
  }

  d-article div.sourceCode {
    background-color: white;
  }

  d-article div.sourceCode pre {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }

  d-article pre {
    font-size: 12px;
    color: black;
    background: none;
    margin-top: 0;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  d-article pre a {
    border-bottom: none;
  }

  d-article pre a:hover {
    border-bottom: none;
    text-decoration: underline;
  }

  d-article details {
    grid-column: text;
    margin-bottom: 0.8em;
  }

  @media(min-width: 768px) {

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: visible !important;
  }

  d-article div.sourceCode pre {
    padding-left: 18px;
    font-size: 14px;
  }

  /* tweak for Pandoc numbered line within distill */
  d-article pre.numberSource code > span {
      left: -2em;
  }

  d-article pre {
    font-size: 14px;
  }

  }

  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  /* CSS for d-contents */

  .d-contents {
    grid-column: text;
    color: rgba(0,0,0,0.8);
    font-size: 0.9em;
    padding-bottom: 1em;
    margin-bottom: 1em;
    padding-bottom: 0.5em;
    margin-bottom: 1em;
    padding-left: 0.25em;
    justify-self: start;
  }

  @media(min-width: 1000px) {
    .d-contents.d-contents-float {
      height: 0;
      grid-column-start: 1;
      grid-column-end: 4;
      justify-self: center;
      padding-right: 3em;
      padding-left: 2em;
    }
  }

  .d-contents nav h3 {
    font-size: 18px;
    margin-top: 0;
    margin-bottom: 1em;
  }

  .d-contents li {
    list-style-type: none
  }

  .d-contents nav > ul {
    padding-left: 0;
  }

  .d-contents ul {
    padding-left: 1em
  }

  .d-contents nav ul li {
    margin-top: 0.6em;
    margin-bottom: 0.2em;
  }

  .d-contents nav a {
    font-size: 13px;
    border-bottom: none;
    text-decoration: none
    color: rgba(0, 0, 0, 0.8);
  }

  .d-contents nav a:hover {
    text-decoration: underline solid rgba(0, 0, 0, 0.6)
  }

  .d-contents nav > ul > li > a {
    font-weight: 600;
  }

  .d-contents nav > ul > li > ul {
    font-weight: inherit;
  }

  .d-contents nav > ul > li > ul > li {
    margin-top: 0.2em;
  }


  .d-contents nav ul {
    margin-top: 0;
    margin-bottom: 0.25em;
  }

  .d-article-with-toc h2:nth-child(2) {
    margin-top: 0;
  }


  /* Figure */

  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }

  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }

  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }

  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }

  /* Citations */

  d-article .citation {
    color: inherit;
    cursor: inherit;
  }

  div.hanging-indent{
    margin-left: 1em; text-indent: -1em;
  }

  /* Citation hover box */

  .tippy-box[data-theme~=light-border] {
    background-color: rgba(250, 250, 250, 0.95);
  }

  .tippy-content > p {
    margin-bottom: 0;
    padding: 2px;
  }


  /* Tweak 1000px media break to show more text */

  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }

    .grid {
      grid-column-gap: 16px;
    }

    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }

  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }

    .grid {
      grid-column-gap: 32px;
    }
  }


  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */

  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  /* Include appendix styles here so they can be overridden */

  d-appendix {
    contain: layout style;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-top: 60px;
    margin-bottom: 0;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    color: rgba(0,0,0,0.5);
    padding-top: 60px;
    padding-bottom: 48px;
  }

  d-appendix h3 {
    grid-column: page-start / text-start;
    font-size: 15px;
    font-weight: 500;
    margin-top: 1em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.65);
  }

  d-appendix h3 + * {
    margin-top: 1em;
  }

  d-appendix ol {
    padding: 0 0 0 15px;
  }

  @media (min-width: 768px) {
    d-appendix ol {
      padding: 0 0 0 30px;
      margin-left: -30px;
    }
  }

  d-appendix li {
    margin-bottom: 1em;
  }

  d-appendix a {
    color: rgba(0, 0, 0, 0.6);
  }

  d-appendix > * {
    grid-column: text;
  }

  d-appendix > d-footnote-list,
  d-appendix > d-citation-list,
  d-appendix > distill-appendix {
    grid-column: screen;
  }

  /* Include footnote styles here so they can be overridden */

  d-footnote-list {
    contain: layout style;
  }

  d-footnote-list > * {
    grid-column: text;
  }

  d-footnote-list a.footnote-backlink {
    color: rgba(0,0,0,0.3);
    padding-left: 0.5em;
  }



  /* Anchor.js */

  .anchorjs-link {
    /*transition: all .25s linear; */
    text-decoration: none;
    border-bottom: none;
  }
  *:hover > .anchorjs-link {
    margin-left: -1.125em !important;
    text-decoration: none;
    border-bottom: none;
  }

  /* Social footer */

  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }

  .disqus-comments {
    margin-right: 30px;
  }

  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }

  #disqus_thread {
    margin-top: 30px;
  }

  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }

  .article-sharing a:hover {
    border-bottom: none;
  }

  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }

  .subscribe p {
    margin-bottom: 0.5em;
  }


  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }


  .sidebar-section.custom {
    font-size: 12px;
    line-height: 1.6em;
  }

  .custom p {
    margin-bottom: 0.5em;
  }

  /* Styles for listing layout (hide title) */
  .layout-listing d-title, .layout-listing .d-title {
    display: none;
  }

  /* Styles for posts lists (not auto-injected) */


  .posts-with-sidebar {
    padding-left: 45px;
    padding-right: 45px;
  }

  .posts-list .description h2,
  .posts-list .description p {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  }

  .posts-list .description h2 {
    font-weight: 700;
    border-bottom: none;
    padding-bottom: 0;
  }

  .posts-list h2.post-tag {
    border-bottom: 1px solid rgba(0, 0, 0, 0.2);
    padding-bottom: 12px;
  }
  .posts-list {
    margin-top: 60px;
    margin-bottom: 24px;
  }

  .posts-list .post-preview {
    text-decoration: none;
    overflow: hidden;
    display: block;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
    padding: 24px 0;
  }

  .post-preview-last {
    border-bottom: none !important;
  }

  .posts-list .posts-list-caption {
    grid-column: screen;
    font-weight: 400;
  }

  .posts-list .post-preview h2 {
    margin: 0 0 6px 0;
    line-height: 1.2em;
    font-style: normal;
    font-size: 24px;
  }

  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.4em;
    font-size: 16px;
  }

  .posts-list .post-preview .thumbnail {
    box-sizing: border-box;
    margin-bottom: 24px;
    position: relative;
    max-width: 500px;
  }
  .posts-list .post-preview img {
    width: 100%;
    display: block;
  }

  .posts-list .metadata {
    font-size: 12px;
    line-height: 1.4em;
    margin-bottom: 18px;
  }

  .posts-list .metadata > * {
    display: inline-block;
  }

  .posts-list .metadata .publishedDate {
    margin-right: 2em;
  }

  .posts-list .metadata .dt-authors {
    display: block;
    margin-top: 0.3em;
    margin-right: 2em;
  }

  .posts-list .dt-tags {
    display: block;
    line-height: 1em;
  }

  .posts-list .dt-tags .dt-tag {
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0.3em 0.4em;
    margin-right: 0.2em;
    margin-bottom: 0.4em;
    font-size: 60%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  .posts-list img {
    opacity: 1;
  }

  .posts-list img[data-src] {
    opacity: 0;
  }

  .posts-more {
    clear: both;
  }


  .posts-sidebar {
    font-size: 16px;
  }

  .posts-sidebar h3 {
    font-size: 16px;
    margin-top: 0;
    margin-bottom: 0.5em;
    font-weight: 400;
    text-transform: uppercase;
  }

  .sidebar-section {
    margin-bottom: 30px;
  }

  .categories ul {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }

  .categories li {
    color: rgba(0, 0, 0, 0.8);
    margin-bottom: 0;
  }

  .categories li>a {
    border-bottom: none;
  }

  .categories li>a:hover {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  }

  .categories .active {
    font-weight: 600;
  }

  .categories .category-count {
    color: rgba(0, 0, 0, 0.4);
  }


  @media(min-width: 768px) {
    .posts-list .post-preview h2 {
      font-size: 26px;
    }
    .posts-list .post-preview .thumbnail {
      float: right;
      width: 30%;
      margin-bottom: 0;
    }
    .posts-list .post-preview .description {
      float: left;
      width: 45%;
    }
    .posts-list .post-preview .metadata {
      float: left;
      width: 20%;
      margin-top: 8px;
    }
    .posts-list .post-preview p {
      margin: 0 0 12px 0;
      line-height: 1.5em;
      font-size: 16px;
    }
    .posts-with-sidebar .posts-list {
      float: left;
      width: 75%;
    }
    .posts-with-sidebar .posts-sidebar {
      float: right;
      width: 20%;
      margin-top: 60px;
      padding-top: 24px;
      padding-bottom: 24px;
    }
  }


  /* Improve display for browsers without grid (IE/Edge <= 15) */

  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }

  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }

  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }

  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }

  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }

  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }

  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }


  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }

  .downlevel .footnotes ol {
    padding-left: 13px;
  }

  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }

  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }

  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }

  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  .downlevel .posts-list .post-preview {
    color: inherit;
  }



  </style>

  <script type="application/javascript">

  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }

  // show body when load is complete
  function on_load_complete() {

    // add anchors
    if (window.anchors) {
      window.anchors.options.placement = 'left';
      window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
    }


    // set body to visible
    document.body.style.visibility = 'visible';

    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }

    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }

  function init_distill() {

    init_common();

    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);

    // create d-title
    $('.d-title').changeElementType('d-title');

    // separator
    var separator = '<hr class="section-separator" style="clear: both"/>';
    // prepend separator above appendix
    $('.d-byline').before(separator);
    $('.d-article').before(separator);

    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);

    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();

    // move posts container into article
    $('.posts-container').appendTo($('d-article'));

    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');

    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;

    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();

    // move refs into #references-listing
    $('#references-listing').replaceWith($('#refs'));

    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-contents a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });

    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');

    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {

      // capture layout
      var layout = $(this).attr('data-layout');

      // apply layout to markdown level block elements
      var elements = $(this).children().not('details, div.sourceCode, pre, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });


      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });

    // remove code block used to force  highlighting css
    $('.distill-force-highlighting-css').parent().remove();

    // remove empty line numbers inserted by pandoc when using a
    // custom syntax highlighting theme, except when numbering line
    // in code chunk
    $('pre:not(.numberLines) code.sourceCode a:empty').remove();

    // load distill framework
    load_distill_framework();

    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {

      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;

      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');

      // article with toc class
      $('.d-contents').parent().addClass('d-article-with-toc');

      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

      // add orcid ids
      $('.authors-affiliations').find('.author').each(function(i, el) {
        var orcid_id = front_matter.authors[i].orcidID;
        var author_name = front_matter.authors[i].author
        if (orcid_id) {
          var a = $('<a></a>');
          a.attr('href', 'https://orcid.org/' + orcid_id);
          var img = $('<img></img>');
          img.addClass('orcid-id');
          img.attr('alt', author_name ? 'ORCID ID for ' + author_name : 'ORCID ID');
          img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
          a.append(img);
          $(this).append(a);
        }
      });

      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }

      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");

      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }

       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }

      // remove d-appendix and d-footnote-list local styles
      $('d-appendix > style:first-child').remove();
      $('d-footnote-list > style:first-child').remove();

      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();

      // hoverable references
      $('span.citation[data-cites]').each(function() {
        const citeChild = $(this).children()[0]
        // Do not process if @xyz has been used without escaping and without bibliography activated
        // https://github.com/rstudio/distill/issues/466
        if (citeChild === undefined) return true

        if (citeChild.nodeName == "D-FOOTNOTE") {
          var fn = citeChild
          $(this).html(fn.shadowRoot.querySelector("sup"))
          $(this).id = fn.id
          fn.remove()
        }
        var refs = $(this).attr('data-cites').split(" ");
        var refHtml = refs.map(function(ref) {
          // Could use CSS.escape too here, we insure backward compatibility in navigator
          return "<p>" + $('div[id="ref-' + ref + '"]').html() + "</p>";
        }).join("\n");
        window.tippy(this, {
          allowHTML: true,
          content: refHtml,
          maxWidth: 500,
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        });
      });

      // fix footnotes in tables (#411)
      // replacing broken distill.pub feature
      $('table d-footnote').each(function() {
        // we replace internal showAtNode methode which is triggered when hovering a footnote
        this.hoverBox.showAtNode = function(node) {
          // ported from https://github.com/distillpub/template/pull/105/files
          calcOffset = function(elem) {
              let x = elem.offsetLeft;
              let y = elem.offsetTop;
              // Traverse upwards until an `absolute` element is found or `elem`
              // becomes null.
              while (elem = elem.offsetParent && elem.style.position != 'absolute') {
                  x += elem.offsetLeft;
                  y += elem.offsetTop;
              }

              return { left: x, top: y };
          }
          // https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement/offsetTop
          const bbox = node.getBoundingClientRect();
          const offset = calcOffset(node);
          this.show([offset.left + bbox.width, offset.top + bbox.height]);
        }
      })

      // clear polling timer
      clearInterval(tid);

      // show body now that everything is ready
      on_load_complete();
    }

    var tid = setInterval(distill_post_process, 50);
    distill_post_process();

  }

  function init_downlevel() {

    init_common();

     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));

    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;

    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();

    // remove toc
    $('.d-contents').remove();

    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });


    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);

    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();

    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });

    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));

    $('body').addClass('downlevel');

    on_load_complete();
  }


  function init_common() {

    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};

        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });

        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);

    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});

    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      // ignore leaflet img layers (#106)
      figures = figures.filter(':not(img[class*="leaflet"])')
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });

      }
    });

    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });

    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace(/^index[.]html/, "./"));
      });
    }

    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');

    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");

    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();

    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }

  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });

  </script>

  <!--/radix_placeholder_distill-->
  <script src="RJ-2025-020_files/header-attrs-2.29/header-attrs.js"></script>
  <script src="RJ-2025-020_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
  <script src="RJ-2025-020_files/popper-2.6.0/popper.min.js"></script>
  <link href="RJ-2025-020_files/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="RJ-2025-020_files/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="RJ-2025-020_files/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="RJ-2025-020_files/anchor-4.2.2/anchor.min.js"></script>
  <script src="RJ-2025-020_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="RJ-2025-020_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="RJ-2025-020_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->
  <script>
    $(function() {
      console.log("Starting...")

      // Mathjax config (add automatic linebreaks when supported)
      // MathJax = {
      //    tex: {
      //        inlineMath: [['$', '$'], ['\\(', '\\)']],
      //        displayMath: [['$$', '$$'], ['\\[', '\\]']],
      //        tags: 'ams',
      //        multline: true,
      //    },
      //    options: {
      //        linebreaks: { automatic: true },
      //    },
      // };

      // Always show Published - distill hides it if not set
      function show_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'visible');
      }

      show_byline_column('Published')

      // tweak function
      var rmd_meta = JSON.parse($("#radix-rmarkdown-metadata").html());
      function get_meta(name, meta) {
        var ind = meta.attributes.names.value.findIndex((e) => e == name)
        var val = meta.value[ind]
        if (val.type != 'list') {
          return val.value.toString()
        }
        return val
      }

      // tweak description
      // Add clickable tags
      const slug = get_meta('slug', rmd_meta)
      const cite_url = get_meta('citation_url', rmd_meta)

      var title = $("d-title").text

      const buttons = $('<div class="dt-tags" style="grid-column: page;">')
      buttons.append('<a href="#citation" class="dt-tag"><i class="fas fa-quote-left"></i> Cite</a>')
      buttons.append('<a href="' + slug + '.pdf" class="dt-tag"><i class="fas fa-file-pdf"></i> PDF</a>')
      buttons.append('<a href="' + slug + '.zip" class="dt-tag"><i class="fas fa-file-zipper"></i> Supplement</a>')

      // adds Abstract: in front of the first <p> in the title section --
      // unless it happens to be the subtitle (FIXME: this is a bad hack - can't distill do this?)
      var tpar = $("d-title p:not(:empty)").filter(function() {
        return !$(this).hasClass("subtitle");
      }).first();
      if (tpar) {
        const abstract = $('<d-abstract>')
        abstract.append('<b>Abstract:</b><br>')
        abstract.append(tpar) // Move description to d-abstract
        $("d-title p:empty").remove() // Remove empty paragraphs after title
        abstract.append(buttons)
        abstract.insertAfter($('d-title')) // Add abstract section after title */
      }

      // tweak by-line
      var byline = $("d-byline div.byline")
      ind = rmd_meta.attributes.names.value.findIndex((e) => e == "journal")
      const journal = get_meta('journal', rmd_meta)
      const volume = get_meta('volume', rmd_meta)
      const issue = get_meta('issue', rmd_meta)
      const jrtitle = get_meta('title', journal)
      const year = ((jrtitle == "R News") ? 2000 : 2008) + parseInt(volume)
      const firstpage = get_meta('firstpage', journal)
      const lastpage = get_meta('lastpage', journal)
      byline.append('<div class="rjournal grid">')
      $('div.rjournal').append('<h3>Volume</h3>')
      $('div.rjournal').append('<h3>Pages</h3>')
      $('div.rjournal').append('<a class="volume" href="../../issues/'+year+'-'+issue+'">'+volume+'/'+issue+'</a>')
      $('div.rjournal').append('<p class="pages">'+firstpage+' - '+lastpage+'</p>')

      const received_date = new Date(get_meta('date_received', rmd_meta))
      byline.find('h3:contains("Published")').parent().append('<h3>Received</h3><p>'+received_date.toLocaleDateString('en-US', {month: 'short'})+' '+received_date.getDate()+', '+received_date.getFullYear()+'</p>')

    })
  </script>

  <style>
      /*
    .nav-dropdown-content .nav-dropdown-header {
      text-transform: lowercase;
    }
    */

    d-byline .byline {
      grid-template-columns: 2fr 2fr 2fr 2fr;
    }

    d-byline .rjournal {
      grid-column-end: span 2;
      grid-template-columns: 1fr 1fr;
      margin-bottom: 0;
    }

    d-title h1, d-title p, d-title figure,
    d-abstract p, d-abstract b {
      grid-column: page;
    }

    d-title .dt-tags {
      grid-column: page;
    }

    .dt-tags .dt-tag {
      text-transform: lowercase;
    }

    d-article h1 {
      line-height: 1.1em;
    }

    d-abstract p, d-article p {
      text-align: justify;
    }

    @media(min-width: 1000px) {
      .d-contents.d-contents-float {
        justify-self: end;
      }

      nav.toc {
        border-right: 1px solid rgba(0, 0, 0, 0.1);
        border-right-width: 1px;
        border-right-style: solid;
        border-right-color: rgba(0, 0, 0, 0.1);
      }
    }

    .posts-list .dt-tags .dt-tag {
      text-transform: lowercase;
    }

    @keyframes highlight-target {
      0% {
        background-color: #ffa;
      }
      66% {
        background-color: #ffa;
      }
      100% {
        background-color: none;
      }
    }

    d-article :target, d-appendix :target {
       animation: highlight-target 3s;
    }

    .header-section-number {
      margin-right: 0.5em;
    }
    
    d-appendix .citation-appendix,
    .d-appendix .citation-appendix {
      color: rgb(60, 60, 60);
    }

    d-article h2 {
      border-bottom: 0px solid rgba(0, 0, 0, 0.1);
      padding-bottom: 0rem;
    }
    d-article h3 {
      font-size: 20px;
    }
    d-article h4 {
      font-size: 18px;
      text-transform: none;
    }

    @media (min-width: 1024px) {
      d-article h2 {
        font-size: 32px;
      }
      d-article h3 {
        font-size: 24px;
      }
      d-article h4 {
        font-size: 20px;
      }
    }
  </style>


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"MSmix: An R Package for clustering partial rankings via mixtures of Mallows Models with Spearman distance","description":"MSmix is a recently developed R package\nimplementing maximum likelihood estimation of finite mixtures of\nMallows models with Spearman distance for full and partial rankings.\nThe package is designed to implement computationally tractable\nestimation routines, with the ability to handle arbitrary forms of\npartial rankings and a large number of items. The frequentist\nestimation task is accomplished via Expectation-Maximization\nalgorithms, integrating data augmentation strategies to recover the\nunobserved heterogeneity and the missing ranks. The package also\nprovides functionalities for uncertainty quantification of the\nparameter estimates, via diverse bootstrap methods and asymptotic\nconfidence intervals. Generic methods for S3 class objects are\nconstructed for more effectively managing the output of the main\nroutines. The usefulness of the package and its computational\nperformance compared with competing software is illustrated via\napplications to both simulated and original real ranking datasets.","doi":"10.32614/RJ-2025-020","authors":[{"author":"Marta Crispino","authorURL":"#","affiliation":"Department of Economics, Statistics and Research,Bank of Italy Rome,\nItaly","affiliationURL":"#","orcidID":""},{"author":"Cristina Mollica","authorURL":"#","affiliation":"Department of Statistical Sciences, Sapienza University of Rome","affiliationURL":"#","orcidID":""},{"author":"Lucia Modugno","authorURL":"#","affiliation":"Department of Economics, Statistics and Research, Bank of Italy","affiliationURL":"#","orcidID":""}],"publishedDate":"2025-09-25T00:00:00.000+10:00","citationText":"Crispino, et al., 2025"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>MSmix: An R Package for clustering partial rankings via mixtures of Mallows Models with Spearman distance</h1>

<!--radix_placeholder_categories-->
<!--/radix_placeholder_categories-->
<p><p>MSmix is a recently developed R package
implementing maximum likelihood estimation of finite mixtures of
Mallows models with Spearman distance for full and partial rankings.
The package is designed to implement computationally tractable
estimation routines, with the ability to handle arbitrary forms of
partial rankings and a large number of items. The frequentist
estimation task is accomplished via Expectation-Maximization
algorithms, integrating data augmentation strategies to recover the
unobserved heterogeneity and the missing ranks. The package also
provides functionalities for uncertainty quantification of the
parameter estimates, via diverse bootstrap methods and asymptotic
confidence intervals. Generic methods for S3 class objects are
constructed for more effectively managing the output of the main
routines. The usefulness of the package and its computational
performance compared with competing software is illustrated via
applications to both simulated and original real ranking datasets.</p></p>
</div>

<div class="d-byline">
  Marta Crispino  (Department of Economics, Statistics and Research,Bank of Italy Rome,
Italy)
  
,   Cristina Mollica  (Department of Statistical Sciences, Sapienza University of Rome)
  
,   Lucia Modugno  (Department of Economics, Statistics and Research, Bank of Italy)
  
<br/>2025-09-25
</div>

<div class="d-article">
<div class="article">
<h3 data-number="1" id="introduction"><span class="header-section-number">1</span> Introduction</h3>
<p>Ranking data play a pivotal role in numerous research and practical
domains, where the focus is on comparing and ordering a set of <span class="math inline">\(n\)</span> items
according to personal preferences or other relevant criteria. From
market surveys to sports competitions, from academic assessments to
online recommendation systems, rankings are ubiquitous in modern society
to capture human choice behaviors or, more generally, ordinal comparison
processes in various contexts.</p>
<p>Ranking data analysis has attracted significant attention, as evidenced
by the extensive literature on the subject <span class="citation" data-cites="critchlow91probability Marden1995">(see <a href="#ref-critchlow91probability" role="doc-biblioref">Critchlow et al. 1991</a>; <a href="#ref-Marden1995" role="doc-biblioref">Marden 1995</a> for fundamental reviews)</span> and by the
development of a broad spectrum of probabilistic models designed to
capture meaningful choice patterns and quantify estimation uncertainty.
Traditionally, four main classes of parametric models have been
identified, each representing a distinct ranking generative process. The
first category, order statistics models (OSs), is originally attributed
to <span class="citation" data-cites="thurstone27law">(<a href="#ref-thurstone27law" role="doc-biblioref">Thurstone 1927</a>)</span> and conceptualizes rankings as arising from the
ordering of latent item utilities. The second, paired comparison models,
is exemplified by the Bradley-Terry model (BT) proposed by
<span class="citation" data-cites="bradley1952rank">Bradley and Terry (<a href="#ref-bradley1952rank" role="doc-biblioref">1952</a>)</span> and is based on the possibility to decompose a ranking
sequence into the corresponding set of pairwise comparisons. The third
category, stagewise models, breaks the ranking process into sequential
stages and is well represented by the popular Plackett-Luce model (PL)
introduced by <span class="citation" data-cites="Luce1959">(<a href="#ref-Luce1959" role="doc-biblioref">Luce 1959</a>)</span> and <span class="citation" data-cites="Plackett1975">(<a href="#ref-Plackett1975" role="doc-biblioref">Plackett 1975</a>)</span>. Finally, distance-based
models, often referred to as <em>Mallows models</em> (MMs), trace their origins
to the seminal work by <span class="citation" data-cites="Mallows1957">Mallows (<a href="#ref-Mallows1957" role="doc-biblioref">1957</a>)</span>. In this paper, we focus on the last
class, which provides an ideal option for applications where a
meaningful consensus ranking can be identified in the sample and,
consequently, offers a valuable parametric tool for rank aggregation
tasks <span class="citation" data-cites="Marden1995">(<a href="#ref-Marden1995" role="doc-biblioref">Marden 1995</a>)</span>. For further insights into probabilistic ranking
models and their unique characteristics, that can support the critical
choice of suitable parametric families for specific real contexts, the
reader is referred to <span class="citation" data-cites="Liu2019">Liu et al. (<a href="#ref-Liu2019" role="doc-biblioref">2019</a>)</span> and <span class="citation" data-cites="AlvoYu2014">Alvo and Yu (<a href="#ref-AlvoYu2014" role="doc-biblioref">2014</a>)</span>.</p>
<p>The MM is based on the assumption that a modal consensus ranking of the
<span class="math inline">\(n\)</span> items exists in the population, effectively capturing the collective
preferences. Under this framework, the likelihood of observing any
particular ranking decreases as its distance from the consensus
increases. While the distance measure in the MM induces distinct
probabilistic models, it only needs to satisfy minimal properties. This
simplicity offers researchers remarkable flexibility to choose the
distance that best fits their scientific context. For example, Kendall
and Cayley distances are well suited for sorting problems, Hamming works
well in coding theory, and Spearman distance is particularly suitable
for applications involving human preferences or social choice
<span class="citation" data-cites="Diaconis1988">(<a href="#ref-Diaconis1988" role="doc-biblioref">Diaconis 1988</a>)</span>. Traditionally, the choice of the distance in the MM was
mainly driven by computational considerations, specifically the
availability of a closed-form expression for the model normalizing
constant (or <em>partition function</em>). This favored the use of Kendall,
Cayley, and Hamming distances, while the Spearman distance has been
relatively underexplored due to its perceived intractability, despite
its relevance in preference domains. However, <span class="citation" data-cites="crispino23efficient">Crispino et al. (<a href="#ref-crispino23efficient" role="doc-biblioref">2023</a>)</span>
recently demonstrated that the Spearman distance is a metric that
combines both computational feasibility and interpretability. By
leveraging the unique properties of the Spearman distance, and by means
of a novel approximation of the model partition function, the authors
addressed the critical inferential challenges that historically limited
its application. Their approach enabled the development of an efficient
strategy to fit the MM with Spearman distance (MMS) for datasets with
arbitrary forms of partial rankings. Moreover, they extended the model
to finite mixtures, allowing the capture of possible unobserved sample
heterogeneity.</p>
<p>Clustering ranking data to detect and characterize groups with similar
preferences has long been a major motivation for extending traditional
methods beyond their basic forms. This practical need is reflected in
the fact that nearly all R packages dedicated to ranking
analysis include clustering methods. From a methodological perspective,
the clustering problem has been tackled using both model-based
strategies and machine learning approaches. For example, the <strong>PLMIX</strong>
package <span class="citation" data-cites="mollica2020plmix">(<a href="#ref-mollica2020plmix" role="doc-biblioref">Mollica and Tardella 2020</a>)</span> fits finite PL mixtures for partial top
rankings within the Bayesian framework <span class="citation" data-cites="mollica2017bayesian">(<a href="#ref-mollica2017bayesian" role="doc-biblioref">Mollica and Tardella 2017</a>)</span>, which
notably recovers the maximum likelihood estimation (MLE) described in
<span class="citation" data-cites="gormley2006analysis">(<a href="#ref-gormley2006analysis" role="doc-biblioref">Gormley and Murphy 2006</a>)</span> as a special case when a noninformative prior is
specified. For the same parametric class, the <strong>PlackettLuce</strong> package
<span class="citation" data-cites="turner2020">(<a href="#ref-turner2020" role="doc-biblioref">Turner et al. 2020</a>)</span> implements MLE procedures for generalizations of the PL
model that are capable of handling partial and tied rankings, as well as
including covariates to achieve model-based partitioning via PL trees.
Concerning OSs, the <strong>StatRank</strong> package addresses the estimation of
finite mixture generalizations from both full and partial rankings
through the generalized method of moments <span class="citation" data-cites="soufiani">(<a href="#ref-soufiani" role="doc-biblioref">Soufiani and Chen 2015</a>)</span>. Additionally, the
R package <strong>Rankcluster</strong> <span class="citation" data-cites="Rankcluster">(<a href="#ref-Rankcluster" role="doc-biblioref">Jacques et al. 2014</a>)</span>, offers an
innovative model-based clustering approach through mixtures of Insertion
Sort Rank data models <span class="citation" data-cites="Jacques2014">(<a href="#ref-Jacques2014" role="doc-biblioref">Jacques and Biernacki 2014</a>)</span>, which is able to handle partial
rankings with arbitrary patterns of incompleteness and, if needed, with
multivariate (hierarchical) structures. An additional contribution to
rankings with missing data is provided by the <strong>prefmod</strong> package
<span class="citation" data-cites="prefmod2012">(<a href="#ref-prefmod2012" role="doc-biblioref">Hatzinger and Dittrich 2012</a>)</span>, which primarily analyzes preference data in the form of
paired comparisons, hence also rankings as a by-product, by using the BT
and extensions thereof to accommodate ties, subject- and item-specific
covariates, as well as partial observations with different censoring
forms and missingness processes. However, the extension proposed in
<span class="citation" data-cites="prefmod2012">Hatzinger and Dittrich (<a href="#ref-prefmod2012" role="doc-biblioref">2012</a>)</span> for clustering heterogeneous data relies on the
introduction of non-parametric random-effects models that, in the case
of rankings, are implemented only for completely-observed sequences
<span class="citation" data-cites="prefmod.package">(<a href="#ref-prefmod.package" role="doc-biblioref">Hatzinger and Maier 2023</a>)</span>.</p>
<p>Regarding the availability of software which is more related to our
proposal, one can first notice that only a few packages of the
Comprehensive R Archive Network (CRAN) implement MMs and generalizations
thereof. <strong>BayesMallows</strong> <span class="citation" data-cites="BayesMallows">(<a href="#ref-BayesMallows" role="doc-biblioref">Sørensen et al. 2020</a>)</span> is the unique package adopting
the Bayesian perspective to perform inference for the MM and its finite
mixture extension. The flexibility of <strong>BayesMallows</strong> stands in the
wide range of supported distances (including Spearman) and ranked data
formats (complete and partial rankings, as well as pairwise
comparisons). Moreover, <strong>BayesMallows</strong> provides estimation uncertainty
by building posterior credible sets for the model parameters. Although
Bayesian inference of ranking data is effectively addressed, the
R packages adopting the frequentist perspective provide
users with less flexibility and computational performance. For example,
<strong>pmr</strong> <span class="citation" data-cites="pmr_R">(<a href="#ref-pmr_R" role="doc-biblioref">Lee and Yu 2013</a>)</span> performs MLE of several ranking models, including the
MM with Kendall, Footrule, and Spearman distances. However, despite the
variety of parametric distributions, <strong>pmr</strong> does not handle partial
rankings nor mixtures. Additionally, the estimation routines require the
enumeration of all <span class="math inline">\(n!\)</span> permutations for the global search of the
consensus ranking MLE and the naïve computation of the partition
function, implying that the analysis of ranking datasets with <span class="math inline">\(n\geq 12\)</span>
items is unfeasible. The <strong>rankdist</strong> package <span class="citation" data-cites="rankdist">(<a href="#ref-rankdist" role="doc-biblioref">Qian and Yu 2019</a>)</span> fits mixtures
of MMs with various basic and weighted metrics <span class="citation" data-cites="lee2012mixtures">(<a href="#ref-lee2012mixtures" role="doc-biblioref">Lee and Yu 2012</a>)</span>,
including the Spearman, on a sample of either full or top-<span class="math inline">\(k\)</span> partial
rankings. While the implementation for the Kendall distance is highly
efficient, it shares similar drawbacks with <strong>pmr</strong>, since the partition
function of the MMS is computed by summing over all <span class="math inline">\(n!\)</span> permutations,
and the MLE of the consensus ranking is obtained through a
time-consuming local search. As a result, the procedures can be highly
demanding, especially in mixture model applications. Moreover, the
package does not support the analysis of full rankings with <span class="math inline">\(n\geq12\)</span>
items or of top-<span class="math inline">\(k\)</span> rankings with <span class="math inline">\(n\geq8\)</span> items. Other packages related
to the MM, but limited to the Kendall distance, are <strong>RMallow</strong>
<span class="citation" data-cites="rmallow">(<a href="#ref-rmallow" role="doc-biblioref">Gregory 2020</a>)</span>, which fits the MM and mixtures thereof to both full or
partially-observed ranking data, and <strong>ExtMallows</strong> <span class="citation" data-cites="extmallows">(<a href="#ref-extmallows" role="doc-biblioref">Li et al. 2018</a>)</span>, which
supports the MM and the extended MM <span class="citation" data-cites="EMMjasa">(<a href="#ref-EMMjasa" role="doc-biblioref">Li et al. 2020</a>)</span>.</p>
<p>Our review underscores that most of the available packages for
frequentist estimation of the MM focus on distances admitting a
convenient analytical expression of the model normalizing constant (more
often, the Kendall), in the attempt to simplify the estimation task.
Moreover, regardless of the chosen metric, these packages face common
limitations, particularly in handling large datasets and partial
rankings, typically restricted to top-<span class="math inline">\(k\)</span> sequences. These computational
constraints impose restrictions on the sample size, the number of items,
and the censoring patterns they can feasibly handle. Finally, the
current implementations generally lack methods for quantifying MLE
uncertainty, particularly for the consensus ranking or when a finite
mixture is assumed.</p>
<p><strong>MSmix</strong> efficiently enlarges the current suite of methods for
model-based clustering of full and partial rankings via mixture-based
analysis, by achieving several methodological and computational advances
that overcome the practical limitations experienced with the existing
packages, namely: 1) implementation of a recent normalizing constant
approximation and of the closed-form MLE of the consensus ranking, to
allow inference for the MMS even with a large number of items; 2)
analysis of arbitrary forms of incompleteness in the observed sample of
partial rankings via data augmentation strategies; 3) availability of
routines for measuring estimation uncertainty of all model parameters,
through bootstrap and asymptotic confidence intervals (CIs); 4) possible
parallel execution of the Expectation-Maximization (EM) algorithms over
multiple starting points, to better and more efficiently explore the
critical mixed-type parameter space.</p>
<p>The paper is organized as follows. In Section 2, we first provide the
methodological background of the MMS specification and its finite
mixture extension within the frequentist domain. We then detail the
approaches considered for the quantification of inferential uncertainty.
Section 3 outlines the package architecture, the main computational
aspects, and shows a comparison with existing packages. Section 4
represents the core part of the paper, illustrating the usage of the
routines included in <strong>MSmix</strong>, with applications to brand new ranking
datasets and simulations. Finally, Section 5 discusses possible
directions for future releases of our package.</p>
<h3 data-number="2" id="sec:background"><span class="header-section-number">2</span> Methodological background</h3>
<p>In this work, we consider ranking experiments where the same set of <span class="math inline">\(n\)</span>
items is presented to the assessors for comparative evaluation.
Respondents can provide either a full ranking, by completely and
uniquely attributing the <span class="math inline">\(n\)</span> positions to the items, or a partial
ranking, by assigning distinct positions only to a subset of the items
and leaving the attribution of the remaining ranks undetermined. The
novel R package <strong>MSmix</strong> implements finite mixtures of
MMS (MMS-mix) for full and partial rankings with the following key
features: i) the unranked items are treated as missing data and are
implicitly assumed to occupy the non-assigned positions; ii) missing
data may occur at any position within the observed partial ranking,
i.e., not necessarily in bottom positions as in the top-<span class="math inline">\(k\)</span> rankings;
iii) inferential procedures rely on the implementation of EM algorithms
assuming that the missing data generative process is Missing at Random
(MAR), see <span class="citation" data-cites="little2011calibrated">(<a href="#ref-little2011calibrated" role="doc-biblioref">Little 2011</a>)</span> and references therein for a general
discussion on ignorable missingness in likelihood-based methods.</p>
<h4 class="unnumbered" data-number="2.1" id="ssec:inference_complete">The Mallows model with Spearman distance and its mixture extension</h4>
<p>Let <span class="math inline">\(\boldsymbol{\mathbf{r}}=(r_1,\dots,r_n)\)</span> be a full ranking of <span class="math inline">\(n\)</span>
items, with the generic entry <span class="math inline">\(r_i\)</span> indicating the rank assigned to item
<span class="math inline">\(i\)</span>. A full ranking <span class="math inline">\(\boldsymbol{\mathbf{r}}\)</span> is a permutation of the
first <span class="math inline">\(n\)</span> integers and belongs to the finite discrete space of
permutations, <span class="math inline">\(\mathcal{P}_n\)</span>. The MMS assumes that the probability of
observing the ranking <span class="math inline">\(\boldsymbol{\mathbf{r}}\)</span> is
<span class="math display">\[
\mathbb{P}(\boldsymbol{\mathbf{r}}\,\vert \boldsymbol{\mathbf{\rho}},\theta)
=\frac{e^{-\theta\, d(\boldsymbol{\mathbf{r}},\boldsymbol{\mathbf{\rho}})}}{Z(\theta)}
\qquad\qquad\boldsymbol{\mathbf{r}}\in\mathcal{P}_n,   \]</span>
where <span class="math inline">\(\boldsymbol{\mathbf{\rho}}\in\mathcal{P}_n\)</span> is the <em>consensus
ranking</em>, <span class="math inline">\(\theta\in\mathbb{R}_0^+\)</span> is the <em>concentration</em>,
<span class="math inline">\(d(\boldsymbol{\mathbf{r}},\boldsymbol{\mathbf{\rho}})=\sum_{i=1}^n(r_i-\rho_i)^2\)</span>
is the Spearman distance, and
<span class="math inline">\(Z(\theta)=\sum_{\boldsymbol{\mathbf{r}} \in \mathcal{P}_{n}} e^{-\theta\, d(\boldsymbol{\mathbf{r}},\boldsymbol{\mathbf{e}})}\)</span>,
with <span class="math inline">\(\boldsymbol{\mathbf{e}}=(1, 2, ..., n)\)</span>, is the normalizing
constant.</p>
<p>Let
<span class="math inline">\(\underline{\boldsymbol{\mathbf{r}}}=\{\boldsymbol{\mathbf{r_1}},\dots,\boldsymbol{\mathbf{r_N\}}}\)</span>
be a random sample of <span class="math inline">\(N\)</span> full rankings drawn from the MMS and <span class="math inline">\(N_l\)</span> be
the frequency of the <span class="math inline">\(l\)</span>-th distinct observed ranked sequence
<span class="math inline">\(\boldsymbol{\mathbf{r_l}}\)</span>, such that <span class="math inline">\(\sum_{l=1}^L N_l=N\)</span>. As shown in
<span class="citation" data-cites="crispino23efficient">(<a href="#ref-crispino23efficient" role="doc-biblioref">Crispino et al. 2023</a>)</span>, the observed-data log-likelihood can be written
as follows
<span class="math display">\[\begin{split}
\ell(\boldsymbol{\mathbf{\rho}},\theta\vert\underline{\boldsymbol{\mathbf{r}}})
=-N\left(\log{Z(\theta)}+2\theta\left(c_n-\boldsymbol{\mathbf{\rho^T}}{\boldsymbol{\mathbf{\bar r}}}\right)\right),
\end{split}\]</span>
where <span class="math inline">\(c_n=n(n+1)(2n+1)/6\)</span>, the symbol <span class="math inline">\(^T\)</span> denotes the transposition
(row vector),
<span class="math inline">\({\boldsymbol{\mathbf{\bar{r}}}}=(\bar{r}_1,\ldots,\bar{r}_n)\)</span> is the
sample mean rank vector whose <span class="math inline">\(i\)</span>-th entry is
<span class="math inline">\(\bar{r}_i=\frac{1}{N}\sum_{l=1}^LN_lr_{li}\)</span>, and
<span class="math inline">\(\boldsymbol{\mathbf{\rho}}^T{\boldsymbol{\mathbf{\bar{r}}}}=\sum_{i=1}^n\rho_i\bar{r}_i\)</span>
is the scalar product. The MLE of the consensus ranking is given by the
ranking arising from ordering the items according to their sample
average rank,
<span class="math display">\[\hat{\boldsymbol{\mathbf{\rho}}}=(\hat\rho_1,\ldots,\hat\rho_i,\ldots,\hat\rho_n)\quad\text{with}\quad\hat\rho_i=\text{rank}(\bar{\boldsymbol{\mathbf{r}}})_i \,.\]</span></p>
<p>The MLE <span class="math inline">\(\hat\theta\)</span> of the concentration parameter is the value
equating the expected Spearman distance under the MMS,
<span class="math inline">\(\mathbb{E}_\theta(D)\)</span>, to the sample average Spearman distance
<span class="math inline">\(\overline{d}=\frac{1}{N}\sum_{l=1}^LN_ld(\boldsymbol{\mathbf{r}}_l,\hat{\boldsymbol{\mathbf{\rho}}})\)</span>.
The root of this equation can be found numerically, provided that one
can evaluate the expected Spearman distance, given by
<span class="math display">\[\mathbb{E}_{\theta}[D] = \frac{\sum_{\boldsymbol{\mathbf{r}} \in \mathcal{P}_{n}} d(\boldsymbol{\mathbf{r}},\boldsymbol{\mathbf{e}}) e^{-\theta\, d(\boldsymbol{\mathbf{r}},\boldsymbol{\mathbf{e}})}}{Z(\theta)}=
\frac{\sum_{d\in\mathcal{D}_n}dN_d \,e^{-d\theta}}{\sum_{d\in\mathcal{D}_n}N_d \,e^{-d\theta}},\]</span>
with
<span class="math inline">\(\mathcal{D}_n=\left\{d=2h\, : \, h\in\mathbb{N}_0\text{ and } 0\leq d\leq 2\binom{n+1}{3}\right\}\)</span>
and
<span class="math inline">\(N_d=\vert\{\boldsymbol{\mathbf{r}}\in\mathcal{P}_{n}\,:\,d(\boldsymbol{\mathbf{r}},\boldsymbol{\mathbf{e}})=d\}\vert\)</span>.
The exact values of the frequencies <span class="math inline">\(N_d\)</span> are available for <span class="math inline">\(n\leq 20\)</span>
(sequence A175929 in the Online Encyclopedia of Integer Sequences). In
order to tackle inference on rankings of a larger number of items,
<span class="citation" data-cites="crispino23efficient">(<a href="#ref-crispino23efficient" role="doc-biblioref">Crispino et al. 2023</a>)</span> introduced an approximation of the Spearman
distance distribution. In <strong>MSmix</strong>, we implement their strategy, so
that when the normalizing constant and the expected Spearman distance
cannot be computed exactly, inference targets an approximation.
Algorithm <a href="#alg:full" data-reference-type="ref" data-reference="alg:full">1</a>
reported in Appendix A1 illustrates the steps described above.</p>
<p>In order to account for the unobserved sample heterogeneity typical in
real ranking data and, more generally, to increase the model
flexibility, an MMS-mix can be adopted. Under the MMS-mix, the sampling
distribution is assumed to be
<span class="math display">\[
\mathbb{P}(\boldsymbol{\mathbf{r}}|\underline{\boldsymbol{\mathbf{\rho}}},{\boldsymbol{\mathbf{\theta}}},{\boldsymbol{\mathbf{\omega}}})
=\sum_{g=1}^G\omega_g\mathbb{P}(\boldsymbol{\mathbf{r}}\,|\boldsymbol{\mathbf{\rho}}_g,\theta_g)
=\sum_{g=1}^G\omega_g\frac{e^{-2\theta_g\, \left(c_n-\boldsymbol{\mathbf{\rho}}_g^T\boldsymbol{\mathbf{r}}\right)}}{Z(\theta_g)}\qquad\qquad\boldsymbol{\mathbf{r}}\in\mathcal{P}_n,  \]</span>
with <span class="math inline">\(\omega_g\)</span> and <span class="math inline">\((\boldsymbol{\mathbf{\rho}}_g,\theta_g)\)</span> denoting
respectively the weight and the pair of MMS parameters of the <span class="math inline">\(g\)</span>-th
mixture component. <span class="citation" data-cites="MurphyMartin2003">(<a href="#ref-MurphyMartin2003" role="doc-biblioref">Murphy and Martin 2003</a>)</span> first proposed an EM algorithm to
fit such mixture models, but the more efficient version described by
<span class="citation" data-cites="crispino23efficient">(<a href="#ref-crispino23efficient" role="doc-biblioref">Crispino et al. 2023</a>)</span> is implemented in the <strong>MSmix</strong> package
(Algorithm <a href="#alg:full_mixture" data-reference-type="ref" data-reference="alg:full_mixture">2</a> in Appendix A1).</p>
<h4 class="unnumbered" data-number="2.2" id="ssec:partial">Inference on partial rankings</h4>
<p><strong>MSmix</strong> implements two schemes to draw inference from partial rankings
with arbitrary types of censoring. One is the recent proposal of
<span class="citation" data-cites="crispino23efficient">(<a href="#ref-crispino23efficient" role="doc-biblioref">Crispino et al. 2023</a>)</span>, which extends the method originally described by
<span class="citation" data-cites="beckett93maximum">(<a href="#ref-beckett93maximum" role="doc-biblioref">Beckett 1993</a>)</span> to the finite mixture framework. The key idea is to
augment each distinct partially observed ranking
<span class="math inline">\(\boldsymbol{\mathbf{r_l}}\)</span> with the corresponding set
<span class="math inline">\(\mathcal{C}(\boldsymbol{\mathbf{r_l}})\subset \mathcal{P}_n\)</span> of
compatible full rankings and then maximize the complete-data
log-likelihood
<span class="math display" id="eq:loglik-compl">\[\label{eq:loglik_compl}
\ell_c(\underline{\boldsymbol{\mathbf{\rho}}},{\boldsymbol{\mathbf{\theta}}},{\boldsymbol{\mathbf{\omega}}},\underline{\boldsymbol{\mathbf{z}}},\underline{\boldsymbol{\mathbf{r}}}^*\vert\underline{\boldsymbol{\mathbf{r}}})
=\sum_{m=1}^M\sum_{g=1}^GN_mz_{mg}\left(\log\omega_g-2\theta_g\left(c_n-{\boldsymbol{\mathbf{\rho}}^T_g}\boldsymbol{\mathbf{r}}^*_m\right)-\log Z(\theta_g)\right),   \tag{1}\]</span>
where <span class="math inline">\(\boldsymbol{\mathbf{r}}^*_m\)</span> is a generic full ranking belonging
to <span class="math inline">\(\mathcal{C}(\boldsymbol{\mathbf{r_l}})\)</span>, <span class="math inline">\(N_m\)</span> is its latent
frequency,
<span class="math inline">\(\sum_{m=1}^MN_m=\vert\cup_{l=1}^L\mathcal{C}(\boldsymbol{\mathbf{r_l}})\vert\)</span>,
and <span class="math inline">\(\boldsymbol{\mathbf{z_m}} = (z_{m1},\dots, z_{mG})\)</span> is its latent
group membership. The algorithm to maximize <a href="#eq:loglik-compl">(1)</a> is
outlined in Algorithm <a href="#alg:partial_mixture" data-reference-type="ref" data-reference="alg:partial_mixture">3</a> in Appendix A1.</p>
<p>Algorithm <a href="#alg:partial_mixture" data-reference-type="ref" data-reference="alg:partial_mixture">3</a> requires the computationally intensive
construction and iterative computations on the sets
<span class="math inline">\(\mathcal{C}(\boldsymbol{\mathbf{r_l}})\)</span> associated to each partial
observation. This typically demands a lot of memory, especially in the
case of many censored positions (greater than 10, say) and large sample
sizes. To address this issue, in <strong>MSmix</strong> we propose the use of a
second scheme to draw inference on partial rankings, that uses a Monte
Carlo (MC) step in place of the complete augmentation, giving rise to a
MCEM-type algorithm <span class="citation" data-cites="wei_tanner">(<a href="#ref-wei_tanner" role="doc-biblioref">Wei and Tanner 1990</a>)</span>. Let <span class="math inline">\(\kappa &gt; 0\)</span> be a tuning constant
and <span class="math inline">\(\mathcal{I}_{s}\subset \{1,2,\dots,n\}\)</span> be the subset of items
actually ranked in the observed partial ranking
<span class="math inline">\(\boldsymbol{\mathbf{r}}_s\)</span>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> The core idea is to iteratively
complete the missing ranks by sampling from the postulated MMS-mix
conditionally on the current values of the parameters. Specifically, the
MC step is designed as follows:</p>
<dl>
<dt>MC step:</dt>
<dd>
<p>for <span class="math inline">\(s=1,\dots,N\)</span>, simulate
<span class="math display" id="eq:mcem1">\[\begin{aligned}
\tilde{\boldsymbol{\mathbf{z}}}_s\,\vert\,\hat{\boldsymbol{\mathbf{z}}}_s&amp;\sim\text{Multinom}\big(1,(\hat z_{s1},\dots,\hat z_{sG})\big) \label{eq:mcem1}\\
\end{aligned}   \tag{2}\]</span></p>
<p><span class="math display" id="eq:mcem1bis">\[\begin{aligned}
\tilde{\boldsymbol{\mathbf{r}}}_s\,\vert\,\underline{\boldsymbol{\mathbf{\rho}}},{\boldsymbol{\mathbf{\theta}}},\tilde{\boldsymbol{\mathbf{z}}}_s&amp;\sim\sum_{g=1}^G\tilde{z}_{sg}\mathbb{P}\left(\boldsymbol{\mathbf{r}}|\boldsymbol{\mathbf{\rho}}_{g},\kappa\theta_{g}\right)
\label{eq:mcem1bis}
\end{aligned}   \tag{3}\]</span></p>
<p>and complete the partial ranking <span class="math inline">\(\boldsymbol{\mathbf{r_s}}\)</span> with
the full sequence
<span class="math inline">\(\boldsymbol{\mathbf{r}}^*_s=(r^*_{s1},\dots,r^*_{sn})\)</span> such that
<span class="math inline">\(r^*_{si}=r_{si}\)</span> for <span class="math inline">\(i\in\mathcal{I}_s\)</span> whereas, for
<span class="math inline">\(i\notin\mathcal{I}_s\)</span>, the positions must be assigned to the items
so that their relative ranks match those in
<span class="math inline">\(\tilde{\boldsymbol{\mathbf{r}}}_s\)</span>.</p>
</dd>
</dl>
<p>The tuning constant in <a href="#eq:mcem1bis">(3)</a> serves to possibly increase
the variability (for <span class="math inline">\(0&lt;\kappa&lt;1\)</span>) or the concentration (for
<span class="math inline">\(\kappa &gt;1\)</span>) of the sampled rankings around the current consensus
ranking. The MCEM scheme is detailed in Algorithm
<a href="#alg:partial_mcem" data-reference-type="ref" data-reference="alg:partial_mcem">4</a> in Appendix A1.</p>
<h4 class="unnumbered" data-number="2.3" id="ssec:uncertainty">Uncertainty quantification</h4>
<p>To quantify estimation uncertainty, we constructed confidence sets using
both asymptotic likelihood theory and bootstrap procedures.</p>
<p>Concerning the former approach, <span class="citation" data-cites="critchlow85metric">(<a href="#ref-critchlow85metric" role="doc-biblioref">Critchlow 1985</a>)</span> showed that,
although the MMS-mix model is not regular due to the presence of the
discrete component <span class="math inline">\(\mathcal{P}_n\)</span> in the parameter space, the
likelihood asymptotically behaves as if the consensus ranking parameters
were known <span class="citation" data-cites="Marden1995">(<a href="#ref-Marden1995" role="doc-biblioref">Marden 1995</a>)</span>. This result justifies the construction of CIs
based on the asymptotic likelihood theory for the continuous parameters
of the MMS-mix. In particular, we adopt the methodology described in
<span class="citation" data-cites="mclachan2000">Mclachlan and Peel (<a href="#ref-mclachan2000" role="doc-biblioref">2000</a>)</span>, which allows us to derive the standard errors from the
output of the EM algorithm without an additional computational burden.</p>
<p>Since asymptotic CIs rely on large sample approximations, their validity
depends on having a sufficiently large sample size. This is especially
crucial in mixture models, where the required sample size must be very
large <span class="citation" data-cites="mclachan2000">(<a href="#ref-mclachan2000" role="doc-biblioref">Mclachlan and Peel 2000</a>)</span>. Therefore, we also employ a non-parametric
bootstrap approach <span class="citation" data-cites="efron82boot">(<a href="#ref-efron82boot" role="doc-biblioref">Efron 1982</a>)</span>. Specifically, for <span class="math inline">\(b=1,\dots,B\)</span>, we
draw with replacement a sample
<span class="math inline">\(\underline{\boldsymbol{\mathbf{r}}}^{(b)} =\{\boldsymbol{\mathbf{r_1^{(b)}}},\dots,\boldsymbol{\mathbf{r_N^{(b)}}}\}\)</span>
from the observed data <span class="math inline">\(\underline{\boldsymbol{\mathbf{r}}}\)</span>, and then
compute the MLEs <span class="math inline">\(\hat{\boldsymbol{\mathbf{\rho}}}^{(b)}\)</span> and
<span class="math inline">\(\hat{\theta}^{(b)}\)</span>.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> Then, to summarize the uncertainty on
<span class="math inline">\(\hat{\boldsymbol{\mathbf{\rho}}}\)</span>, we construct itemwise CIs, providing
plausible sets of ranks separately for each item. To guarantee narrower
intervals as well as a proper account of possible multimodality, these
are obtained as highest probability regions of the <span class="math inline">\(n\)</span> bootstrap
first-order marginals, that is the sets of most likely ranks for each
item at the given <span class="math inline">\(100(1-\alpha)\%\)</span> level of confidence. We also provide
a way to visualize the variability of the bootstrap MLEs through a
heatmap of the corresponding first-order marginals, that is, the
<span class="math inline">\(n\times n\)</span> matrix whose <span class="math inline">\((i,j)-\)</span>th element is given by
<span class="math inline">\(\frac{1}{B}\sum_{b=1}^{B} \mathbb{I}_{[\hat{\rho}^{(b)}_i=j]}\)</span>. For the
continuous concentration parameter, the bounds of the <span class="math inline">\(100(1-\alpha)\%\)</span>
CIs are determined as the quantiles at level <span class="math inline">\(\alpha/2\)</span> and
<span class="math inline">\((1 - \alpha/2)\)</span> of the MLE bootstrap sample.</p>
<p>In the presence of multiple mixture components (<span class="math inline">\(G&gt;1\)</span>), the bootstrap
CIs of the component-specific parameters are determined using the
non-parametric bootstrap method applied on each subsample of rankings
allocated to the <span class="math inline">\(G\)</span> clusters <span class="citation" data-cites="taushanov2019bootstrap">(<a href="#ref-taushanov2019bootstrap" role="doc-biblioref">Taushanov and Berchtold 2019</a>)</span>. We considered
two approaches to perform this allocation: i) the deterministic <em>Maximum
A Posteriori</em> (MAP) classification (<em>separated method</em>) or ii) a
simulated classification at each iteration <span class="math inline">\(b\)</span> from a multinomial
distribution with the estimated posterior membership probabilities
<span class="math inline">\(\underline{\hat{\boldsymbol{\mathbf{z}}}}\)</span> (<em>soft method</em>). The key
difference between the two methods is that the separated one ignores the
uncertainty in cluster assignment, hence, it does not return CIs for the
mixture weights and, in general, leads to narrower CIs for the
component-specific parameters. In contrast, the soft method accounts for
this uncertainty, allowing the construction of intervals for the mixture
weights and providing more conservative CIs.</p>
<h3 data-number="3" id="sec:package_arch"><span class="header-section-number">3</span> Package architecture and implementation</h3>
<p>The <strong>MSmix</strong> package is available on the CRAN at
<a href="https://cran.r-project.org/web/packages/MSmix" class="uri">https://cran.r-project.org/web/packages/MSmix</a>. The software is mainly
written in R language, but several strategies have been
designed to effectively address the computational challenges, especially
related to the analysis of large samples of partial rankings with a wide
set of alternatives. The key approaches adopted to limit execution time
and memory load are described below.</p>
<ul>
<li><p>Even though the input ranking dataset is required in non-aggregated
form, as detailed in Section 4.1, most of the proposed inferential
algorithms first determine the frequency distribution of the
observations, and then work at aggregated level. This step reduces
data volume and, consequently, the overall computational burden.</p></li>
<li><p>For very large <span class="math inline">\(n\)</span>, the approximate Spearman distance distribution
is evaluated over a predefined grid of distance values. This
approach prevents the computation of frequencies <span class="math inline">\(N_d\)</span> from becoming
numerically intractable or prohibitive, both in terms of
computational time and memory allocation.</p></li>
<li><p>The ranking spaces <span class="math inline">\(\mathcal{P}_n\)</span> for <span class="math inline">\(n\leq 11\)</span>, needed for the
data augmentation of partial rankings in Algorithm
<a href="#alg:partial_mixture" data-reference-type="ref" data-reference="alg:partial_mixture">3</a>, are internally stored in the
package and available for offline use.</p></li>
<li><p><strong>MSmix</strong> is one of the few R packages for ranking
data which includes the parallelization option of the iterative
estimation procedures over multiple initializations. This is crucial
to guarantee a good parameter space exploration and convergence
achievement at significantly reduced costs in terms of execution
time.</p></li>
<li><p>The implementation of some critical steps is optimized with a call
to functions coded in the <span class="sans-serif">C++</span> language, such as the
essential computation of the Spearman distance.</p></li>
</ul>
<p>According to their specific task, the objects contained in <strong>MSmix</strong> can
be grouped into five main categories, namely</p>
<dl>
<dt>Ranking data functions:</dt>
<dd>
<p>objects denoted with the prefix <code>"data_"</code> that allow to apply
several transformations or summaries to the ranking data.</p>
</dd>
<dt>Model functions:</dt>
<dd>
<p>all the routines aimed at performing an MMS-mix analysis.</p>
</dd>
<dt>Ranking datasets:</dt>
<dd>
<p>objects of class <code>"data.frame"</code> denoted with the prefix <code>"ranks_"</code>,
which collect the observed rankings in the first <span class="math inline">\(n\)</span> columns and
possible covariates. Most of them are original datasets never
analyzed earlier in the literature.</p>
</dd>
<dt>Spearman distance functions:</dt>
<dd>
<p>a series of routines related to the Spearman distance computation
and its distributional properties.</p>
</dd>
<dt>S3 class methods:</dt>
<dd>
<p>generic functions for the S3 class objects associated with the main
routines.</p>
</dd>
</dl>
<p>In Section 4, we extensively describe the usage of the above objects
through applications on simulated and real-world data.</p>
<h4 class="unnumbered" data-number="3.1" id="performance-benchmarking">Performance benchmarking</h4>
<p>The algorithms developed in <strong>MSmix</strong> result in impressive gains in
terms of overall efficiency compared to the few existing
R packages for the frequentist analysis of ranking data
with the MMS, that is, <strong>pmr</strong> and <strong>rankdist</strong>. Their general
characteristics are outlined in Table <a href="#tab:T1" data-reference-type="ref" data-reference="tab:compare">1</a>, highlighting the greater flexibility of
<strong>MSmix</strong> to handle different forms of partial rankings in a finite
mixture framework.</p>
<div id="tab:compare">
<table style="width:99%;">
<caption><span id="tab:T1">Table 1: </span> Characteristics of the existing R
packages for the MLE of MMS mixtures.</caption>
<colgroup>
<col style="width: 8%" />
<col style="width: 15%" />
<col style="width: 15%" />
<col style="width: 15%" />
<col style="width: 15%" />
<col style="width: 15%" />
<col style="width: 15%" />
</colgroup>
<tbody>
<tr class="odd">
<td></td>
<td style="text-align: center;"><strong>Full rankings</strong></td>
<td></td>
<td style="text-align: center;"><strong>Top partial</strong></td>
<td></td>
<td style="text-align: center;"><strong>Arbitrary partial</strong></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td style="text-align: center;"><span class="math inline">\(G=1\)</span></td>
<td><span class="math inline">\(G&gt;1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(G=1\)</span></td>
<td><span class="math inline">\(G&gt;1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(G=1\)</span></td>
<td><span class="math inline">\(G&gt;1\)</span></td>
</tr>
<tr class="odd">
<td><strong>pmr</strong></td>
<td style="text-align: center;"><span style="color: green">✓</span></td>
<td><span style="color: red">✗</span></td>
<td style="text-align: center;"><span style="color: red">✗</span></td>
<td><span style="color: red">✗</span></td>
<td style="text-align: center;"><span style="color: red">✗</span></td>
<td><span style="color: red">✗</span></td>
</tr>
<tr class="even">
<td><strong>rankdist</strong></td>
<td style="text-align: center;"><span style="color: green">✓</span></td>
<td><span style="color: green">✓</span></td>
<td style="text-align: center;"><span style="color: green">✓</span></td>
<td><span style="color: green">✓</span></td>
<td style="text-align: center;"><span style="color: red">✗</span></td>
<td><span style="color: red">✗</span></td>
</tr>
<tr class="odd">
<td><strong>MSmix</strong></td>
<td style="text-align: center;"><span style="color: green">✓</span></td>
<td><span style="color: green">✓</span></td>
<td style="text-align: center;"><span style="color: green">✓</span></td>
<td><span style="color: green">✓</span></td>
<td style="text-align: center;"><span style="color: green">✓</span></td>
<td><span style="color: green">✓</span></td>
</tr>
</tbody>
</table>
</div>
<p>Table <a href="#tab:T2" data-reference-type="ref" data-reference="tab:comp1">2</a> reports
the execution times for an experiment with full rankings and <span class="math inline">\(G=1\)</span>,
representing the only case supported by all the three packages.
Specifically, we simulated <span class="math inline">\(N=100\)</span> full rankings from the MMS with
increasing number of items <span class="math inline">\(n\)</span> and then fitted the true model. The
comparison shows that <strong>MSmix</strong> outperforms the other packages in all
scenarios and its remarkable speed seems almost not to be impacted by
<span class="math inline">\(n\)</span>, at least up to <span class="math inline">\(n=20\)</span>. This happens because, for the homogeneous
case, <strong>MSmix</strong> exploits the theoretical properties of the Spearman
distance and conveniently implements the MLEs as a one-step procedure,
without the need to iterate (nor to locally search).</p>
<div id="tab:comp1">
<table style="width:97%;">
<caption><span id="tab:T2">Table 2: </span> Comparison among <strong>MSmix</strong>, <strong>rankdist</strong> and <strong>pmr</strong>
in terms of computational times (seconds) to fit the basic MMS (<span class="math inline">\(G=1\)</span>)
on full rankings with increasing number of items. Note: <em>not run</em>
indicates that we did not perform the fit because of the excessive
computing time and the symbol <span style="color: red">✗</span> indicates that
the fit is not supported.</caption>
<colgroup>
<col style="width: 14%" />
<col style="width: 15%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: center;"><strong>MSmix</strong></th>
<th style="text-align: center;"><strong>rankdist</strong></th>
<th style="text-align: center;"><strong>pmr</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(n = 5\)</span></td>
<td style="text-align: center;">0.004</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.263</td>
</tr>
<tr class="even">
<td><span class="math inline">\(n = 6\)</span></td>
<td style="text-align: center;">0.004</td>
<td style="text-align: center;">0.028</td>
<td style="text-align: center;">3.955</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(n = 7\)</span></td>
<td style="text-align: center;">0.003</td>
<td style="text-align: center;">0.276</td>
<td style="text-align: center;">137.781</td>
</tr>
<tr class="even">
<td><span class="math inline">\(n = 8\)</span></td>
<td style="text-align: center;">0.004</td>
<td style="text-align: center;">2.748</td>
<td style="text-align: center;"><em>not run</em></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(n = 9\)</span></td>
<td style="text-align: center;">0.004</td>
<td style="text-align: center;">32.1</td>
<td style="text-align: center;"><em>not run</em></td>
</tr>
<tr class="even">
<td><span class="math inline">\(n = 10\)</span></td>
<td style="text-align: center;">0.004</td>
<td style="text-align: center;">538.71</td>
<td style="text-align: center;"><em>not run</em></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(n = 15\)</span></td>
<td style="text-align: center;">0.004</td>
<td style="text-align: center;"><span style="color: red">✗</span></td>
<td style="text-align: center;"><span style="color: red">✗</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(n = 20\)</span></td>
<td style="text-align: center;">0.004</td>
<td style="text-align: center;"><span style="color: red">✗</span></td>
<td style="text-align: center;"><span style="color: red">✗</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(n = 50\)</span></td>
<td style="text-align: center;">0.031</td>
<td style="text-align: center;"><span style="color: red">✗</span></td>
<td style="text-align: center;"><span style="color: red">✗</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(n=100\)</span></td>
<td style="text-align: center;">0.485</td>
<td style="text-align: center;"><span style="color: red">✗</span></td>
<td style="text-align: center;"><span style="color: red">✗</span></td>
</tr>
</tbody>
</table>
</div>
<p>The results of two additional experiments, both supported exclusively by
<strong>MSmix</strong> and <strong>rankdist</strong>, are reported in Table
<a href="#tab:T3" data-reference-type="ref" data-reference="tab:comp2">3</a>. The first
(left panel) concerns inference of a basic MMS on top partial rankings:
we simulated <span class="math inline">\(N=100\)</span> full rankings of <span class="math inline">\(n=7\)</span> items from the MMS, and then
censor them with decreasing number of top-<span class="math inline">\(k\)</span> ranked items. The second
(right panel) concerns inference of MMS-mix with full rankings: we
simulated <span class="math inline">\(N=100\)</span> full rankings of increasing length <span class="math inline">\(n\)</span> from the
MMS-mix with <span class="math inline">\(G=2\)</span> components, and then estimated the true model. Again,
<strong>MSmix</strong> turns out to be particularly fast and more efficient when
compared to the competing package. Moreover, the choice of <span class="math inline">\(n=7\)</span> is
motivated by the fact that <strong>rankdist</strong> only works with a maximum of 7
items in the case partial rankings are considered.</p>
<p>The comparative analysis of this section was performed using
R version 4.4.0 on a macOS Monterey 12.7.3 (2.5GHz Intel
Core i7 quad-core). For further results and discussion on the
computational performance of the <strong>MSmix</strong> package, see Appendix A2.</p>
<div id="tab:comp2">
<table style="width:98%;">
<caption><span id="tab:T3">Table 3: </span> Comparison between <strong>Msmix</strong> and <strong>rankdist</strong> to fit a
basic MMS on partial top<span class="math inline">\(-k\)</span> rankings (left) and a MMS-mix with <span class="math inline">\(G=2\)</span>
components on full rankings (right). Computational times (in seconds)
averaged over 100 independent replications.</caption>
<colgroup>
<col style="width: 9%" />
<col style="width: 14%" />
<col style="width: 17%" />
<col style="width: 9%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;"><strong>MSmix</strong></th>
<th style="text-align: right;"><strong>rankdist</strong></th>
<th></th>
<th></th>
<th style="text-align: center;"><strong>MSmix</strong></th>
<th style="text-align: center;"><strong>rankdist</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(k=5\)</span></td>
<td style="text-align: right;">0.029</td>
<td style="text-align: right;">0.301</td>
<td></td>
<td><span class="math inline">\(n = 5\)</span></td>
<td style="text-align: center;">0.049</td>
<td style="text-align: center;">0.089</td>
</tr>
<tr class="even">
<td><span class="math inline">\(k=4\)</span></td>
<td style="text-align: right;">0.041</td>
<td style="text-align: right;">0.321</td>
<td></td>
<td><span class="math inline">\(n = 6\)</span></td>
<td style="text-align: center;">0.035</td>
<td style="text-align: center;">0.185</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(k=3\)</span></td>
<td style="text-align: right;">0.064</td>
<td style="text-align: right;">0.386</td>
<td></td>
<td><span class="math inline">\(n = 7\)</span></td>
<td style="text-align: center;">0.023</td>
<td style="text-align: center;">0.262</td>
</tr>
<tr class="even">
<td><span class="math inline">\(k=2\)</span></td>
<td style="text-align: right;">0.103</td>
<td style="text-align: right;">0.543</td>
<td></td>
<td><span class="math inline">\(n = 8\)</span></td>
<td style="text-align: center;">0.024</td>
<td style="text-align: center;">0.411</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(k=1\)</span></td>
<td style="text-align: right;">0.122</td>
<td style="text-align: right;">0.673</td>
<td></td>
<td><span class="math inline">\(n = 9\)</span></td>
<td style="text-align: center;">0.018</td>
<td style="text-align: center;">0.612</td>
</tr>
</tbody>
</table>
</div>
<h3 data-number="4" id="sec:format"><span class="header-section-number">4</span> Using the <strong>MSmix</strong> package</h3>
<h4 class="unnumbered" data-number="4.1" id="subsec:format">Data format</h4>
<p>The knowledge of the data format adopted in a package is, especially for
ranked sequences, crucial before safely conducting any ranking data
analysis. The <strong>MSmix</strong> package privileges the ranking data format,
which is a natural choice for the MM, and the non-aggregate form,
meaning that observations must be provided as an integer <span class="math inline">\(N\times n\)</span>
<code>matrix</code> or <code>data.frame</code> with each row representing individual observed
partial rankings. Missing positions must be coded as <code>NA</code>s and ties are
not allowed.</p>
<p>We start the illustration of the main functionalities of <strong>MSmix</strong> by
using a new full ranking dataset contained in the package, called
<code>ranks_antifragility</code>. This dataset, stemming from a 2021 survey on
Italian startups during the COVID-19 outbreak, collects rankings of
<span class="math inline">\(n=7\)</span> crucial antifragility features.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> Since covariates are also
included, the <span class="math inline">\(N=99\)</span> full rankings can be extracted from the first <span class="math inline">\(n=7\)</span>
columns as follows</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> n <span class="ot">&lt;-</span> <span class="dv">7</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> ranks_AF <span class="ot">&lt;-</span> ranks_antifragility[, <span class="dv">1</span><span class="sc">:</span>n]</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">str</span>(ranks_AF)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="st">&#39;data.frame&#39;</span><span class="sc">:</span>   <span class="dv">99</span> obs. of  <span class="dv">7</span> variables<span class="sc">:</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a> <span class="er">$</span> Absorption        <span class="sc">:</span> int  <span class="dv">4</span> <span class="dv">1</span> <span class="dv">3</span> <span class="dv">4</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">4</span> <span class="dv">4</span> ...</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a> <span class="sc">$</span> Redundancy        <span class="sc">:</span> int  <span class="dv">2</span> <span class="dv">4</span> <span class="dv">4</span> <span class="dv">2</span> <span class="dv">3</span> <span class="dv">1</span> <span class="dv">4</span> <span class="dv">1</span> <span class="dv">3</span> <span class="dv">3</span> ...</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a> <span class="sc">$</span> Small_stressors   <span class="sc">:</span> int  <span class="dv">1</span> <span class="dv">3</span> <span class="dv">1</span> <span class="dv">7</span> <span class="dv">4</span> <span class="dv">6</span> <span class="dv">5</span> <span class="dv">4</span> <span class="dv">6</span> <span class="dv">6</span> ...</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a> <span class="sc">$</span> Non_monotonicity  <span class="sc">:</span> int  <span class="dv">3</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">3</span> <span class="dv">2</span> <span class="dv">5</span> <span class="dv">1</span> <span class="dv">7</span> ...</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a> <span class="sc">$</span> Requisite_variety <span class="sc">:</span> int  <span class="dv">5</span> <span class="dv">7</span> <span class="dv">7</span> <span class="dv">3</span> <span class="dv">7</span> <span class="dv">7</span> <span class="dv">7</span> <span class="dv">3</span> <span class="dv">7</span> <span class="dv">2</span> ...</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a> <span class="sc">$</span> Emergence         <span class="sc">:</span> int  <span class="dv">6</span> <span class="dv">6</span> <span class="dv">6</span> <span class="dv">6</span> <span class="dv">6</span> <span class="dv">5</span> <span class="dv">6</span> <span class="dv">7</span> <span class="dv">2</span> <span class="dv">1</span> ...</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a> <span class="sc">$</span> Uncoupling        <span class="sc">:</span> int  <span class="dv">7</span> <span class="dv">5</span> <span class="dv">5</span> <span class="dv">5</span> <span class="dv">5</span> <span class="dv">4</span> <span class="dv">3</span> <span class="dv">6</span> <span class="dv">5</span> <span class="dv">5</span> ...</span></code></pre></div>
<p>To facilitate the visualization of the outputs, let us shorten the item
labels, and then see the appearance of the rankings provided by the very
first three startups.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">names</span>(ranks_AF) <span class="ot">&lt;-</span> <span class="fu">substr</span>(<span class="at">x =</span> <span class="fu">names</span>(ranks_AF), <span class="at">start =</span> <span class="dv">1</span>, <span class="at">stop =</span> <span class="dv">3</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> ranks_AF[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, ]</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  Abs Red Sma Non Req Eme Unc</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>   <span class="dv">4</span>   <span class="dv">2</span>   <span class="dv">1</span>   <span class="dv">3</span>   <span class="dv">5</span>   <span class="dv">6</span>   <span class="dv">7</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span>   <span class="dv">1</span>   <span class="dv">4</span>   <span class="dv">3</span>   <span class="dv">2</span>   <span class="dv">7</span>   <span class="dv">6</span>   <span class="dv">5</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span>   <span class="dv">3</span>   <span class="dv">4</span>   <span class="dv">1</span>   <span class="dv">2</span>   <span class="dv">7</span>   <span class="dv">6</span>   <span class="dv">5</span></span></code></pre></div>
<p>The switch to the ordering format (and vice versa) can be easily
realized with the <code>data_conversion</code> routine, that has the flexibility to
support partial sequences with arbitrary patterns of censoring. Here is
the transformation into orderings of the above three full rankings.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">data_conversion</span>(<span class="at">data =</span> ranks_AF[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, ])</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  [,<span class="dv">1</span>] [,<span class="dv">2</span>] [,<span class="dv">3</span>] [,<span class="dv">4</span>] [,<span class="dv">5</span>] [,<span class="dv">6</span>] [,<span class="dv">7</span>]</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>    <span class="dv">3</span>    <span class="dv">2</span>    <span class="dv">4</span>    <span class="dv">1</span>    <span class="dv">5</span>    <span class="dv">6</span>    <span class="dv">7</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span>    <span class="dv">1</span>    <span class="dv">4</span>    <span class="dv">3</span>    <span class="dv">2</span>    <span class="dv">7</span>    <span class="dv">6</span>    <span class="dv">5</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span>    <span class="dv">3</span>    <span class="dv">4</span>    <span class="dv">1</span>    <span class="dv">2</span>    <span class="dv">7</span>    <span class="dv">6</span>    <span class="dv">5</span></span></code></pre></div>
<h4 class="unnumbered" data-number="4.2" id="subsec:descr">Data description and manipulation</h4>
<p>Descriptive statistics and other useful sample summaries can be obtained
with the <code>data_description</code> routine that, differently from analogous
functions supplied by other R packages, can handle
partial observations with arbitrary type of censoring. The output is a
list of S3 class <code>"data_descr"</code>, whose components can be displayed with
the <code>print.data_descr</code> method. For the entire Antifragility sample, the
basic application of these commands is the following</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> data_descr_AF <span class="ot">&lt;-</span> <span class="fu">data_description</span>(<span class="at">rankings =</span> ranks_AF)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">print</span>(data_descr_AF)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>Sample size<span class="sc">:</span> <span class="dv">99</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>N. of items<span class="sc">:</span> <span class="dv">7</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>Frequency distribution of the number of ranked items<span class="sc">:</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a> <span class="dv">1</span>  <span class="dv">2</span>  <span class="dv">3</span>  <span class="dv">4</span>  <span class="dv">5</span>  <span class="dv">6</span>  <span class="dv">7</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a> <span class="dv">0</span>  <span class="dv">0</span>  <span class="dv">0</span>  <span class="dv">0</span>  <span class="dv">0</span>  <span class="dv">0</span> <span class="dv">99</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>Number of missing positions <span class="cf">for</span> each item<span class="sc">:</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>Abs Red Sma Non Req Eme Unc</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  <span class="dv">0</span>   <span class="dv">0</span>   <span class="dv">0</span>   <span class="dv">0</span>   <span class="dv">0</span>   <span class="dv">0</span>   <span class="dv">0</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>Mean rank of each item<span class="sc">:</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a> Abs  Red  Sma  Non  Req  Eme  Unc</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="fl">2.45</span> <span class="fl">3.27</span> <span class="fl">4.02</span> <span class="fl">2.71</span> <span class="fl">5.38</span> <span class="fl">5.01</span> <span class="fl">5.15</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>Borda ordering<span class="sc">:</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;Abs&quot;</span> <span class="st">&quot;Non&quot;</span> <span class="st">&quot;Red&quot;</span> <span class="st">&quot;Sma&quot;</span> <span class="st">&quot;Eme&quot;</span> <span class="st">&quot;Unc&quot;</span> <span class="st">&quot;Req&quot;</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>First<span class="sc">-</span>order marginals<span class="sc">:</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>      Abs Red Sma Non Req Eme Unc Sum</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>Rank1  <span class="dv">37</span>  <span class="dv">13</span>   <span class="dv">6</span>  <span class="dv">34</span>   <span class="dv">3</span>   <span class="dv">3</span>   <span class="dv">3</span>  <span class="dv">99</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>Rank2  <span class="dv">28</span>  <span class="dv">25</span>  <span class="dv">10</span>  <span class="dv">18</span>   <span class="dv">3</span>   <span class="dv">9</span>   <span class="dv">6</span>  <span class="dv">99</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>Rank3  <span class="dv">13</span>  <span class="dv">20</span>  <span class="dv">22</span>  <span class="dv">18</span>  <span class="dv">10</span>   <span class="dv">7</span>   <span class="dv">9</span>  <span class="dv">99</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>Rank4   <span class="dv">6</span>  <span class="dv">18</span>  <span class="dv">28</span>  <span class="dv">16</span>  <span class="dv">11</span>   <span class="dv">9</span>  <span class="dv">11</span>  <span class="dv">99</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>Rank5   <span class="dv">6</span>  <span class="dv">12</span>  <span class="dv">14</span>   <span class="dv">4</span>  <span class="dv">19</span>  <span class="dv">20</span>  <span class="dv">24</span>  <span class="dv">99</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>Rank6   <span class="dv">6</span>   <span class="dv">8</span>   <span class="dv">9</span>   <span class="dv">3</span>  <span class="dv">16</span>  <span class="dv">39</span>  <span class="dv">18</span>  <span class="dv">99</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>Rank7   <span class="dv">3</span>   <span class="dv">3</span>  <span class="dv">10</span>   <span class="dv">6</span>  <span class="dv">37</span>  <span class="dv">12</span>  <span class="dv">28</span>  <span class="dv">99</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>Sum    <span class="dv">99</span>  <span class="dv">99</span>  <span class="dv">99</span>  <span class="dv">99</span>  <span class="dv">99</span>  <span class="dv">99</span>  <span class="dv">99</span> <span class="dv">693</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>Pairwise comparison matrix<span class="sc">:</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>    Abs Red Sma Non Req Eme Unc</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>Abs   <span class="dv">0</span>  <span class="dv">67</span>  <span class="dv">80</span>  <span class="dv">52</span>  <span class="dv">86</span>  <span class="dv">83</span>  <span class="dv">82</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>Red  <span class="dv">32</span>   <span class="dv">0</span>  <span class="dv">63</span>  <span class="dv">41</span>  <span class="dv">79</span>  <span class="dv">79</span>  <span class="dv">75</span></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>Sma  <span class="dv">19</span>  <span class="dv">36</span>   <span class="dv">0</span>  <span class="dv">33</span>  <span class="dv">75</span>  <span class="dv">68</span>  <span class="dv">64</span></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>Non  <span class="dv">47</span>  <span class="dv">58</span>  <span class="dv">66</span>   <span class="dv">0</span>  <span class="dv">86</span>  <span class="dv">84</span>  <span class="dv">84</span></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>Req  <span class="dv">13</span>  <span class="dv">20</span>  <span class="dv">24</span>  <span class="dv">13</span>   <span class="dv">0</span>  <span class="dv">43</span>  <span class="dv">47</span></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>Eme  <span class="dv">16</span>  <span class="dv">20</span>  <span class="dv">31</span>  <span class="dv">15</span>  <span class="dv">56</span>   <span class="dv">0</span>  <span class="dv">59</span></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>Unc  <span class="dv">17</span>  <span class="dv">24</span>  <span class="dv">35</span>  <span class="dv">15</span>  <span class="dv">52</span>  <span class="dv">40</span>   <span class="dv">0</span></span></code></pre></div>
<p>where the two displayed matrices correspond, respectively, to the
first-order marginals, with the <span class="math inline">\((j,i)\)</span>-th entry indicating the number
of times that item <span class="math inline">\(i\)</span> is ranked in position <span class="math inline">\(j\)</span>, and the pairwise
comparison matrix, with the <span class="math inline">\((i,i&#39;)\)</span>-th entry indicating the number of
times that item <span class="math inline">\(i\)</span> is preferred to item <span class="math inline">\(i&#39;\)</span>. The function
<code>data_description</code> also includes an optional <code>subset</code> argument which
allows to summarize specific subsamples defined, for example, through a
condition on some of the available covariates. The idea is to facilitate
a preliminary exploration of possible different preference patterns
influenced, for example, by some of the observed subjects’
characteristics.</p>
<p>Finally, we created a further generic method for the class
<code>"data_descr"</code> to offer a more attractive and intuitive rendering of the
fundamental summaries, that is, the function <code>plot.data_descr</code>. This
method produces a list of five plots by relying on the fancy graphical
tools implemented in the <strong>ggplot2</strong> package <span class="citation" data-cites="ggplot">(<a href="#ref-ggplot" role="doc-biblioref">Wickham 2016</a>)</span>, namely: 1) the
barplot with the percentages of the number of ranked items in the
observed rankings, 2) the pictogram of the mean rank vector, 3) the
heatmap of the first-order marginals (either by item or by rank), 4) the
Empirical Cumulative Distribution Functions (ECDFs) of the marginal rank
distributions and 5) the bubble plot of the pairwise comparison matrix.
For the Antifragility dataset, the following code snippet illustrates
the creation of the above graphics and how to access, separately, to the
ECDFs and the bubble plot displayed in Figure
<a href="#fig:plot.data_descr" data-reference-type="ref" data-reference="fig:plot.data_descr">1</a>.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> p_descr_AF <span class="ot">&lt;-</span> <span class="fu">plot</span>(data_descr_AF)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> p_descr_AF<span class="sc">$</span><span class="fu">ecdf</span>()</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> p_descr_AF<span class="sc">$</span><span class="fu">pc</span>()</span></code></pre></div>
<figure id="fig:plot.data_descr">
<img src="figures/RJ2025_paper_plotsanti.png" style="width:100.0%" alt="graphic without alt text" />
<figcaption>Figure 1: ECDFs of the marginal rank distributions (left) and bubble
plot of the pairwise comparison matrix (right) for the Antifragility
dataset. These plots correspond, respectively, to the elements named
<code>ecdf</code> and <code>pc</code> of the output list returned by the generic method
<code>plot.data_descr</code>.</figcaption>
</figure>
<p>Concerning ranking data manipulation, <strong>MSmix</strong> provides functions
designed to switch from complete to partial sequences, with the routine
<code>data_censoring</code>, or from partial to complete sequences, with the
routines <code>data_augmentation</code> and <code>data_completion</code>. These functions are
particularly useful in simulation scenarios for evaluating the
robustness of inferential procedures in recovering the actual
data-generating mechanisms under various types and extents of censoring
and different data augmentation strategies for handling partial data.</p>
<p>With <code>data_censoring</code>, complete rankings can be converted into partial
rankings in two distinct ways. One approach obscures only the bottom
ranks to produce a top partial ranking (set <code>topk = TRUE</code>), while the
other obscures ranks at any position (set <code>topk = FALSE</code>). In both
cases, users can specify how many positions are retained for each
sequence through two schemes: (i) a deterministic method, where an
integer vector (of length <span class="math inline">\(N\)</span>) is provided to the <code>nranked</code> argument
specifying the desired number of ranks to be retained in each partial
sequence; (ii) a stochastic method, where <code>nranked = NULL</code> (default) and
a numeric vector is provided to the <code>probs</code> argument defining the
<span class="math inline">\((n-1)\)</span> probabilities associated with retaining different number of
ranks (from 1 to <span class="math inline">\(n-1\)</span>). These probabilities determine the random number
of ranks to be retained in each partial sequence after censoring.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> An
example of a deterministic top-<span class="math inline">\(k\)</span> censoring scheme is implemented below
to covert the complete Antifragility ranking data into top-3 rankings.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> N <span class="ot">&lt;-</span> <span class="fu">nrow</span>(ranks_AF)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> top3_AF <span class="ot">&lt;-</span> <span class="fu">data_censoring</span>(<span class="at">rankings =</span> ranks_AF, <span class="at">topk =</span> <span class="cn">TRUE</span>, <span class="at">nranked =</span> <span class="fu">rep</span>(<span class="dv">3</span>,N))</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> top3_AF<span class="sc">$</span>part_rankings[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>,]</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  Abs Red Sma Non Req Eme Unc</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>  <span class="cn">NA</span>   <span class="dv">2</span>   <span class="dv">1</span>   <span class="dv">3</span>  <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span>   <span class="dv">1</span>  <span class="cn">NA</span>   <span class="dv">3</span>   <span class="dv">2</span>  <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span>   <span class="dv">3</span>  <span class="cn">NA</span>   <span class="dv">1</span>   <span class="dv">2</span>  <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">table</span>(top3_AF<span class="sc">$</span>nranked)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a> <span class="dv">3</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="dv">99</span></span></code></pre></div>
<p>The output of <code>data_censoring</code> is a list with a first component, named
<code>part_rankings</code>, corresponding to the input complete data matrix
<code>rankings</code> with suitably censored (<code>NA</code>) entries, and a second
component, named <code>nranked</code>, corresponding to the vector with the number
of actually visible positions in each partial ranking.</p>
<p>An example of stochastic top-<span class="math inline">\(k\)</span> censoring scheme on the same dataset,
that will result in a random number of bottom positions obscured, can be
run as follows</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> top_AF <span class="ot">&lt;-</span> <span class="fu">data_censoring</span>(<span class="at">rankings =</span> ranks_AF, <span class="at">topk =</span> <span class="cn">TRUE</span>, <span class="at">probs =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>(n<span class="dv">-2</span>),<span class="dv">0</span>))</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> top_AF<span class="sc">$</span>part_rankings[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>,]</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  Abs Red Sma Non Req Eme Unc</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>   <span class="dv">4</span>   <span class="dv">2</span>   <span class="dv">1</span>   <span class="dv">3</span>   <span class="dv">5</span>  <span class="cn">NA</span>  <span class="cn">NA</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span>   <span class="dv">1</span>  <span class="cn">NA</span>   <span class="dv">3</span>   <span class="dv">2</span>  <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span>   <span class="dv">3</span>  <span class="cn">NA</span>   <span class="dv">1</span>   <span class="dv">2</span>  <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">table</span>(top_AF<span class="sc">$</span>nranked)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a> <span class="dv">1</span>  <span class="dv">2</span>  <span class="dv">3</span>  <span class="dv">4</span>  <span class="dv">5</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a> <span class="dv">1</span> <span class="dv">14</span> <span class="dv">16</span> <span class="dv">19</span> <span class="dv">49</span></span></code></pre></div>
<p>In this case, the vector <code>probs</code> assigns an increasing chance of
retaining a higher number of top positions, with the exception of a zero
value in the last entry, forcing the non-occurrence of full rankings
after censoring. Apart from the different setting for the <code>topk</code>
argument, applying a censoring scheme to arbitrary positions requires a
similar syntax to the top-<span class="math inline">\(k\)</span>. The main difference is that, instead of
the censoring process acting only on the bottom part of the rankings,
the positions to be censored are determined uniformly at random once the
number of ranks to be kept is specified by the user (either
deterministically or stochastically).</p>
<p>We conclude this section with an illustration of the counterpart
commands of <code>data_censoring</code> available in <strong>MSmix</strong>, which act on
partial rankings and fill in the missing positions with different
criteria. The first, called <code>data_augmentation</code>, is the key function for
estimating a MMS-mix on partial rankings via Algorithm
<a href="#alg:partial_mixture" data-reference-type="ref" data-reference="alg:partial_mixture">3</a>. Here is a toy example with only two
partial rankings characterized by different types of censoring.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> ranks_toy <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="cn">NA</span>, <span class="dv">1</span>, <span class="cn">NA</span>, <span class="dv">3</span>), <span class="fu">c</span>(<span class="cn">NA</span>, <span class="dv">4</span>, <span class="cn">NA</span>, <span class="dv">1</span>, <span class="cn">NA</span>))</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> ranks_toy</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>     [,<span class="dv">1</span>] [,<span class="dv">2</span>] [,<span class="dv">3</span>] [,<span class="dv">4</span>] [,<span class="dv">5</span>]</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>,]    <span class="dv">2</span>   <span class="cn">NA</span>    <span class="dv">1</span>   <span class="cn">NA</span>    <span class="dv">3</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>[<span class="dv">2</span>,]   <span class="cn">NA</span>    <span class="dv">4</span>   <span class="cn">NA</span>    <span class="dv">1</span>   <span class="cn">NA</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">data_augmentation</span>(<span class="at">rankings =</span> ranks_toy)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>[[<span class="dv">1</span>]]</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>     [,<span class="dv">1</span>] [,<span class="dv">2</span>] [,<span class="dv">3</span>] [,<span class="dv">4</span>] [,<span class="dv">5</span>]</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>,]    <span class="dv">2</span>    <span class="dv">4</span>    <span class="dv">1</span>    <span class="dv">5</span>    <span class="dv">3</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>[<span class="dv">2</span>,]    <span class="dv">2</span>    <span class="dv">5</span>    <span class="dv">1</span>    <span class="dv">4</span>    <span class="dv">3</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>[[<span class="dv">2</span>]]</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>     [,<span class="dv">1</span>] [,<span class="dv">2</span>] [,<span class="dv">3</span>] [,<span class="dv">4</span>] [,<span class="dv">5</span>]</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>,]    <span class="dv">2</span>    <span class="dv">4</span>    <span class="dv">3</span>    <span class="dv">1</span>    <span class="dv">5</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>[<span class="dv">2</span>,]    <span class="dv">3</span>    <span class="dv">4</span>    <span class="dv">2</span>    <span class="dv">1</span>    <span class="dv">5</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>[<span class="dv">3</span>,]    <span class="dv">3</span>    <span class="dv">4</span>    <span class="dv">5</span>    <span class="dv">1</span>    <span class="dv">2</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>[<span class="dv">4</span>,]    <span class="dv">2</span>    <span class="dv">4</span>    <span class="dv">5</span>    <span class="dv">1</span>    <span class="dv">3</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>[<span class="dv">5</span>,]    <span class="dv">5</span>    <span class="dv">4</span>    <span class="dv">2</span>    <span class="dv">1</span>    <span class="dv">3</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>[<span class="dv">6</span>,]    <span class="dv">5</span>    <span class="dv">4</span>    <span class="dv">3</span>    <span class="dv">1</span>    <span class="dv">2</span></span></code></pre></div>
<p>The output list contains the matrices of all full rankings compatible
with each partial sequence.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> We remark that, despite the name
<code>rankings</code> of the input (partially ranked) data matrix, the function
<code>data_augmentation</code> can also be applied to partial observations
expressed in ordering format. In general, it supports the data
augmentation of sequences containing at most 10 missing entries.</p>
<p>The second function, named <code>data_completion</code>, completes each partial
ranking with a single compatible full ranking. To complete the rankings
in <code>ranks_toy</code>, one needs to set the <code>ref_rho</code> argument equal to a
matrix of the same dimensions as <code>ranks_toy</code>, containing the reference
full rankings in each row. In the example below, we use the identity
permutation and its opposite as the reference sequences for completion.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">data_completion</span>(<span class="at">rankings =</span> ranks_toy, <span class="at">ref_rho =</span> <span class="fu">rbind</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="dv">5</span><span class="sc">:</span><span class="dv">1</span>))</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>     [,<span class="dv">1</span>] [,<span class="dv">2</span>] [,<span class="dv">3</span>] [,<span class="dv">4</span>] [,<span class="dv">5</span>]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>,]    <span class="dv">2</span>    <span class="dv">4</span>    <span class="dv">1</span>    <span class="dv">5</span>    <span class="dv">3</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>[<span class="dv">2</span>,]    <span class="dv">5</span>    <span class="dv">4</span>    <span class="dv">3</span>    <span class="dv">1</span>    <span class="dv">2</span></span></code></pre></div>
<p>The output is the matrix obtained by filling in the missing entries of
each partial sequence with the relative positions of the unranked items
according to the reference full ranking.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> The <code>data_completion</code>
command accommodates any type of censoring, similar to
<code>data_augmentation</code>, but without the need to enumerate all possible
orders of missing positions. Consequently, there is no upper limit on
the number of <code>NA</code> entries in the partial sequences.</p>
<h4 class="unnumbered" data-number="4.3" id="subsec:sampling">Sampling</h4>
<p>The function devoted to simulating an i.i.d. sample of full rankings
from a MMS-mix is <code>rMSmix</code>, which relies on the Metropolis-Hastings (MH)
procedure implemented in the R package <strong>BayesMallows</strong>
<span class="citation" data-cites="BayesMallows">(<a href="#ref-BayesMallows" role="doc-biblioref">Sørensen et al. 2020</a>)</span>. When <span class="math inline">\(n\leq 10\)</span>, the routine also offers the
possibility to perform exact sampling by setting the logical <code>mh</code>
argument to <code>FALSE</code>.</p>
<p>The <code>rMSmix</code> function requires the user to specify: i) the desired
number of rankings (<code>sample_size</code>), ii) the number of items (<code>n_items</code>)
and iii) the number of mixture components (<code>n_clust</code>). The mixture
parameters can be separately passed with the (optional) arguments <code>rho</code>,
<code>theta</code> and <code>weights</code>, set to <code>NULL</code> by default. If the user does not
input the above parameters, the concentrations are sampled uniformly in
the interval <span class="math inline">\((1/n^2,3/n^{3/2})\)</span>,<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> while the simulation of the
consensus parameters and the weights can be selected with the logical
argument <code>uniform</code>. The option <code>uniform = TRUE</code> consists in generating
the non-specified parameters uniformly in their support. Here is an
example where <span class="math inline">\(N=100\)</span> full rankings of <span class="math inline">\(n=8\)</span> items are exactly generated
from a 3-component MMS-mix, with assigned and equal concentrations
<span class="math inline">\(\boldsymbol{\mathbf{\theta}}=(.15,.15,.15)\)</span> and the other parameters
sampled uniformly at random.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> sam_unif <span class="ot">&lt;-</span> <span class="fu">rMSmix</span>(<span class="at">sample_size =</span> <span class="dv">100</span>, <span class="at">n_items =</span> <span class="dv">8</span>, <span class="at">n_clust =</span> <span class="dv">3</span>, <span class="at">theta =</span> <span class="fu">rep</span>(.<span class="dv">15</span>, <span class="dv">3</span>),</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>               <span class="at">uniform =</span> <span class="cn">TRUE</span>, <span class="at">mh =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p>The function <code>rMSmix</code> returns a list of five named objects: the
<span class="math inline">\(N\times n\)</span> matrix with the simulated complete rankings (<code>samples</code>), the
model parameters actually used for the simulation (<code>rho</code>, <code>theta</code> and
<code>weights</code>) and the simulated group membership labels (<code>classification</code>).
For the previous example, they can be extracted as follows</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> sam_unif<span class="sc">$</span>samples[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>,]</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>     [,<span class="dv">1</span>] [,<span class="dv">2</span>] [,<span class="dv">3</span>] [,<span class="dv">4</span>] [,<span class="dv">5</span>] [,<span class="dv">6</span>] [,<span class="dv">7</span>] [,<span class="dv">8</span>]</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>,]    <span class="dv">6</span>    <span class="dv">1</span>    <span class="dv">7</span>    <span class="dv">5</span>    <span class="dv">8</span>    <span class="dv">3</span>    <span class="dv">2</span>    <span class="dv">4</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>[<span class="dv">2</span>,]    <span class="dv">2</span>    <span class="dv">1</span>    <span class="dv">3</span>    <span class="dv">7</span>    <span class="dv">5</span>    <span class="dv">4</span>    <span class="dv">8</span>    <span class="dv">6</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>[<span class="dv">3</span>,]    <span class="dv">6</span>    <span class="dv">2</span>    <span class="dv">7</span>    <span class="dv">5</span>    <span class="dv">8</span>    <span class="dv">3</span>    <span class="dv">1</span>    <span class="dv">4</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> sam_unif<span class="sc">$</span>rho</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>     [,<span class="dv">1</span>] [,<span class="dv">2</span>] [,<span class="dv">3</span>] [,<span class="dv">4</span>] [,<span class="dv">5</span>] [,<span class="dv">6</span>] [,<span class="dv">7</span>] [,<span class="dv">8</span>]</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>,]    <span class="dv">6</span>    <span class="dv">2</span>    <span class="dv">1</span>    <span class="dv">5</span>    <span class="dv">4</span>    <span class="dv">3</span>    <span class="dv">8</span>    <span class="dv">7</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>[<span class="dv">2</span>,]    <span class="dv">4</span>    <span class="dv">2</span>    <span class="dv">5</span>    <span class="dv">3</span>    <span class="dv">8</span>    <span class="dv">7</span>    <span class="dv">1</span>    <span class="dv">6</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>[<span class="dv">3</span>,]    <span class="dv">6</span>    <span class="dv">2</span>    <span class="dv">8</span>    <span class="dv">4</span>    <span class="dv">7</span>    <span class="dv">3</span>    <span class="dv">1</span>    <span class="dv">5</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> sam_unif<span class="sc">$</span>weights</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.49165535</span> <span class="fl">0.04123627</span> <span class="fl">0.46710838</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">table</span>(sam_unif<span class="sc">$</span>classification)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a> <span class="dv">1</span>  <span class="dv">2</span>  <span class="dv">3</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="dv">35</span>  <span class="dv">5</span> <span class="dv">60</span></span></code></pre></div>
<p>One can note that, with uniform sampling, cluster separation and balance
of the drawings among the mixture components are not guaranteed. In
fact, cluster 2 has a very small weight (<span class="math inline">\(\omega_2 \approx 0.04\)</span>)
corresponding to only 5 observations; moreover, the consensus rankings
of clusters 2 and 3 are quite similar, as testified by their low
relative Spearman distance obtained by dividing the output of command
<code>spear_dist</code> included in <strong>MSmix</strong> by the maximum value of the
metric.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> max_spear_dist <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span><span class="fu">choose</span>(<span class="dv">8</span><span class="sc">+</span><span class="dv">1</span>,<span class="dv">3</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">spear_dist</span>(<span class="at">rankings =</span> sam_unif<span class="sc">$</span>rho[<span class="dv">2</span>,], <span class="at">rho =</span> sam_unif<span class="sc">$</span>rho[<span class="dv">3</span>,])<span class="sc">/</span>max_spear_dist</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.1904762</span></span></code></pre></div>
<p>To ensure separation among the mixture components and non-sparse
weights, the user can set the option <code>uniform = FALSE</code>. Specifically,
the consensus rankings are drawn with a minimum Spearman distance from
each other equal to <span class="math inline">\(\frac{2}{G}\binom{n+1}{3}\)</span>, and the mixing weights
are sampled from a symmetric Dirichlet distribution with (large) shape
parameters <span class="math inline">\(\boldsymbol{\mathbf{\alpha}}=(2G,\dots,2G)\)</span> to favour
populated and balanced clusters.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> sam_sep <span class="ot">&lt;-</span> <span class="fu">rMSmix</span>(<span class="at">sample_size =</span> <span class="dv">100</span>, <span class="at">n_items =</span> <span class="dv">8</span>, <span class="at">n_clust =</span> <span class="dv">3</span>, <span class="at">theta =</span> <span class="fu">rep</span>(.<span class="dv">15</span>, <span class="dv">3</span>),</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>               <span class="at">uniform =</span> <span class="cn">FALSE</span>, <span class="at">mh =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p>The three clusters are now more balanced and their central rankings have
a larger relative distance.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> sam_sep<span class="sc">$</span>weights</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.5214495</span> <span class="fl">0.2594782</span> <span class="fl">0.2190723</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">spear_dist</span>(<span class="at">rankings =</span> sam_sep<span class="sc">$</span>rho)<span class="sc">/</span>max_spear_dist</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>     <span class="dv">1</span>         <span class="dv">2</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span> <span class="fl">0.6309524</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span> <span class="fl">0.7023810</span> <span class="fl">0.6666667</span></span></code></pre></div>
<figure id="fig:s1">
<table>
<caption>
</caption>
<tbody>
<tr>
<td style="text-align: center;">
<img
src="figures/RJ2025_paper_dist1_new.png" style="width:100.0%"
alt="graphic without alt text" />
</td>
<td style="text-align: center;">
<img
src="figures/RJ2025_paper_dist2_new.png" style="width:100.0%"
alt="graphic without alt text" />
</td>
</tr>
<tr>
<td style="text-align: center;">
<ol type="a">
<li><span>Samples with uniformly
generated parameters.</span>
</td>
<td style="text-align: center;">
<ol start="2" type="a">
<li><span>Samples from separated
clusters.</span>
</td>
</tr>
</tbody>
</table>
<figcaption>
Figure 2: Heatmap of the Spearman distance matrix between
all pairs of full rankings for two simulated samples from a 3-component
MMS-mix, obtained by setting <code>uniform = TRUE</code> (a) and
<code>uniform = FALSE</code> (b) in the <code>rMSmix</code>
routine.
</figcaption>
</figure></li>
</ol></li>
</ol>
<p>In Figure <a href="#fig:s1" data-reference-type="ref" data-reference="fig:s1">2</a>, we show
the separation among clusters in the two examples through the Spearman
distance matrix of the simulated samples, which quantifies the
dissimilarity between each pair of observations. Specifically, Figures
<a href="#fig:s1" data-reference-type="ref" data-reference="fig:s1">2</a>a and
<a href="#fig:s1" data-reference-type="ref" data-reference="fig:s1">2</a>b can be
constructed as follows<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">plot</span>(<span class="fu">spear_dist</span>(<span class="at">rankings =</span> sam_unif<span class="sc">$</span>samples), <span class="at">show_labels =</span> <span class="cn">FALSE</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">plot</span>(<span class="fu">spear_dist</span>(<span class="at">rankings =</span> sam_sep<span class="sc">$</span>samples), <span class="at">show_labels =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p>where the argument <code>show_labels = FALSE</code> allows to drop the labels of
the observations over the axes in the case of large samples. The
heatmaps indicate the presence of only two well-separated clusters in
the sample obtained with uniformly generated parameters (Figure
<a href="#fig:s1" data-reference-type="ref" data-reference="fig:s1">2</a>a), while three
groups are evident when the simulation is performed by controlling the
distance among components (Figure <a href="#fig:s1" data-reference-type="ref" data-reference="fig:s1">2</a>b).</p>
<p>In conclusion, <code>rMSmix</code> is designed to facilitate the implementation of
alternative sampling schemes, that can be fruitful to assess the
performance of the inferential procedures and their robustness under a
variety of simulation scenarios.</p>
<h4 class="unnumbered" data-number="4.4" id="subsec:est_full">Application on full rankings</h4>
<p>In this section, we show how to perform a mixture model analysis on the
Antifragility rankings. To this aim, we use the command <code>fitMSmix</code>, the
core function of the <strong>MSmix</strong> package, which performs MLE of the
MMS-mix on the input <code>rankings</code> via EM algorithm with the desired number
<code>n_clust</code> of components. The number of multiple starting points, needed
to address the issue of local maxima, can be set through the argument
<code>n_start</code>, and the list <code>init</code> possibly allows to configure initial
values of the parameters for each starting point.</p>
<p>The code below shows how to estimate the MMS-mix with a number of
components ranging from 1 to 6 and save the values of the Bayesian
information criterion (BIC) in a separate vector for then choosing the
optimal number of clusters.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> FIT.try <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> BIC <span class="ot">&lt;-</span> <span class="fu">setNames</span>(<span class="fu">numeric</span>(<span class="dv">6</span>), <span class="fu">paste0</span>(<span class="st">&#39;G = &#39;</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>))</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>){</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>    FIT.try[[i]] <span class="ot">&lt;-</span> <span class="fu">fitMSmix</span>(<span class="at">rankings =</span> ranks_AF, <span class="at">n_clust =</span> i, <span class="at">n_start =</span> <span class="dv">50</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>    BIC[i] <span class="ot">&lt;-</span> FIT.try[[i]]<span class="sc">$</span>mod<span class="sc">$</span>bic}</span></code></pre></div>
<p>The BIC values of the six estimated models are</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">print</span>(BIC)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>   G <span class="ot">=</span> <span class="dv">1</span>    G <span class="ot">=</span> <span class="dv">2</span>    G <span class="ot">=</span> <span class="dv">3</span>    G <span class="ot">=</span> <span class="dv">4</span>    G <span class="ot">=</span> <span class="dv">5</span>    G <span class="ot">=</span> <span class="dv">6</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="fl">1494.435</span> <span class="fl">1461.494</span> <span class="fl">1442.749</span> <span class="fl">1444.223</span> <span class="fl">1449.714</span> <span class="fl">1453.101</span></span></code></pre></div>
<figure id="f:antifr_plot1">
<img src="figures/RJ2025_paper_cons.png" style="width:100.0%" alt="graphic without alt text" />
<figcaption>Figure 3: Bump plot depicting the estimated consensus rankings of the
<span class="math inline">\({G}=3\)</span> clusters for the <code>ranks_antifragility</code> dataset. This plot
corresponds to the element named <code>bump_plot</code> of the output list returned
by the generic method
<code>plot.emMSmix</code>.</figcaption>
</figure>
<p>suggesting <code>G = 3</code> as the optimal number of groups (lowest BIC). The
function <code>fitMSmix</code> creates an object of S3 class <code>"emMSmix"</code>, which is
a list whose main component, named <code>mod</code>, describes the best fitted
model over the <code>n_start</code> initializations. It includes, for example, the
MLE of the parameters (<code>rho</code>, <code>theta</code> and <code>weights</code>), the fitting
measures (<code>log_lik</code> and <code>bic</code>), the estimated posterior membership
probabilities (<code>z_hat</code>) and the related MAP allocation
(<code>map_classification</code>) as well as the binary indicator of convergence
achievement (<code>conv</code>).</p>
<p>The MLEs of the best fitted model can be shown also through the generic
method <code>summary.emMSmix</code>,</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">summary</span>(<span class="at">object =</span> FIT.try[[<span class="dv">3</span>]])</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>Call<span class="sc">:</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="fu">fitMSmix</span>(<span class="at">rankings =</span> ranks_AF, <span class="at">n_clust =</span> <span class="dv">3</span>, <span class="at">n_start =</span> <span class="dv">50</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="sc">-----------------------------</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="sc">---</span> MLE of the parameters <span class="sc">---</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="sc">-----------------------------</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>Component<span class="sc">-</span>specific consensus rankings<span class="sc">:</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>       Abs Red Sma Non Req Eme Unc</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>Group1   <span class="dv">5</span>   <span class="dv">6</span>   <span class="dv">4</span>   <span class="dv">7</span>   <span class="dv">2</span>   <span class="dv">1</span>   <span class="dv">3</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>Group2   <span class="dv">1</span>   <span class="dv">3</span>   <span class="dv">4</span>   <span class="dv">2</span>   <span class="dv">5</span>   <span class="dv">6</span>   <span class="dv">7</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>Group3   <span class="dv">2</span>   <span class="dv">3</span>   <span class="dv">4</span>   <span class="dv">1</span>   <span class="dv">7</span>   <span class="dv">6</span>   <span class="dv">5</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>Component<span class="sc">-</span>specific consensus orderings<span class="sc">:</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>       Rank1 Rank2 Rank3 Rank4 Rank5 Rank6 Rank7</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>Group1 <span class="st">&quot;Eme&quot;</span> <span class="st">&quot;Req&quot;</span> <span class="st">&quot;Unc&quot;</span> <span class="st">&quot;Sma&quot;</span> <span class="st">&quot;Abs&quot;</span> <span class="st">&quot;Red&quot;</span> <span class="st">&quot;Non&quot;</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>Group2 <span class="st">&quot;Abs&quot;</span> <span class="st">&quot;Non&quot;</span> <span class="st">&quot;Red&quot;</span> <span class="st">&quot;Sma&quot;</span> <span class="st">&quot;Req&quot;</span> <span class="st">&quot;Eme&quot;</span> <span class="st">&quot;Unc&quot;</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>Group3 <span class="st">&quot;Non&quot;</span> <span class="st">&quot;Abs&quot;</span> <span class="st">&quot;Red&quot;</span> <span class="st">&quot;Sma&quot;</span> <span class="st">&quot;Unc&quot;</span> <span class="st">&quot;Eme&quot;</span> <span class="st">&quot;Req&quot;</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>Component<span class="sc">-</span>specific precisions<span class="sc">:</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>Group1 Group2 Group3</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a> <span class="fl">0.111</span>  <span class="fl">0.241</span>  <span class="fl">0.087</span></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>Mixture weights<span class="sc">:</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>Group1 Group2 Group3</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a> <span class="fl">0.083</span>  <span class="fl">0.343</span>  <span class="fl">0.574</span></span></code></pre></div>
<p>which also displays the estimated modal orderings in the rows of the
second output matrix. The generic function <code>plot.emMSmix</code> is also
associated to the class <code>"emMSmix"</code> and constructs a list of two fancy
plots, see commands below.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> p_fit3_AF <span class="ot">&lt;-</span> <span class="fu">plot</span>(FIT.try[[<span class="dv">3</span>]])</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> p_fit3_AF<span class="sc">$</span><span class="fu">bump_plot</span>()</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> p_fit3_AF<span class="sc">$</span><span class="fu">est_clust_prob</span>()</span></code></pre></div>
<p>The first one is the bump plot (Figure
<a href="#f:antifr_plot1" data-reference-type="ref" data-reference="f:antifr_plot1">3</a>)
depicting the consensus ranking of each cluster, with different colors
assigned to each item, circle sizes proportional to the estimated
weights and lines to better highlight item positions in the modal
orderings of the various components. For this example, we note that the
size of the second cluster is almost half that of the third cluster,
while the first cluster is very small. Moreover, the two larger groups
(2 and 3) exhibit very similar modal rankings and quite opposite
preferences with respect to the first cluster (items such as
“Emergence”, “Requisite variety”, and “Uncoupling” are ranked at the top
in cluster 1, but placed at the bottom in groups 2 and 3).</p>
<p>Figure <a href="#f:antifr_plot2" data-reference-type="ref" data-reference="f:antifr_plot2">4</a> shows, instead, the individual cluster
memberships probabilities, describing the uncertainty with which each
observation could be assigned to the mixture components. For example,
the units 10, 15, 19, 20, 71, 74, 78 and 94 have high probabilities
(close to 1) of belonging to group 1. Instead, some units (e.g., unit 8,
28, 36, and 44) have similar membership probabilities of belonging to
clusters 2 or 3, indicating less confidence in their assignment to one
of the two groups. On the other hand, when some clusters are close on
the ranking space, a certain degree of uncertainty in recovering the
true membership is expected.</p>
<figure id="f:antifr_plot2">
<img src="figures/RJ2025_paper_zeta.png" style="width:100.0%" alt="graphic without alt text" />
<figcaption>Figure 4: Heatplot of the estimated cluster membership probabilities
for each observation of the <code>ranks_antifragility</code> dataset. This plot
corresponds to the element named <code>est_clust_prob</code> of the output list
returned by the generic method
<code>plot.emMSmix</code>.</figcaption>
</figure>
<p>The package provides also routines for computing the CIs, working with
the object of class <code>"emMSmix"</code> as first input argument. For example, we
can produce asymptotic CIs for the precisions and mixture weights with
<code>confintMSmix</code>, which is a function specific for full ranking data. With
the default confidence level (<code>conf_level = 0.95</code>), one obtains</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">confintMSmix</span>(<span class="at">object =</span> FIT.try[[<span class="dv">3</span>]])</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>Asymptotic <span class="dv">95</span>%CIs <span class="cf">for</span> the precisions<span class="sc">:</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>       lower upper</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>Group1 <span class="fl">0.000</span> <span class="fl">0.226</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>Group2 <span class="fl">0.153</span> <span class="fl">0.329</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>Group3 <span class="fl">0.068</span> <span class="fl">0.106</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>Asymptotic <span class="dv">95</span>%CIs <span class="cf">for</span> the mixture weights<span class="sc">:</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>       lower upper</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>Group1 <span class="fl">0.021</span> <span class="fl">0.144</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>Group2 <span class="fl">0.195</span> <span class="fl">0.491</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>Group3 <span class="fl">0.473</span> <span class="fl">0.676</span></span></code></pre></div>
<p>Another possibility relies on bootstrap CI calculation. Let us opt for
the soft bootstrap method (the default choice when <span class="math inline">\(G&gt;1\)</span>) which, unlike
the separated one (<code>type = "separated"</code>), produces CIs also for weights.
We require <code>n_boot = 500</code> bootstrap samples and then print the output
object of class <code>"bootMSmix"</code> through the generic function
<code>print.bootMSmix</code>.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> CI_bootSoft <span class="ot">&lt;-</span> <span class="fu">bootstrapMSmix</span>(<span class="at">object =</span> FIT.try[[<span class="dv">3</span>]], <span class="at">n_boot =</span> <span class="dv">500</span>, <span class="at">all =</span> <span class="cn">TRUE</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">print</span>(CI_bootSoft)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>Bootstrap itemwise <span class="dv">95</span>%CIs <span class="cf">for</span> the consensus rankings<span class="sc">:</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>       Abs           Red         Sma           Non     Req         Eme</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>Group1 <span class="st">&quot;{3,4,5,6,7}&quot;</span> <span class="st">&quot;{4,5,6,7}&quot;</span> <span class="st">&quot;{2,3,4,5,6}&quot;</span> <span class="st">&quot;{6,7}&quot;</span> <span class="st">&quot;{1,2,3,4}&quot;</span> <span class="st">&quot;{1,2}&quot;</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>Group2 <span class="st">&quot;{1}&quot;</span>         <span class="st">&quot;{2,3}&quot;</span>     <span class="st">&quot;{4}&quot;</span>         <span class="st">&quot;{2,3}&quot;</span> <span class="st">&quot;{5}&quot;</span>       <span class="st">&quot;{6}&quot;</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>Group3 <span class="st">&quot;{1,2,3}&quot;</span>     <span class="st">&quot;{2,3}&quot;</span>     <span class="st">&quot;{4,5}&quot;</span>       <span class="st">&quot;{1,2}&quot;</span> <span class="st">&quot;{7}&quot;</span>       <span class="st">&quot;{5,6}&quot;</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>       Unc</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>Group1 <span class="st">&quot;{2,3,4,5}&quot;</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>Group2 <span class="st">&quot;{7}&quot;</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>Group3 <span class="st">&quot;{4,5,6}&quot;</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>Bootstrap <span class="dv">95</span>%CIs <span class="cf">for</span> the precisions<span class="sc">:</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>       lower upper</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>Group1 <span class="fl">0.068</span> <span class="fl">0.212</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>Group2 <span class="fl">0.193</span> <span class="fl">0.314</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>Group3 <span class="fl">0.069</span> <span class="fl">0.112</span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>Bootstrap <span class="dv">95</span>%CIs <span class="cf">for</span> the mixture weights<span class="sc">:</span></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>       lower upper</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>Group1 <span class="fl">0.071</span> <span class="fl">0.101</span></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>Group2 <span class="fl">0.283</span> <span class="fl">0.404</span></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>Group3 <span class="fl">0.505</span> <span class="fl">0.636</span></span></code></pre></div>
<p>The logical argument <code>all</code> indicates whether the MLEs estimates obtained
from the bootstrap samples must be returned in the output. When
<code>all = TRUE</code>, as in this case, the user can visualize the bootstrap
sample variability with the generic function <code>plot.bootMSmix</code>. It
returns a list with the heatmap of the first-order marginals of the
bootstrap samples, and the kernel densities for the precisions and
weights. For this application, the latter two plots
(Figure <a href="#fig:boot_theta_weights" data-reference-type="ref" data-reference="fig:boot_theta_weights">5</a>) are obtained as follows.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> p_ci_soft <span class="ot">&lt;-</span> <span class="fu">plot</span>(CI_bootSoft)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> p_ci_soft<span class="sc">$</span><span class="fu">theta_density</span>()</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> p_ci_soft<span class="sc">$</span><span class="fu">weights_density</span>()</span></code></pre></div>
<figure id="fig:boot_theta_weights">
<table>
<caption>
</caption>
<tbody>
<tr>
<td style="text-align: center;">
<img
src="figures/RJ2025_paper_boot1.png" style="width:100.0%"
alt="graphic without alt text" />
</td>
<td style="text-align: center;">
<img
src="figures/RJ2025_paper_boot2.png" style="width:100.0%"
alt="graphic without alt text" />
</td>
</tr>
</tbody>
</table>
<figcaption>
Figure 5: Kernel densities of the soft bootstrap MLEs of the
precision parameters (left) and the weights (right) for the
<code>ranks_antifragility</code> dataset. These plots correspond,
respectively, to the elements named <code>theta_density</code> and
<code>weights_density</code> of the output list returned by the generic
method <code>plot.bootMSmix</code>.
</figcaption>
</figure>
<h4 class="unnumbered" data-number="4.5" id="subsec:est_partial">Application on partial rankings</h4>
<p>In this section, we illustrate how to perform inference on the partial
rankings collected in the original <code>ranks_beers</code> dataset. These data
were gathered through an online survey administered to the participants
of the 2018 Pint of Science festival held in Grenoble. A sample of
<span class="math inline">\(N = 105\)</span> subjects provided their partial rankings of <span class="math inline">\(n=20\)</span> beers
according to their personal tastes. The partial rankings, characterized
by different censoring patterns (that is, not exclusively top-<span class="math inline">\(k\)</span>
sequences), are recorded in the first 20 columns of the dataset, while
column 21 contains a covariate regarding respondents’ residency.</p>
<p>The barplot with the percentages of the number of beers actually ranked
by the participants is reported in Figure
<a href="#fig:descr_beers" data-reference-type="ref" data-reference="fig:descr_beers">6</a>.
We restrict the analysis to partial rankings with maximum 8 missing
positions, to show both the data augmentation schemes (Algorithms
<a href="#alg:partial_mixture" data-reference-type="ref" data-reference="alg:partial_mixture">3</a> and
<a href="#alg:partial_mcem" data-reference-type="ref" data-reference="alg:partial_mcem">4</a>) implemented in the package. Note that,
since our EM algorithms rely on the MAR assumption, we preliminarily
conducted an empirical evaluation to assess whether the realized
missingness pattern significantly deviates from this hypothesis. This
check is described in Appendix A3.</p>
<p>Thanks to the <code>subset</code> argument of <code>fitMSmix</code>, we can specify the
subsample of observations to be considered directly in the fit command.
To speed up the estimation process, we parallelize the multiple starting
points by setting <code>parallel = TRUE</code>.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> rankings <span class="ot">&lt;-</span> ranks_beers[,<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>]</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> subset_beers <span class="ot">&lt;-</span> (<span class="fu">rowSums</span>(<span class="fu">is.na</span>(rankings)) <span class="sc">&lt;=</span> <span class="dv">8</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">library</span>(doParallel)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">registerDoParallel</span>(<span class="at">cores =</span> <span class="fu">detectCores</span>())</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> FIT_aug <span class="ot">&lt;-</span> <span class="fu">fitMSmix</span>(rankings,<span class="at">n_clust =</span> <span class="dv">1</span>, <span class="at">n_start =</span> <span class="dv">15</span>,</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>                     <span class="at">subset =</span> subset_beers, <span class="at">mc_em =</span> <span class="cn">FALSE</span>, <span class="at">parallel =</span> <span class="cn">TRUE</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> FIT_mcem <span class="ot">&lt;-</span> <span class="fu">fitMSmix</span>(rankings, <span class="at">n_clust =</span> <span class="dv">1</span>, <span class="at">n_start =</span> <span class="dv">15</span>,</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>                      <span class="at">subset =</span> subset_beers, <span class="at">mc_em =</span> <span class="cn">TRUE</span>, <span class="at">parallel =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<figure id="fig:descr_beers">
<img src="figures/RJ2025_paper_descr_beers.png" style="width:100.0%" alt="graphic without alt text" />
<figcaption>Figure 6: Percentages of the number of ranked items in the
<code>ranks_beers</code> dataset. This barplot corresponds to the element named
<code>n_ranked_distr</code> of the output list returned by the generic method
<code>plot.data_descr</code>.</figcaption>
</figure>
<p>The logical <code>mc_em</code> argument indicates whether the MCEM scheme
(Algorithm <a href="#alg:partial_mcem" data-reference-type="ref" data-reference="alg:partial_mcem">4</a>) must be applied. When <code>mc_em = FALSE</code>
(default), Algorithm <a href="#alg:partial_mixture" data-reference-type="ref" data-reference="alg:partial_mixture">3</a> is implemented.<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> We note that, for
this application, the results of the two methods are very similar.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">spear_dist</span>(FIT_aug<span class="sc">$</span>mod<span class="sc">$</span>rho,FIT_mcem<span class="sc">$</span>mod<span class="sc">$</span>rho)<span class="sc">/</span>(<span class="dv">2</span><span class="sc">*</span><span class="fu">choose</span>(<span class="dv">20</span><span class="sc">+</span><span class="dv">1</span>,<span class="dv">3</span>))</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.001503759</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">c</span>(<span class="st">&#39;theta_aug&#39;</span> <span class="ot">=</span> FIT_aug<span class="sc">$</span>mod<span class="sc">$</span>theta, <span class="st">&#39;theta_mcem&#39;</span> <span class="ot">=</span> FIT_mcem<span class="sc">$</span>mod<span class="sc">$</span>theta)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>  theta_aug  theta_mcem</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="fl">0.008580397</span> <span class="fl">0.008964391</span></span></code></pre></div>
<p>One can then evaluate the uncertainty associated to the consensus
ranking estimated via the MCEM with the non-parametric bootstrap
(default for <span class="math inline">\(G=1\)</span>). Also in this case, we can parallelize over the
multiple starting points of the EM algorithm used to fit the bootstrap
samples.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> boot_mcem <span class="ot">&lt;-</span> <span class="fu">bootstrapMSmix</span>(<span class="at">object =</span> FIT_mcem, <span class="at">n_boot =</span> <span class="dv">300</span>, <span class="at">n_start =</span> <span class="dv">15</span>,</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>                             <span class="at">all =</span> <span class="cn">TRUE</span>, <span class="at">parallel =</span> <span class="cn">TRUE</span>)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">print</span>(boot_mcem)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>Bootstrap itemwise <span class="dv">95</span>%CIs <span class="cf">for</span> the consensus rankings<span class="sc">:</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>       Stella                   Kwak          KronKron  Faro</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>Group1 <span class="st">&quot;{12,13,14,15,16,17,18}&quot;</span> <span class="st">&quot;{2,3,4,5,6}&quot;</span> <span class="st">&quot;{19,20}&quot;</span> <span class="st">&quot;{8,9,10,11,12,13,14,15}&quot;</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>       Kron1664           Chimay  Pelforth           KronCarls</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>Group1 <span class="st">&quot;{14,15,16,17,18}&quot;</span> <span class="st">&quot;{1,2}&quot;</span> <span class="st">&quot;{11,12,13,14,15}&quot;</span> <span class="st">&quot;{12,13,14,15,16,17,18}&quot;</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>       KronKanter Hoegaarden           Grimbergen      Pietra</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>Group1 <span class="st">&quot;{19,20}&quot;</span>  <span class="st">&quot;{6,7,8,9,10,11,12}&quot;</span> <span class="st">&quot;{2,3,4,5,6,7}&quot;</span> <span class="st">&quot;{6,7,8,9,10,11,12,13}&quot;</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>       Affligem         Goudale           Leffe             Heineken</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>Group1 <span class="st">&quot;{3,4,5,6,7,8}&quot;</span> <span class="st">&quot;{4,5,6,7,8,9,10}&quot;</span> <span class="st">&quot;{6,7,8,9,10,11}&quot;</span> <span class="st">&quot;{14,15,16,17,18}&quot;</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>       Duvel             Choulette                Orval</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>Group1 <span class="st">&quot;{2,3,4,5,6,7,8}&quot;</span> <span class="st">&quot;{12,13,14,15,16,17,18}&quot;</span> <span class="st">&quot;{5,6,7,8,9,10,11,12,13,15}&quot;</span></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>       Karmeliet</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>Group1 <span class="st">&quot;{1,2,3,4,5,6}&quot;</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>Bootstrap <span class="dv">95</span>%CIs <span class="cf">for</span> the precisions<span class="sc">:</span></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>       lower upper</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>Group1 <span class="fl">0.007</span> <span class="fl">0.013</span></span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">plot</span>(boot_mcem)<span class="sc">$</span><span class="fu">rho_heatmap</span>()</span></code></pre></div>
<p>The heatmap of the bootstrap output, displayed in Figure
<a href="#fig:heat_beers" data-reference-type="ref" data-reference="fig:heat_beers">7</a>,
helps in understanding the variability and confidence in the rankings of
the beers. In fact, the top ranked beer (Chimay) and the two bottom
ranked ones (KronKanter and KronKron) are quite reliably ranked in those
positions. On the contrary, the ranks of the other beers are more
uncertain, with itemwise 95% bootstrap-based CIs for some beers being as
wide as 10 positions (out of 20). Note also that some itemwise regions
can result in subsets of non-contiguous ranks, as in the case of <code>Orval</code>
whose CI does not include rank 14.</p>
<figure id="fig:heat_beers">
<img src="figures/RJ2025_paper_heat.png" style="width:100.0%" alt="graphic without alt text" />
<figcaption>Figure 7: Heatmap of the bootstrap MLE of the consensus ranking for a
subsample of the <code>ranks_beers</code> dataset. On the y-axis, items are ordered
according to the MLE of <span class="math inline">\(\boldsymbol{\mathbf{\rho}}\)</span> (top-ranked beer at
the bottom). This plot corresponds to the element named <code>rho_heatmap</code> of
the output list returned by the generic method
<code>plot.bootMSmix</code>.</figcaption>
</figure>
<p>We conclude this section by stressing that the application to the beers
dataset represents a non-trivial case of ranking data analysis, since
currently there are no other R packages supporting MLE of
the MM on partially-ranked sequences with arbitrary missing positions.</p>
<h4 class="unnumbered" data-number="4.6" id="additional-options">Additional options</h4>
<p>The <strong>MSmix</strong> package also supplies some functions to deal with the
distribution of the Spearman distance. Although these functions are
primarily used internally to fit the model (see the algorithms in
Appendix A1), they are made available for external use due to their
standalone utility.</p>
<p>The function <code>spear_dist_distr</code> returns the (log-)frequency distribution
of the Spearman distance under the uniform model. If <span class="math inline">\(n\leq 20\)</span>, the
function returns the exact distribution by relying on a call to the
<code>get_cardinalities</code> routine of <strong>BayesMallows</strong>. Here is an example with
<span class="math inline">\(n=5\)</span>.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">spear_dist_distr</span>(<span class="at">n_items =</span> <span class="dv">5</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>distances</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a> [<span class="dv">1</span>]  <span class="dv">0</span>  <span class="dv">2</span>  <span class="dv">4</span>  <span class="dv">6</span>  <span class="dv">8</span> <span class="dv">10</span> <span class="dv">12</span> <span class="dv">14</span> <span class="dv">16</span> <span class="dv">18</span> <span class="dv">20</span> <span class="dv">22</span> <span class="dv">24</span> <span class="dv">26</span> <span class="dv">28</span> <span class="dv">30</span> <span class="dv">32</span> <span class="dv">34</span> <span class="dv">36</span> <span class="dv">38</span> <span class="dv">40</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>logcard</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a> [<span class="dv">1</span>] <span class="fl">0.000000</span> <span class="fl">1.386294</span> <span class="fl">1.098612</span> <span class="fl">1.791759</span> <span class="fl">1.945910</span> <span class="fl">1.791759</span> <span class="fl">1.386294</span> <span class="fl">2.302585</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a> [<span class="dv">9</span>] <span class="fl">1.791759</span> <span class="fl">2.302585</span> <span class="fl">1.791759</span> <span class="fl">2.302585</span> <span class="fl">1.791759</span> <span class="fl">2.302585</span> <span class="fl">1.386294</span> <span class="fl">1.791759</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>[<span class="dv">17</span>] <span class="fl">1.945910</span> <span class="fl">1.791759</span> <span class="fl">1.098612</span> <span class="fl">1.386294</span> <span class="fl">0.000000</span></span></code></pre></div>
<p>When <span class="math inline">\(n&gt; 20\)</span>, the approximate distribution introduced by
<span class="citation" data-cites="crispino23efficient">(<a href="#ref-crispino23efficient" role="doc-biblioref">Crispino et al. 2023</a>)</span> is returned and, in the case <span class="math inline">\(n\geq 170\)</span>, its
calculation is restricted over a fixed grid of values of the Spearman
distance to limit computational burden.</p>
<p>The functions <code>partition_fun_spear</code>, <code>expected_spear_dist</code> and
<code>var_spear_dist</code> provide, respectively, the partition function
<span class="math inline">\(Z(\theta)\)</span>, the expected value <span class="math inline">\(\mathbb{E}_{\theta}[D]\)</span> and the
variance <span class="math inline">\(\mathbb{V}_{\theta}[D]\)</span> of the Spearman distance under the
MMS. For <span class="math inline">\(n=5\)</span>, one has</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">partition_fun_spear</span>(<span class="at">theta =</span> <span class="fl">0.1</span>, <span class="at">n_items =</span> <span class="dv">5</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">3.253889</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">expected_spear_dist</span>(<span class="at">theta =</span> <span class="fl">0.1</span>, <span class="at">n_items =</span> <span class="dv">5</span>)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">2.421115</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>R<span class="sc">&gt;</span> <span class="fu">var_spear_dist</span>(<span class="at">theta =</span> <span class="fl">0.1</span>, <span class="at">n_items =</span> <span class="dv">5</span>)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">4.202741</span></span></code></pre></div>
<p>For these functions, the computation is exact or approximate according
to the same principle described for <code>spear_dist_distr</code>.</p>
<h3 data-number="5" id="sec:concl"><span class="header-section-number">5</span> Conclusions</h3>
<p>The new <strong>MSmix</strong> package enriches the R software
environment with functions to analyze finite mixtures of MMS on full and
partial rankings with arbitrary patterns of censoring. Inference is
conducted within the ML framework via EM algorithms. Estimation
uncertainty is quantified with bootstrap methods and approximate CIs
from the asymptotic likelihood theory.</p>
<p>The innovative contributions of <strong>MSmix</strong> span from both methodological
and computational advancements to address the lacks and limitations
found in most of the existing packages, especially the possibility of
realizing a ranking data analysis with many items and missing positions
or assessing estimation uncertainty of model parameters. Moreover, the
estimation procedures have been generalized and optimized to work
effectively across a spectrum of censoring patterns, rather than being
limited solely to the top-<span class="math inline">\(k\)</span> scenario. The package also exploits the
construction of S3 class objects and related generic methods to offer a
unified and original analysis framework. In this regard, a special
attention was devoted to the development of effective visualization
tools and summaries, that can assist the users in the reporting results
and designing conclusions with a more transparent account of the
associated uncertainty.</p>
<p>Our inferential procedures rely on EM algorithms assuming a MAR missing
data mechanism. Under the MAR assumption, missingness does not depend on
the unobserved preferences, allowing the EM algorithm to yield unbiased
estimates without explicitly modeling the missing data process
<span class="citation" data-cites="rubin1976inference little2019statistical">(<a href="#ref-rubin1976inference" role="doc-biblioref">Rubin 1976</a>; <a href="#ref-little2019statistical" role="doc-biblioref">Little and Rubin 2019</a>)</span>. Although MAR is a common
simplifying assumption in partial ranking analysis
<span class="citation" data-cites="beckett93maximum Jacques2014 piancastelli2025time">(<a href="#ref-beckett93maximum" role="doc-biblioref">Beckett 1993</a>; <a href="#ref-Jacques2014" role="doc-biblioref">Jacques and Biernacki 2014</a>; <a href="#ref-piancastelli2025time" role="doc-biblioref">Piancastelli and Barreto-Souza 2025</a>)</span>, it may not
hold in real-world settings. For instance, top-<span class="math inline">\(k\)</span> rankings can arise
when respondents omit to rank certain items due to unfamiliarity or low
popularity, indicating that missingness depends on unobserved
preferences and could, thus, significantly depart from the pure MAR
assumption. It is well known that ignoring the missingness process under
non-MAR scenarios can bias estimates obtained from standard EM
algorithms <span class="citation" data-cites="little2019statistical">(<a href="#ref-little2019statistical" role="doc-biblioref">Little and Rubin 2019</a>)</span>. However, the effects of MAR
violations on the estimation accuracy of EM algorithms, as well as
methods to address non-ignorable missingness, remain largely unexplored
in the partial ranking literature. In this context, extending the
methods provided by <strong>MSmix</strong> to better handle missing data in ranking
models would represent a valuable methodological contribution for future
research.</p>
<p>The package architecture and its computational achievements can
facilitate code extensibility for accomplishing these innovative
directions. For example, its flexibility in accommodating diverse data
censoring patterns could be of support for exploring the plausibility of
the standard MAR assumption or developing extensions of parametric
mixture models incorporating non-ignorable missing data mechanisms.
Moreover, the package capability to analyze data characterized by a
large number of alternatives could motivate the interest in clustering
similar items, as recently proposed for the MM in <span class="citation" data-cites="piancastelli">Piancastelli and Friel (<a href="#ref-piancastelli" role="doc-biblioref">2025</a>)</span>, or even
in developing methods to solve bi-clustering problems. Finally, to
better characterize choice processes, the EM algorithms could be
integrated with an additional step for estimating the impact of
individual and/or item-specific covariates - a typical but complex task
in preference analysis from ranking data <span class="citation" data-cites="gormley2008mixture zhu21partition">(see e.g., <a href="#ref-gormley2008mixture" role="doc-biblioref">Gormley and Murphy 2008</a>; <a href="#ref-zhu21partition" role="doc-biblioref">Zhu et al. 2021</a>)</span>. We are currently working in this
direction with a proposal to enrich the MMS-mix with a <em>Mixture of
Experts</em> model <span class="citation" data-cites="jacobs jordan">(<a href="#ref-jacobs" role="doc-biblioref">Jacobs et al. 1991</a>; <a href="#ref-jordan" role="doc-biblioref">Jordan and Jacobs 1994</a>)</span>, that is, a mixture model in which the
weights are functions of the covariates <span class="citation" data-cites="crispinoMoE">(<a href="#ref-crispinoMoE" role="doc-biblioref">Crispino et al. 2024</a>)</span>. Future releases
of <strong>MSmix</strong> will also include functions to deal with different
distances among rankings.</p>
<h3 data-number="6" id="acknowledgments"><span class="header-section-number">6</span> Acknowledgments</h3>
<p>The authors would like to thank the anonymous reviewers for their
constructive and insightful comments that greatly improved the
manuscript and the package. The authors wish to thank Prof. Luca
Tardella and Prof. Enrico Casadio Tarabusi for the insightful
discussions on various aspects of the methodology used in this paper.
Additionally, the authors wish to thank Prof Maria Vincenza Ciasullo,
Dr. Nicola Cucari, Dr. Raffaella Montera, Prof Maria Iannario and Prof.
Rosaria Simone for generously sharing their data.<br />
The opinions expressed are those of the authors and do not necessarily
reflect the views of the Bank of Italy or the Eurosystem.</p>
<h3 class="appendix" data-number="7" id="appendix"><span class="header-section-number">7</span> Appendix</h3>
<h4 class="unnumbered" data-number="7.1" id="app:Algo">Estimation algorithms</h4>
<p>We here provide the pseudo-code of the estimation algorithms implemented
in <strong>MSmix</strong>. In the heterogeneous case (<span class="math inline">\(G&gt;1\)</span>), the latent group
membership of the <span class="math inline">\(l\)</span>-th distinct observed ranking
<span class="math inline">\(\boldsymbol{\mathbf{r}}_l\)</span> is denoted with
<span class="math inline">\(\boldsymbol{\mathbf{z_l = (z_{l1},\dots, z_{lG})}}\)</span>, where <span class="math inline">\(z_{lg} = 1\)</span>
if the observation belongs to component <span class="math inline">\(g\)</span> and <span class="math inline">\(z_{lg} = 0\)</span> otherwise.</p>
<hr />
<figure id="alg:full">
<figcaption>
Algorithm 1: MLE of the MMS parameters from full
rankings
</figcaption>
</figure>
<p><strong>Input</strong>:
<span class="math inline">\(\underline{\boldsymbol{\mathbf{r}}}=\{\boldsymbol{\mathbf{r}}_1,\dots,\boldsymbol{\mathbf{r}}_N\}\)</span>
full <span class="math inline">\(n\)</span>-rankings.</p>
<ol type="1">
<li><p><strong>Preliminary steps</strong>:</p>
<ul>
<li><p>For <span class="math inline">\(l=1,\dots,L\)</span>, compute the frequency <span class="math inline">\(N_l\)</span> of each distinct
observed ranking <span class="math inline">\(\boldsymbol{\mathbf{r}}_l\)</span>.</p></li>
<li><p>Compute either the exact or the approximate frequency
distribution of the Spearman distance
<span class="math inline">\(\{d,N_d\}_{d\in\mathcal{D}_n}\)</span>.</p></li>
</ul></li>
<li><p>Compute the MLE of the consensus ranking
<span class="math inline">\(\boldsymbol{\mathbf{\rho}}\)</span>:</p>
<ol type="1">
<li><p>Compute the sample mean rank vector
<span class="math inline">\({\boldsymbol{\mathbf{\bar r}}}=(\bar{r}_1,\ldots,\bar{r}_n)\)</span>.</p></li>
<li><p>Compute
<span class="math inline">\(\hat{\boldsymbol{\mathbf{\rho}}}=\text{rank}({\boldsymbol{\mathbf{\bar r}}})\)</span>.</p></li>
</ol></li>
<li><p>Compute the MLE of the concentration parameter <span class="math inline">\(\theta\)</span>:</p>
<ol type="1">
<li><p>Compute the sample average distance
<span class="math inline">\(\bar d=\frac{1}{N}\sum_{l=1}^LN_ld(\boldsymbol{\mathbf{r}}_l,\hat{\boldsymbol{\mathbf{\rho}}})=2(c_n-\hat{\boldsymbol{\mathbf{\rho}}}^T{\boldsymbol{\mathbf{\bar r}}})\)</span>.</p></li>
<li><p>Apply <code>uniroot</code> to find the solution of the equation
<span class="math inline">\(\mathbb{E}_{\theta}(D) = 2(c_n-\hat{\boldsymbol{\mathbf{\rho}}}^T{\boldsymbol{\mathbf{\bar r}}})\)</span>
in <span class="math inline">\(\theta\)</span>.</p></li>
</ol></li>
</ol>
<p><strong>Output</strong>: <span class="math inline">\(\hat{\boldsymbol{\mathbf{\rho}}}\)</span> and <span class="math inline">\(\hat{\theta}\)</span>.</p>
<hr />
<hr />
<figure id="alg:full_mixture">
<figcaption>
Algorithm 2: MLE of the MMS-mix parameters from full
rankings
</figcaption>
</figure>
<p><strong>Input</strong>:
<span class="math inline">\(\underline{\boldsymbol{\mathbf{r}}}=\{\boldsymbol{\mathbf{r}}_1,\dots,\boldsymbol{\mathbf{r}}_N\}\)</span>
full <span class="math inline">\(n\)</span>-rankings; <span class="math inline">\(G\)</span> number of clusters;
<span class="math inline">\(\underline{\boldsymbol{\mathbf{\rho}}}^{(0)}, \boldsymbol{\mathbf{\theta}}^{(0)}, \boldsymbol{\mathbf{\omega}}^{(0)}\)</span>
initial values.</p>
<ol type="1">
<li><p><strong>Preliminary steps</strong>:</p>
<ul>
<li><p>For <span class="math inline">\(l=1,\dots,L\)</span>, compute the frequency <span class="math inline">\(N_l\)</span> of each distinct
observed ranking <span class="math inline">\(\boldsymbol{\mathbf{r}}_l\)</span>.</p></li>
<li><p>Compute either the exact or the approximate frequency
distribution of the Spearman distance
<span class="math inline">\(\{d,N_d\}_{d\in\mathcal{D}_n}\)</span>.</p></li>
</ul></li>
<li><p>Repeat the E- and M-step below until convergence:</p></li>
<li><p><strong>E-step</strong>: for <span class="math inline">\(l=1,\dots,L\)</span> and <span class="math inline">\(g=1,\dots,G\)</span>, compute
<span class="math inline">\(\hat z_{lg} = \frac{\hat\omega_g\mathbb{P}(\boldsymbol{\mathbf{r}}_l\,|\hat{\boldsymbol{\mathbf{\rho}}}_g,\hat\theta_g)}{\sum_{g\prime=1}^G\hat\omega_{g\prime}\mathbb{P}(\boldsymbol{\mathbf{r}}_l\,|\hat{\boldsymbol{\mathbf{\rho}}}_{g\prime},\hat\theta_{g\prime})}\)</span>.</p></li>
<li><p><strong>M-step</strong>: for <span class="math inline">\(g=1,\dots,G\)</span> compute</p>
<ol type="1">
<li><p><span class="math inline">\(\hat \omega_g =\hat{N}_g/N\)</span> with
<span class="math inline">\(\hat{N}_g =\sum_{l=1}^L N_l \hat z_{lg}\)</span>.</p></li>
<li><p>The MLE of <span class="math inline">\(\boldsymbol{\mathbf{\rho_g}}\)</span> as in step 1 of
Algorithm <a href="#alg:full" data-reference-type="ref" data-reference="alg:full">1</a>, by replacing
<span class="math inline">\(\bar{\boldsymbol{\mathbf{r}}}\)</span> with<br />
<span class="math inline">\(\bar{\boldsymbol{\mathbf{r}}}_g = (\bar r_{g1},\dots, \bar r_{gn})\)</span>,
where
<span class="math inline">\(\bar r_{gi} = \frac{1}{\hat N_g}\sum_{l=1}^L N_l\hat z_{lg}r_{li}\)</span>.</p></li>
<li><p>The MLE of <span class="math inline">\(\theta_g\)</span> as in step 2 of Algorithm
<a href="#alg:full" data-reference-type="ref" data-reference="alg:full">1</a>, by
replacing <span class="math inline">\(\bar{\boldsymbol{\mathbf{r}}}\)</span> with
<span class="math inline">\(\bar{\boldsymbol{\mathbf{r}}}_g\)</span> and
<span class="math inline">\(\hat{\boldsymbol{\mathbf{\rho}}}\)</span> with
<span class="math inline">\(\hat{\boldsymbol{\mathbf{\rho}}}_g\)</span>.</p></li>
</ol></li>
</ol>
<p><strong>Output</strong>:
<span class="math inline">\(\underline{\hat{\boldsymbol{\mathbf{\rho}}}}=\{\hat{\boldsymbol{\mathbf{\rho}}}_1,\dots,\hat{\boldsymbol{\mathbf{\rho}}}_G\},{\hat{\boldsymbol{\mathbf{\theta}}}}=\{\hat{\theta}_1,\dots,\hat{\theta}_G\},{\hat{\boldsymbol{\mathbf{\omega}}}}=\{\hat\omega_1,\dots,\hat\omega_G\}\)</span>, and <span class="math inline">\(\underline{\hat{\boldsymbol{\mathbf{z}}}}=\{\boldsymbol{\mathbf{\hat z_1}},\dots,\boldsymbol{\mathbf{\hat z_N}}\}\)</span>.</p>
<hr />
<hr />
<figure id="alg:partial_mixture">
<figcaption>
Algorithm 3: MLE of the MMS-mix parameters from partial
rankings
</figcaption>
</figure>
<p><strong>Input</strong>:
<span class="math inline">\(\underline{\boldsymbol{\mathbf{r}}}=\{\boldsymbol{\mathbf{r}}_1,\dots,\boldsymbol{\mathbf{r}}_N\}\)</span>
partial <span class="math inline">\(n\)</span>-rankings; <span class="math inline">\(G\)</span> number of clusters;
<span class="math inline">\(\underline{\boldsymbol{\mathbf{\rho}}}^{(0)}, \boldsymbol{\mathbf{\theta}}^{(0)}, \boldsymbol{\mathbf{\omega}}^{(0)}\)</span>
initial values.</p>
<ol type="1">
<li><p><strong>Preliminary steps</strong>: for <span class="math inline">\(l=1,\dots,L\)</span>,</p>
<ul>
<li><p>compute the frequency <span class="math inline">\(N_l\)</span> of each distinct observed ranking
<span class="math inline">\(\boldsymbol{\mathbf{r}}_l\)</span>.</p></li>
<li><p>Compute and store the sets
<span class="math inline">\(\mathcal{C}(\boldsymbol{\mathbf{r_l}})\)</span> of full rankings
compatible with each distinct <span class="math inline">\(\boldsymbol{\mathbf{r}}_l\)</span>.</p></li>
</ul></li>
<li><p>Repeat the E- and M-step below until convergence:</p></li>
<li><p><strong>E-step</strong>:</p>
<ol type="1">
<li><p>For each distinct <span class="math inline">\(\boldsymbol{\mathbf{r_l}}\)</span> with <span class="math inline">\(l=1,\dots,L\)</span>
and for each
<span class="math inline">\(\boldsymbol{\mathbf{r}}^*_{m^\prime}\in\mathcal{C}(\boldsymbol{\mathbf{r_l}})\)</span>,
compute</p>
<p><span class="math display">\[\hat{p}_{lm^\prime}=\mathbb{P}(\boldsymbol{\mathbf{r}}^*_{m^\prime}\,|\boldsymbol{\mathbf{r}}_l,\underline{\hat{\boldsymbol{\mathbf{\rho}}}},{\hat{\boldsymbol{\mathbf{\theta}}}},{\hat{\boldsymbol{\mathbf{\omega}}}})
  =\frac{\sum_{g=1}^G \hat\omega_g e^{-2\hat\theta_g\left(c_n-{\hat{\boldsymbol{\mathbf{\rho}}}_g^T}\boldsymbol{\mathbf{r}}^*_{m^\prime}\right)-\log Z\left(\hat\theta_g\right)}}{\sum_{\boldsymbol{\mathbf{s}}^*\in \mathcal{C}(\boldsymbol{\mathbf{r}}_l)}\sum_{g=1}^G \hat\omega_ge^{-2\hat\theta_g\left(c_n-\hat{\boldsymbol{\mathbf{\rho}}}^T_{g}\boldsymbol{\mathbf{s}}^*\right)-\log Z\left(\hat\theta_g\right)}}
  .\]</span></p></li>
<li><p>For <span class="math inline">\(m=1,\dots,M\)</span>, compute
<span class="math inline">\(\hat{N}_m=\sum_{l:\,\boldsymbol{\mathbf{r}}^*_{m^\prime}\in\mathcal{C}(\boldsymbol{\mathbf{r}}_l)} N_l \hat{p}_{lm^\prime}\)</span>.</p></li>
<li><p>For <span class="math inline">\(m=1,\dots,M\)</span>, and <span class="math inline">\(g=1,\dots,G\)</span>, compute
<span class="math inline">\(\hat z_{mg}=\dfrac{\hat\omega_g\mathbb{P}\big(\boldsymbol{\mathbf{r}}^*_m\big\vert\hat{\boldsymbol{\mathbf{\rho}}}_g,\hat\theta_g\big)}{\sum_{g&#39;=1}^G\hat\omega_{g&#39;}\mathbb{P}\big(\boldsymbol{\mathbf{r}}^*_m\big\vert\hat{\boldsymbol{\mathbf{\rho}}}_{g&#39;},\hat\theta_{g&#39;}\big)}\)</span>.</p></li>
</ol></li>
<li><p><strong>M-step</strong>: for <span class="math inline">\(g=1,\dots,G\)</span>, compute</p>
<ul>
<li><p><span class="math inline">\(\hat\omega_g =\hat{N}_g/N\)</span> with
<span class="math inline">\(\hat{N}_g=\sum_{m=1}^M\hat{N}_m\hat z_{mg}\)</span>.</p></li>
<li><p>The MLE of <span class="math inline">\(\boldsymbol{\mathbf{\rho_g}}\)</span> as in M-step (b) of
Algorithm <a href="#alg:full_mixture" data-reference-type="ref" data-reference="alg:full_mixture">2</a>, by replacing
<span class="math inline">\(\bar{\boldsymbol{\mathbf{r}}}_g\)</span> with<br />
<span class="math inline">\(\bar{\boldsymbol{\mathbf{r}}}^*_g = (\bar r^*_{g1},\dots, \bar r^*_{gn})\)</span>,
where
<span class="math inline">\(\bar r^*_{gi} = \frac{1}{\hat N_g}\sum_{m=1}^M \hat N_m \hat z_{mg}r^*_{mi}\)</span>.</p></li>
<li><p>The MLE of <span class="math inline">\(\theta_g\)</span> as in M-step (c) of Algorithm
<a href="#alg:full_mixture" data-reference-type="ref" data-reference="alg:full_mixture">2</a>, by substituting
<span class="math inline">\(\bar{\boldsymbol{\mathbf{r}}}_g\)</span> with
<span class="math inline">\(\bar{\boldsymbol{\mathbf{r}}}^*_g\)</span>.</p></li>
</ul></li>
</ol>
<p><strong>Output</strong>:
<span class="math inline">\(\underline{\hat{\boldsymbol{\mathbf{\rho}}}}=\{\hat{\boldsymbol{\mathbf{\rho}}}_1,\dots,\hat{\boldsymbol{\mathbf{\rho}}}_G\},{\hat{\boldsymbol{\mathbf{\theta}}}}=\{\hat{\theta}_1,\dots,\hat{\theta}_G\},{\hat{\boldsymbol{\mathbf{\omega}}}}=\{\hat\omega_1,\dots,\hat\omega_G\}\text{ and }\underline{\hat{\boldsymbol{\mathbf{z}}}}=\{\boldsymbol{\mathbf{\hat z_1}},\dots,\boldsymbol{\mathbf{\hat z_N}}\}\)</span>.</p>
<hr />
<hr />
<figure id="alg:partial_mcem">
<figcaption>
Algorithm 4: MLE of the MMS-mix parameters from partial rankings
(MCEM)
</figcaption>
</figure>
<p><strong>Input</strong>:
<span class="math inline">\(\underline{\boldsymbol{\mathbf{r}}}=\{\boldsymbol{\mathbf{r}}_1,\dots,\boldsymbol{\mathbf{r}}_N\}\)</span>
partial <span class="math inline">\(n\)</span>-rankings; <span class="math inline">\(G\)</span> number of clusters;
<span class="math inline">\(\underline{\boldsymbol{\mathbf{\rho}}}^{(0)}, \boldsymbol{\mathbf{\theta}}^{(0)}, \boldsymbol{\mathbf{\omega}}^{(0)}\)</span>
initial values.</p>
<ol type="1">
<li><p><strong>Preliminary step</strong>: for <span class="math inline">\(s=1,\dots,N\)</span>, complete
<span class="math inline">\(\boldsymbol{\mathbf{r}}_s\)</span> at random, obtaining a full ranking
<span class="math inline">\(\boldsymbol{\mathbf{r}}^*_s\in \mathcal{C}(\boldsymbol{\mathbf{r_s}})\)</span>.</p></li>
<li><p>Repeat the E-, M- and MC-step below until convergence:</p></li>
<li><p><strong>E-step</strong>: for <span class="math inline">\(s=1,\dots,N\)</span>, compute
<span class="math inline">\(\hat{\boldsymbol{\mathbf{z}}}_s\)</span> as in E-step of Algorithm
<a href="#alg:full_mixture" data-reference-type="ref" data-reference="alg:full_mixture">2</a>, by replacing
<span class="math inline">\(\boldsymbol{\mathbf{r_l}}\)</span> with <span class="math inline">\(\boldsymbol{\mathbf{r^*_s}}\)</span>.</p></li>
<li><p><strong>M-step</strong>: same as in Algorithm
<a href="#alg:full_mixture" data-reference-type="ref" data-reference="alg:full_mixture">2</a>.</p></li>
<li><p><strong>MC step</strong>: for <span class="math inline">\(s=1,\dots,N\)</span>, complete <span class="math inline">\(\boldsymbol{\mathbf{r}}_s\)</span>
with the scheme <a href="#eq:mcem1">(2)</a>-<a href="#eq:mcem1bis">(3)</a>, obtaining an
updated
<span class="math inline">\(\boldsymbol{\mathbf{r}}^*_s\in\mathcal{C}(\boldsymbol{\mathbf{r_s}})\)</span>.</p></li>
</ol>
<p><strong>Output</strong>:
<span class="math inline">\(\underline{\hat{\boldsymbol{\mathbf{\rho}}}}=\{\hat{\boldsymbol{\mathbf{\rho}}}_1,\dots,\hat{\boldsymbol{\mathbf{\rho}}}_G\},{\hat{\boldsymbol{\mathbf{\theta}}}}=\{\hat{\theta}_1,\dots,\hat{\theta}_G\},{\hat{\boldsymbol{\mathbf{\omega}}}}=\{\hat\omega_1,\dots,\hat\omega_G\}\)</span>,
and
<span class="math inline">\(\underline{\hat{\boldsymbol{\mathbf{z}}}}=\{\boldsymbol{\mathbf{\hat z_1}},\dots,\boldsymbol{\mathbf{\hat z_N}}\}\)</span>.</p>
<hr />
<h4 class="unnumbered" data-number="7.2" id="app:scalability">Performance of the algorithms</h4>
<p>In this section, we further explore and discuss the computational
efficiency of the estimation algorithms under a variety of scenarios
illustrated in the following:</p>
<ul>
<li><p><em>Homogeneous data (<span class="math inline">\(G = 1\)</span>)</em>. When the data is homogeneous, the
Algorithm <a href="#alg:full" data-reference-type="ref" data-reference="alg:full">1</a>
performs efficiently even for large sample sizes <span class="math inline">\(N\)</span> (see Table
<a href="#tab:T4" data-reference-type="ref" data-reference="largeN">4</a>). This is
because the typical computational challenges associated to the MLE
of <span class="math inline">\(\boldsymbol{\mathbf{\rho}}\)</span> (the consensus ranking) with other
distance specification in the MM are eliminated. In fact, with
Spearman distance the problem simplifies to the straightforward
application of the Borda rank aggregation method, where items are
ranked based on their sample average rank. This closed-form solution
avoids the need of time consuming iterative estimation procedures
and multiple initializations for addressing issues of local optima.
This is a major advantage over existing R packages, which rely on
global or local search methods that quickly become computationally
prohibitive as <span class="math inline">\(n\)</span> increases. Concerning the MLE of <span class="math inline">\(\theta\)</span> (the
dispersion parameter), we recall that this step relates to <span class="math inline">\(N\)</span>
through the sample average Spearman distance, whose computation is
optimized with the use of an internal C++ routine called from the
<strong>BayesMallows</strong> package. Moreover, the analytical approximation of
the expected Spearman distance proposed by <span class="citation" data-cites="crispino23efficient">(<a href="#ref-crispino23efficient" role="doc-biblioref">Crispino et al. 2023</a>)</span>,
and implemented in <strong>MSmix</strong>, improves the computational efficiency
for the MLE of <span class="math inline">\(\theta\)</span>, particularly for large <span class="math inline">\(n\)</span>.</p>
<div id="largeN">
<table style="width:90%;">
<caption><span id="tab:T4">Table 4: </span> Computational times (seconds) of Algorithm
<a href="#alg:full" data-reference-type="ref" data-reference="alg:full">1</a> applied
on rankings of <span class="math inline">\(n=20\)</span> items sampled from a MMS with increasing
sample size <span class="math inline">\(N\)</span>.</caption>
<colgroup>
<col style="width: 15%" />
<col style="width: 11%" />
<col style="width: 9%" />
<col style="width: 9%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><span class="math inline">\(N\)</span></th>
<th style="text-align: left;">500</th>
<th style="text-align: left;">1000</th>
<th style="text-align: left;">5000</th>
<th style="text-align: left;">10000</th>
<th style="text-align: left;">20000</th>
<th style="text-align: left;">50000</th>
<th style="text-align: left;">1e+05</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">time (s)</td>
<td style="text-align: left;">0.009</td>
<td style="text-align: left;">0.01</td>
<td style="text-align: left;">0.08</td>
<td style="text-align: left;">0.29</td>
<td style="text-align: left;">1.04</td>
<td style="text-align: left;">8.3</td>
<td style="text-align: left;">54.56</td>
</tr>
</tbody>
</table>
</div></li>
<li><p><em>Heterogeneous data (<span class="math inline">\(G &gt; 1\)</span>)</em>. as <span class="math inline">\(G\)</span> increases, the computational
burden naturally grows since the EM algorithm must iteratively
estimate both the cluster-specific parameters and the individual
cluster membership probabilities. However, Algorithm
<a href="#alg:full_mixture" data-reference-type="ref" data-reference="alg:full_mixture">2</a> maintains efficiency by leveraging the
Borda method for estimating the cluster-specific consensus rankings,
significantly simplifying a critical step in the clustering process.
Nevertheless, since clustering involves iterative updates, our
package optimizes the E- and M-steps to ensure computational
efficiency, even in large <span class="math inline">\(N\)</span> and <span class="math inline">\(G\)</span> scenarios, as shown in Table
<a href="#tab:T5" data-reference-type="ref" data-reference="largeG">5</a>. Let us also
add that, in general, more complex problems - such as when clusters
are less distinct - require a great number of initializations to
reliably reach the global optimum. The number of starting points is
controlled by the argument <code>n_start</code> of the <code>fitMSmix</code> function and
a parallelization of the EM algorithm over multiple initializations
is also possible thanks to the <code>parallel</code> argument. These options
enlarge the applicability and efficiency of MMS-mixtures, and reduce
computational time by improving the exploration of the mixed-type
parameter space for increasing <span class="math inline">\(G\)</span>.</p>
<div id="largeG">
<table style="width:61%;">
<caption><span id="tab:T5">Table 5: </span> Computational times (seconds) of Algorithm
<a href="#alg:full_mixture" data-reference-type="ref" data-reference="alg:full_mixture">2</a> running with 10 starting points on
<span class="math inline">\(N=5000\)</span> rankings of <span class="math inline">\(n=20\)</span> items sampled from a MMS-mix with
increasing number <span class="math inline">\(G\)</span> of clusters.</caption>
<colgroup>
<col style="width: 15%" />
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 9%" />
<col style="width: 9%" />
<col style="width: 9%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><span class="math inline">\(G\)</span></th>
<th style="text-align: center;">5</th>
<th style="text-align: center;">10</th>
<th style="text-align: center;">15</th>
<th style="text-align: center;">30</th>
<th style="text-align: center;">60</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">time (s)</td>
<td style="text-align: center;">3.1</td>
<td style="text-align: center;">4.6</td>
<td style="text-align: center;">15.8</td>
<td style="text-align: center;">27.1</td>
<td style="text-align: center;">47.6</td>
</tr>
</tbody>
</table>
</div></li>
<li><p><em>Big data scenarios</em>. In the context of ranking data, “big data”
typically refers to cases with a large number of items (<span class="math inline">\(n\)</span>) and a
small sample size (<span class="math inline">\(N\)</span>), where the primary focus is on rank
aggregation. Even in such cases, Algorithm
<a href="#alg:full" data-reference-type="ref" data-reference="alg:full">1</a> remains
efficient (see Table <a href="#tab:T6" data-reference-type="ref" data-reference="bigdata">6</a>). For extremely large <span class="math inline">\(n\)</span>, the main
computational challenge is the computation of the partition function
which, in our implementation, relies on the approximation of the
frequency distribution of the Spearman distance among <span class="math inline">\(n\)</span>-rankings
(provided by the <code>spear_dist_distr</code> function in the package). When
<span class="math inline">\(n&gt;170\)</span>, the function returns an approximation restricted over a
fixed grid of values for the Spearman distance to limit both the
computational and memory load.</p>
<div id="bigdata">
<table style="width:65%;">
<caption><span id="tab:T6">Table 6: </span> Computational times (seconds) of Algorithm
<a href="#alg:full" data-reference-type="ref" data-reference="alg:full">1</a> applied
on <span class="math inline">\(N=200\)</span> rankings sampled from a MMS with increasing number <span class="math inline">\(n\)</span>
of items.</caption>
<colgroup>
<col style="width: 15%" />
<col style="width: 9%" />
<col style="width: 9%" />
<col style="width: 9%" />
<col style="width: 9%" />
<col style="width: 11%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><span class="math inline">\(n\)</span></th>
<th style="text-align: center;">200</th>
<th style="text-align: center;">500</th>
<th style="text-align: center;">1000</th>
<th style="text-align: center;">5000</th>
<th style="text-align: center;">10000</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">time (s)</td>
<td style="text-align: center;">2.74</td>
<td style="text-align: center;">2.58</td>
<td style="text-align: center;">3.38</td>
<td style="text-align: center;">3.66</td>
<td style="text-align: center;">3.9</td>
</tr>
</tbody>
</table>
</div></li>
</ul>
<h4 class="unnumbered" data-number="7.3" id="app:censoring_beers">Empirical evaluation of the MAR assumption for a subsample of the Beers dataset</h4>
<p>In the reduced Beers dataset used in our application, 18 respondents
(39%) provided full rankings, while 28 (61%) ranked only a subset of the
alternatives.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>  R<span class="sc">&gt;</span> n_items <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>  R<span class="sc">&gt;</span> rankings <span class="ot">&lt;-</span> ranks_beers[,<span class="dv">1</span><span class="sc">:</span>n_items]</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>  R<span class="sc">&gt;</span> subset_beers <span class="ot">&lt;-</span> (<span class="fu">rowSums</span>(<span class="fu">is.na</span>(rankings)) <span class="sc">&lt;=</span> <span class="dv">8</span>)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>  R<span class="sc">&gt;</span> rankings_subset <span class="ot">&lt;-</span> rankings[subset_beers,]</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>  R<span class="sc">&gt;</span> is_partial <span class="ot">&lt;-</span> <span class="fu">rowSums</span>(<span class="fu">is.na</span>(rankings_subset))<span class="sc">&gt;</span><span class="dv">1</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>  R<span class="sc">&gt;</span> <span class="fu">cbind</span>(<span class="at">Freq =</span> <span class="fu">table</span>(is_partial), <span class="st">&#39;\%&#39;</span> <span class="ot">=</span> <span class="fu">round</span>(<span class="dv">100</span><span class="sc">*</span><span class="fu">prop.table</span>(<span class="fu">table</span>(is_partial))))</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>       Freq  \%</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>  <span class="cn">FALSE</span>   <span class="dv">18</span> <span class="dv">39</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>  <span class="cn">TRUE</span>    <span class="dv">28</span> <span class="dv">61</span></span></code></pre></div>
<p>Notably, although the survey design did not require respondents to
prioritize their most liked items, the incomplete rankings exhibit a
clear top-like censoring pattern, as highlighted by the higher rate of
missingness for bottom positions.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>  R<span class="sc">&gt;</span> rankings_subset_part <span class="ot">&lt;-</span> rankings_subset[is_partial,]</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>  R<span class="sc">&gt;</span> orderings_subset_part <span class="ot">&lt;-</span> <span class="fu">data_conversion</span>(rankings_subset_part)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>  R<span class="sc">&gt;</span> na_perc_by_rank <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="dv">100</span><span class="sc">*</span><span class="fu">colMeans</span>(<span class="fu">is.na</span>(orderings_subset_part)),<span class="dv">1</span>)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>  R<span class="sc">&gt;</span> <span class="fu">names</span>(na_perc_by_rank) <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">&quot;Rank&quot;</span>, <span class="dv">1</span><span class="sc">:</span>n_items)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>  R<span class="sc">&gt;</span> na_perc_by_rank</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>   Rank <span class="dv">1</span>  Rank <span class="dv">2</span>  Rank <span class="dv">3</span>  Rank <span class="dv">4</span>  Rank <span class="dv">5</span>  Rank <span class="dv">6</span>  Rank <span class="dv">7</span>  Rank <span class="dv">8</span>  Rank <span class="dv">9</span> Rank <span class="dv">10</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>      <span class="fl">7.1</span>     <span class="fl">7.1</span>     <span class="fl">3.6</span>     <span class="fl">3.6</span>     <span class="fl">3.6</span>     <span class="fl">7.1</span>     <span class="fl">7.1</span>    <span class="fl">14.3</span>     <span class="fl">3.6</span>     <span class="fl">7.1</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>  Rank <span class="dv">11</span> Rank <span class="dv">12</span> Rank <span class="dv">13</span> Rank <span class="dv">14</span> Rank <span class="dv">15</span> Rank <span class="dv">16</span> Rank <span class="dv">17</span> Rank <span class="dv">18</span> Rank <span class="dv">19</span> Rank <span class="dv">20</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>     <span class="fl">28.6</span>    <span class="fl">32.1</span>    <span class="fl">35.7</span>    <span class="fl">39.3</span>    <span class="fl">42.9</span>    <span class="fl">50.0</span>    <span class="fl">53.6</span>    <span class="fl">46.4</span>    <span class="fl">46.4</span>    <span class="fl">46.4</span></span></code></pre></div>
<p>In the case of top-<span class="math inline">\(k\)</span> rankings, missing data could be significantly
related to lower preferences, suggesting a Missing Not At Random (MNAR)
process. To assess a possible critical deviation from the assumed MAR
mechanism, we checked whether items which are more frequently missing in
partial sequences systematically receive lower preferences from
respondents who provided full rankings. Specifically, we explored the
relationship between the average ranks resulting from the complete
rankings and the missingness rate of each item in the partial rankings.
The code below shows that, thanks to descriptive tools supplied by
<strong>MSmix</strong> designed to facilitate a focused analysis of subsamples, the
computation of these quantities is straightforward.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>  R<span class="sc">&gt;</span> descr_full<span class="ot">=</span><span class="fu">data_description</span>(rankings_subset,<span class="at">subset=</span><span class="sc">!</span>is_partial)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>  R<span class="sc">&gt;</span> descr_part<span class="ot">=</span><span class="fu">data_description</span>(rankings_subset,<span class="at">subset=</span>is_partial)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>  R<span class="sc">&gt;</span> na_prop_part_by_item <span class="ot">&lt;-</span> descr_part\<span class="sc">$</span>n_ranks_by_item[<span class="dv">1</span>,]<span class="sc">/</span><span class="fu">nrow</span>(rankings_subset_part)</span></code></pre></div>
<p>The relationship was first evaluated through a graphical inspection as
follows.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>  R<span class="sc">&gt;</span> <span class="fu">plot</span>(na_prop_part_by_item, descr_full\<span class="sc">$</span>mean_rank,</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>       <span class="at">xlab=</span><span class="st">&quot;Missingness proportion in partial rankings&quot;</span>,</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>       <span class="at">ylab=</span><span class="st">&quot;Mean rank from full rankings&quot;</span>,</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>       <span class="at">cex.lab=</span><span class="fl">0.9</span>, <span class="at">pch=</span><span class="dv">20</span>)</span></code></pre></div>
<figure id="fig:scat_beers">
<img src="figures/RJ2025_paper_scatter_beers.png" style="width:100.0%" alt="graphic without alt text" />
<figcaption>Figure 8: Relationship between the missingness proportion of the items
in the partial rankings and their mean ranks from full rankings for the
reduced <code>ranks_beers</code>
dataset.</figcaption>
</figure>
<p>The scatterplot in the Figure <a href="#fig:scat_beers" data-reference-type="ref" data-reference="fig:scat_beers">8</a> does not reveal a clear association pattern.
To formally assess this, we performed a rank-correlation test<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> as
follows</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>  R<span class="sc">&gt;</span> <span class="fu">library</span>(coin)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>  R<span class="sc">&gt;</span> test_df<span class="ot">=</span><span class="fu">data.frame</span>(<span class="at">NaProp=</span>na_prop_part_by_item, <span class="at">AvgRank=</span>descr_full\<span class="sc">$</span>mean_rank)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>  R<span class="sc">&gt;</span> perm_test <span class="ot">&lt;-</span> <span class="fu">spearman_test</span>(AvgRank <span class="sc">~</span> NaProp, <span class="at">data =</span> test_df,</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>                               <span class="at">distribution =</span> <span class="fu">approximate</span>(<span class="at">nresample =</span> <span class="dv">10000</span>))</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>  R<span class="sc">&gt;</span> perm_test</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>    Approximative Spearman Correlation Test</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>  data<span class="sc">:</span>  AvgRank by NaProp</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>  Z <span class="ot">=</span> <span class="sc">-</span><span class="fl">0.18296</span>, p<span class="sc">-</span>value <span class="ot">=</span> <span class="fl">0.8603</span></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>  alternative hypothesis<span class="sc">:</span> true rho is not equal to <span class="dv">0</span></span></code></pre></div>
<p>The resulting <span class="math inline">\(p\)</span>-value is well above the conventional 0.05 threshold,
indicating no statistically significant evidence against the MAR
assumption.</p>
<p>:::::::</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<h3 class="appendix" data-number="8" id="note"><span class="header-section-number">8</span> Note</h3>
<p>This article is converted from a Legacy LaTeX article using the
<a href="https://cran.r-project.org/package=texor">texor</a> package.
The pdf version is the official version. To report a problem with the html,
refer to CONTRIBUTE on the R Journal homepage.</p>
</div>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-AlvoYu2014" class="csl-entry" role="listitem">
M. Alvo and P. L. H. Yu. <em>Statistical methods for ranking data.</em> New York, USA: Springer, 2014.
</div>
<div id="ref-beckett93maximum" class="csl-entry" role="listitem">
L. A. Beckett. Maximum likelihood estimation in <span>Mallows</span>’s model using partially ranked data. In <em>Probability models and statistical analyses for ranking data</em>, Eds M. A. Fligner and J. S. Verducci pages. 92–107 1993. Springer New York.
</div>
<div id="ref-bradley1952rank" class="csl-entry" role="listitem">
R. A. Bradley and M. E. Terry. <span class="nocase">Rank Analysis of Incomplete Block Designs: I. The Method of Paired Comparisons</span>. <em>Biometrika</em>, 39(3/4): 324–345, 1952.
</div>
<div id="ref-crispinoMoE" class="csl-entry" role="listitem">
M. Crispino, L. Modugno and L. Mollica. The <span>Mallows</span> model with respondents’ covariates for the analysis of preference rankings. In <em>Proceedings of the SDS 2024 conference</em>, 2024. ISBN 978-88-5509-645-4.
</div>
<div id="ref-crispino23efficient" class="csl-entry" role="listitem">
M. Crispino, C. Mollica, V. Astuti and L. Tardella. Efficient and accurate inference for mixtures of <span>Mallows</span> models with spearman distance. <em>Statistics and Computing</em>, 98(33): 2023.
</div>
<div id="ref-critchlow85metric" class="csl-entry" role="listitem">
D. E. Critchlow. <em>Metric methods for analyzing partially ranked data.</em> Lecture Notes in Statistics No. 34, Springer New York, 1985.
</div>
<div id="ref-critchlow91probability" class="csl-entry" role="listitem">
D. E. Critchlow, M. A. Fligner and J. S. Verducci. Probability <span>M</span>odels on <span>R</span>ankings. <em>Journal of Mathematical Psychology</em>, 35(3): 294–318, 1991.
</div>
<div id="ref-Diaconis1988" class="csl-entry" role="listitem">
P. Diaconis. <em>Group representations in probability and statistics.</em> Hayward, USA: Institute of Mathematical Statistics, 1988.
</div>
<div id="ref-efron82boot" class="csl-entry" role="listitem">
B. Efron. <em><span class="nocase">The Jackknife, the Bootstrap and Other Resampling Plans</span>.</em> Philadelphia, USA: SIAM, 1982.
</div>
<div id="ref-gormley2008mixture" class="csl-entry" role="listitem">
I. C. Gormley and T. B. Murphy. A <span>M</span>ixture of <span>E</span>xperts <span>M</span>odel for <span>R</span>ank <span>D</span>ata with <span>A</span>pplications in <span>E</span>lection <span>S</span>tudies. <em>The Annals of Applied Statistics</em>, 2(4): 1452–1477, 2008.
</div>
<div id="ref-gormley2006analysis" class="csl-entry" role="listitem">
I. C. Gormley and T. B. Murphy. Analysis of <span>I</span>rish <span>T</span>hird-<span>L</span>evel <span>C</span>ollege <span>A</span>pplications <span>D</span>ata. <em>Journal of the Royal Statistical Society A</em>, 169(2): 361–379, 2006.
</div>
<div id="ref-rmallow" class="csl-entry" role="listitem">
E. Gregory. <em>RMallow: Fit multi-modal <span>Mallows</span>’ models to ranking data.</em> 2020. URL <a href="https://CRAN.R-project.org/package=RMallow">https://CRAN.R-project.org/package=RMallow</a>. R package version 1.1.
</div>
<div id="ref-prefmod2012" class="csl-entry" role="listitem">
R. Hatzinger and R. Dittrich. <span class="nocase"><span class="nocase">prefmod</span>: An <span>R</span> Package for Modeling Preferences Based on Paired Comparisons, Rankings, or Ratings</span>. <em><span>Journal of Statistical Software</span></em>, 48(10): 1–31, 2012. URL <a href="https://www.jstatsoft.org/v48/i10/">https://www.jstatsoft.org/v48/i10/</a>.
</div>
<div id="ref-prefmod.package" class="csl-entry" role="listitem">
R. Hatzinger and M. J. Maier. <em><span class="nocase"><span class="nocase">prefmod</span>: Utilities to Fit Paired Comparison Models for Preferences</span>.</em> 2023. URL <a href="https://CRAN.R-project.org/package=prefmod">https://CRAN.R-project.org/package=prefmod</a>. <span>R package version 0.8-36</span>.
</div>
<div id="ref-jacobs" class="csl-entry" role="listitem">
R. A. Jacobs, M. I. Jordan, S. J. Nowlan and G. E. Hinton. Adaptive <span>M</span>ixtures of <span>L</span>ocal <span>E</span>xperts. <em>Neural <span>C</span>omputation</em>, 3(1): 79–87, 1991.
</div>
<div id="ref-Jacques2014" class="csl-entry" role="listitem">
J. Jacques and C. Biernacki. Model-<span>B</span>ased <span>C</span>lustering for <span>M</span>ultivariate <span>P</span>artial <span>R</span>anking <span>D</span>ata. <em>Journal of Statistical Planning and Inference</em>, 149: 201–217, 2014.
</div>
<div id="ref-Rankcluster" class="csl-entry" role="listitem">
J. Jacques, Q. Grimonprez and C. Biernacki. Rankcluster: An <span>R</span> <span>P</span>ackage for <span>C</span>lustering <span>M</span>ultivariate <span>P</span>artial <span>R</span>ankings. <em>The R Journal</em>, 6(1): 101–110, 2014.
</div>
<div id="ref-jordan" class="csl-entry" role="listitem">
M. I. Jordan and R. A. Jacobs. Hierarchical <span>M</span>ixtures of <span>E</span>xperts and the EM <span>A</span>lgorithm. <em>Neural <span>C</span>omputation</em>, 6(2): 181–214, 1994.
</div>
<div id="ref-pmr_R" class="csl-entry" role="listitem">
P. H. Lee and P. L. H. Yu. <span class="nocase">An R Package for Analyzing and Modeling Ranking Data</span>. <em>BMC Medical Research Methodology</em>, 3(1): 1–11, 2013.
</div>
<div id="ref-lee2012mixtures" class="csl-entry" role="listitem">
P. H. Lee and P. L. H. Yu. Mixtures of <span>W</span>eighted <span>D</span>istance-<span>B</span>ased <span>M</span>odels for <span>R</span>anking <span>D</span>ata with <span>A</span>pplications in <span>P</span>olitical <span>S</span>tudies. <em>Computational Statistics &amp; Data Analysis</em>, 56(8): 2486–2500, 2012.
</div>
<div id="ref-EMMjasa" class="csl-entry" role="listitem">
H. Li, M. Xu, J. S. Liu and X. Fan. An extended <span>Mallows</span> model for ranked data aggregation. <em>Journal of the American Statistical Association</em>, 115(530): 730–746, 2020.
</div>
<div id="ref-extmallows" class="csl-entry" role="listitem">
H. Li, M. Xu, J. S. Liu and X. Fan. <em><span>ExtMallows</span>: An extended <span>Mallows</span> model and its hierarchical version for ranked data aggregation.</em> 2018. URL <a href="https://CRAN.R-project.org/package=ExtMallows">https://CRAN.R-project.org/package=ExtMallows</a>. R package version 0.1.0.
</div>
<div id="ref-little2011calibrated" class="csl-entry" role="listitem">
R. Little. <span class="nocase">Calibrated <span>B</span>ayes, for Statistics in General, and Missing Data in Particular</span>. <em>Statistical Science</em>, 26(2): 162–174, 2011.
</div>
<div id="ref-little2019statistical" class="csl-entry" role="listitem">
R. J. Little and D. B. Rubin. <em><span class="nocase">Statistical Analysis with Missing Data</span>.</em> John Wiley &amp; Sons, 2019.
</div>
<div id="ref-Liu2019" class="csl-entry" role="listitem">
Q. Liu, M. Crispino, I. Scheel, V. Vitelli and A. Frigessi. <span class="nocase">Model-Based Learning from Preference Data</span>. <em>Annual Review of Statistics and Its Application</em>, 6(1): 329–354, 2019. DOI <a href="https://doi.org/10.1146/annurev-statistics-031017-100213">10.1146/annurev-statistics-031017-100213</a>.
</div>
<div id="ref-Luce1959" class="csl-entry" role="listitem">
R. D. Luce. <em><span>Individual Choice Behavior: A Theoretical Analysis</span>.</em> New York, USA: Wiley, 1959.
</div>
<div id="ref-Mallows1957" class="csl-entry" role="listitem">
C. L. Mallows. <span>Non-Null Ranking Models. <span>I</span></span>. <em>Biometrika</em>, 44(1/2): 114–130, 1957.
</div>
<div id="ref-Marden1995" class="csl-entry" role="listitem">
J. I. Marden. <em>Analyzing and modeling rank data.</em> Chapman &amp; Hall, 1995.
</div>
<div id="ref-mclachan2000" class="csl-entry" role="listitem">
G. Mclachlan and D. Peel. <em>Finite mixture models.</em> New York: Wiley, 2000.
</div>
<div id="ref-mollica2017bayesian" class="csl-entry" role="listitem">
C. Mollica and L. Tardella. <span class="nocase">Bayesian Plackett-Luce Mixture Models for Partially Ranked Data</span>. <em>Psychometrika</em>, 82(2): 442–458, 2017.
</div>
<div id="ref-mollica2020plmix" class="csl-entry" role="listitem">
C. Mollica and L. Tardella. <span class="nocase">PLMIX: An R Package for Modelling and Clustering Partially Ranked Data</span>. <em>Journal of Statistical Computation and Simulation</em>, 90(5): 925–959, 2020.
</div>
<div id="ref-MurphyMartin2003" class="csl-entry" role="listitem">
T. B. Murphy and D. Martin. <span class="nocase">Mixtures of Distance-Based Models for Ranking Data</span>. <em>Computational Statistics &amp; Data Analysis</em>, 41(3–4): 645–655, 2003.
</div>
<div id="ref-piancastelli" class="csl-entry" role="listitem">
L. S. Piancastelli and N. Friel. The clustered <span>Mallows</span> model. <em>Statistics and Computing</em>, 35(1): 21, 2025.
</div>
<div id="ref-piancastelli2025time" class="csl-entry" role="listitem">
L. Piancastelli and W. Barreto-Souza. Time series analysis of rankings: A GARCH-type approach. 2025. arXiv preprint arXiv:2502.05102.
</div>
<div id="ref-Plackett1975" class="csl-entry" role="listitem">
R. L. Plackett. <span class="nocase">The Analysis of Permutations</span>. <em>Journal of the Royal Statistical Society C</em>, 24(2): 193–202, 1975.
</div>
<div id="ref-rankdist" class="csl-entry" role="listitem">
Z. Qian and P. L. H. Yu. <span class="nocase">Weighted Distance-Based Models for Ranking Data Using the <span>R</span> Package <span class="nocase">rankdist</span></span>. <em>Journal of Statistical Software</em>, 90(5): 1–31, 2019.
</div>
<div id="ref-rubin1976inference" class="csl-entry" role="listitem">
D. B. Rubin. <span class="nocase">Inference and Missing Data</span>. <em>Biometrika</em>, 63(3): 581–592, 1976.
</div>
<div id="ref-BayesMallows" class="csl-entry" role="listitem">
Øystein Sørensen, M. Crispino, Q. Liu and V. Vitelli. <span class="nocase">BayesMallows: An R Package for the Bayesian Mallows Model</span>. <em><span>The R Journal</span></em>, 12(1): 324–342, 2020.
</div>
<div id="ref-soufiani" class="csl-entry" role="listitem">
H. A. Soufiani and W. Chen. <em>StatRank: Statistical rank aggregation: Inference, evaluation, and visualization.</em> 2015. URL <a href="https://CRAN.R-project.org/package=StatRank">https://CRAN.R-project.org/package=StatRank</a>. R package version 0.0.6.
</div>
<div id="ref-taushanov2019bootstrap" class="csl-entry" role="listitem">
Z. Taushanov and A. Berchtold. Bootstrap validation of the estimated parameters in mixture models used for clustering. <em>Journal de la Soci<span>é</span>t<span>é</span> Fran<span>ç</span>aise de Statistique</em>, 160(1): 114–129, 2019.
</div>
<div id="ref-thurstone27law" class="csl-entry" role="listitem">
L. L. Thurstone. <span class="nocase">A Law of Comparative Judgment</span>. <em>Psychological Review</em>, 34(4): 273–286, 1927. DOI <a href="https://doi.org/10.1037/h0070288">10.1037/h0070288</a>.
</div>
<div id="ref-turner2020" class="csl-entry" role="listitem">
H. L. Turner, J. van Etten, D. Firth and I. Kosmidis. <span class="nocase">Modelling Rankings in <span>R</span>: the <span>PlackettLuce</span> package</span>. <em>Computational Statistics</em>, 35: 1027–1057, 2020. URL <a href="https://doi.org/10.1007/s00180-020-00959-3">https://doi.org/10.1007/s00180-020-00959-3</a>.
</div>
<div id="ref-wei_tanner" class="csl-entry" role="listitem">
G. C. G. Wei and M. A. Tanner. A <span>Monte Carlo</span> implementation of the <span>EM</span> algorithm and the poor man’s data augmentation algorithms. <em>Journal of the American Statistical Association</em>, 85(411): 699–704, 1990.
</div>
<div id="ref-ggplot" class="csl-entry" role="listitem">
H. Wickham. <em>ggplot2: Elegant graphics for data analysis.</em> Springer-Verlag New York, 2016. URL <a href="https://ggplot2.tidyverse.org">https://ggplot2.tidyverse.org</a>.
</div>
<div id="ref-zhong2021mallows" class="csl-entry" role="listitem">
C. Zhong. <span>Mallows</span> permutation models with <span class="math inline">\({L}^1\)</span> and <span class="math inline">\({L}^2\)</span> distances <span>I</span>: Hit and run algorithms and mixing times. 2021. arXiv preprint arXiv:2112.13456.
</div>
<div id="ref-zhu21partition" class="csl-entry" role="listitem">
W. Zhu, Y. Jiang, J. S. Liu and K. Deng. Partition–<span>Mallows</span> model and its inference for rank aggregation. <em>Journal of the American Statistical Association</em>, 118(541): 343–359, 2021.
</div>
</div>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Note that for a better account of sampling variability and
exploration of the parameter space, the MCEM algorithm works at the
level of the single observed units, indexed by <span class="math inline">\(s=1,\dots,N\)</span>,
instead of the aggregated data
<span class="math inline">\((\boldsymbol{\mathbf{r_l, N_l}})_{l=1,\dots,L}\)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>For full rankings and a single mixture component, the <strong>MSmix</strong>
package also offers the parametric bootstrap method, where each
simulated sample <span class="math inline">\(\underline{\boldsymbol{\mathbf{r}}}^{(b)}\)</span> is
obtained by randomly sampling from the fitted MMS rather than from
the observed data.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>The antifragility properties reflect a company’s ability to not
only adapt but also improve its activity and grow in response to
stressors, volatility and disorders caused by critical and
unexpected events.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Recall that a partial sequence with <span class="math inline">\((n-1)\)</span> observed entries
corresponds to a full ranking.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>These correspond to the sets
<span class="math inline">\(\mathcal{C}(\boldsymbol{\mathbf{r}})\)</span> introduced in Section 2.2.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>These sequences correspond to the result of data completion from
the MC step described in Section 2.2.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>The concentration parameters play a delicate role. In fact, if
<span class="math inline">\(\theta\)</span> is too close to zero, the MMS turns out to be
indistinguishable from the uniform distribution on <span class="math inline">\(\mathcal{P}_n\)</span>,
while if <span class="math inline">\(\theta\)</span> is too large the MMS distribution would tend to a
Dirac on the consensus ranking <span class="math inline">\(\boldsymbol{\mathbf{\rho}}\)</span>. The
critical magnitude turns out to be <span class="math inline">\(\theta\sim c/n^2\)</span> with <span class="math inline">\(c &gt; 0\)</span>
fixed <span class="citation" data-cites="zhong2021mallows">(<a href="#ref-zhong2021mallows" role="doc-biblioref">Zhong 2021</a>)</span>.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>The maximum Spearman distance among two rankings of a given length
<span class="math inline">\(n\)</span> is equal to <span class="math inline">\(2\binom{n+1}{3}\)</span>.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>Notably, the <code>plot.dist</code> function of <strong>MSmix</strong> fills in the gap of
a generic method for objects of class <code>"dist"</code> in R,
since it allows to visualize, and hence compare, distance matrices
of any metric.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>Note that exact reproducibility of this section may not be
possible due to the use of parallelization, which can lead to minor
variations in inferential results between runs.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>This type of data augmentation is supported for up to 10 missing
positions in the partial rankings. However, it is important to note
that while this operation may be feasible in principle for some
datasets, it can be slow and memory-intensive. For instance,
augmenting and storing all rankings compatible with the subset of
the beers dataset with a maximum of 10 missing positions requires
more than 3GB of storage space.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>We opted for the permutation test based on the Spearman
correlation, as it is nonparametric and allows to better captures
monotonic relationships in the case of small samples and ties
occurring after rank-transformation.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
<h3 id="references">References</h3>
<div id="references-listing"></div>
<h3 id="reuse">Reuse</h3>
<p>Text and figures are licensed under Creative Commons Attribution <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>. The figures that have been reused from other sources don't fall under this license and can be recognized by a note in their caption: "Figure from ...".</p>
<h3 id="citation">Citation</h3>
<p>For attribution, please cite this work as</p>
<pre class="citation-appendix short">Crispino, et al., "MSmix: An R Package for clustering partial rankings via mixtures of Mallows Models with Spearman distance", The R Journal, 2025</pre>
<p>BibTeX citation</p>
<pre class="citation-appendix long">@article{RJ-2025-020,
  author = {Crispino, Marta and Mollica, Cristina and Modugno, Lucia},
  title = {MSmix: An R Package for clustering partial rankings via mixtures of Mallows Models with Spearman distance},
  journal = {The R Journal},
  year = {2025},
  note = {https://doi.org/10.32614/RJ-2025-020},
  doi = {10.32614/RJ-2025-020},
  volume = {17},
  issue = {2},
  issn = {2073-4859},
  pages = {206-230}
}</pre>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
