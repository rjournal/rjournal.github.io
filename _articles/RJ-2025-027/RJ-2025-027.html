<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { color: #00769e; background-color: #f1f3f5; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #00769e; } /* Normal */
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #657422; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #00769e; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #00769e; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #00769e; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #5e5e5e; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

<style>
  div.csl-bib-body { }
  div.csl-entry {
    clear: both;
      margin-bottom: 0em;
    }
  .hanging div.csl-entry {
    margin-left:2em;
    text-indent:-2em;
  }
  div.csl-left-margin {
    min-width:2em;
    float:left;
  }
  div.csl-right-inline {
    margin-left:2em;
    padding-left:1em;
  }
  div.csl-indent {
    margin-left: 2em;
  }
</style>

  <!--radix_placeholder_meta_tags-->
  <title>Rgof and R2sample: Testing and Benchmarking for the Univariate Goodness-of-Fit and Two-Sample Problems</title>

  <meta property="description" itemprop="description" content="In a goodness-of-fit problem one attempts to see whether a data set&#10;might have been generated by some theoretical probability&#10;distribution, possibly with unknown parameters. In a (non-parametric)&#10;two-sample problem one wants to check whether two data sets could have&#10;come from the same unspecified distribution. Both are among the oldest&#10;and best studied problems in Statistics. While they seem quite&#10;different, there are a number of similarities between these problems,&#10;not the least of which is that many methods exist that have versions&#10;for both. The two packages discussed in this article bring together a&#10;large number of methods and many different scenarios, most of which do&#10;not yet have existing implementations. They also include routines that&#10;allow a developer of a new method to quickly compare its performance&#10;(aka power) to those included in the package for a large number of&#10;cases."/>

  <link rel="license" href="https://creativecommons.org/licenses/by/4.0/"/>

  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2025-10-21"/>
  <meta property="article:created" itemprop="dateCreated" content="2025-10-21"/>
  <meta name="article:author" content="Wolfgang Rolke"/>

  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Rgof and R2sample: Testing and Benchmarking for the Univariate Goodness-of-Fit and Two-Sample Problems"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="In a goodness-of-fit problem one attempts to see whether a data set&#10;might have been generated by some theoretical probability&#10;distribution, possibly with unknown parameters. In a (non-parametric)&#10;two-sample problem one wants to check whether two data sets could have&#10;come from the same unspecified distribution. Both are among the oldest&#10;and best studied problems in Statistics. While they seem quite&#10;different, there are a number of similarities between these problems,&#10;not the least of which is that many methods exist that have versions&#10;for both. The two packages discussed in this article bring together a&#10;large number of methods and many different scenarios, most of which do&#10;not yet have existing implementations. They also include routines that&#10;allow a developer of a new method to quickly compare its performance&#10;(aka power) to those included in the package for a large number of&#10;cases."/>
  <meta property="og:locale" content="en_US"/>

  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Rgof and R2sample: Testing and Benchmarking for the Univariate Goodness-of-Fit and Two-Sample Problems"/>
  <meta property="twitter:description" content="In a goodness-of-fit problem one attempts to see whether a data set&#10;might have been generated by some theoretical probability&#10;distribution, possibly with unknown parameters. In a (non-parametric)&#10;two-sample problem one wants to check whether two data sets could have&#10;come from the same unspecified distribution. Both are among the oldest&#10;and best studied problems in Statistics. While they seem quite&#10;different, there are a number of similarities between these problems,&#10;not the least of which is that many methods exist that have versions&#10;for both. The two packages discussed in this article bring together a&#10;large number of methods and many different scenarios, most of which do&#10;not yet have existing implementations. They also include routines that&#10;allow a developer of a new method to quickly compare its performance&#10;(aka power) to those included in the package for a large number of&#10;cases."/>

  <!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
  <meta name="citation_title" content="Rgof and R2sample: Testing and Benchmarking for the Univariate Goodness-of-Fit and Two-Sample Problems"/>
  <meta name="citation_fulltext_html_url" content="https://doi.org/10.32614/RJ-2025-027"/>
  <meta name="citation_pdf_url" content="RJ-2025-027.pdf"/>
  <meta name="citation_volume" content="17"/>
  <meta name="citation_issue" content="3"/>
  <meta name="citation_doi" content="10.32614/RJ-2025-027"/>
  <meta name="citation_journal_title" content="The R Journal"/>
  <meta name="citation_issn" content="2073-4859"/>
  <meta name="citation_firstpage" content="140"/>
  <meta name="citation_lastpage" content="163"/>
  <meta name="citation_fulltext_world_readable" content=""/>
  <meta name="citation_online_date" content="2025/10/21"/>
  <meta name="citation_publication_date" content="2025/10/21"/>
  <meta name="citation_author" content="Wolfgang Rolke"/>
  <meta name="citation_author_institution" content="University of Puerto Rico - Mayaguez"/>
  <!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=Nortest: Tests for normality;citation_author=J. Gross;citation_author=U. Ligges"/>
  <meta name="citation_reference" content="citation_title=ADGofTest: Anderson-darling GoF test;citation_author=C. J. Gil Bellosta"/>
  <meta name="citation_reference" content="citation_title=Dgof: Discrete goodness-of-fit tests;citation_publisher=None;citation_author=B. A. Taylor;citation_author=J. W. Emerson"/>
  <meta name="citation_reference" content="citation_title=EnvStats: Package for environmental statistics, including US EPA guidance;citation_publisher=None;citation_author=S. P. Millard;citation_author=A. K. Kowarik"/>
  <meta name="citation_reference" content="citation_title=Goftest: Classical goodness-of-fit tests for univariate distributions;citation_publisher=None;citation_author=J. Faraway;citation_author=G. Marsalia;citation_author=J. Marsalia;citation_author=A. Baddeley"/>
  <meta name="citation_reference" content="citation_title=Twosamples: Fast permutation based two sample tests;citation_publisher=None;citation_author=Connor Dowd"/>
  <meta name="citation_reference" content="citation_title=Rcpp: Seamless R and C++ integration;citation_author=Dirk Eddelbuettel;citation_author=Romain Francois;citation_author=JJ Allaire;citation_author=Kevin Ushey;citation_author=Qiang Kou;citation_author=Nathan Russell;citation_author=Inaki Ucar;citation_author=Douglas Bates;citation_author=John Chambers"/>
  <meta name="citation_reference" content="citation_title=R: A language and environment for statistical computing;citation_publisher=R Foundation for Statistical Computing;citation_author=R: A language and environment for statistical computing"/>
  <meta name="citation_reference" content="citation_title=Rgof: 1d goodness of fit tests;citation_publisher=None;citation_author=Wolfgang Rolke"/>
  <meta name="citation_reference" content="citation_title=R2sample: 1d two-sample tests;citation_publisher=None;citation_author=Wolfgang Rolke"/>
  <meta name="citation_reference" content="citation_title=Goodness-of-fit techniques;citation_publisher=Statistics: Textbooks; Monographs. Marcel Dekker;citation_author=R B D’Agostini;citation_author=M A Stephens"/>
  <meta name="citation_reference" content="citation_title=Das gesetz der kleinen zahlen;citation_publisher=Teubner;citation_author=L Bortkewitsch"/>
  <meta name="citation_reference" content="citation_title=The power to see: A new graphical test of normality;citation_volume=67;citation_author=Sivan Aldor-Noima;citation_author=Lawrence D. Brown;citation_author=Andreas Buja;citation_author=Robert A. Stine;citation_author=Wolfgang Rolke"/>
  <meta name="citation_reference" content="citation_title=Asymptotic theory of certain goodness-of-fit criteria based on stochastic processes;citation_volume=23;citation_author=T W Anderson;citation_author=D A Darling"/>
  <meta name="citation_reference" content="citation_title=On the distribution of the two-sample Cramer-von Mises criterion;citation_volume=33;citation_author=T W Anderson"/>
  <meta name="citation_reference" content="citation_title=Minimum chi-square, not maximum likelihood;citation_volume=8;citation_author=J Berkson"/>
  <meta name="citation_reference" content="citation_title=Mathematical statistics vol 1 and 2;citation_publisher=CRC Press;citation_author=Peter J Bickel;citation_author=Kjell A Doksum"/>
  <meta name="citation_reference" content="citation_title=Statistical inference;citation_publisher=Duxbury Advanced Series in Statistics; Decision Sciences. Thomson Learning;citation_author=George Casella;citation_author=Robert Berger"/>
  <meta name="citation_reference" content="citation_title=On the composition of elementary errors;citation_volume=1;citation_author=H Cramer"/>
  <meta name="citation_reference" content="citation_title=On the interpretation of chi square from contingency tables, and the calculation of P.J.R.;citation_volume=85;citation_author=R A Fisher"/>
  <meta name="citation_reference" content="citation_title=The conditions under which chi square measures the discrepancy between observation and hypothesis;citation_volume=87;citation_author=R A Fisher"/>
  <meta name="citation_reference" content="citation_title=Sulla determinazione empirica di una legge di distribuzione;citation_volume=4;citation_author=A Kolmogorov"/>
  <meta name="citation_reference" content="citation_title=Tests concerning random points on a circle;citation_volume=63;citation_author=N H Kuiper"/>
  <meta name="citation_reference" content="citation_title=Consistency and unbiasedness of certain nonparametric tests;citation_volume=22(1);citation_author=E. L. Lehmann"/>
  <meta name="citation_reference" content="citation_title=A two-sample anderson-darling rank statistic;citation_volume=63 No.1;citation_author=A. N. Pettitt"/>
  <meta name="citation_reference" content="citation_title=Bortkewitsch’s horse-kicks and the generalised linear model;citation_volume=37;citation_author=D A Preece;citation_author=G J S Ross;citation_author=P J Kirby"/>
  <meta name="citation_reference" content="citation_title=Smooth tests of goodness of fit;citation_publisher=Wiley Sons;citation_author=J C Raynor;citation_author=Oliver Thas;citation_author=D J Best"/>
  <meta name="citation_reference" content="citation_title=Limit theorems associated with variants of the Von Mises statistic;citation_volume=23;citation_author=M. Rosenblatt"/>
  <meta name="citation_reference" content="citation_title=Estimate of deviation between empirical distribution functions in two independent samples;citation_volume=2;citation_author=N. V. Smirnov"/>
  <meta name="citation_reference" content="citation_title=Continuous distributions;citation_publisher=Springer Series in Statistics. Springer;citation_author=Oliver Thas"/>
  <meta name="citation_reference" content="citation_title=Wahrscheinlichkeit, statistik und wahrheit;citation_publisher=Springer;citation_author=R E Mises"/>
  <meta name="citation_reference" content="citation_title=Markov processes over denumerable products of spaces, describing large systems of automata;citation_volume=5(3);citation_author=L. N. Vaserstein"/>
  <meta name="citation_reference" content="citation_title=Goodness-of-fit tests on a circle;citation_volume=48;citation_author=G S Watson"/>
  <meta name="citation_reference" content="citation_title=Powerful goodness-of-fit tests based on likelihood ratio;citation_volume=64;citation_author=J Zhang"/>
  <meta name="citation_reference" content="citation_title=Powerful two-sample tests based on the likelihood ratio;citation_volume=48;citation_author=J. Zhang"/>
  <!--radix_placeholder_rmarkdown_metadata-->

  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","date_received","journal","volume","issue","slug","citation_url","packages","preview","bibliography","CTV","legacy_pdf","legacy_converted","output","draft","pdf_url","doi","creative_commons","csl"]}},"value":[{"type":"character","attributes":{},"value":["Rgof and R2sample: Testing and Benchmarking for the Univariate Goodness-of-Fit and Two-Sample Problems"]},{"type":"character","attributes":{},"value":["In a goodness-of-fit problem one attempts to see whether a data set\nmight have been generated by some theoretical probability\ndistribution, possibly with unknown parameters. In a (non-parametric)\ntwo-sample problem one wants to check whether two data sets could have\ncome from the same unspecified distribution. Both are among the oldest\nand best studied problems in Statistics. While they seem quite\ndifferent, there are a number of similarities between these problems,\nnot the least of which is that many methods exist that have versions\nfor both. The two packages discussed in this article bring together a\nlarge number of methods and many different scenarios, most of which do\nnot yet have existing implementations. They also include routines that\nallow a developer of a new method to quickly compare its performance\n(aka power) to those included in the package for a large number of\ncases.\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation","address"]}},"value":[{"type":"character","attributes":{},"value":["Wolfgang Rolke"]},{"type":"character","attributes":{},"value":["University of Puerto Rico - Mayaguez"]},{"type":"character","attributes":{},"value":["Department of Mathematical Sciences","Mayaguez, Puerto Rico, USA, 00681","*ORCiD: [0000-0002-3514-726X](https://orcid.org/0000-0002-3514-726X)*","[`wolfgang.rolke@upr.edu`](mailto:wolfgang.rolke@upr.edu)\n"]}]}]},{"type":"character","attributes":{},"value":["2025-10-21"]},{"type":"character","attributes":{},"value":["2025-02-12"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","issn","firstpage","lastpage"]}},"value":[{"type":"character","attributes":{},"value":["The R Journal"]},{"type":"character","attributes":{},"value":["2073-4859"]},{"type":"integer","attributes":{},"value":[140]},{"type":"integer","attributes":{},"value":[163]}]},{"type":"integer","attributes":{},"value":[17]},{"type":"integer","attributes":{},"value":[3]},{"type":"character","attributes":{},"value":["RJ-2025-027"]},{"type":"character","attributes":{},"value":["https://doi.org/10.32614/RJ-2025-027"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["cran","bioc"]}},"value":[{"type":"list","attributes":{},"value":[]},{"type":"list","attributes":{},"value":[]}]},{"type":"character","attributes":{},"value":["preview.png"]},{"type":"character","attributes":{},"value":["RgofR2sampleRolke.bib"]},{"type":"list","attributes":{},"value":[]},{"type":"logical","attributes":{},"value":[true]},{"type":"logical","attributes":{},"value":[true]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc","mathjax","md_extension"]}},"value":[{"type":"logical","attributes":{},"value":[true]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"]},{"type":"character","attributes":{},"value":["-tex_math_single_backslash"]}]}]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["RJ-2025-027.pdf"]},{"type":"character","attributes":{},"value":["10.32614/RJ-2025-027"]},{"type":"character","attributes":{},"value":["CC BY"]},{"type":"character","attributes":{},"value":["/home/mitchell/R/x86_64-pc-linux-gnu-library/4.5/rjtools/rjournal.csl"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["figures/fig1.png","figures/fig2.png","figures/fig3.png","figures/fig4.png","figures/fig5.png","figures/fig6.png","figures/Rlogo-5.png","RgofR2sampleRolke.bib","RgofR2sampleRolke.tex","RJ-2025-027_files/anchor-4.2.2/anchor.min.js","RJ-2025-027_files/bowser-1.9.3/bowser.min.js","RJ-2025-027_files/distill-2.2.21/template.v2.js","RJ-2025-027_files/header-attrs-2.30/header-attrs.js","RJ-2025-027_files/jquery-3.6.0/jquery-3.6.0.js","RJ-2025-027_files/jquery-3.6.0/jquery-3.6.0.min.js","RJ-2025-027_files/jquery-3.6.0/jquery-3.6.0.min.map","RJ-2025-027_files/popper-2.6.0/popper.min.js","RJ-2025-027_files/tippy-6.2.7/tippy-bundle.umd.min.js","RJ-2025-027_files/tippy-6.2.7/tippy-light-border.css","RJ-2025-027_files/tippy-6.2.7/tippy.css","RJ-2025-027_files/tippy-6.2.7/tippy.umd.min.js","RJ-2025-027_files/webcomponents-2.0.0/webcomponents.js","RJ-2025-027.zip","RJournal.sty","RJwrapper.bbl","RJwrapper.blg","RJwrapper.brf","RJwrapper.fdb_latexmk","RJwrapper.fls","RJwrapper.log","RJwrapper.out","RJwrapper.tex"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

  <style type="text/css">

  body {
    background-color: white;
  }

  .pandoc-table {
    width: 100%;
  }

  .pandoc-table>caption {
    margin-bottom: 10px;
  }

  .pandoc-table th:not([align]) {
    text-align: left;
  }

  .pagedtable-footer {
    font-size: 15px;
  }

  d-byline .byline {
    grid-template-columns: 2fr 2fr;
  }

  d-byline .byline h3 {
    margin-block-start: 1.5em;
  }

  d-byline .byline .authors-affiliations h3 {
    margin-block-start: 0.5em;
  }

  .authors-affiliations .orcid-id {
    width: 16px;
    height:16px;
    margin-left: 4px;
    margin-right: 4px;
    vertical-align: middle;
    padding-bottom: 2px;
  }

  d-title .dt-tags {
    margin-top: 1em;
    grid-column: text;
  }

  .dt-tags .dt-tag {
    text-decoration: none;
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0em 0.4em;
    margin-right: 0.5em;
    margin-bottom: 0.4em;
    font-size: 70%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  d-article table.gt_table td,
  d-article table.gt_table th {
    border-bottom: none;
    font-size: 100%;
  }

  .html-widget {
    margin-bottom: 2.0em;
  }

  .l-screen-inset {
    padding-right: 16px;
  }

  .l-screen .caption {
    margin-left: 10px;
  }

  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .shaded-content {
    background: white;
  }

  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }

  .hidden {
    display: none !important;
  }

  hr.section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    margin: 0px;
  }


  d-byline {
    border-top: none;
  }

  d-article {
    padding-top: 2.5rem;
    padding-bottom: 30px;
    border-top: none;
  }

  d-appendix {
    padding-top: 30px;
  }

  d-article>p>img {
    width: 100%;
  }

  d-article h2 {
    margin: 1rem 0 1.5rem 0;
  }

  d-article h3 {
    margin-top: 1.5rem;
  }

  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }

  /* Tweak code blocks */

  d-article div.sourceCode code,
  d-article pre code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: auto;
  }

  d-article div.sourceCode {
    background-color: white;
  }

  d-article div.sourceCode pre {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }

  d-article pre {
    font-size: 12px;
    color: black;
    background: none;
    margin-top: 0;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  d-article pre a {
    border-bottom: none;
  }

  d-article pre a:hover {
    border-bottom: none;
    text-decoration: underline;
  }

  d-article details {
    grid-column: text;
    margin-bottom: 0.8em;
  }

  @media(min-width: 768px) {

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: visible !important;
  }

  d-article div.sourceCode pre {
    padding-left: 18px;
    font-size: 14px;
  }

  /* tweak for Pandoc numbered line within distill */
  d-article pre.numberSource code > span {
      left: -2em;
  }

  d-article pre {
    font-size: 14px;
  }

  }

  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  /* CSS for d-contents */

  .d-contents {
    grid-column: text;
    color: rgba(0,0,0,0.8);
    font-size: 0.9em;
    padding-bottom: 1em;
    margin-bottom: 1em;
    padding-bottom: 0.5em;
    margin-bottom: 1em;
    padding-left: 0.25em;
    justify-self: start;
  }

  @media(min-width: 1000px) {
    .d-contents.d-contents-float {
      height: 0;
      grid-column-start: 1;
      grid-column-end: 4;
      justify-self: center;
      padding-right: 3em;
      padding-left: 2em;
    }
  }

  .d-contents nav h3 {
    font-size: 18px;
    margin-top: 0;
    margin-bottom: 1em;
  }

  .d-contents li {
    list-style-type: none
  }

  .d-contents nav > ul {
    padding-left: 0;
  }

  .d-contents ul {
    padding-left: 1em
  }

  .d-contents nav ul li {
    margin-top: 0.6em;
    margin-bottom: 0.2em;
  }

  .d-contents nav a {
    font-size: 13px;
    border-bottom: none;
    text-decoration: none
    color: rgba(0, 0, 0, 0.8);
  }

  .d-contents nav a:hover {
    text-decoration: underline solid rgba(0, 0, 0, 0.6)
  }

  .d-contents nav > ul > li > a {
    font-weight: 600;
  }

  .d-contents nav > ul > li > ul {
    font-weight: inherit;
  }

  .d-contents nav > ul > li > ul > li {
    margin-top: 0.2em;
  }


  .d-contents nav ul {
    margin-top: 0;
    margin-bottom: 0.25em;
  }

  .d-article-with-toc h2:nth-child(2) {
    margin-top: 0;
  }


  /* Figure */

  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }

  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }

  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }

  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }

  /* Citations */

  d-article .citation {
    color: inherit;
    cursor: inherit;
  }

  div.hanging-indent{
    margin-left: 1em; text-indent: -1em;
  }

  /* Citation hover box */

  .tippy-box[data-theme~=light-border] {
    background-color: rgba(250, 250, 250, 0.95);
  }

  .tippy-content > p {
    margin-bottom: 0;
    padding: 2px;
  }


  /* Tweak 1000px media break to show more text */

  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }

    .grid {
      grid-column-gap: 16px;
    }

    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }

  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }

    .grid {
      grid-column-gap: 32px;
    }
  }


  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */

  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  /* Include appendix styles here so they can be overridden */

  d-appendix {
    contain: layout style;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-top: 60px;
    margin-bottom: 0;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    color: rgba(0,0,0,0.5);
    padding-top: 60px;
    padding-bottom: 48px;
  }

  d-appendix h3 {
    grid-column: page-start / text-start;
    font-size: 15px;
    font-weight: 500;
    margin-top: 1em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.65);
  }

  d-appendix h3 + * {
    margin-top: 1em;
  }

  d-appendix ol {
    padding: 0 0 0 15px;
  }

  @media (min-width: 768px) {
    d-appendix ol {
      padding: 0 0 0 30px;
      margin-left: -30px;
    }
  }

  d-appendix li {
    margin-bottom: 1em;
  }

  d-appendix a {
    color: rgba(0, 0, 0, 0.6);
  }

  d-appendix > * {
    grid-column: text;
  }

  d-appendix > d-footnote-list,
  d-appendix > d-citation-list,
  d-appendix > distill-appendix {
    grid-column: screen;
  }

  /* Include footnote styles here so they can be overridden */

  d-footnote-list {
    contain: layout style;
  }

  d-footnote-list > * {
    grid-column: text;
  }

  d-footnote-list a.footnote-backlink {
    color: rgba(0,0,0,0.3);
    padding-left: 0.5em;
  }



  /* Anchor.js */

  .anchorjs-link {
    /*transition: all .25s linear; */
    text-decoration: none;
    border-bottom: none;
  }
  *:hover > .anchorjs-link {
    margin-left: -1.125em !important;
    text-decoration: none;
    border-bottom: none;
  }

  /* Social footer */

  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }

  .disqus-comments {
    margin-right: 30px;
  }

  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }

  #disqus_thread {
    margin-top: 30px;
  }

  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }

  .article-sharing a:hover {
    border-bottom: none;
  }

  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }

  .subscribe p {
    margin-bottom: 0.5em;
  }


  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }


  .sidebar-section.custom {
    font-size: 12px;
    line-height: 1.6em;
  }

  .custom p {
    margin-bottom: 0.5em;
  }

  /* Styles for listing layout (hide title) */
  .layout-listing d-title, .layout-listing .d-title {
    display: none;
  }

  /* Styles for posts lists (not auto-injected) */


  .posts-with-sidebar {
    padding-left: 45px;
    padding-right: 45px;
  }

  .posts-list .description h2,
  .posts-list .description p {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  }

  .posts-list .description h2 {
    font-weight: 700;
    border-bottom: none;
    padding-bottom: 0;
  }

  .posts-list h2.post-tag {
    border-bottom: 1px solid rgba(0, 0, 0, 0.2);
    padding-bottom: 12px;
  }
  .posts-list {
    margin-top: 60px;
    margin-bottom: 24px;
  }

  .posts-list .post-preview {
    text-decoration: none;
    overflow: hidden;
    display: block;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
    padding: 24px 0;
  }

  .post-preview-last {
    border-bottom: none !important;
  }

  .posts-list .posts-list-caption {
    grid-column: screen;
    font-weight: 400;
  }

  .posts-list .post-preview h2 {
    margin: 0 0 6px 0;
    line-height: 1.2em;
    font-style: normal;
    font-size: 24px;
  }

  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.4em;
    font-size: 16px;
  }

  .posts-list .post-preview .thumbnail {
    box-sizing: border-box;
    margin-bottom: 24px;
    position: relative;
    max-width: 500px;
  }
  .posts-list .post-preview img {
    width: 100%;
    display: block;
  }

  .posts-list .metadata {
    font-size: 12px;
    line-height: 1.4em;
    margin-bottom: 18px;
  }

  .posts-list .metadata > * {
    display: inline-block;
  }

  .posts-list .metadata .publishedDate {
    margin-right: 2em;
  }

  .posts-list .metadata .dt-authors {
    display: block;
    margin-top: 0.3em;
    margin-right: 2em;
  }

  .posts-list .dt-tags {
    display: block;
    line-height: 1em;
  }

  .posts-list .dt-tags .dt-tag {
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0.3em 0.4em;
    margin-right: 0.2em;
    margin-bottom: 0.4em;
    font-size: 60%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  .posts-list img {
    opacity: 1;
  }

  .posts-list img[data-src] {
    opacity: 0;
  }

  .posts-more {
    clear: both;
  }


  .posts-sidebar {
    font-size: 16px;
  }

  .posts-sidebar h3 {
    font-size: 16px;
    margin-top: 0;
    margin-bottom: 0.5em;
    font-weight: 400;
    text-transform: uppercase;
  }

  .sidebar-section {
    margin-bottom: 30px;
  }

  .categories ul {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }

  .categories li {
    color: rgba(0, 0, 0, 0.8);
    margin-bottom: 0;
  }

  .categories li>a {
    border-bottom: none;
  }

  .categories li>a:hover {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  }

  .categories .active {
    font-weight: 600;
  }

  .categories .category-count {
    color: rgba(0, 0, 0, 0.4);
  }


  @media(min-width: 768px) {
    .posts-list .post-preview h2 {
      font-size: 26px;
    }
    .posts-list .post-preview .thumbnail {
      float: right;
      width: 30%;
      margin-bottom: 0;
    }
    .posts-list .post-preview .description {
      float: left;
      width: 45%;
    }
    .posts-list .post-preview .metadata {
      float: left;
      width: 20%;
      margin-top: 8px;
    }
    .posts-list .post-preview p {
      margin: 0 0 12px 0;
      line-height: 1.5em;
      font-size: 16px;
    }
    .posts-with-sidebar .posts-list {
      float: left;
      width: 75%;
    }
    .posts-with-sidebar .posts-sidebar {
      float: right;
      width: 20%;
      margin-top: 60px;
      padding-top: 24px;
      padding-bottom: 24px;
    }
  }


  /* Improve display for browsers without grid (IE/Edge <= 15) */

  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }

  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }

  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }

  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }

  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }

  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }

  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }


  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }

  .downlevel .footnotes ol {
    padding-left: 13px;
  }

  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }

  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }

  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }

  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  .downlevel .posts-list .post-preview {
    color: inherit;
  }



  </style>

  <script type="application/javascript">

  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }

  // show body when load is complete
  function on_load_complete() {

    // add anchors
    if (window.anchors) {
      window.anchors.options.placement = 'left';
      window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
    }


    // set body to visible
    document.body.style.visibility = 'visible';

    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }

    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }

  function init_distill() {

    init_common();

    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);

    // create d-title
    $('.d-title').changeElementType('d-title');

    // separator
    var separator = '<hr class="section-separator" style="clear: both"/>';
    // prepend separator above appendix
    $('.d-byline').before(separator);
    $('.d-article').before(separator);

    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);

    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();

    // move posts container into article
    $('.posts-container').appendTo($('d-article'));

    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');

    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;

    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();

    // move refs into #references-listing
    $('#references-listing').replaceWith($('#refs'));

    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-contents a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });

    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');

    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {

      // capture layout
      var layout = $(this).attr('data-layout');

      // apply layout to markdown level block elements
      var elements = $(this).children().not('details, div.sourceCode, pre, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });


      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });

    // remove code block used to force  highlighting css
    $('.distill-force-highlighting-css').parent().remove();

    // remove empty line numbers inserted by pandoc when using a
    // custom syntax highlighting theme, except when numbering line
    // in code chunk
    $('pre:not(.numberLines) code.sourceCode a:empty').remove();

    // load distill framework
    load_distill_framework();

    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {

      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;

      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');

      // article with toc class
      $('.d-contents').parent().addClass('d-article-with-toc');

      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

      // add orcid ids
      $('.authors-affiliations').find('.author').each(function(i, el) {
        var orcid_id = front_matter.authors[i].orcidID;
        var author_name = front_matter.authors[i].author
        if (orcid_id) {
          var a = $('<a></a>');
          a.attr('href', 'https://orcid.org/' + orcid_id);
          var img = $('<img></img>');
          img.addClass('orcid-id');
          img.attr('alt', author_name ? 'ORCID ID for ' + author_name : 'ORCID ID');
          img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
          a.append(img);
          $(this).append(a);
        }
      });

      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }

      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");

      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }

       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }

      // remove d-appendix and d-footnote-list local styles
      $('d-appendix > style:first-child').remove();
      $('d-footnote-list > style:first-child').remove();

      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();

      // hoverable references
      $('span.citation[data-cites]').each(function() {
        const citeChild = $(this).children()[0]
        // Do not process if @xyz has been used without escaping and without bibliography activated
        // https://github.com/rstudio/distill/issues/466
        if (citeChild === undefined) return true

        if (citeChild.nodeName == "D-FOOTNOTE") {
          var fn = citeChild
          $(this).html(fn.shadowRoot.querySelector("sup"))
          $(this).id = fn.id
          fn.remove()
        }
        var refs = $(this).attr('data-cites').split(" ");
        var refHtml = refs.map(function(ref) {
          // Could use CSS.escape too here, we insure backward compatibility in navigator
          return "<p>" + $('div[id="ref-' + ref + '"]').html() + "</p>";
        }).join("\n");
        window.tippy(this, {
          allowHTML: true,
          content: refHtml,
          maxWidth: 500,
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        });
      });

      // fix footnotes in tables (#411)
      // replacing broken distill.pub feature
      $('table d-footnote').each(function() {
        // we replace internal showAtNode methode which is triggered when hovering a footnote
        this.hoverBox.showAtNode = function(node) {
          // ported from https://github.com/distillpub/template/pull/105/files
          calcOffset = function(elem) {
              let x = elem.offsetLeft;
              let y = elem.offsetTop;
              // Traverse upwards until an `absolute` element is found or `elem`
              // becomes null.
              while (elem = elem.offsetParent && elem.style.position != 'absolute') {
                  x += elem.offsetLeft;
                  y += elem.offsetTop;
              }

              return { left: x, top: y };
          }
          // https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement/offsetTop
          const bbox = node.getBoundingClientRect();
          const offset = calcOffset(node);
          this.show([offset.left + bbox.width, offset.top + bbox.height]);
        }
      })

      // clear polling timer
      clearInterval(tid);

      // show body now that everything is ready
      on_load_complete();
    }

    var tid = setInterval(distill_post_process, 50);
    distill_post_process();

  }

  function init_downlevel() {

    init_common();

     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));

    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;

    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();

    // remove toc
    $('.d-contents').remove();

    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });


    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);

    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();

    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });

    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));

    $('body').addClass('downlevel');

    on_load_complete();
  }


  function init_common() {

    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};

        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });

        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);

    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});

    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      // ignore leaflet img layers (#106)
      figures = figures.filter(':not(img[class*="leaflet"])')
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });

      }
    });

    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });

    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace(/^index[.]html/, "./"));
      });
    }

    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');

    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");

    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();

    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }

  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });

  </script>

  <!--/radix_placeholder_distill-->
  <script src="RJ-2025-027_files/header-attrs-2.30/header-attrs.js"></script>
  <script src="RJ-2025-027_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
  <script src="RJ-2025-027_files/popper-2.6.0/popper.min.js"></script>
  <link href="RJ-2025-027_files/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="RJ-2025-027_files/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="RJ-2025-027_files/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="RJ-2025-027_files/anchor-4.2.2/anchor.min.js"></script>
  <script src="RJ-2025-027_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="RJ-2025-027_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="RJ-2025-027_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->
  <script>
    $(function() {
      console.log("Starting...")

      // Mathjax config (add automatic linebreaks when supported)
      // MathJax = {
      //    tex: {
      //        inlineMath: [['$', '$'], ['\\(', '\\)']],
      //        displayMath: [['$$', '$$'], ['\\[', '\\]']],
      //        tags: 'ams',
      //        multline: true,
      //    },
      //    options: {
      //        linebreaks: { automatic: true },
      //    },
      // };

      // Always show Published - distill hides it if not set
      function show_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'visible');
      }

      show_byline_column('Published')

      // tweak function
      var rmd_meta = JSON.parse($("#radix-rmarkdown-metadata").html());
      function get_meta(name, meta) {
        var ind = meta.attributes.names.value.findIndex((e) => e == name)
        var val = meta.value[ind]
        if (val.type != 'list') {
          return val.value.toString()
        }
        return val
      }

      // tweak description
      // Add clickable tags
      const slug = get_meta('slug', rmd_meta)
      const cite_url = get_meta('citation_url', rmd_meta)

      var title = $("d-title").text

      const buttons = $('<div class="dt-tags" style="grid-column: page;">')
      buttons.append('<a href="#citation" class="dt-tag"><i class="fas fa-quote-left"></i> Cite</a>')
      buttons.append('<a href="' + slug + '.pdf" class="dt-tag"><i class="fas fa-file-pdf"></i> PDF</a>')
      
      // Conditionally add supplementary files button
      document.addEventListener('DOMContentLoaded', () => {
        if (document.getElementById('supplementary-materials')) {
          // create element safely
          const btn_suppl = document.createElement('a');
          btn_suppl.href = slug + '.zip';
          btn_suppl.className = 'dt-tag';
          btn_suppl.innerHTML = '<i class="fas fa-file-zipper"></i> Supplement';
          buttons.append(btn_suppl);
        }
      });

      // adds Abstract: in front of the first <p> in the title section --
      // unless it happens to be the subtitle (FIXME: this is a bad hack - can't distill do this?)
      var tpar = $("d-title p:not(:empty)").filter(function() {
        return !$(this).hasClass("subtitle");
      }).first();
      if (tpar) {
        const abstract = $('<d-abstract>')
        abstract.append('<b>Abstract:</b><br>')
        abstract.append(tpar) // Move description to d-abstract
        $("d-title p:empty").remove() // Remove empty paragraphs after title
        abstract.append(buttons)
        abstract.insertAfter($('d-title')) // Add abstract section after title */
      }

      // tweak by-line
      var byline = $("d-byline div.byline")
      ind = rmd_meta.attributes.names.value.findIndex((e) => e == "journal")
      const journal = get_meta('journal', rmd_meta)
      const volume = get_meta('volume', rmd_meta)
      const issue = get_meta('issue', rmd_meta)
      const jrtitle = get_meta('title', journal)
      const year = ((jrtitle == "R News") ? 2000 : 2008) + parseInt(volume)
      const firstpage = get_meta('firstpage', journal)
      const lastpage = get_meta('lastpage', journal)
      byline.append('<div class="rjournal grid">')
      $('div.rjournal').append('<h3>Volume</h3>')
      $('div.rjournal').append('<h3>Pages</h3>')
      $('div.rjournal').append('<a class="volume" href="../../issues/'+year+'-'+issue+'">'+volume+'/'+issue+'</a>')
      $('div.rjournal').append('<p class="pages">'+firstpage+' - '+lastpage+'</p>')

      const received_date = new Date(get_meta('date_received', rmd_meta))
      byline.find('h3:contains("Published")').parent().append('<h3>Received</h3><p>'+received_date.toLocaleDateString('en-US', {month: 'short'})+' '+received_date.getDate()+', '+received_date.getFullYear()+'</p>')

    })
  </script>

  <style>
      /*
    .nav-dropdown-content .nav-dropdown-header {
      text-transform: lowercase;
    }
    */

    d-byline .byline {
      grid-template-columns: 2fr 2fr 2fr 2fr;
    }

    d-byline .rjournal {
      grid-column-end: span 2;
      grid-template-columns: 1fr 1fr;
      margin-bottom: 0;
    }

    d-title h1, d-title p, d-title figure,
    d-abstract p, d-abstract b {
      grid-column: page;
    }

    d-title .dt-tags {
      grid-column: page;
    }

    .dt-tags .dt-tag {
      text-transform: lowercase;
    }

    d-article h1 {
      line-height: 1.1em;
    }

    d-abstract p, d-article p {
      text-align: justify;
    }

    @media(min-width: 1000px) {
      .d-contents.d-contents-float {
        justify-self: end;
      }

      nav.toc {
        border-right: 1px solid rgba(0, 0, 0, 0.1);
        border-right-width: 1px;
        border-right-style: solid;
        border-right-color: rgba(0, 0, 0, 0.1);
      }
    }

    .posts-list .dt-tags .dt-tag {
      text-transform: lowercase;
    }

    @keyframes highlight-target {
      0% {
        background-color: #ffa;
      }
      66% {
        background-color: #ffa;
      }
      100% {
        background-color: none;
      }
    }

    d-article :target, d-appendix :target {
       animation: highlight-target 3s;
    }

    .header-section-number {
      margin-right: 0.5em;
    }
    
    d-appendix .citation-appendix,
    .d-appendix .citation-appendix {
      color: rgb(60, 60, 60);
    }

    d-article h2 {
      border-bottom: 0px solid rgba(0, 0, 0, 0.1);
      padding-bottom: 0rem;
    }
    d-article h3 {
      font-size: 20px;
    }
    d-article h4 {
      font-size: 18px;
      text-transform: none;
    }

    @media (min-width: 1024px) {
      d-article h2 {
        font-size: 32px;
      }
      d-article h3 {
        font-size: 24px;
      }
      d-article h4 {
        font-size: 20px;
      }
    }
  </style>


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Rgof and R2sample: Testing and Benchmarking for the Univariate Goodness-of-Fit and Two-Sample Problems","description":"In a goodness-of-fit problem one attempts to see whether a data set\nmight have been generated by some theoretical probability\ndistribution, possibly with unknown parameters. In a (non-parametric)\ntwo-sample problem one wants to check whether two data sets could have\ncome from the same unspecified distribution. Both are among the oldest\nand best studied problems in Statistics. While they seem quite\ndifferent, there are a number of similarities between these problems,\nnot the least of which is that many methods exist that have versions\nfor both. The two packages discussed in this article bring together a\nlarge number of methods and many different scenarios, most of which do\nnot yet have existing implementations. They also include routines that\nallow a developer of a new method to quickly compare its performance\n(aka power) to those included in the package for a large number of\ncases.","doi":"10.32614/RJ-2025-027","authors":[{"author":"Wolfgang Rolke","authorURL":"#","affiliation":"University of Puerto Rico - Mayaguez","affiliationURL":"#","orcidID":""}],"publishedDate":"2025-10-21T00:00:00.000+11:00","citationText":"Rolke, 2025"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Rgof and R2sample: Testing and Benchmarking for the Univariate Goodness-of-Fit and Two-Sample Problems</h1>

<!--radix_placeholder_categories-->
<!--/radix_placeholder_categories-->
<p><p>In a goodness-of-fit problem one attempts to see whether a data set
might have been generated by some theoretical probability
distribution, possibly with unknown parameters. In a (non-parametric)
two-sample problem one wants to check whether two data sets could have
come from the same unspecified distribution. Both are among the oldest
and best studied problems in Statistics. While they seem quite
different, there are a number of similarities between these problems,
not the least of which is that many methods exist that have versions
for both. The two packages discussed in this article bring together a
large number of methods and many different scenarios, most of which do
not yet have existing implementations. They also include routines that
allow a developer of a new method to quickly compare its performance
(aka power) to those included in the package for a large number of
cases.</p></p>
</div>

<div class="d-byline">
  Wolfgang Rolke  (University of Puerto Rico - Mayaguez)
  
<br/>2025-10-21
</div>

<div class="d-article">
<div class="article">
<h3 data-number="1" id="introduction"><span class="header-section-number">1</span> Introduction</h3>
<p>Both the goodness-of-fit and the nonparametric two-sample problem have
histories going back a century, with many contributions by some of the
most eminent statisticians. In the goodness-of-fit problem we have a
sample <span class="math inline">\((x_1,..,x_n)\)</span> drawn from a random variable X. We also have a
probability distribution <span class="math inline">\(F\)</span>, possibly with unknown parameters, and we
wish to test <span class="math inline">\(H_0:X\sim F\)</span>. In the two-sample problem we also have a
second sample <span class="math inline">\((y_1,..,y_m)\)</span> drawn from some distribution <span class="math inline">\(G\)</span>, and here
we want to test <span class="math inline">\(H_0:F=G\)</span>, that is we want to test whether the two data
sets were generated by the same (unspecified) distribution.</p>
<p>The literature on both of these problems is vast and steadily growing.
Detailed discussions can be found in <span class="citation" data-cites="agostini1986">(<a href="#ref-agostini1986" role="doc-biblioref">D’Agostini and Stephens 1986</a>)</span>, <span class="citation" data-cites="thas2010">(<a href="#ref-thas2010" role="doc-biblioref">Thas 2010</a>)</span>,
<span class="citation" data-cites="raynor2009">(<a href="#ref-raynor2009" role="doc-biblioref">Raynor et al. 2012</a>)</span>. For an introduction to Statistics and hypothesis testing
in general see <span class="citation" data-cites="casella2002">(<a href="#ref-casella2002" role="doc-biblioref">Casella and Berger 2002</a>)</span> or <span class="citation" data-cites="bickel2015">(<a href="#ref-bickel2015" role="doc-biblioref">Bickel and Doksum 2015</a>)</span>.</p>
<p>Some tests such as the Kolmogorov-Smirnov test are already implemented
for both problems in base <strong>R</strong> <span class="citation" data-cites="r2021">(<a href="#ref-r2021" role="doc-biblioref">R Core Team 2021</a>)</span>. Many others can be run through
various existing packages, for example the Anderson-Darling
goodness-of-fit test is available in the <strong>R</strong> package <em>ADGofTest</em>
<span class="citation" data-cites="adgoftest2011">(<a href="#ref-adgoftest2011" role="doc-biblioref">Bellosta 2011</a>)</span>. There are a number of packages with tests that focus
on a specific distribution, for example the <em>nortest</em> <span class="citation" data-cites="nortest2015">(<a href="#ref-nortest2015" role="doc-biblioref">Gross and Ligges 2015</a>)</span>
package has five tests for composite normality. There are also packages
that allow the user to run several tests, for example the <em>twosamples</em>
<span class="citation" data-cites="dowd2022">(<a href="#ref-dowd2022" role="doc-biblioref">Dowd 2022</a>)</span>, <em>dgof</em> <span class="citation" data-cites="dgof2009">(<a href="#ref-dgof2009" role="doc-biblioref">Taylor and Emerson 2009</a>)</span>, <em>EnvStats</em> <span class="citation" data-cites="envstats2017">(<a href="#ref-envstats2017" role="doc-biblioref">Millard and Kowarik 2017</a>)</span> and
<em>goftest</em> <span class="citation" data-cites="goftest2007">(<a href="#ref-goftest2007" role="doc-biblioref">Faraway et al. 2007</a>)</span> packages.</p>
<p>However, there are no packages that bring together as many tests as
<em>R2sample</em> and <em>Rgof</em>. Moreover, some methods do not currently have any
<em>R</em> implementations, for example Zhang’s test, Lehmann-Rosenblatt, the
Wasserstein p1 test and almost all tests for discrete data.</p>
<p>Both packages have the following features:</p>
<ul>
<li><p>many methods are implemented for both continuous and discrete data.</p></li>
<li><p>the methods are implemented using both <em>Rcpp</em> <span class="citation" data-cites="rcpp2024">(<a href="#ref-rcpp2024" role="doc-biblioref">Eddelbuettel et al. 2024</a>)</span> and
parallel programming.</p></li>
<li><p>the packages include routines to run several test and then find a
corrected p value for the combination of tests.</p></li>
<li><p>some of the methods allow for data with weights.</p></li>
<li><p>the routines allow for a random sample size, assumed to come from a
Poisson distribution.</p></li>
<li><p>in the two-sample problem some methods make use of large-sample
formulas, therefore allowing for very large data sets.</p></li>
<li><p>the routines can also use any other user-defined tests.</p></li>
<li><p>the packages include routines to easily carry out power studies and
draw power graphs.</p></li>
<li><p>the packages include routines to easily compare the power of a new
test to those included in the packages.</p></li>
<li><p>in the two-sample package the user can provide a routine that
generates new data from a model. This can be used as an alternative
to the permutation method to find p values.</p></li>
</ul>
<p>There are several reasons for including tests for discrete data. In the
context of a computer program this means a finite (and usually fairly
small) number of different values which then repeat many times.</p>
<ul>
<li><p>Tests for discrete data such as from Binomial or Poisson
distributions are of interest in their own right.</p></li>
<li><p>There are currently almost no implementations of either
goodness-of-fit or two-sample methods for discrete data in <em>R</em>.</p></li>
<li><p>It also makes it possible to apply the tests to very large
continuous data sets via discretization. While a goodness-of-fit
test for a continuous data set with (say) 100,000 observations can
be done in a matter of a few minutes, for larger data sets the
calculations will be quite time consuming. Data sets with many
millions of observations are not uncommon today. Binning the data
and then running the corresponding discrete tests however is quite
fast.</p></li>
<li><p>There are also situations where the underlying distribution is
continuous but the data is collected in binned form. This is for
example often the case for data from high energy physics experiments
and from astronomy because of finite detector resolution. In some
fields this is referred to as histogram data. For the purpose of
either the goodness-of-fit or two-sample problems standard discrete
data and histogram data can be treated the same, with the midpoints
of the bins used as observations where such are needed.</p></li>
</ul>
<p>For the two-sample problem p values are found via the permutation
method. If the data sets are large for some of the tests the p values
can be found via large sample approximations. In the goodness-of-fit
case p values are always found via simulation. While large sample
approximations are know for some methods such as Kolmogorov-Smirnov and
Anderson-Darling, there are no known large sample theories for most of
the other tests. Moreover, in the more common situation where the
distribution under the null hypothesis depends on parameters, which have
to be estimated from the data, even those tests no longer have known
large sample theories and one is forced to use simulation to find p
values.</p>
<p>The packages <em>Rgof</em> <span class="citation" data-cites="rgof2023">(<a href="#ref-rgof2023" role="doc-biblioref">Rolke 2023b</a>)</span> and <em>R2sample</em> <span class="citation" data-cites="r2sample2023">(<a href="#ref-r2sample2023" role="doc-biblioref">Rolke 2023a</a>)</span> are
available from CRAN.</p>
<h3 data-number="2" id="goodness-of-fit-vs-two-sample-problems"><span class="header-section-number">2</span> Goodness-of-fit / two-sample hybrid problem</h3>
<p>As was mentioned in the abstract, while the goodness-of-fit problem and
the two-sample problem are quite different, they also share certain
features such as methods that exist for both. On a deeper level they are
both hypothesis tests in the Fisherian sense, in that they are tests
without an alternative hypothesis. These tests are usually done for
confirmation, that is in the goodness-of-fit case the researcher wants
to make sure that his assumed probability model is reasonably good,
without any consideration of how it might be wrong.</p>
<p>There is yet another connection between these types of problems.
Sometimes one wants to carry out a goodness-of-fit test. However, the
model under the null hypothesis is quite complex with a large number of
nuisance parameters Therefore calculating values from the distribution
function requires integration in high dimensions and is at present not
feasible. It is however possible to sample from the distribution. So the
problem now changes from a goodness-of-fit to a two-sample problem.</p>
<p>If the null hypothesis in the goodness-of-fit problem does not fully
specify the distribution but just its functional form one can then
estimated the parameters from the data. However, in this situation the
permutation method for estimating the p value fails, it is extremely
conservative. Instead the user can provide a routine to generate new
data, essentially using a parametric bootstrap approach.</p>
<h3 data-number="3" id="the-types-of-problems"><span class="header-section-number">3</span> The types of problems</h3>
<p>The problems that can be analyzed with these packages are as follows:</p>
<ul>
<li><p><strong>Goodness-of-Fit Problem - Continuous Data</strong>: We have a sample <span class="math inline">\(x\)</span>
of size of <span class="math inline">\(n\)</span> drawn from some random variable X. <span class="math inline">\(F\)</span> is a
continuous probability distribution, which may depend on unknown
parameters. We want to test <span class="math inline">\(X\sim F\)</span>.</p></li>
<li><p><strong>Goodness-of-Fit Problem - Discrete Data</strong>: We have a set of values
<em>vals</em> and a vector of counts <span class="math inline">\(x\)</span>. <span class="math inline">\(F\)</span> is a discrete probability
distribution, which may depend on unknown parameters. We want to
test <span class="math inline">\(X\sim F\)</span>.</p></li>
<li><p><strong>Two-sample Problem - Continuous Data</strong>: We have a sample <span class="math inline">\(x\)</span> of
size of <span class="math inline">\(n\)</span>, drawn from some unknown continuous probability
distribution <span class="math inline">\(F\)</span>, and a sample <span class="math inline">\(y\)</span> of size <span class="math inline">\(m\)</span>, drawn from some
unknown continuous probability distribution <span class="math inline">\(G\)</span>. We want to test
<span class="math inline">\(F=G\)</span>.</p></li>
<li><p><strong>Two-sample Problem - Discrete Data</strong>: We have a set of values
<em>vals</em> and vectors of counts <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, drawn from some unknown
discrete probability distributions <span class="math inline">\(F\)</span> and <span class="math inline">\(G\)</span>. We want to test
<span class="math inline">\(F=G\)</span>.</p></li>
</ul>
<p>In all of the above problems, the sample size can either be fixed or
follow a Poisson distribution with a known rate. In all cases the data
can be weighted. In all cases the user can provide his/her own testing
method.</p>
<h3 data-number="4" id="the-methods"><span class="header-section-number">4</span> The methods</h3>
<p>In the following we list the methods included in the packages. Most are
well known and have been in use for a long time. For their details see
the references. They are:</p>
<div id="tab:T1">
<table style="width:97%;">
<colgroup>
<col style="width: 28%" />
<col style="width: 17%" />
<col style="width: 15%" />
<col style="width: 17%" />
<col style="width: 17%" />
</colgroup>
<tbody>
<tr class="odd">
<td></td>
<td style="text-align: right;"><em>Rgof</em></td>
<td></td>
<td style="text-align: right;"><em>R2sample</em></td>
<td></td>
</tr>
<tr class="even">
<td>Method</td>
<td style="text-align: right;">Continuous</td>
<td>Discrete</td>
<td style="text-align: right;">Continuous</td>
<td>Discrete</td>
</tr>
<tr class="odd">
<td>Chi-Square Tests</td>
<td style="text-align: right;">Yes</td>
<td>Yes</td>
<td style="text-align: right;">Yes</td>
<td>Yes</td>
</tr>
<tr class="even">
<td>Kolomorov-Smirnov</td>
<td style="text-align: right;">Yes</td>
<td>Yes</td>
<td style="text-align: right;">Yes</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td>Kuiper</td>
<td style="text-align: right;">Yes</td>
<td>Yes</td>
<td style="text-align: right;">Yes</td>
<td>Yes</td>
</tr>
<tr class="even">
<td>Cramer-von Mises</td>
<td style="text-align: right;">Yes</td>
<td>Yes</td>
<td style="text-align: right;">Yes</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td>Anderson-Darling</td>
<td style="text-align: right;">Yes</td>
<td>Yes</td>
<td style="text-align: right;">Yes</td>
<td>Yes</td>
</tr>
<tr class="even">
<td>Zhang’s tests</td>
<td style="text-align: right;">Yes</td>
<td>No</td>
<td style="text-align: right;">Yes</td>
<td>No</td>
</tr>
<tr class="odd">
<td>Wasserstein</td>
<td style="text-align: right;">Yes</td>
<td>Yes</td>
<td style="text-align: right;">Yes</td>
<td>Yes</td>
</tr>
<tr class="even">
<td>Watson’s test</td>
<td style="text-align: right;">Yes</td>
<td>Yes</td>
<td style="text-align: right;">No</td>
<td>No</td>
</tr>
<tr class="odd">
<td>Lehmann-Rosenblatt</td>
<td style="text-align: right;">No</td>
<td>No</td>
<td style="text-align: right;">Yes</td>
<td>Yes</td>
</tr>
</tbody>
</table>
</div>
<p><span id="tab:T1" data-label="tab:T1"></span></p>
<p>There are of course many other tests that could have also been
implemented in the routines. All the tests included share the following
features. They are true omnibus tests, that is not designed with any
specific alternative in mind. For this reason we did not include the
class of Neyman’s smooth tests, for example. Moreover they are all tests
that do not depend on some tuning parameters. The exception here are the
chi-square tests, which depend on the choice of the number and shape of
the bins. The chi-square tests are included because they are so well
known and widely used, even so their power often leaves much to be
desired.</p>
<p>We denote the cumulative distribution function (cdf) by <span class="math inline">\(F\)</span>, its
empirical distribution function (edf) by <span class="math inline">\(\widehat{F}\)</span>. In the case of
the two-sample problem we also have the edf of the second data set
<span class="math inline">\(\widehat{G}\)</span> and the edf of the combined data set <span class="math inline">\(\widehat{H}\)</span>.</p>
<ol type="1">
<li><strong>Chi-Square Tests</strong></li>
</ol>
<p>In the case of continuous data the routines include eight chi-square
tests, with either equal size (ES) or equal probability (EP) bins,
either a large (<em>nbins[1]</em>=50) or a small (<em>nbins[2]</em>=10) number of
bins and with either the Pearson (P) or the log-likelihood (L) formula.
Here and in what follows <em>nbins</em> and similar items are arguments to the
routines that the user can change. So the combination of a large number
of equal size bins and Pearson’s chi-square formula is denoted by
<em>ES-l-P</em>, etc.</p>
<p>In the case of discrete data the type and the number of classes is
already given, and for a second test these are combined for a total of
<em>nbins[2]</em>=10. Again both chi-square formulas are used. So here the
case of a large number of bins and Pearson’s formula is denoted by
<em>l-P</em>.</p>
<p>In all cases neighboring bins with low counts are joined until all bins
have a count of at least <em>minexpcount</em>=5. In all cases the p values are
found using the usual chi-square approximation.</p>
<p>If parameters have to be estimated, this is done via the user-provided
routine <span class="math inline">\(phat\)</span>. As long as the method of estimation used is consistent
and efficient and the expected counts are large enough the chi-square
statistic will have a chi-square distribution, as shown by <span class="citation" data-cites="fisher1922">(<a href="#ref-fisher1922" role="doc-biblioref">Fisher 1922</a>)</span>
and <span class="citation" data-cites="fisher1924">(<a href="#ref-fisher1924" role="doc-biblioref">Fisher 1924</a>)</span>.</p>
<p>Alternatively we can use the argument <em>ChiUsePhat=FALSE</em>. In that case
the value provided by <em>phat</em> is used as a starting point but the
parameters are estimated via the method of minimum chi-square. This
method has the desirable feature that if the null hypothesis is rejected
for this set of values, it will always be rejected for any other as
well. For a discussion of this estimation method see <span class="citation" data-cites="berkson1980">(<a href="#ref-berkson1980" role="doc-biblioref">Berkson 1980</a>)</span>.</p>
<ol type="1">
<li><strong>Kolmogorov-Smirnov (KS)</strong></li>
</ol>
<p>This test is based on the largest absolute distance between <span class="math inline">\(F\)</span> and
<span class="math inline">\(\widehat{F}\)</span> in the goodness-of-fit problem and between <span class="math inline">\(\widehat{F}\)</span>
and <span class="math inline">\(\widehat{G}\)</span> in the two-sample problem. The tests were first
proposed in <span class="citation" data-cites="kolmogorov1933">(<a href="#ref-kolmogorov1933" role="doc-biblioref">Kolmogorov 1933</a>)</span>, <span class="citation" data-cites="smirnov1939">(<a href="#ref-smirnov1939" role="doc-biblioref">Smirnov 1939</a>)</span> and are among the most
widely used tests today. There is a known large sample distribution of
the test statistic in the two-sample problem, which is used either if
both sample sizes exceed 10000 or if the argument <em>UseLargeSample=TRUE</em>
is set. In the goodness-of-fit case the large sample theory is known
only in the case of a fully specified distribution under the null
hypothesis. Because this is rarely of interest the large sample
approximation is not used.</p>
<ol type="1">
<li><strong>Kuiper (K)</strong></li>
</ol>
<p>This test is closely related to Kolmogorov-Smirnov, but it uses the sum
of the largest positive and negative differences as a test statistic. It
was first proposed in <span class="citation" data-cites="kuiper1960">(<a href="#ref-kuiper1960" role="doc-biblioref">Kuiper 1960</a>)</span>.</p>
<ol type="1">
<li><strong>Cramer-vonMises (CvM)</strong></li>
</ol>
<p>This test is based on the integrated squared differences:</p>
<ul>
<li><p>Goodness-of-Fit:
<span class="math inline">\(\int_{-\infty}^{\infty} \left(F(x)-\widehat{F}(x)\right)^2 dF(x)\)</span></p></li>
<li><p>Two-Sample:
<span class="math inline">\(\int_{-\infty}^{\infty} \left(\widehat{F}(x)-\widehat{G}(x)\right)^2 d\widehat{H}(x)\)</span></p></li>
</ul>
<p>The goodness-of-fit version is discussed in <span class="citation" data-cites="cramer1928">(<a href="#ref-cramer1928" role="doc-biblioref">Cramer 1928</a>)</span> and
<span class="citation" data-cites="mises1928">(<a href="#ref-mises1928" role="doc-biblioref">Mises 1928</a>)</span>. The two-sample version was proposed in <span class="citation" data-cites="anderson1962">(<a href="#ref-anderson1962" role="doc-biblioref">Anderson 1962</a>)</span>.</p>
<ol type="1">
<li><strong>Anderson-Darling (AD)</strong></li>
</ol>
<p>This test is similar to the Cramer-vonMises test but with an integrand
that emphasizes the tails:</p>
<ul>
<li><p>Goodness-of-Fit:
<span class="math inline">\(\int_{-\infty}^{\infty} \frac{\left(F(x)-\widehat{F}(x)\right)^2}{F(x)(1-F(x)} dF(x)\)</span></p></li>
<li><p>Two-Sample:
<span class="math inline">\(\int_{-\infty}^{\infty} \frac{\left(\widehat{F}(x)-\widehat{G}(x)\right)^2}{\widehat{H}(x)(1-\widehat{H}(x)} d\widehat{H}(x)\)</span></p></li>
</ul>
<p>It was first proposed in <span class="citation" data-cites="anderson1952">(<a href="#ref-anderson1952" role="doc-biblioref">Anderson and Darling 1952</a>)</span>. The two-sample version is
discussed in <span class="citation" data-cites="pettitt1976">(<a href="#ref-pettitt1976" role="doc-biblioref">Pettitt 1976</a>)</span>.</p>
<ol type="1">
<li><strong>Zhang’s tests (ZA, ZK and ZC)</strong></li>
</ol>
<p>These tests were proposed in <span class="citation" data-cites="zhang2002">(<a href="#ref-zhang2002" role="doc-biblioref">Zhang 2002</a>)</span> and <span class="citation" data-cites="zhang2006">(<a href="#ref-zhang2006" role="doc-biblioref">Zhang 2006</a>)</span>. They are
variations of test statistics based on the likelihood ratio and
different weight functions. Note that these tests do not work for
discrete data, that is, they never achieve the correct type I error
rate. They are therefore not run for discrete data.</p>
<ol type="1">
<li><strong>Wasserstein p=1 (Wassp1)</strong></li>
</ol>
<p>A test using the Wasserstein p=1 metric. It is based on a comparison of
quantiles. In the goodness-of-fit case these are the quantiles of the
data set and the quantiles of the cdf, and in the two-sample problem
they are the quantiles of the individual data sets and the quantiles of
the combined data set. If <span class="math inline">\(n=m\)</span> the test statistic in the continuous
case takes a very simple form: <span class="math inline">\(\frac1n\sum_{i=1}^n |x_i-y_i|\)</span>. In the
goodness-of-fit problem for continuous data the user has to supply a
function that calculates the inverse of the cdf under the null
hypothesis. For a discussion of the Wasserstein distance see
<span class="citation" data-cites="wasserstein1969">(<a href="#ref-wasserstein1969" role="doc-biblioref">Vaserstein 1969</a>)</span>.</p>
<p>There are also a number of tests which are only implemented for either
the goodness-of-fit or the two-sample problem:</p>
<ol type="1">
<li><strong>Watson’s Test (W), Goodness-of-Fit Problem</strong></li>
</ol>
<p>This test is closely related to the Cramer-vonMises test. It adjust that
tests statistic via a squared difference of the mean of
<span class="math inline">\(\widehat{F}(x_i)\)</span> and 0.5. It was proposed in <span class="citation" data-cites="watson1961">(<a href="#ref-watson1961" role="doc-biblioref">Watson 1961</a>)</span>.</p>
<ol type="1">
<li><strong>Lehmann-Rosenblatt (LR), Two-sample Problem</strong></li>
</ol>
<p>Let <span class="math inline">\(r_i\)</span> and <span class="math inline">\(s_i\)</span> be the ranks of x and y in the combined sample, then
the test statistic is given by</p>
<p><span class="math display">\[\frac1{nm(n+m)}\left[n\sum_{i=1}^n(r_i-1)^2+m\sum_{i=1}^m(s_i-1)^2\right]\]</span></p>
<p>For details see <span class="citation" data-cites="lehmann1951">(<a href="#ref-lehmann1951" role="doc-biblioref">Lehmann 1951</a>)</span> and <span class="citation" data-cites="rosenblatt1952">(<a href="#ref-rosenblatt1952" role="doc-biblioref">Rosenblatt 1952</a>)</span>.</p>
<h3 data-number="5" id="simultaneous-inference"><span class="header-section-number">5</span> Simultaneous inference</h3>
<p>As no single test can be relied upon to consistently have good power, it
is reasonable to employ several of them. We would then reject the null
hypothesis if any of the tests does so, that is, if the smallest p value
is less than the desired type I error probability <span class="math inline">\(\alpha\)</span>.</p>
<p>This procedure clearly suffers from the problem of simultaneous
inference, and the true type I error probability will be much larger
than <span class="math inline">\(\alpha\)</span>. It is however possible to adjust the p value so it does
achieve the nominal type I error. A sketch of the algorithm is as
follows:</p>
<ul>
<li><p>generate a new data set under the null hypothesis, run the desired
tests and record the smallest p value.</p></li>
<li><p>repeat B(=1000) times.</p></li>
<li><p>use the empirical distribution function <span class="math inline">\(\hat{F}_p\)</span> of the B
smallest p values to estimate their distribution function.</p></li>
<li><p>apply <span class="math inline">\(\hat{F}_p\)</span> to the smallest p value of the data set. This is
essentially the probability integral transform.</p></li>
</ul>
<p>Here is an example: say the null hypothesis specifies a uniform <span class="math inline">\([0,1]\)</span>
distribution and a sample size of 250. Next we find the smallest p value
in each run for two selections of four methods. One includes the methods
by Wilson, Anderson-Darling, Zhang’s ZC and a chi square test with a
small number of bins and using Pearson’s formula. This selection has
good power against a large number of alternatives. As a second selection
we use the methods by Kolmogorov-Smirnov, Kuiper, Anderson-Darling and
Cramer-vonMises. For the case where the null hypothesis specifies a
Uniform <span class="math inline">\([0,1]\)</span> distribution these tests turn out to be highly
correlated.</p>
<p>Next we find the empirical distribution function for the two sets of p
values and draw their graphs. We also add the curve for the cases of
four identical tests and the case of four independent tests, which of
course is the Bonferroni correction. These are shown in figure 1.</p>
<figure id="fig:fig1">
<img src="figures/fig1.png" style="width:4in" alt="Figure 1: Distribution functions of the smallest p value for four dependence cases." />
<figcaption aria-hidden="true">Figure 1: Distribution functions of the smallest p value for four
dependence cases.</figcaption>
</figure>
<p>As one would expect, the two curves for the p values fall between the
extreme cases of total dependence and independence. Moreover, the curve
of our good selection is closer to the curve of independence than the
selection of correlated methods.</p>
<p>Finally we simply have to apply this function to the smallest p value
found for the actual data.</p>
<p><em>Rgof::gof_test_adjusted_pvalues</em> and
<em>R2sample::twosample_test_adjusted_pvalues</em> find these adjusted p
values. Their arguments are the same as those of <em>Rgof::gof_test</em> and
<em>R2sample::twosample_test</em>, see the section Usage
<a href="#usage" data-reference-type="ref" data-reference="usage">7</a>. For an example that
uses this adjustment method in the context of simultaneous confidence
bands see <span class="citation" data-cites="aldor2013">(<a href="#ref-aldor2013" role="doc-biblioref">Aldor-Noima et al. 2013</a>)</span>.</p>
<h3 data-number="6" id="special-circumstances"><span class="header-section-number">6</span> Special circumstances</h3>
<h4 class="unnumbered" data-number="6.1" id="random-sample-size">Random sample size</h4>
<p>In some cases the sample size is not determined at the beginning of the
experiment but is a consequence of other factors. As an example, in high
energy physics experiments the sample size is determined by the
luminosity (aka energy) at which the accelerator is run, and by how
long. In such a situation the distributions of the test statistics are
different from the fixed sample size case, and there are no known null
distributions. In the case of the chi-square tests, for example, the bin
counts are now independent according to the theory of marked Poisson
processes, and therefore the degrees of freedom need to be adjusted
accordingly. Often though it is reasonable to assume that the sample
size has a Poisson distribution. If so the routines in <em>Rgof</em> and
<em>R2sample</em> have an argument <em>rate</em> to indicate a random sample size from
a Poisson distribution with rate <span class="math inline">\(\lambda\)</span>.</p>
<h4 class="unnumbered" data-number="6.2" id="weighted-samples">Weighted samples</h4>
<p>Another variation is as follows. Say we have a continuous random
variable <span class="math inline">\(X\)</span> and a weight function <span class="math inline">\(w\)</span>. There also exists a random
variable <span class="math inline">\(Y\)</span> such that <span class="math inline">\(E[f(Y)]=E[f(X)w(x)]\)</span> for (almost) any function
<span class="math inline">\(f\)</span>. In other words, these are weights as one encounters in importance
sampling. Say we wish to test whether the distribution of <span class="math inline">\(Y\)</span> is <span class="math inline">\(F\)</span> but
using observations from <span class="math inline">\(X\)</span> with their weights. This is done very easily
with the routines by supplying the weights as arguments. These weights
can then be used to find for example the empirical distribution
function, and with it run tests such as Kolmogorov-Smirnov or
Anderson-Darling.</p>
<p>One field were this situation is common is high energy physics. There we
have the Standard Model, the current best model for explaining the
physics of collision experiments in particle accelerators such as the
Large Hadron Collider at CERN. Say we wish to test some specific part of
this theory, that is we want to do a goodness-of-fit test. However, the
Standard Model depends on dozens of parameters. The calculations of the
probabilities needed for a goodness-of-fit test are at present not
feasible. Among other issues they would require integration in very high
dimensions. However, it is possible to generate a Monte Carlo sample
from the Standard Model, so instead we can run a two-sample test,
comparing the data to the Monte Carlo sample. There is however another
problem. The Monte Carlo sampling of the Standard Model is very
computationally expensive. There exist a number of such samples, each
for a specific set of the parameters of the Standard Model. Now if the
test we wish to do requires a sample with a slightly different set of
parameters we can use an existing sample and importance sampling. The
routines in the packages discussed here make this very easy.</p>
<h3 data-number="7" id="usage"><span class="header-section-number">7</span> Usage</h3>
<h4 class="unnumbered" data-number="7.1" id="goodness-of-fit-problem---testing">Goodness-of-fit problem - testing</h4>
<p>The routine to carry out hypothesis tests is <em>Rgof::gof_test</em>. It’s
arguments are</p>
<ul>
<li><p>x: a data set, either the continuous outcomes or the counts in the
discrete case.</p></li>
<li><p>vals=NA: all possible values of the discrete random variable, or NA
if data is continuous.</p></li>
<li><p>pnull: a function to calculate values for the cdf.</p></li>
<li><p>rnull: a function to generate new data under the null hypothesis.</p></li>
<li><p>w=function(x) -99: a weight function if weights are present, or -99
if not.</p></li>
<li><p>phat=function(x) -99: a function to estimate parameters, or -99 if
null hypothesis is simple and no parameters are estimated.</p></li>
<li><p>TS: routine to calculate test statistics other than those included.</p></li>
<li><p>TSextra: a list passed to TS.</p></li>
<li><p>nbins=c(50, 10): number of bins to use in chi-square tests.</p></li>
<li><p>rate=0: rate of Poisson if sample size is random, 0 if sample size
is fixed.</p></li>
<li><p>Range=c(-Inf, Inf): range of continuous random variable.</p></li>
<li><p>B=5000: number of simulation runs.</p></li>
<li><p>minexpcount=5: required minimal expected counts for chi-square
tests.</p></li>
<li><p>maxProcessors=1: number of cores to use for parallel processing, 1
means no parallel programming.</p></li>
<li><p>doMethod=“all”: vector with names of methods, if not all are to be
included.</p></li>
</ul>
<p>The format of the routines pnull, rnull and w has to be as follows. In
the continuous case we will use as an example the normal distribution
and in the discrete case the Binomial distribution with 10 tries.</p>
<ul>
<li><p>Continuous data, no parameter estimation: a function of one
variable, the data. For example, pnull=function(x) pnorm(x)</p></li>
<li><p>Continuous data, with parameter estimation: a function of two
variables, the data and a vector of parameter estimates. For
example, pnull=function(x,p) pnorm(x,p[1],p[2])</p></li>
<li><p>Discrete data, no parameter estimation: a function without
arguments. For example, pnull=function() pbinom(0:10, 10, 0.5)</p></li>
<li><p>Discrete data, with parameter estimation: a function of one
variable, a vector of parameter estimates. For example,
pnull=function(p) pbinom(0:10, 10, p)</p></li>
</ul>
<h5 class="unnumbered" data-number="7.1.1" id="continuous-data">Continuous data</h5>
<p>As an example we generate <span class="math inline">\(N=1000\)</span> observations from a standard normal
distribution. Then we test to see whether the data comes from a normal
distribution with the mean estimated from the data, so in this case the
null hypothesis is true:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>pnull <span class="ot">=</span> <span class="cf">function</span>(x, <span class="at">mu=</span><span class="dv">0</span>) <span class="fu">pnorm</span>(x, mu) <span class="co"># cdf under null hypothesis</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>rnull <span class="ot">=</span> <span class="cf">function</span>(<span class="at">mu=</span><span class="dv">0</span>) <span class="fu">rnorm</span>(<span class="dv">1000</span>, mu) <span class="co"># generate data under null hypothesis</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>phat <span class="ot">=</span> <span class="cf">function</span>(x) <span class="fu">mean</span>(x) <span class="co"># estimate parameter </span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">rnull</span>() <span class="co"># data from distribution under the null hypothesis</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>Rgof<span class="sc">::</span><span class="fu">gof_test</span>(x, <span class="cn">NA</span>, pnull, rnull, <span class="at">phat=</span>phat)</span></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $statistics</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      KS       K       AD      CvM       W        ZA      ZK      ZC    </span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   0.0208   0.0407   0.6500   0.0926   0.0911   3.2940  1.4780  12.4900    </span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    ES-l-P   ES-s-P   EP-l-P   EP-s-P   ES-l-L   ES-s-L  EP-l-L   EP-s-L </span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   37.4800   9.6060   51.7300  11.9200  38.5700  9.4030  50.2600  12.4700 </span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $p.values</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     KS      K     AD     CvM      W      ZA      ZK      ZC  </span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 0.4712 0.4712   0.2328 0.2546  0.2354  0.6292  0.7692  0.5828 </span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ES-l-P  ES-s-P  EP-l-P  EP-s-P  ES-l-L  ES-s-L  EP-l-L EP-s-L </span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 0.4011  0.2120  0.3302  0.1550  0.3542  0.2250  0.3840  0.1315</span></span></code></pre></div>
<p>If we wish to find an adjusted p value for a combination of tests we can
run</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>Rgof<span class="sc">::</span><span class="fu">gof_test_adjusted_pvalue</span>(x, <span class="cn">NA</span>, pnull, rnull, <span class="at">phat=</span>phat)</span></code></pre></div>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; p values of individual tests:</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; W :  0.128</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ZC :  0.232</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; AD :  0.08</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ES-s-P :  0.212</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; adjusted p value of combined tests: 0.2267</span></span></code></pre></div>
<p>Next we generate a data set from a t distribution with 5 degrees of
freedom, so now the null hypothesis is false. Here and in the examples
that follow we only show the p values of the tests:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">rt</span>(<span class="dv">1000</span>, <span class="dv">5</span>) <span class="co"># data where null hypothesis is false</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>Rgof<span class="sc">::</span><span class="fu">gof_test</span>(y, <span class="cn">NA</span>, pnull, rnull, <span class="at">phat=</span>phat)[[<span class="st">&quot;p.values&quot;</span>]]</span></code></pre></div>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     KS       K      AD      CvM      W       ZA     ZK     ZC </span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   0.0106  0.0106  0.0000  0.0048   0.0034  0.0000  0.0000 0.0000     </span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   ES-l-P  ES-s-P  EP-l-P  EP-s-P  ES-l-L  ES-s-L  EP-l-L  EP-s-L </span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0408</span></span></code></pre></div>
<p>If the quantile function (aka inverse) of the cdf is known it can be
included. It is then used in some of the chi-square tests and the
Wasserstein test. It can be passed to the routine that finds the test
statistic(s) via the list TSextra:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>TSextra <span class="ot">=</span> <span class="fu">list</span>(<span class="at">qnull=</span><span class="cf">function</span>(x, mu) <span class="fu">qnorm</span>(x, mu))</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>Rgof<span class="sc">::</span><span class="fu">gof_test</span>(x, <span class="cn">NA</span>, pnull, rnull, <span class="at">phat=</span>phat, <span class="at">TSextra=</span>TSextra)[[<span class="st">&quot;p.values&quot;</span>]]</span></code></pre></div>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     KS      K      AD      CvM      W      ZA      ZK      ZC    Wassp1  </span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  0.4710  0.4710  0.2288  0.2444  0.2238  0.6198  0.7664  0.5762  0.1760 </span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  ES-l-P  ES-s-P  EP-l-P  EP-s-P  ES-l-L  ES-s-L  EP-l-L  EP-s-L </span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  0.4011  0.2120  0.5634  0.4413  0.3542  0.2250  0.5182  0.4210</span></span></code></pre></div>
<p>A user can also use this routine to run their own test. For example,
let’s say we wish to include the Neyman’s smooth test from the <em>DDST</em> (P
Niecek 2016) package:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>NeymanSmoothTest <span class="ot">=</span> <span class="cf">function</span>(x, pnull, param) {</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  ts<span class="ot">=</span><span class="fu">as.numeric</span>(<span class="fu">unlist</span>(ddst<span class="sc">::</span><span class="fu">ddst.norm.test</span>(x))[<span class="dv">1</span>])</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">names</span>(ts) <span class="ot">=</span> <span class="st">&quot;DDST&quot;</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  ts</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>Rgof<span class="sc">::</span><span class="fu">gof_test</span>(x, <span class="cn">NA</span>, pnull, rnull, <span class="at">phat=</span>phat, <span class="at">TS=</span>NeymanSmoothTest)[[<span class="st">&quot;p.values&quot;</span>]]</span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   DDST </span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 0.5482</span></span></code></pre></div>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>Rgof<span class="sc">::</span><span class="fu">gof_test</span>(y, <span class="cn">NA</span>, pnull, rnull, <span class="at">phat=</span>phat, <span class="at">TS=</span>NeymanSmoothTest)[[<span class="st">&quot;p.values&quot;</span>]]</span></code></pre></div>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; DDST </span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    0</span></span></code></pre></div>
<p>The routine has to have the following form:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">newTS</span>(x, pnull, param, TSextra)</span></code></pre></div>
<p>x is the data set and pnull the distribution function under the null
hypothesis, as described above. param is the estimated parameters in the
case of a composite null hypothesis and is ignored in the case without
parameter estimation. The argument TSextra, a list of items also needed
for calculating the test statistic, is optional.</p>
<p>Next we assume that the sample size was random and drawn from a Poisson
distribution with rate 950. One of the consequences of this is that now
the degrees of freedom of the chi-square tests is the number of bins -
number of estimated parameters rather than number of bins - 1 - number
of estimated parameters.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>Rgof<span class="sc">::</span><span class="fu">gof_test</span>(x, <span class="cn">NA</span>, pnull, rnull, <span class="at">phat=</span>phat, <span class="at">TSextra=</span>TSextra, <span class="at">rate=</span><span class="dv">950</span>)[[<span class="st">&quot;p.values&quot;</span>]]</span></code></pre></div>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     KS      K      AD     CvM      W       ZA      ZK      ZC    Wassp1 </span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  0.4736  0.4736  0.2406  0.2580  0.2372  0.6206  0.7642  0.5782  0.1904</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  ES-l-P ES-s-P EP-l-P EP-s-P ES-l-L ES-s-L EP-l-L EP-s-L </span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  0.2602 0.1210 0.4009 0.2779 0.2936 0.1517 0.4539 0.2957 </span></span></code></pre></div>
<p>As an example for the use of importance sampling weights we generate the
data from a mixture of two normal random variables but as above test for
a simple normal distribution with unknown mean.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>rnull <span class="ot">=</span> <span class="cf">function</span>(<span class="at">mu=</span><span class="dv">0</span>) <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">500</span>, <span class="sc">-</span><span class="dv">1</span>), <span class="fu">rnorm</span>(<span class="dv">500</span>, <span class="dv">1</span>))</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">rnull</span>()</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>w<span class="ot">=</span><span class="cf">function</span>(x, <span class="at">mu=</span><span class="dv">0</span>) <span class="fu">dnorm</span>(x, mu)<span class="sc">/</span>(<span class="fu">dnorm</span>(x, <span class="sc">-</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span><span class="sc">+</span><span class="fu">dnorm</span>(x, <span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>Rgof<span class="sc">::</span><span class="fu">gof_test</span>(x, <span class="cn">NA</span>, pnull, rnull, <span class="at">w=</span>w, <span class="at">phat=</span>phat)[[<span class="st">&quot;p.values&quot;</span>]]</span></code></pre></div>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     KS      K     CvM      AD </span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  0.7990  0.7718  0.6330  0.4516</span></span></code></pre></div>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>Rgof<span class="sc">::</span><span class="fu">gof_test</span>(y, <span class="cn">NA</span>, pnull, rnull, <span class="at">w=</span>w, <span class="at">phat=</span>phat)[[<span class="st">&quot;p.values&quot;</span>]]</span></code></pre></div>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     KS      K    CvM     AD </span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     0       0     0      0</span></span></code></pre></div>
<h5 class="unnumbered" data-number="7.1.2" id="discrete-data">Discrete data</h5>
<p>Here we will consider the following example. The null hypothesis
specifies a binomial distribution with <span class="math inline">\(n=100\)</span> trials and a success
probability <span class="math inline">\(p\)</span>, estimated from the data. As an example where the null
hypothesis is false we generate data that is a mixture of a binomial
distribution with <span class="math inline">\(p=0.5\)</span> and a discrete uniform distribution on the
integers from 30 to 70.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>vals <span class="ot">=</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">100</span> <span class="co"># all possible values</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>pnull <span class="ot">=</span> <span class="cf">function</span>(<span class="at">p=</span><span class="fl">0.5</span>) <span class="fu">pbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">100</span>, <span class="dv">100</span>, p)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>rnull <span class="ot">=</span> <span class="cf">function</span>(<span class="at">p=</span><span class="fl">0.5</span>) <span class="fu">table</span>(<span class="fu">c</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">100</span>,<span class="fu">rbinom</span>(<span class="dv">1000</span>, <span class="dv">100</span>, p)))<span class="sc">-</span><span class="dv">1</span>  </span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>phat <span class="ot">=</span> <span class="cf">function</span>(x) <span class="fu">mean</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">100</span><span class="sc">*</span>x)<span class="sc">/</span><span class="dv">1000</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">rnull</span>()</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>Rgof<span class="sc">::</span><span class="fu">gof_test</span>(x, vals, pnull, rnull, <span class="at">phat=</span>phat)<span class="sc">$</span>p.values</span></code></pre></div>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      KS      K      AD     CvM      W     Wassp1    l-P    s-P    l-L     s-L </span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   0.2320  0.2752  0.4858  0.3132  0.2460  0.6257  0.1599  0.5592  0.1456 0.1456</span></span></code></pre></div>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">table</span>(<span class="fu">c</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">100</span>, <span class="fu">rbinom</span>(<span class="dv">900</span>, <span class="dv">100</span>, <span class="fl">0.5</span>), <span class="fu">sample</span>(<span class="dv">30</span><span class="sc">:</span><span class="dv">70</span>, <span class="at">size=</span><span class="dv">100</span>, <span class="at">replace=</span><span class="cn">TRUE</span>)))<span class="sc">-</span><span class="dv">1</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>Rgof<span class="sc">::</span><span class="fu">gof_test</span>(y, vals, pnull, rnull, <span class="at">phat=</span>phat)<span class="sc">$</span>p.values</span></code></pre></div>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     KS      K       AD     CvM      W       l-P    s-P      l-L    s-L </span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   0.3846  0.3290  0.0000  0.0174  0.0114  0.0000  0.0000  0.0000  0.0000</span></span></code></pre></div>
<p>Here we have an example where most tests correctly reject the null
hypothesis but some do not.</p>
<p>Note that the routine <em>rnull</em> has to insure that all values of <em>vals</em>
are present, even if many have counts of zero.</p>
<p>Again the user can provide his/her own test statistic. The routine has
to be as follows:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">newTS</span>(x, pnull, param, vals, TSextra)</span></code></pre></div>
<p>Here x is the counts and pnull the distribution function under the null
hypothesis as described above. param is the estimated parameters in the
case of a composite null hypothesis and is ignored in the case without
parameter estimation. vals is the set of values where <span class="math inline">\(P(X=vals)&gt;0\)</span>. The
argument TSextra, a list of items also needed for calculating the test
statistic, is optional.</p>
<h4 class="unnumbered" data-number="7.2" id="goodness-of-fit-problem---power-estimation">Goodness-of-fit problem - power estimation</h4>
<p>To estimate the power of the various tests we can use the function
<em>gof_power</em>. It’s arguments are the same as <em>gof_test</em>, as well as</p>
<ul>
<li><p>ralt: a function that generates data under the alternative
hypothesis.</p></li>
<li><p>param_alt: a vector of values to be passed to ralt.</p></li>
<li><p>With.p.value=FALSE: set to TRUE if the new user supplied routine
calculates p values.</p></li>
<li><p>alpha=0.05: type I error probability to be used for test.</p></li>
<li><p>B=1000: number simulation runs.</p></li>
</ul>
<p>As an example say we wish to estimate the power of the tests when the
null hypothesis specifies a normal distribution, but the data comes from
a t distribution. We have 500 observations, and both the mean and
standard deviation are estimated from the data. The package also
includes the routine <em>plot_power</em>, which has as its argument the output
from the <em>gof_power</em> command and draws the power curve. It is shown in
figure 2.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>pnull <span class="ot">=</span> <span class="cf">function</span>(x, <span class="at">p=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>)) <span class="fu">pnorm</span>(x, p[<span class="dv">1</span>], p[<span class="dv">2</span>]) <span class="co"># cdf under null hypothesis</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>rnull <span class="ot">=</span> <span class="cf">function</span>(<span class="at">p=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>)) <span class="fu">rnorm</span>(<span class="dv">500</span>, p[<span class="dv">1</span>], p[<span class="dv">2</span>]) <span class="co"># generate data under null hypothesis</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>phat <span class="ot">=</span> <span class="cf">function</span>(x) <span class="fu">c</span>(<span class="fu">mean</span>(x), <span class="fu">sd</span>(x)) <span class="co"># estimate parameters</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>TSextra <span class="ot">=</span> <span class="fu">list</span>(<span class="at">qnull =</span> <span class="cf">function</span>(x, <span class="at">p=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>)) <span class="fu">qnorm</span>(x, p[<span class="dv">1</span>], p[<span class="dv">2</span>])) <span class="co"># quantile function</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>ralt <span class="ot">=</span> <span class="cf">function</span>(df) <span class="fu">rt</span>(<span class="dv">500</span>, df) <span class="co"># generate data under alternative</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>tmp<span class="ot">=</span>Rgof<span class="sc">::</span><span class="fu">gof_power</span>(pnull, <span class="cn">NA</span>, rnull, ralt, <span class="at">param_alt=</span><span class="dv">4</span><span class="sc">*</span><span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, <span class="at">phat=</span>phat, <span class="at">TSextra =</span> TSextra)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>Rgof<span class="sc">::</span><span class="fu">plot_power</span>(tmp, <span class="st">&quot;df&quot;</span>, <span class="st">&quot;Standard Normal vs t Distributions&quot;</span>)</span></code></pre></div>
<figure id="fig:fig2">
<img src="figures/fig2.png" style="width:4in" alt="Figure 2: Power graph for goodness-of-fit-tests of normal vs t distributions, with mean and standard deviation estimated from the data." />
<figcaption aria-hidden="true">Figure 2: Power graph for goodness-of-fit-tests of normal vs t
distributions, with mean and standard deviation estimated from the
data.</figcaption>
</figure>
<p><em>plot_power</em> has the arguments</p>
<ul>
<li><p>pwr: a matrix, usually the output of the <em>gof_power</em> command.</p></li>
<li><p>xname: name of parameter of ralt.</p></li>
<li><p>title=" ": title of graph</p></li>
<li><p>Smooth=TRUE: should curves be smoothed?</p></li>
<li><p>span=0.25: parameter for smoothing routine.</p></li>
</ul>
<p>Power estimation for discrete data works the same. As an example
consider the following. One data set comes from a Poisson distribution,
restricted to the set of integers from 70 to 140. The second data set is
a 50-50 mixture of Poisson random variables with a rate of 100 and a
rate of <span class="math inline">\(100+\lambda\)</span>. The power graph is in figure 3.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>vals<span class="ot">=</span><span class="dv">70</span><span class="sc">:</span><span class="dv">140</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>pnull<span class="ot">=</span><span class="cf">function</span>(lambda) (<span class="fu">ppois</span>(<span class="dv">70</span><span class="sc">:</span><span class="dv">140</span>, lambda)<span class="sc">-</span><span class="fu">ppois</span>(<span class="dv">69</span>,lambda))<span class="sc">/</span>(<span class="fu">ppois</span>(<span class="dv">140</span>, lambda)<span class="sc">-</span><span class="fu">ppois</span>(<span class="dv">69</span>,lambda))</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>rnull<span class="ot">=</span><span class="cf">function</span>(lambda) {</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>  vals<span class="ot">=</span><span class="dv">70</span><span class="sc">:</span><span class="dv">140</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>  x<span class="ot">=</span><span class="fu">rpois</span>(<span class="dv">1000</span>, lambda)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>  x[x<span class="sc">&lt;</span><span class="dv">70</span>]<span class="ot">=</span><span class="dv">70</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>  x[x<span class="sc">&gt;</span><span class="dv">140</span>]<span class="ot">=</span><span class="dv">140</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>  x<span class="ot">=</span><span class="fu">table</span>(<span class="fu">c</span>(<span class="dv">70</span><span class="sc">:</span><span class="dv">140</span>, x))<span class="sc">-</span><span class="dv">1</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>phat<span class="ot">=</span><span class="cf">function</span>(x) <span class="fu">sum</span>(<span class="dv">70</span><span class="sc">:</span><span class="dv">140</span><span class="sc">*</span>x)<span class="sc">/</span><span class="dv">1000</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>ralt<span class="ot">=</span><span class="cf">function</span>(lambda) {</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>  vals<span class="ot">=</span><span class="dv">70</span><span class="sc">:</span><span class="dv">140</span></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>  x<span class="ot">=</span><span class="fu">c</span>(<span class="fu">rpois</span>(<span class="dv">500</span>, <span class="dv">100</span>), <span class="fu">rpois</span>(<span class="dv">500</span>, <span class="dv">100</span><span class="sc">+</span>lambda))</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>  x[x<span class="sc">&lt;</span><span class="dv">70</span>]<span class="ot">=</span><span class="dv">70</span></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>  x[x<span class="sc">&gt;</span><span class="dv">140</span>]<span class="ot">=</span><span class="dv">140</span></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>  x<span class="ot">=</span><span class="fu">table</span>(<span class="fu">c</span>(<span class="dv">70</span><span class="sc">:</span><span class="dv">140</span>, x))<span class="sc">-</span><span class="dv">1</span></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>tmp<span class="ot">=</span>Rgof<span class="sc">::</span><span class="fu">gof_power</span>(pnull, vals, rnull, ralt, <span class="at">param_alt=</span><span class="dv">2</span><span class="sc">*</span><span class="dv">0</span><span class="sc">:</span><span class="dv">8</span>, <span class="at">phat=</span>phat)</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>Rgof<span class="sc">::</span><span class="fu">plot_power</span>(tmp, <span class="st">&quot;lambda&quot;</span>, <span class="st">&quot;Poisson vs Mixture of Poisson Distributions&quot;</span>)</span></code></pre></div>
<figure id="fig:fig3">
<img src="figures/fig3.png" style="width:4in" alt="Figure 3: Power graph for goodness-of-fit-tests of Poisson vs a mixture of Poisson distributions, with the rate estimated from the data." />
<figcaption aria-hidden="true">Figure 3: Power graph for goodness-of-fit-tests of Poisson vs a
mixture of Poisson distributions, with the rate estimated from the
data.</figcaption>
</figure>
<h4 class="unnumbered" data-number="7.3" id="twosample-problem---testing">Two-sample problem - testing</h4>
<p>p values are generally found using the permutation method. The idea of a
permutation test is simple. Say we have data sets <span class="math inline">\(x_1,..,x_n\)</span> and
<span class="math inline">\(y_1,..,y_m\)</span>. They are combined into one large data set
<span class="math inline">\(x_1,..,x_n, y_1,..,y_m\)</span>, permuted and split again in sets of size n and
m. Under the null hypothesis these new data sets come from the same
distribution as the actual data. Therefore calculating the tests
statistics for them and repeating many times one can build up the
distributions of the test statistics and find p values from them.</p>
<p>In the case of continuous data the routines also allow for the use of
large sample formulas for some of the tests. In the discrete case none
of the methods (outside of the chi-square tests) has a known large
sample theory.</p>
<p>In the discrete case the permutation method is somewhat more
complicated. Say we have data sets with values <span class="math inline">\(v_1,..,v_k\)</span> and counts
<span class="math inline">\(x_1,..,x_k\)</span>, <span class="math inline">\(y_1,..,y_k\)</span>. One can then simply expand these to yield a
large data set with <span class="math inline">\(x_1+y_1\)</span> <span class="math inline">\(v_1\)</span>’s, <span class="math inline">\(x_2+y_2\)</span> <span class="math inline">\(v_2\)</span>’s and so on. Then
this vector is permuted and split as described above. The drawback of
this sampling method is that its calculation speed increases with the
sample size and would be impossible for data sets with very large
counts.</p>
<p>Alternatively <em>R2sample</em> provides the following option. One can show
that the distribution of the permuted data sets is as follows: let
<span class="math inline">\(n=\sum x_i\)</span> and <span class="math inline">\(m=\sum y_i\)</span>, then</p>
<p><span class="math display">\[P(\pmb{X}=\pmb{a}|\pmb{x},\pmb{y})=\left[\prod_{j=1}^k{{{x_j+y_j}\choose{a_j}}}\right]/{{n+m}\choose{n}}\]</span></p>
<p>for any <span class="math inline">\(\pmb{a}\)</span> such that <span class="math inline">\(0\le a_i \le x_i; i=1,..,k\)</span> and
<span class="math inline">\(\sum a_i=n\)</span>.</p>
<p>It is possible to sample from this distribution as follows: Let <span class="math inline">\(N\)</span> and
<span class="math inline">\(M\)</span> be the sample sizes of the two data sets, respectively. Let
<span class="math inline">\(p=N/(N+M)\)</span> be the proportion of events in the first data set. Say that
in a data set we have <span class="math inline">\(x_1\)</span> observations of the smallest discrete value
<span class="math inline">\(v_1\)</span> in the first data set and <span class="math inline">\(y_1\)</span> in the second. We can then
generate a random sample by drawing an observation from a Binomial with
parameters <span class="math inline">\(x_1+y_1\)</span> and <span class="math inline">\(p\)</span>. We repeat this for all values of the
discrete random variable. We also need to insure, though, that the total
number of observations in the first simulated data set is again <span class="math inline">\(N\)</span> and
in the second data set <span class="math inline">\(M\)</span>. If this is not so, we randomly choose two
values, giving a higher priority for those with high counts, and
flipping one observation between the two data sets. This is repeated
until the simulated data set has <span class="math inline">\(N\)</span> events total.</p>
<p>The routine is <em>twosample_test</em>. It’s arguments are</p>
<ul>
<li><p>x, y: the two data sets, either the observations in the continuous
case or the counts in the discrete case. x can also be a list with
elements x and y, and then y is ignored.</p></li>
<li><p>vals=NA: the possible values of the discrete random variables, or NA
for continuous data.</p></li>
<li><p>TS: routine to calculate test statistics other than those included</p></li>
<li><p>TSextra: a list passed to TS</p></li>
<li><p>wx = rep(1, length(x)): weights for x data</p></li>
<li><p>wy = rep(1, length(y)): weights for y data</p></li>
<li><p>B=5000: number of simulation runs</p></li>
<li><p>nbins=c(50,10): number of bins to use in chi -quare tests</p></li>
<li><p>minexpcount=5: required minimal expected counts for chi-square tests</p></li>
<li><p>maxProcessors: number of cores to use for parallel processing,
default is 1 less than are detected on computer</p></li>
<li><p>UseLargeSample: should large sample approximations be used instead
of permutation?</p></li>
<li><p>samplingmethod="Binomial": sampling method for discrete data.</p></li>
<li><p>rnull: a function that generates data from a model, possibly with
parameter estimation. This is needed in the
goodness-of-fit/two-sample hybrid problem.</p></li>
<li><p>doMethod="all": vector with names of methods, if not all are to be
included.</p></li>
</ul>
<p>The arguments match those of <em>gof_test</em>, where this makes sense.</p>
<h5 class="unnumbered" data-number="7.3.1" id="continuous-data-1">Continuous data</h5>
<p>The <span class="math inline">\(x\)</span> and <span class="math inline">\(y1\)</span> data sets come from a standard normal distribution, and
<span class="math inline">\(y2\)</span> from a normal distribution with mean 1.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>y1 <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">150</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>y2 <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">150</span>, <span class="dv">1</span>)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>R2sample<span class="sc">::</span><span class="fu">twosample_test</span>(x, y1)[[<span class="st">&quot;p.values&quot;</span>]]</span></code></pre></div>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      KS   Kuiper    CvM     AD       LR      ZA     ZK      ZC </span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   0.9514  0.8730  0.9242  0.9126  0.8992  0.7480  0.4502  0.7888  </span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   Wassp1 ES large ES small EP large EP small </span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   0.8580   0.6309   0.2454   0.4334   0.9496</span></span></code></pre></div>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>R2sample<span class="sc">::</span><span class="fu">twosample_test</span>(x, y2)[[<span class="st">&quot;p.values&quot;</span>]]</span></code></pre></div>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       KS   Kuiper      CvM       AD       LR       ZA       ZK       ZC </span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        0        0        0        0        0        0        0        0 </span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   Wassp1 ES large ES small EP large EP small </span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        0        0        0        0        0</span></span></code></pre></div>
<p>Again, the user can provide their own test statistic:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>DiffStandardizedMeans <span class="ot">=</span> <span class="cf">function</span>(x, y) {</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>   TS <span class="ot">=</span> <span class="fu">abs</span>(<span class="fu">mean</span>(x)<span class="sc">/</span><span class="fu">sd</span>(x)<span class="sc">-</span><span class="fu">mean</span>(y)<span class="sc">/</span><span class="fu">sd</span>(y))</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">names</span>(TS) <span class="ot">=</span> <span class="st">&quot;DSM&quot;</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>   TS</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>R2sample<span class="sc">::</span><span class="fu">twosample_test</span>(x, y1, <span class="at">TS=</span>DiffStandardizedMeans)[[<span class="st">&quot;p.values&quot;</span>]]</span></code></pre></div>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    DSM </span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   0.585</span></span></code></pre></div>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>R2sample<span class="sc">::</span><span class="fu">twosample_test</span>(x, y2, <span class="at">TS=</span>DiffStandardizedMeans)[[<span class="st">&quot;p.values&quot;</span>]]</span></code></pre></div>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; DSM </span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   0</span></span></code></pre></div>
<p>The user supplied routine has to be a function of the two data sets x
and y and optionally a list TSextra.</p>
<p>As an example for weighted data, let’s say the x data set actually came
from a t distribution with 5 degrees of freedom:</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">rt</span>(<span class="dv">100</span>, <span class="dv">5</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>wx <span class="ot">=</span> <span class="fu">dnorm</span>(x)<span class="sc">/</span><span class="fu">dt</span>(x, <span class="dv">5</span>)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>R2sample<span class="sc">::</span><span class="fu">twosample_test</span>(x, y1, <span class="at">wx=</span>wx)[[<span class="st">&quot;p.values&quot;</span>]]</span></code></pre></div>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       KS   Kuiper    CvM     AD    ES large  ES small  EP large  EP small </span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    0.2400  0.2354  0.2522  0.2560   0.7627    0.8632    0.3814    0.8636</span></span></code></pre></div>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>R2sample<span class="sc">::</span><span class="fu">twosample_test</span>(x, y2, <span class="at">wx=</span>wx)[[<span class="st">&quot;p.values&quot;</span>]]</span></code></pre></div>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       KS   Kuiper      CvM       AD ES large ES small EP large EP small </span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    0.0004   0.0004   0.0000   0.0000   0.0001   0.0000   0.0270   0.0000</span></span></code></pre></div>
<p>If the data sets are very large using permutation to derive the null
distribution of the test statistics can be very slow. In this case one
can use the argument <em>UseLargeSample=TRUE</em>. This will be done
automatically if both sample sizes are at least 10000.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="fl">1e5</span>)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>y1 <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="fl">1e5</span>)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>y2 <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="fl">1e5</span>, <span class="fl">0.02</span>)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>R2sample<span class="sc">::</span><span class="fu">twosample_test</span>(x, y1)[[<span class="st">&quot;p.values&quot;</span>]]</span></code></pre></div>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      KS   Kuiper    CvM      AD     </span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   0.098  0.1214   0.1602   0.1330   </span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   ES large  ES small   EP large  EP small </span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    0.2683    0.3347     0.0974    0.1988</span></span></code></pre></div>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>R2sample<span class="sc">::</span><span class="fu">twosample_test</span>(x, y2)[[<span class="st">&quot;p.values&quot;</span>]]</span></code></pre></div>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     KS    Kuiper      CvM     AD </span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  0.0112  0.0542    0.0046  0.0013 </span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   ES large  ES small  EP large  EP small </span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    0.0935     0.0074   0.6170    0.0717</span></span></code></pre></div>
<h5 class="unnumbered" data-number="7.3.2" id="discrete-data-1">Discrete data</h5>
<p>As an example for the case of discrete data we will use two data sets
from geometric random variables with slightly different rates. x and y
have to have the same length as vals and x+y has to be positive for all
values in vals.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">table</span>(<span class="fu">rgeom</span>(<span class="dv">1000</span>, <span class="fl">0.7</span>))</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">table</span>(<span class="fu">rgeom</span>(<span class="dv">1000</span>, <span class="fl">0.8</span>))</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>vals <span class="ot">=</span> <span class="fu">unique</span>(<span class="fu">c</span>(<span class="fu">names</span>(x), <span class="fu">names</span>(y))) <span class="co"># all values from either x or y</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="fu">length</span>(vals))</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(x1)<span class="ot">=</span>vals</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>y1 <span class="ot">=</span> x1</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>x1[<span class="fu">names</span>(x)]<span class="ot">=</span>x</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>y1[<span class="fu">names</span>(y)]<span class="ot">=</span>y</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>vals <span class="ot">=</span> <span class="fu">as.numeric</span>(vals)</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>R2sample<span class="sc">::</span><span class="fu">twosample_test</span>(x1, y1, vals)[[<span class="st">&quot;p.values&quot;</span>]]</span></code></pre></div>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     KS Kuiper    CvM     AD     LR     ZA Wassp1  large  small </span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      0      0      0      0      0      0      0      0      0</span></span></code></pre></div>
<p>Again the user can supply their own test. The routine has to be a
function of the two data sets x and y and a vector <em>vals</em> of possible
values of the discrete random variable. A list TSextra is optional.</p>
<h4 class="unnumbered" data-number="7.4" id="two-sample-problem---power-estimation">Two-sample problem - power estimation</h4>
<p>The package <em>R2sample</em> includes the routine <em>twosample_power</em>. The
arguments TS, TSextra, B, nbins, minexpcount, UseLargeSample and
maxProcessor are the same as in <em>twosample_test</em>. In addition we have</p>
<ul>
<li><p>f: a function that generates a list with two vectors called x and y
and (in the case of discrete data) a vector vals. The function can
have zero, one or two arguments.</p></li>
<li><p>… arguments passed to f.</p></li>
<li><p>With.p.value=FALSE: set to TRUE is user supplied routine calculates
p values.</p></li>
<li><p>alpha=0.05: type I error probability for the tests.</p></li>
</ul>
<p>As an example for continuous data we again consider the case of normal
vs t distributions. One data set with 10001 observations comes from a
standard normal distribution, the other with 10002 observations from a t
distribution with df degrees of freedom. Because of the large sample
sizes the large sample approximations are used.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>f<span class="ot">=</span><span class="cf">function</span>(df) {</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>  x<span class="ot">=</span><span class="fu">rnorm</span>(<span class="dv">10001</span>)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>  y<span class="ot">=</span><span class="fu">rt</span>(<span class="dv">10002</span>, df)</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(<span class="at">x=</span>x, <span class="at">y=</span>y)</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>tmp<span class="ot">=</span>R2sample<span class="sc">::</span><span class="fu">twosample_power</span>(f, <span class="at">df=</span><span class="fu">seq</span>(<span class="dv">5</span>, <span class="dv">100</span>, <span class="dv">5</span>))</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>R2sample<span class="sc">::</span><span class="fu">plot_power</span>(tmp, <span class="st">&quot;df&quot;</span>, <span class="st">&quot;Data from Standard Normal vs t Distributions&quot;</span>)</span></code></pre></div>
<figure id="fig:fig4">
<img src="figures/fig4.png" style="width:4in" alt="Figure 4: Power graph for two-sample tests where one data set comes from a standard normal distribution and the other from a t distribution." />
<figcaption aria-hidden="true">Figure 4: Power graph for two-sample tests where one data set comes
from a standard normal distribution and the other from a t
distribution.</figcaption>
</figure>
<p>For discrete data we again consider the case of a Poisson random
variable vs a 50-50 mixture of Poisson random variables:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>f<span class="ot">=</span><span class="cf">function</span>(a) {</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>  vals<span class="ot">=</span><span class="dv">70</span><span class="sc">:</span><span class="dv">140</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>  x<span class="ot">=</span><span class="fu">rpois</span>(<span class="dv">1000</span>, <span class="dv">100</span>)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>  x[x<span class="sc">&lt;</span><span class="dv">70</span>]<span class="ot">=</span><span class="dv">70</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>  x[x<span class="sc">&gt;</span><span class="dv">140</span>]<span class="ot">=</span><span class="dv">140</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>  x<span class="ot">=</span><span class="fu">table</span>(<span class="fu">c</span>(<span class="dv">70</span><span class="sc">:</span><span class="dv">140</span>, x))<span class="sc">-</span><span class="dv">1</span></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>  y<span class="ot">=</span><span class="fu">c</span>(<span class="fu">rpois</span>(<span class="dv">500</span>, <span class="dv">100</span>), <span class="fu">rpois</span>(<span class="dv">500</span>, <span class="dv">100</span><span class="sc">+</span>a))</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>  y[y<span class="sc">&lt;</span><span class="dv">70</span>]<span class="ot">=</span><span class="dv">70</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>  y[y<span class="sc">&gt;</span><span class="dv">140</span>]<span class="ot">=</span><span class="dv">140</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>  y<span class="ot">=</span><span class="fu">table</span>(<span class="fu">c</span>(<span class="dv">70</span><span class="sc">:</span><span class="dv">140</span>, y))<span class="sc">-</span><span class="dv">1</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>  I<span class="ot">=</span><span class="fu">seq_along</span>(vals)[x<span class="sc">+</span>y<span class="sc">&gt;</span><span class="dv">0</span>]</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(<span class="at">x=</span>x[I], <span class="at">y=</span>y[I], <span class="at">vals=</span>vals[I])</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>tmp<span class="ot">=</span>R2sample<span class="sc">::</span><span class="fu">twosample_power</span>(f, <span class="at">a=</span><span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">5</span>,<span class="fl">0.25</span>))</span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>R2sample<span class="sc">::</span><span class="fu">plot_power</span>(tmp, <span class="st">&quot;lambda&quot;</span>, <span class="st">&quot;Data from Poisson vs Mixture of Poisson Distributions&quot;</span>)</span></code></pre></div>
<figure id="fig:fig5">
<img src="figures/fig5.png" style="width:4in" alt="Figure 5: Power graph for two-sample tests where one data set comes from Poisson distribution and the other from a mixture of two Poisson distributions." />
<figcaption aria-hidden="true">Figure 5: Power graph for two-sample tests where one data set comes
from Poisson distribution and the other from a mixture of two Poisson
distributions.</figcaption>
</figure>
<h3 data-number="8" id="benchmarking"><span class="header-section-number">8</span> Benchmarking</h3>
<p>Say a researcher has developed a new method for the univariate
goodness-of-fit problem and wants to see how it stacks up in comparison
to the standard methods such as the chi-square tests or the
Kolmogorov-Smirnov test. Both <em>Rgof</em> and <em>R2sample</em> packages include the
routine <em>run_studies</em>, which makes this very easy.</p>
<p>As a specific example say we wish to see whether the Kolmogorov-Smirnov
test or the Anderson-Darling test has better power when the null
hypothesis specifies a normal distribution with mean and standard
deviation unspecified, but in reality the data comes from a t
distribution. Say we run the <em>Rgof::gof_power</em> command for a sample size
of 500, a t distribution with 8 degrees of freedom and a true type I
error of <span class="math inline">\(5\%\)</span>, and we find that the Kolmogorov-Smirnov test has a power
of <span class="math inline">\(43\%\)</span> whereas the Anderson-Darling test has a power of <span class="math inline">\(70\%\)</span>. It is
then true that the Anderson-Darling test will also have a higher power
for any other combination of sample size, degrees of freedom and true
type I error. In order to assess the ranking of the methods it therefore
suffices to run each case study with just one combination of n, <span class="math inline">\(\alpha\)</span>
and the parameter under the alternative.</p>
<h4 class="unnumbered" data-number="8.1" id="goodness-of-fit-problem">Goodness-of-fit problem</h4>
<p>Here the user needs to create a function that finds either the test
statistic or, if possible, the p value of the new test. Its arguments
should be as described previously. Say the routine is called myTS and is
designed for continuous data and calculates the test statistic. Then the
user can run</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">run_studies</span>(myTS)</span></code></pre></div>
<p>This will run 20 different case studies and provide some information on
the relative power of the new method when compared to those included in
<em>Rgof</em>. For a list of the case studies see the appendix.</p>
<p>If the routine actually calculates a p value, run instead</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">run_studies</span>(myTS, <span class="at">With.p.value=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<p>This will of course be much faster as it does not require simulation.</p>
<p>The arguments of <em>run_studies</em> are</p>
<ul>
<li><p>TS: the name of the new test routine</p></li>
<li><p>study: the name of the study to run, or all studies if missing</p></li>
<li><p>TSextra: a list of additional info passed to TS, if such are needed</p></li>
<li><p>With.p.value=FALSE: TRUE if routine finds p values</p></li>
<li><p>BasicComparison=TRUE: if TRUE the values for sample size, type I
error etc from included studies are used.</p></li>
<li><p>nsample = 500: desired sample size</p></li>
<li><p>alpha = 0.05: desired type I error probability</p></li>
<li><p>param_alt: (list of) parameters for alternative distributions</p></li>
<li><p>maxProcessor: number of cores to use for parallel programming,
number of cores - 1 if missing</p></li>
<li><p>B = 1000: number of simulation runs</p></li>
</ul>
<p>As an example we will use the R built-in ks.test to do the
Kolmogorov-Smirnov test:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>myTS<span class="ot">=</span><span class="cf">function</span>(x, pnull, param) {</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>   <span class="cf">if</span>(<span class="fu">length</span>(<span class="fu">formals</span>(pnull))<span class="sc">==</span><span class="dv">1</span>) <span class="co"># case studies without parameter estimation</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>      mypnull<span class="ot">=</span><span class="cf">function</span>(x) <span class="fu">pnull</span>(x)</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>   <span class="cf">else</span> mypnull<span class="ot">=</span><span class="cf">function</span>(x) <span class="fu">pnull</span>(x, param) <span class="co"># case studies with parameter estimation</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>   z<span class="ot">=</span><span class="fu">ks.test</span>(x, mypnull)[[<span class="st">&quot;p.values&quot;</span>]]</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>   <span class="fu">names</span>(z)<span class="ot">=</span><span class="st">&quot;RKS&quot;</span></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>   z</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>pwrs<span class="ot">=</span><span class="fu">run.studies</span>(myTS, <span class="at">With.p.value =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Average number of studies a method is close to the best::</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; EP-l-P ES-l-P EP-l-L  RKS   ES-l-L EP-s-P EP-s-L   KS      K  ES-s-P  </span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  5.450  5.9   6.200  6.900  6.950  8.875  9.175  9.400  9.400 10.175  </span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   W      CvM  ES-s-L  ZA      ZK   Wassp1   ZC     AD </span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 10.525 10.550 10.850 11.625 11.850 12.050 12.300 13.050</span></span></code></pre></div>
<p>Note that the performance of RKS is much lower than that of the
Kolmogorov-Smirnov test included in the <em>Rgof</em> package. This is due to
the fact the <em>R</em> routine ks.test does not actually allow for parameter
estimation.</p>
<p>As another example say the user routine calculates the test statistic
and the user wants to find the power of the methods in the case where
the null hypothesis specifies a normal distribution with mean and
standard deviation estimated from the data, but the true distribution is
a t distributions with df degrees of freedom. He also wants a sample
size of 1000 and a true type I error of 0.1 Then he can run</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">run_studies</span>(myTS, <span class="st">&quot;normal.t.est&quot;</span>, <span class="at">nsample=</span><span class="dv">1000</span>, <span class="at">alpha=</span><span class="fl">0.1</span>, <span class="at">param_alt=</span><span class="dv">5</span><span class="sc">*</span><span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>)</span></code></pre></div>
<h4 class="unnumbered" data-number="8.2" id="two-sample-problem">Two-sample problem</h4>
<p>This works in the exact same way as in the goodness-of-fit problem.</p>
<h4 class="unnumbered" data-number="8.3" id="real-data-examples">Real data examples</h4>
<h5 class="unnumbered" data-number="8.3.1" id="r-sunspots-data">R sunspots data</h5>
<p>This data set has the monthly mean relative sunspot numbers from 1749 to
1983, collected at Swiss Federal Observatory, Zurich until 1960, then
Tokyo Astronomical Observatory. It is part of the base <em>R</em> program. It
is of course a time series, but we will treat it here as if it were
independent data.</p>
<p>A histogram of the data suggests that an exponential model might be a
good fit. However, all the tests in <em>Rgof</em> reject that null hypothesis:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>dta<span class="ot">=</span><span class="fu">data.frame</span>(<span class="at">Sunspots=</span><span class="fu">c</span>(sunspots))</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dta, <span class="fu">aes</span>(<span class="at">x=</span>Sunspots)) <span class="sc">+</span> </span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">color=</span><span class="st">&quot;black&quot;</span>, <span class="at">fill=</span><span class="st">&quot;white&quot;</span>) <span class="sc">+</span> </span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Sunspots Data&quot;</span>)</span></code></pre></div>
<figure id="fig:fig6">
<img src="figures/fig6.png" style="width:4in" alt="Figure 6: Histogram of sunspots data set." />
<figcaption aria-hidden="true">Figure 6: Histogram of sunspots data set.</figcaption>
</figure>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>pnull <span class="ot">=</span> <span class="cf">function</span>(x, <span class="at">p=</span><span class="dv">1</span>) <span class="fu">pexp</span>(x, p)</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>TSextra<span class="ot">=</span><span class="fu">list</span>(<span class="at">qnull=</span> <span class="cf">function</span>(x, <span class="at">p=</span><span class="dv">1</span>) <span class="fu">qexp</span>(x, p))</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>rnull <span class="ot">=</span> <span class="cf">function</span>(p) <span class="fu">rexp</span>(N, p)</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>phat <span class="ot">=</span> <span class="cf">function</span>(x) <span class="dv">1</span><span class="sc">/</span><span class="fu">mean</span>(x)</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>Rgof<span class="sc">::</span><span class="fu">gof_test</span>(<span class="fu">c</span>(sunspots), <span class="cn">NA</span>, pnull, rnull, <span class="at">phat=</span>phat, <span class="at">TSextra =</span> TSextra, <span class="at">Range=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="cn">Inf</span>))</span></code></pre></div>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $statistics</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      KS     K      AD     CvM      W        ZA     ZK       ZC </span></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   0.0631 0.1260  0.000  2.8873  1.8894   0.0000  0.0000  0.0000</span></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   Wassp1   ES-l-P   ES-s-P   EP-l-P   EP-s-P   ES-l-L   ES-s-L   EP-l-L </span></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   5.2559 154.7900 100.0300 252.8700  84.6450 170.2800 122.7200 255.0200 </span></span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   EP-s-L </span></span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  84.1610 </span></span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $p.values</span></span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     KS      K     AD    CvM      W     ZA     ZK     ZC Wassp1 ES-l-P ES-s-P </span></span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      0      0      0      0      0      0      0      0      0      0      0 </span></span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; EP-l-P EP-s-P ES-l-L ES-s-L EP-l-L EP-s-L </span></span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      0      0      0      0      0      0</span></span></code></pre></div>
<h5 class="unnumbered" data-number="8.3.2" id="death-by-horsekicks-data">Death by horsekicks data</h5>
<p>This is the famous data set first discussed in <span class="citation" data-cites="bortkewitsch1898">(<a href="#ref-bortkewitsch1898" role="doc-biblioref">Bortkewitsch 1898</a>)</span> and
analyzed in many statistics text books and articles, see for example
<span class="citation" data-cites="preece1988">(<a href="#ref-preece1988" role="doc-biblioref">Preece et al. 1988</a>)</span>. It is the number of soldiers in the Prussian army killed
by being kicked by a horse between 1875 to 1894. The data is</p>
<div id="tab:T2">
<table style="width:46%;">
<colgroup>
<col style="width: 26%" />
<col style="width: 19%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Number of Deaths</th>
<th style="text-align: right;">Frequencies</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: right;">109</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: right;">65</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2</td>
<td style="text-align: right;">22</td>
</tr>
<tr class="even">
<td style="text-align: left;">3</td>
<td style="text-align: right;">3</td>
</tr>
<tr class="odd">
<td style="text-align: left;">4</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">5+</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
</div>
<p><span id="tab:T2" data-label="tab:T2"></span></p>
<p>We will run the tests to see whether a Poisson model might fit this data
set:</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>vals<span class="ot">=</span><span class="dv">0</span><span class="sc">:</span><span class="dv">5</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>x<span class="ot">=</span><span class="fu">c</span>(<span class="dv">109</span>, <span class="dv">65</span>, <span class="dv">22</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>pnull <span class="ot">=</span> <span class="cf">function</span>(<span class="at">lambda=</span><span class="dv">1</span>) <span class="fu">c</span>(<span class="fu">ppois</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">4</span>,lambda), <span class="dv">1</span>)</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>rnull <span class="ot">=</span> <span class="cf">function</span>(<span class="at">lambda=</span><span class="dv">1</span>) {</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">=</span>  <span class="fu">rpois</span>(<span class="dv">200</span>, lambda)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>  x[x<span class="sc">&gt;</span><span class="dv">5</span>]<span class="ot">=</span><span class="dv">5</span></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">table</span>(<span class="fu">c</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">5</span>, x))<span class="sc">-</span><span class="dv">1</span></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>}  </span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a>phat <span class="ot">=</span> <span class="cf">function</span>(x) <span class="fu">sum</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">5</span><span class="sc">*</span>x)<span class="sc">/</span><span class="dv">200</span></span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>Rgof<span class="sc">::</span><span class="fu">gof_test</span>(x, vals, pnull, rnull, <span class="at">phat=</span>phat)</span></code></pre></div>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $statistics</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     KS      K     AD    CvM      W Wassp1    l-P    s-P    l-L    s-L </span></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 0.5434 0.5481 0.0323 0.0026 4.5350 0.0124 0.0628 0.0628 0.0625 0.0625 </span></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $p.values</span></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     KS      K     AD    CvM      W Wassp1    l-P    s-P    l-L    s-L </span></span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 0.4830 0.6372 0.9434 0.9412 0.5288 0.9386 0.8021 0.8021 0.8026 0.8026</span></span></code></pre></div>
<p>All methods fail to reject the null hypothesis, so the Poisson
distribution is a good model for the horsekick data.</p>
<h3 data-number="9" id="conclusion"><span class="header-section-number">9</span> Conclusion</h3>
<p>The R packages <em>Rgof</em> and <em>R2sample</em> bring together a large number of
methods for the univariate goodness-of-fit problem and the univariate
two-sample problem. The routines make it easy to run these tests
simultaneously. They are implemented for both continuous and discrete
data and can handle a number of different situations such as random
sample sizes and weighted data. The packages also include routines for
power estimation as well as routines for benchmarking new tests.</p>
<h3 data-number="10" id="appendix"><span class="header-section-number">10</span> Appendix</h3>
<h4 class="unnumbered" data-number="10.1" id="case-studies-for-goodness-of-fit-problem">Case Studies for Goodness-of-fit Problem</h4>
<p><strong>Without parameter estimation</strong></p>
<ol type="1">
<li><p>uniform.linear U[0,1] vs a linear model on [0,1] with slope s.</p></li>
<li><p>uniform.quadratic U[0,1] vs a quadratic model with vertex at 0.5
and some curvature a.</p></li>
<li><p>uniform.bump U[0,1] vs U[0,1]+N(0.5,0.05).</p></li>
<li><p>uniform.sine U[0,1] vs U[0,1]+Sine wave</p></li>
<li><p>beta22.betaaa Beta(2,2) vs Beta(a,a)</p></li>
<li><p>beta22.beta2a Beta(2,2) vs Beta(2,a)</p></li>
<li><p>normal.shift N(0,1) vs N(<span class="math inline">\(\mu\)</span>,1)</p></li>
<li><p>normal.stretch N(0,1) vs N(0, <span class="math inline">\(\sigma\)</span>)</p></li>
<li><p>normal.t N(0,1) vs t(df)</p></li>
<li><p>normal.outlier1 N(0,1) vs N(0,1)+U[2,3]</p></li>
<li><p>normal.outlier2 N(0,1) vs N(0,1)+U[-3,-2]+U[2,3]</p></li>
<li><p>exponential.gamma Exp(1) vs Gamma(1,b)</p></li>
<li><p>exponential.weibull Exp(1) vs Weibull(1,b)</p></li>
<li><p>exponential.bump Exp(1) vs Exp(1)+N(0.5,0.05)</p></li>
<li><p>trunc.exponential.linear Exp(1) vs Linear, on [0,1]</p></li>
</ol>
<p><strong>With parameter estimation</strong></p>
<ol type="1">
<li><p>normal.t.est N(<span class="math inline">\(\mu,\sigma\)</span>) vs t(df)</p></li>
<li><p>exponential.weibull.est Exp(<span class="math inline">\(\lambda\)</span>) vs Weibull(1,b)</p></li>
<li><p>trunc.exponential.linear.est Exp(<span class="math inline">\(\lambda\)</span>) vs Linear, on [0,1]</p></li>
<li><p>exponential.gamma.est Exp(<span class="math inline">\(\lambda\)</span>) vs Gamma(1,b)</p></li>
<li><p>normal.cauchy.est N(<span class="math inline">\(\mu\)</span>,<span class="math inline">\(\sigma\)</span>) vs Cauchy (Breit-Wigner)</p></li>
</ol>
<h4 class="unnumbered" data-number="10.2" id="case-studies-for-two-sample-problem">Case Studies for two-sample problem</h4>
<p>The first 14 case studies are the same as those of the goodness-of-fit
problem. The others are</p>
<ol start="15" type="1">
<li><p>gamma.normal Gamma(<span class="math inline">\(\mu\)</span>) vs N(<span class="math inline">\(\bar{x}\)</span>, sd(x)), here the mean of
the normal distribution are the sample mean and sample standard
deviation of the x data set.</p></li>
<li><p>normal.normalmixture N(0,1) vs N(<span class="math inline">\(-\mu\)</span>,1)+N(<span class="math inline">\(\mu\)</span>,1)</p></li>
<li><p>uniform.uniformmixture U[0,1]
vs. <span class="math inline">\(\alpha\)</span>U[0,1/2]+(1-<span class="math inline">\(\alpha\)</span>)U[1/2,1]</p></li>
<li><p>uniform.betamixture U[0,1]
vs. <span class="math inline">\(\alpha\)</span>U[0,1/2]+(1-<span class="math inline">\(\alpha\)</span>)Beta(2,2)</p></li>
<li><p>chisquare.noncentral <span class="math inline">\(\chi^2(5)\)</span> vs. <span class="math inline">\(\chi^2(5, \tau)\)</span></p></li>
<li><p>uniform.triangular U[0,1] vs. triangular</p></li>
</ol>
</div>
<div class="sourceCode" id="cb57"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<h3 class="appendix" data-number="11" id="supplementary-materials"><span class="header-section-number">11</span> Supplementary materials</h3>
<p>Supplementary materials are available in addition to this article. It can be downloaded at
<a href="RJ-2025-027.zip">RJ-2025-027.zip</a></p>
<h3 class="appendix" data-number="12" id="note"><span class="header-section-number">12</span> Note</h3>
<p>This article is converted from a Legacy LaTeX article using the
<a href="https://cran.r-project.org/package=texor">texor</a> package.
The pdf version is the official version. To report a problem with the html,
refer to CONTRIBUTE on the R Journal homepage.</p>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-aldor2013" class="csl-entry" role="listitem">
S. Aldor-Noima, L. D. Brown, A. Buja, R. A. Stine and W. Rolke. The power to see: A new graphical test of normality. <em>The American Statistician</em>, 67: 2013.
</div>
<div id="ref-anderson1962" class="csl-entry" role="listitem">
T. W. Anderson. On the distribution of the two-sample <span class="nocase">Cramer-von Mises</span> criterion. <em>Annals of Mathematical Statistics</em>, 33(3): 1148–1159, 1962.
</div>
<div id="ref-anderson1952" class="csl-entry" role="listitem">
T. W. Anderson and D. A. Darling. Asymptotic theory of certain goodness-of-fit criteria based on stochastic processes. <em>Annals of Mathematical Statistics</em>, 23: 193–212, 1952.
</div>
<div id="ref-adgoftest2011" class="csl-entry" role="listitem">
C. J. G. Bellosta. <em>ADGofTest: Anderson-darling GoF test.</em> 2011. URL <a href="https://CRAN.R-project.org/package=ADGofTest">https://CRAN.R-project.org/package=ADGofTest</a>. R package version 0.3.
</div>
<div id="ref-berkson1980" class="csl-entry" role="listitem">
J. Berkson. Minimum chi-square, not maximum likelihood. <em>Ann. Math. Stat</em>, 8(3): 457–487, 1980.
</div>
<div id="ref-bickel2015" class="csl-entry" role="listitem">
P. J. Bickel and K. A. Doksum. <em>Mathematical statistics vol 1 and 2.</em> CRC Press, 2015.
</div>
<div id="ref-bortkewitsch1898" class="csl-entry" role="listitem">
L. Bortkewitsch. <em>Das gesetz der kleinen zahlen.</em> Teubner, 1898.
</div>
<div id="ref-casella2002" class="csl-entry" role="listitem">
G. Casella and R. Berger. <em>Statistical inference.</em> Duxbury Advanced Series in Statistics; Decision Sciences. Thomson Learning, 2002.
</div>
<div id="ref-cramer1928" class="csl-entry" role="listitem">
H. Cramer. On the composition of elementary errors. <em>Scandinavian Actuarial Journal</em>, 1: 13–74, 1928.
</div>
<div id="ref-agostini1986" class="csl-entry" role="listitem">
R. B. D’Agostini and M. A. Stephens. <em>Goodness-of-fit techniques.</em> Statistics: Textbooks; Monographs. Marcel Dekker, 1986.
</div>
<div id="ref-dowd2022" class="csl-entry" role="listitem">
C. Dowd. <em>Twosamples: Fast permutation based two sample tests.</em> None, 2022. URL <a href="https://CRAN.R-project.org/package=twosamples">https://CRAN.R-project.org/package=twosamples</a>. R package version 2.0.0.
</div>
<div id="ref-rcpp2024" class="csl-entry" role="listitem">
D. Eddelbuettel, R. Francois, J. Allaire, K. Ushey, Q. Kou, N. Russell, I. Ucar, D. Bates and J. Chambers. <em><span>Rcpp</span>: Seamless <span>R</span> and <span>C++</span> integration.</em> 2024. URL <a href="https://CRAN.R-project.org/package=Rcpp">https://CRAN.R-project.org/package=Rcpp</a>. R package version 1.0.12.
</div>
<div id="ref-goftest2007" class="csl-entry" role="listitem">
J. Faraway, G. Marsalia, J. Marsalia and A. Baddeley. <em>Goftest: Classical goodness-of-fit tests for univariate distributions.</em> None, 2007. URL <a href="https://CRAN.R-project.org/package=goftest">https://CRAN.R-project.org/package=goftest</a>. R package version 1.2.3.
</div>
<div id="ref-fisher1922" class="csl-entry" role="listitem">
R. A. Fisher. On the interpretation of chi square from contingency tables, and the calculation of <span>P.J.R.</span> <em>Journal of the Royal Statistcal Society</em>, 85: 87–94, 1922.
</div>
<div id="ref-fisher1924" class="csl-entry" role="listitem">
R. A. Fisher. The conditions under which chi square measures the discrepancy between observation and hypothesis. <em>Journal of the Royal Statistcal Society</em>, 87: 442–450, 1924.
</div>
<div id="ref-nortest2015" class="csl-entry" role="listitem">
J. Gross and U. Ligges. <em>Nortest: Tests for normality.</em> 2015. URL <a href="https://CRAN.R-project.org/package=nortest">https://CRAN.R-project.org/package=nortest</a>. R package version 1.0-4.
</div>
<div id="ref-kolmogorov1933" class="csl-entry" role="listitem">
A. Kolmogorov. Sulla determinazione empirica di una legge di distribuzione. <em>G. Ist. Ital. Attuari.</em>, 4: 83–91, 1933.
</div>
<div id="ref-kuiper1960" class="csl-entry" role="listitem">
N. H. Kuiper. Tests concerning random points on a circle. <em>Proceedings of the Koninklijke Nederlandse Akademie van Wetenschappen</em>, 63: 38–47, 1960.
</div>
<div id="ref-lehmann1951" class="csl-entry" role="listitem">
E. L. Lehmann. Consistency and unbiasedness of certain nonparametric tests. <em>Ann. MAth. Statist.</em>, 22(1): 165–179, 1951.
</div>
<div id="ref-envstats2017" class="csl-entry" role="listitem">
S. P. Millard and A. K. Kowarik. <em>EnvStats: Package for environmental statistics, including <span>US EPA</span> guidance.</em> None, 2017. URL <a href="https://CRAN.R-project.org/package=EnvStats">https://CRAN.R-project.org/package=EnvStats</a>. R package version 3.5.0.
</div>
<div id="ref-mises1928" class="csl-entry" role="listitem">
R. E. von Mises. <em>Wahrscheinlichkeit, statistik und wahrheit.</em> Springer, 1928.
</div>
<div id="ref-pettitt1976" class="csl-entry" role="listitem">
A. N. Pettitt. A two-sample anderson-darling rank statistic. <em>Biometrika</em>, 63 No.1: 161–168, 1976.
</div>
<div id="ref-preece1988" class="csl-entry" role="listitem">
D. A. Preece, G. J. S. Ross and P. J. Kirby. Bortkewitsch’s horse-kicks and the generalised linear model. <em>Journal of the Royal Statistical Society</em>, 37: 1988.
</div>
<div id="ref-r2021" class="csl-entry" role="listitem">
R Core Team. <em><span>R</span>: A language and environment for statistical computing.</em> Vienna, Austria: R Foundation for Statistical Computing, 2021. URL <a href="https://www.R-project.org/">https://www.R-project.org/</a>.
</div>
<div id="ref-raynor2009" class="csl-entry" role="listitem">
J. C. Raynor, O. Thas and D. J. Best. <em>Smooth tests of goodness of fit.</em> Wiley Sons, 2012.
</div>
<div id="ref-r2sample2023" class="csl-entry" role="listitem">
W. Rolke. <em>R2sample: 1d two-sample tests.</em> None, 2023a. URL <a href="https://CRAN.R-project.org/package=R2sample">https://CRAN.R-project.org/package=R2sample</a>. R package version 1.0.1.
</div>
<div id="ref-rgof2023" class="csl-entry" role="listitem">
W. Rolke. <em>Rgof: 1d goodness of fit tests.</em> None, 2023b. URL <a href="https://CRAN.R-project.org/package=Rgof">https://CRAN.R-project.org/package=Rgof</a>. R package version 1.0.1.
</div>
<div id="ref-rosenblatt1952" class="csl-entry" role="listitem">
M. Rosenblatt. Limit theorems associated with variants of the <span>Von Mises</span> statistic. <em>Ann. Math. Statist.</em>, 23: 617–623, 1952.
</div>
<div id="ref-smirnov1939" class="csl-entry" role="listitem">
N. V. Smirnov. Estimate of deviation between empirical distribution functions in two independent samples. <em>Bull. Moscow Univ.</em>, 2: 3–16, 1939.
</div>
<div id="ref-dgof2009" class="csl-entry" role="listitem">
B. A. Taylor and J. W. Emerson. <em>Dgof: Discrete goodness-of-fit tests.</em> None, 2009. URL <a href="https://CRAN.R-project.org/package=dgof">https://CRAN.R-project.org/package=dgof</a>. R package version 1.5.1.
</div>
<div id="ref-thas2010" class="csl-entry" role="listitem">
O. Thas. <em>Continuous distributions.</em> Springer Series in Statistics. Springer, 2010.
</div>
<div id="ref-wasserstein1969" class="csl-entry" role="listitem">
L. N. Vaserstein. Markov processes over denumerable products of spaces, describing large systems of automata. <em>Problemy Peredachi Informatsii</em>, 5(3): 64–72, 1969.
</div>
<div id="ref-watson1961" class="csl-entry" role="listitem">
G. S. Watson. Goodness-of-fit tests on a circle. <em>Biometrica</em>, 48: 109–114, 1961.
</div>
<div id="ref-zhang2002" class="csl-entry" role="listitem">
J. Zhang. Powerful goodness-of-fit tests based on likelihood ratio. <em>Journal of the RSS (Series B)</em>, 64: 281–294, 2002.
</div>
<div id="ref-zhang2006" class="csl-entry" role="listitem">
J. Zhang. Powerful two-sample tests based on the likelihood ratio. <em>Techometrics</em>, 48: 95–103, 2006.
</div>
</div>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
<h3 id="references">References</h3>
<div id="references-listing"></div>
<h3 id="reuse">Reuse</h3>
<p>Text and figures are licensed under Creative Commons Attribution <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>. The figures that have been reused from other sources don't fall under this license and can be recognized by a note in their caption: "Figure from ...".</p>
<h3 id="citation">Citation</h3>
<p>For attribution, please cite this work as</p>
<pre class="citation-appendix short">Rolke, "Rgof and R2sample: Testing and Benchmarking for the Univariate Goodness-of-Fit and Two-Sample Problems", The R Journal, 2025</pre>
<p>BibTeX citation</p>
<pre class="citation-appendix long">@article{RJ-2025-027,
  author = {Rolke, Wolfgang},
  title = {Rgof and R2sample: Testing and Benchmarking for the Univariate Goodness-of-Fit and Two-Sample Problems},
  journal = {The R Journal},
  year = {2025},
  note = {https://doi.org/10.32614/RJ-2025-027},
  doi = {10.32614/RJ-2025-027},
  volume = {17},
  issue = {3},
  issn = {2073-4859},
  pages = {140-163}
}</pre>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
