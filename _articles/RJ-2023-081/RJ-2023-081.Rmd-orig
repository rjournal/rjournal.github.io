---
title: '[binGroup2](https://CRAN.R-project.org/package=binGroup2): Statistical Tools
  for Infection Identification via Group Testing'
abstract: 'Group testing is the process of testing items as an amalgamation, rather
  than separately, to determine the binary status for each item. Its use was especially
  important during the COVID-19 pandemic through testing specimens for SARS-CoV-2.
  The adoption of group testing for this and many other applications is because members
  of a negative testing group can be declared negative with potentially only one test.
  This subsequently leads to significant increases in laboratory testing capacity.
  Whenever a group testing algorithm is put into practice, it is critical for laboratories
  to understand the algorithm''s operating characteristics, such as the expected number
  of tests. Our paper presents the [binGroup2](https://CRAN.R-project.org/package=binGroup2)
  package that provides the statistical tools for this purpose. This R package is
  the first to address the identification aspect of group testing for a wide variety
  of algorithms. We illustrate its use through COVID-19 and chlamydia/gonorrhea applications
  of group testing. '
author:
- name: Christopher R. Bilder
  affiliation: University of Nebraska-Lincoln
  email: chris@chrisbilder.com
  address:
  - Department of Statistics
  - Lincoln, NE 68583, USA
  - |
    [www.chrisbilder.com](www.chrisbilder.com){.uri}
- name: Brianna D. Hitt
  affiliation: United States Air Force Academy
  email: |
    brianna.hitt@afacademy.af.edu
  address:
  - Department of Mathematical Sciences
  - Colorado Springs, CO 80840, USA
- name: Brad J. Biggerstaff
  affiliation: Centers for Disease Control and Prevention
  email: |
    bkb5@cdc.gov
  address:
  - Division of Vector-Borne Diseases
  - Fort Collins, CO 80521, USA
- name: Joshua M. Tebbs
  affiliation: University of South Carolina
  email: |
    tebbs@stat.sc.edu
  address:
  - Department of Statistics
  - Columbia, SC 29208, USA
- name: Christopher S. McMahan
  affiliation: Clemson University
  email: |
    mcmaha2@clemson.edu
  address:
  - School of Mathematical and Statistical Sciences
  - Clemson, SC 29634, USA
date: '2024-04-11'
date_received: '2022-05-30'
journal:
  firstpage: ~
  lastpage: ~
volume: 15
issue: 4
slug: RJ-2023-081
packages:
  cran: ~
  bioc: ~
draft: no
preview: preview.png
bibliography: refs.bib
CTV: ~
output:
  rjtools::rjournal_web_article:
    self_contained: no
    toc: no
    legacy_pdf: yes

---

# Introduction

The COVID-19 pandemic showed the need for accessible, fast, and reliable
testing for severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)
and for infections in general. To meet this need, many laboratories
turned to the use of group testing. Group testing---also known as pooled
testing, specimen pooling, batch testing, and bulk testing---involves
combining portions of multiple specimens from different individuals into
a "group" and testing this group as if it were a single specimen. If the
group tests negative, all individuals represented within it generally
can be declared negative. Thus, for a group of size 10, it takes only
one test to determine whether all 10 individuals are infection free,
whereas it would take 10 tests if each specimen was tested separately.
Alternatively, if a group tests positive, retesting in some form is
needed to determine who is positive or negative within the group.
@dorfman1943detection proposed the original retesting method that
involved simply retesting each group member separately using the
remaining portions of their specimens. Since this seminal paper, many
other group testing algorithms have been proposed. These algorithms are
categorized into hierarchical and non-hierarchical approaches
corresponding to whether specimens are tested in non-overlapping or
overlapping groups, respectively, at each stage of the algorithm
(@hitt2019objective).

A large number of research papers (see e.g. @abdalhamid2020assessment;
@Hogan2020; @barathidasan2022pooled), articles in the news media (see
e.g. @ABCnews; @NYTimesMandavilli; @NYTimesAnthes), and Emergency Use
Authorizations given by the US Food and Drug Administration (@LabCorp;
@Verily; @Yale) showed that group testing was one of the important tools
available to mitigate the crisis caused by COVID-19. Our new
[binGroup2](https://CRAN.R-project.org/package=binGroup2) package for
the R software environment provides the statistical tools that
researchers and laboratories need for group testing. This package is
available from the Comprehensive R Archive Network (CRAN) at
<https://CRAN.R-project.org/package=binGroup2>. By its name, one can
surmise that it is the second large-scale implementation of the package.
The [binGroup](https://CRAN.R-project.org/package=binGroup) package
(@Bilder2010b) focused on estimation using the unique type of data that
arises through group testing. Its applications ranged from estimating an
overall infection prevalence to estimating a regression model for
individual-specific infection probabilities as a function of risk
factors. @Bilder2010b encouraged researchers to provide new functions so
that there would be one main package for group testing in R. This
resulted in new functions for estimation and a few functions focused on
the identification aspect of group testing (i.e., determine a
positive/negative outcome for each individual). Over time, these
additions resulted in many different syntax styles among functions,
making use of the package inconsistent and more difficult. The new
[binGroup2](https://CRAN.R-project.org/package=binGroup2) package was
created to unify function syntax and, most importantly, to incorporate a
new suite of functions for identification. These new functions provide
the information that laboratories need to increase their testing
capacity to its fullest potential.

Our paper focuses on these identification functions of
[binGroup2](https://CRAN.R-project.org/package=binGroup2) because they
represent the main new contribution of the package. There are two other
R packages on CRAN that also examine the identification aspect of group
testing but for different settings. First, the gtcorr package (@gtcorr;
archived in 2022) examines hierarchical and non-hierarchical algorithms
for a homogeneous population when there is a constant correlation among
individuals within a group. This package implements the work of
@lendle2012group that uses single-infection assays only. Second, the
[mMPA](https://CRAN.R-project.org/package=mMPA) package (@mMPA) examines
three hierarchical algorithms, where two are for homogeneous populations
and one is for heterogeneous populations. This package implements the
work of @tao2017improved for single-infection assays that return an
additive count outcome (e.g., viral load) when applied to a group. Both
gtcorr and [mMPA](https://CRAN.R-project.org/package=mMPA) are useful
for their specialized situations. Our package encompasses a total of 27
different algorithms that include homogeneous/heterogeneous populations
and hierarchical/non-hierarchical algorithms. These algorithms are
constructed for the most common setting of a binary test response
(positive/negative) from independent individuals within a group. We
allow for the possibility of testing error and single or
multiple-infection assays. Our package implements the work of more than
ten papers on the identification aspect of group testing (e.g.,
@Kim2007; @mcmahan2012two; @houarray1).

An outline of our paper is as follows. The next section provides a
review of group testing algorithms that are commonly used by
laboratories. The third section discusses how to calculate important
operating characteristics, such as the expected number of tests, for a
group testing algorithm by using
[binGroup2](https://CRAN.R-project.org/package=binGroup2). This section
also demonstrates how one can choose the most efficient implementation
of an algorithm. Finally, we conclude with an overview of changes to
estimation functions and future extensions of the package. Throughout
our text, we phrase our discussion in the context of testing humans for
infectious diseases. Applications of group testing for this purpose
outside of COVID-19 include testing for influenza (@van2012pooling),
gonorrhea (@ando2020modified), HIV (@kim2014pooled), and West Nile virus
(@ARC). The package can also be used in a wide variety of other areas
where group testing is implemented, such as infectious disease testing
for farm animals (@NVDC), detection of human exposure to pollutants
(@thai2020analysis), determination of virus presence in insect carriers
(@zhao2020thrips), development of new pharmaceuticals
(@salzer2016screening), and security of computer networks
(@thai2011group).

# Algorithms[]{#sec:Algorithms label="sec:Algorithms"}

Laboratories select a group testing algorithm by examining 1) the
expected number of tests needed to make a positive/negative
determination for every individual, 2) the expected accuracy of the
positive/negative determinations, 3) the information available on
individuals tested, and 4) the ease of implementation. The
[binGroup2](https://CRAN.R-project.org/package=binGroup2) package
provides computations needed to address 1) through 3), while
laboratories need to address 4) relative to their work environment.
Overall, there is not one group testing algorithm that is best for all
situations, which has resulted in many different hierarchical and
non-hierarchical algorithms being used in practice.

## Hierarchical algorithms

Hierarchical group testing algorithms involve testing a group and
splitting its members into smaller, non-overlapping sub-groups for
retesting if the original group tests positive. These sub-groups are
split further whenever they test positive. If a group/sub-group tests
negative, its members are declared negative, so that no further testing
is performed upon them. Overall, testing can continue until each group
member is tested separately.

A recent example of a hierarchical algorithm comes from
@lohse2020pooling to test for SARS-CoV-2 (see Figure
[1](#fig:hierarchical-Lohse){reference-type="ref"
reference="fig:hierarchical-Lohse"}). Individuals were put into
non-overlapping groups of size 30. If a group tested positive, three
non-overlapping groups of size 10 were formed from its members. If one
of these sub-groups tested positive, each of its members were retested
separately (i.e., individual testing). This hierarchical algorithm is
referred to as a three-stage algorithm because three distinct stages are
defined for it.

<figure id="fig:hierarchical-Lohse">
<div class="centering">
<embed src="figures/images_hier30-10-1BW.pdf" />
</div>
<figcaption><span id="fig:hierarchical-Lohse"
label="fig:hierarchical-Lohse"></span>The hierarchical testing algorithm
of <span class="citation"
data-cites="lohse2020pooling"></span>.</figcaption>
</figure>

Hierarchical algorithms can have more or fewer stages than used by
@lohse2020pooling. For example, @abdalhamid2020assessment used two
stages for SARS-CoV-2 detection by testing in groups of size 5 and
subsequently retesting each member of a positive group separately. More
than three stages are possible as well, but applications are much rarer
because of logistics, larger chance for error, and delay in obtaining
the positive/negative individual outcomes. With respect to the last
reason, this delay can be significant for nucleic acid amplification
tests which can take hours to complete. For example, the Centers for
Disease Control and Prevention's assay to detect SARS-CoV-2 takes
approximately four hours to complete.

## Non-hierarchical algorithms

Non-hierarchical algorithms were developed to minimize the number of
retests needed after an initial stage of testing. The most prominent of
these algorithms is referred to as array testing (also known as matrix
pooling). For this algorithm, specimens are arranged in a grid (see
Figure [2](#fig:array-1-1){reference-type="ref"
reference="fig:array-1-1"}). Groups are formed by row and by column, and
each of these groups are subsequently tested. Specimens that lie at the
intersections of positive testing rows and positive testing columns are
retested separately in a second stage to determine a positive/negative
outcome for each of them. All other specimens are declared negative.
Because the accuracy of infectious disease assays is not perfect,
ambiguities may occur, resulting in positive rows (columns) without any
positive columns (rows). In those situations, members of positive rows
(columns) should be retested separately (@Kim2007). A recent example of
an array testing algorithm is the use of a $5\times5$ array by LabCorp
for SARS-CoV-2 detection (@LabCorp).

<figure id="fig:array-1-1">
<div class="centering">
<embed src="figures/images_array5x5BW.pdf" />
</div>
<figcaption><span id="fig:array-1-1" label="fig:array-1-1"></span>The
array testing algorithm of <span class="citation"
data-cites="LabCorp"></span>. Circles within the square represent
specimen locations. Row and column groups are formed from the specimens
with two each testing positive. The intersections of these positive rows
and columns indicate which specimens need to be retested (filled-in
circles). </figcaption>
</figure>

Array testing has a number of variants in application. For example, a
master group containing portions of all specimens within an array can be
tested first. If this master group is negative, all individuals are
quickly declared negative. If the master group is positive, row and
column groups are tested as usual.

## Additional considerations

The probability an individual has an infection plays a very important
role in determining the number of tests needed by any group testing
algorithm. For a homogeneous population of individuals tested, we can
define $p$ as this probability. Equivalently, this $p$ is the overall
infection prevalence. In general, the lower (higher) the $p$, the lower
(higher) the expected number of tests needed for group testing (see e.g.
Figure 3 of @Kim2007 and Table 1 of @bilder2021pool).

In many situations, additional information is available on each
individual to be tested. This information can be used to determine an
individual-specific probability of an infection, say $p_{i}$, which can
be incorporated into the group testing algorithm to reduce the number of
tests (@Bilder2010b; @lewis2012cost). For example, testing is performed
by public health laboratories across the United States for *Chlamydia
trachomatis* (CT) and *Neisseria gonorrhoeae* (NG), the bacteria that
lead to chlamydia and gonorrhea, respectively. Clinics collecting
specimens also obtain important information on their patients, including
recent sexual history and whether a patient has symptoms, and this
information can be incorporated into a statistical model to estimate
individual-specific probabilities of infection. In general, group
testing algorithms that take advantage of this type of additional
information are referred to as being "informative"
hierarchical/non-hierarchical algorithms (@mcmahan2012informative;
@mcmahan2012two).

Group testing algorithms can also be used with multiplex assays. Thus,
rather than testing for only one infection, multiple infections can be
detected simultaneously. For example, Roche was the first to receive an
Emergency Use Authorization for their SARS-CoV-2 and influenza multiplex
assay (@Roche). Also, the widely adopted Aptima Combo 2 Assay (@Aptima)
is used for CT and NG detection via group testing. Algorithms with
multiplex assays are implemented in the same way as for single-infection
assays, but now a group that tests positive for *at least one* infection
leads to retesting for *all* infections in the next stage. For example,
if a group tests positive for CT and negative for NG in a two-stage
hierarchical algorithm, each group member is retested for both bacteria
in the second stage. Testing is performed in this manner, rather than
retesting for CT only, because of the dedicated testing platforms used.

# Identification[]{#sec:Identification label="sec:Identification"}

Identifying infected individuals is most often the primary goal of
infectious disease testing. Prior to implementing a particular group
testing algorithm for this purpose, laboratories need to know the
expected number of tests. This information is used for planning purposes
to make sure enough resources and staff are available to implement
testing. Because cost is often directly proportional to the number of
tests, the expected number of tests can be used for budgeting purposes
as well.

Define $T$ as the number of tests required to determine the
positive/negative outcomes for $I$ individuals. These $I$ individuals
may be those represented within one initial group for hierarchical
testing or in one array for array testing. For the simplest algorithm,
two-stage hierarchical testing, suppose a single-infection assay is
applied to a homogeneous population. The expected number of tests is
$$\begin{aligned}
E(T) & =1+I\left[S_{e}^{(1)}+(1-S_{p}^{(1)}-S_{e}^{(1)})(1-p)^{I}\right],
\end{aligned}$$

where $S_{e}^{(1)}$ and $S_{p}^{(1)}$ are the first-stage sensitivity
and specificity, respectively, of the assay. This expression includes a
leading 1 because a single group test starts the testing process. The
$I$ outside of the square brackets is for the separate tests performed
on each individual when the group tests positive (which has the
probability given within the square brackets; see @Kim2007 and
@bilder2019id). Expressions for $E(T)$ become much more complicated with
other group testing algorithms. This is especially the case for
informative algorithms and when multiplex assays are used. We refer
interested readers to the works of @Kim2007, @mcmahan2012informative,
@mcmahan2012informative, @black2015optimal, @bilder2019informative, and
@houarray1 for specific expressions and calculation details.

The efficiency of a group testing algorithm is expressed typically as
the expected number of tests per individual $E(T)/I$, rather than $E(T)$
alone, so that comparisons can be made for different $I$. The optimal
testing configuration (OTC) is the group size or set of group sizes
needed by a single algorithm to minimize $E(T)/I$. This testing
configuration represents the most efficient process to implement group
testing. In other words, it is the group size(s) that increases a
laboratory's testing capacity to its fullest potential, because
resources saved from its application can be used to test more specimens
by the same algorithm. Unfortunately, closed form expressions for the
OTC do not exist, but grid searches are sufficient to find it. Note that
group testing is more efficient than initially testing each individual
separately when $E(T)/I$\<1. This is simply because testing each
individual separately results in 1 test per individual.

Accuracy is also important to examine for group testing algorithms. This
includes the pooling sensitivity, the probability a truly positive
individual is found to be positive from the group testing algorithm, and
the pooling specificity, the probability a truly negative individual is
found to be negative from the group testing algorithm. These
probabilities are not necessarily equal to an assay's stated sensitivity
and specificity because individuals are tested in one or more groups.
For example, the pooling sensitivity for a two-stage hierarchical
algorithm can be shown to be $S_{e}^{(1)}S_{e}^{(2)}$, where
$S_{e}^{(2)}$ is the sensitivity of the assay at the second stage
(@johnson1991inspection, @Kim2007, and @hitt2020group1). Expressions for
these accuracy measures corresponding to other algorithms are available
in the previously mentioned references for $E(T)$.

One issue related to accuracy is what is known as the *dilution effect*
that sometimes can reduce the sensitivity of a group test. If the same
sample volume is used for a group and individual test, the dilution
effect can occur because each individual is represented by a smaller
portion in the group than if each individual was tested separately. For
example, @abdalhamid2020assessment used a sample volume of
$250\textrm{\ensuremath{\mu}L}$ for a group of size 5 with each
individual contributing $50\textrm{\ensuremath{\mu}L}$. In their
validation study, specimens were tested one at a time using a sample
volume of $250\textrm{\ensuremath{\mu}L}$. Thus, there can be less
pathogen present for the test performed upon the group than for a test
performed upon a single specimen. @bilder2021discussion discussed the
potential dilution effect and solutions for it. In summary, the
resulting outcome from the dilution effect is often known for assays
(@tan2020considerations), like for those using real-time reverse
transcription polymerase chain reaction (RT-qPCR) which was widely used
for SARS-CoV-2 testing. This effect can be accounted for by specifying a
smaller value for a group test sensitivity when computing $E(T)$.
Alternatively, the process for applying the assay can be changed so that
there is not a reduction in the sensitivity (@abdalhamid2020assessment,
@sanghani2021concentrating).

## Main functions

There are two main sets of functions in
[binGroup2](https://CRAN.R-project.org/package=binGroup2) used for
identification. First, the opChar1() and opChar2() functions calculate
operating characteristics for a group testing algorithm. These functions
are for single-infection and two-infection assays, where the number in
the name designates the number of infections. Calculations for three or
more infection assays are discussed in the concluding section of the
paper. The syntax for opChar1() is

::: Sinput
opChar1(algorithm, p = NULL, probabilities = NULL, Se = 0.99, Sp = 0.99,
hier.config = NULL, rowcol.sz = NULL, alpha = 2, a = NULL, print.time =
TRUE, \...)
:::

The required algorithm argument specifies the chosen group testing
algorithm. Possible values for this argument are listed in Table
[1](#tab:Values-for-algorithm){reference-type="ref"
reference="tab:Values-for-algorithm"}. For example, a value of \"D2\"
indicates two-stage hierarchical testing in a homogeneous population
(the "D" is for its originator, Robert Dorfman). The remaining arguments
are dependent on the algorithm chosen or are optional. To indicate the
probability of an infection, a scalar can be given for p or a vector of
potentially different probabilities for each individual can be given for
probabilities. Rather than providing a specific vector of probabilities,
the p and alpha arguments can be used together for informative group
testing algorithms to specify a beta distribution from which the
expected values of order statistics are found. For this case, p
represents the expected value of a beta random variable and alpha
represents a shape parameter. This type of specification is helpful when
probabilities of infection can be characterized well by a beta
distribution.

::: {#tab:Values-for-algorithm}
   algorithm                Description
  ----------- ---------------------------------------
      A2                   Array testing
      A2M         Array testing with master group
      D2              Two-stage hierarchical
      D3             Three-stage hierarchical
      D4              Four-stage hierarchical
      IA2            Informative array testing
      ID2       Two-stage, informative hierarchical
      ID3      Three-stage, informative hierarchical
      ID4      Four-stage, informative hierarchical

  : Values for algorithm in opChar1() and opChar2(). A five-stage
  informative hierarchical algorithm ( ID5) is also available for two
  infections. Informative array testing is not included for opChar2()
  because closed-form expressions of operating characteristics have not
  been proposed in the literature.
:::

For hierarchical algorithms, a group membership matrix
(@bilder2019informative) must be provided for hier.config to detail the
testing of each individual. In this matrix, the rows correspond to the
stages of testing, the columns correspond to each individual to be
tested, and the cell values specify the group number of each individual
at each stage. We provide an example of its use shortly. For
non-hierarchical algorithms, the rowcol.sz argument must be provided for
the row and column size of a square array.

Additional arguments include Se and Sp for the sensitivity and
specificity of the assay, respectively. If a single value is given for
one of these arguments, this value is used for each stage. Otherwise, a
vector of values can be given in order of stage. The `a` argument
specifies individuals for which to compute accuracy measures. By
default, accuracy measures are computed for all individuals. Finally,
print.time allows users to turn off information regarding the duration
of calculations.

The opChar2() function follows a similar syntax so we do not provide it
here. The main difference involves p becoming a vector of joint
probabilities of infection. For example, p = (0.90, 0.03, 0.02, 0.05)
represents $(p_{--},p_{+-},p_{-+},p_{++})$, where $p_{ab}$ is the
probability of being positive/negative ($+/-$) for infections $a$ and
$b$. Also, the probabilities argument value becomes a $4\times I$ matrix
of these probabilities. Similarly, the alpha argument becomes the
parameter vector for a Dirichlet distribution.

The second set of functions are OTC1() and OTC2() that find the OTC
corresponding to single-infection and two-infection assays,
respectively. The syntax for OTC1() is

::: Sinput
OTC1(algorithm, p = NULL, probabilities = NULL, Se = 0.99, Sp = 0.99,
group.sz, obj.fn = \"ET\", weights = NULL, alpha = 2, trace = TRUE,
print.time = TRUE, \...)
:::

The syntax is similar to opChar1() as well, so we highlight the main
differences only. There is no group membership matrix or row/column size
specified because OTC1() searches for the OTC. Instead, the group.sz
argument specifies the initial group sizes to search over. For example,
a value of 3:10 searches over initial group sizes of 3 to 10 for
hierarchical testing or array testing (row/column size).

The obj.fn argument of OTC1() indicates which objective function to
minimize when searching for the OTC. Earlier in this section, we focused
on using the expected number of tests per individual as this objective
function ( obj.fn = \"ET\"). While this is used most often in practice,
other objective functions are possible (@hitt2019objective). For
example, @Graff1972 proposed to minimize a linear combination of the
expected number of tests and the number of misclassified individuals
(false positives, false negatives). This objective function is specified
using \"GR\", and the coefficients in this linear combination are given
in the weights argument.

The OTC2() function follows a similar syntax as OTC1() with changes like
those for opChar2() compared to opChar1(). We next provide examples
using these functions for group testing applications.

## Operating characteristics[]{#subsec:Operating-characteristics label="subsec:Operating-characteristics"}

We illustrate the use of opChar1() for the three-stage hierarchical
testing algorithm of @lohse2020pooling. The group membership matrix for
this application is the $3\times30$ matrix below.

::: Sinput
\> group.member \<- matrix(data = c(rep(1, times = 30), rep(1:3, each =
10), 1:30), nrow = 3, ncol = 30, byrow = TRUE) \> group.member\[, 11\]
:::

::: Soutput
1 2 11
:::

For example, the 11th individual is tested initially in a group of size
30 that includes every specimen (one group overall). In the second
stage, this individual is tested in the second sub-group of 10
individuals if its first-stage group is positive. In the third stage,
this individual is tested separately if its second-stage group is
positive.

We need to specify $p$ or $p_{i}$ for each individual. In actual
practice, these values will be unknown. However, very good point
estimates are usually available from past testing results in high volume
clinical specimen settings where group testing is used. For the
@lohse2020pooling application, the observed prevalence of SARS-CoV-2 was
0.0193, so we use this value here for $p$. By specifying \"D3\" for
algorithm to represent three-stage hierarchical testing, we invoke
opChar1() as follows.

::: Sinput
\> library(package = \"binGroup2\") \> save.Lohse \<- opChar1(algorithm
= \"D3\", p = 0.0193, Se = 1, Sp = 1, hier.config = group.member,
print.time = FALSE) \> summary(save.Lohse)
:::

::: Soutput
Algorithm: Non-informative three-stage hierarchical testing

Testing configuration: Stage 1: 30 Stage 2: 10,10,10

Expected number of tests: 7.64 Expected number of tests per individual:
0.2547

Accuracy for individuals: PSe PSp PPPV PNPV Individuals 1 1.0000 1.0000
1.0000 1.0000 All

Overall accuracy of the algorithm: PSe PSp PPPV PNPV 1 1.0000 1.0000
1.0000 1.0000

PSe denotes the pooling sensitivity. PSp denotes the pooling
specificity. PPPV denotes the pooling positive predictive value. PNPV
denotes the pooling negative predictive value.
:::

The sensitivity ( Se) and the specificity ( Sp) are set to 1 for each
stage because the assay accuracy is not stated in @lohse2020pooling or
in the product insert of the assay (@RealStar). While the algorithm's
accuracy values produced will not be useful, this approach is often
followed in practice to focus on the expected number of tests regardless
of false positives/negatives.

The generic summary() function uses the corresponding method function
for the class to summarize the operating characteristics. For example,
the expected number of tests per individual is $E(T)/I=0.2547$. A more
compact summary based on the expected number of tests is available with
ExpTests().

::: Sinput
\> ExpTests(save.Lohse)
:::

::: Soutput
ExpTests ExpTestsPerIndividual PercentReductionTests
PercentIncreaseTestCap 1 7.6403 0.2547 74.53 292.66
:::

Group testing requires $1-E(T)/I=75\%$ fewer tests on average than
testing each specimen separately. In turn, this leads to a
$100\{1/[E(T)/I]-1\}\%=293\%$ increase in testing capacity on average
when applying the algorithm to a continuous stream of specimens. This
type of large increase in testing capacity is why laboratories
implemented group testing during the COVID-19 pandemic.

Our second example focuses on the Aptima Combo 2 Assay and its use by
the State Hygienic Laboratory (SHL) at the University of Iowa. The SHL
tests thousands of female swab specimens each year in groups of size
four using a two-stage hierarchical algorithm. We focus here instead on
their male urine specimens because group testing is not currently
implemented. The reason is due to concern that their infection
prevalence may be too large for group testing to be beneficial.
@bilder2019informative provided a Dirichlet distribution with parameter
vector $\alpha=(10.99,0.18,2.04,0.31)$ to describe a vector of the joint
probabilities of infection for CT and NG that take into account risk
factors, such as symptoms and exposure to an infected individual. Using
a first-stage group size of 5, we want to calculate how well three-stage
hierarchical testing would perform when allowing for differences among
probabilities of infection for individuals. To begin, we simulate what
one potential set of probabilities of infection could be using the
Dirichlet distribution and the rdirichlet() function of the
[rBeta2009](https://CRAN.R-project.org/package=rBeta2009) package
(@rBeta2009). These probabilities are ordered by the probability of
having at least one infection.

::: Sinput
\> library(package = \"rBeta2009\") \> set.seed(3789) \> p.unordered \<-
t(rdirichlet(n = 5, shape = c(10.99, 0.18, 2.04, 0.31))) \> p.ordered
\<- p.unordered\[, order(1 - p.unordered\[1, \])\] \> round(p.ordered,
4)
:::

::: Soutput
0.9714 0.8841 0.8356 0.8291 0.7009 \[2,\] 0.0001 0.0006 0.0000 0.0238
0.0000 \[3,\] 0.0274 0.0879 0.1643 0.1292 0.2991 \[4,\] 0.0011 0.0274
0.0001 0.0178 0.0000
:::

Next, we create the group membership matrix for three-stage informative
hierarchical testing using the OTC found in @bilder2019informative.
Because individuals 4 and 5 are tested separately in the second stage, a
NA is used for them in the third stage of the group membership matrix.

::: Sinput
\> group.member \<- matrix(data = c(rep(1, times = 5), 1, 1, 1, 2, 3, 1,
2, 3, NA, NA), nrow = 3, ncol = 5, byrow = TRUE) \> group.member
:::

::: Soutput
1 1 1 1 1 \[2,\] 1 1 1 2 3 \[3,\] 1 2 3 NA NA
:::

Lastly, the opChar2() function calculates the operating characteristics
for the algorithm. The Se and Sp matrices provide the sensitivity and
specificity values, respectively, for each infection at each stage
(@IowaComm). Because these accuracies are equal across the stages, the
sensitivity (specificity) for CT and NG could be instead included as a
single vector of length 2 for the Se ( Sp) argument of opChar2().
Alternatively, if accuracies were different across stages, the full
matrices provide a general way to include this information.

::: Sinput
\> Se \<- matrix(data = rep(c(0.979, 0.985), times = 3), nrow = 2, ncol
= 3, dimnames = list(Infection = 1:2, Stage = 1:3)) \> Sp \<-
matrix(data = rep(c(0.985, 0.996), times = 3), nrow = 2, ncol = 3,
dimnames = list(Infection = 1:2, Stage = 1:3)) \> save.SHL \<-
opChar2(algorithm = \"ID3\", probabilities = p.ordered, Se = Se, Sp =
Sp, hier.config = group.member, print.time = FALSE) \> summary(save.SHL)
:::

::: Soutput
Algorithm: Informative three-stage hierarchical testing

Testing configuration: Stage 1: 5 Stage 2: 3,1,1

Expected number of tests: 3.59 Expected number of tests per individual:
0.7182

Disease 1 accuracy for individuals: PSe PSp PPPV PNPV Individuals 1
0.9770 0.9958 0.2111 1.0000 1 2 0.9778 0.9961 0.8784 0.9994 2 3 0.9784
0.9958 0.0124 1.0000 3 4 0.9729 0.9915 0.8330 0.9988 4 5 0.9787 0.9913
0.0012 1.0000 5

Disease 2 accuracy for individuals: PSe PSp PPPV PNPV Individuals 1
0.9585 0.9990 0.9643 0.9988 1 2 0.9633 0.9992 0.9940 0.9952 2 3 0.9575
0.9994 0.9969 0.9917 3 4 0.9725 0.9979 0.9879 0.9953 4 5 0.9714 0.9984
0.9961 0.9879 5

Overall accuracy of the algorithm: PSe PSp PPPV PNPV 1 0.9749 0.9941
0.7039 0.9996 2 0.9669 0.9988 0.9931 0.9941

PSe denotes the pooling sensitivity. PSp denotes the pooling
specificity. PPPV denotes the pooling positive predictive value. PNPV
denotes the pooling negative predictive value.
:::

The expected number of tests per individual is 0.7182. Because this
value is less than 1, group testing would be more efficient on average
than testing each individual separately. The PSe and PSp values in the
output are the pooling sensitivity and specificity, respectively.
Additionally, values are given for the pooling positive predictive value
(PPPV) and the pooling negative predictive value (PNPV; see
@altman1994statistics and @hitt2019objective).

Of course, not every set of 5 individuals has these 5 joint
probabilities of infection. When this group testing algorithm was
applied to the data from which the Dirichlet distribution was estimated,
@bilder2019informative showed that the number of tests decreased by
approximately 26% on average.

## Optimal testing configuration[]{#subsec:Optimal-testing-configuration label="subsec:Optimal-testing-configuration"}

Returning to the three-stage hierarchical algorithm of
@lohse2020pooling, suppose again that $p=0.0193$. The OTC is found using
the following code.

::: Sinput
\> OTC.Lohse \<- OTC1(algorithm = \"D3\", p = 0.0193, Se = 1, Sp = 1,
group.sz = 3:20, obj.fn = \"ET\", print.time = FALSE)
:::

::: Soutput
Initial Group Size = 3 Initial Group Size = 4 Initial Group Size = 5
Initial Group Size = 6 Initial Group Size = 7 Initial Group Size = 8
Initial Group Size = 9 Initial Group Size = 10 Initial Group Size = 11
Initial Group Size = 12 Initial Group Size = 13 Initial Group Size = 14
Initial Group Size = 15 Initial Group Size = 16 Initial Group Size = 17
Initial Group Size = 18 Initial Group Size = 19 Initial Group Size = 20
:::

::: Sinput
\> summary(OTC.Lohse)
:::

::: Soutput
Algorithm: Non-informative three-stage hierarchical testing

Optimal testing configuration: Stage 1 Stage 2 ET 16 4,4,4,4

Expected number of tests: E(T) Value ET 3.27 0.2045

E(T) denotes the expected number of tests. Value denotes the objective
function value per individual.

Overall accuracy of the algorithm: PSe PSp PPPV PNPV ET 1.0000 1.0000
1.0000 1.0000

PSe denotes the pooling sensitivity. PSp denotes the pooling
specificity. PPPV denotes the pooling positive predictive value. PNPV
denotes the pooling negative predictive value.
:::

The summary() function summarizes the OTC. The first-stage group size is
16, the second stage has 4 groups of size 4, and the third stage uses
individual testing. The expected number of tests per individual is
0.2045. Therefore, the OTC decreases the expected number of tests per
individual further by almost 20% ($=(0.2547-0.2045)/0.2547$) over the
testing configuration used by @lohse2020pooling. In terms of expected
test capacity, one can show with ExpTests(OTC.Lohse) that the OTC leads
to a 389% increase in testing capacity when compared to testing each
specimen separately. Again, this is significantly better than the
testing configuration chosen by @lohse2020pooling and helps to show the
importance of choosing a testing configuration.

The OTC1() function searches for the optimal set of group sizes at
*each* first-stage group size specified in the group.sz argument. By
default, the function's progress is printed during its running ( trace =
TRUE). We take this approach to finding the OTC, rather than optimizing
over all group sizes initially, because a laboratory may prefer a
sub-optimal testing configuration due to their work environment. The
Config() function provides information about these sub-optimal testing
configurations. This function extracts each of the best testing
configurations by initial group size and returns them as a data frame
sorted by the value of the objective function ($E(T)/I$ because the
default was used in OTC1()).

::: Sinput
\> Config(OTC.Lohse)
:::

::: Soutput
I config ET value PSe PSp PPPV PNPV 1 16 4,4,4,4 3.2714 0.2045 1 1 1 1 2
17 5,4,4,4 3.4922 0.2054 1 1 1 1 3 15 4,4,4,3 3.0842 0.2056 1 1 1 1 4 20
4,4,4,4,4 4.1138 0.2057 1 1 1 1 5 19 4,4,4,4,3 3.9176 0.2062 1 1 1 1
:::

Adding top.overall = TRUE to Config() provides the same information but
with the top testing configurations overall rather than for each initial
group size.

The most efficient outcome from the OTC depends on the chosen value of
$p$. As mentioned earlier in this section, very good point estimates for
$p$ are often available. Still, it would be of interest to determine
what would occur for other choices of $p$. The
[binGroup2](https://CRAN.R-project.org/package=binGroup2) package
provides the tools needed by experienced R users for this more in depth
examination. Our Appendix A discusses additional code using OTC1() to
produce Figure [3](#fig:Expected-number-of){reference-type="ref"
reference="fig:Expected-number-of"}. The testing configuration chosen by
@lohse2020pooling is never optimal. In fact, two-stage hierarchical
group testing is more efficient than @lohse2020pooling for $p>0.03$.

<figure id="fig:Expected-number-of">
<div class="centering">
<embed src="figures/Lohse.pdf" />
</div>
<figcaption>Expected number of tests per individual as a function of
infection prevalence. Three-stage hierarchical testing using the OTC is
not plotted for prevalences greater than 0.10 because two stages results
in a lower expected number of tests. <span id="fig:Expected-number-of"
label="fig:Expected-number-of"></span></figcaption>
</figure>

Our second example focuses on SARS-CoV-2 detection again, but now in the
context of LabCorp's array testing. @LabCorp examined the potential
performance of their approach using possible prevalences between 0.001
and 0.15, so we begin with using a prevalence of 0.05. Also, @LabCorp
estimated that approximately 0.023 of all positives would be missed
using array testing rather than individual testing. This is not quite
the sensitivity of the assay, but we will use 0.977 and 1 as the
sensitivity for the first and second stages, respectively, for
illustration purposes. We will also use 1 as the specificity for
illustration purposes. The expected number of tests per individual for
the algorithm is found first using opChar1() with algorithm = \"A2\".

::: Sinput
\> save.LabCorp \<- opChar1(algorithm = \"A2\", p = 0.05, rowcol.sz = 5,
Se = c(1 - 0.023, 1), Sp = 1, print.time = FALSE) \>
ExpTests(save.LabCorp)
:::

::: Soutput
ExpTests ExpTestsPerIndividual PercentReductionTests
PercentIncreaseTestCap 1 12.0763 0.4831 51.69 107.02
:::

The expected number of tests per individual is 0.48, resulting in an
expected 107% increase in testing capacity.

Could LabCorp do better? Below is the code used to find the OTC for a
range of group sizes from 3 to 10 with array testing.

::: Sinput
\> OTC.LabCorp.Array \<- OTC1(algorithm = \"A2\", p = 0.05, Se =
c(0.977, 1), Sp = 1, group.sz = 3:10, obj.fn = \"ET\", trace = FALSE,
print.time = FALSE) \> summary(OTC.LabCorp.Array)
:::

::: Soutput
Algorithm: Non-informative array testing without master pooling

Optimal testing configuration: Row/column size Array size ET 10 100

Expected number of tests: E(T) Value ET 37.20 0.3720

E(T) denotes the expected number of tests. Value denotes the objective
function value per individual.

Overall accuracy of the algorithm: PSe PSp PPPV PNPV ET 0.9550 1.0000
1.0000 0.9976

PSe denotes the pooling sensitivity. PSp denotes the pooling
specificity. PPPV denotes the pooling positive predictive value. PNPV
denotes the pooling negative predictive value.
:::

::: Sinput
\> ExpTests(OTC.LabCorp.Array)
:::

::: Soutput
ExpTests ExpTestsPerInd PercentReductionTests PercentIncreaseTestCap
opt.ET 37.1953 0.3720 62.80 168.85
:::

The OTC for array testing is a $10\times10$ array that has an expected
number of tests per individual of 0.37 and an increase in testing
capacity of 169%. This is a significant improvement over the $5\times5$
array. One could perform similar calculations using two-stage
hierarchical testing with algorithm = \"D2\" in OTC1. This results in an
OTC that uses an initial group size of 5 and leads to an expected number
of tests per individual of 0.42.

Because these calculations rely on $p=0.05$, Appendix B includes
additional results for different values of $p$ and a discussion of the
corresponding more advanced code. In most cases, we find that a
$5\times5$ array is not the OTC.

## Additional functions[]{#subsec:Additional functions-1 label="subsec:Additional functions-1"}

Not all group testing algorithms fit well within a general computing
framework. For this reason, we include a few additional functions
outside of those discussed previously. In particular, the halving() and
Sterrett() functions provide alternative ways to use hierarchical
testing algorithms. The former function calculates operating
characteristics when positive testing groups are split only in half
(@litvak1994screening; @black2012group). The latter function calculates
operating characteristics for algorithms that retest only one specimen
at a time from a positive group (@sterrett1957detection; @Bilder2010a).
Once a positive is found, the remaining specimens are retested again in
a group. The idea behind this strategy is there will likely be only one
positive (or few positives) in the original group.

# Conclusion[]{#sec:Conclusion label="sec:Conclusion"}

The [binGroup2](https://CRAN.R-project.org/package=binGroup2) package
provides researchers and laboratories with the statistical tools needed
to implement group testing effectively. An earlier version of this
package was used as well by *The New York Times* to help readers
understand the benefits from group testing during the COVID-19 pandemic
(@NYTimesBui). Similar to @Bilder2010b, we encourage researchers to
submit their own functions to us to be included within the package. This
will allow users to have one overall package rather than many packages
that may duplicate the work of others.

The identification functions are for one and two-infection assays. While
there are a few three- and four-infection assays for infectious disease
detection that have been recently released (e.g., the BD Max CT/GC/TV
assay (@BD) that tests for pathogens which lead to chlamydia, gonorrhea,
and trichomoniasis), these assays are used currently much less than
single and two-infection assays. Also, derivations for operating
characteristics become much more complex for more than two infections,
so there are no closed-form expressions available for these types of
assays. For example, @houarray1 needed Monte Carlo simulation for a
three-infection assay. We anticipate that it will be useful to include
Monte Carlo simulation-based estimates of operating characteristics in
future versions of
[binGroup2](https://CRAN.R-project.org/package=binGroup2) as these types
of multiplex assays become more widely used. New research is needed
though to find efficient computational approaches when searching for the
OTC because of these simulation aspects.

While not the focus of this paper, the estimation functions from
[binGroup](https://CRAN.R-project.org/package=binGroup) have been
simplified and expanded upon using a coherent style. The new propCI()
function combines three previous functions into one to calculate point
estimates and confidence intervals for an infection prevalence. The new
propDiffCI() provides similar functionality for the difference of two
infection prevalences. Both functions incorporate new research since
@Bilder2010b. In particular, the bias correction methods of
@hepworth2017bias are included to account for the long-standing problem
of bias for point estimates in group testing (@swallow1985group). The
gtReg() function combines three previous
[binGroup](https://CRAN.R-project.org/package=binGroup) functions used
to estimate regression models with group testing data that arise from
different testing algorithms. The gtSim() function also combines three
previous [binGroup](https://CRAN.R-project.org/package=binGroup)
functions to simulate group testing data with covariates that can arise
from different testing algorithms.

# Acknowledgments

The authors thank Jeffrey Benfer and Kristopher Eveland at the SHL and
Peter Iwen and Baha Abdalhamid at the Nebraska Public Health Laboratory
for their consultation on CT/NG and SARS-CoV-2 testing. This research
was supported by Grant R01 AI121351 from the National Institutes of
Health. The views expressed in this article are those of the authors and
do not necessarily reflect the official policy or position of the United
States Air Force Academy, the Air Force, the Department of Defense, or
the U.S. Government. Approved for public release: distribution
unlimited. PA#: USAFA-DF-2022-474.

# Appendix A: Details for figure

Our separate R program provides the code to create Figure
[3](#fig:Expected-number-of){reference-type="ref"
reference="fig:Expected-number-of"}. This figure presents a comparison
of the three-stage hierarchical testing algorithm of @lohse2020pooling
to using the OTC for two- and three-stage hierarchical testing. We use
the OTC1() function to find the OTCs for the prevalences of 0.001,
0.005, and 0.01 to 0.20 by 0.01 with a maximum group size of 64. The
large number of prevalences and large group sizes will result in a
significant amount of computational time. For readers interested in
testing the code, we recommend using a few prevalence values and a
maximum group size of 30 for an initial running of it.

# Appendix B: Labcorp's array testing

@LabCorp described the use of arrays for up to size $5\times5$. Our
separate R program provides the code to create Figure
[4](#fig:LabCorp){reference-type="ref" reference="fig:LabCorp"} that
examines their use further. This figure provides evidence that a
$5\times5$ array size is not an optimal choice. For the corresponding
calculations, we found the OTC for array testing by minimizing the
expected number of tests per individual for the prevalences of 0.001,
0.005, and 0.01 to 0.20 by 0.01. Because two-stage hierarchical testing
is also frequently used for SARS-CoV-2 detection, we also found the OTC
for this algorithm. Throughout these calculations, we conservatively
limit the maximum group size to 10.

<figure id="fig:LabCorp">
<div class="centering">
<embed src="figures/LabCorp.pdf" />
</div>
<figcaption>Expected number of tests per individual as a function of
infection prevalence for LabCorpâ€™s setting. <span id="fig:LabCorp"
label="fig:LabCorp"></span></figcaption>
</figure>
