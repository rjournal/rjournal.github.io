% !TeX root = RJwrapper.tex
\title{Rfssa: An R Package for Functional Singular Spectrum Analysis}
\author{by Hossein Haghbin, Jordan Trinka and Mehdi Maadooliat}
\maketitle
\begin{abstract}
Functional Singular Spectrum Analysis (FSSA) is a non-parametric approach for analyzing Functional Time Series (FTS) and Multivariate FTS (MFTS) data. This paper introduces Rfssa, an R package that addresses implementing FSSA for FTS and MFTS data types. Rfssa provides a flexible container, the funts class, for FTS/MFTS data observed on one-dimensional or multi-dimensional domains. It accepts arbitrary basis systems and offers powerful graphical tools for visualizing time-varying features and pattern changes. The package incorporates two forecasting algorithms for FTS data. Developed using object-oriented programming and Rcpp/RcppArmadillo, Rfssa ensures computational efficiency. The paper covers theoretical background, technical details, usage examples, and highlights potential applications of Rfssa.
\end{abstract}
\section{Introduction}\label{sec:introduction}
In recent times, advancements in data acquisition techniques have made it possible to collect data in high-resolution formats. Due to the presence of temporal-spatial dependence, one may consider this type of data as \textit{functional data}.
Functional Data Analysis (FDA) focuses on developing statistical methodologies for analyzing data represented as functions or curves. While FDA methods are particularly well-suited for handling smooth continuum data, they can also be adapted and extended to effectively analyze functional data that may not exhibit perfect smoothness, including high-resolution data and data with inherent variability.
The widely-used \proglang{R} package for FDA is \CRANpkg{fda} \citep{fdapackage}, which is designed to support analysis of functional data, as described in the textbook by \cite{ramsay2005}. Additionally, there are over 40 other \proglang{R} packages available on CRAN that incorporate functional data analysis, such as \CRANpkg{funFEM} \citep{funFEMpackage}, \CRANpkg{fda.usc} \citep{fdauscpackage}, \CRANpkg{refund} \citep{refundpackage}, \CRANpkg{fdapace} \citep{fdapacepackage}, \CRANpkg{funData} \citep{funDatapackage}, \CRANpkg{ftsspec} \citep{ftsspecpackage}, \CRANpkg{rainbow} \citep{rainbowpackage}, and \CRANpkg{ftsa} \citep{ftsapackage}.
One crucial initial requirement for any of these packages is to establish a framework for representing and storing infinite-dimensional functional observations. The \CRANpkg{fda} package, for instance, employs the \code{fd} class as a container for functional data defined on a one-dimensional (1D) domain. An \code{fd} object represents functional data as a finite linear combination of known basis functions (e.g., Fourier, B-splines, etc.), storing both the basis functions and their respective coefficients for each curve. This representation aligns with the practical implementation found in many papers within the field of FDA. Conversely, several other \proglang{R} packages store functional data in a discrete form evaluated on grid points (e.g., \CRANpkg{fda.usc}, \CRANpkg{refund}, \CRANpkg{funData}, \CRANpkg{rainbow}, and \CRANpkg{fdapace}). These packages also provide the capability to analyze functions beyond the one-dimensional case, such as image data treated as two-dimensional (2D) functions (e.g., \CRANpkg{refund}, \CRANpkg{fdasrvf}, and \CRANpkg{funData}). To the best of our knowledge, packages that support representation beyond 1D functions utilize the grid point representation for execution and storage.
Moreover, recent packages have been developed to handle multivariate functional data, which consist of more than one function per observation unit. Examples of such packages include \CRANpkg{roahd}, \CRANpkg{fda.usc}, and \CRANpkg{funData}.
While some recent FDA packages have focused on analyzing and implementing techniques for Functional Time Series (FTS), where sequences of functions are observed over time, none of them handle Multivariate FTS (MFTS) or multidimensional MFTS. For example, see the packages \CRANpkg{ftsspec}, \CRANpkg{rainbow}, and \CRANpkg{ftsa}. In summary, there is still a need for a unified and flexible container for FTS/MFTS data, defined on either one or multidimensional domains. The \code{funts} class in \CRANpkg{Rfssa} \citep{rfssapackage}, the package discussed in this article, aims to address this gap. One of the primary contributions of the package is its capacity to handle and visualize 2-dimensional FTS, including image data. Furthermore, the package accommodates MFTS, especially when observed on distinct domains. This flexibility empowers users to analyze and visualize FTS with multiple variables, even when they do not share the same domain. Notably, the \CRANpkg{Rfssa} package introduces novel visualization tools (as exemplified in Figure \ref{fig:call_center}). These tools include heatmaps and 3D plots, thoughtfully designed to provide a deeper understanding of functional patterns over time. They enhance the ability to discern trends and variations that might remain inconspicuous in conventional plots. An additional feature of the \code{funts} class is its ability to accept any arbitrary basis system as input for the class constructor, including FDA basis functions or even empirical basis represented as matrices evaluated at grid points. The classes in the \CRANpkg{Rfssa} package are developed using the S3 object-oriented programming system, and for computational efficiency, significant portions of the package are implemented using the \CRANpkg{Rcpp}/\CRANpkg{RcppArmadillo} packages. Notably, the package includes a shiny web application that provides a user-friendly GUI for implementing Functional Singular Spectrum Analysis (FSSA) on real or simulated FTS/MFTS data.
The \CRANpkg{Rfssa} package was initially developed to implement FSSA for FTS, as discussed in the work of \cite{haghbin2021}. FSSA extends Singular Spectrum Analysis (SSA), a model-free procedure commonly used to analyze time series data. The primary goal of SSA is to decompose the original series into a collection of interpretable components, such as slowly varying trends, oscillatory patterns, and structureless noise. Notably, SSA does not rely on restrictive assumptions like stationarity, linearity, or normality \citep{golyandina2013}.
It's worth noting that SSA finds applications beyond the functional framework, including smoothing and forecasting purposes \citep{hassani2013, deCarvalho2017realtime}. The non-functional version of FSSA, known as SSA, has previously been implemented in the \CRANpkg{Rssa} package \citep{rssapackage} and the \CRANpkg{ASSA} package \citep{ASSApackage}.
The \CRANpkg{Rssa} package provides various visualization tools to facilitate the grouping stage, and the \CRANpkg{Rfssa} package includes equivalent functional versions of those tools \citep{golyandina2018singular}. While the foundational theory of FSSA was originally designed for univariate FTS, it has since been extended to handle multidimensional FTS data, referred to as Multivariate FSSA (MFSSA) \citep{trinka2022multivariate}. Furthermore, in line with the developments in SSA for forecasting, two distinct algorithms known as Recurrent Forecasting (FSSA R-forecasting) and Vector Forecasting (FSSA V-forecasting) were introduced for FSSA by \cite{trinka2023functional}. Both of these forecasting algorithms, along with the capabilities for handling MFSSA, have been seamlessly integrated into the most recent version of the \CRANpkg{Rfssa} package.
The remainder of this manuscript is organized as follows. Section 2 introduces the FTS/MFTS data preparation theory used in the \code{funts} class. Section 3 discusses the FSSA methodology, including the basic schema of FSSA, FSSA R-forecasting, and FSSA V-forecasting. Technical details of the \CRANpkg{Rfssa} package are provided in Section 4, where we describe the available classes in the package and illustrate their practical usage with examples of real data. Section 5 focuses on the reconstruction stage and FSSA/MFSSA forecasting. In Section 6, we provide a summary of the embedded shiny app. Finally, we conclude the paper in Section 7.
\section{Data preparation in FTS}\label{sec:preparation}
Define $\textbf{y}_N=(y_1,\ldots,y_N)$ to be a collection of observations from an FTS. In the theory of FTS, $y_i$'s are considered as functions in the space $\mathbb{H}=L^2(\mathcal{T})$ where $\mathcal{T}$ is a compact subset of $\mathbb{R}.$ Let $s\in\mathcal{T}$ and consider $y_i(s)\in\mathbb{R}^p$, the sequence of $\textbf{y}_N$ is called (univariate) FTS if $p=1$, and multivariate FTS (or MFTS) if $p>1.$
In the realm of functional data analysis, we operate under the assumption that the underlying sample functions, denoted as $y_{i}(\cdot)$, exhibit smoothness for each sample $i$, where $i=1, \ldots, N$. Nevertheless, in practical scenarios, observations are typically acquired discretely at a set of grid points and are susceptible to contamination by random noise. This phenomenon can be represented as follows:
\begin{equation}\label{discr_data}
	Y_{i,k} = y_{i}(t_k) +\varepsilon_{i,k}, \quad k=1,\ldots, K.
\end{equation}
In this expression, $t_k\in\mathcal{T}$, and $K$ denotes the count of discrete grid points across all samples. The $\varepsilon_{i,k}$ terms represent i.i.d. random noise.
To preprocess the raw data, it is customary to employ smoothing techniques, converting the discrete observations $Y_{i,k}$ into a continuous form, $y_{i}(\cdot)$. This is typically performed individually for each variable and sample. One widely used approach is finite basis function expansion \citep{ramsay2005}. In this method, a set of basis functions $\left\lbrace \nu_i \right\rbrace_{ i\in\mathbb{N}}$ is considered (not necessarily orthogonal) for the function space $\mathbb{H}$. Each sample function $y_{i}(\cdot)$ in \eqref{discr_data} is then considered as a finite linear combination of the first $d$ basis functions:
\begin{equation}\label{basis_expan}
	y_i(s)= \sum_{j=1}^d c_{ij}\nu_j(s).
\end{equation}
Subsequently, the coefficients $c_{ij}$ can be estimated using least square techniques. By adopting the linear representation form for the functional data in \eqref{basis_expan}, we establish a correspondence between each function $y_i(\cdot)$ and its coefficient vector ${\pmb c}_i=(c_{ij})_{j=1}^d.$ As a result, the coefficient vectors ${\pmb c}_i$ can serve to store and retrieve the original functions, $y_i(\cdot)$'s. This arises from the inherent isomorphism between two finite vector spaces of the same dimension (in this case, $d$). Consequently, ${\pmb c}_i$'s are stored as the primary attribute of \code{funts} objects within the \CRANpkg{Rfssa} package.
Take two elements $x, y\in \mathbb{H}$ with corresponding coefficient vectors ${\pmb c}_x$ and ${\pmb c}_y.$ Then, the inner product of $x, y$ can be computed in matrix form as $\langle x,y \rangle={\pmb c}_x^\top \mathbf{G} {\pmb c}_y$, where $\mathbf{G}=[ \langle \nu_i,\nu_j \rangle ]_{i,j=1}^{d}$ is the Gram matrix.
It is important to note that $\mathbf{G}$ is Hermitian. Furthermore, because the basis functions $\{\nu_i\}_{i=1}^d$ are linearly independent, $\mathbf{G}$ is positive definite, making it invertible \citep[][Thm. 7.2.10]{horn2012matrix}.
Moreover, let $A:\mathbb{H}\rightarrow \mathbb{H}$ be a linear operator and $y=A(x).$ Then, ${\pmb c}_y= \mathbf{G}^{-1}\mathbf{A}{\pmb c}_x,$ where $\mathbf{A}=[ \langle A(\nu_j),\nu_i \rangle ]_{i,j=1}^{d}$ is called the corresponding matrix of the operator $A.$
It is worth noting that while the FSSA theory extends to arbitrary dimensions, practical implementation for dimensions greater than $2$ introduces considerable computational complexity. Moreover, high-dimensional FTS data are relatively rare in real-world applications. Therefore, within the \CRANpkg{Rfssa} package, we have chosen to confine the \code{funts} object to support functions observed over domains that are one or two-dimensional. In the \CRANpkg{Rfssa} package, the task of preprocessing the raw discrete observations and converting those to the \code{funts} object is assigned to the \code{funts($\cdot$)} constructor.
\section{An overview of the FSSA methodology}\label{sec:methodology}
FSSA is a nonparametric technique to decompose FTS and MFTS, and the methodology can also be used to forecast such data \citep{haghbin2021, trinka2022multivariate, trinka2023functional}; it can also be used as a visualization tool to illustrate the concept of seasonality and periodicity in the functional space over time.
\subsection{Basic schema of FSSA}
Basic FSSA consists of two stages where each stage includes two steps. We outline the four steps of the FSSA algorithm here.
\begin{itemize}
\item[I)] \textbf{First stage: decomposition}
\begin{itemize}
\item[1.]  \textit{Embedding} \\ For a positive integer, $L<N/2$, let $\mathbb{H}^L$ be the Cartesian product of $L$ copies of $\mathbb{H}$ and define the \textit{trajectory} operator $\mathbfcal{X}:\mathbb{R}^{K} \rightarrow \mathbb{H}^{L}$ with
	\begin{equation}\label{trajectory}
		\mathbfcal{X}{\pmb a}:=\sum_{j=1}^K a_j{\pmb x}_j,\qquad
		{\pmb a}=\left(a_1,\ldots, a_K\right)^\top \in\mathbb{R}^K.
	\end{equation}
	where $K=N-L+1$ and 
	\begin{equation}\label{flvec}
		{\pmb x}_j(s):= \left( y_j(s), y_{j+1}(s), \ldots, y_{j+L-1}(s)\right)^\top,\ j=1,\ldots, K,
	\end{equation}
	are called \textit{lag-vectors}. One may consider the trajectory operator $\mathbfcal{X}$ in \eqref{trajectory} as an $L \times K$ matrix with functional entries in the form of	
	\begin{equation}\label{eqn:hankelmat}
		\mathbfcal{X}(s) = \begin{bmatrix}y_{1}(s) & y_{2}(s) & y_{3}(s) & \cdots & y_{K}(s) \\ y_{2}(s) & y_{3}(s) & y_{4}(s) & \cdots & y_{K+1}(s) \\ y_{3}(s) & y_{4}(s) & y_{5}(s) & \cdots & y_{K+2}(s) \\ \vdots  & \vdots & \vdots & \ddots & \vdots \\ y_{L}(s) & y_{L+1}(s) & y_{L+2}(s) & \cdots & y_{N}(s)  \end{bmatrix}.
	\end{equation}
Note that the antidiagonal elements of the matrix in \eqref{eqn:hankelmat} are all equal. Such matrices are called Hankel, and since $\mathbfcal{X}(s)$ is a Hankel matrix for any $s$ in the domain, we call $\mathbfcal{X}$ a Hankel operator. In practice, a main challenge is how to use the original basis of $\mathbb{H}$ to represent the lag-vectors in $\mathbb{H}^L$. To do this, one may define a quotient sequence $q_k$, and a remainder sequence $r_k$, by $k=(q_k-1)L+r_k,$ where $1\leq r_k\leq L$, and $1\leq q_k\leq d$. Now, consider ${\pmb \phi}_{k}$ as a functional vector of length $L$ with all zero functions, except the $r_k$-th element, which is $\nu_{q_k}$. Using this definition, the lag-vector ${\pmb{x}_j}$ given in \eqref{flvec} can be represented as a linear combination of $\{{\pmb \phi}_{k}\}_{k=1}^{Ld}$ with the corresponding coefficient vector ${\bf b}_j=(c_{1j},\ldots, c_{1,j+L-1},c_{2j},\ldots,c_{2,j+L-1},\ldots,c_{d,j+L-1} )^\top.$ 
\item[2.] \textit{FSVD }\\ We apply the functional singular value decomposition (FSVD) to $\mathbfcal{X}$ and obtain a collection of singular values, $\{\sqrt{\lambda_i}\}_{i=1}^{r}$, orthonormal right singular vectors $\{\mathbf{v}_{i}\}_{i=1}^{r}$ (that are elements of $\mathbb{R}^{K}$), and orthonormal left singular functions $\{\pmb{\psi}_{i}\}_{i=1}^{r}$ (that are elements of $\mathbb{H}^{L}$). The collection $(\sqrt{\lambda_i}, \pmb{\psi}_i, \mathbf{v}_i)$ will be called the $i^{th}$ eigentriple of the FSVD, and $r$ is the rank of $\mathbfcal{X}$:	
	\begin{equation}\label{FSVD}
		\mathbfcal{X} = \sum_{i=1}^{r} \mathbfcal{X}_{i} = \sum_{i=1}^{r} \sqrt{\lambda_i} \mathbf{v}_{i} \otimes \pmb{\psi}_{i},
	\end{equation}
where $\mathbfcal{X}_{i}:\mathbb{R}^{K} \rightarrow \mathbb{H}^{L}$ is a rank one elementary operator. To implement the FSVD of $\mathbfcal{X}$ given in \eqref{FSVD}, let ${\bf B}:=[{\bf b}_1,\cdots,{\bf b}_K]$, $\mathbf{G}:=[ \langle {\pmb \phi}_{i}, {\pmb \phi}_{j} \rangle_{\mathbb{H}^L}]_{i,j=1}^{Ld}$, $\mathbf{X}:=\mathbf{G}^{1/2}\mathbf{B}$, and $\left(\sqrt{\lambda_i}, \pmb{u}_i, \mathbf{v}_i\right)$'s be the eigentriples of the SVD of the matrix $\mathbf{X}$. It can be shown that $\left(\sqrt{\lambda_i},\pmb{\psi}_i,\mathbf{v}_i \right)$ is the $i^{th}$ eigentriple of the FSVD of $\mathbfcal{X}$, where the left singular function, ${\pmb \psi}_i$, is corresponding to the coefficient vector $\mathbf{G}^{-1/2}{\pmb u}_i$. See \citep{haghbin2021} for more details.
\end{itemize}
These steps can also be extended to the multivariate case, i.e. MFSSA. See \cite{trinka2022multivariate} for more details. In the \CRANpkg{Rfssa} package, the results of the decomposition stage are held in an object from the \code{fssa} class. The constructor, \code{fssa($\cdot$)}, performs the decomposition for both FSSA and MFSSA algorithms and returns an object of class \code{fssa}. Further discussion about the attributes and methods of the \code{fssa} class is given in the technical details section.
\item[II)] \textbf{Second stage: reconstruction}
\begin{itemize}
\item[3.] \textit{Grouping}\\ We partition the set of indices $\{1,\dots,r\}$ into disjoint sets $I_{q}$, where $q \in \{1,\dots, m\}$ and $m\leq r$. From here, we obtain the group $\mathbfcal{X}_{I_{q}}$ by combining the respective elementary operators accordingly:
	\begin{equation}
		\mathbfcal{X}_{I_{q}} = \sum_{i \in I_{q}} \mathbfcal{X}_{i}. \nonumber
	\end{equation}
Exploratory plots of singular values, right singular vectors, and left singular functions that investigate the different modes of variation extracted in the decomposition stage are used to decide how to form the sets, $I_{q}$, and we discuss such plots in further detail in section five.
\item[4.] \textit{Hankelization }\\ Since each $\mathbfcal{X}_{I_{q}}$ is not necessarily Hankel, we perform diagonal averaging of the entries to Hankelize each operator. From each Hankelized $\mathbfcal{X}_{I_{q}}$, we obtain an FTS, $\mathbf{y}_{N}^{q}$, that describes main characteristics of $\mathbf{y}_{N}$ such as mean, seasonal, trend, and noise behaviors.
\end{itemize}
For the reconstruction stage, the \CRANpkg{Rfssa} package provides the function \code{freconstruct($\cdot$)} which returns a list of objects of class \code{funts} associated with the groups specified by the user. If the supplied input to the \code{fssa($\cdot$)} function is an MFTS, the signal extraction process is almost identical as compared to the univariate case with the exception that now, we have that each element of the time series is a tuple of functions comprised of elements observed over one or two-dimensional domains.
\section*{Acknowledgments}
The authors would like to express their sincere gratitude to the anonymous reviewers for their valuable feedback and constructive comments, which greatly contributed to the improvement of this work.
Additionally, we would like to acknowledge the significant contributions of Dr. S. Morteza Najibi during the development stages of the first version of the \CRANpkg{Rfssa} package. 
\bibliography{Haghbin_Rfssa}
\address{Hossein Haghbin\\
	Artificial Intelligence and Data Mining Research Group, ICT Research Institute \\
	Faculty of Intelligent Systems Engineering and Data Science, Persian Gulf University\\ Boushehr, Iran\\
	(ORCiD 0000-0001-8416-2354)\\
	\email{haghbin@pgu.ac.ir}}
\address{Jordan Trinka\\
  Department of Mathematical and Statistical Sciences, Marquette University,\\
  Wisconsin, USA\\
  (ORCiD 0000-0001-9118-5781)\\
  \email{jordantrinka4@hotmail.com}}
\address{Mehdi Maadooliat\\
  Department of Mathematical and Statistical Sciences, Marquette University,\\
  Wisconsin, USA\\
  (ORCiD: 0000-0002-5408-2676)\\
  \email{mehdi.maadooliat@mu.edu}}
