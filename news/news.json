[
  {
    "path": "news/RJ-2024-1-bioconductor/",
    "title": "Bioconductor Notes, March 2024",
    "description": "We discuss general project news.",
    "author": [
      {
        "name": "Maria Doyle, Bioconductor Community Manager",
        "url": {}
      },
      {
        "name": "Bioconductor Core Developer Team",
        "url": {}
      }
    ],
    "date": "2024-03-01",
    "categories": [],
    "contents": "\n1 Introduction\nBioconductor provides\ntools for the analysis and comprehension of high-throughput genomic\ndata. The project has entered its twentieth year, with funding\nfor core development and infrastructure maintenance secured\nthrough 2025 (NIH NHGRI 2U24HG004059). Additional support is provided\nby NIH NCI, Chan-Zuckerberg Initiative, National Science Foundation,\nMicrosoft, and Amazon. In this news report, we give some updates on\ncore team and project activities.\n2 Software\n\n\n\nIn October 2023, Bioconductor 3.18 was released*. It is compatible with R 4.3 and includes 2266 software packages, 429 experiment data packages, 920 up-to-date annotation packages, 30 workflows, and 4 books. Books are built regularly from source, ensuring full reproducibility; an example is the community-developed Orchestrating Single-Cell Analysis with Bioconductor.\n*Note: Bioconductor 3.19 and 3.20 were subsequently released in May and October 2024, respectively. For details on the latest release, visit the Bioconductor website.\n3 Website Redesign\nIn January 2024, we unveiled the new Bioconductor.org, featuring a cleaner design, improved accessibility, and reorganized content. This redesign, shaped by community feedback, aims to better serve our global users. Looking ahead, we have identified the need to enhance search functionalities and improve how Bioconductor content is structured and integrated to support advanced tools, including AI. Planning is underway, with development expected to begin in 2025, subject to grant outcomes. See blog post for more details.\n4 Community and Impact\n4.1 Community Profile\nAt the end of 2023, the Center for Scientific Collaboration and Community Engagement (CSCCE) published a Bioconductor Community Profile. This report highlights the impact of Bioconductor’s first year of CZI EOSS 4 funding, providing insights into our community’s structure, challenges, and successes. Read the full profile here.\n4.2 Outreachy Internships\nBioconductor participated in the Outreachy Internship program for the December 2023 – March 2024 cohort. Interns Chioma Onyido, Ester Afuape, and Peace Sandy from Nigeria contributed to curating microbiome studies for BugSigDB. They also shared their experiences working on these projects and engaging with the Bioconductor community in a blog post, which you can read here.\n4.3 YERUN Open Science Award\nIn February 2024, the Bioconductor Community Advisory Board received the YERUN Open Science Award for advancing open-source software in biomedical research and promoting equitable access to genomic analysis tools. The €2,000 prize will fund a hackathon focused on AI-assisted translation of training materials. Learn more in the UL article.\n4.4 Bioconductor Leaves Twitter/X\nIn December 2023, Bioconductor transitioned away from Twitter/X due to concerns about the platform’s alignment with our Code of Conduct. The account is now archived, and we encourage the community to connect with us on platforms like Mastodon, LinkedIn, YouTube, Slack, and our mailing lists. Read the full announcement here.\n5 Conferences\n5.1 BioC2024 Announcement\nThe annual Bioconductor Conference, BioC2024, will take place in Grand Rapids, Michigan, from July 24–26, 2024. This event will feature keynote talks, workshops, and opportunities for community engagement. For more details, visit the conference website here.\n5.2 EuroBioC2024 Announcement\nThe European Bioconductor Conference, EuroBioC2024, will be held in Oxford, UK, from September 4–6, 2024. Join us for discussions, tutorials, and networking with the Bioconductor community in Europe. More information is available here.\n6 Boards and Working Groups Updates\nIf you are interested in becoming involved with any Bioconductor working group please contact the group leader(s).\n6.1 EDAM Working Group Announcement\nBioconductor has launched an EDAM Working Group in collaboration with EDAM-bio.tools to improve the discoverability of Bioconductor packages through the EDAM ontology, a widely used bioinformatics vocabulary and classification system. This effort supports greater integration with communities beyond R and platforms like Galaxy and aligns with Bioconductor’s mission of accessibility and interoperability. The group is submitting a proposal for the ELIXIR BioHackathon 2024, and invites interested contributors to join the discussion on the Bioconductor Slack in the #edam-collaboration channel.\n7 Using Bioconductor\nStart using\nBioconductor by installing the most recent version of R and evaluating\nthe commands\n  if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n      install.packages(\"BiocManager\")\n  BiocManager::install()\nInstall additional packages and dependencies,\ne.g., SingleCellExperiment, with\n  BiocManager::install(\"SingleCellExperiment\")\nDocker\nimages provides a very effective on-ramp for power users to rapidly\nobtain access to standardized and scalable computing environments.\nKey resources include:\nbioconductor.org to install,\nlearn, use, and develop Bioconductor packages.\nA list of available software\nlinking to pages describing each package.\nA question-and-answer style\nuser support site and\ndeveloper-oriented mailing list.\nA community slack workspace (sign up)\nfor extended technical discussion.\nThe F1000Research Bioconductor gateway\nfor peer-reviewed Bioconductor workflows as well as conference contributions.\nThe Bioconductor YouTube\nchannel includes recordings of keynote and talks from recent\nconferences, in addition to\nvideo recordings of training courses.\nOur package submission\nrepository for open technical review of new packages.\nUpcoming and recently completed events are browsable at our\nevents page.\nThe Technical\nand and Community\nAdvisory Boards provide guidance to ensure that the project addresses\nleading-edge biological problems with advanced technical approaches,\nand adopts practices (such as a\nproject-wide Code of Conduct)\nthat encourages all to participate. We look forward to\nwelcoming you!\nWe welcome your feedback on these updates and invite you to connect with us through the Bioconductor Slack workspace or by emailing community@bioconductor.org.\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2024-1-cran/",
    "title": "Changes on CRAN",
    "description": {},
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2024-03-01",
    "categories": [],
    "contents": "\n1 CRAN growth\nIn the past 6 months, 1060 new packages were\nadded to the CRAN package repository. 405 packages\nwere unarchived, 690 were archived and\n7 had to be removed. The following shows the\ngrowth of the number of active packages in the CRAN package repository:\n\n\n\nOn 2024-06-30, the number of active packages was around 21018.\n\n2 CRAN package submissions\nFrom January 2024 to June 2024\nCRAN received 14584 package submissions.\nFor these, 23887 actions took place of which\n16756 (70%) were auto processed actions and\n7131 (30%) manual actions.\nMinus some special cases, a summary of the auto-processed and manually\ntriggered actions follows:\n\n\narchive\ninspect\nnewbies\npending\npretest\npublish\nrecheck\nwaiting\nauto\n4316\n1674\n3532\n383\n0\n4588\n1572\n691\nmanual\n2726\n140\n93\n255\n179\n2881\n638\n219\n\nThese include the final decisions for the submissions which were\n\n\narchive\npublish\nauto\n4083 (28.7%)\n4045 (28.4%)\nmanual\n2692 (18.9%)\n3399 (23.9%)\n\nwhere we only count those as auto processed whose publication or\nrejection happened automatically in all steps.\nA new team member, Konstanze Lauseker, joined the CRAN submission team. Welcome, Konstanze.\nUnfortunately, Victoria Wimmer left the CRAN submission team after processing 4588 incoming submissions. Thanks a lot!\n3 CRAN mirror security\nCurrently, there are 94 official CRAN mirrors,\n73 of which provide both\nsecure downloads via ‘https’ and use secure mirroring from the CRAN master\n(via rsync through ssh tunnels). Since the R 3.4.0 release, chooseCRANmirror()\noffers these mirrors in preference to the others which are not fully secured (yet).\n4 CRAN Task View Initiative\n\n\n\nCurrently there are 46 task views (see https://CRAN.R-project.org/web/views/),\nwith median and mean numbers of CRAN packages covered\n104 and 122, respectively.\nOverall, these task views cover 4711 CRAN packages,\nwhich is about 22% of all active CRAN packages.\nJulia Piaskowski (University of Idaho) joined the team of CRAN Task View Editors, welcome!\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2024-1-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in The R Journal.",
    "author": [
      {
        "name": "Mark P.J. van der Loo",
        "url": "https://journal.r-project.org"
      }
    ],
    "date": "2024-03-01",
    "categories": [],
    "contents": "\nOn behalf of the editorial board, I am pleased to present Volume 16 Issue 1 of\nthe R Journal.\nWe would like to welcome our new Associate Editors Jouni Helseke, Christoph\nSax, Thomas Fung, Wenjie Wang, Matthias Templ, Thiyanga Talagala, Xiaoqian\nWang, Romain Lesur, and Ivan Svetunkov to the editorial team.\nWe also express our gratitude to Simon Urbanek, who worked as editor-in-chief,\nand will stay on as executive editor. Simon has not only worked as an editor of\nthe journal but is also contributing to improving the submission\ninfrastructure. The articles in this issue have been carefully copy edited by\nAdam Bartonicek and Harriet Mason. We thank Mitchell O’Hara-Wild for technical\nediting work on this issue.\nWe are deeply saddened that the publication of this issue also marks the passing\nof Friedrich ‘Fritz’ Leisch. Fritz was one of the founding fathers of R News,\nthe peer-reviewed publication that would turn into the journal that you are\nreading today. The fact that R News started with just two people, and is now\nrun by more than 30 volunteers is a testimony to his impact within the R community.\nAs a member of the R Core Team, Fritz also committed Sweave to R, which must\nbe seen as a visionary and pioneering step towards the reproducible research\nworkflow for which R is now famous and that supports the publication of this\nJournal. For these and all his other contributions, we will forever be\ngrateful. On behalf of the R Journal team, we extend our deepest\ncondolences to his family, his friends, and others close to him.\nTo honour Fritz, the first paper in this issue by Bettina Grün, Kurt Hornik,\nTorsten Hothorn, Theresa Scharl, and Achim Zeilis, commemorates Fritz’ work and\nlife.\nIn this issue\nNews from CRAN, the R Foundation and Bioconductor are included in this issue.\nThis issue features 10 contributed research articles the majority of\nwhich relate to R packages on a diverse range of topics. All packages are\navailable on CRAN. Supplementary material with fully reproducible code is\navailable for download from the Journal website. Topics covered in this issue\nare the following.\nTime Series, Stochastic Processes\nbootCT: An R Package for Bootstrap Cointegration Tests in ARDL Models\nGenMarkov: Modeling Generalized Multivariate Markov Chains in R\nnortsTest: An R Package for Assessing Normality of Stationary Processes\nSurvival Analyses\nebmstate: An R Package For Disease Progression Analysis Under Empirical Bayes Cox Models\nFitting a Quantile Regression Model for Residual Life with the R Package qris\nStatistical Inference\nPrediction, Bootstrapping and Monte Carlo Analyses Based on Linear Mixed Models with QAPE 2.0 Package\nBayesian Model Selection with Latent Group-Based Effects and Variances with the R Package slgf\nBMRMM: An R Package for Bayesian Markov (Renewal) Mixed Models\nProgramming and applications\ntext2sdg: An R Package to Monitor Sustainable Development Goals from Text\nshinymgr: A Framework for Building, Managing, and Stitching Shiny Modules into Reproducible Workflows\n\n0.1 CRAN packages used\nbootCT, GenMarkov, nortsTest, ebmstate, qris, QAPE, slgf, BMRMM, text2sdg, shinymgr\n0.2 CRAN Task Views implied by cited packages\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2024-1-rfoundation/",
    "title": "R Foundation News",
    "description": "\"R Foundation News\" published in The R Journal.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2024-03-01",
    "categories": [],
    "contents": "\n1 Donations and members\nMembership fees and donations received between\n2024-04-12 and 2024-12-06.\n1.1 Donations\nQualitas AG (Switzerland)\nKeith Chamberlain (United States)\nLawrence Fredendall (United States)\nThomas Hennequin (Netherlands)\nCalvin Hopper (United States)\nEmma Howard (Ireland)\nRoger Koenker (United Kingdom)\nKorea R User Group (Korea, Republic of)\nPlamen Vladkov Mirazchiyski (Slovenia)\nDavid Smith (United States)\nTobias Strapatsas (Germany)\nJason Wyse (Ireland)\n1.2 Supporting benefactors\nZubin Dowlaty (United States)\n1.3 Supporting institutions\nAlfred Mueller Analytic Services, München (Germany)\nDigital Ecology Limited , Berkeley (United Kingdom)\nNIFU Nordic Institute for Studies in Innovation, Research and Education, Oslo (Norway)\nRoseburg Forest Products, Springfield (United States)\nThe University of Auckland, Statistics Department, Auckland (New Zealand)\nUniversity of Iowa, Iowa City (United States)\n1.4 Supporting members\nDouglas Adamoski (Brazil)\nVedo Alagic (Austria)\nTim Appelhans (Germany)\nKristoffer Winther Balling (Denmark)\nAmit Behera (United States)\nAshanka Beligaswatte (Australia)\nNathan Bernhardt (United States)\nChris Billingham (United Kingdom)\nGordon Blunt (United Kingdom)\nRobert Carnell (United States)\nIvan Maria Castellani (Italy)\nWilliam Chiu (United States)\nTom Clarke (United Kingdom)\nGiuseppe Corbelli (Italy)\nRafael Costa (Brazil)\nCharles Cowens (United States)\nTerry Cox (United States)\nAlistair Cullum (United States)\nRobert Daly (Australia)\nGergely Daroczi (Hungary)\nAjit de Silva (United States)\nElliott Deal (United States)\nDubravko Dolic (Germany)\nSerban Dragne (United Kingdom)\nMitch Eppley (United States)\nGuenter Faes (Germany)\nDavid Freedman (United States)\nKeita Fukasawa (Japan)\nAnne Catherine Gieshoff (Switzerland)\nSpencer Graves (United States)\nSusan Gruber (United States)\nChris Hanretty (United Kingdom)\nJames Harris (United States)\nTakehiko Hayashi (Japan)\nKieran Healy (United States)\nken ikeda (Japan)\nKnut Helge Jensen (Norway)\nSebastian Jeworutzki (Germany)\nBrian Johnson (United States)\nMarkus Kainu (Finland)\nChristian Kampichler (Netherlands)\nKatharina Kesy (Germany)\nAn Khuc (United States)\nMiha Kosmac (United Kingdom)\nSebastian Krantz (Germany)\nJan Herman Kuiper (United Kingdom)\nTeemu Daniel Laajala (Finland)\nJindra Lacko (Czechia)\nVishal Lama (United States)\nBernardo Lares (Venezuela)\nRory Lawless (United States)\nThierry Lecerf (Switzerland)\nSeungdoe Lee (Korea, Republic of)\nMauro Lepore (United States)\nAndrea Luciani (Italy)\nDavid Luckett (Australia)\nSharon Machlis (United States)\nMehrad Mahmoudian (Finland)\nMichal Majka (Austria)\nAmanuel Medhanie (United States)\nBogdan-Alexandru Micu (Luxembourg)\nIgor Mikheenko (Russian Federation)\nharvey minnigh (Puerto Rico)\nGuido Möser (Germany)\nMarkus Näpflin (Switzerland)\nMark Niemann-Ross (United States)\nJens Oehlschlägel (Germany)\nDan Orsholits (Switzerland)\nGeorge Ostrouchov (United States)\nJaesung James Park (Korea, Republic of)\nMatt Parker (United States)\njosiah parry (United States)\nElgin Perry (United States)\nBill Pikounis (United States)\nKelly Pisane (Netherlands)\nPaul Rayburn (Canada)\nRamon Rodriguez-Santana (United States)\nDavid Romano (United States)\nPeter Ruckdeschel (Germany)\nRaoul Schorer (Switzerland)\nDominic Schuhmacher (Germany)\nDejan Schuster (Germany)\nChristian Seubert (Austria)\nJagat Sheth (United States)\nSindri Shtepani (Canada)\nDavid Sides (United States)\nRachel Smith-Hunter (United States)\nMurray Sondergard (Canada)\nMatteo Starri (Italy)\nMarco Steenbergen (Switzerland)\nBerthold Stegemann (Germany)\nROBERT Szabo (Sweden)\nJan Tarabek (Czechia)\nTim Taylor (United Kingdom)\nChris Toney (United States)\nNicholas Turner (United States)\nPhilipp Upravitelev (Russian Federation)\nMark van der Loo (Netherlands)\nFrans van Dunné (Costa Rica)\nVincent van Hees (Netherlands)\nMarcus Vollmer (Germany)\nJaap Walhout (Netherlands)\nSandra Ware (Australia)\nLim Zhong Hao (Singapore)\n杨(Yang) 胡(Hu) (New Zealand)\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2023-4-core/",
    "title": "Changes in R",
    "description": "We present selected changes in the development version of R (referred to as R-devel, to become R 4.4) and provide some statistics on bug tracking activities in 2023.",
    "author": [
      {
        "name": "Tomas Kalibera",
        "url": {}
      },
      {
        "name": "Sebastian Meyer",
        "url": {}
      }
    ],
    "date": "2023-12-01",
    "categories": [],
    "contents": "\n1 Selected changes in R-devel\nR 4.4.0 is due to be released around April 2024. The following gives a\nselection of changes in R-devel, which are likely to appear in the new\nrelease.\nThe summaries below include text contributed by authors of some of the\nchanges: Peter Dalgaard, Martyn Plummer, Brian Ripley, Deepayan Sarkar and\nLuke Tierney.\nThe anova() function is used for analysis of variance for linear models\nand analysis of deviance for generalized linear models (GLMs). Previously\nthe anova() function behaved differently for GLMs: it would not show\ntest statistics and p-values by default, instead relying on the user to\nspecify the required test statistic. Thanks to changes to \"family\"\nobjects already included in R 4.3.0, the anova() function can now\ndetermine an appropriate default test for comparing two GLMs (\"LRT\" for\nfamilies with a fixed dispersion parameter and \"F\" for families with free\ndispersion) and will show this along with the associated p-value.\nAs part of the process of allowing the use of Rao’s score test in\nconnection with glm(), the confint() method for \"glm\" objects now\nallows test = \"Rao\", as does the underlying profile() method. To enable\nthis, the code for these functions, and also the corresponding plot()\nand pairs() methods, was copied from the MASS package to the R sources\nbefore modification. The pairs() method has also been revised to better\nhandle the case where only a subset of parameters have been profiled.\nR 4.4.0 will include support for producing single-page HTML reference\nmanuals for an entire package, similar to the PDF reference manuals\ncurrently hosted on CRAN package pages. It will also include support for\na table of contents in HTML help pages, which is controlled by\noptions(\"help.htmltoc\").\nR 4.3.0 added support for experimenting with alternate object systems by\nproviding the chooseOpsMethod() generic for resolving method selection for\nOps group generics, and the nameOfClass() generic to allow more flexible\nclass representations to be used in inherits(). In addition, @ became\nan internal generic, @<- already was. R 4.4.0 will add internal support\nfor bare objects by renaming the S4SXP type to OBJSXP and having\ntypeof() return \"object\" for generic bare objects. For now, generic\nbare S4 objects are distinguished by having a special bit set; it is\nhoped that this can eventually be dropped.\nR relies on the system libiconv for encoding conversions, especially from\nUTF-8. Apple replaced completely its libiconv in macOS 14 with\nsubstantial revisions in 14.1 and 14.2: rather than reporting errors when\nan exact conversion is not possible, it in almost all cases attempts\n‘transliteration’ so for example permille (“‰”) is rendered as “o/oo”.\nmusl (as used by Alpine Linux) has long substituted “*“, but we now faced\nconverted strings growing in length. Issues were particularly seen when\nplotting on pdf() devices and it became clear many package authors had\nnever looked at their graphical output. That suggested that\ntransliteration was a safer route, and now R transliterates if the system\nlibiconv has not got there first and so (except in rare cases and under\nmusl) R will give the same PDF output on all platforms.\nRprof(), the sampling profiler in R, now supports profiling in “elapsed”\ntime (a.k.a. wall-clock time, real-time) on Unix in addition to “cpu” time.\nWhen profiling in elapsed time, the time advances also while R is waiting\non I/O, so it may be preferred for some kinds of analysis in I/O intensive\napplications. Also, elapsed time profiling is the only one currently\nsupported on Windows, so it is good to have a matching option on Unix.\nR gained initial support for 64-bit ARM hardware on Windows (macOS and\nLinux machines are already supported). It is already possible to build R\nand recommended packages from source and they pass their automated checks.\nTesting and porting of other CRAN packages has been started, with a number\nof patches contributed to package maintainers. This effort uses an\nexperimental LLVM-based toolchain with the new flang compiler, which has\nbeen added to Rtools. In addition to actually supporting 64-bit ARM\nWindows machines, which are still rare but emerging, this effort also\ndrives portability improvements of R and R packages. Previously, a lot of\nthis code explicitly or implicitly assumed GCC compilers and Intel CPUs on\nWindows.\nThe R CMD check utility for package development performs some additional\nchecks on R documentation (Rd) files. The most prominent addition (in\nthe sense that over 3000 CRAN packages were affected) is a new note\nabout “lost braces”. In (LaTeX-like) Rd syntax,\nbraces are used to mark arguments and otherwise group tokens; they must\nbe escaped as \\{ and \\} to be included literally in normal text.\nThe new check tries hard to report relevant mistakes, for example:\ncode{...}: missing backslash in front of the macro name\n{1, 2}: in-text set notation, where the braces need escaping or\nthe whole expression needs to be put inside a math \\eqn{}\n\\itemize{ ... \\item{label}{description} ... }: Rd code meant as a\ndescription list with initial labels; this needs \\describe instead\nof \\itemize, otherwise the element becomes “labeldescription” because\nan \\itemize \\item does not take any arguments.\n\nA new binary infix operator %||% is defined in base.\nThis is the so-called null coalescing operator:\nx %||% y expresses “use x if not NULL, otherwise use y”.\nis.atomic(NULL) now returns FALSE and thus behaves according to\nthe R language definition of an atomic vector (RShowDoc(\"R-lang\"),\nSection 2.1.1), which covers the six basic types logical, integer,\ndouble, complex, character and raw.\nFor historical reasons (compatibility with S), is.atomic(NULL) gave\nTRUE in R < 4.4.0, treating NULL loosely as “any vector of size 0”.\nSimilarly, NCOL(NULL) returned 1 but now gives 0.\nThere is a new startup option --max-connections to set the maximum\nnumber of connections for the R session. It defaults to 128 as before.\nValues up to 4096 are allowed, but resource limits may in practice\nrestrict to smaller values. This enables advanced users to configure R\nin environments where a large number of connections (e.g., network) is\nneeded.\nR 4.4.0 on recent Windows will use the new Segment Heap allocator provided\nby the system. This new allocator has slightly better performance on some\napplications than the default Low Fragmentation Heap allocator, with the\nhope that it would be further improved in future versions of Windows.\nR makes use of a system libdeflate library if available, in preference to\nthe system libz library. This can speed up decompressing R objects in\nlazy-loading databases and other operations.\nSee the NEWS.Rd file in the R sources for a more complete list; nightly\nrendered versions are available at\nhttps://CRAN.R-project.org/doc/manuals/r-devel/NEWS.html with RSS feeds at\nhttps://developer.R-project.org/RSSfeeds.html.\n2 Bug statistics for 2023\n\nSummaries of bug-related activities over the past year were derived from the\ndatabase underlying R’s Bugzilla system.\nOverall, 186 new bugs or requests for enhancements were reported,\n204 reports were closed, and 942 comments were added\nby a total of 120 contributors.\nThe numbers of new reports and contributors were comparable to 2022,\nbut comments increased by 8% and closures by 20%.\nHigher activity in 2023 was driven by a dedicated effort\nin reviewing and discussing open reports during the R Project Sprint\nat the University of Warwick, UK, 30 August to 1 September\n(Turner and Becker 2023).\n\n\n\nFigure 1: Bug tracking activity by month in 2023.\n\n\n\nFigure 1 shows the monthly numbers of\nnew reports, closures and comments in 2023.\nComment activity was relatively low in July and peaked in September\ndue to the sprint.\nThe top 5 components reporters have chosen for their reports were\n“Low-level”, “Misc”, “Language”, “Documentation”, and “Accuracy”.\n9% of the reports were suggestions for\nenhancements that were submitted either in the “Wishlist” component or in a\nspecific component but with severity level set to “enhancement”.\n\n\n\n\nH. Turner and G. Becker. R Project Sprint 2023. The R Journal, 15: 299–305, 2023. URL https://journal.R-project.org/news/RJ-2023-3-sprint.\n\n\n\n\n",
    "preview": "news/RJ-2023-4-core/figures/bzstats-mon.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 600,
    "preview_height": 450
  },
  {
    "path": "news/RJ-2023-4-cran/",
    "title": "Changes on CRAN",
    "description": {},
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2023-12-01",
    "categories": [],
    "contents": "\n1 CRAN growth\nIn the past 3 months, 455 new packages were\nadded to the CRAN package repository. 217 packages\nwere unarchived, 362 were archived and\n1 had to be removed. The following shows the\ngrowth of the number of active packages in the CRAN package repository:\n\n\n\nOn 2023-12-31, the number of active packages was around 20249.\n\n2 CRAN package submissions\nFrom October 2023 to December 2023\nCRAN received 7408 package submissions.\nFor these, 12015 actions took place of which\n8598 (72%) were auto processed actions and\n3417 (28%) manual actions.\nMinus some special cases, a summary of the auto-processed and manually\ntriggered actions follows:\n\n\narchive\ninspect\nnewbies\npending\npretest\npublish\nrecheck\nwaiting\nauto\n2489\n749\n1627\n18\n0\n2352\n842\n521\nmanual\n1178\n73\n58\n206\n75\n1380\n379\n68\n\nThese include the final decisions for the submissions which were\n\n\narchive\npublish\nauto\n2394 (32.9%)\n2045 (28.1%)\nmanual\n1162 (16.0%)\n1681 (23.1%)\n\nwhere we only count those as auto processed whose publication or\nrejection happened automatically in all steps.\n3 CRAN mirror security\nCurrently, there are 94 official CRAN mirrors,\n77 of which provide both\nsecure downloads via ‘https’ and use secure mirroring from the CRAN master\n(via rsync through ssh tunnels). Since the R 3.4.0 release, chooseCRANmirror()\noffers these mirrors in preference to the others which are not fully secured (yet).\n4 CRAN Task View Initiative\n\n\n\nCurrently there are 44 task views (see https://CRAN.R-project.org/web/views/),\nwith median and mean numbers of CRAN packages covered\n104 and 123, respectively.\nOverall, these task views cover 4516 CRAN packages,\nwhich is about 22% of all active CRAN packages.\n\n\n\n",
    "preview": "news/RJ-2023-4-cran/RJ-2023-4-cran_files/figure-html5/cran_growth-1.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 1920,
    "preview_height": 1344
  },
  {
    "path": "news/RJ-2023-4-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in The R Journal.",
    "author": [
      {
        "name": "Simon Urbanek",
        "url": "https://journal.r-project.org"
      }
    ],
    "date": "2023-12-01",
    "categories": [],
    "contents": "\nOn behalf of the editorial board, I am pleased to present Volume 15 Issue 4 of the R Journal.\nThis is my last issue as Editor-in-Chief. Mark van der Loo takes over as Editor-in-Chief for 2024, having served as an Executive Editor since 2022 and as Associate Editor since 2021.\nCatherine Hurley recently finished her Editorial board term. She has been leading the expansion to four issues a year as the first Editor-in-Chief to oversee the process, and worked tirelessly to reduce the turn-around times despite an increasing numer of submissions.\nThe articles in this issue have been carefully copy edited by Adam Bartonicek, Chase Robertson and Taylor Lee.\nIn this issue\nNews from CRAN, the R core Development Team, Forwards Taskforce and the R Foundation are included in this issue.\nThis issue features 16 contributed research articles the majority of which relate to R packages\non a diverse range of topics. All packages are available on CRAN. Supplementary material with fully reproducible code is available for download from the Journal website.\nSIMEXBoost: An R package for Analysis of High-Dimensional Error-Prone Data Based on Boosting Method\nbinGroup2: Statistical Tools for Infection Identification via Group Testing\nmultiocc: An R Package for Spatio-Temporal Occupancy Models for Multiple Species\nAccessible Computation of Tight Symbolic Bounds on Causal Effects using an Intuitive Graphical Interface\nsingR: An R Package for Simultaneous Non-Gaussian Component Analysis for Data Integration\nRobustCalibration: Robust Calibration of Computer Models in R\nglmmPen: High Dimensional Penalized Generalized Linear Mixed Models\nUnified ROC Curve Estimator for Diagnosis and Prognosis Studies: The sMSROC Package\nSparse Model Matrices for Multidimensional Hierarchical Aggregation\nopenalexR: An R-Tool for Collecting Bibliometric Data from OpenAlex\nComputer Algebra in R Bridges a Gap Between Symbolic Mathematics and Data in the Teaching of Statistics and Data Science\nA Comparison of R Tools for Nonlinear Least Squares Modeling\nexvatools: Value Added in Exports and Other Input-Output Table Analysis Tools\nPLreg: An R Package for Modeling Bounded Continuous Data\nInference for Network Count Time Series with the R Package PNAR\nSUrvival Control Chart EStimation Software in R: the success Package\n\n0.1 CRAN packages used\nSIMEXBoost, binGroup2, multiocc, singR, RobustCalibration, glmmPen, sMSROC, openalexR, exvatools, PLreg, PNAR, success\n0.2 CRAN Task Views implied by cited packages\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2023-4-forwards/",
    "title": "News from the Forwards Taskforce",
    "description": "[Forwards](https://forwards.github.io/) is an R Foundation taskforce working to widen the participation of under-represented groups in the R project and in related activities, such as the *useR!* conference. This report rounds up activities of the taskforce during 2023.",
    "author": [
      {
        "name": "Heather Turner",
        "url": "https://warwick.ac.uk/heatherturner"
      }
    ],
    "date": "2023-12-01",
    "categories": [],
    "contents": "\n1 Accessibility\nDi Cook, along with Mitchell O’Hara Wild, co-mentored Abhishek Ulayil on a\nGoogle Summer of Code (GSoC) 2023 project converting past R Journal articles to HTML\ncontinuing from work started in GSoC 2022. Further improvements were made to\nthe R packages written for the conversion, enabling HTML versions to be created\nfor all articles in the archive.\nDi Cook, Heather Turner and Jonathan Godfrey are leading an R Consortium funded\nproject to begin adding alt text to the figures in the converted HTML articles,\nto make them fully accessible.\nAt R Project Sprint 2023, Jonathan Godfrey collaborated with participants on a\ncouple of accessibility issues, now incorporated BrailleR. Work with\nDeepayan Sarkar led to improvement in the ability to extract content of graphics devices, see summary.recordedplot(). Work with Gabriel Becker led to a working solution to extract recent console output, see the ShowMe(), SessionLog(),\nand GrabLast() functions.\n2 Community engagement\nKevin O’Brien, Ella Kaye and Heather Turner attended SatRdays London 2023. This\nwas an opportunity to catch up with community organizers, including Tuli Amutenya\nand Emmanuel Olawale Olamijuwon, from Namibia and Eswatini R User Groups\nrespectively, now working in UK. Ella and Heather gave a talk on\nSustainability and EDI in the R Project,\ngiving an overview of their work as part of Heather’s research fellowship on\nthis topic.\nRainbowR, led by Ella Kaye and Hanne Oberman,\nhave increased the frequency of their online meetups and are now meeting\nmonthly. At the end of November, they launched a pilot buddy scheme to foster\nstronger connections between community members, with a plan to pair people up\nwith buddies every three months.\nAlso in November, Kevin O’Brien started a monthly community call for organizers\nof R User Groups - upcoming meetings can be found on the Global R User Group meetup.\n3 Conferences\nJulie Josse is on the program committee for useR! 2024 and Forwards have been\ninvolved in suggesting people for keynotes and the organizing/program committees.\nYanina Bellini Saibene co-chaired LatinR 2023 along with\nNatalia da Silva and Riva Quiroga. This was the first in-person LatinR since\ngoing online in 2020 and the first time R experts from outside Latin America\nattended as keynotes and instructors. The conference was attended by 300 people\nfrom 14 different countries and of the 82% who reported their gender,\n48% identified themselves as women. Thanks to sponsor support, scholarships\nwere awarded to 25 participants. As in previous years, content was presented in\nSpanish, Portuguese, and English. In future, the conference will alternate\nbetween in-person and online format.\n4 R Contribution\nForwards members continue to play an active role in the R Contribution Working\nGroup (RCWG).\nHeather Turner and Ella Kaye, have been regular facilitators of the monthly\noffice hours for R contributors, along with Gabriel Becker. Thanks to the\nR Consortium, these office hours are now advertised on the R Contributors Meetup, along with other RCWG events,\nwhich has help to sustain good attendance.\nSaranjeet Kaur Bhogal continued work on the R Development Guide, with funding\nremaining from the Google Season of Docs (GSoD) 2022. This work improved structure and\ncontent, based on reviews by the steering committee.\nSeveral Forwards members were involved in R Project Sprint 2023 (a full report\nof this event was published in the R Journal Volume 15/3). One important outcome\nof the sprint was a new section in the R Dev Guide on How to contribute new translations using the Weblate interface, which only\nexisted as a prototype when the translation chapter was added as part of the\nGSoD 2022 project.\nHeather Turner, along with James Tripp, mentored Atharva Shirdhankar on a\nGoogle Summer of Code 2023 project creating the R Dev Container a GitHub Codespace providing a\ncontainerised development environment for editing and compiling the R source\ncode. The prototype proved useful at the R Project Sprint and further\ndevelopment is planned to improve on the first version.\nAt LatinR 2023, Pao Corrales gave a lightning talk with María Nanton on contributing translations\nto R and they co-organized a translation space. The Spanish translation coverage\nincreased from 40% to 42% during the event. Heather Turner gave a keynote on\nContributing to R at the\nII Conference of R in Barcelona in November, where the audience were happy to\nhear that a Catalan translation has been started, with initial translations\ndue to be added to R 4.4.0.\n5 Social Media\nZane Daz, Ella Kaye, gwynn gebeyehu and Heather Turner gave the Forwards website\na long overdue update, switching from the previous Hugo/blogdown framework to\nQuarto. This should be easier to maintain and we hope to add some fresh\ncontent in 2024.\n6 Changes in Membership\n6.1 Previous members\nThe following members have stepped down:\nTeaching team: Emily Dodwell, Ritwik Mitra\nCommunity team: Sam Toet\nConferences team: Yanina Bellini Saibene (co-leader), Noa Tamir (co-leader)\nSurveys team: Andrea Sánchez-Tapia (co-leader), Claudia Huaylla\nOn-ramps team: Jyoti Bhogal, Allison Vuong\nWe thank them for their contribution to the taskforce.\n\n6.2 CRAN packages used\nBrailleR\n6.3 CRAN Task Views implied by cited packages\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2023-3-cran/",
    "title": "Changes on CRAN",
    "description": "",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2023-11-26",
    "categories": [],
    "contents": "\n1 CRAN growth\nIn the past 5 months, 866 new packages were\nadded to the CRAN package repository. 332 packages\nwere unarchived, 701 were archived and\n5 had to be removed. The following shows the\ngrowth of the number of active packages in the CRAN package repository:\n\n\n\nOn 2023-09-30, the number of active packages was around 19932.\n2 Changes in the CRAN Repository Policy\nThe Policy now links to an\naccompanying document on Using Rust in CRAN packages.\n\n3 CRAN package submissions\nFrom May 2023 to September 2023\nCRAN received 12237 package submissions.\nFor these, 20527 actions took place of which\n14006 (68%) were auto processed actions and\n6521 (32%) manual actions.\nMinus some special cases, a summary of the auto-processed and manually\ntriggered actions follows:\n\n\narchive\ninspect\nnewbies\npending\npretest\npublish\nrecheck\nwaiting\nauto\n3677\n1889\n2460\n0\n0\n3734\n1282\n964\nmanual\n2378\n186\n431\n317\n52\n2423\n599\n135\n\nThese include the final decisions for the submissions which were\n\n\narchive\npublish\nauto\n3573 (29.7%)\n3246 (27%)\nmanual\n2337 (19.4%)\n2883 (23.9%)\n\nwhere we only count those as auto processed whose publication or\nrejection happened automatically in all steps.\n4 CRAN mirror security\nCurrently, there are 94 official CRAN mirrors,\n76 of which provide both\nsecure downloads via ‘https’ and use secure mirroring from the CRAN master\n(via rsync through ssh tunnels). Since the R 3.4.0 release, chooseCRANmirror()\noffers these mirrors in preference to the others which are not fully secured (yet).\n5 CRAN Task View Initiative\n\nThere is one new task view:\nActuarial Science: Maintained by Christophe Dutang, Vincent Goulet.\n\nCurrently there are 44 task views (see https://CRAN.R-project.org/web/views/),\nwith median and mean numbers of CRAN packages covered\n104 and 122, respectively.\nOverall, these task views cover 4496 CRAN packages,\nwhich is about 22% of all active CRAN packages.\n\n\n\n",
    "preview": "news/RJ-2023-3-cran/RJ-2023-3-cran_files/figure-html5/cran_growth-1.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 1920,
    "preview_height": 1344
  },
  {
    "path": "news/RJ-2023-3-bioc/",
    "title": "News from Bioconductor",
    "description": "\"News from Bioconductor\" published in The R Journal.",
    "author": [
      {
        "name": "Bioconductor Core Developers",
        "url": {}
      }
    ],
    "date": "2023-09-01",
    "categories": [],
    "contents": "\nSoftware\nBioconductor version 3.18 was released on Oct 25 2023. The system is compatible with R 4.3. See the release announcement for full details. Noteworthy additions since our last report to the R Journal include\na BSgenome package for the telomere-to-telomere build of the\nhuman genome (Aganezov et al. (2022)),\nthe SparseArray package for overcoming the limit on the number of non-zero elements allowable in a sparse Matrix instance,\nBiocBook, a package to facilitate the creation of package-based, versioned online books authored in Quarto,\na pair of Annotation packages with the the AlphaMissense (Cheng et al. (2023)) pathogenicity scores\nfor coding variants in the human genome for builds hg19 and\nhg38.\nSee the release announcement for full details.\nThe growth of the package repertory is greatly aided by a group of committed\nand energetic reviewers. All reviews are conducted in github issues streams\nat contributions.bioconductor.org/issues.\nInfrastructure\nNational Science Foundation ACCESS Award BIR190004 provides\nsignificant compute resources in the Jetstream2 academic cloud along with storage provided by the Open Storage Network.\nThese resources form the basis for the\nGalaxy/Kubernetes-backed Bioconductor workshop platform\noriginally known as Orchestra.\nWorkshop submissions are now\naccepted through a Shiny app made available at the platform site.\nThe “BuildABiocWorkshop”\ntemplate has been updated\nwith GitHub Actions, and now uses the GitHub Container Registry (ghcr.io)\nAt present, Bioconductor 3.18 packages are tested regularly on\nUbuntu 22.04, macOS 13.6 (arm64), macOS 12.7 (x86_64), and Windows\nServer 2022 Datacenter. Testing of packages in the devel branch\nincludes an arm64 Linux platform (openEuler 22.03) thanks to efforts\nof Martin Grigorov and Yikun Jiang.\nDocker container updates\nAn active effort to revamp the Bioconductor Docker stack is in progress, maintaining backwards compatibility, but featuring a number of new capabilities. Notably, all containers are now published both on\nDockerHub as well as the\nGitHub Container Registry (GHCR), so any container previously pulled as bioconductor/bioconductor_docker for example, can now also be pulled from GHCR as ghcr.io/bioconductor/bioconductor_docker.\nAdditionally, the traditional rstudio-based containers, previously published under the bioconductor/bioconductor_docker name, are now also available under the bioconductor/bioconductor name, eliminating the need to type the _docker suffix. Moreover, release tags can still be used as “RELEASE_3_18” as before, but the simpler “3.18” tag now suffices. The latest rstudio-based container can thus now be pulled as docker pull bioconductor/bioconductor:3.18 and will be identical to bioconductor/bioconductor_docker:RELEASE_3_18.\nBioconductor now has containers built on top of different flavors of rocker such as bioconductor/r-ver container, a slimmer container with R but not RStudio, and bioconductor/ml-verse, featuring tidyverse and some GPU drivers pre-installed. These and more container flavors can be found at DockerHub and GitHub.\nBioc2u alpha release\nUcar and Eddelbuettel (2021) discuss motivations and methods for distributing precompiled R packages via\nLinux system package managers.\nBioconductor has recently undergone an effort to make a full package repository of Bioconductor packages and their dependencies available via apt on Ubuntu systems. Building on top of previous work from the Debian r-pkg-team and the r2u project, the Bioc2u repository currently offers 3708 packages for the Bioconductor 3.18 release for Ubuntu Jammy. More information can be found at https://github.com/bioconductor/bioc2u, and alpha testers are welcome to join the #bioc2u channel on the Bioconductor Community Slack.\nDeveloper support \nBioconductor is developing containers similar to the Bioconductor Linux build machines. BBS containers are configured like the build machines and aim to provide a comparable experience for developers to troubleshoot issues observed on the linux build machines. The 3.18 BBS container is available for testing with\ndocker pull ghcr.io/bioconductor/bioconductor_salt:jammy-bioc-3.18-r-4.3.2\nFuture work on the BBS containers will focus on testing the container’s performance\nin comparison to the linux build machine, building the devel container, and\nincorporating the container in a GitHub Action Workflow.\nUser support\nThanks to support from the Chan-Zuckerberg Initiative Essential Open Source Software\nfor Science program, the web site at bioconductor.org has been extensively revised.\nPartnering with Outreachy\nBioconductor mentored three interns in the May - August 2023 Outreachy cohort. Outreachy partners with open source and open science organizations to create paid open source internships to individuals underrepresented in technology. The organization, which recently celebrated surpassing 1000 interns, funded the interns for three Bioconductor-mentored projects through their general fund. Interns are selected based on the contributions they make to projects as part of their final application.\nAtrayee Samanta, an undergraduate student at IIEST Shibpur, India, curated microbiome studies for BugSigDB, a comprehensive database of published microbial signatures. Daena Rys, a computer science student from Cameroon, worked on issues within the miaverse, an ecosystem based on (Tree)SummarizedExperiment for microbiome bioinformatics. Sonali Kumari, an IGDTUW student from New Dehli, India, converted Sweave vignettes in Bioconductor packages to R Markdown for Sweave2Rmd. You can read more about their experiences on the Bioconductor blog at Our Journey as Outreachy Interns with Bioconductor.\nOutreachy will also fund three internships with Bioconductor for the December 2023 - March 2024 Outreachy cohort. Chioma Onyido, Ester Afuape, and Peace Sandy of Nigeria will curate microbiome studies for BugSigDB.\n\n\n\nS. Aganezov, S. M. Yan, D. C. Soto, M. Kirsche, S. Zarate, P. Avdeyev, D. J. Taylor, K. Shafin, A. Shumate, C. Xiao, et al. A complete reference genome improves analysis of human genetic variation. Science, 376: 2022. DOI 10.1126/science.abl3533.\n\n\nJ. Cheng, G. Novati, J. Pan, C. Bycroft, A. Žemgulytė, T. Applebaum, A. Pritzel, L. H. Wong, M. Zielinski, T. Sargeant, et al. Accurate proteome-wide missense variant effect prediction with AlphaMissense. Science, 381: 2023. URL https://www.science.org/doi/10.1126/science.adg7492.\n\n\nI. Ucar and D. Eddelbuettel. Binary r packages for linux: Past, present and future. 2021. URL https://arxiv.org/abs/2103.08069.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2023-3-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in The R Journal.",
    "author": [
      {
        "name": "Simon Urbanek",
        "url": "https://journal.r-project.org"
      }
    ],
    "date": "2023-09-01",
    "categories": [],
    "contents": "\nOn behalf of the editorial board, I am pleased to present Volume 15 Issue 3 of the R Journal.\nWe would like to welcome Emi Tanaka to our executive editorial board. Emi has served as an Associate Editor for the last two years and kindly agreed to take the role of an Executive Editor. In addition, we would like to also welcome Ursula Laa, Yanfei Kang and Lucy D’Agostino McGowan to our Associate Editors team.\nThe articles in this issue have been carefully copy edited by Adam Bartonicek and Chase Robertson.\nIn this issue\nNews from CRAN, the R Foundation and Bioconductor are included in this issue as well as a report on the R Project Sprint 2023.\nThis issue features 14 contributed research articles the majority of which relate to R packages\non a diverse range of topics. All packages are available on CRAN. Supplementary material with fully reproducible code is available for download from the Journal website. Topics covered in this issue are\nGraphics and visualization\nColoring in R’s Blind Spot\nUpdates to the R Graphics Engine: One Person’s Chart Junk is Another’s Chart Treasure\nC443: An R Package to See a Forest for the Trees\nGREENeR: An R Package to Estimate and Visualize Nutrients Pressures on Surface Waters\nBayesian inference\nSSNbayes: An R Package for Bayesian Spatio-Temporal Modelling on Stream Networks\nThe R Package rater\nbayesassurance: An R Package for Calculating Sample Size and Bayesian Assurance\nBayesian Inference for Multivariate Spatial Models with INLA\nMultivariate statistics\nfasano.franceschini.test: An Implementation of a Multivariate KS Test in R\nTwoSampleTest.HD: An R Package for the Two-Sample Problem with High-Dimensional Data\nfnets: An R Package for Network Estimation and Forecasting via Factor-Adjusted VAR Modelling\nOther\nVariety and Mainstays of the R Developer Community\nTwo-stage Sampling Design and Sample Selection with the R Package R2BEAT\nmathml: Translate R Expressions to MathML and LaTeX\n\n0.1 CRAN packages used\nC443, GREENeR, SSNbayes, rater, bayesassurance, fasano.franceschini.test, TwoSampleTest.HD, fnets, R2BEAT, mathml\n0.2 CRAN Task Views implied by cited packages\nOfficialStatistics, TimeSeries\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2023-3-rf/",
    "title": "R Foundation News",
    "description": "\"R Foundation News\" published in The R Journal.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2023-09-01",
    "categories": [],
    "contents": "\n1 Donations and members\nMembership fees and donations received between\n2023-05-09 and 2023-10-20.\n2 Donations\nDaniel J. Duarte (Netherlands)\nSpyridon Fortis (United States)\nDmitriy Grishin (United States)\nKen Ikeda (Japan)\nNickalus Redell (United States)\nAxxos AG (Switzerland)\n3 Supporting institutions\nDigital Ecology Limited , Berkeley (United Kingdom)\nNIFU Nordic Institute for Studies in Innovation, Research and Education, Oslo (Norway)\nRIATE (CNRS), Paris (France)\nRoseburg Forest Products, Springfield (United States)\nUniversity of Iowa, Iowa City (United States)\n4 Supporting members\nVedo Alagic (Austria)\nKristoffer Winther Balling (Denmark)\nJoaquín Baquer-Miravete (Spain)\nChris Billingham (United Kingdom)\nSusan M Carlson (United States)\nRobert Carnell (United States)\nWilliam Chiu (United States)\nRafael Costa (Brazil)\nCharles Cowens (United States)\nTerry Cox (United States)\nAlistair Cullum (United States)\nGergely Daroczi (Hungary)\nAjit de Silva (United States)\nDubravko Dolic (Germany)\nSerban Dragne (United Kingdom)\nLaurent Drouet (Italy)\nS Ellison (United Kingdom)\nMitch Eppley (United States)\nStephen Ewing (United States)\nGottfried Fischer (Austria)\nDavid Freedman (United States)\nKeita Fukasawa (Japan)\nChris Hanretty (United Kingdom)\nJames Harris (United States)\nTakehiko Hayashi (Japan)\nMalik Hebbat (Germany)\nAlessamdro Ielpi (Canada)\nBrian Johnson (United States)\nAn Khuc (United States)\nMiha Kosmac (United Kingdom)\nJan Herman Kuiper (United Kingdom)\nJindra Lacko (Czechia)\nBernardo Lares (Venezuela)\nRory Lawless (United States)\nSeungdoe Lee (Korea, Republic of)\nMauro Lepore (United States)\nAmanuel Medhanie (United States)\nHarvey Minnigh (Puerto Rico)\nGuido Möser (Germany)\nMark Niemann-Ross (United States)\nGeorge Ostrouchov (United States)\nJaesung James Park (Korea, Republic of)\nMatt Parker (United States)\nBill Pikounis (United States)\nKelly Pisane (Netherlands)\nChristian Seubert (Austria)\nJagat Sheth (United States)\nSindri Shtepani (Canada)\nDavid Sides (United States)\nMurray Sondergard (Canada)\nOlga Starostecka (Germany)\nMarco Steenbergen (Switzerland)\nBerthold Stegemann (Germany)\nRicardo Torres-Jardón (Mexico)\nNicholas Turner (United States)\nPhilipp Upravitelev (Russian Federation)\nMark van der Loo (Netherlands)\nFrans van Dunné (Costa Rica)\nVincent van Hees (Netherlands)\n\n杨(Yang) 胡(Hu) (New Zealand)\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2023-3-sprint/",
    "title": "R Project Sprint 2023",
    "description": "R Project Sprint 2023 was a three-day event at the University of Warwick, UK,  that brought together novice and experienced contributors to work alongside  members of the R Core Team. 55 members of the R community participated, with  external contributors selected to balance technical expertise and provide  opportunities for members of historically under-represented groups.  Participants worked collaboratively on contributions to base R and on  infrastructure supporting contribution. Several small tasks were completed  within the duration of the sprint, whilst significant steps were made on  larger projects. The event provided a unique opportunity for external  contributors to learn about the R development process and to develop their  contribution skills.",
    "author": [
      {
        "name": "Heather Turner",
        "url": "https://warwick.ac.uk/heatherturner"
      },
      {
        "name": "Gabriel Becker",
        "url": {}
      }
    ],
    "date": "2023-09-01",
    "categories": [],
    "contents": "\n1 Introduction\nR Project Sprint 2023 was a three-day event hosted at the University of Warwick,\nUK. The aim of the event was to bring novice and experienced contributors\ntogether to work collaboratively with members of the R Core Team, who\nmaintain and develop the code and documentation that forms the base\ndistribution of R (“base R”).\n2 Participants\nAll members of the R Core Team were invited to the event and 11 were\nable to participate. Another 13 participants were invited/pre-selected - these\nincluded local organizers, representatives from sponsors, and experienced\ncontributors. The remaining 31 participants - along with a few more who were\nultimately unable to participate - were selected from a pool of 71\nself-nominated applicants. Figure 1 shows group photos taken\non Day 2 and Day 3 of the sprint, a full list of participants is on the sprint website. Participation was in-person by default,\nbut exceptions were made in a few cases where travel was not possible, e.g.,\ndue to visa issues. The number online was higher than anticipated due to\ntravel disruptions; in the end seven people participated online.\n\n\n\nFigure 1: Photos of sprint participants on Day 2 (top) and Day 3 (bottom) including online participants on screen (not all participants photographed).\n\n\n\nMembers of demographic groups underrepresented within the contributor community\nwere encouraged to apply for a place, by promoting the event to affinity groups (R-Ladies, MiR, RainbowR, AfricaR, ArabR, AsiaR, and LatinR) and by direct\ncommunication with potential participants. Figure 2 shows the\ngeographical distribution of all 55 participants. There were 16 from Europe with 8 from the UK; 13 from North America with 12 from the USA;\n7 from Asia with 5 from India; 6 from Latin America with 3 from Argentina; 5 from Africa with 2 from Nigeria; 4 from Oceania - all from New Zealand, and 3 from the Middle East.\n\n\n\nFigure 2: Choropleth showing the distribution of participants on the world map.\n\n\n\nWe have further information from the nomination form, which was completed by 40 of the 44 invited/selected contributors. Over half (25/40) self-identified as belonging to one or more underrepresented groups. Figure 3 summarises the skills of these contributors as assessed by the selection committee, using data from the nomination forms. A “contributor level” was assigned based on self-ratings of familiarity with relevant concepts and processes, along with answers to free text questions about the applicant’s experience and motivation.\nThe committee deliberately selected participants to achieve the balance shown in\nthe first plot of Figure 3: an equal number of advanced and\nnovice contributors, with the remainder having intermediate expertise. The second\nplot summarises the potential for contribution to translations: 14 of\nthe selected contributors expressed a specific interest in translation; 8 more\nwere surmised to have potential based on country of residence. For the\nremainder (22) there was no evidence as we did not ask about this explicitly in the form.\n\n\n\nFigure 3: Skills of external contributors as judged by the selection committee. Left: level of expertise in R contribution. Right: potential as a translator of English to other languages.\n\n\n\n3 Preparation\nThere were two sides to preparation for the sprint: gathering suitable tasks to\nwork on and helping participants brush up their knowledge and skills.\nWe collected ideas for suitable tasks via the discussion forum on the R Project Sprint 2023 GitHub\nrepository (GitHub Discussions).\nThis provided a space for participating members of R Core to give\nfeedback and for participating contributors to express an interest. Sprint\nparticipants could propose a project by adding a page to the Projects\nsection of the sprint website. In the run up to the sprint, ideas and projects\nwere transferred to issues on the sprint GitHub repository\nalong with further last-minute ideas from core developers and members of the R Contribution Working Group (RCWG). This enabled participants to assign themselves to\nissues and provided a way to track tasks during the sprint.\nIn the lead-up to the sprint, participants were\npointed to resources created by the R Core Team and the RCWG,\nincluding the R Blog post on reviewing bugs and\nthe useR! 2021 tutorials on analysing bugs/contributing patches and\ntranslating messages in R. In addition, participants were encouraged to engage with relevant events,\nin particular the Debugging in R tutorial run\nby Shannon Pileggi for R-Ladies Remote, and the C Book Club for R Contributors and\nR Contributor Office Hours\nrun by the RCWG.\nBy the time of the sprint, participants were expected to be able to build R\nfrom source on the laptop they brought along. People new to this were\npointed to the R-admin manual,\nthe R Dev Guide and the\nprototype GitHub Codespace which\nprovides a virtual environment in which to build R - this was demonstrated in\none of the contributor office hours.\n4 Format\nThe sprint began with a hybrid evening welcome event where Martyn Plummer gave some opening remarks on contributing to the R Project, then participants split into small groups to chat with a member of R Core. An informal drinks reception then followed for in-person participants.\nEach sprint day started with a kick-off session and ended with a report-back session, both hybrid to include our online participants. On the first day, R Core members gave short talks in these sessions, introducing themselves and their work for the R Project, and laying out their broad interests for work during the sprint. Beyond these introductions, participants used the daily kick-off sessions to collectively match people to tasks.\nThe remaining day time was spent working in small groups, sometimes arranging\nhybrid meetings to discuss specific issues.\nOn the second evening, in-person participants enjoyed a conference dinner, whilst on the final evening the sprint participants joined the Warwick R User Group for a hybrid meetup to present progress made thus far at the sprint, this was followed by a buffet dinner for in-person participants.\n5 Translation\nTranslating English messages into other languages to enhance\nlocalization of R was a core activity at the sprint.\nIn 2022, Gergely Daróczi set up a prototype Weblate instance https://translate.rx.studio to provide a modern, user-friendly interface for contributing translations to the R Project. Under the RCWG, he has developed and maintained this service, working with Michael Lawrence of R Core to incorporate translations submitted via Weblate into the R sources. Sprint participants created a new\nset of guidelines for translators and\na new section in the R Dev Guide on How to contribute new translations. Several new features were enabled on the Weblate instance,\nincluding translation memory, hyperlinking to the source string location and\ndedicated reviewers to approve translations. New components were added, so that\nthe instance not only covers base R (messages, warnings, errors and the\nWindows GUI), but also the Mac GUI and recommended packages.\nFigure 4 gives a summary of activity on Weblate during\nthe sprint: around 2000 messages were changed over 14 languages. The\nvast majority of this activity can be attributed to the sprint\ndirectly or indirectly - the Hungarian translations were imported from earlier\nwork in 2011 and the Turkish translations were made by external contributors\nafter the Mac GUI component was added.\n\n\n\nFigure 4: Changes in the R Project components on Weblate during the three days of the sprint\n\n\n\n6 Code and Documentation\nThe remaining activity at the sprint related to code and documentation in base R.\nCode issues were split into topics to help organize work groups:\naccessibility, graphics, packages, statistics, translation and low-level. The\ntranslation issues here related to infrastructure maintained by the R Core Team, as opposed to Weblate. The low-level topic was a catch-all that covered utility\nfunctions and/or issues that required advanced technical expertise, e.g., in C.\nFigure 5 shows the progress of issues at the end of the sprint\nand two months after. An issue is considered closed if a corresponding bug report on R’s Bugzilla (https://bugs.r-project.org) was closed, if a corresponding patch was committed to base R, or if the issue was closed by an update to a CRAN package. By the end of the sprint, ten issues had been closed. Seven of these were documentation bugs, including one that was closed just before the sprint due to a participant reviewing issues in preparation. However, progress had been made on thirty-four other issues, ranging from discussing the issue, through defining a roadmap, to work in progress or proposing a patch. Two months after the sprint, another twelve issues had been closed and six more had progressed status (e.g., from roadmap to work in progress). These eighteen issues included three that were not started at the sprint, but worked on soon after as follow-up to a partial fix or due to participants reviewing the progress of sprint issues.\n\n\n\nFigure 5: Status of issues at the end of the sprint and two months after\n\n\n\nThe low-level issues included new functionality, e.g., supporting custom parallel backends; refactoring, e.g.,\nimproving the speed of scalar random number generation; improving behaviour, e.g., better formating of complex numbers, and bug fixes, e.g. managing long names when creating tarballs.\nParticipants working on documentation began by triaging all open documentation bugs on Bugzilla to identify ones that could be closed without fixing, or ones that appeared straight-forward to fix, hence the high closure rate for these issues. Some closed bugs had been open for several years.\nPackage-related issues included adding support for defining vignette order, improving messages to CRAN maintainers, and caching installed packages.\nTranslation-related issues included identifying untranslated strings in the\nR source files, and creating\na roadmap towards internationalization of help pages. The R Consortium are funding a project by participants Elio Campitelli and Renata Hirota for the first step on this roadmap.\nStatistics issues included improving the behaviour of t.test.formula() and wilcox.test.formula() for paired tests and enhancing\nsample.int() for unequal probability sampling, for which a prototype package was developed after the sprint for testing.\nAccessibility focused on two issues faced by screenreader users: logging base\ngraphics and logging R sessions. Functions resulting from this work are now\nimplemented in BrailleR.\nFinally there were two issues related to graphics, one fixed during the sprint\nimplementing 3-digit hex colors and one\nlarger project on adding alpha masks to the Quartz graphics device.\nThere were more issues prepared for the sprint than are summarised here, but\nthey were not taken up at the sprint. In some cases there was insufficient support from R Core to pursue the idea, or it was considered out of scope for the sprint, or there were no available participants with relevant skills and/or bandwidth to take the idea forward. Often participants were interested in multiple issues and were encouraged to favour issues/topics where larger group discussions were taking\nplace, to take advantage of everyone being together.\n7 Participant experience\nAs well as aiming to make progress on contributions to the R Project, the\nsprint was intended to develop participants’ knowledge and experience in\ncontribution and motivate them to continue contributing after the sprint.\nWe further looked to improve visibility and networking between\nthe R Core Team and the R community (as represented by sprint\nparticipants).\nFigure 6 summarises the activities engaged in at the sprint, for 32 out of 44 external contributors that responded to a post-sprint survey.\nAround two-thirds were involved in working on code issues and around a third worked on documentation and/or translation. Scoping work was also an important activity, in which a third of contributors engaged.\n\n\n\nFigure 6: Activities of external contributors, based on 32 responses to the participant survey.\n\n\n\nFigure 7 summarises the activities that contributors engaged in for the first time either during the sprint, or to prepare for or follow up on work done at the sprint. For around two-thirds of contributors it was the first time they had discussed a bug or issue with an R Core member, whether online or in person. About a third commented on Bugzilla for the first time and around a quarter posted their first patch. Around half the contributors built R from source for the first time, either on their own laptop or in the GitHub Codespace (or both) and for about half the contributors it was their first time working on R, C, or Rd (R documentation) files in base R.\n\n\n\nFigure 7: R core interactions and R contribution activities that external contributors engaged in for the first time, based on 32 responses to participant survey.\n\n\n\n8 Organizers and sponsors\nThe organization of the sprint was led by Heather Turner, as part of a\nresearch fellowship funded by the UK Engineering and Physical Sciences Research Council. This fellowship provided core funding and was supplemented by additional sponsorship:\nPlatinum Sponsor (R Core travel): the R Foundation.\nGold sponsors (evening events, participant travel): the R Consortium; the Centre for Research in Statistical Methodology, University of Warwick, and Posit.\nSilver Sponsors (participant travel): Seminar for Statistics, ETH Zurich; Rx Studio; The Prostate Cancer Clinical Trials Consortium, and Google.\n\nThis sponsorship funded travel, accommodation and subsistence for all participants.\nMartyn Plummer and Ella Kaye completed the local organizer team. The selection committee was made up of Heather, Ella, and Gabe Becker of the RCWG.\nMembers of the RCWG helped with the planning, especially Gabe Becker who also helped gather issues in the run up to the sprint.\n9 Summary\nR Project Sprint 2023 was a very collaborative event, where external contributors had a unique opportunity to work closely with R Core members. Good progress was made across a broad range of issues with continued impact after the sprint. The feedback from both R Core and external participants was very positive, e.g.,\n\nThank you for organizing an incredible sprint and creating space for newcomers\n\n\nThere were many different parts that contributed so well to\nmake it very productive, envigourating, and motivating\n\n\nFrom arrival to departure, everything was seamless and I had a great time discovering what it takes to maintain R.\n\n\nI’m exhausted but also super excited by all the work we did and that I take as homework.\n\nSeveral participants - as well as R community members that could not attend this time - asked when we would hold a repeat event. Finding funding for ~50 people from around the world to attend a 3-day sprint is quite a challenge. So in the short term we plan to run 1-day events in collaboration with in-person conferences. Whilst this will limit the scope of tasks that can be tackled, we can benefit from people already travelling for the conference, with conference scholarship schemes helping to support inclusion.\n10 Links\nSprint website: https://contributor.r-project.org/r-project-sprint-2023/\nGitHub repository: https://github.com/r-devel/r-project-sprint-2023\n\n10.1 CRAN packages used\nBrailleR\n10.2 CRAN Task Views implied by cited packages\n\n\n",
    "preview": "https://null#distill-is-buggy-and-will-break-without-this",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2023-4-rf/",
    "title": "R Foundation News",
    "description": "\"R Foundation News\" published in The R Journal.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2023-09-01",
    "categories": [],
    "contents": "\n1 Donations and members\nMembership fees and donations received between\n2023-10-20 and 2024-04-12.\n2 Donations\nb-data GmbH (Switzerland)\nSAS EUREKA MER (France)\nGilberto Camara (Brazil)\nKeith Chamberlain (United States)\nGiles Dickenson-Jones (Australia)\nShalese Fitzgerald (United States)\nRoger Koenker (United Kingdom)\nFlavio Lombardo (Switzerland)\nRudolph Martin (United States)\nRees Morrison (United States)\nQuintessa Ltd (United Kingdom)\nKem Phillips (United States)\nAlexandra Pippitt (United States)\nBruno Rodrigues (Luxembourg)\nDavid Smith (United States)\nRav Vaid (United States)\nAlejandro Verri Kozlowski (Argentina)\nYihui Xie (China)\nilustat, Lisbon (Portugal)\nStatistik Aargau, Aarau (Switzerland)\n3 Supporting institutions\nDepartement Klinische Forschung, Basel (Switzerland)\nEf-prime, Inc., Tokyo (Japan)\nInstitute of Botany of the Czech Academy of Sciences, Průhonice (Czechia)\noikostat GmbH, Ettiswil (Switzerland)\n4 Supporting members\nRichard Abdill (United States)\nDouglas Adamoski (Brazil)\nMohammed Almozini (Saudi Arabia)\nTim Appelhans (Germany)\nTim Arbogast (United States)\nMichael Blanks (United States)\nEmmanuel Blondel (France)\nGordon Blunt (United Kingdom)\nRiccardo Bonfichi (Italy)\nTom Boulay (United States)\nTamara Bozovic (New Zealand)\nKeith Chamberlain (United States)\nCédric Chambru (Switzerland)\nJohn Chandler (United States)\nMichael Chirico (United States)\nTom Clarke (United Kingdom)\nGerard Conaghan (United Kingdom)\nRobin Crockett (United Kingdom)\nAlistair Cullum (United States)\nBrandon Dahl (United States)\nRobert Daly (Australia)\nKevin DeMaio (United States)\nAnna Doizy (Réunion)\nFraser Edwards (United Kingdom)\nAnthony Alan Egerton (Malaysia)\nIsaac Florence (United Kingdom)\nNeil Frazer (United States)\nDavid Freedman (United States)\nBernd Fröhlich (Germany)\nSven Garbade (Germany)\nJan Marvin Garbuszus (Germany)\nEduardo García Galea (Spain)\nGabriel Gersztein (Brazil)\nSUJOY GHOSH (United States)\nAnne Catherine Gieshoff (Switzerland)\nPavel Goriacko (United States)\nBrian Gramberg (Netherlands)\nSpencer Graves (United States)\nKrushi Gurudu (United States)\nFrank Hafner (United States)\nHlynur Hallgrímsson (Iceland)\nJoe Harwood (United Kingdom)\nBela Hausmann (Austria)\nKieran Healy (United States)\nPhilippe Heymans Smith (Costa Rica)\nAdam Hill (United States)\nAlexander Huelle (Germany)\nHeidi Imker (United States)\nSebastian Jeworutzki (Germany)\nJUNE KEE KIM (Korea, Republic of)\nZiyad Knio (United States)\nSebastian Koehler (Germany)\nChris Kuty (United States)\nLuca La Rocca (Italy)\nVishal Lama (United States)\nThierry Lecerf (Switzerland)\nThomas Levine (United States)\nEric Lim (United Kingdom)\nBaoxiao Liu (Netherlands)\nJoseph Luchman (United States)\nMehrad Mahmoudian (Finland)\nGilles Marodon (France)\nDaniel McNichol (United States)\nPhilippe MICHEL (France)\nBogdan-Alexandru Micu (Luxembourg)\nErnst Molitor (Germany)\nDavid Monterde (Spain)\nStefan Moog (Germany)\nKeon-Woong Moon (Korea, Republic of)\nSteffen Moritz (Germany)\nyoshinobu nakahashi (Japan)\nTsubasa Narihiro (Japan)\nMaciej Nasinski (Poland)\nDan Orsholits (Switzerland)\nAntonio Paez (Canada)\nSermet Pekin (Turkey)\nElgin Perry (United States)\nPierGianLuca Porta Mana (Norway)\nFergus Reig Gracia (Spain)\nPeter Ruckdeschel (Germany)\nIngo Ruczinski (United States)\nChoonghyun Ryu (Korea, Republic of)\nJohn Schmitt (United States)\nRaoul Schorer (Switzerland)\nDejan Schuster (Germany)\nIvan Scotti (France)\nDavid Sides (United States)\nRachel Smith-Hunter (United States)\nMatteo Starri (Italy)\nHarald Sterly (Germany)\nTobias Strapatsas (Germany)\nKai Streicher (Switzerland)\nROBERT Szabo (Sweden)\nJan Tarabek (Czechia)\nKoray Tascilar (Germany)\nChris Toney (United States)\nRobert van den Berg (Austria)\nMarcus Vollmer (Germany)\nPetr Waldauf (Czechia)\nJaap Walhout (Netherlands)\nSandra Ware (Australia)\nFredrik Wartenberg (Sweden)\nSam Waters (United States)\nDieter Wilhelm (Germany)\nNan Xiao (United States)\nMatti Zemack (Sweden)\nVaidotas Zemlys-Balevičius (Lithuania)\nLim Zhong Hao (Singapore)\n\n广宇 曾 (China)\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2023-2-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in The R Journal.",
    "author": [
      {
        "name": "Simon Urbanek",
        "url": "https://journal.r-project.org"
      }
    ],
    "date": "2023-06-01",
    "categories": [],
    "contents": "\nOn behalf of the editorial board, I am pleased to present Volume 15 Issue 2 of the R Journal.\nBehind the scenes, several people assist with the journal operations. Mitchell O’Hara-Wild continues to work on infrastructure, H. Sherry Zhang continues to develop the rjtools package under the direction of Professor Dianne Cook. In addition, articles in this issue have been carefully copy edited by Adam Bartonicek and Chase Robertson.\nIn this issue\nThis issue features 18 contributed research articles the\nmajority of which relate to R packages on a diverse range of\ntopics. All packages are available on CRAN. Supplementary material\nwith fully reproducible code is available for download from the\nJournal website. Topics covered in this issue are\nGraphics and Visualisation\nlangevitour: smooth interactive touring of high dimensions, demonstrated with scRNA-Seq data\nggdensity: Improved Bivariate Density Visualization in R\nTaking the Scenic Route: Interactive and Performant Tour Animations\nvivid: An R package for Variable Importance and Variable Interactions Displays for Machine Learning Models\nMultivariate Statistics\nGeneralized Estimating Equations using the package glmtoolbox\ngenpathmox: An R Package to Tackle Numerous Categorical Variables and Heterogeneity in Partial Least Squares Structural Equation Modeling\nBayesian Inference\nbqror: An R package for Bayesian Quantile Regression in Ordinal Models\nA framework for estimating and visualising excess mortality during the COVID-19 pandemic\nSocial Sciences\nPINstimation: An R Package for Estimating Models of Probability of Informed Trading\nmutualinf: An R Package for Computing and Decomposing the Mutual Information Index of Segregation\nThree-way Correspondence Analysis in R\nDifficult Choices? Estimating Heteroskedastic and Instrumental Variable Models for Binary Dependent Variables in R\nMixture Models and Optimization\nnlstac: Non-gradient Separable Nonlinear Least Squares Fitting\nUnivariate Gaussian mixtures in R\nClustering and Graphs\nIdentifying Counterfactual Queries with the R package cfid\nclustAnalytics: An R Package for Assessing Stability and Significance of Clusters in Networks\nOther\nhydrotoolbox: a Package for Hydrometeorological Data Management\nEviewsR: an R Package for Dynamic and Reproducible Research Using EViews, R, R Markdown and Quarto\n\n0.1 CRAN packages used\nrjtools\n0.2 CRAN Task Views implied by cited packages\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2023-1-cran/",
    "title": "Changes on CRAN",
    "description": {},
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2023-03-01",
    "categories": [],
    "contents": "\nIn the past 3 months, 516 new packages were\nadded to the CRAN package repository. 206\npackages were unarchived, 416 were archived and\n4 had to be removed. The following shows the\ngrowth of the number of active packages in the CRAN package repository:\n\n\n\nOn 2023-04-30, the number of active packages was around 19439.\n\n0.1 CRAN package submissions\nFrom February 2023 to April 2023\nCRAN received 7905 package submissions.\nFor these, 13597 actions took place of which\n9071 (67%) were auto processed actions and\n4526 (33%) manual actions.\nMinus some special cases, a summary of the auto-processed and manually\ntriggered actions follows:\n\n\narchive\ninspect\nnewbies\npending\npretest\npublish\nrecheck\nwaiting\nauto\n2276\n1725\n1370\n0\n0\n2300\n787\n613\nmanual\n1809\n94\n361\n175\n73\n1497\n406\n111\n\nThese include the final decisions for the submissions which were\n\n\narchive\npublish\nauto\n2126 (27.6%)\n1977 (25.7%)\nmanual\n1788 (23.2%)\n1808 (23.5%)\n\nwhere we only count those as auto processed whose publication or\nrejection happened automatically in all steps.\n0.2 CRAN mirror security\nCurrently, there are 100 official CRAN mirrors,\n80 of which provide both\nsecure downloads via ‘https’ and use secure mirroring from the CRAN master\n(via rsync through ssh tunnels). Since the R 3.4.0 release, chooseCRANmirror()\noffers these mirrors in preference to the others which are not fully secured (yet).\n0.3 CRAN Task View Initiative\n\nThere is one new task view:\nGenomics, Proteomics, Metabolomics, Transcriptomics, and Other Omics: Maintained by Julie Aubert, Toby Dylan Hocking, Nathalie Vialaneix.\n\nCurrently there are 43 task views (see https://cran.r-project.org/web/views/),\nwith median and mean numbers of CRAN packages covered\n106 and 120, respectively.\nOverall, these task views cover 4344 CRAN packages,\nwhich is about 22% of all active CRAN packages.\n\n\n\n",
    "preview": "news/RJ-2023-1-cran/RJ-2023-1-cran_files/figure-html5/cran_growth-1.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 1920,
    "preview_height": 1344
  },
  {
    "path": "news/RJ-2023-1-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in The R Journal.",
    "author": [
      {
        "name": "Simon Urbanek",
        "url": "https://journal.r-project.org"
      }
    ],
    "date": "2023-03-01",
    "categories": [],
    "contents": "\nOn behalf of the editorial board, I am pleased to present Volume 15 Issue 1 of the R Journal.\nCatherine Hurley has stepped down as Editor-in-Chief, but continues to serve on the editorial board as an Executive Editor.\nCatherine has overseen the expansion of the journal as EIC to accommodate four issues a year as a response to the growing number of publications.\nDue to her relentless work she was able to maintain stability in challenging times when personal and external circumstances have affected availabilty of our editorial teams. We would like to welcome Vincent Arel-Bundock to our team of Associate Editors.\nBehind the scenes, several people assist with the journal operations. Mitchell O’Hara-Wild continues to work on infrastructure, H. Sherry Zhang continues to develop the rjtools package under the direction of Professor Dianne Cook. In addition, articles in this issue have been carefully copy edited by Adam Bartonicek and Chase Robertson.\n0.1 In this issue\nNews from CRAN and the R Foundation and RForwards are included in this issue.\nThis issue features 19 contributed research articles the majority of which relate to R packages\non a diverse range of topics. All packages are available on CRAN. Supplementary material with fully reproducible code is available for download from the Journal website. Topics covered in this issue are\nSpatial analysis\nA Clustering Algorithm to Organize Satellite Hotspot Data for the Purpose of Tracking Bushfires Remotely\nasteRisk - Integration and Analysis of Satellite Positional Data in R\nNon-parametric analysis of spatial and spatio-temporal point patterns\nThe segmetric Package: Metrics for Assessing Segmentation Accuracy for Geospatial Data\nGraphics and visualisation\nA Hexagon A Hexagon Tile Map Algorithm for Displaying Spatial Data\nnlmeVPC: Visual Model Diagnosis For The Nonlinear Mixed Effect Model\nBayesian inference\nGCPBayes: An R package for studying Cross-Phenotype Genetic Associations with Group-level Bayesian Meta-Analysis\nEstimating Causal Effect using the Bayesian Method with the R Package BayesCACE\nRobust statistical methods\nResampling Fuzzy Numbers with Statistical Applications: FuzzyResampling Package\nonlineforecast: An R Package for Adaptive and Recursive Forecasting\nRobust functional linear regression models\nA Framework for Producing Small Area Estimates Based on Area-Level Models in R\nGPLSIM: An R Package for Penalized Spline Estimation for Generalized Partially Linear Single-index Models\nDesign and analysis of experiments\nrankFD: An R Software Package for Nonparametric Analysis of General Factorial Designs\ncombinIT: An R Package for Combining Interaction Tests for Testing Interaction in Unreplicated Two-Way Tables\nModel deployment\nLikelihood Ratio Test-Based Drug Safety Assessment Using R Package pvLRT\nmarkovMSM: An R package for checking the Markov Condition in Multi-state Survival Data\nFairness Audits And Debiasing Using mlr3fairness\nClusROC: An R package for ROC analysis in three-class classification problems for clustered data\n\n0.2 CRAN packages used\nrjtools\n0.3 CRAN Task Views implied by cited packages\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2023-1-rfoundation/",
    "title": "R Foundation News",
    "description": "\"R Foundation News\" published in The R Journal.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2023-03-01",
    "categories": [],
    "contents": "\n1 Donations and members\nMembership fees and donations received between\n2023-02-20 and 2023-05-09.\n1.1 Donations\nGilberto Camara (Brazil)\nKorea R User Group (Korea, Republic of)\nNickalus Redell (United States)\nScrub the web (Poland)\nRav Vaid (United States)\n1.2 Supporting institutions\nAlfred Mueller Analytic Services, München (Germany)\nDepartment of Clinical Research, University of Basel, Switzerland, Basel (Switzerland)\nEf-prime, Inc., Tokyo (Japan)\n1.3 Supporting members\nAshanka Beligaswatte (Australia)\nFrederic Bertrand (France)\nAlistair Cullum (United States)\nGuenter Faes (Germany)\nBernd Fröhlich (Germany)\nDejan Gregor (United Kingdom)\nHeidi Imker (United States)\nKnut Helge Jensen (Norway)\nChristian Kampichler (Netherlands)\nKatharina Kesy (Germany)\nZiyad Knio (United States)\nSebastian Koehler (Germany)\nSebastian Krantz (Germany)\nChris Kuty (United States)\nLuca La Rocca (Italy)\nTeemu Daniel Laajala (Finland)\nThierry Lecerf (Switzerland)\nEric Lim (United Kingdom)\nMichal Majka (Austria)\nMyriam Maumy (France)\nErnst Molitor (Germany)\nDavid Monterde (Spain)\nStefan Moog (Germany)\nSteffen Moritz (Germany)\nMaciej Nasinski (Poland)\nJens Oehlschlägel (Germany)\nHarald Sterly (Germany)\nRobert van den Berg (Austria)\nThomas van der Vaart (Netherlands)\nFredrik Wartenberg (Sweden)\nJason Wyse (Ireland)\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2022-4-bioconductor/",
    "title": "Bioconductor Notes",
    "description": "\"Bioconductor Notes\" published in The R Journal.",
    "author": [
      {
        "name": "Maria Doyle",
        "url": {}
      },
      {
        "name": "Bioconductor Core Developer Team",
        "url": {}
      }
    ],
    "date": "2022-12-01",
    "categories": [],
    "contents": "\nIntroduction\nBioconductor provides\ntools for the analysis and comprehension of high-throughput genomic\ndata. The project has entered its twentieth year, with funding\nfor core development and infrastructure maintenance secured\nthrough 2025 (NIH NHGRI 2U24HG004059). Additional support is provided\nby NIH NCI, Chan-Zuckerberg Initiative, National Science Foundation,\nMicrosoft, and Amazon. In this news report, we give some updates on\ncore team and project activities.\nSoftware\nThe current Bioconductor release is 3.16. It is\ncompatible with R 4.2 and consists of 2183 software packages, 416\nexperiment data packages, 909 up-to-date annotation packages, 28\nworkflows, and 3 books. are\nbuilt regularly from source and therefore fully\nreproducible; an example is the\ncommunity-developed Orchestrating Single-Cell Analysis with Bioconductor.\nBioconductor in Python!\nWe’re excited to introduce BiocPy, a project aimed at enabling Bioconductor workflows in Python. Analysts today use a variety of languages in their workflows, including R/Bioconductor for statistical analysis and Python for imaging or machine learning tasks. BiocPy aims to facilitate interoperability between R and Python by providing standardized data structures based on existing Bioconductor data structures. These include genomic ranges for interval based operations, summarized experiments and other derivatives for analyzing genomic experiments. To learn more, visit the BiocPy GitHub organization.\nCore team updates\nDefault Branch Renaming\nThe default branch (that corresponds to Bioconductor devel version) will be renamed to devel on git.bioconductor.org for all packages to move forward with diversity and inclusiveness. The core has been doing extensive testing and is ready to move forward within the next 2-3 weeks.\nMaintainers will temporarily still be able to push to either devel or master to allow time for adaptation, with the goal of eventually making it an error in maybe 2-3 release cycles (1-1.5 years)\nWe will be making announcements on bioc-devel mailing list, Twitter, Mastodon, Slack, etc with an upcoming/heads up and an announcement when it is live.\nPartnering with Outreachy\nBioconductor participated as a mentoring community in Outreachy’s December 2022\n- March 2023 internship round. Outreachy provides\nopen source and open science internships to individuals impacted by systemic\nbias and underrepresentation in tech. Bioconductor received funding for two\ninterns through Outreachy’s general fund for two projects. Kirabo Atuhurira,\na software engineering student from Kampala, Uganda, was chosen to work on the\nBSgenomeForge, which attempts\nto simplify making Bsgenome data packages. Beryl Kanali, a masters student\nfrom Nairobi, Kenya, was chosen to work on\nSweave2Rmd, which attempts to\nmodernize Sweave vignettes by converting them into R Markdown. You can read more\nabout their experience at Our experience as Outreachy interns with\nBioconductor.\nBioconductor will also participate in Outreachy’s May 2023 - August 2023\ninternship round to offer internships with Bioconductor community projects.\nConferences\nThe BioC2023 and EuroBioC2023 conferences have both been announced, and abstract submissions are open. BioC Asia 2023 will be announced later this year.\nBioC2023 will be held in Boston, USA from Aug 2-4. Abstracts can be submitted until March 19.\nEuroBioC2023 will be held in Ghent, Belgium from Sep 20-22. Abstracts can be submitted until April 14.\nBlog\nThe Bioconductor blog is used for articles of interest by and for the community. Recent articles include:\nBioconductor Carpentries instructors Year 1\nAn update on the Bioconductor Carpentries global training program - applicants selected for Year 1\nIntroducing CuratedAtlasQueryR package\nCuratedAtlasQueryR is a new package that enables easy programmatic exploration of CELLxGENE single-cell human cell atlas data.\nOur experience as Outreachy interns with Bioconductor\nBioconductor participated in the Outreachy Internship program for the December 2022 cohort. Our interns share their experience working on their various projects and Bioconductor in general.\nBioconductor Hacktoberfest 2022 review and looking ahead to 2023\nLast October, Bioconductor joined Hacktoberfest and got great community contributions there. Here, we describe its success and notify the community we plan to participate in 2023.\nBoards updates\nCommunity Advisory Board\nThe Community Advisory Board (CAB) are voting in new members. Outgoing members are Susan Holmes, Leonardo Collado-Torres, Yagoub A. I. Adam, Matt Ritchie, Benilton Carvalho, we gratefully thank them for their service.\nThere is a Call for Bioconductor Community-Led events supported by the CAB.\nApply in this form\nCommittees and Working groups updates\nIf you are interested in becoming involved with one of these groups please contact the group leader(s).\nCloud Methods\nheld their first meeting Feb 2023. The working group will meet monthly to\ndevelop standards and tools for the Bioconductor community related to the\ncloud.\nSocial media working group.\nA new group, started in Feb 2023, have set up\nBioconductor Mastodon acccount.\nTeaching Committee\nAre planning a hackathon for the\nBioconductor Carpentries RNA-seq lesson.\nWill be participating in\nGalaxy Training Smorgasbord 2023,\na free online global event, May 22-26.\n\nWebsite working group\nare planning the redesign of bioconductor.org.\nOther\nSummer school “Statistical Data Analysis for Genome-Scale Biology” CSAMA 2023 in Bressanone-Brixen, Italy, June 11-16 2023. Application deadline March 15.\nCourse “Statistical Analysis of Genome Scale Data” at CSHL in New York, USA, June 30 - July 13 2023. Application deadline March 15.\nWorkshop “Opportunities for Bioconductor and ELIXIR communities to co-develop training infrastructure” accepted for the ELIXIR All Hands meeting in Dublin, Ireland, June 5-8 2023.\nWorkshop “Orchestrating Large-Scale Single-Cell Analysis with Bioconductor” accepted for ISMB/ECCB 2023 in Lyon, France, July 23 2023.\nUsing Bioconductor\nStart using\nBioconductor by installing the most recent version of R and evaluating\nthe commands\n  if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n      install.packages(\"BiocManager\")\n  BiocManager::install()\nInstall additional packages and dependencies,\ne.g., SingleCellExperiment, with\n  BiocManager::install(\"SingleCellExperiment\")\nDocker\nimages provides a very effective on-ramp for power users to rapidly\nobtain access to standardized and scalable computing environments.\nKey resources include:\nbioconductor.org to install,\nlearn, use, and develop Bioconductor packages.\nA list of available software\nlinking to pages describing each package.\nA question-and-answer style\nuser support site and\ndeveloper-oriented mailing list.\nA community slack workspace (sign up)\nfor extended technical discussion.\nThe F1000Research Bioconductor gateway\nfor peer-reviewed Bioconductor workflows as well as conference contributions.\nThe Bioconductor YouTube\nchannel includes recordings of keynote and talks from recent\nconferences including BioC2022, EuroBioC2022, and BiocAsia2021, in addition to\nvideo recordings of training courses.\nOur package submission\nrepository for open technical review of new packages.\nUpcoming and recently completed events are browsable at our\nevents page.\nThe Technical\nand and Community\nAdvisory Boards provide guidance to ensure that the project addresses\nleading-edge biological problems with advanced technical approaches,\nand adopts practices (such as a\nproject-wide Code of Conduct\nthat encourages all to participate. We look forward to\nwelcoming you!\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2022-4-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in The R Journal.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2022-12-01",
    "categories": [],
    "contents": "\nIn the past 3 months, 462 new packages were\nadded to the CRAN package repository. 219\npackages were unarchived, 330 were archived and\n1 had to be removed. The following shows the\ngrowth of the number of active packages in the CRAN package repository:\n\n\n\nOn 2023-01-31, the number of active packages was around 19135.\n\nCRAN package submissions\nFrom November 2022 to January 2023\nCRAN received 6904 package submissions.\nFor these, 12365 actions took place of which\n8114 (66%) were auto processed actions and\n4251 (34%) manual actions.\nMinus some special cases, a summary of the auto-processed and manually\ntriggered actions follows:\n\n\narchive\ninspect\nnewbies\npending\npretest\npublish\nrecheck\nwaiting\nauto\n1786\n1594\n1140\n0\n0\n2164\n724\n706\nmanual\n1523\n81\n365\n209\n54\n1422\n515\n82\n\nThese include the final decisions for the submissions which were\n\n\narchive\npublish\nauto\n1665 (24.7%)\n1733 (25.7%)\nmanual\n1506 (22.3%)\n1844 (27.3%)\n\nwhere we only count those as auto processed whose publication or\nrejection happened automatically in all steps.\nCRAN mirror security\nCurrently, there are 96 official CRAN mirrors,\n80 of which provide both\nsecure downloads via ‘https’ and use secure mirroring from the CRAN master\n(via rsync through ssh tunnels). Since the R 3.4.0 release, chooseCRANmirror()\noffers these mirrors in preference to the others which are not fully secured (yet).\nCRAN Task View Initiative\n\n\n\nCurrently there are 42 task views (see https://cran.r-project.org/web/views/),\nwith median and mean numbers of CRAN packages covered\n103 and 116, respectively.\nOverall, these task views cover 4050 CRAN packages,\nwhich is about 21% of all active CRAN packages.\n\n\n\n",
    "preview": "news/RJ-2022-4-cran/distill-preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 1920,
    "preview_height": 1344
  },
  {
    "path": "news/RJ-2022-4-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in The R Journal.",
    "author": [
      {
        "name": "Catherine Hurley",
        "url": "https://journal.r-project.org"
      }
    ],
    "date": "2022-12-01",
    "categories": [],
    "contents": "\nOn behalf of the editorial board, I am pleased to present Volume 14 Issue 4 of the R Journal. In response to our increased number of publications (now about 80 per year), this is the first year the R Journal moved to four issues. In addition, over the last year our software supporting the publication process has substantially improved. As a result of these developments, accepted articles are now published in a more timely fashion.\nWe have also added some R Journal reporting summaries to our webpage, and will expand on this in future.\nFor published articles, the time from first submission to accept averages at under a year.\nCurrently, just a very small number of 2021 submissions await a final decision, and even for 2022 submission, the majority of articles have received an accept/reject decision.\nThis is my last issue as Editor-in-Chief. Simon Urbanek takes over as Editor-in-Chief for 2023, having served as an Executive Editor since 2020. Simon is a huge contributor to the R community as a long-standing member of the R-core team. During his term, he plans to build further infrastructure to further streamline the R Journal submission and review process.\nDianne Cook recently finished her Editorial board term. She has been a hugely positive influence on the R Journal over the last number of years, and has been the driving force behind new software for journal operations and article production. Personally, I was very grateful for the guidance she provided as I took on the daunting role of EIC.\nDuring the last year, Gavin Simpson stepped down from his editorial board role, having served two years. Beth Atkinson and Earo Wang have completed their terms as Associate Editors. On behalf of the board, I would like to thank Gavin, Beth and Earo for their hard work on behalf of the Journal.\nNew additions are Rob Hyndman who has joined the Editorial board, and Vincent Arel-Bundock who has just joined the Associate Editor team.\nThe R Journal Editors recently held our first meeting with our Editorial Advisory Board. The purpose of the board is to assist with continuity across editors and to provide independent advice. We thank them for their time and guidance.\nBehind the scenes, several people assist with the journal operations. Mitchell O’Hara-Wild continues to work on infrastructure, H. Sherry Zhang continues to develop the rjtools package under the direction of Professor Dianne Cook. In addition, articles in this issue have been carefully copy edited by Hannah Comiskey.\nIn this issue\nNews from CRAN, Rcore, Bioconductor, RFoundation and RForwards are included in this issue.\nThis issue features 20 contributed research articles the majority of which relate to R packages\non a diverse range of topics. All packages are available on CRAN. Supplementary material with fully reproducible code is available for download from the Journal website. Topics covered in this issue are\nReproducible Research\nknitrdata: A Tool for Creating Standalone Rmarkdown Documents\nMaking Provenance Work for You\nA Study in Reproducibility: The Congruent Matching Cells Algorithm and cmcR package\nThe openVA Toolkit for Verbal Autopsies\nMultivariate Statistics, Visualisation\nBootstrapping Clustered Data in R using lmeresampler\nGeneralized Mosaic Plots in the ggplot2 Framework\nrobslopes: Efficient Computation of the (Repeated) Median Slope\nEconometrics\nDGLMExtPois: Advances in Dealing with Over and Underdispersion in a Double GLM Framework\nLimitations of the R mcvis package\nSpatial Analysis\nremap: Regionalized Models with Spatially Smooth Predictions\npopulR: A Package for Population Down-Scaling in R\nEcological and Environmental analysis\nHostSwitch: An R Package to Simulate the Extent of Host-Switching by a Consumer\ndycdtools: an R Package for Assisting Calibration and Visualising Output\nStatistical Genetics\nSurvMetrics: An R package for Predictive Evaluation Metrics in Survival Analysis\nnetgwas: An R Package for Network-Based Genome Wide Association Studies\nBayesian inference\nBayesPPD: An R Package for Bayesian Sample Size Determination Using the Power and Normalized Power Prior for Generalized Linear Models\nppseq: An R Package for Sequential Predictive Probability Monitoring\nOther\npCODE: Estimating Parameters of ODE Models\nTreeSearch: Morphological Phylogenetic Analysis\nOTrecod: An R Package for Data Fusion using Optimal Transportation Theory\n\nCRAN packages used\nrjtools\nCRAN Task Views implied by cited packages\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2022-4-forwards/",
    "title": "News from the Forwards Taskforce",
    "description": "\"News from the Forwards Taskforce\" published in The R Journal.",
    "author": [
      {
        "name": "Heather Turner",
        "url": {}
      }
    ],
    "date": "2022-12-01",
    "categories": [],
    "contents": "\nForwards is an R Foundation taskforce working to widen the participation of under-represented groups in the R project and in related activities, such as the useR! conference. This report rounds up activities of the taskforce during the second half of 2022.\nAccessibility\nLiz Hare gave a workshop on Writing Meaningful Alt-Texts for Data Visualizations in R for R-Ladies New York and contributed a chapter on the same topic to the Urban Institute’s Do No Harm Guide: Centering Accessibility in Data Visualization. Liz also participated in a Book Dash for the Turing Way, a handbook for reproducible, ethical and collaborative data science, discussing technical accessibility, e.g., bandwidth and hardware requirements, as well as disability-related issues.\ns gwynn sturdevant contributed to an article for the Justice, Equity, Diversity, and Inclusion (JEDI) Corner of Amstat News, on the topic From Visualization to ‘Sensification’, considering how senses other than sight might be used for statistical communication.\nYanina Bellini Saibene and Andrea Sánchez-Tapia contributed to a CarpentryCon 2022 panel on Translation at The Carpentries, sharing their experience of translating technical and educational materials into Spanish. The panel was part of a wider effort by The Carpentries to make their materials available in languages other than English, which will help more people to teach or learn data science skills, including R programming.\nCommunity engagement\nRainbowR continued to build on its relaunch, led by Ella Kaye and Zane Dax. Inspired by a post on the RainbowR Twitter, community member Laura Bakala developed the gglgbtq package, which provides ggplot2 palettes and themes based on various pride flags. Zane led the development of the tidyrainbow GitHub repository that collates several datasets pertaining to the LGBTQ+ community, where LGBTQ+ folk are explicitly represented and where it is not assumed that gender is binary. These data sets provide great opportunities for data analysis and visualisation in R and other languages.\nRainbowR are meeting bimonthly online, giving people an opportunity to present, in an informal and safe space, anything R related they had been working on. Ella recently set up a Mastodon account @rainbowr@tech.lgbt, which has helped to grow the community, with several new folk joining the RainbowR Slack as a result.\nConferences\nYanina Bellini Saibene was co-chair of the LatinR 2022 conference. Now in its 5th year, 900 people attended the online conference, with keynotes, regular talks and tutorials in each of the conference languages: English, Spanish and Portuguese. A charge was introduced for tutorials reducing no-shows and enabling tutors to be paid, but scholarships were offered thanks to donations. Yanina was a keynote speaker at CarpentryCon 2022, where she spoke about Achieving the change we want one conference at a time (in Spanish). In the talk she shared actions that can be taken to make events more diverse and inclusive, based on 20 years of experience organizing face-to-face, virtual and hybrid events. Many of these actions are summarized in the article “Ten simple rules to host an inclusive conference” (Joo et al. 2022), which distils learnings from organizing useR! 2021.\nTeaching\nPaola Corrales and Yanina Bellini Saibene gave a tutorial From spreadsheets to R at the Software Sustainability Institute’s Research Software Camp: Next Steps in Coding. The tutorial was presented in Spanish - one of two events during the research camp in a language other than English.\nFor anyone wanting to teach package development, we would like to highlight the Forwards materials which are organized into four 1-hour hands-on modules: Packages in a Nutshell, Setting up your system, Your first package, and Package documentation. The material is released under a CC BY-NC-SA license.\nR Contribution\nSaranjeet Kaur Bhogal continued work on the R Development Guide, as part of the R project’s Google Summer of Docs project, alongside the second technical writer, Lluís Revilla. The case study summarises the progress made during the official project period. There is some funding remaining from the grant, so there are plans to continue work in 2023.\nMichael Chirico and others supported R Contribution Working Group (RCWG) initiatives to encourage more people to contribute translations to base R. RCWG member Gergely Daróczi set up a Weblate server to provide a user-friendly web interface for adding/editing translations. This was used during the R translatón/Hackaton de tradução do R that was organized by RCWG/LatinR as a satellite to LatinR 2022, led by Beatriz Milz, Ángela Sanzo, Macarena Quiroga, and Caio Lente. Use of the Weblate server has gradually increased and Michael Lawrence made a recent commit to R-devel, which bundled over 3000 translations from the platform across 8 languages and 17 translators.\nHeather Turner and Ella Kaye joined RCWG members Elin Waring and Gabriel Becker in running monthly Office Hours for R contributors. These sessions provide an opportunity to discuss how to get started contributing to R and to look at open bugs or work on translations together. This has led to some bugs being closed such as Bug 16158: Error in predict.lm for rank-deficient cases and Bug 17853: stats::factanal print method drops labels when sort=TRUE. The Office Hours are held at two times on the same day to cater for different time zones, see the R Contributors Events page or Meetup for upcoming events.\nWe also started planning for the R Project Developer Sprint 2023, to be hosted at the University of Warwick, Coventry, UK, from August 30 to September 1. This sprint will bring together novice and experienced contributors, to work alongside members of the R Core Team on contributions to base R. Thanks to the event sponsors, full board on-campus accommodation will be provided during the sprint and funding is available for travel if required. Anyone interested to attend is encouraged to self-nominate via the application form by Friday 10 March. Additional sponsors are also welcome.\nSocial Media\nRCWG and Forwards have also set up Mastodon accounts, follow them at @R_Contributors@hachyderm.io and @R_Forwards@hachyderm.io, respectively.\nChanges in Membership\nNew members\nWe welcome the following members to the taskforce:\nOn-ramps team: Allison Vuong\nSurveys team: Daniela Cialfi\n\n\n\nR. Joo, A. Sánchez-Tapia, S. Mortara, Y. Bellini Saibene, H. Turner, D. Hug Peter, N. Soledad Morandeira, M. Bannert, B. Almazrouq, E. Hare, et al. Ten simple rules to host an inclusive conference. PLOS Computational Biology, 18(7): 1–13, 2022. URL https://doi.org/10.1371/journal.pcbi.1010164.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2022-4-rcore/",
    "title": "Changes in R",
    "description": "We present important changes in the development version of R (referred to as R-devel, to become R 4.3). Some statistics on bug tracking activities in 2022 are also provided.",
    "author": [
      {
        "name": "Tomas Kalibera",
        "url": {}
      },
      {
        "name": "Sebastian Meyer",
        "url": {}
      },
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2022-12-01",
    "categories": [],
    "contents": "\n1 R-devel selected changes\nR 4.3.0 is due to be released around April 2023. The following gives a\nselection of the most important changes in R-devel, which are likely to\nappear in the new release.\nDates and times\nThere are a number of (robustness) improvements in the handling of dates\nand times. These include warnings about extrapolation for datetimes before\n1902/1900, finer control for padding when printing years, improved detection\nof offset with strftime() (%z), inclusion of system time zone and\ninformation on timezone support implementation in sessionInfo(), more\nrobust handling of hand-crafted POSIXlt objects, optional support for\nusing system timezone support on recent macOS, improved detection of the\nsystem time zone on Windows and improved default tick locations and default\nformats in axis.Date() and axis.POSIXct().\nEncoding support\nPerformance of regular expression operations in R has been improved by\nreducing the costs of encoding conversions. With perl=FALSE, all\ninputs have to be converted to UTF-16 or UTF-32, and the conversion is\nnow faster. With perl=TRUE, performance has been improved by opting\nout from duplicate checks for UTF-8 validity in PCRE2. With\nfixed=TRUE, performance has been improved by taking advantage of the\nproperties of UTF-8. One of the motivations for the speedups was to\nreduce the incentive for using useBytes=TRUE with regular expression\noperations, which often leads to incorrect results or errors due to\nproducing invalid strings.\nSee Speedups in operations with regular expressions\nfor more information.\nThe support for encoding-agnostic string operations in R using the\n“bytes” encoding has been improved. It is now possible to read a text\nfile directly as bytes. Regexp operations, when creating new strings by\nsplitting or substituting, now also flag them as “bytes” when any of the\ninput has been flagged as such. This simplifies encoding-agnostic parsing\nof files such as DESCRIPTION. iconv(,from=\"\") now respects the\nencoding flag of the input string, making it easier to recover from\ntype-instability in return values of regular expression operations.\nImproving the support for encoding-agnostic operations using the “bytes”\nencoding comes together with stricter checking of validity of real\nstrings in a character encoding, e.g. “unknown/native”, which has been\nhelpful in revealing user errors. In the long term, it should also help\nto simplify encoding support in R.\nSee Improvements in handling bytes encoding\nfor more information. The blog includes a detailed introduction to string and\nencoding support in R.\nSee Why to avoid \\x in regular expressions\nfor related information on the danger of using \\x escapes in regular\nexpressions, which leads to errors, that are now more likely to be\ndetected by R. This is closely related as \\x is a common way to\ncreate invalid strings.\nGraphics\nThe grDevices and grid packages have new functions for rendering typeset\nglyphs, primarily: grDevices::glyphInfo() and grid::grid.glyph().\nThe behaviour of compositing operators in grid::grid.group() has been\ntweaked to allow consistency across graphics devices.\nThe grDevices::quartz() device will support gradient fills, pattern\nfills, clipping paths, masks, compositing operators, affine\ntransformations, stroked/filled paths, and glyphs. To be soon merged to\nR-devel.\nAccessibility on Windows\nRgui console on Windows now works better with the open-source NVDA\nscreen reader when the “full” blinking cursor is selected. This is due to\nimproved implementation of the console cursor (when it is displayed and\nhidden with respect to application startup and window focus) on which\nmakes it easier for the screen reader to detect where the cursor is.\nPreviously, NVDA was not able to read out the character under the cursor\nmoved by the arrow keys.\nThe drop-field GraphApp control, which is used in the Rgui configuration\neditor, has been extended so that it can be left by pressing the TAB key,\nso without using the mouse.\nGraphApp has been extended to allow reverse-order navigation through the\ncontrols using Shift+TAB key, which can now be done also in the Rgui\nconfiguration editor.\nOther selected changes\nUsing vectors of more than one element with the logical operators &&\nand || will give an error in R 4.3.0 (a warning in R 4.2.x, a check\nerror since R 3.6.0).\nSupport for working with concordances has been extended from\nSweave to help files. A concordance is a mapping between lines in an\nintermediate file (e.g., .tex or .html) and lines in the\ncorresponding input file (e.g., .Rnw or .Rd), which, for example, allows\nrelating problems in the intermediate file to the source file from which\nit was generated.\nSee Concordances for more\ninformation.\nThe implementation of the sampling profiler, Rprof(), has been\nimproved. On macOS, the profiler is now more robust against high load on\nthe system by using low-level Mach API to avoid a race condition between\ninitialization of pthread data and arrival of a profiler signal. This\nrace condition could lead to a live-lock when the system has been\noverloaded due to a too short profiling interval. As an additional\nmeasure, Rprof() now refuses to use a too short profiling interval,\nwhich in the first place would lead to incorrect profiling results. To\nprevent a deadlock seen on Windows, the profiler has been rewritten to\navoid using C runtime functions while the main thread is suspended.\nPackage installation now uses C++17 as the default C++ standard (and\nthere is initial support for C++23). Also, there now is support for\na package to indicate the version of the C standard which should be\nused to compile it, and for the installing user to specify this. In\nmost cases, C17 (a “bug-fix” of C11) is used by default.\nProducing PDF manuals (R CMD Rd2pdf) now loads standard AMS-LaTeX\npackages for greater coverage of math commands in Rd equations\n(e.g., \\lVert and \\text), and for consistency with the\nenhanced HTML math rendering introduced in R 4.2.0. This change has been\nbackported to the R 4.2 release branch.\nThe \"repos\" option is now initialized from the repositories file,\nsee ?R_REPOSITORIES, allowing the default CRAN mirror to be set therein.\n2 Bug statistics for 2022\nSummaries of bug-related activities over the past year were derived from the\ndatabase underlying R’s Bugzilla system.\nOverall, 180 new bugs or requests for enhancements were reported,\n171 reports were closed, and 869 comments (on any report) were added\nby a total of 123 contributors.\nThis amounts to one report/closure every other day,\nand 2–3 comments per day.\nThe numbers of reports, closures and comments are about 20% lower than in\n2021, \nwhereas the number of contributors stayed the same.\nHigh bug activity in 2021 had largely been driven by dedicated efforts of\nseveral contributors in reviewing old reports.\n\n\n\nFigure 1: Bug tracking activity by month in 2022\n\n\n\n\n\n\nFigure 2: Bug tracking activity by weekday in 2022\n\n\n\nFigures 1 and 2 show statistics for the numbers of new reports,\nclosures and comments by calendar month and weekday, respectively, in 2022.\nThe frequency of new reports was relatively stable over the year with minor\npeaks in January and June. There tended to be more new reports than\nclosures, except for July and especially March with a revived effort\nto deal with old reports, including 9 related to the nlme package,\nwhich is also maintained by the R Core Team.\nThe top 5 components reporters have chosen for their reports were\n“Misc”, “Language”, “Low-level”, “Documentation”, and “Wishlist”,\nwhich is the same set as in 2021. Many reports are suggestions for\nenhancements and placed either in the “Wishlist” or in a\nspecific component but with severity level set to “enhancement”.\nBug discussions led to an average of 72 comments per month, with a minimum\nof 42 in August and a maximum of 111 in January.\nFrom the numbers in Figure 2 we see that the R community is also active during\nweekends, though at a lower frequency.\nAcknowledgements\nTomas Kalibera’s work on the article and R development has received funding\nfrom the National Science Foundation award 1925644.\n\nCRAN packages used\nnlme\nCRAN Task Views implied by cited packages\nChemPhys, Econometrics, Environmetrics, Finance, MixedModels, OfficialStatistics, Psychometrics, Spatial, SpatioTemporal\n\n\n",
    "preview": "news/RJ-2022-4-rcore/distill-preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 600,
    "preview_height": 450
  },
  {
    "path": "news/RJ-2022-4-rfoundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2022-4 issue.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2022-12-01",
    "categories": [],
    "contents": "\n1 Donations and members\nMembership fees and donations received between 2022-09-05 and\n2023-02-19.\nDonations\nBharat R Adhikary (Nepal) b-data GmbH (Switzerland) RV Detailing Pros of\nSan Diego (United States) Shalese Fitzgerald (United States) Roger\nKoenker (United Kingdom) Rudolph Martin (United States) Kem Phillips\n(United States) Panagiotis Togias (Greece) Jason Wyse (Ireland)\nStatistik Aargau, Aarau (Switzerland)\nSupporting institutions\nEf-prime, Inc., Chuo-ku (Japan) Institute of Botany of the Czech Academy\nof Sciences, Pruhonice (Czechia) oikostat GmbH, Ettiswil (Switzerland)\nPutnam Data Sciences, LLC, Cambridge (United States)\nSupporting members\nDouglas Adamoski (Brazil) Tim Appelhans (Germany) Luis Biedma\n(Luxembourg) Michael Blanks (United States) Gordon Blunt (United\nKingdom) Tamara Bozovic (New Zealand) Susan M Carlson (United States)\nCédric Chambru (Switzerland) John Chandler (United States) Michael\nChirico (United States) Tom Clarke (United Kingdom) Gerard Conaghan\n(United Kingdom) Terry Cox (United States) Robin Crockett (United\nKingdom) Brandon Dahl (United States) Robert Daly (Australia) Gergely\nDaroczi (Hungary) Dereck de Mezquita (United States) Anna Doizy\n(Réunion) Fraser Edwards (United Kingdom) Anthony Alan Egerton\n(Malaysia) MAEL ELEGOET (France) Faisel Eskander (United Kingdom) Dane\nEvans (United States) Isaac Florence (United Kingdom) Neil Frazer\n(United States) David Freedman (United States) Keita Fukasawa (Japan)\nSven Garbade (Germany) Jan Marvin Garbuszus (Germany) Gabriel Gersztein\n(Brazil) Anne Catherine Gieshoff (Switzerland) Pavel Goriacko (United\nStates) Brian Gramberg (Netherlands) Spencer Graves (United States)\nKrushi Gurudu (United States) Hlynur Hallgrímsson (Iceland) Joe Harwood\n(United Kingdom) Bela Hausmann (Austria) Kieran Healy (United States)\nPhilippe Heymans Smith (Costa Rica) Adam Hill (United States) Alexander\nHuelle (Germany) Lorenzo Isella (Belgium) Sebastian Jeworutzki (Germany)\nNigokhos Kanaryan (Bulgaria) Curtis Kephart (United States) JUNE KEE KIM\n(Korea, Republic of) Miha Kosmac (United Kingdom) Jan Herman Kuiper\n(United Kingdom) Flavio L (Switzerland) Bernardo Lares (Venezuela)\nThierry Lecerf (Switzerland) Mauro Lepore (United States) Thomas Levine\n(United States) Chin Soon Lim (Singapore) Joseph Luchman (United States)\nMehrad Mahmoudian (Finland) Gilles Marodon (France) Daniel McNichol\n(United States) Amanuel Medhanie (United States) Orlando Monsalve\n(Switzerland) Keon-Woong Moon (Korea, Republic of) Guido (Germany)\nyoshinobu nakahashi (Japan) Dan Orsholits (Switzerland) George\nOstrouchov (United States) Antonio Paez (Canada) Elgin Perry (United\nStates) VASILEIOS PLESSAS (United Kingdom) PierGianLuca Porta Mana\n(Norway) Bianca Prandi (Austria) Fergus Reig Gracia (Spain) Peter\nRuckdeschel (Germany) Ingo Ruczinski (United States) Choonghyun Ryu\n(Korea, Republic of) Nico Schäfer (Germany) Raoul Schorer (Switzerland)\nDejan Schuster (Germany) Jagat Sheth (United States) David Sides (United\nStates) Pedro Silva (Brazil) Rachel Smith-Hunter (United States) Murray\nSondergard (Canada) Matteo Starri (Italy) Tobias Strapatsas (Germany)\nKai Streicher (Switzerland) ROBERT Szabo (Sweden) Fred Viole (United\nStates) Marcus Vollmer (Germany) Dr. Alfred Wagner (Germany) Petr\nWaldauf (Czechia) Jaap Walhout (Netherlands) Sandra Ware (Australia)\nArne Jonas Warnke (Germany) Vaidotas Zemlys-Balevičius (Lithuania) Lim\nZhong Hao (Singapore) 广宇 曾 (China)\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2022-3-bioconductor/",
    "title": "Bioconductor Notes, Autumn 2022",
    "description": "We discuss the release of Bioconductor 3.16, along with educational activities and general project news.",
    "author": [
      {
        "name": "Bioconductor Core Developer Team",
        "url": {}
      }
    ],
    "date": "2022-09-01",
    "categories": [],
    "contents": "\n1 Introduction\nBioconductor provides\ntools for the analysis and comprehension of high-throughput genomic\ndata. The project has entered its twentieth year, with funding\nfor core development and infrastructure maintenance secured\nthrough 2025 (NIH NHGRI 2U24HG004059). Additional support is provided\nby NIH NCI, Chan-Zuckerberg Initiative, National Science Foundation,\nMicrosoft, and Amazon. In this news report, we give some\ndetails about the software and data resource collection,\ninfrastructure for building, checking, and distributing resources,\ncore team activities, and some new initiatives.\n2 Software\nBioconductor 3.16 was released on 2 November, 2022. It is\ncompatible with R 4.2 and consists of 2183 software packages, 416\nexperiment data packages, 909 up-to-date annotation packages, 28\nworkflows, and 3 books. are\nbuilt regularly from source and therefore fully\nreproducible; an example is the\ncommunity-developed Orchestrating Single-Cell Analysis with Bioconductor.\nThe Bioconductor\n3.16 release announcement\nincludes descriptions of 71 new software packages, 9 new data\nexperiment packages, 2 new annotation packages, and updates to NEWS files for\nmany additional packages.\n3 Core team updates\nNew developer Robert Shear of the\nDepartment of Data Science at Dana-Farber Cancer\nInstitute has joined the Bioconductor Core Developer Team.\nRobert is joined by long-term core members Lori Kern of Roswell Park\nComprehensive Cancer Center, Marcel Ramos of CUNY and Roswell, Herv'e Pages of\nFred Hutchinson Cancer Research Center, Jennifer Wokaty of CUNY, and Alex\nMahmoud at Channing Division of Network Medicine.\n4 Educational activities and resources\nEngagement with The Carpentries\nIn August 2022, Bioconductor joined The Carpentries. Details and opportunities\nfor receiving training on teaching are discussed in this blog post.\nWe are currently inviting applications to become a Bioconductor Carpentries instructor through this form and particularly encourage people who could teach underserved communities in their local languages to apply.\nThree lessons are under development in the Carpentries incubator: Introduction to data analysis with R and Bioconductor, RNA-seq analysis with Bioconductor and The Bioconductor project. We welcome any contributions, feedback or testing of the material.\nAnyone is welcome to join the #education-and-training channel in Bioconductor Slack or the monthly Bioconductor Teaching Committee meetings to learn more.\nYES for CURE\nThe Dana-Farber/Harvard Cancer Center Young Empowered Scientists program included a module on cancer data science\nfor Summer 2022 participants. Materials presented are assembled at a pkgdown site; contact Vince Carey for information on an interactive deployment of these materials.\n5 Using Bioconductor\nStart using\nBioconductor by installing the most recent version of R and evaluating\nthe commands\n  if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n      install.packages(\"BiocManager\")\n  BiocManager::install()\nInstall additional packages and dependencies,\ne.g., SingleCellExperiment, with\n  BiocManager::install(\"SingleCellExperiment\")\nDocker\nimages provides a very effective on-ramp for power users to rapidly\nobtain access to standardized and scalable computing environments.\nKey resources include:\nbioconductor.org to install,\nlearn, use, and develop Bioconductor packages.\nA list of available software\nlinking to pages describing each package.\nA question-and-answer style\nuser support site and\ndeveloper-oriented mailing list.\nA community slack workspace (sign up)\nfor extended technical discussion.\nThe F1000Research Bioconductor gateway\nfor peer-reviewed Bioconductor workflows as well as conference contributions.\nThe Bioconductor YouTube\nchannel includes recordings of keynote and talks from recent\nconferences including BioC2022, EuroBioC2022, and BiocAsia2021, in addition to\nvideo recordings of training courses.\nOur package submission\nrepository for open technical review of new packages.\nUpcoming and recently completed conferences are browsable at our\nevents page.\nThe Technical\nand and Community\nAdvisory Boards provide guidance to ensure that the project addresses\nleading-edge biological problems with advanced technical approaches,\nand adopts practices (such as a\nproject-wide Code of Conduct\nthat encourages all to participate. We look forward to\nwelcoming you!\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2022-3-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2022-3 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2022-09-01",
    "categories": [],
    "contents": "\n\nIn the past 4 months, 664 new packages were added to the CRAN package\nrepository. 154 packages were unarchived, 353 were archived and 6 had to\nbe removed. The following shows the growth of the number of active\npackages in the CRAN package repository:\n\nOn 2022-10-31, the number of active packages was around 18730.\nCRAN package submissions\nFrom September 2022 to October 2022 CRAN received 5227 package\nsubmissions. For these, 9429 actions took place of which 6070 (64%) were\nauto processed actions and 3359 (36%) manual actions.\nMinus some special cases, a summary of the auto-processed and manually\ntriggered actions follows:\n\narchive\ninspect\nnewbies\npending\npretest\npublish\nrecheck\nwaiting\nauto\n1335\n1211\n926\n0\n0\n1560\n513\n525\nmanual\n1250\n35\n325\n232\n39\n1054\n353\n71\nThese include the final decisions for the submissions which were\n\narchive\npublish\nauto\n1283 (25.1%)\n1239 (24.3%)\nmanual\n1222 (23.9%)\n1361 (26.7%)\nwhere we only count those as auto processed whose publication or\nrejection happened automatically in all steps.\nCRAN mirror security\nCurrently, there are 100 official CRAN mirrors, 81 of which provide both\nsecure downloads via https and use secure mirroring from the CRAN\nmaster (via rsync through ssh tunnels). Since the R 3.4.0 release,\nchooseCRANmirror() offers these mirrors in preference to the others\nwhich are not fully secured (yet).\nCRAN Task View Initiative\nThere are three new task views:\nAgricultural Science\n\nMaintained by Julia Piaskowski, Adam Sparks, and Janet Williams.\n\nMixed, Multilevel, and Hierarchical Models in R\n\nMaintained by Ben Bolker, Julia Piaskowski, Emi Tanaka, Phillip\nAlday, and Wolfgang Viechtbauer.\n\nPhylogenetics\n\nMaintained by William Gearty, Brian O’Meara, Jacob Berv, Gustavo A.\nBallen, Diniz Ferreira, Hilmar Lapp, Lars Schmitz, Martin R. Smith,\nNathan S. Upham, and Jonathan A. Nations.\n\nCurrently there are 42 task views (see\nhttps://cran.r-project.org/web/views/), with median and mean numbers\nof CRAN packages covered 102 and 115, respectively. Overall, these task\nviews cover 4015 CRAN packages, which is about 21% of all active CRAN\npackages.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2022-3-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in The R Journal.",
    "author": [
      {
        "name": "Catherine Hurley",
        "url": "https://journal.r-project.org"
      }
    ],
    "date": "2022-09-01",
    "categories": [],
    "contents": "\nOn behalf of the editorial board, I am pleased to present Volume 14 Issue 3 of the R Journal.\nOur incoming editor-in-chief for 2023 Simon Urbanek has been successful in seeking funding from the R Consortium. The project will provide a web-based front-end for managing the R Journal submission and review process.\nBehind the scenes, several people assist with the journal operations. Mitchell O’Hara-Wild continues to work on infrastructure, and thanks to this work, producing a new issue is far more straightforward. H. Sherry Zhang continues to develop the rjtools package under the direction of Professor Dianne Cook. This package, recently available from CRAN assists in producing RMarkdown articles in the R Journal format. In addition, articles in this issue have been carefully copy edited by Hannah Comiskey.\nIn this issue\nNews from the CRAN and Bioconductor are included in this issue.\nThis issue features 18 contributed research articles the majority of which relate to R packages\non a diverse range of topics. All packages are available on CRAN. The most common article keywords in this issue are\n\n\n\n\n\n\nFor the first time, we give times from submission to article acceptabce for an issue. Median times are just under a year, which is consistent other issues over the last few years.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCRAN packages used\nrjtools\nCRAN Task Views implied by cited packages\n\n\n",
    "preview": "news/RJ-2022-3-editorial/distill-preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 2400,
    "preview_height": 1440
  },
  {
    "path": "news/RJ-2022-2-bioconductor/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2022-2 issue.",
    "author": [
      {
        "name": "Bioconductor Core Team",
        "url": {}
      }
    ],
    "date": "2022-06-01",
    "categories": [],
    "contents": "\n\nBioconductor provides tools for the analysis\nand comprehension of high-throughput genomic data. The project has\nentered its twentieth year, with funding for core development and\ninfrastructure maintenance secured through 2025 (NIH NHGRI\n2U24HG004059). Additional support is provided by NIH NCI,\nChan-Zuckerberg Initiative, National Science Foundation, Microsoft, and\nAmazon. In this news report, we give some details about the software and\ndata resource collection, infrastructure for building, checking, and\ndistributing resources, core team activities, and some new initiatives.\nSoftware ecosystem\nBioconductor 3.15 was released on 27 April, 2022. It is compatible with\nR 4.2.0 and consists of 2140 software packages, 410 experiment data\npackages, 990 up-to-date annotation packages, 29 workflows, and 3 books.\nBooks are built regularly\nfrom source and therefore fully reproducible; an example is the\ncommunity-developed Orchestrating Single-Cell Analysis with\nBioconductor. The\nBioconductor 3.15 release\nannouncement includes\ndescriptions of 78 new software packages, and updates to NEWS files for\nmany additional packages.\nInfrastructure updates\nThanks to a generous allocation (BIR190004, \"Engineering and\ndisseminating a software and analysis ecosystem for genomic data\nscience\") provided through the National Science Foundation ACCESS\n(formerly XSEDE) program, academic cloud resources including GPUs\nand highly accessible object storage systems are being integrated\ninto project operations.\nTransition of primary funding administration from Roswell Park\nComprehensive Cancer Center to Dana-Farber Cancer Institute has led\nto a number of changes to platforms in use for the checking and\nproduction of binary package images.\nLinux builds occur at Dana-Farber Cancer Institute.\nWindows builds occur in machinery provided by Microsoft Genomics\nin the Azure cloud environment.\nMacOS builds occur at Dana-Farber Cancer Institute. Work on the\nsupport of ARM Mac systems occurs at MacStadium.\nDetails on the configurations of builders (e.g., the Linux\nbuilder\nfor the devel branch) are available at the Build\nreports link at\nbioconductor.org.\n\nAn interactive app for surveying adverse conditions arising for\npackage install, build, and check processes has been introduced for\nrelease and\ndevel branches.\nCloud-based workshop delivery systems have been an integral part of\nBioconductor conferences and teaching activities.\nWorkshops from Bioconductor 2022 are continuously available for\ninspection and hands-on exercises at\nhttp://app.orchestra.cancerdatasci.org, thanks to cloud\ncomputing support provided by Dr. Sean Davis of University of\nColorado.\nhttp://workshop.bioconductor.org is a Galaxy-based workshop\ncollection deployed on Jetstream2 in NSF ACCESS.\n\nCore team updates\nAfter six years of highly effective work in the core, Nitesh Turaga\nhas left for a position in industry. We will miss him!\nNew core developers Jen Wokaty and Alexandru Mahmoud have joined.\nJen is a member of the Waldron Lab at CUNY. Alex works at Channing\nDivision of Network Medicine.\nJen and Alex are joined by long-term core members Lori Kern of\nRoswell Park Comprehensive Cancer Center, Marcel Ramos of CUNY and\nRoswell, and Hervé Pages of Fred Hutchinson Cancer Research Center.\nNew initiatives\nThanks to efforts of members of the Technical and Community Advisory\nBoards and community members, a collection of working groups has\nbeen defined to achieve new project aims. An\noverview\nof currently active working groups is available, along with\nguidelines for proposing new working\ngroups.\nThe objectives of the bioconductor-teaching working group are stated\nat the associated\nrepository:\n> The Bioconductor teaching committee is a collaborative effort to\n> consolidate Bioconductor-focused training material and establish a\n> community of Bioconductor trainers. We define a curriculum and\n> implement online lessons for beginner and more advanced R users\n> who want to learn to analyse their data with Bioconductor\n> packages.\nA mentoring\nprogram\nfor new developers has taken flight.\nThanks to an Essential Open Source Software grant from the\nChan-Zuckerberg Initiative, we have partnered with the Dana-Farber\nCancer Institute YES for\nCURE\n(Young Empowered Scientists for Continued Research Engagement)\nprogram to offer instruction in cancer data science to interested\nundergraduates. A pkgdown site\nincludes current curricular materials.\nWith the NSF-based academic cloud resources previously mentioned, we\nhave begun gestation of G-DADS, a program for Genomic Data and\nAnalysis Development Services, with the objectives of providing\npublicly accessible storage and compute on exemplars of the latest\nhigh-volume experimental modalities, and of promoting GPUs to\nfirst-class citizenship in our build and check systems.\nUsing Bioconductor\nStart using Bioconductor by installing the most recent version of R and\nevaluating the commands\n  if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n      install.packages(\"BiocManager\")\n  BiocManager::install()\nInstall additional packages and dependencies, e.g.,\nSingleCellExperiment,\nwith\n  BiocManager::install(\"SingleCellExperiment\")\nDocker images provides a very\neffective on-ramp for power users to rapidly obtain access to\nstandardized and scalable computing environments. Key resources include:\nbioconductor.org to install, learn, use,\nand develop Bioconductor packages.\nA list of available software,\nlinking to pages describing each package.\nA question-and-answer style user support\nsite and developer-oriented\nmailing list.\nA community slack (sign up)\nfor extended technical discussion.\nThe F1000Research Bioconductor\nchannel for\npeer-reviewed Bioconductor work flows.\nThe Bioconductor\nYouTube channel includes\nrecordings of keynote and talks from recent conferences including\nBioc2022, EuroBioC2022, and BiocAsia2021, in addition to video\nrecordings of training courses.\nOur package\nsubmission\nrepository for open technical review of new packages.\nRecent Bioconductor conferences include BioC\n2022 (July 27-29), and European\nBioconductor Meeting (September\n14-16). Each had invited and contributed talks, as well as workshops and\nother sessions to enable community participation. Slides, videos, and\nworkshop material for each conference are, or will soon be, available on\neach conference web site as well as from the Courses and\nConferences section of\nthe Bioconductor web site.\nThe Bioconductor project continues to mature as a community. The\nTechnical\nand\nCommunity\nAdvisory Boards provide guidance to ensure that the project addresses\nleading-edge biological problems with advanced technical approaches, and\nadopts practices (such as a project-wide Code of\nConduct) that\nencourages all to participate. We look forward to welcoming you!\n\n\nBioconductor packages used\nSingleCellExperiment\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2022-2-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2022-2 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2022-06-01",
    "categories": [],
    "contents": "\n\nIn the past 3 months, 485 new packages were added to the CRAN package\nrepository. 76 packages were unarchived, 1179 were archived and 3 had to\nbe removed. The following shows the growth of the number of active\npackages in the CRAN package repository:\n\nOn 2022-03-31, the number of active packages was around 18260.\nChanges in the CRAN Repository Policy\nThe Policy now\nsays the following:\nThe ownership of copyright and intellectual property rights of all\ncomponents of the package must be clear and unambiguous […]\n(‘All components’ includes any downloaded at installation or during\nuse.)\nThe package’s DESCRIPTION file must show both the name and email\naddress of a single designated maintainer (a person, not a mailing\nlist). That contact address must be kept up to date, and be usable\nfor information mailed by the CRAN team without any form of\nfiltering, confirmation …. Forwarding mail from the maintainer\naddress increasingly results in confusing non-delivery notifications\nto the original sender, so is best avoided.\nSecurity provisions must not be circumvented, for example by not\nverifying SSL/TLS certificates.\nExternal Libraries for CRAN\npackages\nnow says\nFor macOS: JAGS may or may not be available. There is an ‘official’\nrelease for both architectures at\nhttps://sourceforge.net/projects/mcmc-jags/files/JAGS/4.x/.\nFor Windows: The build system for Windows changed with 4.2.0 and\nonly that is considered here (and only 64-bit Windows is now\nsupported).\nCRAN package submissions\nIn the second third of 2022 (May 2022 to August 2022), CRAN received\n9860 package submissions. For these, 17476 actions took place of which\n11354 (65%) were auto processed actions and 6122 (35%) manual actions.\nMinus some special cases, a summary of the auto-processed and manually\ntriggered actions follows:\n\narchive\ninspect\nnewbies\npending\npretest\npublish\nrecheck\nwaiting\nauto\n2559\n2660\n1635\n0\n0\n2830\n933\n737\nmanual\n2178\n113\n568\n255\n55\n2226\n595\n132\nThese include the final decisions for the submissions which were\naction\narchive\npublish\nauto\n2462 (25.5%)\n2311 (23.9%)\nmanual\n2156 (22.3%)\n2735 (28.3%)\nwhere we only count those as auto processed whose publication or\nrejection happened automatically in all steps.\nA new team member, Benjamin Altmann, joined the CRAN submission team.\nWelcome, Beni. Unfortunately, Gregor Seyer left the CRAN submission team\nafter processing 5482 incoming submissions. Thanks a lot!\nCRAN mirror security\nCurrently, there are 102 official CRAN mirrors, 80 of which provide both\nsecure downloads via https and use secure mirroring from the CRAN\nmaster (via rsync through ssh tunnels). Since the R 3.4.0 release,\nchooseCRANmirror() offers these mirrors in preference to the others\nwhich are not fully secured (yet).\nCRAN Task View Initiative\nThere are three new task views:\nCausalInference\n\nMaintained by Imke Mayer, Pan Zhao, Noah Greifer, Nick\nHuntington-Klein, and Julie Josse.\n\nEpidemiology\n\nMaintained by Thibaut Jombart, Matthieu Rolland, and Hugo Gruson.\n\nSportsAnalytics\n\nMaintained by Benjamin S. Baumer, Quang Nguyen, and Gregory J.\nMatthews.\n\nCurrently there are 39 task views (see\nhttps://cran.r-project.org/web/views/), with median and mean numbers\nof CRAN packages covered 101 and 112, respectively. Overall, these task\nviews cover 3668 CRAN packages, which is about 20% of all active CRAN\npackages.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2022-2-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in The R Journal.",
    "author": [
      {
        "name": "Catherine Hurley",
        "url": "https://journal.r-project.org"
      }
    ],
    "date": "2022-06-01",
    "categories": [],
    "contents": "\nOn behalf of the editorial board, I am pleased to present Volume 14 Issue 2 of the R Journal.\nFirst, some news about the journal board. Mark van der Loo has very kindly agreed to move from Associate Editor to Executive Editor to fill a temporary gap. One new Associate Editor, Kevin Burke, has recently joined the team.\nBehind the scenes, several people are assisting with the journal operations and the new developments. Mitchell O’Hara-Wild continues to work on infrastructure, and H. Sherry Zhang continues to develop the rjtools package. In addition, articles in this issue have been carefully copy edited by Hannah Comiskey.\nThere are also exciting new efforts in developing software to convert the legacy papers from latex to Rmarkdown, and hence create an html version to complement the pdf. Abhishek Ulayil, funded by the 2022 Google Summer of Code project, supervised by Heather Turner and Di Cook, with collaboration from Christophe Dervieux and Mitch O’Hara-Wild, has created the R package, texor, https://abhi-1u.github.io/texor/. It converts the legacy latex style into to the new Rmarkdown template, as would be given with the rjtools package. This package will be used to slowly, and steadily convert as many past articles into an html version.\nIf you are currently only a latex author, the texor package will get your paper into an Rmarkdown paper, doing the hard-work of the conversion. This is a good opportunity to get a head start on learning how to make reproducible documents. Reproducible documents keeps your code and results in the same place, and reduces the chance of getting them out of sync. Going forwards with the R Journal there will be a growing emphasis on receiving papers in Rmarkdown (and Quarto, at some point) format, because it is easier to test the code, and it makes the work more accessible to readers.\n1 In this issue\nNews from the CRAN, the R Foundation and the Forwards Taskforce are included in this issue. We also have a report from the Why R? Turkey 2022 conference.\nThis issue features 18 contributed research articles the majority of which relate to R packages\nfor modelling tasks. All packages are available on CRAN. Topics covered are:\nStatistical modelling and inference\nAPCI: An R and Stata Package for Age-Period-Cohort Analysis\nrefreg: an R package for estimating conditional reference regions\nFrom the multivariate Faà di Bruno’s formula to unbiased estimates of joint cumulant products: the kStatistics package in R\nThe Concordance Test, an Alternative to Kruskal-Wallis Based on the Kendall tau Distance: An R Package\nshinybrms: Fitting Bayesian Regression Models Using a Graphical User Interface for the R Package brms\nPDFEstimator: An R Package for Density Estimation and Analysis\nhtestClust: Hypothesis Tests for Clustered Data under Informative Cluster Size in R\nClusTorus: An R Package for Prediction and Clustering on the Torus by Conformal Prediction\nTensorTest2D: Fitting Generalized Linear Models with Matrix Covariates\n\nEcological and Environmental analysis\nQuantifying Population Movement Using a Novel Implementation of Digital Image Correlation in the ICvectorfields package\niccCounts: an R Package to Estimate the Intraclass Correlation Coefficient for Assessing Agreement with Count Data\nrassta: Raster-based Spatial Stratification Algorithms\n\nMissing data\nR-miss-tastic: a unified platform for missing values methods and workflows\nreclin2: a Toolkit for Record Linkage and Deduplication\n\nTime Series Analysis\nwavScalogram: an R package with wavelet scalogram tools for time series analysis\nbrolgar: An R package to BRowse Over Longitudinal Data Graphically and Analytically in R”\n\nOther\nakc: A tidy framework for automatic knowledge classification in R\nAn Open-Source Implementation of the CMPS Algorithm for Assessing Similarity of Bullets\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2022-2-forwards/",
    "title": "News from the Forwards Taskforce",
    "description": "\"News from the Forwards Taskforce\" published in The R Journal.",
    "author": [
      {
        "name": "Heather Turner",
        "url": {}
      }
    ],
    "date": "2022-06-01",
    "categories": [],
    "contents": "\nForwards is an R Foundation taskforce working to widen the participation of under-represented groups in the R project and in related activities, such as the useR! conference. This report rounds up activities of the taskforce during the first half of 2022.\nAccessibility\nAs another step towards improving the accessibility of the R Journal, Di Cook and Heather Turner are mentoring a Google Summer of Code student, Abhishek Ulayil, on the project Converting past R Journal articles to HTML. This project has benefited from regular input from Mitchell O’Hara Wild and Christophe Dervieux, authors of the rjtools package that provides the new HTML template for R Journal articles (O’Hara-Wild et al. 2022).\ns gwynn sturdevant and Jonathan Godfrey were part of an invited panel at JSM 2022 on Delivering Data Differently that explored alternatives to data visualisation.\nCommunity engagement\nThe community team have taken a number of actions to support the R community in Africa. A WhatsApp group has been set up for leaders of African R User Groups, to facilitate collaboration. Kevin O’Brien has been a Zoom host for several R User Groups, including the Botswana, Eswatini and Bulawayo groups. Zane Dax worked with the Accra R User Group on graphical design for advertising their meetups. Kevin O’Brien and Sam Toet helped to organize the first Francophone satRday, which featured a line up of African speakers.\nAnother focus has been the relaunch of RainbowR led by Ella Kaye and Zane Dax. Following a well-attended online meetup, the website was rebuilt, the Slack group opened to new members with a new code of conduct, and the Twitter account has been in active use. The group plan to have regular online meetups and to raise awareness of issues affecting the LGBTQ+ community through sharing relevant data sets for exploration and teaching.\nBeyond this, taskforce members continue to engage with a range of communities. Zane Dax contributed to an update of the Minorities in R (MiR) website. Yanina Bellini Saibene and Heather Turner joined the Building inclusive communities panel at the launch of the AsiaR community, to share their experience from working with different communities.\nConferences\nYanina Bellini Saibene assisted the useR! 2022 team on behalf of the R Foundation, to share expertise in the organization of virtual conferences and help incorporate good practices that encourage diverse participation. (The conference was originally planned to be hybrid, but moved to be completely online.) Such practices included adding representatives from different regions to the organizing team, securing funding to caption talks, accepting elevator pitches and tutorials in non-English languages, and adjusting the registration fees to the income group of each participant’s country of residence. Many of these practices were based on the work of the organizing team of useR! 2021 - that included Yanina and other Forwards members - who summarized their recommendations in the recent publication: “Ten simple rules to host an inclusive conference” (Joo et al. 2022).\nR Contribution\nSaranjeet Kaur Bhogal and Heather Turner organized a series of Collaboration Campfires with a goal to demystify the R development process and highlight ways that R programmers can contribute. The first two sessions explored R’s bug-tracking process and how R users can contribute to reviewing bugs. The second two sessions explored R’s process for localization and how to contribute to a translation team. The sessions attracted a diverse group of participants who engaged with the interactive activities, providing a foundation for further engagement.\nThe R Contribution working Group (RCWG) organized a Bug BBQ as a satellite to useR! 2022. Members of the RCWG prepared a number of open bugs in advance, for participants to look at in one or more of three organized online sessions. The event was supported by several R Core members and attended by both novice and experienced contributors. For experienced contributors the event provided a spur to work on open bugs, leading to progress on several issues. Meanwhile novice contributors contributed to the analysis of open bugs, under the guidance of experienced contributors. As the first event of its kind, the event showed promise as a way to engage the wider R community in contribution.\nSaranjeet Kaur Bhogal has been working on a new chapter for the R Development Guide on contributing translations, as part of the R project’s Google Summer of Docs project, with substantial contribution from Michael Chirico. Along with Ben Ubah, Michael is co-mentoring a Google Summer of Code student, Meet Bhatnagar, to create a dashboard to monitor the status of translations in R.\nChanges in Membership\nNew members\nWe welcome the following member to the taskforce:\nCommunity team: Ella Kaye (co-leader)\nPrevious members\nThe following members have stepped down:\nCommunity team: Richard Ngamita (co-leader)\nAccessibility team: Becca Wilson\nSurveys team: Anna Vasylytsya (co-leader)\nWe thank them for their contribution to the taskforce.\n\n\n\nR. Joo, A. Sánchez-Tapia, S. Mortara, Y. Bellini Saibene, H. Turner, D. Hug Peter, N. Soledad Morandeira, M. Bannert, B. Almazrouq, E. Hare, et al. Ten simple rules to host an inclusive conference. PLOS Computational Biology, 18(7): 1–13, 2022. URL https://doi.org/10.1371/journal.pcbi.1010164.\n\n\nM. O’Hara-Wild, S. Kobakian, H. S. Zhang, D. Cook and C. Dervieux. rjtools: Tools for Preparing, Checking, and Submitting Articles to the R Journal. 2022. URL https://github.com/rjournal/rjtools. R package version 1.0.1.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2022-2-rcore/",
    "title": "Changes in R",
    "description": "We give a selection of the most important changes in R 4.2.0 and of subsequent bug fixes for the Windows port of R. We also provide statistics on source code commits.",
    "author": [
      {
        "name": "Tomas Kalibera",
        "url": {}
      },
      {
        "name": "Sebastian Meyer",
        "url": {}
      },
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2022-06-01",
    "categories": [],
    "contents": "\n\n1 R 4.2.0 selected changes\nR 4.2.0 (codename “Vigorous Calisthenics”) was released on 2022-04-22.\nThe December 2021 (13/2) issue of the R Journal provided a selection of\nthe most important changes in that release that were already settled at\nthat time, including:\nR on Windows uses UTF-8 as the native encoding, uses the new\nUniversal C Runtime (UCRT) and a new toolchain (Rtools42).\nR on Windows changed the default library location and the default\ninstallation location for user-only installation to match current\nWindows conventions.\nSupport for isolated groups, compositing operators, affine\ntransformations, and stroking and filling paths has been added to\nthe R graphics engine.\nR now provides an R-level interface for hash tables.\nA selection of the remaining important R 4.2.0 changes is provided here.\nThe HTML help system has several new features: LaTeX-like math can\nbe typeset using either KaTeX or\nMathJax, usage and example code is\nhighlighted using Prism, and for dynamic help\nthe output of examples and demos can be shown within the browser if\nthe knitr package is\ninstalled. (These features can be disabled by setting the\nenvironment variable _R_HELP_ENABLE_ENHANCED_HTML_ to a false\nvalue.)\nThe HTML help system now uses HTML5, the current HTML standard,\nwhich in particular helps to facilitate some of the enhancements\ndescribed above. Considerable effort was put into ensuring valid\nHTML5 output. The old validation toolchain could not handle HTML5,\nso a new one was created based on HTML\nTidy and integrated into the tools\npackage. R CMD check can now optionally (but included in\n–as-cran) validate the package HTML help files.\nSee\nhttps://blog.r-project.org/2022/04/08/enhancements-to-html-documentation/\nfor more information.\nCalling if() or while() with a condition of length greater than\none now gives an error rather than a warning. Consequently,\nenvironment variable _R_CHECK_LENGTH_1_CONDITION_ no longer has\nany effect. Similarly, calling && or || with either argument of\nlength greater than one now gives a warning. In R 4.3.0, it will\ngive an error, and environment variable _R_CHECK_LENGTH_1_LOGIC2_\nwill no longer have any effect.\nThe grid package now allows the user to specify a vector of\npattern fills. The fill argument to gpar() accepts a list of\ngradients and/or patterns and the functions linearGradient(),\nradialGradient(), and pattern() have a new group argument.\nFinally, points grobs (data symbols) can now also have a pattern\nfill.\nSee\nhttps://blog.r-project.org/2022/06/09/vectorised-patterns-in-r-graphics/\nfor more information.\nIn lhs |> rhs expressions using the native pipe operator it is now\npossible to use a named argument with the placeholder _ in the\nrhs call to specify where the lhs is to be inserted. The\nplaceholder can only appear once on the rhs.\nOn Windows, download.file(method = \"auto\") and\nurl(method = \"default\") now follow Unix in using \"libcurl\" for\nall except file:// URIs. This impacts, for example, updating of R\npackages (HTTPS downloads). Most users should not notice, but an\nadditional proxy setup may be required (see\nhelp(\"download.file\")). Also, \"libcurl\" is by the decision of\nthe library authors stricter in checking certificate revocation than\nthe previous \"wininet\" method. This brings more security, but also\nmay cause trouble with some corporate HTTPS MITM proxies, which\nfilter HTTPS traffic. R-patched (to become R 4.2.2) has a\nwork-around via environment variable\nR_LIBCURL_SSL_REVOKE_BEST_EFFORT.\n2 R 4.2.1 and R-patched changes on Windows\nR 4.2.0 on Windows switched to UTF-8 as the native encoding and to UCRT\nas the Windows runtime. R is an early adopter of UCRT in the open-source\ncommunity of projects compiled using free and open-source compilers, and\nparticularly an early adopter of UTF-8 as the native encoding on\nWindows, hence this came with considerable effort and risk of bugs.\nHence, testing using CRAN package checks has been in place for over a\nyear before the release (and 9 months of that time in parallel to the\nusual CRAN checks when R-devel still used MSVCRT as the C runtime).\nStill, some issues not covered by such tests, mostly in interactive use\nand Rgui, have been reported by users after the 4.2 release and have\nbeen fixed in R-patched. R users on Windows should update to the latest\navailable patch version.\nSelected fixes in R 4.2.1:\nAccent keys now work in GraphApp Unicode windows, which are used by\nRgui whenever running in a multi-byte locale (so also in UTF-8),\nhence fixing a regression for users of systems where R 4.1 used a\nsingle-byte locale. This was one of the bugs already present in\nGraphApp, but never reported before, e.g., by users of other\nmulti-byte locales.\nText injection from external applications via SendInput now works\nin GraphApp Unicode windows, fixing a regression in R 4.2.0 for\nRgui users of systems where R 4.1 used a single-byte locale but\nR 4.2.0 uses UTF-8. Text injection is used via applications such as\nDasher, which helps people with hand impairment to enter text, and\nby general GUIs that prefer to use a standalone Rgui window over\nembedding R. This was another old bug in GraphApp impacting\nmulti-byte locales. Some other applications injecting text via\nsending Windows window messages such as WM_CHAR directly to Rgui\nshould switch to injection via SendInput, which is the proper\ninjection method on Windows and the switch should not be difficult.\nAllowing injection via WM_CHAR even in a multi-byte locale would\nrequire too big changes in GraphApp.\nA regression in writing to the clipboard connection has been fixed.\nThat code had to be rewritten for the UTF-8 transition, but the new\nversion had a bug which prevented writing text in consecutive\noperations.\ngetlocale has been fixed to also work with strict checking of\ninvalid arguments to the C runtime. These are normally disabled in\napplications built using Rtools, but it impacted embedded use in\nRStudio with the rJava\npackage, causing crashes by default. This issue was related to\nswitching to UCRT, which is stricter in checking the validity of\nfunction arguments (it was not directly related to UTF-8 nor the\nlocale).\nThe script editor in Rgui has been fixed to work with UTF-8: some\noperations (such as running a line of code from the editor in the R\nconsole) before did not work with non-ASCII characters, with a\nregression in R 4.2.0 (in earlier versions one could work at least\nwith non-ASCII characters representable in the current locale).\nThese issues are related to at least surprising behavior of the\nunderlying Windows component used for the editor with UTF-8 as the\nnative (ANSI) encoding: one would think that no change would be\nneeded for the transition from a non-UTF-8 native encoding to UTF-8\nhere. Users of the script editor have to convert their scripts with\nnon-ASCII characters to UTF-8 before reading them in R 4.2.1 or\nnewer (on recent Windows where UTF-8 is used), and they should\nupgrade to R 4.2.2 when it is available.\nSelected fixes in R-patched, to become R 4.2.2:\nRterm support for Alt+xxx sequences has been fixed to produce\nthe corresponding character (only) once. This fixes pasting text\nthat includes tilde on Italian keyboard; without the fix, tilde may\nappear twice, depending on the Windows console program used. This\nwas a regression introduced by an earlier rewrite of Rterm for\nsupporting multi-width characters. That change was part of the\ntransition to UTF-8, but already included in R 4.1.\nFind and replace operations work again in the script editor in\nRgui.\nThe bug reports have revealed that Rgui is frequently used, including\nby users with visual or hand impairments who find Rgui working well\nwith assistive technologies.\nThe bugs were fixed promptly in R-patched. Impacted users may install a\nsnapshot of R-patched in case waiting for the next release would be too\nlimiting.\n3 R 4.2.0 code statistics\nFrom the source code Subversion repository, the overall change between\nMay 18, 2021 and April 22, 2022 (so between R 4.1.0 and R 4.2.0) was:\n29,000 added lines, 20,000 deleted lines and 900 changed files. This is\nrounded to thousands/hundreds and excludes changes to common generated\nfiles, bulk re-organizations, etc. (translations, parsers, Autoconf,\nLAPACK, R Journal bibliography, test outputs, Unicode tables,\nincorporated M4 macros, BLAS, KaTeX files). This is about 10% fewer\nadditions and changed files and about 43% more deletions than between\nR 4.0.0 and R 4.1.0, see News and Notes from the June 2021 issue of the\nR Journal.\nFigure 1 shows commits by month and weekday, respectively,\ncounting line-based changes in individual commits, excluding the files\nas above. The statistics are computed the same way as in the June 2021\nissue, hence allowing direct comparisons. However, monthly statistics\nare impacted by the release date which varies across versions, so the\nnumbers for April and May are somewhat biased. The statistics cover code\ndirectly committed to the trunk, plus commits from the merged branches\nR-groups, R-vecpat. R-ucrt and R-structure. Statistics are based\non the dates of the original commits in the branches, which includes\ncommits from April 2021 (R-groups).\n\n\n\nFigure 1: Commit statistics by month (left) and weekday\n(right) during R 4.2.0 development. *Counts for April 2021 represent\nearly work on the R-groups branch. May 2021 and April 2022 are\npartial months impacted by the release dates.\n4 Acknowledgements\nTomas Kalibera’s work on the article and R development has received\nfunding from the Czech Ministry of Education, Youth and Sports from the\nCzech Operational Programme Research, Development, and Education, under\ngrant agreement No.CZ.02.1.01/0.0/0.0/15_003/0000421, from the European\nResearch Council (ERC) under the European Union’s Horizon 2020 research\nand innovation programme, under grant agreement No. 695412, and from the\nNational Science Foundation award 1925644.\n\n\nCRAN packages used\nknitr, rJava\nCRAN Task Views implied by cited packages\nHighPerformanceComputing, ReproducibleResearch\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2022-2-rfoundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2022-2 issue.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2022-06-01",
    "categories": [],
    "contents": "\n1 Donations and members\nMembership fees and donations received between 2022-03-31 and\n2022-09-05.\nDonations\nNew Elements GmbH (Germany) William Chiu (United States) Giles\nDickenson-Jones (Australia) Jonathan Keane (United States) Daniel\nWollschläger (Germany)\nSupporting institutions\nAlfred Mueller Analytic Services, München (Germany) Chicago R User\nGroup, Chicago (United States) Ef-prime, Inc., Chuo-ku (Japan) KIN\nServices, Tijuana (Mexico) University of Iowa, Iowa City (United States)\nSupporting members\nVedo Alagic (Austria) Mohammed Almozini (Saudi Arabia) Kristoffer\nWinther Balling (Denmark) Joaquín Baquer-Miravete (Spain) Ashanka\nBeligaswatte (Australia) Chris Billingham (United Kingdom) Wesley Brooks\n(United States) Robert Carnell (United States) Rafael Costa (Brazil)\nCharles Cowens (United States) Alistair Cullum (United States) Ajit de\nSilva (United States) Dubravko Dolic (Germany) Mitch Eppley (United\nStates) Guenter Faes (Germany) Leonardo Ferreira (Germany) Gottfried\nFischer (Austria) Ainota Galadriota (United Kingdom) Jutta Gampe\n(Germany) James Harris (United States) Takehiko Hayashi (Japan)\nAlessamdro Ielpi (Canada) ken ikeda (Japan) Anup Jaltade (United States)\nKnut Helge Jensen (Norway) Brian Johnson (United States) Christian\nKampichler (Netherlands) Sebastian Koehler (Germany) Sebastian Krantz\n(Germany) Luca La Rocca (Italy) Teemu Daniel Laajala (Finland) Jindra\nLacko (Czechia) Seungdoe Lee (Korea, Republic of) Zhiguang Li (United\nStates) Eric Lim (United Kingdom) Sharon Machlis (United States) Michal\nMajka (Austria) harvey minnigh (Puerto Rico) Maciej Nasinski (Poland)\nAliaksandr Nekrashevich (Canada) Mark Niemann-Ross (United States) Boris\nNtwoku (United States) Jens Oehlschlägel (Germany) Jaesung James Park\n(Korea, Republic of) Bill Pikounis (United States) Kelly Pisane\n(Netherlands) Andrzej Pokładek (Poland) Davor Pranjic (United States)\nSrivatsan Raghunathan (India) Sindri Shtepani (Canada) Murray Sondergard\n(Canada) Marco Steenbergen (Switzerland) Berthold Stegemann (Germany)\nMichael Tiefelsdorf (United States) Nicholas Turner (United States)\nPhilipp Upravitelev (Russian Federation) Mark van der Loo (Netherlands)\nFrans van Dunné (Costa Rica) Jason Wyse (Ireland) Jaejoong Yun (Korea,\nRepublic of) 杨(Yang) 胡(Hu) (New Zealand)\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2022-2-whyrturkey/",
    "title": "The Conference Report of Why R? Turkey 2022: The First R Conference with Call For Papers in Turkey",
    "description": "Why R? Turkey 2022 was a non-profit conference that aimed to bring Turkish R users together and encourage them to attend the R conferences. The targeted audience of the conference consisted of, data scientists, data analysts, and all R users from academia and industry. The three-day conference, which consisted of several events such as workshops, regular talks, lightning talks, short tutorials, and panels, was free of charge and fully online. This article describes the challenges and benefits, as well as providing an overview of the conference's content and participants’ profile.",
    "author": [
      {
        "name": "Mustafa Cavus",
        "url": {}
      },
      {
        "name": "Olgun Aydin",
        "url": {}
      },
      {
        "name": "Ozan Evkaya",
        "url": {}
      },
      {
        "name": "Derya Turfan",
        "url": {}
      },
      {
        "name": "Filiz Karadag",
        "url": {}
      },
      {
        "name": "Ozancan Ozdemir",
        "url": {}
      },
      {
        "name": "Ugur Dar",
        "url": {}
      },
      {
        "name": "Deniz Bezer",
        "url": {}
      }
    ],
    "date": "2022-06-01",
    "categories": [],
    "contents": "\n1 Motivation\nThe Why R? Turkey 2022 conference was a three-day online conference that was organized as a part of the Why R? Global conference series have been organized annually by the Why R? Foundation since 2017. It is known as one of the largest annual R conferences in Europe (Burdukiewicz et al. 2018, 2019). In addition to the main conference, pre-meetings are held in different cities from all over the world. One of these pre-meetings was organized with the invited speakers in Turkey in 2020. This online event was the first R conference in Turkey. In addition, as a result of the positive feedback received from the participants, the theme of the Why R? Turkey 2021 conference was determined immediately. Thereafter, the second R conference was organized in 2021 with invited speakers (Cavus et al. 2021). The main objective was to bring Turkish R users together from all over the world, the second conference attracted a lot of attention with over 2000 registered participants.\n\n\n\nFigure 1: The logo of Why R? Turkey 2022 Conference\n\n\n\nThe main limitation of the conference in 2021 was that it consisted of invited speakers only. Upon the feedback from the participants, the conference structure was changed into having regular talks, lightning talks. In addition, the conference also had a practical side with workshops for both beginners and more experienced R users. In this way, the conference turned into a more participant-friendly format. The following subsections are summarizing the planning phase and the content of the events.\n2 Planning\nAfter comparing several alternatives, it was decided to continue with Zoom (zoom.us) with one main account and six admins as the main platform for all events.\nA mailing tool called MailChimp, which also has on admin account, was used to establish seamless communication with the scientific committee and all other participants in the organization.\nParticipation certificates for attendees, speakers, workshop tutors and panelists were prepared and delivered by using the Sertifier platform (sertifier.com/tr/) at the end of the conference.\nNumerous academic publishing houses were investigated for publishing proceeding book with E-ISBN and it was decided to work with Nobel Publication House. The electronic version of the proceeding book was provided by the international publishing house.\nWorkshops\nFive workshops (\\(\\sim 1.5\\) hour-long sessions), from beginner level to advanced level were organized. Three of the workshops were held in Turkish and two in English. Thus, it was ensured that participants from all over the world would benefit from them. Detailed contents provided by the tutors for the workshops. Each each workshop was recorded with the consent of the tutor and after the conference videos were published on Youtube. Details and Youtube links for each workshop can be found below.\nIntroduction to R Programming by Ahmet Uraz Akgül (Turkish):\nR programming language is increasing its popularity day by day, including our country, and it has found use in almost every discipline. Being a free software, it has started to reach more people with its access to open source codes and the opportunities it offers. In such an environment, knowing the R programming language provides serious advantages. In the competitive software world, R can survive as a language worth learning; it may even be the language we use most often.\nData Visualization with R by İnan Utku Türkmen and Cansu Hürses (Turkish):\nAs part of the data visualization workshop with R, we will cover basic visualization issues with the ggplot2 (Wickham 2016) package, which is one of the most popular data visualization tools in the field of data science. Using this package we will practice how to create basic static chart types. We will see with examples how a chart can be customized by adding a title, specifying axis names, coloring according to certain categories, marking a specific region on the chart, and taking a section. During the workshop, we will create the interactive graphic in the link below, which is one of the famous visualizations of the Gapminder foundation, using R packages step by step: https://www.gapminder.org/tag/map/.\nProcessing tabular data with tidyverse by İmran Kocabıyık (Turkish):\nMost of the data we use in practice are kept in tabular format. The purpose of use of these data, which are stored in databases and various types of files, may not always be analysis. For this reason, even if the data is kept in tabular form, it requires serious processing to model or analyze it. The dplyr (Wickham et al. 2022) and tidyr (Wickham and Girlich 2022) packages offer very simple and effective solutions for these processes.\nIntroduction to Bioconductor by Nitesh Turaga (English):\nThis talk is an overview of the Bioconductor project which develops, supports, and disseminates free open source software, in the R programming language, that facilitates rigorous and reproducible analysis of data from current and emerging biological assays. The Bioconductor project has a large footprint around the world both in industry and academic research. We’ll discuss the important aspects of project such as methods of contribution, programming paradigms - interoperability and data structure design, and differences to other projects to draw comparison. It will also include a brief introduction to essential genomics data structures that have been pillars to the Bioconductor ecosystem. We welcome participation as we are dedicated to building a diverse, collaborative, and welcoming community of developers and data scientists.\nDeep Learning using R by Krystian Zielinski (English):\nDeep Learning is certainly not a future of technologies that surround us on a daily basis. It’s too late – it’s already here. Just try to find a company that’s not willing to enhance its products with AI driven algorithms. The data is there already, and the trust barrier is shrinking. It’s to nobody’s surprise – if AI is used in very sensitive areas like banking, military or medicine, it can’t be that bad. Netflix’s recommendation algorithms, Google Lens, Self Driving cars – you name it, Deep Learning is used everywhere. Thanks to many popular frameworks, training Neural Network model has never been so easy. You can find tutorials online, and based on them solve many problems. But after some time, the question arises: „How does this even work?” – and you should really know the answer. In the workshops I’d like to show you how theory affects the practice. Based on many examples we will train DNN models, show its limits, check how parameters like e.g. activation function affect the training phase, suggest best practices in data preparation and DNN architecture, explain the model’s predictions. If you’re familiar with R – this workshop is suited for you! If you’re just starting with Deep Learning or already have some experience, come and join us - I bet you won’t regret it!\nShort Tutorials\nIn addition to the workshops, short tutorials on three topics were organized. This type of event was planned to focus on more specific topics in longer duration than a regular talk. (\\(\\sim 30\\) mins each) Each workshop was recorded with the consent of the tutor and after the conference videos were published on Youtube. Details and Youtube links for each workshop can be found below.\nSpatial Analysis with R by Fırat Gündem (Turkish):\nOpen Data Portal applications of local governments both in America and Europe added a serious spatial dimension to data. The spatial dimension in question covers a wide area, from storing data in a way that includes spatial information (shape file, GeoJSON, etc.) to spatial data visualizations and analysis with spatial statistics and spatial econometric methods. The R program is constantly being renewed and expanded to include all spatial analysis techniques in the literature. Although there are many people who do spatial analysis with package programs such as ArcGIS, which are expensive and require personal licenses, RStudio allows to perform all spatial analyzes easily and free of charge with the libraries it contains. In this short study, all the basic steps of spatial analysis will be performed using a set of R libraries. For this, real spatial data from Turkey (GDP per capita on a provincial basis, etc.) will be used. Then, spatial data projection (sf, sp), neighborhood matrix creation and manipulation (rgdal), spatial data visualization and static and dynamic mapping ggplot2 (Wickham 2016), tmap (Tennekes 2018), leaflet (Cheng et al. 2021), three-dimensional mapping rayshader (Morgan-Wall 2021), spatial statistics rgeoda (Li and Anselin 2022) in RStudio. and spatial econometric models will be introduced practically using the relevant R libraries. Thus, all necessary tools for spatial data science will be introduced in R and the use of R will be encouraged with user-friendly applications.\nThe R Application for Physics-Informed Neural Networks by Melih Ağraz (Turkish):\nPhysics-Informed Neural Networks (PINNs) is a deep learning framework designed to solve nonlinear differential equations using artificial neural networks, published in 2019. Simple deep feed-forward neural network architectures and automatic differentiation method are used to solve differential equations in PINNs method. The PINNs method was first developed with Python Tensorflow. In this study, we will show how the solution of the equation \\(y'-y=0\\) for \\(y(0)=1\\), \\(y(1)=e\\) is solved by using reticulate (Ushey et al. 2021) library in R, with the help of PINNs method. This study is thought to find application area of PINNs method for R users as well. For this reason, a simple differential equation solution example such as \\(y' - y = 0\\) is preferred.\nServerless R in the Cloud - Deploying R into Production with AWS and Docker by İsmail Tigrek (English):\nThis tutorial will walk through deploying R code, machine learning models, or Shiny applications in the cloud environment. With this knowledge, you will be able to take any local R-based project you’ve built on your machine or at your company and deploy it into production on AWS using modern serverless and microservices architectures. In order to do this, you will learn how to properly containerize R code using Docker, allowing you to create reproducible environments. You will also learn how to set up event-based and time-based triggers. We will build out a real example that reads in live data, processes it, and writes it into a data lake, all in the cloud.\nPanels\nThe panels were planned based on the sharing experience in an interactive environment, where the participants could come together with experts in different domains. Biostatistics and R Education were selected as major topics in these events. The links to the video recordings and detailed content of the panels are given below:\nBiostatistics and Applications in R moderated by Prof. Dr. Ergun Karaağaoğlu (Turkish):\nProf. Dr. Recai Yücel (Temple University), Prof. Dr. Mithat Gönen (Memorial Sloan Kettering Cancer Center), and Dr. Anıl Dolgun (CSL Limited) attended as the panelists. In this panel, current research studies on biostatistics and the importance of using R in this domain were discussed. In addition, information about how career development was positively affected by using R was shared by the panelists with the audience. Thus, it was ensured that the participants were informed about the importance of the R in this field.\nR Education moderated by Olgun Aydin (Turkish):\nThe main topic of the panel was how to teach R in academia. Prof. Dr. Mine Çetinkaya-Rundel (Duke University), Dr. Mine Doğucu (University of California), and Assoc. Prof. Dr. Kübra Kabasakal (Hacettepe University) attended as the panelists. The panelists shared their approach in terms of teaching R in different fields of academic stuides. Moreoever, the panelists shared examples from their teaching materials with the audience.\n3 Participants\nThe \\(1366\\) participants were registered for the conference: \\(70\\%\\) of the participants were students and the rest were professionals who work for governmental institutions, companies from the private sector, and as academicians. The \\(43\\%\\) of the students are undergraduates, \\(26\\%\\) of them master studies and the \\(31\\%\\) are Ph.D. students.\n\n\n\nFigure 2: The percentage of the degree of the participant students by years\n\n\n\nWhen the channels that the participants heard about the conference are examined, surprisingly, the percentage of participants who registered for the conference “on recommendation” was quite high (\\(26\\%\\)), in addition to the social media channels (LinkedIn - \\(30\\%\\), Twitter - \\(26\\%\\), and Instagram - \\(12\\%\\)) of which usage has increased in recent years.\n\n\n\nFigure 3: How did the participants hear about the conference?\n\n\n\nIn the registration form, questions about participants’ level of R knowledge and motivation of participants’ to take part in Why R? Turkey 2022 were included to deeply analyze profile of the participants. The \\(69\\%\\) of the participants stated that they had taken or attended a course related to R before. They evaluated their R programming language usage levels as shown in Table 1.\n\n\n\nIt can be seen from Table 1 that \\(90\\%\\) of them did not attend a conference about R before. In this respect, the conference was held with an audience suitable for the purpose of expanding usage of R. The areas of their interest are Data Visualization, Statistical Modeling, Big Data, Data Mining, Machine Learning, and Deep Learning, respectively. The events planned for Why R? Turkey 2022 that motivated them register the conference are respectively: Scientific Sessions (\\(40\\%\\)), Workshops (\\(35\\%\\)) and Panels (\\(26\\%\\)).\n4 Evaluation\nAn evaluation questionnaire was conducted after the event to measure the satisfaction with the conference and to collect suggestions future organizations (Cordoba et al. 2019). The satisfaction part of the questionnaire consists of two questions: (1) general satisfaction and (2) the interaction level between the presenters and the listeners. The results of the questionnaire are quite positive in terms of the answer of the respondents. On a scale of \\(0-5\\), the mean of the satisfaction score is \\(4.74\\) with \\(0.46\\) standard deviation. Besides that, the mean of the interaction score is \\(4.50\\) with \\(0.69\\) standard deviation.\nThe second part of the questionnaire consists of the questions related to the motivation of the respondents regarding attendance and being a presenter for the next edition of the conference. According to the responses, although nearly all of the respondents (\\(99\\%\\)) plan to attend the conference in the next years, \\(30\\%\\) aim to participate to as a presenter.\nThe last part of the questionnaire is about the suggestions from the respondents. The suggestions generally focus on increasing the duration of regular talks and workshops. In addition, among the speakers, the higher number of private sector employees and the mention of sector or freelance job opportunities were among the most prominent suggestions. Respondents strongly mentioned that next events, which has been held online for two years, should be held face-to-face in the coming years to increase its effectiveness.\n5 Summary\nWhy R? Turkey 2022, as the next edition of Why R? Turkey 2021 conference, was the first R conference with call for papers held in Turkey. This conference aimed to encourage researchers and professionals, who are R users and developers, to share their work with a wider audience. This conference was organized as a user-friendly conference, taking into account the feedback received in the previous year’s version. In addition to scientific sessions, workshops, short tutorials, and panels were organized to broaden the content of the event. According to the evaluation survey made right after the conference, the participants stated that they were very satisfied and they would like to participate as a presenter to Why R conferences in the upcoming years. This finding demonstrates that the organisers of the conference succeeded the goals.\n6 Organizers\nThe Organizing Committee of Why R? Turkey 2022 consisted of eight Turkish researchers from three different countries: Turkey, Poland, and United Kingdom. It consisted of Mustafa Cavus (Warsaw University of Technology, Eskisehir Technical University), Olgun Aydin (Gdansk University of Technology, Why R? Foundation), Filiz Karadag (Ege University), Ugur Dar (Eskisehir Technical University), Ozan Evkaya (University of Edinburgh), Derya Turfan (Hacettepe University), Ozancan Ozdemir, Deniz Bezer (Middle East Technical University).\n7 Acknowledgement\nAs an organization committee, we would like to thank for his suggestions and support during the preparation part of the conference, for designing our graphics, and , for their guidance in general and also organizing the some of the panels and workshops. Moreover, we would like to thank the sponsors that support the Why R? Turkey 2022, , as gold sponsor, as the award sponsor, and silver sponsor.\n8 Additional Information\nFurther information about the conference such as website of the conference, recordings for regular, lightning talks, workshops and panels, materials, proceeding book and social media accounts used for the conference can be reached out via following links:\nWebsite: https://whyr.pl/2022/turkey/\nAbstract book: https://www.nobelyayin.com/why-r-turkiye-2022-konferansi-18447.html\nYouTube channel: https://www.youtube.com/c/WhyRTurkey\nTwitter: https://twitter.com/whyrturkey\nLinkedIn: https://www.linkedin.com/company/why-r-turkey/\nInstagram: https://www.instagram.com/whyrturkey/\n\nCRAN packages used\nggplot2, dplyr, tidyr, tmap, leaflet, rgeoda, reticulate\nCRAN Task Views implied by cited packages\nDatabases, Epidemiology, HighPerformanceComputing, MissingData, ModelDeployment, NumericalMathematics, OfficialStatistics, Phylogenetics, Spatial, TeachingStatistics\n\n\nM. Burdukiewicz, M. Karas, L. E. Jessen, M. Kosinski, B. Bischl and S. Rödiger. Conference report: Why r? 2018. R Journal, 10(2): 572–578, 2018. URL https://doi.org/10.32614/RJ-2018-2-whyR.\n\n\nM. Burdukiewicz, F. Pietluch, J. Chilimoniuk, K. Sidorczuk, D. Rafacz, L. E. Jessen, S. Rödiger, M. Kosinski and P. Wojcik. Conference report: Why r? 2019. R Journal, 12(1): 484–493, 2019. URL https://doi.org/10.1080/10618600.1996.10474713.\n\n\nM. Cavus, O. Aydin, O. Evkaya, O. Ozdemir, D. Bezer and U. Dar. Conference report of why r? Turkey 2021. R Journal, 13(1): 648–653, 2021. URL https://journal.r-project.org/archive/2021-1/whyr2021.pdf.\n\n\nJ. Cheng, B. Karambelkar and Y. Xie. Leaflet: Create interactive web maps with the JavaScript ’leaflet’ library. 2021. URL https://CRAN.R-project.org/package=leaflet. R package version 2.0.4.1.\n\n\nM. A. Cordoba, F. Dunne, A. G. Melendez and J. Etten. Conference report: ConectaR2019. R Journal, 11(2): 439–442, 2019.\n\n\nX. Li and L. Anselin. Rgeoda: R library for spatial data analysis. 2022. https://github.com/geodacenter/rgeoda/, https://geodacenter.github.io/rgeoda/.\n\n\nT. Morgan-Wall. Rayshader: Create maps and visualize data in 2D and 3D. 2021. URL https://CRAN.R-project.org/package=rayshader. R package version 0.24.10.\n\n\nM. Tennekes. tmap: Thematic maps in R. Journal of Statistical Software, 84(6): 1–39, 2018. DOI 10.18637/jss.v084.i06.\n\n\nK. Ushey, J. Allaire and Y. Tang. Reticulate: Interface to ’python’. 2021. URL https://CRAN.R-project.org/package=reticulate. R package version 1.20.\n\n\nH. Wickham. ggplot2: Elegant graphics for data analysis. Springer-Verlag New York, 2016. URL https://ggplot2.tidyverse.org.\n\n\nH. Wickham, R. François, L. Henry and K. Müller. Dplyr: A grammar of data manipulation. 2022. https://dplyr.tidyverse.org, https://github.com/tidyverse/dplyr.\n\n\nH. Wickham and M. Girlich. Tidyr: Tidy messy data. 2022. https://tidyr.tidyverse.org, https://github.com/tidyverse/tidyr.\n\n\n\n\n",
    "preview": "news/RJ-2022-2-whyrturkey/distill-preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 1292,
    "preview_height": 1290
  },
  {
    "path": "news/RJ-2022-1-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2022-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2022-03-01",
    "categories": [],
    "contents": "\n\nIn the past 3 months, 617 new packages were added to the CRAN package\nrepository. 86 packages were unarchived and 307 were archived. The\nfollowing shows the growth of the number of active packages in the CRAN\npackage repository:\n\nOn 2022-03-31, the number of active packages was around 18924.\nChanges in the CRAN Repository Policy\nThe Policy now\nsays the following:\n(Using external C/C++/Fortran libraries.) Where a package wishes\nto make use of a library not written solely for the package, the\npackage installation should first look to see if it is already\ninstalled and if so is of a suitable version. In case not, it is\ndesirable to include the library sources in the package and compile\nthem as part of package installation. If the sources are too large,\nit is acceptable to download them as part of installation, but do\nensure that the download is of a fixed version rather than the\nlatest. Only as a last resort and with the agreement of the CRAN\nteam should a package download pre-compiled software.\nOn Windows and macOS static libraries must be used. A separate\ndocument, External Libraries for CRAN\npackages,\ncovers what external libraries are or could be made available.\nCRAN package submissions\nDuring the first 4 months of 2022 (January 2022 to April 2022), CRAN\nreceived 9601 package submissions. For these, 17170 actions took place\nof which 11232 (65%) were auto processed actions and 5938 (35%) manual\nactions.\nMinus some special cases, a summary of the auto-processed and manually\ntriggered actions follows:\n\narchive\ninspect\nnewbies\npending\npretest\npublish\nrecheck\nwaiting\nauto\n2391\n2716\n1392\n0\n0\n3018\n1017\n698\nmanual\n1893\n93\n487\n323\n106\n2232\n637\n167\nThese include the final decisions for the submissions which were\naction\narchive\npublish\nauto\n2232 (23.9%)\n2479 (26.5%)\nmanual\n1870 (20.0%)\n2758 (29.5%)\nwhere we only count those as auto processed whose publication or\nrejection happened automatically in all steps.\nA new team member, Viktoria Wimmer, joined the CRAN submission team.\nWelcome, Viktoria. Unfortunately, Julia Haider left the CRAN submission\nteam after processing 3517 incoming submissions. Thanks a lot!\nCRAN mirror security\nCurrently, there are 102 official CRAN mirrors, 81 of which provide both\nsecure downloads via https and use secure mirroring from the CRAN\nmaster (via rsync through ssh tunnels). Since the R 3.4.0 release,\nchooseCRANmirror() offers these mirrors in preference to the others\nwhich are not fully secured (yet).\nCRAN Task View Initiative\nThe transition of the established task views to the new workflow on\nGitHub (https://github.com/cran-task-views/ctv/) that was announced in\nthe previous volume of the journal has been completed (see also\nhttps://twitter.com/AchimZeileis/status/1510945091980038145).\nEach task view now links to a GitHub repository where it is possible to\npost issues and make pull requests for proposing improvements – in\naddition to sending e-mails to the maintainer address which is still\npossible, of course. Moreover, the task view web pages contain further\nimprovements like a citation, installation notes, and a streamlined\noverview of core and regular (and currently archived) packages in the\ntask view.\nProposals of new task views are now also possible on GitHub. In fact, a\nfew have already been made for the topics causal inference, genetics and\ngenomics (as a follow-up to the orphaned and archived Genetics and\nPhylogenetics views), and sports analytics.\nWe look forward to further user contributions to the initiative!\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2022-1-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in The R Journal.",
    "author": [
      {
        "name": "Catherine Hurley",
        "url": "https://journal.r-project.org"
      }
    ],
    "date": "2022-03-01",
    "categories": [],
    "contents": "\nOn behalf of the editorial board, I am pleased to present Volume 14 Issue 1 of the R Journal. This\nissue heralds a switch from two issues per year to four and is my first as Editor-in-Chief. The change to four issues per year is in response to the increase in published articles in recent years. As articles will appear more speedily\nin a published issue, we will no longer list pdfs for Accepted articles on The R Journal website.\nFirst, some news about the journal board. Dianne Cook has stepped down as Editor-in-Chief but continues as an Executive Editor. In her time as EIC she provided excellent leadership and brought in many advances, most notably the change to the new modern journal format. One new Associate Editor, Simone Blomberg, has recently joined the team. We have a new, slimmed-down Editorial advisory board consisting of Henrik Bengtssen, Gabriela de Quiroz, Michael Kane and Rececca Killick. The board will provide continuity across changes in the editorial board, offering advice and acting as an independent body to handle issues of academic integrity.\nBehind the scenes, several people are assisting with the journal operations and the new developments. Mitchell O’Hara-Wild continues to work on infrastructure, and H. Sherry Zhang continues to develop the rjtools package. In addition, articles in this issue have been carefully copy edited by Hannah Comiskey.\n1 In this issue\nNews from the CRAN and the R Foundation are included in this issue.\nThis issue features 22 contributed research articles the majority of which relate to R packages\nfor modelling tasks. All packages are available on CRAN. Topics covered are:\nTemporal and longitudinal methods\ncpsurvsim: An R Package for Simulating Data from Change-Point Hazard Distributions\nThe smoots Package in R for Semiparametric Modeling of Trend Stationary Time Series\nstarvars: An R Package for Analysing Nonlinearities in Multivariate Time Series\nFMM: An R package for modeling rhythmic patterns on oscillatory systems\ntvReg: Time-varying Coefficients in Multi-Equation Regression in R\nPower and Sample Size for Longitudinal Models in R - The longpower Package and Shiny App\n\nEstimation and inference\ndglars A Software Tool For Sparse Estimation Of A General Class Of High-dimensional GLMs\nbayesanova: An R package for Bayesian inference in the analysis of variance via Markov Chain Monte Carlo in Gaussian mixture models\nRKHSMetaMod: An R package to estimate the Hoeffding decomposition of a complex model by solving RKHS ridge group sparse optimization problem\nPSweight: An R Package for PropensityScore Weighting Analysis\n\nMachine learning\nRFpredInterval: An R Package for Prediction Intervals with Random Forests and Boosted Forests\nfairmodels: A Flexible Tool For Bias Detection, Visualization, And Mitigation Graphics and Visualisation, Machine Learning & Statistical Learning\nspherepc: An R Package for Dimension Reduction on a Sphere\n\nOther topics\nblindrecalc: An R Package for Blinded Sample Size Recalculation\nrmonad: Pipelines you can compute on\netrm: Energy Trading and Risk Management in R\nfcaR, Formal Concept Analysis with R\nAdvancing reproducible research by publishing R markdown notebooks as interactive sandboxes using the learnr package\n\nApplications\nPalmer Archipelago Penguins Data in the palmerpenguins R Package - An Alternative to Anderson’s Irises\nA Computational Analysis of the Dynamics of R Style Based on 94 Million Lines of Code from All CRAN Packages in the Past 20 Years\nMeasuring the Extent and Patterns of Urban Shrinkage for Small Towns Using R\nRevisiting Historical Bar Graphics on Epidemics in the Era of R ggplot2\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2022-1-RFoundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2022-1 issue.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2022-03-01",
    "categories": [],
    "contents": "\n1 Donations and members\nMembership fees and donations received between 2021-12-22 and\n2022-03-30.\nDonations\nRV Detailing Pros of San Diego (United States) Shalese Fitzgerald\n(United States) Ken Ikeda (Japan) Rees Morrison (United States) Rav Vaid\n(United States) Clay Valarezo (United States) Kai Wu (China)\nSupporting benefactors\nUniversità degli Studi di Padova, Padova (Italy)\nSupporting institutions\nInstitute of Botany of the Czech Academy of Sciences, Pruhonice\n(Czechia) oikostat GmbH, Ettiswil (Switzerland)\nSupporting members\nConstantin Ahlmann-Eltze (Germany) Vedo Alagic (Austria) Takaharu Araki\n(Japan) Frederic Bertrand (France) Michael Blanks (United States) Cédric\nChambru (Switzerland) John Chandler (United States) Michael Chirico\n(United States) Gerard Conaghan (United Kingdom) Brandon Dahl (United\nStates) Michael Dorman (Israel) Fraser Edwards (United Kingdom) Johan\nEklund (Sweden) S Ellison (United Kingdom) Dane Evans (United States)\nIsaac Florence (United Kingdom) Neil Frazer (United States) Bernd\n(Germany) Jan Marvin Garbuszus (Germany) Gabriel Gersztein (Brazil)\nBrian Gramberg (Netherlands) Spencer Graves (United States) Hlynur\nHallgrímsson (Iceland) Philippe Heymans Smith (Costa Rica) Alexander\nHuelle (Germany) Heidi Imker (United States) Gavin Kirby (United\nKingdom) Ziyad Knio (United States) Gen Kobayashi (Japan) Adrien Le\nGuillou (France) Yuewei Liu (China) Myriam Maumy (France) Daniel\nMcNichol (United States) Bogdan-Alexandru Micu (Luxembourg) Ernst\nMolitor (Germany) David Monterde (Spain) Stefan Moog (Germany) Steffen\nMoritz (Germany) Antonio Paez (Canada) Fergus Reig Gracia (Spain)\nStefano Rezzonico (Canada) Ingo Ruczinski (United States) Choonghyun Ryu\n(Korea, Republic of) Dejan Schuster (Germany) John Smith (United States)\nHarald Sterly (Germany) Kai Streicher (Switzerland) Robert van den Berg\n(Austria) Dr. Alfred Wagner (Germany) Petr Waldauf (Czechia) Fredrik\nWartenberg (Sweden) 广宇 曾 (China)\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2021-2-bioc/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2021-2 issue.",
    "author": [
      {
        "name": "Bioconductor Core Team",
        "url": {}
      }
    ],
    "date": "2021-12-01",
    "categories": [],
    "contents": "\n\nBioconductor provides tools for the analysis\nand comprehension of high-throughput genomic data. Bioconductor 3.14 was\nreleased on 27 October, 2021. It is compatible with R 4.1.0 and consists\nof 2083 software packages, 408 experiment data packages, 904 up-to-date\nannotation packages, and 29 workflows.\nThe project has developed, over the last several years, the\n‘AnnotationHub’ and ‘ExperimentHub’ resources for serving and managing\ngenome-scale annotation data, e.g., from the TCGA, NCBI, and Ensembl. At\nthe time of release there were 60134 records in the AnnotationHub, and\n6075 ExperimentHub records. See the WaldronLab shiny\napp to get an overview\nof the AnnotationHub.\nBook production continues in\nthis release. Books are built regularly from source and therefore fully\nreproducible; an example is the community-developed Orchestrating\nSingle-Cell Analysis with\nBioconductor.\nThe Bioconductor 3.14 release\nannouncement includes\ndescriptions of 89 new software packages, and updates to NEWS files for\nmany additional packages. Start using Bioconductor by installing the\nmost recent version of R and evaluating the commands\n  if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n      install.packages(\"BiocManager\")\n  BiocManager::install()\nInstall additional packages and dependencies, e.g.,\nSingleCellExperiment,\nwith\n  BiocManager::install(\"SingleCellExperiment\")\nDocker images provide a very\neffective on-ramp for power users to rapidly obtain access to\nstandardized and scalable computing environments.\nKey learning resources include:\nbioconductor.org to install, learn, use,\nand develop Bioconductor packages.\nA list of available software,\nlinking to pages describing each package.\nA question-and-answer style user support\nsite and developer-oriented\nmailing list.\nA community slack (sign up)\nfor extended technical discussion.\nThe F1000Research Bioconductor\nchannel for\npeer-reviewed Bioconductor work flows.\nThe Bioconductor\nYouTube channel includes\nrecordings of keynote and talks from recent conferences including\nBioc2021 and BiocAsia2021, in addition to video recordings of\ntraining courses.\nOur package\nsubmission\nrepository for open technical review of new packages.\nThe 2021 Bioconductor conference\nwas held in a virtual format August 4-6, 2021.\nIn conjunction with the Mexican Bioinformatics\nNetwork and the Nodo Nacional de\nBioinformática CCG UNAM, the Comunidad de\nDesarrolladores de Software en Bioinformática held two week-long online\nworkshops\naddressing development of workflows with RStudio and\nshiny and\nanalysis of single-cell RNA-seq\nexperiments,\nAugust 9-13, 2021.\nBiocAsia 2021 was held\nNovember 1-4 2021 as a virtual event. The\nBiopackathon project has\nmany points of contact with Bioconductor and recurs monthly.\nThe National Human Genome Research Institute’s Analysis and\nVisualization Laboratory (AnVIL) is\ndeveloping with contributions from Bioconductor core team members.\nExtensive background\nmaterial\nincludes a series of recorded workshops.\nThe Bioconductor project continues to mature as a community. The\nTechnical\nand\nCommunity\nAdvisory Boards provide guidance to ensure that the project addresses\nleading-edge biological problems with advanced technical approaches, and\nadopts practices (such as a project-wide Code of\nConduct) that\nencourages all to participate. We look forward to welcoming you!\n\n\nBioconductor packages used\nSingleCellExperiment\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2021-2-core/",
    "title": "Changes in R",
    "description": "We present important changes in the development version of R (referred to as R-devel, to become R 4.2) and give a summary of the new search engine interfaced by `RSiteSearch()`. Some statistics on bug tracking activities in 2021 are also provided.",
    "author": [
      {
        "name": "Tomas Kalibera",
        "url": {}
      },
      {
        "name": "Sebastian Meyer",
        "url": {}
      },
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Gennadiy Starostin",
        "url": {}
      },
      {
        "name": "Luke Tierney",
        "url": {}
      }
    ],
    "date": "2021-12-01",
    "categories": [],
    "contents": "\n\n1 R-devel selected changes\nR 4.2.0 is due to be released around April 2022. The following gives a\nselection of the most important changes in R-devel, which are likely to\nappear in the new release.\nNative UTF-8 support and other changes on Windows\nR on Windows now uses UTF-8 as the native encoding. This feature\nrequires recent Windows 10 or newer (or Windows Server 2022 or newer).\nOn older systems, a (non-Unicode) system locale encoding will be used as\nin earlier versions of R. With this feature, it is now possible to work\nwith characters not representable in the locale encoding (e.g., with\nAsian characters on European locales). Previously, such characters could\nonly be used with considerable care needed to prevent their\nmis-representation or undesirable substitution. It is now possible to\nuse Unicode characters even in Rterm, the console front-end for R.\nTo make this possible, R switched to the Universal C Runtime (UCRT),\nwhich is the new C library on Windows and has to be installed manually\non Windows 8.1 and older. The switch required a new toolchain targeting\nUCRT. All code linked statically to R or R packages has to be rebuilt.\nTherefore, a new toolchain bundle, Rtools42, has been created which\nincludes a recent GCC 10 compiler toolchain targeting 64-bit UCRT and a\nset of pre-compiled static libraries for R packages. R and CRAN use this\nnew toolchain for R-devel (to become R 4.2.0). Older versions of R will\nstill use older toolchains. As from 4.2, R on Windows will no longer\nsupport 32-bit builds. Rtools42, containing only the 64-bit toolchain,\nis one step simpler to install for users than the earlier toolchain\nbundle.\nThe change so far required updates of over 100 CRAN packages and several\nof their Bioconductor dependencies. As these packages have a very large\nnumber of reverse dependencies (packages depending recursively on them),\nR gained support for automated installation-time patching of packages,\nso that packages can be quickly patched and their reverse dependencies\ntested, giving package authors more time to incorporate the updates.\nThis feature is experimental and may be removed in the future.\nR allows package authors to maintain the same package sources for R 4.2\n(Rtools42) and R 4.1 (Rtools40) by supporting Makevars.ucrt and other\nmake/configuration files with extension .ucrt which are used by R 4.2\nin preference of their existing .win variants, but ignored by older\nversions of R. Both toolchain bundles can coexist on the same machine.\nThe work on the toolchain and on testing CRAN packages has lead to the\ndiscovery of new bugs in GCC: invalid unwind tables causing crashes (GCC\nPR#103274), inconsistency in option handling related to unwind tables\n(GCC PR#103465) and lack of support for UCRT/C99 format strings (GCC\nPR#95130). Additional bugs were found that turned out to be fixed\nalready in later versions of GCC, but required a back-port (GCC\nPR#101238, GCC PR#100402). Thanks to MinGW-W64 developer Martin Storsjo\nand GCC developers Eric Botcazou and Martin Liska for their help with\nidentifying and resolving the issues. The Rtools42 toolchain bundle\nincludes patches for these and other, smaller, issues.\nFollowing the philosophy that disruptive changes for users and package\nauthors should be rare, this seemed a good time to change also the\ndefault personal library location. Now it is a subdirectory of the Local\nApplication Data directory (usually a hidden directory\nC:\\\\Users\\\\username\\\\AppData\\\\Local). This is to follow Windows\nconventions, but also to avoid problems users experienced with various\ncloud backup/syncing services enabled by default for the personal\ndirectory (usually C:\\\\Users\\\\username\\\\Documents). For the very same\nreason, the default installation location for user-only installation has\nbeen changed to C:\\\\Users\\\\username\\\\AppData\\\\Local\\\\Programs.\nAdditional bug fixes (e.g., for handling previously untested code paths\ninvolving characters not representable in system locale encoding) and\nimprovements (e.g., removal of workarounds no longer needed with UCRT)\nare being added following testing and reports from package authors and\nare to appear in R 4.2.\nMore details on the changes in R for Windows and on what is required\nfrom package authors are available in Tomas Kalibera et al. blog\npost\nand material linked from there.\nGraphics changes\nSupport for isolated groups, compositing operators, affine\ntransformations, and stroking and filling paths has been added to the R\ngraphics engine. The existing support for masks has also been expanded\nto include luminance masks. An R-level interface for these new features\nhas been added to the grid graphics package. See Paul Murrell’s blog\npost\nfor more details. The changes to the R graphics engine mean that\npackages that provide graphics devices, such as the ragg package, will\nneed to be reinstalled.\nHash tables\nHash tables are data structures used to efficiently map keys to\nvalues. Keys can be simple, such as strings or symbols, or more\ncomplex objects, such as environments. Hash tables can be thought of as\ngeneralizations of environments that allow more general key objects,\nthough without the notion of a parent table. Like environments, and\nunlike most objects in R, hash tables are mutable.\nHash tables have been used internally in R for many years, in particular\nin match(), unique(), and duplicate(), to improve the efficiency\nof these functions. R-devel now provides an R level interface to the\nhash table infrastructure used in these functions. The R level interface\nis provided in package utils. New hash tables are created by\nhashtab(); entries are created or modified by sethash(), and values\nare retrieved with gethash(). More details are available in the help\npage for hashtab(). The R level interface is based loosely on hash\ntable support in Common Lisp.\nA C level interface will eventually be made available in the C API as\nwell. The details are still under development. Comparison of keys\ntypically is based on identical(), but can also be based on the memory\naddresses of keys. Address-equality based tables are most likely to be\nuseful at the C level. For address-based hash tables it may be useful to\nprovide a weak version in which keys are not protected from garbage\ncollection and entries are scheduled for removal once keys are\ndetermined to no longer be reachable.\nOther selected changes\nmatrix(x, n, m) now warns in more cases where length(x) differs\nfrom n * m, as suggested by Abby Spurdle and Wolfgang Huber in\nFebruary 2021 on the R-devel mailing list. This warning can be\nturned into an error by setting environment variable\n_R_CHECK_MATRIX_DATA_ to TRUE: R CMD check –as-cran does so\nunless it is already set.\nsimplify2array() gains an except argument for controlling the\nexceptions used by sapply().\nR on Windows now uses the system memory allocator. Doug Lea’s\nallocator was used since R 1.2.0 to mitigate performance limitations\nseen with system allocators on earlier versions of Windows.\nR gains more classed errors. Attempting to subset an object that is\nnot subsettable now signals an error of class notSubsettableError,\nwith the non-subsettable object contained in the object field of\nthe error condition. Also, subscript-out-of-bounds and\nstack-overflow errors are now signaled as errors of class,\nrespectively, subscriptOutOfBoundsError and stackOverflowError.\nNew partly experimental Sys.setLanguage() utility, solving the\nmain problem of\nPR #18055.\nDeparsing no longer remaps attribute names dim, dimnames,\nlevels, names and tsp to historical S-compatible names (which\nstructure() maps back).\n2 Bug statistics for 2021\nSummaries of bug-related activities over the past year were derived from\nthe database underlying R’s Bugzilla\nsystem. Overall, 244 new bugs or requests\nfor enhancements were reported, 220 reports were closed, and 1065\ncomments (on any report) were added by a total of 115 contributors. This\namounts to averages of about two new reports and two closures over three\ndays, and three comments per day. All totals are about 30% lower than in\n2020, especially the number of closures. High bug activity in 2020 had\nlargely been driven by dedicated efforts of several contributors in\nreviewing old reports.\n\n\n\nFigure 1: Bug tracking activity by month (left) and weekday\n(right) in 2021.\nFigure 1 shows statistics for the numbers of new\nreports, closures and comments by calendar month and weekday,\nrespectively, in 2021. The frequency of new reports was relatively\nstable over the year except for a low in March/April. There tended to be\nmore new reports than closures, but this was reversed in\nNovember/December in a revived effort to address old reports. The top 5\ncomponents reporters have chosen for their reports were “Low-level”,\n“Language”, “Documentation”, “Misc”, and “Wishlist”, which is the same\nset as in 2020. Many reports are suggestions for enhancements and marked\nas Wishlist but are sometimes also put in a specific component, ideally\nwith severity level “enhancement”.\nBug discussions led to an average of 65 comments each month from January\nto August 2021, which is less than in the same period of 2020 with an\naverage of 140 comments each month. Comment activity has increased again\nin late 2021.\nLast but not least, from the numbers by weekday in the right panels of\nFigure 1 we see that the R community is also active\nduring weekends, though at a lower frequency.\n3 Relaunch of search.R-project.org\nA long time ago, Jonathan Baron (University of Pennsylvania, USA)\ncreated an “R Site Search” database and has for many years provided a\nweb service for queries into this database, allowing the community to\nsearch help files of CRAN packages, task views, vignettes, and initially\nalso the R-help mail archive. This web service was made available as\nhttps://search.R-project.org, with simple and advanced R interfaces\nprovided by, respectively, functions RSiteSearch() in package utils\nand CRAN package sos (see\nthe corresponding article on “Searching Help Pages of R Packages” in the\nR\nJournal).\nThe next generation of this web service was developed by Gennadiy\nStarostin and is now hosted at Wirtschaftsuniversität Wien, Austria. In\ndoing so, there were two major changes.\nFirst, the old service was based on the namazu search engine\n(http://www.namazu.org/), which is no longer actively developed (last\nrelease more than ten years old). After careful examination of available\nopen-source alternatives xapian-omega (https://xapian.org/) was chosen\nas the new search engine, which provides the necessary versatility\nalongside reasonable complexity. The most notable features of xapian are\nranked search, phrase and proximity searching, Boolean search operators,\nBoolean filters, support for stemming of search terms, and allowing\nsimultaneous update and searching.\nFor compatibility reasons the server still supports requests in the\npreviously used namazu format (limited to the parameters used by the\nformer search engine). This compatibility feature may be dropped in the\nfuture.\nIn addition to the human-readable output of search results, two other\nformats are made available: “xml” and “opensearch”. Simply change in the\nURL FMT=query to either FMT=xml or FMT=opensearch when sending a\nHTTP GET request to the server. One can tailor search queries using\nadditional parameters, see the query part of the URL in the default form\nand the xapian-omega documentation.\nSecond, the covered CRAN content was expanded. Currently, there are\neight categories, any combination of which can be searched\nsimultaneously:\nR manuals (currently based on the R-patched development branch)\nHelp pages of base packages (also from R-patched)\nCRAN packages (5 categories): general info, news, readme files,\nvignettes, and help pages\nCRAN task views\nAlthough content of the majority of these categories is available on\nCRAN to read and explore, two of them, the help pages of base and CRAN\npackages, are additionally generated for search.R-project.org. As of\nDecember 22, 2021, in terms of searchable documents they constitute\napproximately 400,000 out of 450,000 total (about 89%).\nGenerating this content was not straightforward. HTML content is\npreferable to PDF content for browsing search results, but the new R\nhelp system works best for dynamic HTML (see the corresponding article\nin the R\nJournal),\nwhereas for the search service, using static HTML is more appropriate.\nThe code for generating static HTML needed a bit of tweaking by Deepayan\nSarkar and Kurt Hornik, and now can (again) be used to provide help\nfiles which are good for both searching and browsing.\nIn the future, search.R-project.org may be expanded with relevant\nsources outside of CRAN, e.g., the Bioconductor project. Depending on\nuser feedback, which is always welcome, one can expect other\nimprovements.\n4 Acknowledgements\nTomas Kalibera’s work on the article and R development has received\nfunding from the Czech Ministry of Education, Youth and Sports from the\nCzech Operational Programme Research, Development, and Education, under\ngrant agreement No.CZ.02.1.01/0.0/0.0/15_003/0000421, from the European\nResearch Council (ERC) under the European Union’s Horizon 2020 research\nand innovation programme, under grant agreement No. 695412, and from the\nNational Science Foundation award 1925644.\n\n\nCRAN packages used\nsos\nCRAN Task Views implied by cited packages\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2021-2-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2021-2 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2021-12-01",
    "categories": [],
    "contents": "\n\nIn the past 6 months, 1077 new packages were added to the CRAN package\nrepository. 113 packages were unarchived and 331 were archived. The\nfollowing shows the growth of the number of active packages in the CRAN\npackage repository:\n\nOn 2021-12-31, the number of active packages was around 18650.\nChanges in the CRAN Repository Policy\nThe Policy now\nsays the following:\nYou can check that the submission was received by looking at\nhttps://CRAN.R-project.org/incoming/.\nA package showing issues for macos-arm64 or an ‘M1mac’ additional\nissue should be checked using the\nmacbuilder\nservice prior to re-submission.\nCRAN package submissions\nDuring the last half of 2021 (July 2021 to December 2021), CRAN received\n12256 package submissions. For these, 21622 actions took place of which\n14232 (66%) were auto processed actions and 7390 (34%) manual actions.\nMinus some special cases, a summary of the auto-processed and manually\ntriggered actions follows:\n\n\narchive\ninspect\nnewbies\npending\npretest\npublish\nrecheck\nwaiting\nauto\n2748\n2722\n2577\n0\n0\n3899\n1362\n924\nmanual\n2760\n102\n336\n464\n91\n2797\n671\n169\n\nThese include the final decisions for the submissions which were\n\naction\narchive\npublish\nauto\n2586 (21.5%)\n3336 (27.8%)\nmanual\n2728 (22.7%)\n3351 (27.9%)\n\nwhere we only count those as auto processed whose publication or\nrejection happened automatically in all steps.\nInterestingly, for the first time in CRAN’s history there was a decrease\nin the number of submissions:\n\nYear\n1st half\n2nd half\n2018\nNA\n10259\n2019\n13218\n12938\n2020\n17598\n13510\n2021\n16339\n12256\n\nCRAN mirror security\nCurrently, there are 101 official CRAN mirrors, 83 of which provide both\nsecure downloads via https and use secure mirroring from the CRAN\nmaster (via rsync through ssh tunnels). Since the R 3.4.0 release,\nchooseCRANmirror() offers these mirrors in preference to the others\nwhich are not fully secured (yet).\nCRAN Task View Initiative\nTo facilitate the maintenance of established CRAN task views as well as\nthe proposal of new ones, a new improved and much more transparent\nworkflow has been established. It is overseen by the newly established\nCRAN Task View Editors: Roger Bivand, Dirk Eddelbuettel, Rocío Joo,\nDavid Meyer, Heather Turner, Nathalie Vialaneix, and Achim Zeileis. More\ndetails can be found in the corresponding organization on GitHub:\nhttps://github.com/cran-task-views/ctv/. Currently, the focus is on\nthe transition of the established task views to the new workflow which\nalso involves the archival of some task views which turned out to be too\nbroad to be maintainable (Graphics and SocialSciences). Also, the\ngR task view has been renamed to GraphicalModels. When the\ntransition is completed, a more detailed introduction with further\ndetails and instructions will be published soon.\nNew packages in CRAN task views\nBayesian\n\nBayesianTools,\nMHadaptive,\nRoBMA.\n\nCluster\n\nfactoextra.\n\nDatabases\n\ndittodb.\n\nDifferentialEquations\n\ndiffeqr.\n\nEconometrics\n\npdynmc,\nssmrob.\n\nFinance\n\nDOSPortfolio,\nHDShOP,\nRTL,\nbidask,\netrm,\ngreeks,\nichimoku,\nmonobin,\nstrand.\n\nFunctionalData\n\nMFPCA,\nregistr.\n\nHydrology\n\nHBV.IANIGLA,\nNPRED,\nRavenR,\nWASP,\nhydropeak,\nhydrotoolbox,\nmetR,\nnhdR,\nnhdplusTools,\nprism.\n\nMachineLearning\n\nabess\\(^*\\),\nislasso,\njoinet,\nmpath,\ntorch.\n\nMetaAnalysis\n\namanida,\nmetadat,\nnmarank,\nra4bayesmeta.\n\nMissingData\n\nBMTAR,\nIscores,\nMGMM,\ncglasso,\ncmfrec,\nmdgc,\nmgm.\n\nModelDeployment\n\nlightgbm.\n\nNumericalMathematics\n\nFixedPoint,\nGramQuad,\nbignum,\nrim.\n\nOfficialStatistics\n\nSimSurvey,\neurostat,\ninsee,\nrdhs,\ntidyBdE.\n\nOptimization\n\ngslnls,\nstochQN.\n\nPsychometrics\n\nDIFplus,\nsemtree.\n\nReproducibleResearch\n\nRequire,\ngt,\nhuxtable,\nmakepipe,\npharmaRTF,\nr2rtf,\nreproducible,\nstyler,\nunrtf.\n\nRobust\n\nRobStatTM.\n\nTimeSeries\n\nBGVAR,\nGlarmaVarSel,\nSTFTS,\nbrolgar,\nesemifar,\nmrf,\nmvLSW,\nprofoc,\nrdbnomics,\nsynthesis,\ntsBSS,\ntsdb,\ntssim,\nuGMAR,\nugatsdb.\n\n(* = core package)\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2021-2-editorial/",
    "title": "Editorial",
    "description": "The \"Editorial\" article from the 2021-2 issue.",
    "author": [
      {
        "name": "Dianne Cook",
        "url": {}
      }
    ],
    "date": "2021-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2021-2-forwards-news/",
    "title": "News from the Forwards Taskforce",
    "description": "The \"News from the Forwards Taskforce\" article from the 2021-2 issue.",
    "author": [
      {
        "name": "Heather Turner",
        "url": {}
      }
    ],
    "date": "2021-12-01",
    "categories": [],
    "contents": "\nForwards is an R Foundation taskforce working to widen the participation of under-represented groups in the R project and in related activities, such as the useR! conference. This report rounds up activities of the taskforce during the second half of 2022.\nAccessibility\nSince a number of people have joined the taskforce with a particular interest in accessibility, we have established a new Accessibility Team, led by s gwynn sturdevant and Jonathan Godfrey. The team will address accessibility to R and the R ecosystem in a broad sense, considering barriers faced by people with disabilities, or working in situations with limited internet access, or working in a language other than English, to name some of the major issues.\nAt their inaugural meeting in November, the team focused on improving documentation and reference materials for screen-reader users and those who prefer reading electronic documents in dark mode. Both issues are best handled by creating documents in HTML format. Di Cook shared a development version of The R Journal’s new HTML format, which was welcomed enthusiastically by the group and there was agreement to work together on testing and improving the journal’s accessibility.\nThe work of the new team is a continuation of the work Forwards has done on accessibility in the past, primarily in the context of the useR! conference. For 2021, Forwards members supported the organizers in their efforts to ensure that presentation materials and conference tools were accessible. Further detail is given in the blog posts Making Accessible Presentations at useR! 2021: The Story Behind the Scenes and How to Improve Conference Accessibility for Screen-reader Users - An Interview with Liz Hare. Liz Hare has been working on a joint project with Silvia Canelón as part of the MiR community, promoting good accessibility practices in data visualisation, a project that received funding from Code for Science and Society.\nCommunity engagement\nThe community team had a reboot in November, with Richard Ngamita stepping up to join Kevin O’Brien as co-lead. The team plans to focus on fostering networks in regions where the R community is less well connected, in particular supporting the work of AfricaR and the new AsiaR community, which has established a Slack Workspace and plans to hold regional online meetups in 2022.\nA key form of support is to encourage knowledge-sharing between regions, for example, by nominating speakers from Africa or Asia for speaking opportunities, or by joining events as a guest speaker. In recent months, Forwards members Mine Çetinkaya-Rundel spoke at satRday Nairobi, Heather Turner spoke at the 1st anniversary of R-Ladies Nairobi, and Kevin O’Brien spoke at the 3rd anniversary of Accra R User Ghana.\nSeveral members of the Community team are part of the R-Consortium Diversity & Inclusion Working Group, led by Samantha Toet. This group is currently working on four big projects: a guide to writing a code of conduct; an event organizer checklist; a speaker directory, and a speaker nomination form for R Consortium-affiliated events.\nConferences Team\nThe conferences team also gained a new lead, Yanina Bellini Saibene, who has been involved in the organization of many R events and conferences. Along with Natalia da Silva and Riva Quiroga, she chaired the LatinR 2021 conference, which took place online in November. Being online helped them to reach a record 1000 registrants. Highlights of the program included several papers from Spain, a full panel in Portuguese, and a full panel of Latin American women package developers. This is a great advance from the initial R Foundation endorsed event in 2018, which was a satellite to the 47 JAIIO informatics conference, attended by 50 people.\nIn collaboration with Claudia Alejandra Huaylla from the Surveys team, Yanina Bellini Saibene reflected in a blog post on the Latin American Community at useR! 2021, describing an exceptional increase in participation compared to previous years. They identify many practices that facilitated this growth, starting with including Latin American R users in the organizing team.\nSeveral members of Forwards have been involved in the Google Season of Docs project to develop a knowledgebase and information board to support the organization of useR! conferences. In particular, Andrea Sánchez-Tapia (co-lead of the Surveys team) and Noa Tamir (co-lead of the Conferences team) were hired as writers on the project and they made sure that diversity and inclusion were considered throughout the documentation. The project built on a lot of previous work by Forwards, including the annual surveys conducted at useR! and pieces of documentation written by the Conferences team as part of their work to make useR! more inclusive. Forwards will continue to be involved in maintaining these resources, which have already gained attention from the organizers of other R conferences.\nOn-ramps Team\nThe Forwards first-contributions repository walks people through making a simple pull request on GitHub, a useful skill for contributing to R packages and other open source software. Zane Dax updated the README with instructions in Spanish in time for Hacktoberfest 2021, which encourages people to make four quality pull requests to public GitHub and/or GitLab repositories during October.\nThe R Contribution Working Group held an Ideas Incubator over the summer to generate new ideas to work on during 2021/2022. One issue prioritised for attention was improving communications. This led to further development of the R Contribution Site, which is now hosted at https://contributor.r-project.org/ and linked from the main R Project website. The group has also set up the @R_Contributors Twitter account, for sharing event announcements and other news. The current focus is to run some outreach events related to the R Development Guide. Saranjeet Kaur Bhogal and Heather Turner are leading this project, which is supported by a grant from Code for Science and Society, as part of the Digital Infrastructure Incubator. The idea is that these events will provide an on-ramp into a larger contributor event to run in parallel with useR! 2022.\nPackage Development Modules\nMine Çetinkaya-Rundel and Emma Rand ran a “train-the-trainer” event in November/December aimed at R-Ladies leaders and others who wanted to use the Forwards package development teaching materials with their user groups. Attendees are starting to plan workshops based on the materials: a course was run in early January 2022 by R-Ladies NYC (lead by Joyce Robbins, assisted by Erin Grand and Emily Dodwell) and a course is currently underway by R-Ladies Remote (lead by Heather Turner and Rita Giordano).\nChanges in Membership\nNew members\nWe welcome the following members to the taskforce:\nConferences team: Yanina Bellini Saibene (co-leader)\nSurveys team: Andrea Sánchez-Tapia (co-leader)\nPrevious members\nThe following members have stepped down:\nCommunity team: Madlene Hamilton, Ileena Mitra\nOn-ramps team: Jenny Bryan (co-leader)\nSocial media team: Lorna Maria Aine (co-leader), Shakirah Nakalungi (co-leader), Wenfeng Qin\nSurveys team: David Meza\nTeaching team: Yizhe Xu\nWe thank them for their contribution to the taskforce. We also acknowledge the work of Emily Dodwell, who has stepped down as administrator after serving for several years (remaining a member of the Teaching team) – s gwynn sturdevant has taken on this role.\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2021-2-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2021-2 issue.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2021-12-01",
    "categories": [],
    "contents": "\n\n1 Donations and members\nMembership fees and donations received between 2021-07-06 and\n2021-12-22.\nDonations\nJordan Aharoni (Canada) b-data GmbH (Switzerland) Mark Cachia (Canada)\nShalese Fitzgerald (United States) Knut Helge Jensen (Norway) Roger\nKoenker (United Kingdom) Merck Research Laboratories, Kenilwort (United\nStates) Statistik Aargau, Aarau (Switzerland)\nSupporting members\nDiogo Almeida (United Arab Emirates) Tim Appelhans (Germany) Christopher\nBeltz (United States) Gordon Blunt (United Kingdom) Tamara Bozovic (New\nZealand) Greg Bukovatz (United States) Gilberto Camara (Brazil) Susan M\nCarlson (United States) Charles Cowens (United States) Terry Cox (United\nStates) Robin Crockett (United Kingdom) Robert Daly (Australia) Gergely\nDaroczi (Hungary) Jasja Dekker (Netherlands) Anthony Alan Egerton\n(Malaysia) Mitch Eppley (United States) cristiano esclapon (Switzerland)\nGottfried Fischer (Austria) David Freedman (United States) Keita\nFukasawa (Japan) Sven Garbade (Germany) Anne Catherine Gieshoff\n(Switzerland) Spencer Graves (United States) Jim Gruman (United States)\nKrushi Gurudu (United States) Bela Hausmann (Austria) Takehiko Hayashi\n(Japan) Kieran Healy (United States) Adam Hill (United States) Lorenzo\nIsella (Belgium) Sebastian Jeworutzki (Germany) JUNE KEE KIM (Korea,\nRepublic of) Gen KOBAYASHI (Japan) Miha Kosmac (United Kingdom) Jan\nHerman Kuiper (United Kingdom) Seungdoe Lee (Korea, Republic of) Mauro\nLepore (United States) Thomas Levine (United States) Chin Soon Lim\n(Singapore) Joseph Luchman (United States) Alexandra Lypynska (United\nKingdom) Gilles Marodon (France) Guido (Germany) yoshinobu nakahashi\n(Japan) Bernard OFFMANN (France) Dan Orsholits (Switzerland) George\nOstrouchov (United States) Abdullah Öztop (Turkey) Matt Parker (United\nStates) Elgin Perry (United States) Peter Ruckdeschel (Germany) Dejan\nSchuster (Germany) Christian Seubert (Austria) Jagat Sheth (United\nStates) Gaurav Singhal (United States) Tobias Strapatsas (Germany)\nROBERT Szabo (Sweden) Koray Tascilar (Germany) Nicholas Turner (United\nStates) Philipp Upravitelev (Russian Federation) Mark van der Loo\n(Netherlands) Marcus Vollmer (Germany) Jaap Walhout (Netherlands) Sandra\nWare (Australia) Arne Jonas Warnke (Germany) Vaidotas Zemlys-Balevičius\n(Lithuania) Lim Zhong Hao (Singapore)\n2 R Foundation Financial Support 2021\nThe R Foundation financially supported the following projects in 2021:\nThe R Journal, useR! 2020 and 2021, R Developer Guide Project, and CRAN.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2021-1-bioc/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2021-1 issue.",
    "author": [
      {
        "name": "Bioconductor Core Team",
        "url": {}
      }
    ],
    "date": "2021-06-01",
    "categories": [],
    "contents": "\n\nBioconductor provides tools for the analysis\nand comprehension of high-throughput genomic data. Bioconductor 3.13 was\nreleased on 20 May, 2021. It is compatible with R 4.1.0 and consists of\n2042 software packages, 406 experiment data packages, 965 up-to-date\nannotation packages, and 29 workflows.\nBooks were introduced in\nBioconductor 3.12 and production continues in this release. These are\nbuilt regularly from source and therefore fully reproducible; an example\nis the community-developed Orchestrating Single-Cell Analysis with\nBioconductor.\nThe Bioconductor 3.13 release\nannouncement includes\ndescriptions of 133 new software packages, and updates to NEWS files for\nmany additional packages. Start using Bioconductor by installing the\nmost recent version of R and evaluating the commands\n  if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n      install.packages(\"BiocManager\")\n  BiocManager::install()\nInstall additional packages and dependencies, e.g.,\nSingleCellExperiment,\nwith\n  BiocManager::install(\"SingleCellExperiment\")\nDocker images provides a very\neffective on-ramp for power users to rapidly obtain access to\nstandardized and scalable computing environments.\nKey learning resources include:\nbioconductor.org to install, learn, use,\nand develop Bioconductor packages.\nA list of available software,\nlinking to pages describing each package.\nA question-and-answer style user support\nsite and developer-oriented\nmailing list.\nA community slack (sign up)\nfor extended technical discussion.\nThe F1000Research Bioconductor\nchannel for\npeer-reviewed Bioconductor work flows.\nThe Bioconductor\nYouTube channel includes\nrecordings of keynote and talks from recent conferences including\nBioc2020 and BiocAsia2020, in addition to video recordings of\ntraining courses.\nOur package\nsubmission\nrepository for open technical review of new packages.\nThe 2021 Bioconductor conference\nwill be virtual, August 4-6, 2021.\nIn conjunction with the Mexican Bioinformatics\nNetwork and the Nodo Nacional de\nBioinformática CCG UNAM, the Comunidad de\nDesarrolladores de Software en Bioinformática have arranged two\nweek-long online\nworkshops\naddressing development of workflows with RStudio and\nshiny and\nanalysis of single-cell RNA-seq\nexperiments,\nAugust 9-13, 2021.\nBiocAsia 2021 will be held November 1-4 2021 as a virtual event The\nwebsite and call for contributed talks are not open yet. Keep an eye on\nthe events page for updates.\nThe Biopackathon project\nhas many points of contact with Bioconductor and recurs monthly.\nThe National Human Genome Research Institute’s Analysis and\nVisualization Laboratory (AnVIL) is\ndeveloping with contributions from Bioconductor core team members. A\nseries of recorded\nworkshops\non the use of Bioconductor to explore this cloud computing system is\navailable; additional workshops will be presented in the Fall of 2021.\nThe Bioconductor project continues to mature as a community. The\nTechnical\nand\nCommunity\nAdvisory Boards provide guidance to ensure that the project addresses\nleading-edge biological problems with advanced technical approaches, and\nadopts practices (such as a project-wide Code of\nConduct) that\nencourages all to participate. We look forward to welcoming you!\n\n\nBioconductor packages used\nSingleCellExperiment\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2021-1-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2021-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2021-06-01",
    "categories": [],
    "contents": "\n\nIn the past 6 months, 1290 new packages were added to the CRAN package\nrepository. 116 packages were unarchived and 467 were archived. The\nfollowing shows the growth of the number of active packages in the CRAN\npackage repository:\n\nOn 2021-06-30, the number of active packages was around 17778.\nCRAN package submissions\nDuring the the last three quarters (September 2020 to June 2021), CRAN\nreceived 25426 package submissions. For these, 44844 actions took place\nof which 29039 (65%) were auto processed actions and 15805 (35%) manual\nactions.\nMinus some special cases, a summary of the auto-processed and manually\ntriggered actions follows:\n\narchive\ninspect\nnewbies\npending\npretest\npublish\nrecheck\nwaiting\nauto\n6191\n5988\n5585\n0\n0\n7244\n2429\n1602\nmanual\n6586\n117\n874\n855\n249\n5467\n1322\n335\nThese include the final decisions for the submissions which were\naction\narchive\npublish\nauto\n5573 (22.5%)\n6131 (24.8%)\nmanual\n6478 (26.2%)\n6544 (26.5%)\nwhere we only count those as auto processed whose publication or\nrejection happened automatically in all steps.\nCRAN mirror security\nCurrently, there are 103 official CRAN mirrors, 82 of which provide both\nsecure downloads via https and use secure mirroring from the CRAN\nmaster (via rsync through ssh tunnels). Since the R 3.4.0 release,\nchooseCRANmirror() offers these mirrors in preference to the others\nwhich are not fully secured (yet).\nNew packages in CRAN task views\nBayesian\n\ncausact,\ndina,\nedina,\nerrum,\ngreta,\nmcmcensemble,\nrrum,\nshinybrms.\n\nClinicalTrials\n\nDTAT,\nKeyboard,\nMinEDfind,\nPowerUpR,\nUnifiedDoseFinding,\ncosa,\ncrmPack,\npresize,\nrandomizeR,\nreplicateBE,\nrpact,\nsimglm.\n\nCluster\n\nmdendro,\nmixR.\n\nDifferentialEquations\n\nRxODE,\nmrgsolve,\nnlmixr.\n\nEconometrics\n\ncollapse,\nivreg,\nlfe.\n\nFinance\n\nAssetCorr,\nLSMRealOptions,\nNFCP,\nfrenchdata,\ngarchmodels.\n\nFunctionalData\n\nface,\nmfaces,\nsparseFLMM.\n\nHighPerformanceComputing\n\nproffer,\nprofile,\nprofmem,\ntargets.\n\nHydrology\n\nAWAPer,\nHydroMe,\nLWFBrook90R,\nMODIStsp,\nairGRdatassim,\nsynthesis,\ntelemac.\n\nMachineLearning\n\nDoubleML,\nlightgbm\\(^*\\),\nmlpack,\nsplitTools.\n\nMetaAnalysis\n\nCoTiMA,\nDTAplots,\nEvidenceSynthesis,\nMetaIntegration,\nRoBMA,\nRobustBayesianCopas,\nbnma,\nboutliers,\nforplo,\nfsn,\ngmeta,\nmetaSurvival,\nmetamicrobiomeR,\nmetapack,\nnmaplateplot,\nsmd.\n\nMissingData\n\nInformativeCensoring,\nNADIA,\ndejaVu,\ngrf,\nidem,\nlqr,\nmisaem,\nmissRanger,\nmixture,\nnorm2,\nsamon,\nsemTools.\n\nNumericalMathematics\n\nsanic.\n\nOfficialStatistics\n\ncollapse,\nlongCatEDA,\nsdcMicro,\nsimPop.\n\nOptimization\n\nQPmin,\nSPOT,\npsqn,\nrminizinc,\nrmoo.\n\nPsychometrics\n\nata,\ntidyLPA.\n\nReproducibleResearch\n\nknitcitations,\nreportfactory,\ntargets.\n\nRobust\n\nclubSandwich,\nclusterSEs,\nskewlmm.\n\nSpatial\n\nGWmodel,\nRCzechia,\nchilemapas,\ndbmss,\ngeobr,\ngeouy,\ngiscoR,\nipdw,\nmapSpain,\nosmextract,\nrgee,\nrgugik,\nterra.\n\nSurvival\n\nCyclops,\nDAAG,\nInformativeCensoring,\nLTRCtrees,\nLogicReg,\nSGL,\nSimSurvNMarker,\nYPmodel,\nasbio,\nbayesSurv,\nbujar,\nconcreg,\netm,\nfrailtyHL,\nfrailtySurv,\nfrailtypack,\njoineRML,\nkmc,\nkmi,\nmets,\nmlr3proba,\nnpsurv,\nplsRcox,\nreReg,\nrstanarm,\nsimPH,\nsmoothSurv,\nspef,\nsuperpc,\ntranSurv.\n\nTimeSeries\n\nHDTSA,\nLSTS,\nRcatch22,\nRsfar,\nVARDetect,\nautostsm,\nbayesforecast,\nblocklength,\nclock,\ncollapse,\ndynr,\nfpcb,\ngsignal,\nlegion,\nmfbvar,\nstrucchangeRcpp,\ntensorTS,\ntsrobprep.\n\nWebTechnologies\n\nAzureCosmosR,\nAzureGraph,\nAzureKusto,\nAzureQstor,\nAzureTableStor,\nAzureVision,\nMicrosoft365R.\n\n(* = core package)\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2021-1-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in The R Journal.",
    "author": [
      {
        "name": "Dianne Cook",
        "url": "https://journal.r-project.org"
      }
    ],
    "date": "2021-06-01",
    "categories": [],
    "contents": "\nOn behalf of the editorial board, I am pleased to present Volume 13 Issue 1 of the R Journal.\nFirst, some news about the journal board. Welcome to Gavin Simpson, who joins as a new Executive Editor! In addition, welcome to our new Associate Editors Nicholas Tierney, Isabella Gollini, Rasmus Bth, Mark van der Loo, Elizabeth Sweeney, Louis Aslett and Katarina Domijan. With the large volume of submissions, the Associate Editors now play a vital role in processing articles.\nThere are some new developments in the journal operations under way. We are working on a new package rjtools which will operate a little like the devtools package and help you to create a new article from a template, and check that it conforms to the style and requirements of the R Journal.\nWe are also working on supporting articles written in RMarkdown, which will be rendered in html through a modified distill web site. The exciting feature is that interactive graphics could be included directly in the article. You can see how this current issue would look in the new style at rjournal.r-project.org/dev. Particularly, look at articles Conversations in Time by Wang and Cook as an example that has two examples of how interactive graphics might be included. Other articles rendered in html are “Finding Optimal Normalizing Transformations” by Peterson, “Automating Reproducible, Collaborative\nClinical Trial Document Generation” by Kane, Jiang and Urbanek, and “Towards a Grammar for Processing Clinical Trial Data” by Kane. All remaining articles in the new site style are the current pdf style.\nTo experiment with creating a new article, or to check that your article, conforms with the R Journal author guidelines, go to https://rjournal.github.io/rjtools/. Note that it is still ok to use the rticles package R Journal Rmarkdown template to create your article. This will generate the files that are compiled to pdf using latex, but it is an easy translation for us to convert them into the new style.\nThe operational support and the experiments have been supported with generous funding from the R Consortium (https://www.r-consortium.org).\nBehind the scenes, several people are assisting with the journal operations and the new developments. Mitchell O’Hara-Wild has worked on infrastructure, the new article submission system, a new issue build system and now the new article delivery system providing html format. H. Sherry Zhang has taken over from Stephanie Kobakian, in developing the rjtools package including check functions for new articles to help authors get the style constraints correct. In addition, articles in this issue have been painstakingly copy edited by Dewi Amaliah.\n1 In this issue\nNews from the R Core, CRAN, Bioconductor, the R Foundation, and the foRwards Taskforce are included in this issue along with a summary of activities at the R Medicine and Why R? 2021 conferences.\nThis issue features 37 contributed research articles covering these topics:\nMultivariate analysis\nSeedCCA: An integrated R-package for Canonical Correlation Analysis and Partial Least Squares\nUnidimensional and Multidimensional Methods for Recurrence Quantification Analysis with crqa\nclustcurv: An R Package for Determining Groups in Multiple Curves\ngofCopula: Goodness-of-Fit Tests for Copulae\nROCnReg: An R Package for Receiver Operating Characteristic Curve Inference With and Without Covariates\n\nNon-parametric methods\nnpcure: An R Package for Nonparametric Inference in Mixture Cure Models\nROBustness In Network (robin): an R package for Comparison and Validation of Communities\nkrippendorffsalpha: An R Package for Measuring Agreement Using Krippendorff’s Alpha Coefficient\n\nTemporal and longitudinal methods\nJMcmprsk: An R Package for Joint Modelling of Longitudinal and Survival Data with Competing Risks\nLinear Regression with Stationary Errors: the R Package slm\npenPHcure: Variable Selection in Proportional Hazards Cure Model with Time-Varying Covariates\npdynmc: A Package for Estimating Linear Dynamic Panel Data Models Based on Nonlinear Moment Conditions\nDChaos: An R Package for Chaotic Time Series Analysis\nIndexNumber: An R Package for Measuring the Evolution of Magnitudes\ngarchx: Flexible and Robust GARCH-X Modelling\nWorking with CRSP/COMPUSTAT in R: Reproducible Empirical Asset Pricing\nAnalysing Dependence Between Point Processes in Time Using IndTestPP\nConversations in Time: Interactive Visualisation to Explore Structured Temporal Data\n\nComputing infrastructure\nA Method for Deriving Information from Running R Code\nWide-to-tall Data Reshaping Using Regular Expressions and the nc Package\nThe bdpar Package: Big Data Pipelining Architecture for R\nBenchmarking R packages for calculation of Persistent Homology\ndistr6: R6 Object-Oriented Probability Distributions Interface in R\nAutomating Reproducible, Collaborative Clinical Trial Document Generation\nReproducible Summary Tables with the gtsummary Package\nTowards a Grammar for Processing Clinical Trial Data\n\nSimulation and optimisation\nFinding Optimal Normalizing Transformations via bestNormalize\nPackage wsbackfit for Smooth Backfitting Estimation of Generalized Structured\nModels\nRLumCarlo: Simulating Cold Light using Monte Carlo Methods\nOneStep: Le Cam’s one-step estimation procedure\nThe HBV.IANIGLA Hydrological Model\nRegularized Transformation Models: The tramnet Package\n\nOther topics\nexPrior: An R Package for the Formulation of Ex-Situ Priors\nBayesSPsurv: An R Package to Estimate Bayesian (Spatial) Split-Population Survival Models\nStatistical Quality Control with the qcr Package\nThe R Package smicd: Statistical Methods for Interval-Censored Data\nstratamatch: Prognostic Score Stratification Using a Pilot Design\n\nHappy reading, and code testing!\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2021-1-forwardsnews/",
    "title": "News from the Forwards Taskforce",
    "description": "The 'News from the Forwards Taskforce' article from the 2021-1 issue.",
    "author": [
      {
        "name": "Heather Turner",
        "url": {}
      }
    ],
    "date": "2021-06-01",
    "categories": [],
    "contents": "\n\nForwards is an R Foundation taskforce\nworking to widen the participation of under-represented groups in the R\nproject and in related activities, such as the useR! conference. This\nreport rounds up activities of the taskforce during the first half of\n2021.\n1 Community engagement\nKevin O’Brien has been conducting a series of video interviews as part\nof the Why R? World series. A number of interviews are ready to watch\non the Why R?\nFoundation\nYouTube channel and several more rehearsal interviews have been\nconducted preparing the ground for a later recording. The interviewees\ninclude organizers of local groups, such as Nontsikelelo Shongwe\n(Eswatini); other community-builders, such as Reinaldo Zazela\n(Mozambique) connecting R users in Lusophone Africa, and other data\nscientists/related professionals talking about their work, such as Lais\nCarvalho (Brazil/Ireland) working in Developer Relations.\nKevin also facilitated the R-Ladies Remote\nTakeover\nof the Why R? Webinar series. Co-organized with Janani Ravi (R-Ladies\nRemote/R-Ladies East Lansing) and Heather Turner (Forwards/R-Ladies\nRemote) the Takeover featured three talks from speakers from across\nthe globe, spread throughout one day. First up was Afiqah Masrani\n(Malaysia) on Using {gtsummary} For Public Health Research, then Tuli\nAmutenya (Namibia), on Natural Language Processing for Survey Text\nData and finally Beatriz Valdez (Venezuela) on Using R and Text Mining\nto find a Common Ground for Action in Polarized Contexts. We were happy\nto provide a platform for these R-Ladies who live far from an active\ngroup (both R-Ladies and R\nUser groups are being started in\nCaracas, Venezuela, however). The speaker from each talk co-chaired the\nnext talk helping to make connections and a good atmosphere for the Q&A.\nWe hope to run a similar event in future.\n2 R Contribution Working Group\nThe R Contribution Work\nGroup has begun\nwork on some initiatives to encourage new contributors to R core, having\nlaid the groundwork in the second half of 2020.\nThe R Foundation funded a 10-week project to develop a first version of\nthe R Developer’s Guide, a\nuser-friendly introduction to contributing to R core. This project was\nundertaken by Saranjeet Kaur, mentored by Michael Lawrence and Heather\nTurner. Currently the guide covers identifying, reporting and reviewing\nbugs; preparing and submitting a patch; contributing to documentation,\nand testing pre-release versions of R. It also includes some technical\nhelp (building and installing R-devel on Windows, developer tools) and\nsome community orientation (list of R core developers/contributors,\nwhere to get help and keep up-to-date with R project news). This guide\nbenefited from review by RCWG members during and after the project, and\nwe welcome members of the wider R developer community to review the\nguide and contribute to its further development as documented in\nChapter\n1\nof the guide.\nThe R-devel Slack\ngroup now has over 100 members and is gradually seeing more activity. We\nwelcome anyone interested in contributing to R to join - it provides a\nspace for wider discussion compared to the R-devel mailing list and a\nsupportive community for people new to contributing.\n3 useR! 2021\nForwards was involved in a wide range of activities related to useR!\n2021.\nThe Conference Team provided advice to the organizers on aspects such as\ncode of conduct and events for first-timers. Liz Hare was heavily\ninvolved with supporting accessibility practices, including helping to\ndevelop the accessibility guidelines for presenters, providing input to\nthe communications team and testing the accessibility of conference\ntools. The latter led to some improvements for screen-reader users in\nThe Lounge chat platform; although this tool\nwas ultimately abandoned for useR!, these changes will benefit future\nusers. Noa Tamir began work as a Senior Writer/Editor on the R\nProject’s Google Season of\nDocs\nproject to develop documentation supporting useR! organization.\nThe Community Team helped with encouraging participation from\nunder-represented countries, directly contacting R users to let them\nknow about useR! and the fee waivers available for those without\nfunding. They also helped to enlist reviewers for\nMiR’s pre-review service, as well as Zoom\nhosts and volunteers for the team providing online chat support during\nthe conference.\nThe Survey Team supported the organizers in running a Diversity Survey,\nthe preliminary results of which were presented in the Closing Session.\nThe On-ramps Team partnered with the R Contribution Working Group to\narrange two contributor-focused tutorials. The first was on Translating\nR to Your Language, lead by Michael Chirico in collaboration with\nMichael Lawrence. This was attended by an enthusiastic group, that\nworked on translating R messages into Spanish, Bahasa Indonesia, Hindi\nand Hungarian. The second was on Contributing to R lead by Gabriel\nBecker in collaboration with Martin Mächler. Gabriel shared his\nexperiences as an external contributor to R core, before the\nparticipants split into small groups to debug a past issue in R 3.3.2.\nMartin reviewed how the bug was fixed in later versions of R and the\nsession was completed with some parting advice and a round table, with\nMichael Lawrence joining as a guest. The participants reported that the\ntutorial was accessible and rewarding. A sub-group has met since to work\nthrough some of the further exercises prepared by the tutors.\nJonathan Godfrey, long-time member of Forwards, was part of a group\nkeynote on responsible programming. He touched on the importance of\nacknowledging disabled people in our communities and using appropriate\nlanguage when speaking about disability. However, his main theme was\nchoosing tools that are inclusive. \"To be disabled means you have been\nexcluded in some way. But when I am included, I am no longer disabled.\"\nAn example is that HTML documentation is much more accessible to\nscreen-readers than PDF. As a community/developers, we should aim to\n\"make the right things easy to do, and the incorrect ones, harder\".\nThe tutorials and sessions mentioned above are expected to be published\nsoon on the R Consortium YouTube\nchannel -\nlinks will also be shared on the useR! 2021\nwebsite.\n4 Package Development Modules\nAs reported in the last issue, the Teaching Team have been modularizing\nthe Forwards Package Development workshop. The first 3 modules were run\nin February 2021, with a total of 51 people. Only 19 people took all\nthree modules, suggesting the modular approach enables participants to\nselect modules according to their existing knowledge.\nThe modules will be re-run in September, with an additional module on\ndocumentation and testing. The modules will be run on separate days: 20,\n21, 23 and 24 September at 13:00 UTC. Registration pages for each module\ncan be found from the Forwards Eventbrite\nPage.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2021-1-rcore/",
    "title": "Changes in R 4.0--4.1",
    "description": "We give a selection of the most important changes in R 4.1.0. Some statistics on source code commits and bug tracking activities are also provided.",
    "author": [
      {
        "name": "Tomas Kalibera",
        "url": {}
      },
      {
        "name": "Sebastian Meyer",
        "url": {}
      },
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2021-06-01",
    "categories": [],
    "contents": "\n\n1 R 4.1.0 selected changes\nR 4.1.0 (codename “Camp Pontanezen”) was released on 2021-05-18. The\nfollowing gives a selection of the most important changes.\nR now provides a simple native forward pipe syntax |>. The simple\nform of the forward pipe inserts the left-hand side as the first\nargument in the right-hand side call. The pipe implementation as a\nsyntax transformation was motivated by suggestions from Jim Hester\nand Lionel Henry. The current implementation does not provide a\nshorthand for passing the left-hand side as an argument other than\nthe first. Several options for providing such a shorthand are\ncurrently under consideration.\nR now provides a shorthand notation for creating functions, e.g.\n\\(x) x + 1 is parsed as function(x) x + 1.\nThe base environment and its namespace are now locked (so one can no\nlonger add bindings to these or remove from these)\nSupport for gradient fills, pattern fills, clipping paths and masks\nhas been added to the R graphics engine. An R-level interface for\nthese new features has been added to the grid graphics package.\nSee Paul Murrell’s blog\npost\nfor more details.\nGraphics devices can now specify deviceClip. If TRUE, the\ngraphics engine will never perform any clipping of output itself.\nThe clipping that the graphics engine does perform (for both\ncanClip = TRUE and canClip = FALSE) has been improved to avoid\nproducing unnecessary artifacts in clipped output. See Paul\nMurrell’s blog\npost\nfor more details.\nNew palettes \"Rocket\" and \"Mako\" for hcl.colors()\n(approximating palettes of the same name from the ‘viridisLite’\npackage). Contributed by Achim Zeileis.\nRterm, the command-line R front-end on Windows, now supports line\nediting and cursor motion with multi-byte and multi-width printable\ncharacters. It is now possible to use RTerm with non-European\ncharacters when the current locale (e.g. double-byte) supports them.\nPreviously, users of non-European languages had to resort to other\nfront ends, e.g. RGui. On (still experimental) UCRT builds of R on\nrecent Windows 10, the native encoding is UTF-8 and hence all\ncharacters supported by Windows and the font can be used in Rterm,\nincluding characters outside of Basic Multilingual Plane (surrogate\npairs in UTF-16LE). This required a significant rewrite of code\noriginating from getline library. See Tomas Kalibera’s blog\npost\nfor more details.\nData set esoph in package datasets now provides the correct\nnumbers of controls; previously it had the numbers of cases added to\nthese. Reported by Alexander Fowler in\nPR#17964.\nUsing c() to combine a factor with other factors now gives a\nfactor (an ordered factor when combining ordered factors with\nidentical levels).\nNew function charClass() has been added to package utils to\nquery the wide-character classification functions in use by R (such\nas iswprint, iswalpha, islower). On Windows and by default on\nmacOS and AIX, the classes are determined by R’s internal tables. On\nLinux, the C99 functions and the classification provided by the\nplatform are used. charClass() accepts UTF-8 encoded R strings and\ninteger vectors of Unicode points on input.\nR’s internal Unicode tables for character classification and\ncharacter width were updated to Unicode 13.0.0 (used on Windows and\nby default on macOS and AIX). Handling of \\U escapes in the parser\nwas improved. String truncation is now more careful: most instances\nin R have been fixed not to produce incomplete multi-byte\ncharacters. Additionally, there were several encoding-related bug\nfixes.\nR and CRAN package binaries are now available also for the new Apple\nsilicon Macs (M1 and higher) as native 64-bit ARM builds. Fortran\ncode is compiled by a development version of GNU Fortran compiler\nfrom Iain Sandoe as no free Fortran 90 compiler for the platform has\nbeen released, yet. Only minimal changes to base R were needed for\nthis: now R turns off floating-point ARM RunFast mode, hence\ndisabling flush-to-zero and default-NaN modes. The default-NaN mode\nis not desirable for R because it causes R NA values to become\nNaN even in operations involving otherwise only finite values\n(NA * 1 would be NaN). For more details on the NaN/NA issue, see\nan otherwise already outdated blog\npost\nof Tomas Kalibera and Simon Urbanek. For more information on M1\nsupport in R, see R Installation and\nAdministration.\nAn experimental build of R and binaries of CRAN packages and their\nBioconductor dependencies is now available for Windows. The builds\nuse UCRT as the C runtime (previous builds used MSVCRT) to allow\nsetting UTF-8 as the native encoding on recent Windows 10, hence\nsubstantially reducing the amount of encoding issues in R on that\nplatform. All required external libraries had to be rebuilt, because\nall code linked statically on Windows needs to use the same C\nruntime. This used a new GCC 10 MinGW-w64 cross- and native\ntoolchains compiled using MXE. These builds use R-devel and did so\nalso at the time of 4.1.0 release, but were still experimental at\nthat time and only selected patches have been ported to 4.1.0\n(accepting UTF-8 as native encoding, the rewrite of RTerm/getline,\nWindows installer improvements). More details are available in Tomas\nKalibera’s blog posts from March\n2021,\nJuly\n2020,\nand May\n2020.\n2 R 4.1.0 code statistics\nFrom the source code Subversion repository, the overall change between\nApril 25, 2020 and May 28, 2021 (so between R 4.0.0 and R 4.1.0) was:\n33,000 added lines, 14,000 deleted lines and 1000 changed files. This is\nrounded to thousands/hundreds and excludes changes to common generated\nfiles, bulk re-organizations, etc. (translations, parsers, autoconf,\nLAPACK, R Journal bibliography, test outputs, Unicode tables,\nincorporated M4 macros). This change is slightly bigger than that\nbetween R 3.6.0 and R 4.0.0 (24% more insertions, 10% more deletions, 4%\nmore changed files), see News and Notes from the December 2020 issue of\nthe R Journal.\nFigure 1 shows commits by month and weekday, respectively,\ncounting line-based changes in individual commits, excluding the files\nas above. The statistics are computed the same way as in the previous\nissue, hence allowing direct comparisons, but monthly statistics are\nimpacted by the release date which varies across versions, hence\nimpacting the numbers for April and May. The statistics cover code\ndirectly committed to the R-devel trunk, plus commits from the R-defs\nbranch (graphics code from Paul Murrell). The latter was merged into\nR-devel in July 2020, but the statistics is based on months/days the\noriginal commits were made to R-defs, including from December 2019.\n\n\n\nFigure 1: Commit statistics by month (left) and weekday\n(right) during R 4.1.0 development. *Note that the counts for April 2020\nand May 2021 do not cover full months. Commits from December 2019\nrepresent work of Paul Murrell on the later merged R-defs\nbranch.\nWe observe an activity peak just after the release of R 4.0.0, a minimum\nin October 2020, and otherwise relatively stable amounts of code\nchanges. The large numbers in May/June do not seem to follow a general\npattern: here Paul Murrell did most of his changes on graphics. The\nright-hand plot shows that there is still a number of contributions even\nduring the weekends.\n3 R 4.1.0 bugs statistics\nSummaries of bug-related activities during the development of R 4.1.0\n(from April 25, 2020 to May 18, 2021) were derived from the database\nunderlying R’s Bugzilla system.\nFigure 2 shows statistics of reported/closed bugs and\nnumber of added comments (on any bug report) by calendar month and\nweekday, respectively. Deviating from the previous issue, new bug\nreports (comment 0) are not counted as comments, so these numbers cannot\nbe compared directly. Note that monthly statistics are impacted by\ntruncation at the release dates in April 2020 and May 2021,\nrespectively.\nComments are added by reporters of the bugs, R Core members and external\nvolunteers. When a bug report is closed, the bug is either fixed or the\nreport is found invalid. In principle, this can happen multiple times\nfor a single report, but those cases are rare. Hence the number of\ncomments is a measure of effort (yet a coarse one which does not\ndistinguish thorough analyses from one-liners) and the number of bug\nclosures is a measure of success in dealing with bugs.\nR 4.1.0 was released by about 3 weeks later than usual, so the period\nwhich is summarized is also longer. The bug-related activities have\nstill increased much more than what could be explained by that: about\n17% more bugs closed than for (during development of) 4.0.0, but 55%\nmore bugs reported). The increase from 3.6.0 to 4.0.0 was 45% more bug\nreports and 92% more bugs closed.\nThere was a significant increase in the number of comments following a\nblog\npost\nof Tomas Kalibera and Luke Tierney, published October 9, 2019 (so during\ndevelopment of 4.0.0), asking the R community for help with the bugs.\nThe rate of comments stayed relatively high until now, so for the\ndevelopment of 4.1.0. This increased activity also came with more bug\nreports and more bugs closed. Initially, more bugs were closed than\nreported (4.0.0 development), but this changed during 4.1.0. It may be\nthat the bugs fixed initially with the help of external volunteers were\nthe older ones easy to handle, but now there is space for external\nvolunteers to help with the new/harder ones.\n\n\n\nFigure 2: Bug tracking activity by month (left) and weekday\n(right) during R 4.1.0 development. *Note that the counts for April 2020\nand May 2021 do not cover full months.\nFrom the numbers by weekday in the right panel of Figure 2\nwe see that the R community still keeps working during the weekends.\nStill, the overall bigger bug-related activity seems relatively more\nreduced during the weekends than during 4.0.0 and 3.6.0 development.\n4 Acknowledgements\nTomas Kalibera’s work on the article and R development has received\nfunding from the Czech Ministry of Education, Youth and Sports from the\nCzech Operational Programme Research, Development, and Education, under\ngrant agreement No.CZ.02.1.01/0.0/0.0/15_003/0000421, from the European\nResearch Council (ERC) under the European Union’s Horizon 2020 research\nand innovation programme, under grant agreement No. 695412, and from the\nNational Science Foundation award 1925644.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2021-1-rfoundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2021-1 issue.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2021-06-01",
    "categories": [],
    "contents": "\n1 Donations and members\nMembership fees and donations received between 2021-01-29 and\n2021-07-05.\nDonations\nJoaquín Baquer-Miravete (Spain) Generators in Smithfield, Virginia\n(United States) Ruedi Epple (Switzerland) Vancouver Fencing (Canada)\nAbbotsford Handyman (Canada) ken ikeda (Japan) Roofers Akron Ohio\n(United Kingdom) Seattle Handyman (Canada) Vancouver Handyman (Canada)\nLangley Handyman (Canada) Concrete Maple Ridge (Canada) Concrete Maple\nRidge (Canada) Concrete Maple Ridge (Canada) Juan Perez-Franco (Chile)\nVancouver Roofing (United States) Tuckpointing Vancouver (United States)\nBend Fencing Companies (United States) Dr. Alfred Wagner (Germany)\nDaniel Wollschläger (Germany) Duct Cleaning Winnipeg (Canada) Merck\nResearch Laboratories, Kenilwort (United States)\nSupporting institutions\nAlfred Mueller Analytic Services, München (Germany) Department of\nClinical Research, University Hospital Basel, Basel (Switzerland)\nDotcom-Tools, Wayzata (United States)\nSupporting members\nKristoffer Winther Balling (Denmark) Ashanka Beligaswatte (Australia)\nFrederic BERTRAND (France) Michael Blanks (United States) Ryan\nBonifacino (United States) Wesley Brooks (United States) Jack Brown\n(United Kingdom) John Chandler (United States) Gerard Conaghan (United\nKingdom) Michael Dorman (Israel) Werner Engl (Austria) Guenter Faes\n(Germany) Bernd (Germany) Jan Marvin Garbuszus (Germany) Gabriel\nGersztein (Brazil) Robert Hickman (United Kingdom) Alexander Huelle\n(Germany) Péter Kalicz (Hungary) Christian Kampichler (Netherlands)\nJungjoon Kim (Korea, Republic of) Gavin Kirby (United Kingdom) Sebastian\nKoehler (Germany) Sebastian Krantz (Germany) Chris Kuty (United States)\nHOONJEONG KWON (Korea, Republic of) Adrien Le Guillou (France) Michal\nMajka (Austria) Myriam Maumy (France) Ernst Molitor (Germany) David\nMonterde (Spain) Stefan Moog (Germany) Steffen Moritz (Germany) Jens\nOehlschlägel (Germany) Bill Pikounis (United States) VASILEIOS PLESSAS\n(United Kingdom) Stefano Rezzonico (Canada) Harald Sterly (Germany)\nRobert van den Berg (Austria) Fredrik Wartenberg (Sweden) Jason Wyse\n(Ireland)\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2021-1-rmed2020/",
    "title": "R Medicine 2020: The Power of Going Virtual",
    "description": "The third annual R/Medicine conference was planned as a physical event to be held in Philadelphia at the end of August 2020. However, a nationwide lockdown induced by the COVID-19 pandemic required a swift transition to a virtual conference. This article describes the challenges and benefits we encountered with this transition and provides an overview of the conference content.",
    "author": [
      {
        "name": "Elizabeth J. Atkinson",
        "url": {}
      },
      {
        "name": "Peter D. Higgins",
        "url": {}
      },
      {
        "name": "Denise Esserman",
        "url": {}
      },
      {
        "name": "Michael J. Kane",
        "url": {}
      },
      {
        "name": "Steven J. Schwager",
        "url": {}
      },
      {
        "name": "Joseph B. Rickert",
        "url": {}
      },
      {
        "name": "Daniella Mark",
        "url": {}
      },
      {
        "name": "Mara Alexeev",
        "url": {}
      },
      {
        "name": "Stephan Kadauke",
        "url": {}
      }
    ],
    "date": "2021-06-01",
    "categories": [],
    "contents": "\n\nIntroduction\nR/Medicine is an active working group of the R consortium, with the goal\nof supporting R users in medicine, medical research, and related health\nfields. The group includes a mix of statisticians and physicians who use\nR regularly in their work, as well as members from RStudio and the R\nFoundation.\nThe 2018 inaugural R/Medicine conference was a two day event held near\nYale University with Rob Tibshirani providing the initial keynote\naddress; each day began with a two hour tutorial. In 2019 the conference\nwas held in Boston and included, among others, keynote addresses by\nTerry Therneau and Frank Harrell. Two half-day workshops were held on\nthe day prior to the conference.\nIn 2020, the R/Medicine Working Group organized the third annual\nR/Medicine conference which was originally planned to be held in\nPhiladelphia. By early April 2020 it was clear that the conference would\nneed to be held virtually. This article describes some of the challenges\nas well as unexpected benefits we encountered when pivoting to a virtual\nconference, with the hope of providing useful information for other\nconference organizers.\nConference Planning and Logistics\nInitial planning for the conference began in January 2020. By February,\nwe had identified keynote speakers and workshop leaders, and started\nnegotiations with a hotel near the Children’s Hospital of Philadelphia\nwhich was pegged as the site of the conference. However, by the\nbeginning of April we realized that we would need to switch to a virtual\nevent.\nThe initial challenge for the planning committee was identifying\ntechnology that would allow us to run a main session of presentations,\nteach short courses, and host Birds-of-a-Feather (BoF) activities that\nallow like-minded R users to network and socialize. Because of our\nlimited budget we had limited choices for an online conferencing\nplatform. With help from the Linux Foundation, which provided\nrecommendations of some of the available conference platforms, we chose\nto use Crowdcast (https://www.crowdcast.io). This tool was simple to\nuse for the attendees and the organizers, had a green room to line up\nspeakers, an interactive chat feature, and the ability to automatically\nprovide a recording of the session for replay immediately after its\nconclusion. Compared to other conference platforms, Crowdcast has a\nrather minimalist set of features. However, feedback from conference\nparticipants confirmed that the user interface, consisting of a\nsingle-track video feed and sidebar participant chat worked well. One\ndownside of Crowdcast was that it did not support screen readers or\nclosed captioning.\nFor the short courses we chose Zoom (https://zoom.us) as the delivery\nplatform, primarily because of its widespread use and because of a\nmature breakout room functionality. We found that breakout rooms are a\nuseful tool for teaching, but should be used sparingly, because the\noverhead of sending participants into breakout rooms can interrupt the\nflow of teaching the material. For the Introduction to R for\nClinicians course, we had a meet-and-greet breakout near the beginning\nof the course as well as a final “Hackathon” breakout in which\nparticipants were able to team up to design a dashboard.\nOften, the most effective way to teach programming topics is live coding\n(Wilson 2019). Much effort has been devoted to create teaching\nenvironments that allow participants to live code during a short course\nwithout requiring installation of any software. In the R ecosystem, the\nmost notable and laudable effort in this regard is RStudio Cloud\n(https://rstudio.cloud), which is based on the RStudio Server\nIntegrated Development Environment (IDE). From previous experience\nteaching R to an audience of clinicians who have no programming\nexperience and are unfamiliar with the R ecosystem, we knew that the\nRStudio Cloud environment could be challenging because it requires each\nparticipant to first register a personal account on the platform before\nbeing granted access to the training environment. To address this, we\ncreated a training environment with pre-configured generic sequentially\nnumbered training accounts (e.g., train001, train002, etc.). After\nreceiving training account credentials, a participant could directly\naccess their training environment from a web browser without any further\nsign-ups. The training environment was implemented as a Docker-based web\napplication based on RStudio Server which was configured with custom R\npackages and exercise files and hosted on a cloud provider. The\napplication is available for free online (Kadauke 2020c).\nZoom was used for the BoF sessions, and we used Slack for back-channel\ncommunication between the organizers, participants, and presenters. Some\nSlack channels were created for participants while other channels were\nlimited to the conference planners. After the conclusion of the\nconference, all the recorded presentations were loaded onto the\nR/Medicine 2020 YouTube channel which is hosted by the R Consortium\n(2020). Since September 13, 2020 when the videos were uploaded,\nthere have been over 3,200 views. Registration and abstract submission\nwere facilitated by infrastructure provided by the Linux Foundation.\nGoogle Sheets were used to centralize organization of the program and\nthe list of volunteers. We used Google Docs for creating conference\nplanning documents and Google Forms for course sign-ups and surveys.\nSince the @r_medicine Twitter account has a large following (2,557 as\nof June 2021), we used Twitter as the main outlet to promote the event.\nWe also directly engaged specific groups that we wanted to participate\nto improve the conference experience, including R/Ladies, Minorities in\nR, as well as medical professional organizations including the American\nAssociation for Clinical Chemistry (AACC), and Mass Spectrometry &\nAdvances in the Clinical Lab (MSACL).\nVolunteers\nThe number of volunteers needed for the virtual conference was\nsignificantly higher than for the previous in-person R/Medicine\nconferences. For each short course we had at least one teaching\nassistant for every 10 participants. Additionally, we had someone\nmonitoring the Zoom chat to escalate issues when necessary.\nFor the main session we had two moderators who alternated between\nspeakers in order to orient the upcoming speaker in the green room. We\nalso had a Crowdcast host who helped behind the scenes and moved\nparticipants from one presentation to the next. One person was also in\ncharge of playing any of the talks that were pre-recorded. Each BoF room\nhad a facilitator. Because this was a virtual conference, we also\nidentified back-up volunteers in case there were power outages or issues\nwith internet access. Pre-conference training and discussion sessions\nwere held for short course teaching assistants. Pre-conference technical\nchecks were held prior to the conference for the speakers, instructors,\nand volunteers.\nThe Conference\nIn the previous two years, attendance at each conference was around 150\nparticipants. In 2020, 587 people registered for the conference,\nincluding 225 students, 185 academics, 104 from industry, and 73 who\nwere working on COVID-19 related projects. Of these, 32% were from\noutside the United States coming from 43 countries (Figure\n1). Of those who registered, 452 attended at least some\nsessions live and 431 watched some sessions via the replay feature in\nCrowdcast. The main conference was held over two days and included 4\nkeynote addresses, 16 regular talks, 11 lightning talks, and one panel\ndiscussion. The schedule included three BoF time slots, each with 4-5\ndifferent topics.\n\nFigure 1: Location of those who registered for the 2020\nR/Medicine conference\nWe conducted a brief post-conference survey, which garnered 163\nresponses. We included the question “How likely are you to recommend\nthis conference to a friend or colleague?” with a 1-5 scale. The “net\npromoter score”, which was calculated by subtracting the fraction of\nrespondents rating the aforementioned question between 1-3 from the\nfraction of respondents rating it a 5, was 55%. Of all respondents, 98%\nindicated that they planned to attend R/Medicine in the future.\nShort Courses\nPre-conference events included two short courses presented on the day\nprior to the conference. The first course, Introduction to R for\nClinicians, is an adaptation of the popular Welcome to the Tidyverse\ncourse (Grolemund 2019) for an audience of healthcare professionals and\nclinical researchers. The four-hour course placed heavy emphasis on\nreproducibility and using R Markdown as a computational document format\nand introduced fundamental concepts of data visualization and data\ntransformation using the tidyverse set of tools (Wickham et al. 2019). Course\nmaterials (Kadauke 2020a) and recordings (Kadauke 2020b) are available\nonline.\nThe second course, Introduction to Machine Learning with Tidymodels,\nwas taught by Alison Hill and focused on the data scientist/statistician\naudience. This four-hour course aimed to provide a gentle introduction\nto machine learning with R using the modern suite of predictive modeling\npackages called tidymodels. Participants practiced building,\nevaluating, comparing, and tuning predictive models interactively. The\ncourse introduced fundamental concepts including resampling,\noverfitting, the holdout method, the bias-variance trade-off,\nensembling, cross-validation, and feature engineering; the course\nmaterials (Hill 2020) is available online.\nAttendance at the short courses was limited by request of the\ninstructors. The Introduction to R for Clinicians class drew 143\nparticipants, and 80 attended the Introduction to Machine Learning with\nTidymodels course. Course recordings were available for anyone\nregistered for the conference.\nScientific Program\nWe received 43 abstracts and accepted 25. Additionally, we held space\nfor late-breaking COVID-19 related presentations and for two sponsors.\nThe Scientific Program of the conference was divided into six sessions,\neach covering a broad theme.\nR in Clinical Research/Clinical Trials:\nThis session started with a presentation by Daniela Witten, in which the\nkeynote speaker presented a theoretical framework for re-using data that\nwas collected for testing pre-specified hypotheses to drive new\nhypothesis generation. Additional sessions focused on analyzing and\nreporting clinical trial data as well as outlier and anomaly detection\nin clinical trial data sets.\nCollaboration/Reproducibility:\nThe second session started with a keynote by Robert Gentleman in which\nhe outlined the value of large, well-curated data sets as well as how\nthe R ecosystem will be essential for developing new treatments as well\nas validating and deploying healthcare analytics and clinical decision\nsupport tools. Additional talks discussed the {drake} and\n{holepunch} packages.\nNew analysis approaches and packages:\nThe last session of the first day started with a dazzling presentation\nby Travis Gerke and Garrick Aden-Buie in which the speakers discussed\nthe development of internal R packages. An early prototype of a package\nfor creating CONSORT diagrams was presented, as well as summaries of\nmore mature packages including {gtsummary}, {nDSPA}, and\n{treeheatr}.\nR in Clinical Practice, Education, and Bioethics:\nThe first session of the second conference day started with a keynote\nspeech by Ewen Harrison in which he highlighted the flexibility and ease\nof using R which makes it an ideal platform for clinician-researchers or\nother researchers who are not primarily programmers, as well as the\ncollaborative nature of the R community. Additional presentations\ndiscussed the role of R in processing laboratory data in clinical\npractice as well as teaching R to healthcare professionals. Finally, a\nteam presentation by Joy Payton and Paulette McRae highlighted the\nproblematic history of racism in medical research and practice,\ndiscussed root causes of bias in data, and offered suggestions to\nmitigate these biases.\nDashboards and Shiny Apps:\nThis session discussed a variety of web applications developed using the\nShiny framework that were being used either in clinical practice or\nclinical research.\nCOVID-19 research:\nThe final session started with a keynote by Patrick Mathias, who shared\nhis experience directing both the clinical operations and operational\nanalytics efforts of one of the busiest clinical COVID-19 testing\nlaboratories in the United States (Greenwich 2020). Additional presentations\nhighlighted the role R has played in coordinating the response to the\nCOVID-19 pandemic.\nLessons learned\nOverall, the conference succeeded well beyond our expectations. Some of\nthe lessons we learned are as follows.\nThe chat feature helped build community and allowed active\nparticipation in the conference. For instance, some presenters\ntag-teamed where one person presented and another answered questions\nvia chat as they arose. Other presenters had pre-recorded their talk\nand were thus able to answer live questions during the playback of\ntheir presentation.\nSlack was essential for the behind-the-scenes coordination,\nespecially as issues arose. Additionally, we had participants create\ntheir own channels and Zoom sessions for further discussion on\ncertain topics.\nHaving back-ups for all the major coordinating roles was essential.\nFortunately we had limited issues, but one keynote speaker\nexperienced a power outage, leading to an unavoidable delay.\nAlthough Crowdcast allows for smooth transitioning between speakers,\ntime to transition between presenters needs to be built into the\nschedule, since presenters run over, technical issues emerge, and\nbio-breaks are important. It is also wise to build in some flex-time\nin case there are technical difficulties.\nDuring the presentations it was challenging to let speakers know\nwhen they were running out of time. All moderators downloaded a app\nto their phones that allowed them to play a doorbell sound to\nindicate to the speaker that their time is almost up, however that\nwas not always effective. For 2021 we are planning to require that\nlightning talks be pre-recorded.\nHaving a virtual meeting greatly expanded our reach. In 2019 we held\nthe conference in Boston and had roughly 150 attendees from a\nhandful of countries whereas in 2020 we had 452 attendees from 43\ncountries. We hope that the larger attendance will increase our\nimpact as well as our ability to obtain sponsors for future\nconferences.\nRecruitment for high caliber keynote speakers was perhaps easier\nbecause the time commitment and travel effort were substantially\nless than for an in-person conference.\nSponsors\nWe would like to thank all the sponsors that supported the 2020\nconference: American Association for Clinical Chemistry (AACC),\nChildren’s Hospital of Philadelphia (CHOP), Association for Mass\nSpectrometry & Advances in the Clinical Lab (MSACL), Procogia, the R\nConsortium, RStudio, and Yale School of Public Health.\nAcknowledgements\nAs members of the R/Medicine 2020 Organizing and Programming Committees,\nwe would like to thank all the volunteers who contributed to the success\nof the conference, the course instructors and teaching assistants, the\nkeynote and contributed speakers, and all the attendees who dialed in\nfrom around the globe.\nLinks\nFurther information about R/Medicine 2020 and the contributions\npresented during the conference can be found at the conference website:\nhttps://events.linuxfoundation.org/r-medicine/\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\nA. Greenwich. Interview with dr. Alex greenwich. 2020. URL https://muckrack.com/broadcast/savedclips/view/ZfQEE5xUEW.\n\n\nG. Grolemund. Welcome to the tidyverse. 2019. URL https://github.com/rstudio-education/welcome-to-the-tidyverse.\n\n\nA. Hill. Tidymodels, virtually - course notes. 2020. URL https://github.com/rstudio-education/tidymodels-virtually.\n\n\nS. Kadauke. Intro to r for clinicians - course notes. 2020a. URL https://github.com/skadauke/intro-to-r-for-clinicians-rmed2020.\n\n\nS. Kadauke. Intro to r for clinicians - recordings. 2020b. URL https://docs.google.com/document/d/e/2PACX-1vSSeD39D4_nxC4S7lVgyLx9mZjQiU5W96S_4r3Nne8fFVD4aoEiGwnjz0E7nEh-_YYtEyt-9HFWYB78/pub.\n\n\nS. Kadauke. RStudio server pro training environment. 2020c. URL https://github.com/skadauke/rsp-train.\n\n\nR/medicine 2020 YouTube channel. YouTube, 2020. URL https://www.youtube.com/playlist?list=PL4IzsxWztPdljYo7uE5G_R2PtYw3fUReo.\n\n\nH. Wickham, M. Averick, J. Bryan, W. Chang, L. D. McGowan, R. François, G. Grolemund, A. Hayes, L. Henry, J. Hester, et al. Welcome to the tidyverse. Journal of Open Source Software, 4(43): 1686, 2019. URL https://doi.org/10.21105/joss.01686.\n\n\nG. Wilson. Teaching tech together. Taylor; Francis, 2019.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2021-1-whyrturkey2021conferencereport/",
    "title": "Conference Report of Why R? Turkey 2021",
    "description": "The Why R? Turkey 2021 as a three-day online conference was organized to bring together researchers and professionals from Turkey on April 16-17-18, 2021. We hereby aimed to promote the R community in Turkey by bringing R users with different backgrounds such as genetics, sociology, finance, economy, bio-statistics. There were 8 thematic sessions and 18 invited speakers. In this article, it is aimed to describe the preparation phase, technical details, and the impact of the conference on audience.",
    "author": [
      {
        "name": "Mustafa Cavus",
        "url": {}
      },
      {
        "name": "Olgun Aydın",
        "url": {}
      },
      {
        "name": "Ozan Evkaya",
        "url": {}
      },
      {
        "name": "Ozancan Ozdemir",
        "url": {}
      },
      {
        "name": "Deniz Bezer",
        "url": {}
      },
      {
        "name": "Ugur Dar",
        "url": {}
      }
    ],
    "date": "2021-06-01",
    "categories": [],
    "contents": "\n\n1 Why R? Turkey 2021\nThe Why R? Turkey 2021 is a pre-meeting of Why\nR? 2021 conference. Why R? conferences are international conference\nseries organized annually by the Why R? Foundation since\n2017. It is one of the largest annual R conferences in Central Europe\n(Burdukiewicz et al. 2019). In addition to the main conference, pre-meetings are held in\ndifferent cities from all over the world. In 2017, four pre-meetings\nwere organized in Poland. Thereafter, eleven pre-meetings across four\ndifferent countries were held in 2018. In 2019, twelve pre-meetings took\nplace in eight different countries. In 2020, in a pre-meeting framework,\ntotally six organizations appeared in four different countries (Poland\n(2), Turkey (2), Ireland (1), and Germany (1)). Among those six\npre-meetings, two of them were held in Istanbul (24.04.2020) and Ankara\n(27.04.2020) consecutively, as a one-day organization (Why R 2020).\nFigure 1: The logo of Why R? Turkey 2021.Two primary goals of Why R ? Turkey 2021 are;\nto bring together Turkish R users from all over the world\nto broaden the horizon of the students with respect to the diverse\ndisciplines\nFor this purpose, experienced researchers, who are R users, from various\ndisciplines were invited to the conference as a speaker. The conference\nprogram was designed comprehensively to cover various research fields\nsuch as bio-statistics, sociology, educational sciences, psychology,\nmolecular biology, genomics, football analytics, and economics. The\ndetailed program is shown in Table 1.\n2 Participants\nThere were 2180 registered participants, 60% were students and 40% were\nprofessionals who work for governmental institutions, companies from the\nprivate sector, and academicians from the universities in Turkey. With\nregards to the education level of the student participants, 50% of them\nwas graduate and rest was undergraduate students. 60% of the students\nstudy Statistics. The number of unique participants for the conference\nis 880. Additionally, the share of each thematic session is counted as\n540, 435, 380, 355, 390, 360, respectively. The whole event was\norganized and moderated by the organization committee including 6\nmembers.\nMost of the participants were registered from İstanbul, Ankara, and\nİzmir, respectively. In the conference, we had participants from 73\nprovinces out of 81 provinces in Turkey. The distribution of registered\nparticipants by provinces is illustrated in Figure 2.\nFigure 2: The Distribution of Participants by\nProvincesIn addition to Turkey, we had participants from the USA, England,\nBelgium, Sweden, Switzerland, Qatar, Nederland, Italy, France, and\nSpain. In that respect, the conference was successful to bring Turkish R\nusers from different countries as well.\n3 Conference Program\nThe detailed conference program, shown in Table 1, consists\nof 6 main sessions over three days. For each speaker, there were 30\nminutes to complete his/her presentation and thereafter the participants\nare guided to the breakout rooms in the Zoom platform for Q&A session\nwith the speaker.\n\nTable 1: Program of the Why R? Turkey 2021\nSession\nSpeaker\nTitle\n\nZararsız\nUsing R in Medicine and Diagnostic Domains: The Case of the Alzheimer Project\n1\nDinçer\nBioSoft: A cloud-based platform for Biostatistics/Bioinformatics softwares developed using R programming language\n\nErdal Coşgun\nGenetic research on cloud-based systems: The Bioconductor experience\n\nTuba Bircan\nR for whom?\n2\nKaya\nData Analysis and using theory in R for sociological researches: Opportunities and challenges\n\nDilek Yıldız\nUsing R in demography\n\nAli O. İlhan\nR and bibliometric analysis: a brief introduction\n\nKadir Kızılkaya\nUsing R for animal breeding and genomic selection\n3\nHilal Özkılınç\nUsing R in genomics studies\n\nBurcu Mestav\nUsing R in aquaculture and ecology\n\nMehmet Can Demir\nResearch studies in educational science using R\n4\nKübra Atalay Kabasakal\nR packages for educational science\n\nEren Halil Özberk\nUsing R in psychology\n\nYeşim Güney\nStructural Breakpoints in Turkey COVID-19 data\n5\nİpek Güler\nR packages for joint modeling of survival and recurrent data\n\nEmre Toros\nSoccer, data, why, how, and R\n\nBurak Saltoğlu\nBehavioral financial analysis by using R\n6\nAhmet Akgül\nRegression analysis in R: house price prediction model for Istanbul\n\nAyhan Yüksel\nAlgoritmic trade using R\n\n4 Promotion of the Event and Reactions\nThe social media channels (Instagram, Twitter, Facebook and, LinkedIn)\nwere used for the promotion of the conference. Conference social media\naccounts were created to conduct the promotion except LinkedIn.\nOrganization committee members’ personal LinkedIn accounts were\npreferred to promote the event.\nInstagram ads were used to reach out bigger audience. Advertisements\nwent live two weeks before starting date of the conference and finished\n4 days before the conference started. At the end of this period, we\nobtained more than 500 followers most of whom are young adults as shown\nin Figure 3. Besides, the Instagram account of the conference\nwas visited more than 2.000 times during the advertisement period.\nFigure 3: Age Distribution of Instagram\nFollowersIn addition to Instagram, Twitter was also used efficiently for the\npromotion. The Twitter account for this event was created in January,\nbut the posts started to be shared at the end of February. To reach R\nusers, all contents were posted using the #Rstats hashtag. As of May\n8, the Twitter account of the conference was visited by more than 18000\nusers, and tweets were viewed more than 174000 times.\nAccording to our calendar, we started to share our posts once a week on\nTwitter. Although post frequency was lower at the beginning, the number\nof followers reached over three hundreds quickly. However, the account\ngained the highest number of followers in April. (Figure 4).\nFigure 4: Evolution of the number of followers of the WhyR? Turkey\n2021 Twitter AccountThus, visits and view statistics of the Twitter account show that\nTwitter was the most efficient platform to reach R users.\n5 Technical Solutions\nThe official website was developed and used as the primary information\nsource for the conference. The website was hosted on Why R?\nFoundation’s domain. This allowed us to be more visible on\nGoogle Search. The abstract book was prepared using the bookdown R\npackage and was served via the website.\nInstant updates in terms of program, speakers, program, schedule, were\nshared with the audience via Instagram, and Twitter accounts, dedicated\nto the conference. Twitter and Instagram account caught the attention of\npeople interested in participating in the conference very quickly.\nGoogle Forms was preferred for registration purposes and used as a\ncontact form. Hyperlinks to the registration form and contact form were\nadded to the website. During registration, participants were asked to\nanswer questions regarding their professional background, education\nlevel, R knowledge. Thanks to this, we had a chance to better understand\nparticipants’ profiles.\nAll speeches were streamed on Zoom. Premium zoom account was purchased\nto be able to have 1000 participants online at the same time. Separate\nzoom meetings were set for each session. After each talk, dedicated\nbreakout rooms were created and Q&A sessions were conducted in breakout\nrooms. This allowed the audience to have more interaction with speakers.\nThe cost of the Zoom account was covered by the funding received from\nWhy R? Foundation and R Consortium. URLs for the recordings, as well as\nslide decks and R scripts used by speakers during presentations, shared\npublicly on the GitHub\nrepository of the\nconference.\n6 Summary\nThe three-day online conference of Why R? Turkey 2021 aimed to bring R\nusers from different fields and make a connection between the Turkish R\nusers and possible future users from various disciplines. In that\nrespect, the attained total number of participants, the fruitful Q&A\nsessions and the overall positive attitudes from all\nspeakers/participants revealed that the meeting reached its main\nobjective. To sum up, Why R? Turkey 2021 is the best comprehensive\nonline meeting held for Turkish R users and it promises both national\nand international organizations in the near future.\n7 Acknowledgment\nWe would like to thank all the sponsors that support the organization of\nWhy R? Turkey 2021: Why R?\nFoundation, R\nConsortium, and\nStickerMule.\n8 Additional Information\nFurther information about Why R? Turkey 2021 and the contributions\npresented during the conference can be found at the following links:\nWebsite: http://whyr.pl/2021/turkey/\nTwitter: https://twitter.com/whyr2021turkey\nYouTube Channel:\nhttps://www.youtube.com/channel/UCr8qT7gK9WQZjCNz7Agi7sA\nMaterials: https://github.com/whyr2021turkey\nAbstract Book: http://whyr.pl/2021/turkey/abstract_book/\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\nM. Burdukiewicz, F. Pietluch, J. Chilimoniuk, K. Sidorczuk, D. Rafacz, L. E. Jessen, S. Rödiger, M. Kosinski and P. Wojcik. Conference report: Why r? 2019. R Journal, 12(1): 484–493, 2019. URL https://doi.org/10.1080/10618600.1996.10474713.\n\n\nF. Why R. 2020. URL http://whyr.pl/foundation/events/\\#2020.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2020-2-bioc/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2020-2 issue.",
    "author": [
      {
        "name": "Bioconductor Core Team",
        "url": {}
      }
    ],
    "date": "2020-12-01",
    "categories": [],
    "contents": "\n\nBioconductor provides tools for the analysis\nand comprehension of high-throughput genomic data. Bioconductor 3.12 was\nreleased on 28 October, 2020. It is compatible with R 4.0.3 and consists\nof 1974 software packages, 398 experiment data packages, 968 up-to-date\nannotation packages, and 28 workflows.\nBooks are a new addition,\nbuilt regularly from source and therefore fully reproducible; an example\nis the community-developed Orchestrating Single-Cell Analysis with\nBioconductor.\nThe Bioconductor 3.12 release\nannouncement includes\ndescriptions of 125 new software packages, and updates to NEWS files for\nmany additional packages. Start using Bioconductor by installing the\nmost recent version of R and evaluating the commands\n  if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n      install.packages(\"BiocManager\")\n  BiocManager::install()\nInstall additional packages and dependencies, e.g.,\nSingleCellExperiment,\nwith\n  BiocManager::install(\"SingleCellExperiment\")\nDocker images provides a very\neffective on-ramp for power users to rapidly obtain access to\nstandardized and scalable computing environments. Key resources include:\nbioconductor.org to install, learn, use,\nand develop Bioconductor packages.\nA list of available software,\nlinking to pages describing each package.\nA question-and-answer style user support\nsite and developer-oriented\nmailing list.\nA community slack (sign up)\nfor extended technical discussion.\nThe F1000Research Bioconductor\nchannel for\npeer-reviewed Bioconductor work flows.\nThe Bioconductor\nYouTube channel\nincludes recordings of keynote and talks from recent conferences\nincluding BioC 2020 and BioC Asia 2020, in addition to video\nrecordings of training courses and developer forums.\nOur package\nsubmission\nrepository for open technical review of new packages.\nRecent Bioconductor conferences include\nBioC2020 (July 27-31), BioC Asia\n2020 (October 15-18), and the\nEuropean Bioconductor Meeting\n(December 14-18). Each had invited and contributed talks, as well as\nworkshops and other sessions to enable community participation. Slides,\nvideos, and workshop material for each conference are available on\nconference web sites as well as the Courses and\nConferences section of\nthe Bioconductor web site. BioC\n2021 is planned for August 4-6,\nwith an abstract submission due date of March 9; the virtual conference\nwill be augmented by in-person activities if global health permits.\nThe Bioconductor project continues to mature as a community. The\nTechnical\nand\nCommunity\nAdvisory Boards provide guidance to ensure that the project addresses\nleading-edge biological problems with advanced technical approaches, and\nadopts practices (such as a project-wide Code of\nConduct) that\nencourages all to participate. We look forward to welcoming you!\n\n\nBioconductor packages used\nSingleCellExperiment\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2020-2-core/",
    "title": "Changes in R 3.6--4.0",
    "description": "We give a selection of the most important changes in R 4.0.0 and in the R 3.6 release series. Some statistics on source code commits and bug tracking activities are also provided.",
    "author": [
      {
        "name": "Tomas Kalibera",
        "url": {}
      },
      {
        "name": "Sebastian Meyer",
        "url": {}
      },
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2020-12-01",
    "categories": [],
    "contents": "\n\n1 R 4.0.0 selected changes\nR 4.0.0 (codename “Arbor Day”) was released on 2020-04-24. The following\ngives a selection of the most important changes.\nmatrix objects now also inherit from class \"array\", so e.g.,\nclass(diag(1)) is c(\"matrix\", \"array\"). S3 methods for class\n\"array\" are now dispatched for matrix objects. This reduces the\nneed of code duplication between \"array\" and \"matrix\" classes,\nbut invalidates code incorrectly assuming that class(matrix_obj))\nhas length one. In principle, to check whether an object inherits\nfrom (any) class, one should always use inherits() (or is()).\nSee Martin Maechler’s blog\npost\nfor more details.\nThere is a new syntax for specifying raw character constants\nsimilar to the one used in C++: r\"(...)\" with ... any character\nsequence not containing the sequence )\". This makes it easier to\nwrite strings that contain backslashes and/or both single and double\nquotes:\nr\"(c:\\Program files\\R)\" specifies a Windows directory without\nescaping backslashes. r\"(use both \"double\" and 'single' quotes)\"\nmixes single and double quotes without the need to escape either of\nthem. For more details see ?Quotes.\nR now uses a stringsAsFactors = FALSE default, and hence by\ndefault no longer converts strings to factors in calls to\ndata.frame() and read.table(). Automatic conversion of strings\nto factors regardless of the context of the study at hand seems\nconceptually wrong. In addition, when the automatically applied\norder is lexicographical order, the result is locale dependent and\neven so when only ASCII characters are used. Historically, automatic\nconversions to factors could have been disabled on demand, but\nunfortunately that meant that all code dealing with data frames\nwould have to support both ways. That was not the case, leading to\nsurprising or unpredictable results. A large number of packages\nrelied on the previous behavior and so have needed updating. Unlike\nin the case of matrices being treated as arrays, this was a change\nto documented behavior, so even correct package code was affected.\nSee Kurt Hornik’s blog\npost\nfor more details.\nReference counting is now used instead of the NAMED mechanism for\ndetermining when objects can be safely mutated in base C code. This\nreduces the need for copying in some cases and should allow further\noptimizations in the future. It should help make the internal code\neasier to maintain. In principle, even the NAMED mechanism was a\nvariant of reference counting, but a simple one where the number of\nreferences could only increase (up to a maximum value). Even as\nsimple operations as passing an R object (value) to a function that\nwould only read it would permanently increase the reference count of\nthat object, even after that reading-only function would return. Any\nmodification of that object later on would require a copy. This is\none of the scenarios fixed by the new mechanism where the reference\ncounts can and often do decrease as well, so that R knows much more\noften that some R values are in fact private and can be modified in\nplace. This change should not impact existing code (does not break\npackages) using supported coding practices in C/C++. It has no\ndirect impact on R code other than performance/memory usage.\nR now has a listening server socket object which allows to accept\nmultiple incoming socket connections. This simplifies implementation\nof servers and allows them to accept multiple connections much\nfaster. The time needed to set up a PSOCK cluster has been reduced\nusing this new API particularly for clusters with a large number of\nnodes. See a blog\npost\nof Tomas Kalibera and Luke Tierney for more details.\nS3 method lookup now by default skips the elements of the search\npath between the global and base environments, and there is a new\nfunction .S3method() to register S3 methods in R scripts. See\nKurt Hornik’s blog\npost\nfor more details.\nThe palette() function has a new default set of colors which are\nless saturated and have better accessibility properties. There are\nalso some new built-in palettes, which are listed by the new\npalette.pals() function. The new palette.colors() function\nallows a subset of colors to be selected from any of the built-in\npalettes. See a blog\npost\nof Achim Zeileis, Paul Murrell, Martin Maechler, and Deepayan Sarkar\nfor more details.\nThe internal implementation of grid units has changed, but the\nonly visible effects at user-level should be a slightly different\nprint format for some units (especially unit arithmetic), better\nperformance (for unit operations) and two new functions unitType()\nand unit.psum(). Packages that were directly accessing elements of\nthe unit implementation needed updating. See a blog\npost\nby Paul Murrell and Thomas Lin Pedersen for more details.\nThe support for symbol fonts in cairo-based graphics devices has\nbeen improved and one can now specify which symbol font to use. See\nPaul Murrell’s blog\npost\nfor more details.\nSee https://CRAN.R-project.org/doc/manuals/r-patched/NEWS.html for all\nchanges in the current release series of R, which at the time of this\nwriting is R 4.0.z. Overall, there are 156 news entries for the 4.0.0\nrelease, including 5 significant user-visible changes, 65 new features\nand 55 bug fixes.\n2 R 3.6.z selected changes\nR 3.6.0 (codename “Planting of a Tree”) was released on 2019-04-26 and\nthe R 3.6 series closed with the release of R 3.6.3 (“Holding the\nWindsock”) on 2020-02-29, marking the 20th anniversary of the R 1.0.0\nrelease. The following gives a selection of the most important changes\nin the 3.6 series.\nThe default method for generating from a discrete uniform\ndistribution (used in sample(), for instance) has been changed.\nThis addresses the fact, pointed out by Ottoboni and\nStark, that the previous method\nmade sample() noticeably non-uniform on large populations. See\nPR#17494\nfor a discussion. The previous method can be requested using\nRNGkind() or RNGversion() if necessary for reproduction of old\nresults. Thanks to Duncan Murdoch for contributing the patch and\nGabe Becker for further assistance.\nThe output of RNGkind() has been changed to also return the ‘kind’\nused by sample().\nSerialization format version 3 becomes the default for serialization\nand saving of the workspace (save(), serialize(), saveRDS(),\ncompiler::cmpfile()). Serialized data in format 3 cannot be read\nby versions of R prior to version 3.5.0. Serialization format\nversion 2 is still supported and can be selected by version = 2 in\nthe save/serialization functions. The default can be changed back\nfor the whole R session by setting environment variables\nR_DEFAULT_SAVE_VERSION and R_DEFAULT_SERIALIZE_VERSION to 2.\nFor maximal back-compatibility, files vignette.rds and\npartial.rdb generated by R CMD build are in serialization format\nversion 2, and resave by default produces files in serialization\nformat version 2 (unless the original is already in format version\n3). The new serialization format is already supported since R\nversion 3.5.0. It allows compact representation of ALTREP objects,\nso that e.g. compact integer sequences are saved as compact. All\nelements of such sequence have to be enumerated in format version 2.\nThe new serialization format also saves the current local encoding\nat the time of serialization and strings in native encoding are\ntranslated when de-serialized in an R session with different native\nencoding.\nlibrary() and require() now allow more control over handling\nsearch path conflicts when packages are attached. The policy is\ncontrolled by the new conflicts.policy option. See Luke Tierney’s\nblog\npost\nfor more details.\nR now uses staged installation of R packages. A package is first\ninstalled into a temporary library invisible to other R sessions and\nthen moved to the final library location. This reduces interference\ndue to partially installed packages which has been observed\nparticularly during parallel installation. See Tomas Kalibera’s\nblog\npost\nfor more details.\nNew hcl.colors() function to provide wide range of HCL-based color\npalettes with much better perceptual properties than the existing\nRGB/HSV-based palettes like rainbow(). Also a new hcl.pals()\nfunction to list available palette names for hcl.colors().\nContributed by Achim Zeileis. See blog\npost\nof Achim Zeileis and Paul Murrell for more details.\nThere are two new options, keep.parse.data and\nkeep.parse.data.pkgs, which control whether parse data are\nincluded into source (source references) when keep.source or\nkeep.source.pkgs is TRUE. By default, keep.parse.data.pkgs is\nnow FALSE, which changes previous behavior and significantly\nreduces space and time overhead when sources are kept when\ninstalling packages. See Tomas Kalibera’s blog\npost\nfor more details on this and other performance optimizations in the\nparser.\nR 3.6.2 has been fixed to pass hidden string length arguments when\ncalling LAPACK from C. Macros were provided also for packages that\ncall LAPACK directly. This was urgently needed after a new GNU\nFortran release introduced optimizations which caused crashes with\ncode calling LAPACK (or other Fortran code) the “old way”, yet\nwidely used in numerical software including CBLAS and LAPACKE\nitself. GNU Fortran disabled again these optimizations by default in\nlater releases as a result of these findings. For more details, see\nWriting R\nExtensions\nand the\nfirst\nand\nsecond\nblog post by Tomas Kalibera on this issue (the changes in R were\nimplemented and documented by Brian Ripley).\nNew pointer protection C functions R_PreserveInMSet and\nR_ReleaseFromMSet have been introduced to replace UNPROTECT_PTR,\nwhich is not safe to mix with UNPROTECT (and with\nPROTECT_WITH_INDEX). Intended for use in parsers only. See Tomas\nKalibera’s blog\npost\nfor more details.\nS3method() directives in NAMESPACE can now also be used to\nperform delayed S3 method registration. Again, see Kurt Hornik’s\nblog\npost\nfor more details.\nSee https://CRAN.R-project.org/doc/manuals/r-devel/NEWS.3.html for all\nchanges in the R 3.y.z releases. Overall, there are 233 news entries for\nthe 3.6.z releases, including 2 significant user-visible changes, 75 new\nfeatures and 106 bug fixes.\n3 R 4.0.0 code statistics\nFrom the source code Subversion repository, changes between April 27,\n2019 and April 24, 2020, so the overall code change between R 3.6.0 and\nR 4.0.0 was: over 24,000 added lines, 12,000 deleted lines and 900\nchanged files. This is rounded to thousands/hundreds and excludes\nchanges to common generated files, partially generated files, bulk\nre-organizations, etc. (translations, parsers, autoconf, LAPACK,\nR Journal bibliography, test outputs).\nFigure 1 shows commits by month and weekday, respectively,\ncounting line-based changes in individual commits, excluding the files\nas above. A noticeable increase of activity is in March, so right before\ncode freeze for the release. A secondary peak of the number of commits\ncan be observed in August. The low amount of changes in July 2019 may be\ndue to conferences and vacations.\n\n\n\nFigure 1: Commit statistics by month (left) and weekday\n(right) during R 4.0.0 development. *Note that the counts for April\ndon’t correspond to a unique month.\n4 R 3.6.0 code statistics\nChanges between April 23, 2018 and April 26, 2019, so the overall code\nchange between R 3.5.0 and R 3.6.0 was: nearly 27,000 added lines, over\n17,000 deleted lines and nearly 800 changed files. This is again rounded\nto thousands/hundreds and excludes changes to common generated files.\nFigure 2 again shows large changes in March before code\nfreeze and in August, and decreased activity in July during R\nconferences and usual vacations. The right panel suggests that R Core\nmembers work a lot even during the weekends and it was even more so when\nworking on R 3.6.0 than on R 4.0.0 (compare Saturday and Wednesday).\n\n\n\nFigure 2: Commit statistics by month (left) and weekday\n(right) during R 3.6.0 development. *Note that the counts for April\ndon’t correspond to a unique month.\n5 R 4.0.0 bugs statistics\nSummaries of bug-related activities during the development of R 4.0.0\n(from April 27, 2019 to April 24, 2020) were derived from the database\nunderlying R’s Bugzilla system.\nFigure 3 shows statistics of reported/closed bugs and\nnumber of added comments (on any bug report) by calendar month and\nweekday, respectively.\n\n\n\nFigure 3: Bug tracking activity by month (left) and weekday\n(right) during R 4.0.0 development. *Note that the counts for April\ndon’t correspond to a unique month.\nComments are added by reporters of the bugs, R Core members and external\nvolunteers. When a bug report is closed, the bug is either fixed or the\nreport is found invalid. In principle, this can happen multiple times\nfor a single report, but those cases are rare. Hence the number of\ncomments is a measure of effort (yet a coarse one which does not\ndistinguish thorough analyses from one-liners) and the number of bug\nclosures is a measure of success in dealing with bugs.\nThe numbers were impacted by an increase in external contributions to\nanalyzing bugs following a blog\npost\nof Tomas Kalibera and Luke Tierney, published October 9, 2019, asking\nthe R community for help, and to contribute those analyzes in the form\nof comments to R bug reports. There was a considerable increase of\ncomments in October which has lasted (at least) until April. Note that\nthe April numbers don’t cover a full month and are mostly from the 24\ndays of R 4.0 development in 2020, so after the blog post (4 days are\nfrom April 2019). The rate of closing bugs has increased as well since\nOctober. What the numbers don’t show is that this is also due to\nincreased activity of R Core that followed increased input from external\nvolunteers. The numbers also seem to suggest that even new bug reports\nare submitted at a higher rate once more external volunteers focus on\nanalyzing bugs in R.\nFrom the numbers by weekday in the right panel of Figure 3\nwe again see that the R community keeps working during the weekends.\n6 R 3.6.0 bugs statistics\nFigure 4 summarizes bug tracking activities during the\ndevelopment of R 3.6.0 (from April 23, 2018 to April 26, 2019). The\ndecline observed in coding activity in July does not exist in\nbug-related activities; the number of closed bugs actually peaked in\nJuly.\n\n\n\nFigure 4: Bug tracking activity by month (left) and weekday\n(right) during R 3.6.0 development. *Note that the counts for April\ndon’t correspond to a unique month. For comparison with R 4.0.0, the\ny-axes use the same scales as in Figure .\n7 Acknowledgements\nTomas Kalibera’s work on the article and R development has received\nfunding from the Czech Ministry of Education, Youth and Sports from the\nCzech Operational Programme Research, Development, and Education, under\ngrant agreement No.CZ.02.1.01/0.0/0.0/15_003/0000421, and the European\nResearch Council (ERC) under the European Union’s Horizon 2020 research\nand innovation programme, under grant agreement No. 695412.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2020-2-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2020-2 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2020-12-01",
    "categories": [],
    "contents": "\n\nIn the past 4 months, 818 new packages were added to the CRAN package\nrepository. 100 packages were unarchived and 248 were archived. The\nfollowing shows the growth of the number of active packages in the CRAN\npackage repository:\n\nOn 2020-12-31, the number of active packages was around 16851.\nChanges in the CRAN Repository Policy\nThe Policy now\nsays the following:\nFor R version 4.0 or later (hence a version dependency is required\nor only conditional use is possible), packages may store\nuser-specific data, configuration and cache files in their\nrespective user directories obtained from tools::R_user_dir(),\nprovided that by default sizes are kept as small as possible and the\ncontents are actively managed (including removing outdated\nmaterial).\nSecurity provisions must not be cicrumvented, for example by not\nverifying SSL certificates.\nDownloads of additional [………] For downloads of more than a\nfew MB, ensure that a sufficiently large timeout is set.\nFor a package update, please check that any packages depending on\nthis one still pass R CMD check: [………] If possible, check\nreverse strong dependencies, reverse suggests and the recursive\nstrong dependencies of these (by\ntools::package_dependencies(reverse = TRUE, which = \"most\", recursive = \"strong\")).\nThe CRAN URL\nchecks info\nnow says\nThe CRAN submission checks run by R CMD check –as-cran check the\navailability of URLs in files including DESCRIPTION, CITATION,\nNEWS.Rd, NEWS.md, README.md, and the .Rd help pages and HTML\nfiles in inst/doc.\nA surprisingly large number of websites use redirection and the\nissues may apply to a site redirected to. [………] Where\nredirection is permanent you should use the redirected URL (see RFC\n7231).\nCRAN package submissions\nCRAN mirror security\nCurrently, there are 104 official CRAN mirrors, 77 of which provide both\nsecure downloads via https and use secure mirroring from the CRAN\nmaster (via rsync through ssh tunnels). Since the R 3.4.0 release,\nchooseCRANmirror() offers these mirrors in preference to the others\nwhich are not fully secured (yet).\nNew packages in CRAN task views\nBayesian\n\nBGVAR,\nLAWBL,\nbayestestR,\nblavaan,\nloo.\n\nCluster\n\nFCPS,\ncrimCV.\n\nDistributions\n\nCaDENCE,\nDPQ,\nDistributacalcul,\nForestFit,\nMPS,\nNonNorMvtDist,\nPoissonBinomial,\nQBAsyDist,\nROOPSD,\nbetafunctions,\ncort,\ndgumbel,\ndistributional,\ndistributionsrd,\nelfDistr,\nggamma,\nmniw,\nscModels,\ntvgeom.\n\nEconometrics\n\nNNS.\n\nFinance\n\nFFdownload,\nbmgarch,\ngarchx,\nsimfinapi.\n\nFunctionalData\n\nFDboost\\(^*\\),\nfdaoutlier,\nrefund\\(^*\\).\n\nGenetics\n\nSNPassoc.\n\nHighPerformanceComputing\n\nflexiblas.\n\nHydrology\n\nweathercan.\n\nMachineLearning\n\nmlr3proba.\n\nMetaAnalysis\n\nboot.heterogeneity,\nclubSandwich,\nconcurve,\nestimraw,\ngemtc,\nmetabolic,\nmultinma.\n\nMissingData\n\nSNPassoc.\n\nOfficialStatistics\n\nreclin.\n\nOptimization\n\nirace,\nqpmadr.\n\nPsychometrics\n\nEstimateGroupNetwork,\nLAWBL,\nbetafunctions,\ncops.\n\nReproducibleResearch\n\nascii,\nflextable,\nflowr,\ngroundhog,\nliftr,\nmschart,\nofficer,\nopenxlsx,\nreadODS,\nswitchr,\ntrackr,\ntth,\nworcs,\nxaringan,\nzoon.\n\nRobust\n\nrlme.\n\nTeachingStatistics\n\nbivariate.\n\nTimeSeries\n\nFKF.SP,\nFoReco,\nRobKF,\nTSA,\nTSdist,\nbreakfast,\ndiffusion,\nfredr,\ngreybox,\nifultools,\nmodeltime,\nmodeltime.ensemble,\nmssm,\nportes,\nreadabs,\ntfarima,\ntsibbletalk,\ntsutils.\n\nWebTechnologies\n\nRlinkedin,\nipaddress,\nrdrop2.\n\ngR\n\nspectralGraphTopology.\n\n(* = core package)\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2020-2-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2020-2 issue.",
    "author": [
      {
        "name": "Michael J. Kane",
        "url": {}
      }
    ],
    "date": "2020-12-01",
    "categories": [],
    "contents": "\n\nOn behalf of the editorial board, I am pleased to present Volume 12\nIssue 2 of the R Journal. This is my third and final issue as the\nEditor-in-Chief. In the last year, we have made some substantial changes\nto the journal that I believe will continue to increase our capacity to\nsupport the growing data science and computational statistics\ncommunities, and continue to raise the visibility of the journal. In the\nlast few months we recruited 10 Associate Editors and we are continuing\nthe recruitment process. I’d like to publicly welcome our new Associate\nEditors, and thank each of them for joining us, and for their\ncontributions thus far to the journal.\nWe have also been making substantial improvements to the R Journal\ninfrastructure, allowing us to more efficiently usher manuscripts\nthrough the review process. This effort has been made possible through\nan investment by the R Consortium. Thanks very much to Di Cook, Mitchell\nO’Hara-Wild, and Stephanie Kobakian for the new capabilities - they have\nmade my job a lot easier.\nI’d also like to welcome Di as the new Editor-in-Chief of the journal.\nShe has been an instrumental member of the editorial team, she has\nprovided me with insight and guidance with regard to the journal. I look\nforward to seeing how the journal progresses under her direction.\n1 In this issue\nNews from the R Foundation and CRAN are included in this issue along an\nupdate on the e-Rum2020 conference that was held earlier. In addition,\nthis issue features 23 contributed research articles that have been\ncategorized below.\nPapers focusing on health and clinical trial data\nA Fast and Scalable Implementation Method for Competing Risks Data\nwith the R Package fastcmprsk\nAssembling Pharmacometric Datasets in R - The puzzle Package\nAnalyzing Basket Trials under Multisource Exchangeability\nAssumptions\nComparing multiple survival functions with crossing hazards in R\nSupervised and unsupervised model fitting\nThe biglasso Package: A Memory- and Computation-Efficient Solver\nfor Lasso Model Fitting with Big Data in R\nUser-Specified General-to-Specific and Indicator Saturation Methods\nmiWQS: Multiple Imputation Using Weighted Quantile Sum Regression\nNTS: An R Package for Nonlinear Time Series Analysis\nordinalClust: An R Package to Analyse Ordinal Data\nTULIP: A Toolbox for Linear Discriminant Analysis with Penalties\nA Unified Algorithm for the Non-Convex Penalized Estimation: The\nncpen Package\nKSPM: A Package For Kernel Semi-Parametric Models\nProbability distributions and processes\nTesting the Equality of Normally Distributed Groups’ Means Under\nUnequal Variances by doex Package\nMoTBFs: An R Package for Learning Hybrid Bayesian Networks Using\nMixtures of Truncated Basis Functions\nKuhn-Tucker and Multiple Discrete-Continuous Extreme Value Model\nEstimation and Simulation in R: The rmdcev Package\nSpecies Distribution Modeling using Spatial Point Processes: a Case\nStudy of Sloth Occurrence in Costa Rica\nAQuadtree: an R Package for Quadtree Anonymization of Point Data\nRNGforGPD: An R Package for Generation of Univariate and\nMultivariate Generalized Poisson Data\nFarmTest: An R Package for Factor-Adjusted Robust Multiple Testing\nVisualization, reproducibilty, and collaboration\nA Graphical EDA Tool with ggplot2: brinton\nSix Years of Shiny in Research; Collaborative Development of Web\nTools in R\nfitzRoy: An R Package to Encourage Reproducible Sports Analysis\nOpenLand: Software for Quantitative Analysis and Visualization of\nLand Use and Cover Change\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2020-2-forwards-news/",
    "title": "News from the Forwards Taskforce",
    "description": "The 'News from the Forwards Taskforce' article from the 2020-2 issue.",
    "author": [
      {
        "name": "Heather Turner",
        "url": {}
      }
    ],
    "date": "2020-12-01",
    "categories": [],
    "contents": "\n\nForwards is an R Foundation taskforce\nworking to widen the participation of under-represented groups in the R\nproject and in related activities, such as the useR! conference. This\nreport rounds up activities of the taskforce during the second half of\n2020.\n1 useR! 2020 breakout session: Supporting diversity in the R community\nIn this breakout session at useR! 2020, a panel shared their\nexperience as members of marginalized groups or as allies, then\nresponded to Q&A from useR! participants. The panel was chaired by\nLaura Ación (LatinR co-founder) and Shelmith\nKariuki (AfricaR co-founder), and the panelists\nwere Yanina Bellini Saibene (R-Ladies Global\nTeam and LatinR co-founder), Laís Carvalho (Python Ireland board\nmember), Richard Ngamita\n(KampalaR founder and\nForwards Community Team member), Danielle Smalls-Perkins\n(MiR co-founder), Robin Williams\n(Blind R User\nGroup\nmember), and Greg Wilson (Software Carpentry co-founder and Education\nteam member at RStudio).\nThe panel discussed a range of barriers to participation, such as\nlanguage barriers, limited access to education and conferences, specific\nchallenges faced by visually impaired folk and feelings of isolation due\nto location or identity. They highlighted some positive steps the R\ncommunity has made to promote inclusion, for example, founding groups\nsuch as Forwards, R-Ladies, AfricaR, MiR and the Blind R User Group;\noffering diversity scholarships at R conferences and developing\ntechnical solutions to improve accessibility. However, the panel also\nraised the need for greater inclusion of people from minority groups in\ndecision-making and for accessibility to be at the centre of R\ndevelopment and R community events. Allies were recommended to work\nclosely with affinity groups and to base actions on established\nresearch, for example following the Ally Skills\nWorkshop\n(material available under CC BY-SA 4.0). Further suggestions made in the\nQ&A included offering more tutorials/materials in languages other than\nEnglish, subtitling videos and offering live streaming.\nThe full video of the session is available on\nYouTube with live chat replay. This\nsession was organized by Forwards members Damiano Cerasuolo, Jonathan\nGodfrey, Liz Hare, Tatjana Kecojevic, Imke Mayer, Kevin O’Brien, Noa\nTamir and Heather Turner.\n2 R Contribution Working Group\nPartly in response to the useR! breakout session, Forwards established a\ngroup to work on initiatives to encourage new contributors to R core,\nwith a focus on diversity and inclusion. The R Contribution Working\nGroup is open to anyone interested in working towards this goal and\nrepresentatives from R Core, the R Foundation, Forwards, R-Ladies, MiR,\nthe R Consortium Diversity and Inclusion Working Group, as well as\nmembers of the general R community have joined in. The group has met\nevery 1-2 months since July 2020, alternating between the second Friday\nof the month, 15:00 UTC and the second Tuesday of the month, 21:00 UTC.\nThe group recently created the R Contribution\nSite to host information for\npeople interested in contributing to R core, which has information on a\nSlack group that people can join to discuss related issues and support\neach other in progressing as R contributors. Other initiatives include\nplanning contributor-focused events for useR! 2021. Minutes of meetings\nand work in progress is gathered in the public rcontribution repository\non Forwards GitHub.\n3 Introduction to R Workshop, Lomé, Togo\nA 2-day Introduction to R workshop in Lomé, Togo, was held on 16-17\nDecember 2020. The workshop was organized by Anicet Ebou, a member of\nthe AfricaR leadership team based in Ivory Coast. The objective was to\nintroduce people to R and plant the seeds for a local R User Group (as\nfar as we are aware, there is no R-related meetup in Togo). The workshop\nwas co-taught by Audrey Addablah, a leader of Abidjan R User Group\n(Ivory Coast) and supported by the Why R? Foundation and the R\nConsortium, as well as Forwards and AfricaR.\n\n\n\nFigure 1: Anicet Ebou (left) and Audrey Addablah (right)\nteaching at the workshop in Lomé, Togo\nAudrey and Anicet introduced the workshop participants to handling and\nvisualising data in R. More than 20 people attended the event, including\nstudents and professionals from a range of sectors. The participants\nshowed a real interest and we are hopeful that training will continue\nonline and in person in future months.\n4 Latin America Survey\nPaola Corrales and Claudia Huaylla joined the Forwards survey team to\ncollaborate on a survey of R users that were born or currently live in\nLatin America. The survey received close to 1000 responses and they are\ncurrently working with other Latin American R users to analyse the\nresults, with a view to report further in 2021.\n5 Package Development Modules\nThe teaching team have been working on modularizing the Forwards package\ndevelopment workshop materials (developed under a grant from the R\nConsortium to run Workshops for Women and\nGirls).\nEmma Rand and Mine Çetinkaya-Rundel plan to teach the first three\nmodules online, February 1-3, 2021, at 14:30-15:30 UTC each day. You can\nregister for the modules on eventbrite: Packages in a\nnutshell,\nSetting up your\nsystem,\nYour first\npackage!.\n6 Changes in Membership\nNew members\nWe welcome the following members to the taskforce:\nCommunity team: s gwynn sturdevant.\nConferences team: Miljenka Vuko, Becca Wilson.\nOn-ramps team: Jyoti Bhogal, Michael Chirico, Maya Gans, Saranjeet\nKaur Bhogal.\nSocial media team: Maria Prokofieva.\nSurveys team: Pavitra Chakravarty, Paola Corrales, Claudia Huaylla,\nAnna Vasylytsya (co-leader).\nTeaching team: Mine Çetinkaya-Rundel (co-leader).\nPrevious members\nThe following members have stepped down:\nConferences team: Jesse Mostipak.\nOn-ramps team: Zhian N. Kamvar, Charlotte Wickham.\nSocial media team: David Smith.\nTeaching team: Angela Li (co-leader), Dorris Scott.\nWe thank them for their contribution to the taskforce.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2020-2-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2020-2 issue.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2020-12-01",
    "categories": [],
    "contents": "\n1 Donations and members\nMembership fees and donations received between 2020-09-09 and\n2021-01-28.\nDonations\nWordPress Hosting Buddy (United States) b-data GmbH (Switzerland) JBL\nDigital Marketing (Australia) Essex Bricklayers (United Kingdom) Jacopo\nCerri (Italy) Vancouver Drafting (Canada) The R Conference (United\nStates) Lander Analytics (United States) The New York Open Statistical\nProgramming Meetup (United States) RV Detailing Pros of San Diego\n(United States) Maple Ridge Handyman (Canada) Burnaby Handyman (Canada)\nRoger Koenker (United Kingdom) Oleg V Kolesnikov (Ukraine) Bulk CBD\nProviders (United States) Metal Roofing San Antonio (United States)\nMinato Nakazawa (Japan) Rashid Nassar (United States) Appstam Consulting\nGmbH (Germany) Careful Movers (United States) San Diego Piano Moving\n(United States) Bathroom Remodel Dayton (United States) Nursing Home\nVancouver (United States) Clearwater Roofing (United States) Clearwater\nWindows (United States) Tree Service Brandon (United States)\nJacksonville Pavers (United States) Tampe Tree (United States) Fast\nMovers Tampa (United States) Allen’s Tree Works (United States) Steve\nSmith (United States) Maple Ridge Tree Service (Canada) Rav Vaid (United\nStates) Merck Research Laboratories, Kenilwort (United States) Statistik\nAargau, Aarau (Switzerland)\nSupporting benefactors\nwww.5slotsites.com , Alderley Edge (United Kingdom)\nSupporting institutions\nCode Ocean, New York (United States) Ef-prime, Inc., 日本橋茅場町 (Japan)\nInstitute of Botany of the Czech Academy of Sciences, Pruhonice (Czechia)\nSupporting members\nTim Appelhans (Germany) Christopher Beltz (United States) Gordon Blunt\n(United Kingdom) Gilberto Camara (Brazil) Susan M Carlson (United\nStates) Cédric Chambru (Switzerland) Michael Chirico (United States) Tom\nClarke (United Kingdom) Terry Cox (United States) Robin Crockett (United\nKingdom) Robert Daly (Australia) Gergely Daroczi (Hungary) Jasja Dekker\n(Netherlands) Fraser Edwards (United Kingdom) Dane Evans (United States)\nIsaac Florence (United Kingdom) Neil Frazer (United States) Huancheng Fu\n(China) Keita Fukasawa (Japan) Sven Garbade (Germany) Eduardo García\nGalea (Spain) Anne Catherine Gieshoff (Switzerland) Brian Gramberg\n(Netherlands) Spencer Graves (United States) Krushi Gurudu (United\nStates) Hlynur Hallgrímsson (Iceland) Joe Harwood (United Kingdom) Bela\nHausmann (Austria) BaoGiang HoangVu (Vietnam) Lorenzo Isella (Belgium)\nSebastian Jeworutzki (Germany) Grant Joslin (United States) June Kee Kim\n(Korea, Republic of) Miha Kosmac (United Kingdom) Daniel Krüerke\n(Switzerland) Jan Herman Kuiper (United Kingdom) Luca La Rocca (Italy)\nMauro Lepore (United States) Chin Soon Lim (Singapore) Joseph Luchman\n(United States) Sharon Machlis (United States) Daniel McNichol (United\nStates) Bogdan-Alexandru Micu (Luxembourg) Jairo Montenegro Arjona\n(Colombia) Guido (Germany) yoshinobu nakahashi (Japan) Maciej Nasinski\n(Poland) Tilers in Nottingham (United Kingdom) Bernard Offman (France)\nBerk Orbay (Turkey) Dan Orsholits (Switzerland) George Ostrouchov\n(United States) Antonio Paez (Canada) Peter Perez (United States) Elgin\nPerry (United States) jared peterson (United States) Kem Phillips\n(United States) Fergus Reig Gracia (Spain) Ingo Ruczinski (United\nStates) Choonghyun Ryu (Korea, Republic of) Pieta Schofield (United\nKingdom) Dejan Schuster (Germany) Jagat Sheth (United States) Rachel\nSmith-Hunter (United States) Gerardo Soto-Campos (United States) Tobias\nStrapatsas (Germany) Robert Szabo (Sweden) Ville Tenhunen (Netherlands)\nCon Tumass-o’Pool (Australia) Uku Vainik (Estonia) Marcus Vollmer\n(Germany) Jaap Walhout (Netherlands) Sandra Ware (Australia) Lim Zhong\nHao (Singapore)\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2020-2-erum/",
    "title": "e-Rum2020: how we turned a physical conference into a successful virtual event",
    "description": "The European R Users Meeting 2020 (e-Rum2020) was a conference that was held virtually in June 2020. Originally, e-Rum2020 had been planned as a physical event to be held in Milano. However, the spread of the COVID-19 pandemic and the declaration of a nationwide lockdown induced the Organizing Committee to fully rethink the event, and to turn it into a live virtual conference. In this article, we describe the challenges that we encountered during the organization of e-Rum2020, and how we reacted to them. In doing so, we aim to provide future conference organizers with useful information on how to organize a successful virtual conference, and even to turn a physical conference into a virtual meeting on a relatively short notice.",
    "author": [
      {
        "name": "Mariachiara Fortuna",
        "url": {}
      },
      {
        "name": "Francesca Vitalini",
        "url": {}
      },
      {
        "name": "Mirko Signorelli",
        "url": {}
      },
      {
        "name": "Emanuela Furfaro",
        "url": {}
      },
      {
        "name": "Federico Marini",
        "url": {}
      },
      {
        "name": "Gert Janssenswillen",
        "url": {}
      },
      {
        "name": "Riccardo Porreca",
        "url": {}
      },
      {
        "name": "Riccardo L. Rossi",
        "url": {}
      },
      {
        "name": "Andrea Guzzo",
        "url": {}
      },
      {
        "name": "Roberta Sirovich",
        "url": {}
      },
      {
        "name": "Andrea Melloncelli",
        "url": {}
      },
      {
        "name": "Lorenzo Salvi",
        "url": {}
      },
      {
        "name": "Serena Signorelli",
        "url": {}
      },
      {
        "name": "Filippo Chiarello",
        "url": {}
      }
    ],
    "date": "2020-11-30",
    "categories": [],
    "contents": "\n\n1 Introduction\nThe European R Users Meeting (eRum) is a series of international\nconferences that aims to bring together members of the R Community from\nall over Europe. Hallmarks of this conference are its openness to both\nthe academic and the business world, and low registration fees that aim\nto minimize the financial burden required to attend the conference.\nThe first two editions of eRum, eRum2016 and eRum2018, were hosted in\nPoznan, Poland, in October 2016 (Beresewicz et al. 2017), and in Budapest, Hungary,\nin May 2018 (Daróczi 2018). The third edition of eRum, eRum2020, was\noriginally planned to be held in Milano, Italy, in May 2020. The\norganization of the 2020 conference was already at an advanced stage in\nFebruary 2020, when the outburst of the COVID-19 pandemic in Northern\nItaly casted serious doubts on the possibility to hold a physical event\nin Milano in the upcoming months. After evaluating several alternative\noptions, the Organizing Committee took the decision to turn the event\ninto a free virtual conference to be held from June 17 to June 20, 2020.\nTo mark this change into a virtual event, the 2020 edition was renamed\ne-Rum2020.\nThe organization of an international conference typically requires the\ncollaboration and coordination of several professionals, as well as\ncontinuous interactions with many stakeholders and service providers. If\norganizing a conference can already be considered a challenging\nexperience itself, having to quickly turn a physical meeting into a\nvirtual conference in the very middle of a pandemic and of an\nunprecedented lockdown posed additional, unforeseen organizational\nchallenges.\nWith this article we would like not only to report how e-Rum2020 went,\nbut also to describe the challenges that we encountered during the\norganization of the conference, and how we reacted to them. In doing so,\nwe aim to provide future conference organizers with useful information\non how to organize a successful virtual conference, and even to turn a\nphysical conference into a virtual meeting on a relatively short notice.\n2 Pre-pandemic arrangements\nThe original plan was to hold eRum2020 at two universities located in\nMilano, Italy. The first three days (May, 27th-29th) of the conference\nwould have been hosted by the Università degli Studi di Milano-Bicocca,\nand the last day (May, 30th), dedicated to workshops, by the Politecnico\ndi Milano. We planned a maximum capacity of 900 participants for the\nevent. The conference would have included a social event that was going\nto take place at a facility located in Sempione Park, a park in the\nhistorical centre of Milano, next to the Sforza Castle.\nTo facilitate attendance from professionals with parenting\nresponsibilities, at both venues we had arranged a childcare service for\nkids aged 2-8 years old. An open call for travel grants was published,\nresulting in 60 applications. A selection committee reviewed the\napplications and selected 10 awardees based on criteria such as\nfinancial need, potential career and development prospects, and expected\ncommunity impact.\n3 Decision to go virtual\nIn February 2020, Italy was the first European country to be hit by the\nCOVID-19 pandemic, with initial outbreaks right in Northern Italy, a few\nkilometers away from Milano. At that time, the conference organization\nwas already at a fairly advanced stage. In addition to having set the\nlocation (including catering facilities, childcare, social event, etc),\nthe scientific program was also being finalised: we had already closed\nthe call for contributions (which received about 220 submissions), we\nwere in the process of notifying authors of accepted contributions,\nkeynote and invited speakers, and we had already sold about 100 tickets.\nSixteen between sponsors and organizing partners had signed up for\nspecific sponsorship packages that relied on physical presence,\ninteraction and visibility during the event.\nAll throughout February and March, we closely monitored the pandemic\nsituation. We organized weekly meetings to discuss the steps to take\nbased on the daily evolution of the containment measures and of the\nspread of COVID-19 itself. We initially considered three alternatives:\n(1) cancelling eRum2020, (2) postponing it, or (3) turning the event\ninto a virtual conference. While we were preparing for the second\noption, Italy was becoming the first country to progressively implement\na nationwide lockdown amid COVID-19, and the pandemic was hitting more\nand more countries. The uncertainty around the possibility of organizing\nlarge gatherings by the end of 2020 was growing, and postponing the\nevent was becoming too much of a risk: hence, on April 6th we announced\nto our sponsors and organizing partners the intention of turning\neRum2020 into an online conference (e-Rum2020) and of postponing the\nevent by three weeks to allow more time to re-adjust the format.\nUp until that moment, the conference had been completely conceived as an\nin-person meeting, with several arrangements driven by the pursuit of\ninteraction and conviviality. Switching to an online format was the best\nchoice to preserve the work that we had done, but it also meant\nadditional work to completely rethink the event, and it required some\ncourage to dismantle the old conference structure that we had been\nworking on for a year. In rethinking e-Rum2020, we strived to provide a\nvirtual experience that could be as close as possible to the physical\none, and to make the transition as smooth as possible, living up to the\nexpectations of sponsors, speakers and attendees.\nWhile buying time for re-organizing the format and exploring online\nconferencing platforms, we needed to keep the attention high and the\npossible audience engaged. We therefore increased the presence of\ne-Rum2020 on social media (generating additional contents and creating a\ndedicated YouTube channel) and organized a contest featuring\napplications of R to data on the COVID-19 pandemic (CovidR contest). We\nadapted the sponsorship package to the new format by replacing those\nbenefits that required physical interaction (e.g., physical sponsors’\nbooths during the event) with virtual equivalents. Additional visibility\nwas offered through social media, online pre-conference activities and\nvirtual banners, and we also included the possibility of organizing\nvirtual recruiting sessions. Given the reduced costs that the virtual\nevent entailed, we cancelled the registration fees, turning e-Rum2020 in\nan event free of charge. We refunded previously purchased tickets, and\nreduced the cost of sponsorship packages.\nFollowing our “as close as possible to physical\" principle, we decided\nthat all talks were going to be presented live, with Q&A sessions\ntailored to the different types of talks. In order to make up for the\nabsence of in-person interaction, we also decided to have dedicated\nnetworking areas and to add yoga sessions at the beginning and at the\nend of each day. In a few days, we realised that the online format was\nactually a great opportunity to come up with new ideas, and that we\ncould leverage it to bring the conference to a worldwide reach.\nIn the remainder of the article, we present the technical solutions that\nwe adopted for the virtual conference, the promotion strategy that we\nimplemented to increase the reach of e-Rum2020, and the organization and\ncontents of e-Rum2020’s scientific program.\n4 Technical solutions\nA primary challenge in the organization of the virtual conference was\nthe identification of technological solutions that could be used to\nconnect participants throughout the event. After comparing several\nalternative services, we chose to resort to an online conferencing\nplatform called Hopin (https://hopin.to). This choice was made because\nHopin could efficiently recreate the spaces of a live conference in\ndigital format (reception area, main stage, parallel sessions, sponsors\nbooths, etc). Key factors that motivated our choice were the possibility\nto hold all sessions live, to have dedicated spaces for both plenary\nevents and parallel sessions, and networking spaces that made\ninteractions between speakers, attendees and sponsors possible.\nThe conference platform, however, was not the only technological tool\nneeded to provide a smooth conferencing experience. We soon realized\nthat none of the available conferencing platforms, including Hopin,\ncould provide us with a fully comprehensive set of tools, and therefore\nwe decided to complement it with additional tools.\nFor example, a limitation of Hopin was the lack of a system to\ncommunicate effectively “behind the scenes”. To address this problem, we\ncreated a Slack channel to manage backstage communications between staff\nmembers, speakers and session chairs, and to provide the attendees with\ntechnical support. We also decided to manage the Q&A of keynote sessions\nwith sli.do, and to stream part of the event live on YouTube. We used\nVoicemod to launch applauses and other sounds during the live streaming,\nand restream.io to handle breaking times and slideshows in the YouTube\nstreaming.\nAn essential part of this technological setup was the need to explain\nhow it would have worked, and test it with our staff, speakers and\nsession chairs. Four mock events were held with the Organizing Committee\nmembers to check that the setup was functional and could accommodate our\nideas. Furthermore, we decided to hold a pre-conference event, called\nCovidR, that was used as dry-run for the event platform, structure and\nbackstage communication tools (we will come back to CovidR in a later\nsection). We wrote a set of guides with detailed instructions for\nspeakers, sponsors and sessions chairs. Lastly, we organized speaker\ntests to train speakers and session chairs. These tests proved extremely\nuseful not only for the speakers, who learned to use a new and complex\ntool, but also for us, because it helped us to identify the most common\nproblems and how to solve them before the virtual event took place.\nTo ensure that sessions ran smoothly, we complemented session chairs\nwith additional support staff: each session had an OC member assigned as\nsupervisor and a Q&A assistant who collected questions during the\nsessions. We also planned back-ups for each role, in case of connection\nproblems or technical issues. Moreover, we organized technical\nassistance throughout the whole event.\n5 Promotion of the event\nThe promotion e-Rum2020 was taken care of by a team of Organizing\nCommittee members, who were supported in their tasks by a graphic\ndesigner. The first tasks involved the creation of a logo for the\nconference, and of the conference website. The logo was initially\ndesigned for the physical event that was to be held in Milano; for this\nreason, it included a stylized representation of the Duomo di Milano,\none of the main landmarks of the city. When the decision to hold the\nevent virtually was announced, we decided to redesign the logo by\nupdating event name and dates, and adding a wifi symbol on top of the\ncathedral (Figure 1).\n\n\n\nFigure 1: The conference logos designed for the physical\nconference (eRum2020) that should have been held in May 2020 (left) and\nfor the virtual event (e-Rum2020) that was held in June 2020\n(right).\nThe conference website (https://2020.erum.io) was developed using\nWordpress, using a color palette and graphical style in line with those\nused in the conference logo. We opted for a multi-page design with\nsections and subsections, with the purpose of easing information\nretrieval. The website underwent frequent updates that reflected\nimportant milestones (e.g., opening of submission period, opening of\nregistrations, announcement of virtual event, publication of the\nprogram, etc.), with a major reorganization carried out to adapt it to\nthe virtual conference format.\nThe conference promotion strategy was designed to be fully virtual and\ncostless; it mostly relied on the use of social media (Twitter, Facebook\nand LinkedIn), on the blog of the MilanoR foundation and on emails\nspread on target mailing lists. The social media communication strategy\nwas organized using an editorial calendar, in which all announcements\nand posts for each week were scheduled from the start, thereby making\nsure that the style and content were uniform over different channels and\nover time. After the decision to transition to an online conference, we\ncreated a dedicated e-Rum2020 YouTube channel and we redrafted the\neditorial calendar, including additional contents (video interviews with\nkeynote speakers, information about the CovidR pre-conference event,\netc.). Among the social networks used, we found Twitter to be the one\nthat generated the highest engagement; the number of followers of\neRum2020’s Twitter page doubled in a year (growing from 1108 in June\n2019 to 2313 in June 2020), with a steep increase observed when the\nconference was turned into a virtual event (Figure 2).\nFigure 2: Evolution of the number of followers of the eRum Twitter\npage from June 2019 to June 2020.The creation of the e-Rum2020 YouTube channel was instrumental to\nsupport the virtual event. To increase e-Rum2020’s outreach, we recorded\n5 interviews with the keynote speakers that were published prior to the\nconference. The interviews were intentionally informal and provided a\nrelaxed narration of personal experiences and R-related stories of the\nspeakers. The channel was also used to stream plenary sessions live\nduring the event, and to publish recordings of all conference sessions\nafter the end of the event. In total, the channel currently hosts 59\nvideos organized in 12 playlists, with a total of 36 hours of edited\nmaterial uploaded.\n6 Scientific Program\nThe Scientific Program of e-Rum2020 comprised several types of sessions,\nwhich ranged from keynote and invited sessions to different types of\ncontributed sessions (workshops, regular talks, lightning talks, shiny\ndemos and posters). All sessions were organized around a 4-days\nschedule, with the last day entirely dedicated to the workshops.\nMoreover, the conference was preceded by two satellite events: the\nCovidR pre-conference event, and a hackathon on spatial networks.\nTo ensure a balanced representation of the main fields of application of\nR, we identified 6 tracks that were used to guide the selection of both\nkeynote and invited speakers, and of contributed sessions. The tracks\nwere: Machine Learning and Modelling, R World, Applications, Life\nSciences, Data Visualization and R in Production.\nKeynote and invited sessions\nThe invited part of the program comprised six keynote sessions of 45\nminutes, and three invited sessions of 90 minutes each. Six keynote\nspeakers were selected to represent the 6 conference tracks. Of the 11\ninvited speakers, 9 were selected in representation of the 6 tracks, and\ntwo were invited to present their work at eRum2020 after winning the\nCovidR contest.\nContributed sessions\nThe call for contributed sessions was opened on December 11, 2019, and\nclosed on January 29, 2020, well before the outbreak of the pandemic in\nEurope. Abstracts were submitted through the Sessionize system, which\noffered a number of features for handling mass communications with\nusers, but was lacking a simple yet efficient mechanism for evaluation,\nwith the widely used 1-5 notes for scoring each contribution. We\ntherefore decided to complement it by developing assessR\n(https://github.com/Milano-R/assessr), a Shiny app that seamlessly\ndisplayed the most relevant information for each abstract. The app kept\nthe author information hidden, as we believed that a blinded procedure\nwould encourage reviewers to assess the content in a fairer way.\nFor the evaluation of the submitted abstracts, we created a Program\nCommittee (PC) whose members were selected in representation of the\nconference tracks, and were asked to score contributions specific to\ntheir field of expertise. The PC members were: Aldo Solari, Enrico\nDeusebio, Charlotte Soneson, Branko Kovac, Andrie De Vries, Fulvia\nPennoni, Goran Milovanović, Davide Cittaro, Hannah Frick, Adolfo Alvaro,\nOlga Mierzwa-Sulima, Gergely Daróczi, Piercesare Secchi, Diane Beldame,\nXavier Adam, Davide Risso, Pier Luca Lanzi, Levi Waldron, Heather\nTurner, Martin Mächler, Stefano Maria Iacus.\nWe received a total of 230 contributions (Figure 3),\nof which 32 for workshops. Of these, 94 (including 11 workshops) were\nselected for presentation at e-Rum2020. All contributed sessions, with\nthe exception of workshops, were organized in two parallel tracks (later\nassigned to specific rooms in the system provided by Hopin), spread over\n3 days. A separate day was dedicated to the workshops.\nFigure 3: Submitted contributions by track and session\ntype.Definition of the final program\nThe final lineup of talks and contributions reflected a nice balance\nacross the six tracks. As we expected that due to the online format\nparticipants might have been able to join and stay focused for shorter\nstretches of time, we decided to shorten the length of all talks.\nEach session type was linked to a specific room configuration for Q&As:\nfor example, invited speakers had the possibility to individually host\npeople at a virtual table, while panel Q&A sessions were organized for\nregular and lightning talks. Considering the time zones of our speakers\nwas another important aspect to take into account. Most contributed\nsessions were submitted from Europe, but we were also able to\naccommodate late afternoon slots from the Pacific Time Zone.\nTitles, abstracts and authors of each contribution, arranged by format,\nwere published as a booklet using bookdown\n(https://2020.erum.io/program/contributed-sessions). That choice made\neasy and flexible its updates, progressively following confirmations,\nrenunciations and possible changes. The final program of e-Rum2020,\ncomprehensive of the conference schedule, was then published as a\nbrochure (https://2020.erum.io/program).\nHackathon on spatial networks\nThe beginning of e-Rum2020 was preceded by a satellite event on spatial\nnetworks that was held the day before the conference. The event\ncomprised an online webinar and a hackathon, and it focused on\nintroducing and testing sfnetworks, a new R package for the analysis\nof spatial networks. The satellite event was organized by Andrea\nGilardi, Lorena Abad, Robin Lovelace and Lucas van der Meer.\nCovidR pre-conference event\nA significant addition to e-Rum2020, decided alongside with the\ntransition to a virtual conference, was CovidR: a contest and\npre-conference event featuring open-source R contributions around the\ntopic of the COVID-19 pandemic. Since the beginning of the pandemic, the\nR community has been very active in using R for analyzing data,\ndeveloping models and providing useful visualizations. The idea behind\nCovidR was to collect such contributions and motivate the community to\nshare and spread their work through a contest.\nThe CovidR submission process was based on a GitHub repository\n(https://github.com/Milano-R/erum2020-covidr-contest) and a\nstreamlined Pull Request mechanism, from which we constructed an R\nMarkdown gallery website\n(https://milano-r.github.io/erum2020-covidr-contest). The website\ngallery was constructed using the R package rmdgallery\n(https://riccardoporreca.github.io/rmdgallery), which was developed\nalongside the contest. The gallery allowed community engagement through\nthe possibility of thumb-up voting submitted contributions.\nOut of the 35 submissions to the contest, 15 were selected to be\npresented at the CovidR pre-conference event, which was held on May 29,\n2020. The event featured 5-minute-long presentations and virtual round\ntables for Q&As, with awards granted based on the overall quality of the\ncontributions, as well as on community feedback. The two winners of the\ncontest were invited to give an extended presentation of their work at\ne-Rum2020.\nA secondary, but important aspect of this pre-conference was that it\nenabled us to test the technical tools and the overall process of\nrunning a large virtual event. The technical preparation and smoothness\nof the main conference owe a lot to the lessons learned and confidence\ngained during CovidR.\n7 e-Rum2020 in figures\nConference tickets were sold out, with 2000 registered participants.\nAfter registration, 1379 participants actively attended the conference.\nThe CovidR pre-conference event and the workshops were respectively\nattended by 171 and 513 participants. Figure 4\nshows the geographic distribution of the conference attendees.\nFigure 4: Geographic distribution of the attendees of\ne-Rum2020.The program consisted of 104 speakers, among which 6 keynote speakers,\n12 invited speakers, and 86 contributed talks. The contributed talk\nincluded 39 regular talks, 23 lightning talks, 11 Shiny demos and 13\nposter presentations.\nThe conference staff was entirely composed by volunteers. It counted 21\nOrganizing Committee members, 21 Program Committee members, 23 session\nchairs, 7 Q&A assistants, 7 technical support assistants and 1 social\nmedia assistant.\n8 Organizers\ne-Rum2020 was jointly organized by the e-Rum2020 Organizing Committee,\nthe MilanoR association, two universities (Università di Milano-Bicocca\nand Politecnico di Milano), and two data science firms (VanLog and Mirai\nSolutions). The event received the patronage of Comune di Milano.\nThe Organizing Committee of e-Rum2020 consisted of 21 volunteers based\nin 5 different European countries (Italy, Switzerland, Belgium, The\nNetherlands and Germany): Mariachiara Fortuna, Francesca Vitalini,\nEmanuela Furfaro, Mirko Signorelli, Federico Marini, Riccardo L. Rossi,\nRoberta Sirovich, Andrea Meloncelli, Lorenzo Salvi, Riccardo Porreca,\nAndrea Guzzo, Gert Janssenswillen, Serena Signorelli, Filippo Chiarello,\nMatteo Pelagatti, Gabriele Orlando, Matteo Borrotti, Laura Terzera,\nMarta Galvani, Matteo Fontana and Parvaneh Shafiei.\n9 Sponsors\nWe would like to thank all the sponsors that supported the organization\nof e-Rum2020: RStudio, Open Analytics, cynkra, the R Consortium, the SDG\ngroup, Revelo Datalabs, SolidQ, Appsilon Data Science, datahouse and\nKode, as well as our in-kind sponsors StickerMule and CRC Press.\n10 Acknowledgments\nAs members of the e-Rum2020 Organizing Committee, we would like to thank\nall the volunteers that contributed to the success of e-Rum2020: the\nProgram Committee members, keynote, invited and contributed speakers,\nand all the volunteers that helped as session chairs, or helped managing\nthe Q&A, technical support for attendees and social media coverage\nduring the event.\n11 Links\nFurther information about e-Rum2020 and the contributions presented\nduring the conference can be found at the following links:\nconference website: https://2020.erum.io\ne-Rum2020 Youtube channel: https://www.youtube.com/c/eRum2020\nconference materials:\nhttps://github.com/Milano-R/erum2020program#readme\nCovidR gallery with all submissions for the CovidR pre-conference\nevent: https://milano-r.github.io/erum2020-covidr-contest\nAssessR shiny app: https://github.com/Milano-R/assessr\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\nM. Beresewicz, A. Alvarez, P. Biecek, M. K. Dyderski, M. Kosinski, J. Nowosad, K. Rotter, A. Szabelska-Beresewicz, M. Szymkowiak, Ł. Wawrowski, et al. Conference Report: European R Users Meeting 2016. R Journal, 9(1): 2017.\n\n\nG. Daróczi. Conference Report: ERum 2018. R Journal, 10(1): 2018.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2020-1-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2020-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2020-06-01",
    "categories": [],
    "contents": "\n\nIn the past 8 months, 1554 new packages were added to the CRAN package\nrepository. 96 packages were unarchived and 843 were archived. The\nfollowing shows the growth of the number of active packages in the CRAN\npackage repository:\n\nOn 2020-08-31, the number of active packages was around 16174.\nChanges in the CRAN Repository Policy\nThe Policy now\nsays the following:\nAll correspondence with CRAN must be sent to\nCRAN-submissions@R-project.org\n(for submissions) or CRAN@R-project.org\n(for published packages) and not to members of the team, in plain\ntext ASCII and not HTML.\nA package listed in ‘Suggests’ or ‘Enhances’ should be used\nconditionally in examples or tests if it cannot straightforwardly be\ninstalled on the major R platforms. (‘Writing R Extensions’\nrecommends that they are always used conditionally.)\nOrphaned CRAN packages should not be strict requirements (in the\n‘Depends’, ‘Imports’ or ‘LinkingTo’ fields, including indirectly).\nThey are allowed in ‘Suggests’ if used conditionally, although this\nis discouraged.\nPackages which use Internet resources should fail gracefully with an\ninformative message if the resource is not available or has changed\n(and not give a check warning nor error).\nCompiled code should never terminate the R process within which it\nis running. Thus C/C++ calls to\nassert/abort/exit/std::terminate, Fortran calls to STOP and\nso on must be avoided.\nUpdates to previously-published packages must have an increased\nversion. Increasing the version number at each submission reduces\nconfusion so is preferred even when a previous submission was not\naccepted.\nCRAN package submissions\nDuring the first 8 months of 2020 (January to August), CRAN received\n22020 package submissions. For these, 38551 actions took place of which\n25063 (65%) were auto processed actions and 13488 (35%) manual actions.\nMinus some special cases, a summary of the auto-processed and manually\ntriggered actions follows:\n\narchive\ninspect\nnewbies\npending\npretest\npublish\nrecheck\nwaiting\nauto\n5710\n4300\n5269\n0\n0\n6216\n1987\n1581\nmanual\n5437\n95\n936\n783\n291\n4532\n1181\n233\nThese include the final decisions for the submissions which were\naction\narchive\npublish\nauto\n5401 (25.2%)\n5258 (24.5%)\nmanual\n5315 (24.8%)\n5449 (25.4%)\nwhere we only count those as auto processed whose publication or\nrejection happened automatically in all steps.\nThe CRAN team has changed. Martina Schmirl and Jelena Saf left the team.\nThanks a lot to both of you! New members are Gregor Seyer who is very\nactively processing newbies submissions and Julia Haider who just\njoined the team. Welcome to CRAN!\nCRAN mirror security\nCurrently, there are 101 official CRAN mirrors, 65 of which provide both\nsecure downloads via https and use secure mirroring from the CRAN\nmaster (via rsync through ssh tunnels). Since the R 3.4.0 release,\nchooseCRANmirror() offers these mirrors in preference to the others\nwhich are not fully secured (yet).\nNew packages in CRAN task views\nBayesian\n\nBEST,\nBVAR,\nBayesPostEst,\nBergm,\nNGSSEML,\nacebayes,\nbbricks,\nconting,\nmcmcse,\nstableGR.\n\nChemPhys\n\nspectrino.\n\nCluster\n\nDatabionicSwarm,\nProjectionBasedClustering,\ngenieclust.\n\nDatabases\n\nRClickhouse,\ndbx,\ndplyr,\nsparklyr.\n\nEconometrics\n\nREndo,\ncollapse,\nfixest,\nmfx,\nmhurdle,\nmnlogit,\nskedastic.\n\nEnvironmetrics\n\nPMCMRplus,\ndsm,\nrioja.\n\nFinance\n\ncopulaData,\nnvmix,\nqrmdata,\nqrmtools.\n\nFunctionalData\n\nfdANOVA,\nfdaACF.\n\nHighPerformanceComputing\n\npbdBASE.\n\nHydrology\n\nAWAPer,\nRNRCS,\nclimate,\nfasstr,\nmetScanR,\nstationaRy.\n\nMetaAnalysis\n\nNMADiagT,\nSPAtest,\ngetspres,\nmetagam,\nmetapower,\nmetarep,\nmetawho,\nminiMeta,\npoolr,\npublipha.\n\nMissingData\n\nCircSpaceTime,\nClustImpute,\nECLRMC,\nEditImputeCont,\nFSMUMI,\nIPWboxplot,\nNPBayesImputeCat,\nRBtest,\nRMixtComp,\nStempCens,\nareal,\nbiclustermd,\nbootImpute,\ncassandRa,\niai,\nimpimp,\nimputeFin,\nimputeR,\nisotree,\nlodi,\nmetasens,\nmiWQS,\nmiceRanger,\nmipred,\nmisaem,\nmissSBM,\nmissingHE,\nnaivebayes,\nplsRbeta,\npsfmi,\nrobustrank,\nrrcovNA,\nrsparse,\nsievePH,\ntensorBF,\nui.\n\nModelDeployment\n\nRestRserve.\n\nNaturalLanguageProcessing\n\nBTM,\nLexisNexisTools,\ncorporaexplorer,\ncrfsuite,\nruimtehol,\ntextplot,\ntokenizers.bpe,\ntopicdoc.\n\nNumericalMathematics\n\nCarlson,\nJuliaConnectoR,\nRcppBigIntAlgos,\ncaracas,\nclifford,\ndual,\npolyMatrix,\nrmatio,\nsymengine.\n\nOfficialStatistics\n\ncancensus,\ncansim,\ncollapse.\n\nOptimization\n\nmixsqp.\n\nPsychometrics\n\nBGGM,\nEGAnet,\nIsingFit,\nIsingSampler,\nNetworkComparisonTest,\nSemNeT,\nTestDesign,\nbootnet,\nedina,\nedmdata,\nelasticIsing,\nerrum,\ngimme,\nglasso,\ngraphicalVAR,\niarm,\nirtplay,\nlvnet,\nmgm,\nmlVAR,\nnetworktools,\nnetworktree,\nthurstonianIRT.\n\nRobust\n\nrrcovNA.\n\nSpatial\n\ncancensus,\ngear.\n\nTeachingStatistics\n\narm,\nmsos,\nwooldridge.\n\nTimeSeries\n\nBGVAR,\nBMTAR,\nBayesARIMAX,\nDTSg,\nEBMAforecast,\nNGSSEML,\nProbReco,\nUComp,\nbootUR,\nchangepoint.geo,\ncollapse,\ndata.table,\ndisaggR,\nfable.prophet,\nfabletools,\nfdaACF,\nfsMTS,\ngarma,\ngratis,\ngravitas,\nmbsts,\nmixAR,\npcts,\nrhosa,\nrunner,\nscoringutils,\nseer,\nslider,\nsmoots,\nstatespacer,\ntestcorr.\n\nTracking\n\nrerddapXtracto.\n\nWebTechnologies\n\ndash,\nrromeo.\n\n(* = core package)\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2020-1-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2020-1 issue.",
    "author": [
      {
        "name": "Michael J. Kane",
        "url": {}
      }
    ],
    "date": "2020-06-01",
    "categories": [],
    "contents": "\n\nOn behalf of the editorial board, I am pleased to present Volume 12,\nIssue 1 of the R Journal and my second issue as the Editor in Chief.\nSince the last issue Simon Urbanek has joined the editorial board and we\nhave made a few structural changes. First, the R Foundation has approved\nthe R Journal having Associate Editors. This change will allow us to\naddress the increase in submission volume. The addition of the new AE\npositions should help alleviate some of the workload the editors have\nbeen dealing with and will result in shorter turn-around times for\nsubmissions. Second, complete issues of the R Journal will no longer be\npublished in a single pdf. The build process for the document was\ncomplex and time consuming and we were not seeing the volume of download\nthat would justify the effort. Individual articles are still available\nand the issue layout is still shown in the “Current Issue” section of\nthe web page.\n1 In this issue\nNews from the R Foundation is included in this issue along with an\nupdate from the The R Foundation’s histoRicalg project, which documents\nhistoric and historical numerical algorithms and provides reference\nimplementations in R. In addition, a reprint by John Chamber,\ndocumenting the history of R, which was initially published in the\nHistory of Programming Languages. Finally, this issue features 26\ncontributed research articles that have been categorized below.\nPapers focusing on reproducibility, managing code and projects, and\ninstruction:\nari: The Automated R Instructor\nProjectManagement: an R Package for Managing Projects\nThe Rockerverse: Packages and Applications for Containerisation with\nR\nSimilaR: R Code Clone and Plagiarism Detection\nTools for Analyzing R Code the Tidy Way\nData exploration and visualization:\nspinifex: An R Package for Creating a Manual Tour of\nLow-dimensional Projections of Multivariate Data\nVariable Importance Plots—An Introduction to the vip Package\nAstronomy\nrcosmo R Package for Analysis of Spherical, HEALPix and\nCosmological Data\nMedicine and epidemiology\nIndividual-Level Modelling of Infectious Disease Data: EpiILM\nProbability distributions and processes\nBayesMallows: An R Package for the Bayesian Mallows Model\ngk: An R Package for the g-and-k and Generalised g-and-h\nDistributions\nLinear Fractional Stable Motion with the rlfsm R Package\nmistr: A Computational Framework for Mixture and Composite\nDistributions\nmudfold: An R Package for Nonparametric IRT Modelling of Unfolding\nProcesses\nNlinTS: An R Package For Causality Detection in Time Series\nnpordtests: An R Package of Nonparametric Tests for Equality of\nLocation Against Ordered Alternatives\nSkew-t Expected Information Matrix Evaluation and Use for Standard\nError Calculations\ntsmp: An R Package for Time Series with Matrix Profile\nThe R package NonProbEst for estimation in non-probability surveys\nSupervised learning\nCopulaCenR: Copula based Regression Models for Bivariate Censored\nData in R\nCoxPhLb: An R Package for Analyzing Length Biased Data under Cox\nModel\ndifNLR: Generalized Logistic Regression Models for DIF and DDF\nDetection\nlspartition: Partitioning-Based Least Squares Regression\nMapping Smoothed Spatial Effect Estimates from Individual-Level\nData: MapGAM\nSortedEffects: Sorted Causal Effects in R\nSurvBoost: An R Package for High-Dimensional Variable Selection in\nthe Stratified Proportional Hazards Model via Gradient Boosting\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2020-1-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2020-1 issue.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2020-06-01",
    "categories": [],
    "contents": "\n1 Donations and members\nMembership fees and donations received between 2020-02-24 and\n2020-09-08.\nDonations\nIchu Cheng (Canada) Mitchell Gail (United States) ken ikeda (Japan)\nParag Magunia (United States) John McMahon (United States) Daniel\nWollschläger (Germany) 明彦 田中 (Japan)\nSupporting benefactors\nMcGill University, Ottawa (Canada) www.ohmybingo.com, Alderley Edge\n(United Kingdom)\nSupporting institutions\nUniversity of Iowa, Iowa City (United States)\nSupporting members\nDiogo Almeida (United Arab Emirates) Paul Artes (United Kingdom) Ashanka\nBeligaswatte (Australia) Chris Billingham (United Kingdom) Wesley Brooks\n(United States) Robert Carnell (United States) Luca Cocconcelli (United\nKingdom) Rémi Coulaud (France) Alistair Cullum (United States) Ajit de\nSilva (United States) Dubravko Dolic (Germany) Gerrit Eichner (Germany)\nMartin Elff (Germany) Mitch Eppley (United States) Nathan Epstein\n(United States) cristiano esclapon (Switzerland) Guenter Faes (Germany)\nGottfried Fischer (Austria) Jutta Gampe (Germany) Jan Marvin Garbuszus\n(Germany) Stefano Guazzetti (Italy) Chris Hanretty (United Kingdom)\nTakehiko Hayashi (Japan) Alessamdro Ielpi (Canada) Christian Kampichler\n(Netherlands) Srikanth Kannan (India) Curtis Kephart (United States)\nsanghyeon kim (Korea, Republic of) Sebastian Koehler (Germany) Luca La\nRocca (Italy) Adrien Le Guillou (France) Seungdoe Lee (Korea, Republic\nof) Bernhard Lehnert (Germany) Alain Lesaffre (Australia) Eric Lim\n(United Kingdom) Sharon Machlis (United States) John MacKintosh (United\nKingdom) Michal Majka (Austria) harvey minnigh (Puerto Rico) Ernst\nMolitor (Germany) Jairo Montenegro Arjona (Colombia) David Monterde\n(Spain) Stefan Moog (Germany) Steffen Moritz (Germany) Jens Oehlschlägel\n(Germany) Jaesung James Park (Korea, Republic of) Matt Parker (United\nStates) Bill Pikounis (United States) Robert Selden (United States)\nChristian Seubert (Austria) Pedro Silva (Brazil) gabriel silver (United\nStates) Berthold Stegemann (Germany) Harald Sterly (Germany) Dag\nTanneberg (Germany) Nicholas Turner (United States) Philipp Upravitelev\n(Russian Federation) Robert van den Berg (Austria) Mark van der Loo\n(Netherlands) Frans van Dunné (Costa Rica)\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2020-1-whyR/",
    "title": "Conference Report: Why R? 2019",
    "description": "The 'Conference Report: Why R? 2019' article from the 2020-1 issue.",
    "author": [
      {
        "name": "Michał Burdukiewicz",
        "url": {}
      },
      {
        "name": "Filip Pietluch",
        "url": {}
      },
      {
        "name": "Jarosław Chilimoniuk",
        "url": {}
      },
      {
        "name": "Katarzyna Sidorczuk",
        "url": {}
      },
      {
        "name": "Dominik Rafacz",
        "url": {}
      },
      {
        "name": "Leon Eyrich Jessen",
        "url": {}
      },
      {
        "name": "Stefan Rödiger",
        "url": {}
      },
      {
        "name": "Marcin Kosiński",
        "url": {}
      },
      {
        "name": "Piotr Wójcik",
        "url": {}
      }
    ],
    "date": "2020-06-01",
    "categories": [],
    "contents": "\n\nFigure 1: Why R? 2019 conference banner used for social media\npromotion.1 Why R? 2019 conference\nWhy R? conferences have been the hallmark of the Why R? Foundation\n(whyr.pl). Our goal has been to establish a series of\ninternational R-related events in Poland. After three years, we are\nhappy to announce that our main event, the Why R? conference, has become\none of the largest annual R conferences in Central Europe.\nWhy R? 2019 was the third part of Why R? conference event. After the\nlast edition that was held in Wrocław (Burdukiewicz et al. 2018), our\nconference has returned to Warsaw. A total of approximately 300 people\nfrom 20 countries attended the main conference event. The event took\nplace from 26th to 29th September 2019 and was co-organised by the\nFaculty of Economic Sciences of the University of Warsaw\n(wne.uw.edu.pl/en/), a leading academic\ninstitution in Poland, having important achievements in quantitative\nmethods and data science. We received major support from ML in PL\nSociety (mlinpl.org), a group of young\nresearchers, aiming to promote machine learning events in Poland, who\nshared their resources and experience to make the conference more\naccessible.\nFor the first time, this year the conference featured a\nlanguage-agnostic data visualizations hackathon\n(whyr.pl/2019/hackathon). Such an event\ngives the Why R? community a chance to exchange experience and\ninspirations with the users of any other languages and tools.\n2 Participants\nIn spite of the fact that Why R? events are aimed at experienced data\nscience practitioners, each conference gathers a high percentage of\nstudents (around 30%). Our participants have very diverse scientific\nbackgrounds, where mathematics (mainly statistics) and computer science\nare the most common. All of them have jobs related to data science,\nincluding professional R developers (programmers), data engineers,\nmachine learning practitioners and business analysts. One of the key\nadvantages of Why R? is that it gathers participants both from\nacademia and the industry.\n3 Conference program\nFigure 2: Why R? 2019 conference\nprogramme.The format of the conference was aimed at exposing participants to\nrecent developments in the R language as well as a wide range of\napplication examples. The event consisted of workshops, invited keynote\ntalks, field-specific series of talks, lightning-talks, special interest\ngroups and a full-day data visualizations hackathon. It offered\nextensive networking opportunities. The welcome party was held at the\nconference venue on the first day of lectures. In addition, many\ninformal gatherings were organised during each conference day, as the\nevent took place close to the Old Town.\nTo sum up, Why R? 2019 consisted of: one day of hackathon (60\nattendees), one day of workshops (150 attendees), one evening of round\ntables, two days of lectures (250 attendees) and one evening Welcome\npaRty (100 attendees). In 2019 we hosted a total of 315 unique\nattendees. During lectures there were carried out: 6 keynote talks, 42\nregular talks and 14 lightning talks. Below you can find the conference\nagenda.\nFigure 3: Why R? 2019 conference\nagenda.Materials from the conference are available on GitHub and YouTube: -\nabstracts\ngithub.com/WhyR2019/abstracts, -\npresentations\ngithub.com/WhyR2019/presentations -\nvideos whyr.pl/youtube/\n4 Data Visualizations Hackathon\nOn the day before the conference we organized the free Data\nVisualizations Hackathon. It was a great opportunity for networking and\nexchange of experiences between data scientists that use different\nprogramming languages. The challenge was based on the data from Google\nPlaces API, which allows to search for places in a particular area.\nThanks to this API we gathered data related to places in Warsaw, their\nworking hours and occupancy. Based on this source of data participants,\ndivided into 10 teams, were asked to prepare useful business application\npowered data visualizations solutions and techniques.\n5 Pre-meetings\nFigure 4: Locations and dates of the main Why R? 2019 conference and\nWhy R?-branded\npre-meetings.In 2019, Why R? 2019 was preceded by fourteen pre-meetings in eight\ncountries. The purpose of those meetings was to provide the space for\nprofessional networking and knowledge exchange for practitioners and\nstudents, from the area of statistical machine learning, programming,\noptimization and data science. The Why R? Foundation supported\norganisation of pre-meetings financially and/or by sending speakers.\nThe organisation of pre-meetings would not be possible without the\nwonderful support of local R communities. Aside from the promotion of\nWhy R? we had a great opportunity to interact with other R\nenthusiasts.\n6 Workshops\nFigure 5: Why R? 2019\nworkshops.Why R? 2019 conference had a wide portfolio of workshops that are\nlisted below. One can find materials from workshops at this GitHub\nrepository\ngithub.com/WhyR2019/workshops\nIntroduction to modern Generalized Additive Models in R (with\nmgcv) by Matteo Fasiolo (University of Bristol). The\nassumption of the full-day workshop was firstly to give its\nparticipants some theoretical background about GAMs and some\npractical experience in R and finally to make attendees ready to\nstart applying these models themselves. GAM models are a\nnon-parametric extension of traditional regression model and were\nproved to be highly useful for both predictive and inferential\npurposes. Their popularity is based on a good balance between\nflexibility and interpretability as well as on the possible\napplication on large datasets. Matteo started with explanation of\nstandard GAMs and related R packages. He explained what an additive\nmodel is, how the smooth effects and random effects are introduced.\nGAM models fitting was accompanied by the explanation of additional\ndiagnostic and model selection tools, and Big Data GAM methods. In\nthe end more recent developments were also described, i.e. quantile\nGAM models. The practical sessions were based on the mgcv\n(Wood 2017), qgam (Fasiolo et al. 2017) and mgcViz\n(Fasiolo et al. 2018) packages.\ndata.table introduction & time-series by Jan Gorecki (H2O.AI).\nThe workshop was divided into two parts – the first part was\ndevoted to the introduction of data.table query concept while the\nsecond focused on a particular use case of working with time-series\ndata. In the first part Jan showed syntax similarities and\ndifferences between data.table and data.frame approaches. He\nused Arun Srinivasan workshops materials from useR!2017, with a few\nextras: chaining of data.table queries, reference semantics,\nsubset of data: .SD and R function argument matching. In the\nsecond part Jan showed the application of efficient data processing\non financial time series data of high-frequency (tick data\nquotations), including efficient aggregation to OHLC data,\ncalculation of moving averages and using rolling join.\nStraightforward introduction to Deep Learning in R (with Keras)\nby Mikołaj Bogucki and Mikołaj Olszewski (iDash). The workshop\nstarted with the explanation of what Deep Learning and Neural\nNetworks are (complex functions) and what components they include\n(input, output, hidden layers and weights). Then Keras\n(Allaire et al. 2018) was presented as a high level library\nallowing to build neural networks with an easy to use set of\ncommands. The practical example using airBnB data and Keras R\ncodes showed all stages of building a Neural Network: (1) defining\nthe structure of the network, (2) defining the way of training (the\nloss function and the optimizer algorithm), (3) training (together\nwith its visualization), (4) evaluation and (5) prediction. In\naddition, training, validation, test set division, simple imputation\nof missing data, using non-linear activation functions and basic\nfeature engineering was shortly explained.\nauditor + DALEX: a powerful duet for validation and explanation of\nmachine learning models by Alicja Gosiewska and Tomasz Mikołajczyk\n(MI2 Data Lab). The aim of the workshop was to familiarize\nparticipants with modern methods of model verification and\nexploration. In the first part Alicja and Tomasz introduced the idea\nof DALEX (Biecek 2018) explainers, showing how to use\nthem to assess the performance of a model and explain the model’s\npredictions (including global and local explanations). In the second\npart they focused on additional functionalities of the auditor\n(Gosiewska and Biecek 2018) package, showing how the analysis of residuals\nmay be applied to select the best model or even improve models.\nBlack is the new White - using eXplainable Artificial Intelligence\nin Business by Marcin Chlebus (Faculty of Economic Sciences,\nUniversity of Warsaw, Data Juice Lab, Data Donuts). Marcin presented\nXAI as a possible solution for understanding “Black-box” model\ncomplexity and fuzziness. He showed how XAI helps in stability and\nsensitivity analysis, prediction quality assessment and\nidentification of decision drivers. The use cases showing the\napplication of XAI in cross-sell marketing campaigns and risk\nmanagement were presented. With the use of step by step analysis, it\nwas shown that XAI is a set of tools enabling application of “black\nbox” models in many business industries through in-depth\nunderstanding of advanced machine learning modelling.\nShiny Basics by Theo Roe (Jumping Rivers). This workshop was\nintended as a quick introduction to creating interactive\nvisualisations of data using shiny. Theo started with some basic\nexamples of using rmarkdown and htmlwidgets, then showed\ninput and output bindings to interact with R data structures and\nusing inputs to render output tables and graphs. In the end, Theo\nshowed how to create own page layouts using shiny and\nshinydashboard and input and output \"slots\".\nSpeeding up R wih C++ (Rcpp) – from basics to more advanced\napplications by Piotr Wójcik (Faculty of Economic Sciences,\nUniversity of Warsaw, Data Science Lab). Piotr discussed various\naspects of Rcpp that helps to easily replace the R code with\noften significantly faster counterparts in C++. Writing R functions\nin C++ was explained, starting from simple examples with the focus\non similarities and differences between R and C++ syntax. Then Piotr\nat first explained writing loops and recursive calls in C++, using\nRcpp sugar and secondly presented how to store C++ code in *.cpp\nfiles, using Standard Template Library, iterators, algorithms and\nrange-based loops. In the end complex input/output objects (S3 and\nS4) were discussed.\nMachine Learning Pipelines and Reproducible Research with mlr3 and\ndrake by Jakob Richter (TU Dortmund University) and Patrick\nSchratz (LMU Munich). The workshop was divided into two parts – the\nformer introduced the new mlr3 package (Lang et al. 2019) framework\n(the successor of the mlr package) while the latter presented a\nbrief overview of the drake package (Landau 2018) in R. In\nthe first part Jakob and Patrick explained the philosophy and\ningredients of mlr3 package. They presented how to define the\ndata and the target variable, using learners provided by mlr3,\nset and tune hyperparameters, make predictions and evaluate their\nperformance, including resampling techniques and comparing multiple\nlearners. The practical example showed hyperparameter tuning and\ntraining of a random forest classifier on the iris dataset. The\npractical part also involved benchmark analysis of multiple\nlearners, using different hyperparameter ranges on the iris and\nspam datasets. A particular emphasis was put on machine learning\nworkflows that might be easily controlled with mlr3pipelines\npackage (Binder et al. 2019). In the second part the drake\npackage was presented. It helps to set up a reproducible workflow of\nthe project and it easily integrates with the mlr3 package and\nits extensions.\nBasics of spatial data analysis by Jakub Nowosad (Adam\nMickiewicz University, Poznan). The emphasis in this workshop was\nput on getting started with spatial data analysis. Jakub\ndemonstrated key packages for spatial analysis and making maps,\nexplained spatial data representation in R, using sf\n(Pebesma 2018), for spatial vector data, and raster\n(Hijmans et al. 2017) packages. Then he gave a lot of examples of\nspatial data visualization, using a powerful tmap package\n(Tennekes 2018), including some vector-raster interactions. In the\nend, he also showed data manipulation examples with the tidyverse\n(dplyr) approach, in which sf spatial objects are simply special\ndata frames.\n7 Invited talks\nThe invited talks topics included domain knowledge from statistics,\ncomputer science, natural sciences and economics. The speakers list\npresents as follows:\nMarvin Wright\nRandom forests used to be everywhere, from Microsoft Kinect to\nmeteorology, but their popularity considerably dropped with the advent\nof deep learning. During his keynote talk at Why R? 2019 Marvin R.\nWright has shown that random forests still can be used in machine\nlearning routines, making the whole process time- and cost-efficient.\nImplementing a real-life machine learning solution is not only about the\nbest performance. Marvin has shown that considering trade-off between\nperformance and costs of the analysis, random forests are still\nunbeatable. Aside from the methodological background, Marvin has given\nan overview of random forest implementations in\nR (Wright and Ziegler 2017).\nMarvin is a Postdoc at the Leibniz Institute for Prevention Research and\nEpidemiology in Bremen, Germany. He is the author of several R packages,\nincluding the fastest implementation of random forest in R, ranger. He\nholds a Ph.D. in Biostatistics from the University of Lübeck, supervised\nby Andreas Ziegler. In the past, Marvin worked at the University of\nLübeck. He was a visiting researcher at the University of Copenhagen.\nAlso, he spent some time in the automotive and health insurance\nindustries. His main research interests are interpretable machine\nlearning, genetic epidemiology and survival analysis.\nJakub Nowosad\nJakub Nowosad’s keynote lecture was a great opportunity to learn about\ngeostatistics. Jakub, a co-author of the Geocomputation with\nR (Lovelace et al. 2019), has focused on tools used to solve\nreal-life problems in spatial data analysis.\nThe growing importance of spatial data stimulates a rapid evolution of\ngeostatistical methods. Jakub, as the active member of #rspatial\ncommunity, not only presented cutting-edge tools but also gave his\nunique insight into the future of the spatial data analysis.\nJakub is an assistant professor in the Department of Geoinformation at\nthe Adam Mickiewicz University in Poznan, Poland. His main research is\nfocused on developing and applying spatial methods in order to expand\nour understanding of processes and patterns in the environment. He has\nextensive teaching experience in the fields of spatial analysis,\ngeostatistics, statistics, and machine learning.\nSigrid Keydana\nWe know how accurate are our predictions but do we really know how\ncertain they are? This question has been answered by Sigrid Keydana\n(RStudio) during her keynote lecture.\nSigrid has presented tfprobability, an interface to TensorFlow\nProbability, a tool for obtaining uncertainty estimates from deep neural\nnetworks. This exciting tool can be extended beyond a classic deep\nlearning framework into complex hierarchical models.\nSigrid is an Applied Researcher at RStudio. She has experience as a\npsychologist, software developer and data scientist. She is passionate\nabout exploring the borders of deep learning, especially by helping\nusers to apply the power of deep learning in R.\nSteph Locke\nMachine learning models find their place in almost every area of our\nlife, influencing things as small as the video recommendations on\nYouTube or as big as the length and severity of a sentence in a criminal\nprocedure. With the growing importance of machine learning, it becomes\nmore and more important to train models while keeping in mind their\nethical consequences.\nDuring her keynote talk at Why R? 2019, Steph Locke showed us ethical\nconcerns about data science. Apart from pointing out existing issues,\nshe has also presented solutions leading to more fair and transparent\nmachine learning models.\nSteph is the founder of a consultancy in the UK. Her talks, blog posts,\nconferences, and business all have one thing in common – they help\npeople get started with data science. Steph holds the Microsoft MVP\naward for her community contributions. In her spare time, Steph plays\nboard games with her husband and takes copious pictures of her doggos.\nWit Jakuczun\nWit Jakuczun from WLOG Solutions presented his talk about deploying -\nHow to make R great for machine learning in (not only) Enterprise.\nFor many years software engineers have put enormous effort to develop\nbest practices to deliver stable and maintainable software. How R users\ncan benefit from this experience? Wit answered this question by going\nthrough several concepts and tools that are natural for software\nengineers but are often undervalued by R users.\nPaula Brito\nDuring her keynote lecture at Why R? 2019 Paula Brito has given a unique\ninsight into the world of symbolic data, where data points are\nrepresented not as single values, but more complex structures, like sets\nor intervals (Noirhomme‐Fraiture and Brito 2011).\nA classical paradigm of data science assumes that categorical variables,\nlike gender or educational stage, are represented as the single value\nper observation. Paula has shown how to utilize her package, MAINT.Data,\nto model interval data, using its symbolic representation which leads to\nmore accurate and robust models.\nPaula is Associate Professor at the Faculty of Economics of the\nUniversity of Porto, and member of the Artificial Intelligence and\nDecision Support Research Group (LIAAD) of INESC TEC, Portugal. Her\ncurrent research focuses on the analysis of multidimensional complex\ndata, known as symbolic data, for which she develops statistical\napproaches and multivariate analysis methodologies.\n8 Round tables\nRound tables are networking-oriented social mixers devoted to connecting\npeople with similar interests. The exact points discussed during the\nround table and its style depend on the moderators who are shaping out\nthe details, based on the general agenda provided by the Why R?\norganizers. The organizing committee both selects the topics of round\ntables and invites appropriate moderators.\nDiversity in Data Science\nThis board aims to inspire members of affinity groups to pursue careers\nin data science. We hope that this platform for networking will reduce\nthe diversity of R community. Moderator: Barbara Sobkowiak (Women in\nMachine Learning & Data Science Poland).\nCareer-planning in Data Science\nParticipants of WhyR will have a chance to learn from more experienced R\nenthusiasts about their career paths. Moderator: Kamil Kosiński (PwC).\nTeaching Data Science\nPractitioners will share their experiences in introducing their students\nto basic and advanced concepts of data science. Moderator: Patrick\nSchratz (Ludwig Maximilian University of Munich).\nData Visualizations\nDiscuss data visualizations good practices and approaches to various\npresentation challenges. Moderator: Michał Burdukiewicz (Warsaw\nUniversity of Technology).\nEthics in Data Science\nWith the increased importance of machine learning, we are becoming more\nand more concerned about the ethics of data science. Moderator: Steph\nLocke (Locke Data).\n9 Conference organizers\nThe organizing committee consisted of Klaudia Korniluk, Marcin Kosiński,\nMichał Burdukiewicz, Jarosław Chilimoniuk, Katarzyna Sidorczuk, Filip\nPietluch, Weronika Puchała and Dominik Rafacz.\nThe quality of the scientific program of the conference was the\nachievement of Stefan (Brandenburg University of Technology\nCottbus-Senftenberg), Piotr Wójcik (University of Warsaw) and Bernd\nBischl (Ludwig Maximilian University of Munich).\n10 Acknowledgements\nWe would like to express our gratitude to all our sponsors, the Faculty\nof Economic Sciences (University of Warsaw), ML in PL Society, local\norganizers of the pre-meetings and student helpers.\n11 Additional information\nWhy R? 2019 website http://whyr.pl/2019 Corporate sponsors:\nPwC Poland, iDash, R Consortium, umping Rivers Ltd., Appsilon Data\nScience, RStudio, Inc., AnalyxGmbH, Pearson IOKI and WLOG Solutions.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\nJ. J. Allaire, F. Chollet, RStudio, Google, Y. Tang, D. Falbel, W. V. D. Bijl and M. Studer. Keras: R Interface to ’Keras’. 2018. URL https://CRAN.R-project.org/package=keras [online; last accessed July 6, 2018].\n\n\nP. Biecek. DALEX: Descriptive mAchine Learning EXplanations. 2018. URL https://CRAN.R-project.org/package=DALEX [online; last accessed July 6, 2018].\n\n\nM. Binder, F. Pfisterer, B. Bischl, M. Lang and S. Dandl. mlr3pipelines: Preprocessing operators and pipelines for ’mlr3’. 2019. URL https://CRAN.R-project.org/package=mlr3pipelines. R package version 0.1.1.\n\n\nM. Burdukiewicz, L. E. J. Marta Karas, M. Kosiński, B. Bischl and S. Rödiger. Conference report: Why r? 2018. The R Journal, 10(2): 572–578, 2018. URL https://journal.r-project.org/archive/2018-2/whyR.pdf.\n\n\nM. Fasiolo, Y. Goude, R. Nedellec and S. N. Wood. Fast calibrated additive quantile regression. 2017. URL https://arxiv.org/abs/1707.03307.\n\n\nM. Fasiolo, R. Nedellec, Y. Goude and S. N. Wood. Scalable visualisation methods for modern generalized additive models. 2018. URL https://arxiv.org/abs/1809.10632.\n\n\nA. Gosiewska and P. Biecek. auditor: An R package for model-agnostic visual validation and diagnostic. ArXiv e-prints, 2018. URL http://adsabs.harvard.edu/abs/2018arXiv180907763G. Provided by the SAO/NASA Astrophysics Data System.\n\n\nR. J. Hijmans, J. van Etten, J. Cheng, M. Mattiuzzi, M. Sumner, J. A. Greenberg, O. P. Lamigueiro, A. Bevan, E. B. Racine, A. Shortridge, et al. Raster: Geographic Data Analysis and Modeling. 2017. URL https://CRAN.R-project.org/package=raster [online; last accessed July 6, 2018].\n\n\nW. M. Landau. The drake r package: A pipeline toolkit for reproducibility and high-performance computing. Journal of Open Source Software, 3(21): 2018. URL https://doi.org/10.21105/joss.00550.\n\n\nM. Lang, B. Bischl, J. Richter, P. Schratz and M. Binder. mlr3: Machine learning in r - next generation. 2019. URL https://CRAN.R-project.org/package=mlr3. R package version 0.1.4.\n\n\nR. Lovelace, J. Nowosad and J. Muenchow. Geocomputation with R. CRC Press, 2019. Google-Books-ID: 8W2PDwAAQBAJ.\n\n\nM. Noirhomme‐Fraiture and P. Brito. Far beyond the classical data models: Symbolic data analysis. Statistical Analysis and Data Mining: The ASA Data Science Journal, 4(2): 157–170, 2011. URL https://onlinelibrary.wiley.com/doi/abs/10.1002/sam.10112 [online; last accessed December 1, 2019].\n\n\nE. Pebesma. Simple Features for R: Standardized Support for Spatial Vector Data. The R Journal, 10(1): 439–446, 2018. URL https://doi.org/10.32614/RJ-2018-009.\n\n\nM. Tennekes. tmap: Thematic maps in R. Journal of Statistical Software, 84(6): 1–39, 2018. DOI 10.18637/jss.v084.i06.\n\n\nS. N. Wood. Generalized additive models: An introduction with r, second edition. CRC Press, 2017. URL https://books.google.dk/books?id=JTkkDwAAQBAJ.\n\n\nM. N. Wright and A. Ziegler. Ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R. Journal of Statistical Software, 77(1): 2017. URL http://arxiv.org/abs/1508.04409 [online; last accessed December 1, 2019]. arXiv: 1508.04409.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2019-2-bioc/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2019-2 issue.",
    "author": [
      {
        "name": "Bioconductor Core Team",
        "url": {}
      }
    ],
    "date": "2019-12-01",
    "categories": [],
    "contents": "\n\nThe Bioconductor project provides tools for\nthe analysis and comprehension of high-throughput genomic data.\nBioconductor 3.10 was released on 30 October, 2019. It is compatible\nwith R 3.6.1 and consists of 1823 software packages, 384 experiment data\npackages, 953 up-to-date annotation packages, and 27 workflows. The\nrelease announcement\nincludes descriptions of 94 new software packages, and updated NEWS\nfiles for many additional packages. Start using Bioconductor by\ninstalling the most recent version of R and evaluating the commands\n  if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n      install.packages(\"BiocManager\")\n  BiocManager::install()\nInstall additional packages and dependencies, e.g.,\nSingleCellExperiment,\nwith\n  BiocManager::install(\"SingleCellExperiment\")\nDocker and\nAmazon images\nprovides a very effective on-ramp for power users to rapidly obtain\naccess to standardized and scalable computing environments. Key\nresources include:\nThe bioconductor.org web site to\ninstall, learn, use, and develop Bioconductor packages.\nA list of available software,\nlinking to pages describing each package.\nA question-and-answer style user support\nsite and developer-oriented\nmailing list.\nA community slack (sign up)\nfor extended technical discussion.\nThe F1000Research Bioconductor\nchannel for\npeer-reviewed Bioconductor work flows.\nOur package\nsubmission\nrepository for open technical review of new packages.\nOur annual conference will be on\nJuly 29 - 31, 2020 in Boston, USA.\n\n\nBioconductor packages used\nSingleCellExperiment\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2019-2-ch/",
    "title": "CHANGES IN R 3.6.2",
    "description": "The 'CHANGES IN R 3.6.2' article from the 2019-2 issue.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2019-12-01",
    "categories": [],
    "contents": "\n\n\nCHANGES IN R 3.6.2\n\nNEW FEATURES\nrunmed(x, *) gains a new option na.action determining how to\nhandle NaN or NA in x.\ndotchart() gains new options ann, xaxt, frame.plot and\nlog.\n\n\nINSTALLATION on a UNIX-ALIKE\nDetection of the C stack direction has been moved from run-time to\nconfigure: this is safer with LTO builds and allows the detection\nto be overridden – see file config.site.\nSource-code changes enable installation on platforms using\ngcc -fno-common (the expected default for gcc 10.x).\n\n\nC-LEVEL FACILITIES\ninstallTrChar (which is nowadays is wrapped by installChar) is\ndefined in Rinternals.h. (Neither are part of the API.)\n\n\nPACKAGE INSTALLATION\nHeader Rconfig.h contains the value of FC_LEN_T deduced at\ninstallation which is used by the prototypes in headers\nR_ext/BLAS.h and R_ext/Lapack.h but to avoid extensive breakage\nthis is only exposed when USE_FC_LEN_T is defined.\nIf a package’s C/C++ calls to BLAS/LAPACK allow for the ‘hidden’\narguments used by most Fortran compilers to pass the lengths of\nFortran character arguments, define USE_FC_LEN_T and include\nRconfig.h (possibly via R.h) before including R_ext/BLAS.h\nor R_ext/Lapack.h.\nA package with Fortran source code and perhaps C (but not C++)\nsources can request for its shared object/DLL to be linked by the\nFortran compiler by including a line USE_FC_TO_LINK= in\nsrc/Makevars[.win] and using $(SHLIB_OPENMP_FFLAGS) as part of\nPKG_LIBS.\nThe known reason for doing so is a package which uses Fortran (only)\nOpenMP on a platform where the Fortran OpenMP runtime is\nincompatible with the C one (e.g. gfortran 9.x with clang).\n\n\nUTILITIES\nR CMD check has a new option to mitigate checks leaving\nfiles/directories in /tmp. See the ‘R Internals’ manual – this is\npart of –as-cran.\n\n\nWindows\nThe default standard for C++ in package installation is C++11 (as it\nhas been on other platforms where available since R 3.6.0: the\ndefault toolchain on Windows was defaulting to C++98).\n\n\nDEPRECATED AND DEFUNCT\nSupport for specifying C++98 in package installation is deprecated.\nSupport in R CMD config for F77, FCPIFCPLAGS, CPP, CXXCPP\nand CXX98 and similar is deprecated. (CPP is found from the\nsystem make and may well not be set.)\nUse $CC -E and $CXX -E instead of CPP and CXXCPP.\n\n\nBUG FIXES\nrunmed(x, *) when x contains missing values now works\nconsistently for both algorithm=\"Stuetzle\" and \"Turlach\", and no\nlonger segfaults for \"Turlach\", as reported by Hilmar Berger.\napply(diag(3), 2:3, mean) now gives a helpful error message.\ndgamma(x, shape, log=TRUE) now longer overflows to Inf for shape\n< 1 and very small x, fixing , reported by Jonathan Rougier.\nBuffer overflow in building error messages fixed. Reported by\nBenjamin Tremblay.\noptions(str = .) is correctly initialized at package utils load\ntime, now. A consequence is that str() in scripts now is more\nconsistent to interactive use, e.g., when displaying function(**)\nargument lists.\nas.numeric(<call>) now gives correct error message.\nPrinting ls.str() no longer wrongly shows \"<missing>\" in rare\ncases.\nAuto-printing S4 objects no longer duplicates the object, for faster\nspeed and reduced memory consumption. Reported by Aaron Lun.\npchisq(<LRG>, <LRG>, ncp=100) no longer takes practically forever\nin some cases. Hence ditto for corresponding qchisq() calls.\nx %% L for finite x no longer returns NaN when L is\ninfinite, nor suffers from cancellation for large finite L, thanks\nto Long Qu’s .\nAnalogously, x %/% L and L %/% x suffer less from cancellation\nand return values corresponding to limits for large L.\ngrepl(NA, *) now returns logical as documented.\noptions(warn=1e11) is an error now, instead of later leading to C\nstack overflow because of infinite recursion.\nR_tryCatch no longer transfers control for all conditions.\nReported and patch provided by Lionel Henry in .\nformat(object.size(.), digits=NULL) now works, fixing reported by\nJonathan Carroll.\nget_all_vars(f, d) now also works for cases, e.g. where d\ncontains a matrix. Reported by Simon Wood in 2009 and patch provided\nby Ben Bolker in .\nAdditionally, it now also works when some variables are data frames,\nfixing , reported by Patrick Breheny.\nbarplot() could get spacings wrong if there were exactly two bars\n. Patch by Michael Chirico.\npower.t.test() works in more cases when returning values of n\nsmaller than 2.\ndotchart(*, pch=., groups=.) now works better. Reported by Robert\nand confirmed by Nic Rochette in .\ncanCoerce(obj, cl) no longer assumes length(class(obj)) == 1.\nplot.formula(*, subset = *) now also works in a boundary case\nreported by Robert Schlicht (TU Dresden).\nreadBin() and writeBin() of a rawConnection() now also work in\nlarge cases, thanks to a report and proposal by Taeke Harkema in .\n\n\n\nCHANGES IN R 3.6.1\n\nINSTALLATION on a UNIX-ALIKE\nThe default detection of the shell variable libNN is overridden\nfor derivatives of Debian Linux, some of which have started to have\na /usr/lib64 directory. (E.g. Ubuntu 19.04.) As before, it can be\nspecified in config.site.\n\n\nUTILITIES\nR CMD config knows the values of AR and RANLIB, often set for\nLTO builds.\n\n\nDEPRECATED AND DEFUNCT\nThe use of a character vector with .Fortran() is formally\ndeprecated and gives a non-portability warning. (It has long been\nstrongly discouraged in ‘Writing R Extensions’.)\n\n\nBUG FIXES\nOn Windows, GUI package installation via menuInstallPkgs() works\nagain, thanks to Len Weil’s and Duncan Murdoch’s .\nR CMD check on data() fixing thanks to Duncan Murdoch.\nquasi(*, variance = list(..)) now works more efficiently, and\nshould work in all cases fixing . Further, quasi(var = mu(1-mu))\nand quasi(var = \"mu ^ 3\") now work, and\nquasi(variance = \"log(mu)\") now gives a correct error message.\nCreation of lazy loading database during package installation is\nagain robust to Rprofile changing the current working directory ().\nboxplot(y ~ f, horizontal=TRUE) now produces correct x- and\ny-labels.\nrbind.data.frame() allows to keep <NA> levels from factor\ncolumns () via new option factor.exclude.\nAdditionally, it works in one more case with matrix-columns which\nhad been reported on 2017-01-16 by Krzysztof Banas.\nCorrect messaging in C++ pragma checks in tools code for\nR CMD check, fixing thanks to Xavier Robin.\nprint()ing and auto-printing no longer differs for functions with\na user defined print.function, thanks to Bill Dunlap’s report.\nOn Windows, writeClipboard(.., format = <n>) now does correctly\npass format to the underlying C code, thanks to a bug report (with\npatch) by Jenny Bryan.\nas.data.frame() treats 1D arrays the same as vectors, .\nImprovements in smoothEnds(x, *) working with NAs (towards\nrunmed() working in that case, in the next version of R).\nvcov(glm(<quasi>), dispersion = *) works correctly again, fixing\nthanks to Pavel Krivitsky.\nR CMD INSTALL of binary packages on Windows now works also with\nper-directory locking.\nR CMD INSTALL and install.packages() on Windows are now more\nrobust against a locked file in an earlier installation of the\npackage to be installed. The default value of option install.lock\non Windows has been changed to TRUE.\nOn Unix alikes (when readline is active), only expand tilde (~)\nfile names starting with a tilde, instead of almost all tildes.\nIn R documentation (*.Rd) files, item [..] is no longer treated\nspecially when rendered in LaTeX and hence pdf, but rather shows the\nbrackets in all cases.\n\n\n\nCHANGES IN R 3.6.0\n\nSIGNIFICANT USER-VISIBLE CHANGES\nSerialization format version 3 becomes the default for serialization\nand saving of the workspace (save(), serialize(), saveRDS(),\ncompiler::cmpfile()). Serialized data in format 3 cannot be read\nby versions of R prior to version 3.5.0. Serialization format\nversion 2 is still supported and can be selected by version = 2 in\nthe save/serialization functions. The default can be changed back\nfor the whole R session by setting environment variables\nR_DEFAULT_SAVE_VERSION and R_DEFAULT_SERIALIZE_VERSION to 2.\nFor maximal back-compatibility, files vignette.rds and\npartial.rdb generated by R CMD build are in serialization format\nversion 2, and resave by default produces files in serialization\nformat version 2 (unless the original is already in format version\n3).\nThe default method for generating from a discrete uniform\ndistribution (used in sample(), for instance) has been changed.\nThis addresses the fact, pointed out by Ottoboni and Stark, that the\nprevious method made sample() noticeably non-uniform on large\npopulations. See for a discussion. The previous method can be\nrequested using RNGkind() or RNGversion() if necessary for\nreproduction of old results. Thanks to Duncan Murdoch for\ncontributing the patch and Gabe Becker for further assistance.\nThe output of RNGkind() has been changed to also return the ‘kind’\nused by sample().\n\n\nNEW FEATURES\nSys.setFileTime() has been vectorized so arguments path and\ntime of length greater than one are now supported.\naxis() gets new option gap.axis = NA for specifying a\nmultiplication factor for the minimal “gap” (distance) between axis\nlabels drawn. Its default is 1 for labels parallel to the axis,\nand 0.25 for perpendicular ones.\nPerpendicular labels no longer overlap, fixing bug .\nThe default method of plot() gains new arguments xgap.axis = NA\nand ygap.axis = NA to be passed to the x– and y–\naxis(.., gap.axis=*) calls.\nremoveSource() now works not only for functions but also for some\nlanguage objects.\nas.call(), rep.int(), rep_len() and nchar() dispatch\ninternally.\nis(object, class2) looks for class2 in the calling namespace\nafter looking in the namespace of class(object).\nextendrange(.., f) with a length-2 f now extends separately to\nthe left and the right.\nlengths() dispatches internally to S4 methods.\ndownload.file() on Windows now uses URLdecode() to determine the\nfile extension, and uses binary transfer (mode = \"wb\") also for\nfile extension .rds.\nThe help page for download.file() now contains the same\ninformation on all platforms.\nSetting C locale for collation via environment variables\nLC_ALL and LC_COLLATE and via a call to Sys.setlocale() now\ntakes precedence over environment variable R_ICU_LOCALE.\nThere is a new function, nullfile(), to give the file name of the\nnull system device (e.g., /dev/null) on the current platform.\nThere are two new options, keep.parse.data and\nkeep.parse.data.pkgs, which control whether parse data are\nincluded into sources when keep.source or keep.source.pkgs is\nTRUE. By default, keep.parse.data.pkgs is now FALSE, which\nchanges previous behavior and significantly reduces space and time\noverhead when sources are kept when installing packages.\nIn rapply(x, ..), x can also be “list-like” and of length .\ntrimws() gets new optional whitespace argument, allowing more\nextensive definitions of “space”, such as including Unicode spaces\n(as wished in ).\nweighted.mean() no longer coerces the weights to a double/numeric\nvector, since sum() now handles integer overflow. This makes\nweighted.mean() more polymorphic and endomorphic, but be aware\nthat the results are no longer guaranteed to be a vector of type\ndouble.\nWhen loading namespaces, S3 method registrations which overwrite\nprevious registrations are now noted by default (using\npackageStartupMessage()).\ncompiler::cmpfile() gains a version argument, for use when the\noutput file should be saved in serialization format 2.\nThe axis labeling in the default method of pairs() may now be\ntoggled by new options horOdd and verOdd.\n(Not Windows nor macOS.) Package tcltk now supports an environment\nvariable R_DONT_USE_TK which if set disables Tk initialization.\nThis is intended for use to circumvent errors in loading the\npackage, e.g. with recent Linux running under an address sanitizer.\nThe numeric method of all.equal() gets optional arguments\ncountEQ and formatFUN. If countEQ is true, the mean error is\nmore sensible when many entries are ual.\nouter(x,y, FUN = \"*\") is more efficient using tcrossprod(u,v)\ninstead of u %*% t(v).\nvcov(<mlm>) is more efficient via new optional arguments in\nsummary.mlm().\nThe default method of summary() gets an option to choose the\nkind of quantile()s to use; wish of .\nFitting multiple linear models via lm() does work with matrix\noffsets, as suggested in .\nThe new functions mem.maxVSize() and mem.maxMSize() allow the\nmaximal size of the vector heap and the maximal number of nodes\nallowed in the current R process to be queried and set.\nnews() gains support for NEWS.md files.\nAn effort has been started to have our reference manuals, i.e., all\nhelp pages. show platform-independent information (rather than\nWindows or Unix-alike specifics visible only on that platform).\nConsequently, the Windows version of X11() / x11() got identical\nformal arguments to the Unix one.\nsessionInfo()$running has been factored out in a new variable\nosVersion.\nslice.index() now also works for multi-dimensional margins.\nuntar() used with an external tar command assumes this supports\ndecompression including xz and automagically detecting the\ncompression type. This has been true of all mainstream\nimplementations since 2009 (for GNU tar, since version 1.22):\nolder implementations are still supported via the new argument\nsupport_old_tars whose default is controlled by environment\nvariable R_SUPPORT_OLD_TARS. (It looks like NetBSD and OpenBSD\nhave ‘older’ tar commands for this purpose.)\nThe new function asplit() allow splitting an array or matrix by\nits margins.\nNew functions errorCondition() and warningCondition() provide a\nconvenient way to create structured error and warning objects.\n.Deprecated() now signals a warning of class\n\"deprecatedWarning\", and .Defunct() now signals an error of\nclass \"defunctError\".\nMany ‘package not found’ errors are now signaled as errors of class\n\"packageNotFoundError\".\nAs an experimental feature, when loadNamespace() fails because the\nrequested package is not available the error is initially signaled\nwith a retry_loadNamespace restart available. This allows a\ncalling handler to try to install the package and continue.\nS3method() directives in NAMESPACE can now also be used to\nperform delayed S3 method registration.\nExperimentally, setting environment variable\n_R_CHECK_LENGTH_1_LOGIC2_ will lead to warnings (or errors if the\nvariable is set to a ‘true’ value) when && or || encounter and\nuse arguments of length more than one.\nAdded \"lines\" and \"chars\" coordinate systems to grconvertX()\nand grconvertY().\ngetOption() is more efficient notably for the rare case when\ncalled with two arguments, from several contributors in .\nIn .col(dim) and .row(dim), dim now may also be an\ninteger-valued \"double\".\nsQuote() and dQuote() get an explicit q argument with obvious\ndefault instead of using getOption(\"fancyQuotes\") implicitly and\nunconditionally.\nunzip() can list archives with comments and with spaces in file\nnames even using an external unzip command.\nCommand line completion has a new setting\nrc.settings(dots = FALSE) to remove ... from the list of\npossible function arguments.\nlibrary() no longer checks packages with compiled code match\nR.version$platform. loadNamespace() never has, and increasingly\nthe ‘canonical name’ does not reflect the important characteristics\nof compiled code.\nThe primitive functions drop() and unclass() now avoid\nduplicating their data for atomic vectors that are large enough, by\nreturning ALTREP wrapper objects with adjusted attributes. R-level\nassignments to change attributes will also use wrapper objects to\navoid duplicating data for larger atomic vectors. R functions like\nstructure() and unname() will therefore not duplicate data in\nthese settings. Generic vectors as produced by list() are not yet\ncovered by this optimization but may be in due course.\nIn formals(), envir becomes an optional argument instead of\nbeing hardwired.\nInstead of signalling an error for an invalid S4 object x,\nstr(x) now gives a warning and subsequently still shows most parts\nof x, e.g., when slots are missing.\ngamma(x) and lgamma(x) no longer warn when correctly returning\nInf or underflowing to zero. This helps maximum likelihood and\nsimilar computations.\nconvertColor() is now vectorized, so a lot faster for converting\nmany colours at once. The new argument vectorized to\ncolorConverter() ensures that non-vectorized colour converters\nstill work. (Thanks to Brodie Gaslam.)\ndownload.file() and url() get new argument headers for custom\nHTTP headers, e.g., allowing to perform basic http authentication,\nthanks to a patch contributed by Gábor Csárdi.\nFile-based connection functions file(), gzfile(), bzfile() and\nxzfile() now signal an error when used on a directory.\nFor approx(), splinefun() etc, a new setting\nties = c(\"ordered\", <fun>) allows skipping the sorting and still\ntreat ties.\nformat(x) gives a more user friendly error message in the case\nwhere no method is defined. A minimal method is provided in\nformat.default(x) when isS4(x) is true.\nwhich(x) now also works when x is a long vector, thanks to\nSuharto Anggono’s . NB: this may return a double result,\nbreaking the previous guarantee of an integer result.\nseq.default() is more careful to return an integer (as opposed\nto double) result when its arguments are large and/or classed\nobjects; see comment #9 of Suharto Anggono’s .\nThe plot() method for lm and glm fits, plot.lm(), gains a\nnew option iter.smooth with a default of 0 for binomial fits, no\nlonger down-weighting when smoothing the residuals.\nzip() passes its list of files via standard input to the\nexternal command when too long for the command line (on some\nplatforms).\ndata() gains an overwrite argument.\nt.test() now also returns the standard error (in list component\nstderr).\nmodel.matrix(*, contrasts.arg = CC) now warns about invalid\ncontrasts.args.\nPerformance of substr() and substring() has been improved.\nstopifnot() has been simplified thanks to Suharto Anggono’s\nproposals to become considerably faster for cheap expressions.\nThe default ‘user agent’ has been changed when accessing http://\nand https:// sites using libcurl. (A site was found which caused\nlibcurl to infinite-loop with the previous default.)\nsessionInfo() now also contains RNGkind() and prints it when it\ndiffers from the default; based on a proposal and patch by Gabe\nBecker in . Also, RNGversion(getRversion()) works directly.\nlibrary() and require() now allow more control over handling\nsearch path conflicts when packages are attached. The policy is\ncontrolled by the new conflicts.policy option.\nbarplot() gets a formula method, thanks to a patch proposal by\nArni Magnusson in .\npmax() and pmin(x) now also work for long vectors, thanks to\nSuharto Anggono’s .\nbxp() now warns when omitting duplicated arguments.\nNew hcl.colors() function to provide wide range of HCL-based\ncolour palettes with much better perceptual properties than the\nexisting RGB/HSV-based palettes like rainbow().\nAlso a new hcl.pals() function to list available palette names for\nhcl.colors().\nContributed by Achim Zeileis.\nThe default colours for image() and filled.contour() are now\nbased on hcl.colors().\nThe palette-generating functions rainbow(), gray.colors(),\netc. get a new rev argument to facilitate reversing the order of\ncolors.\nNew str2lang() and str2expression() as streamlined versions of\nparse(text=., keep.source=FALSE) allow to abstract typical call\nconstructions, e.g., in formula manipulations. (Somewhat\nexperimental)\nAdd update_PACKAGES() for incrementally updating a package\nrepository index, instead of rebuilding the index from scratch.\nThanks to Gabe Becker in for the patch, based on part of his\nswitchr package.\n\n\nINSTALLATION on a UNIX-ALIKE\nThe options selected for the C++ compiler default to the C++11\nstandard if supported, otherwise to the C++98 standard.\nVisibility macros such as C_VISIBILITY can now be user-set\n(including to empty), e.g. in config.site.\nMacro FCLIBS, which has sometimes been needed on Solaris, has been\nrenamed to FCLIBS_XTRA.\nMacro F77 is always set to the value of FC, so the latter should\nbe set to user-select the Fortran compiler for both fixed-form and\nfree-form Fortran. In particular, gfortran is now the first choice\nfor F77, not f95.\nMacros FFLAGS and FCFLAGS remain distinct to allow for a\ncompiler which needs a flag to select free- or fixed-form Fortran\n(most use the source-file extension to choose: .f is fixed-form\nand .f90 and .f95 are free-form).\nIf only one of them is set, its value is used for both.\nThe special-casing of CFLAGS, CXXFLAGS and FFLAGS for Intel\ncompilers on Linux has been removed: we do not have recent\nexperience but the generic defaults now chosen are the same as those\npreviously special-cased for x86_64.\nIf necessary, override the defaults on the configure command line\nor in file config.site.\nLong-untested configure support for HP-UX and very old versions of\nLinux has been removed.\nconfigure –with-blas (without specifying a value) includes\nOpenBLAS in its search (before ATLAS and a generic BLAS). This\nfollows recent versions of the ax_blas autoconf macro.\nThe configure macro MAKEINFO has been updated to TEXI2ANY.\nSupport for make install-strip has been enhanced.\n\n\nPACKAGE INSTALLATION\nSource package installation is by default ‘staged’: the package is\ninstalled into a temporary location under the final library\ndirectory and moved into place once the installation is complete.\nThe benefit is that partially-installed packages are hidden from\nother R sessions.\nThe overall default is set by environment variable\nR_INSTALL_STAGED. R CMD INSTALL has new options\n–staged-install and –no-staged-install, and packages can use the\nStagedInstall field in their DESCRIPTION file to opt out. (That\nopt-out is a temporary measure which may be withdrawn in future.)\nStaged installation requires either –pkglock or –lock, one of\nwhich is used by default.\nThe interpretation of source code with extension .f is changing.\nPreviously this denoted FORTRAN 77 code, but current compilers no\nlonger have a FORTRAN 77 mode and interpret it as ‘fixed-form’\nFortran 90 (or later where supported) code. Extensions .f90 and\n.f95 continue to indicate ‘free-form’ Fortran code.\nLegal FORTRAN 77 code is also legal fixed-form Fortran 9x; however\nthis change legitimizes the use of later features, in particular to\nreplace features marked ‘obsolescent’ in Fortran 90 and ‘deleted’ in\nFortran 2018 which gfortran 8.x and later warn about.\nPackages containing files in the src directory with extensions\n.f90 or .f95 are now linked using the C or C++ compiler rather\nthan the Fortran 9x compiler. This is consistent with fixed-form\nFortran code and allows mixing of C++ and free-form Fortran on most\nplatforms.\nConsequentially, a package which includes free-form Fortran 9x code\nwhich uses OpenMP should include SHLIB_OPENMP_CFLAGS (or the\nCXXFLAGS version if they also include C++ code) in PKG_LIBS\nrather than SHLIB_OPENMP_FCFLAGS — fortunately on almost all\ncurrent platforms they are the same flag.\nMacro PKG_FFLAGS will be used for the compilation of both\nfixed-form and free-form Fortran code unless PKG_FCFLAGS is also\nset (in src/Makevars or src/Makevars.win).\nThe make macro F_VISIBILITY is now preferred for both fixed-form\nand free-form Fortran, for use in src/Makevars and similar.\nR CMD INSTALL gains a new option –strip which (where supported)\nstrips installed shared object(s): this can also be achieved by\nsetting the environment variable _R_SHLIB_STRIP_ to a true value.\nThe new option –strip-lib attempts stripping of static and shared\nlibraries installed under lib.\nThese are most useful on platforms using GNU binutils (such as\nLinux) and compiling with -g flags.\nThere is more support for installing UTF-8-encoded packages in a\nstrict Latin-1 locale (and probably for other Latin locales):\nnon-ASCII comments in R code (and NAMESPACE files) are worked\naround better.\n\n\nUTILITIES\nR CMD check now optionally checks makefiles for correct and\nportable use of the SHLIB_OPENMP_*FLAGS macros.\nR CMD check now evaluates Sexpr{} expressions (including those\nin macros) before checking the contents of Rd files and so detects\nissues both in evaluating the expressions and in the expanded\ncontents.\nR CMD check now lists missing packages separated by commas and\nwith regular quotes such as to be useful as argument in calling\ninstall.packages(c(..)); from a suggestion by Marcel Ramos.\ntools::Rd2latex() now uses UTF-8 as its default output encoding.\nR CMD check now checks line endings of files with extension .hpp\nand those under inst/include. The check now includes that a\nnon-empty file is terminated with a newline.\nR CMD build will correct line endings in such files.\nR CMD check now tries re-building all vignettes rather than\nstopping at the first error: whilst doing so it adds ‘bookmarks’ to\nthe log. By default (see the ‘R Internals’ manual) it re-builds each\nvignette in a separate process.\nIt now checks for duplicated vignette titles (also known as ‘index\nentries’): they are used as hyperlinks on CRAN package pages and so\ndo need to be unique.\nR CMD check has more comprehensive checks on the data directory\nand the functioning of data() in a package.\nR CMD check now checks autoconf-generated configure files have\ntheir corresponding source files, including optionally attempting to\nregenerate them on platforms with autoreconf.\nR CMD build has a new option –compression to select the\ncompression used for the tarball.\nR CMD build now removes src/*.mod files on all platforms.\n\n\nC-LEVEL FACILITIES\nNew pointer protection C functions R_PreserveInMSet and\nR_ReleaseFromMSet have been introduced to replace UNPROTECT_PTR,\nwhich is not safe to mix with UNPROTECT (and with\nPROTECT_WITH_INDEX). Intended for use in parsers only.\nNAMEDMAX has been raised to 7 to allow further protection of\nintermediate results from (usually ill-advised) assignments in\narguments to BUILTIN functions. Properly written package code\nshould not be affected.\nR_unif_index is now considered to be part of the C API.\nR_GetCurrentEnv() allows C code to retrieve the current\nenvironment.\n\n\nDEPRECATED AND DEFUNCT\nArgument compressed of untar() is deprecated — it is only used\nfor external tar commands which increasingly for extraction\nauto-detect compression and ignore their zjJ flags.\nvar(f) and hence sd(f) now give an error for factor arguments;\nthey gave a deprecation warning since R 3.2.3, .\nPackage tools’ vignetteDepends() has been deprecated (it called\na function deprecated since Feb 2016), being partly replaced by\nnewly exported vignetteInfo().\nThe f77_f2c script has been removed: it no longer sufficed to\ncompile the .f files in R.\nThe deprecated legacy support of make macros such as CXX1X has\nbeen removed: use the CXX11 forms instead.\nMake macro F77_VISIBILITY is deprecated in favour of\nF_VISIBILITY.\nMake macros F77, FCPIFCPLAGS and SHLIB_OPENMP_FCFLAGS are\ndeprecated in favour of FC, FPICFLAGS and SHLIB_OPENMP_FFLAGS\nrespectively.\n$.data.frame had become an expensive version of the default\nmethod, so has been removed. (Thanks to Radford Neal for picking\nthis up and to Duncan Murdoch for providing a patch.)\n\n\nBUG FIXES\nreplayPlot(r) now also works in the same R session when r has\nbeen “reproduced” from serialization, typically after saving to and\nreading from an RDS file.\nsubstr() and substring() now signal an error when the input is\ninvalid UTF-8.\nfile.copy() now works also when its argument to is of length\ngreater than one.\nmantelhaen.test() no longer suffers from integer overflow in\nlargish cases, thanks to Ben Bolker’s .\nCalling setGeneric(\"foo\") in a package no longer fails when the\nenclosing environment of the implicit generic foo() is\n.GlobalEnv.\nuntar(file(\"<some>.tar.gz\"), *) now gives a better error message,\nsuggesting to use gzfile() instead.\nMethod dispatch uses more relevant environments when looking up\nclass definitions.\nThe documentation for identify() incorrectly claimed that the\nindices of identified points were returned in the order that the\npoints were selected. identify() now has a new argument order to\nallow the return value to include the order in which points were\nidentified; the documentation has been updated. Reported by Richard\nRowe and Samuel Granjeaud.\norder(...., decreasing=c(TRUE, FALSE)) could fail in some cases.\nReported from StackOverflow via Karl\nUser macros in Rd files now accept empty and multi-line arguments.\nChanges in print.*(), thanks to Lionel Henry’s patches in :\nPrinting lists, pairlists or attributes containing calls with S3\nclass no longer evaluate those.\nPrinting S4 objects within lists and pairlists dispatches with\nshow() rather than print(), as with auto-printing.\nThe indexing tags (names or [[<n>]]) of recursive data\nstructures are now printed correctly in complex cases.\nArguments supplied to print() are now properly forwarded to\nmethods when printing lists, pairlists or attributes containing\nS3 objects.\nThe print parameters are now preserved when printing S3 objects\nor deparsing symbols and calls. Previously, printing lists\ncontaining S3 objects or expressions would reset these\nparameters.\nPrinting lists, pairlists or attributes containing functions now\nuses srcref attributes if present.\n\nCalling install.packages() with a length zero pkgs argument now\nis a no-op ().\nunlist(x) now returns a correct factor when x is a nested list\nwith factor leaves, fixing and .\nThe documentation help(family) gives more details about the aic\ncomponent, thanks to Ben Bolker’s prompting.\nThe documentation for attributes and ‘attributes<-‘ now gives\nx as name of the first and main argument which the implementation\nhas been requiring, fixing . For consistency, the first argument\nname is also changed from obj to x for ‘mostattributes<-‘.\nstrwidth() now uses par(\"font\") as default font face ().\nplot(<table>, log=\"x\") no longer warns about log.\nThe print() method for \"htest\" objects now formats the test\nstatistic and parameter directly and hence no longer rounds to units\nbefore the decimal point. Consequently, printing of t.test()\nresults with a small number of digits now shows non-large df’s to\nthe full precision ().\nkruskal.test() and fligner.test() no longer erroneously insist\non numeric g group arguments ().\nPrinting a news db via the browser now does a much better job ().\nprint.aov() missed column names in the multivariate case due to\nmisspelling (reported by Chris Andrews).\naxis() now creates valid at locations also for small subnormal\nnumber ranges in log scale plots.\nformat.POSIXlt() now also recycles the zone and gmtoff list\ncomponents to full length when needed, and its internal C code\ndetects have_zone in more cases. In some cases, this changes its\noutput to become compatible with format.POSIXct().\nOn Windows, detectCores() in package parallel now detects\nprocessors in all processor groups, not just the group R is running\nin (impacts particularly systems with more than 64 logical\nprocessors). Reported by Arunkumar Srinivasan.\nOn Windows, socketSelect() would hang with more than 64 sockets,\nand hence parallel::clusterApplyLB() would hang with more than 64\nworkers. Reported by Arunkumar Srinivasan.\nas(1L, \"double\") now does coerce ().\nlm.influence(), influence.measures(), rstudent() etc now work\n(more) correctly for multivariate models (\"mlm\"), thanks to\n(anonymous) stackoverflow remarks.\nsample.int(2.9, *, replace=TRUE) again behaves as documented and\nas in R < 3.0.0, namely identically to sample.int(2, ..).\nFixes to convertColor() for chromatic adaptation; thanks to Brodie\nGaslam .\nUsing Sexpr[stage=install]{..} to create an Rd section no longer\ngives a warning in R CMD check; problem originally posted by Gábor\nCsárdi, then reported as with a partial patch by Duncan Murdoch.\nParse data now include a special node for equal assignment.\nsplit.default() no longer relies on [[<-(), so it behaves as\nexpected when splitting an object by a factor with the empty string\nas one of its levels. Thanks to Brad Friedman for the report.\nLine numbers in messages about .Rd files are now more reliable,\nthanks to a patch from Duncan Murdoch.\nIn the numeric method for all.equal(), a numeric scale\nargument is now checked to be positive and allowed to be of length\n> 1. (The latter worked originally and with a warning in recent\nyears).\nDeferred string conversions now record the OutDec option setting\nwhen not equal to the default. Reported by Michael Sannella.\nWhen y is numeric and f a factor, plot(y ~ f) nicely uses\n\"y\" and \"f\" as y- and x-labels. The more direct boxplot(y ~ f)\nnow does too. The new argument ann = FALSE may be used to suppress\nthese.\nSubassignment to no/empty rows of a data frame is more consistent\nand typically a no-op in all cases instead of sometimes an error;\npart of Emil Bode’s .\nCalls like formatC(*, zero.print = \"< 0.001\") no longer give an\nerror and are further improved via new optional argument\nreplace.zero. Reported by David Hugh-Jones.\nmethods::formalArgs(\"<fn>\") now finds the same function as\nformals(\"<fn>\"), fixing Emil Bode’s .\nThe methods package better handles duplicated class names across\npackages.\nThe default method of seq() now avoids integer overflow, thanks to\nthe report and \"cumsum\" patch of Suharto Anggono’s .\nsub() no longer loses encodings for non-ASCII replacements ().\nFix for rotated raster image on X11 device. (Partial fix for ;\nthanks to Mikko Korpela).\nformula(model.frame(frml, ..)) now returns frml in all cases,\nthanks to Bill Dunlap. The previous behavior is available as\nDF2formula(<model.frame>).\nar.ols() also returns scalar var.pred in univariate case ().\nnormalizePath() now treats NA path as non-existent and\nnormalizes it to NA. file.access() treats NA file name as\nnon-existent. file.edit() and connection functions such as\nfile() now treat NA file names as errors.\nThe internal regularize.values() auxiliary of approx(),\nsplinefun() etc now warns again when there are ties and the caller\ndid not specify ties. Further, it no longer duplicates x and y\nunnecessarily when x is already sorted ().\nstrtoi(\"\", base) now gives NA on all platforms, following its\ndocumentation. Reported by Michael Chirico.\nIn the definition of an S4 class, prototype elements are checked\nagainst the slots of the class, with giving a prototype for an\nundefined slot now being an error. (Reported by Bill Dunlap.)\nFrom setClassUnion(), if environment variable\n_R_METHODS_SHOW_CHECKSUBCLASSES is set to true, the internal\n.checkSubclasses() utility prints debugging info to see where it\nis used.\nmax.col(m) with an m of zero columns now returns integer NA\n(instead of 1).\naxTicks() no longer returns small “almost zero” numbers (in\nexponential format) instead of zero, fixing Ilario Gelmetti’s .\nisSymmetric(matrix(0, dimnames=list(\"A\",\"b\"))) is FALSE again,\nas always documented.\nThe cairo_pdf graphics device (and other Cairo-based devices) now\nclip correctly to the right and bottom border.\nThere was an off-by-one-pixel bug, reported by Lee Kelvin.\nas.roman(3) <= 2:4 and all other comparisons now work, as do group\n\"Summary\" function calls such as max(as.roman(sample(20))) and\nas.roman(NA). (Partly reported by Bill Dunlap in .)\nreformulate(\"x\", response = \"sin(y)\") no longer produces extra\nback quotes, , and gains new optional argument env.\nWhen reading console input from stdin with re-encoding\n(R –encoding=enc < input) the code on a Unix-alike now ensures\nthat each converted input line is terminated with a newline even if\nre-encoding fails.\nas.matrix.data.frame() now produces better strings from logicals,\nthanks to from Gabe Becker.\nThe S4 generic signature of rowSums(), rowMeans(), colSums()\nand colMeans() is restricted to \"x\".\nmatch(x, tab) now works for long character vectors x, thanks\nto by Andreas Kersting.\nClass unions are unloaded when their namespace is unloaded (,\nadapted from a patch by Brodie Gaslam).\nselectMethod() is robust to ANY-truncation of method signatures\n(thanks to Herve Pages for the report).\n\n\n\nCHANGES IN R 3.5.3\n\nINSTALLATION on a UNIX-ALIKE\nDetection of flags for C++98/11/14/17 has been improved: in\nparticular if CXX??STD is set, it is tried first with no additional\nflags.\n\n\nPACKAGE INSTALLATION\nNew macro F_VISIBILITY as an alternative to F77_VISIBILITY. This\nwill become the preferred form in R 3.6.0.\n\n\nBUG FIXES\nwriteLines(readLines(fnam), fnam) now works as expected, thanks to\nPeter Meissner’s .\nsetClassUnion() no longer warns, but uses message() for now,\nwhen encountering “non local” subclasses of class members.\nstopifnot(exprs = T) no longer fails.\n\n\n\nCHANGES IN R 3.5.2\n\nPACKAGE INSTALLATION\nNew macro CXX_VISIBILITY analogous to C_VISIBILITY (which\nseveral packages have been misusing for C++ code) for the default\nC++ compiler (but not necessarily one used for non-default C++\ndialects like C++14).\n\n\nTESTING\nThe random number generator tests in tests/p-r-random-tests.R no\nlonger fail occasionally as they now randomly sample from\n“certified” random seeds.\n\n\nBUG FIXES\nThe \"glm\" method of drop1() miscalculated the score test\n(test=\"Rao\") when the model contained an offset.\nLinear multiple empty models such as lm(y ~ 0) now have a\ncorrectly dimensioned empty coefficient matrix; reported by Brett\nPresnell.\nvcov(<empty mlm>) and hence confint() now work (via a\nconsistency change in summary.lm()).\nconfint(<multiple lm()>) now works correctly; reported on R-devel\nby Steven Pav.\nquade.test() now also works correctly when its arguments are not\nyet sorted along groups, fixing .\nInstallation on a Unix-alike tries harder to link to the pthread\nlibrary where required (rather than relying on OpenMP to provide it:\nconfiguring with –disable-openmp was failing on some Linux\nsystems).\nThe data.frame method for print(x) is fast now also for large\ndata frames x and got an optional argument max, thanks to\nsuggestions by Juan Telleria.\nhist() no longer integer overflows in very rare cases, fixing .\nuntar() ignored a character compressed argument: however many\nexternal tar programs ignore the flags which should have been set\nand automagically choose the compression type, and if appropriate\ngzip or bzip2 compression would have been chosen from the magic\nheader of the tarball.\nzapsmall(x) now works for more “number-like” objects.\nThe tools-internal function called from R CMD INSTALL now gets a\nwarnOption = 1 argument and only sets options(warn = warnOption)\nwhen that increases the warning level ().\nAnalogously, the tools-internal function called from R CMD check\ngets a warnOption = 1 argument and uses the larger of that and\ngetOption(\"warn\"), also allowing to be run with increased warning\nlevel.\nParse data now have deterministic parent nodes ().\nCalling match() with length one x and POSIXlt table gave a\nsegfault ().\nFork clusters could hang due to a race condition in cluster\ninitialization (makeCluster()).\nnextn(n) now also works for larger n and no longer loops\ninfinitely for e.g, n <- 214e7.\ncooks.distance() and rstandard() now work correctly for multiple\nlinear models (\"mlm\").\npolym() and corresponding lm() prediction now also work for a\nboundary \"vector\" case fixing , reported by Alexandre Courtiol.\nWith a very large number of variables terms() could segfault ().\ncut(rep(0, 7)) now works, thanks to Joey Reid and Benjamin Tyner\n().\ndownload.file(*, method = \"curl\", cacheOK = FALSE) should work now\non Windows, thanks to Kevin Ushey’s patch in .\nduplicated(<dataframe with ’f’>) now works, too, thanks to Andreas\nKersting’s ; ditto for anyDuplicated().\nlegend(*, cex = 1:2) now works less badly.\nThe print() method for POSIXct and POSIXlt now correctly obeys\ngetOption(\"max.print\"), fixing a long-standing typo, and it also\ngets a corresponding optional max argument.\nUnserialization of raw vectors serialized in ASCII representation\nnow works correctly.\n<data frame>[TRUE, <new>] <- list(c1, c2) now works correctly,\nthanks to Suharto Anggono’s and Emil Bode’s patch in .\nseq.int(*, by=by, length=n) no longer wrongly “drops fractional\nparts” when by is integer, thanks to Suharto Anggono’s report .\nBuffering is disabled for file() connections to non-regular files\n(like sockets), as well as fifo() and pipe() connections. Fixes\n, reported by Chris Culnane.\n\n\n\nCHANGES IN R 3.5.1\n\nBUG FIXES\nfile(\"stdin\") is no longer considered seekable.\ndput() and dump() are no longer truncating when\noptions(deparse.max.lines = *) is set.\nCalls with an S3 class are no longer evaluated when printed, fixing\npart of , thanks to a patch from Lionel Henry.\nAllow file argument of Rscript to include space even when it is\nfirst on the command line.\ncallNextMethod() uses the generic from the environment of the\ncalling method. Reported by Hervé Pagès with well documented\nexamples.\nCompressed file connections are marked as blocking.\noptim(*, lower = c(-Inf, -Inf)) no longer warns (and switches the\nmethod), thanks to a suggestion by John Nash.\npredict(fm, newdata) is now correct also for models where the\nformula has terms such as splines::ns(..) or stats::poly(..),\nfixing , based on a patch from Duncan Murdoch.\nsimulate.lm(glm(*, gaussian(link = <non-default>))) has been\ncorrected, fixing thanks to Alex Courtiol.\nunlist(x) no longer fails in some cases of nested empty lists.\nReported by Steven Nydick.\nqr.coef(qr(<all 0, w/ colnames>)) now works. Reported by Kun Ren.\nThe radix sort is robust to vectors with >1 billion elements (but\nlong vectors are still unsupported). Thanks to Matt Dowle for the\nfix.\nTerminal connections (e.g., stdin) are no longer buffered. Fixes .\ndeparse(x), dput(x) and dump() now respect c()’s argument\nnames recursive and use.names, e.g., for\nx <- setNames(0, \"recursive\"), thanks to Suharto Anggono’s .\nUnbuffered connections now work with encoding conversion. Reported\nby Stephen Berman.\n.Renviron on Windows with Rgui is again by default searched for\nin user documents directory when invoked via the launcher icon.\nReported by Jeroen Ooms.\nprintCoefmat() now also works with explicit right=TRUE.\nprint.noquote() now also works with explicit quote=FALSE.\nThe default method for pairs(.., horInd=*, verInd=*) now gets the\ncorrect order, thanks to reports by Chris Andrews and Gerrit\nEichner. Additionally, when horInd or verInd contain only a\nsubset of variables, all the axes are labeled correctly now.\nagrep(\"..|..\", .., fixed=FALSE) now matches when it should, thanks\nto a reminder by Andreas Kolter.\nstr(ch) now works for more invalid multibyte strings.\n\n\n\nCHANGES IN R 3.5.0\n\nSIGNIFICANT USER-VISIBLE CHANGES\nAll packages are by default byte-compiled on installation. This\nmakes the installed packages larger (usually marginally so) and may\naffect the format of messages and tracebacks (which often exclude\n.Call and similar).\n\n\nNEW FEATURES\n\n\nUTILITIES\ninstall.packages() for source packages now has the possibility to\nset a ‘timeout’ (elapsed-time limit). For serial installs this uses\nthe timeout argument of system2(): for parallel installs it\nrequires the timeout utility command from GNU coreutils.\nIt is now possible to set ‘timeouts’ (elapsed-time limits) for most\nparts of R CMD check via environment variables documented in the\n‘R Internals’ manual.\nThe ‘BioC extra’ repository which was dropped from Bioconductor 3.6\nand later has been removed from setRepositories(). This changes\nthe mapping for 6–8 used by setRepositories(ind=).\nR CMD check now also applies the settings of environment variables\n_R_CHECK_SUGGESTS_ONLY_ and _R_CHECK_DEPENDS_ONLY_ to the\nre-building of vignettes.\nR CMD check with environment variable _R_CHECK_DEPENDS_ONLY_ set\nto a true value makes test-suite-management packages available and\n(for the time being) works around a common omission of from the\nVignetteBuilder field.\n\n\nINSTALLATION on a UNIX-ALIKE\nSupport for a system Java on macOS has been removed — install a\nfairly recent Oracle Java (see ‘R Installation and Administration’\n§C.3.2).\nconfigure works harder to set additional flags in SAFE_FFLAGS\nonly where necessary, and to use flags which have little or no\neffect on performance.\nIn rare circumstances it may be necessary to override the setting of\nSAFE_FFLAGS.\nC99 functions expm1, hypot, log1p and nearbyint are now\nrequired.\nconfigure sets a -std flag for the C++ compiler for all\nsupported C++ standards (e.g., -std=gnu++11 for the C++11\ncompiler). Previously this was not done in a few cases where the\ndefault standard passed the tests made (e.g. clang 6.0.0 for\nC++11).\n\n\nC-LEVEL FACILITIES\n‘Writing R Extensions’ documents macros MAYBE_REFERENCED,\nMAYBE_SHARED and MARK_NOT_MUTABLE that should be used by package\nC code instead NAMED or SET_NAMED.\nThe object header layout has been changed to support merging the\nALTREP branch. This requires re-installing packages that use\ncompiled code.\n‘Writing R Extensions’ now documents the R_tryCatch,\nR_tryCatchError, and R_UnwindProtect functions.\nNAMEDMAX has been raised to 3 to allow protection of intermediate\nresults from (usually ill-advised) assignments in arguments to\nBUILTIN functions. Package C code using SET_NAMED may need to\nbe revised.\n\n\nDEPRECATED AND DEFUNCT\nSys.timezone(location = FALSE) is defunct, and is ignored (with a\nwarning).\nmethods:::bind_activation() is defunct now; it typically has been\nunneeded for years.\nThe undocumented ‘hidden’ objects .__H__.cbind and .__H__.rbind\nin package base are deprecated (in favour of cbind and rbind).\nThe declaration of pythag() in Rmath.h has been removed — the\nentry point has not been provided since R 2.14.0.\n\n\nBUG FIXES\nprintCoefmat() now also works without column names.\nThe S4 methods on Ops() for the \"structure\" class no longer\ncause infinite recursion when the structure is not an S4 object.\nnlm(f, ..) for the case where f() has a \"hessian\" attribute\nnow computes correctly. ().\nAn S4 method that “rematches” to its generic and overrides the\ndefault value of a generic formal argument to NULL no longer drops\nthe argument from its formals.\nRscript can now accept more than one argument given on the #!\nline of a script. Previously, one could only pass a single argument\non the #! line in Linux.\nConnections are now written correctly with encoding \"UTF-16LE\".\n().\nEvaluation of ..0 now signals an error. When ..1 is used and\n... is empty, the error message is more appropriate.\n(Windows mainly.) Unicode code points which require surrogate pairs\nin UTF-16 are now handled. All systems should properly handle\nsurrogate pairs, even those systems that do not need to make use of\nthem. ()\nstopifnot(e, e2, ...) now evaluates the expressions sequentially\nand in case of an error or warning shows the relevant expression\ninstead of the full stopifnot(..) call.\npath.expand() on Windows now accepts paths specified as\nUTF-8-encoded character strings even if not representable in the\ncurrent locale. ()\nline(x, y) now correctly computes the medians of the left and\nright group’s x-values and in all cases reproduces straight lines.\nExtending S4 classes with slots corresponding to special attributes\nlike dim and dimnames now works.\nFix for legend() when fill has multiple values the first of\nwhich is NA (all colours used to default to par(fg)). ()\ninstalled.packages() did not remove the cached value for a library\ntree that had been emptied (but would not use the old value, just\nwaste time checking it).\nThe documentation for installed.packages(noCache = TRUE)\nincorrectly claimed it would refresh the cache.\naggregate(<data.frame>) no longer uses spurious names in some\ncases. ()\nobject.size() now also works for long vectors.\npackageDescription() tries harder to solve re-encoding issues,\nnotably seen in some Windows locales. This fixes the citation()\nissue in .\npoly(<matrix>, 3) now works, thanks to prompting by Marc Schwartz.\nreadLines() no longer segfaults on very large files with embedded\n’0’ (aka ‘nul’) characters. ()\nns() (package splines) now also works for a single observation.\ninterpSpline() gives a more friendly error message when the number\nof points is less than four.\ndist(x, method = \"canberra\") now uses the correct definition; the\nresult may only differ when x contains values of differing signs,\ne.g. not for 0-1 data.\nmethods:::cbind() and methods:::rbind() avoid deep recursion,\nthanks to Suharto Anggono via .\nArithmetic with zero-column data frames now works more consistently;\nissue raised by Bill Dunlap.\nArithmetic with data frames gives a data frame for ^ (which\npreviously gave a numeric matrix).\npretty(x, n) for large n or large diff(range(x)) now works\nbetter (though it was never meant for large n); internally it uses\nthe same rounding fuzz (1e-10) as seq.default() — as it did up\nto 2010-02-03 when both were 1e-7.\nInternal C-level R_check_class_and_super() and hence\nR_check_class_etc() now also consider non-direct super classes and\nhence return a match in more cases. This e.g., fixes behaviour of\nderived classes in package .\nReverted unintended change in behavior of return calls in\non.exit expressions introduced by stack unwinding changes in R\n3.3.0.\nAttributes on symbols are now detected and prevented; attempt to add\nan attribute to a symbol results in an error.\nfisher.test(*, workspace = <n>) now may also increase the internal\nstack size which allows larger problem to be solved, fixing .\nThe methods package no longer directly copies slots (attributes)\ninto a prototype that is of an “abnormal” (reference) type, like a\nsymbol.\nThe methods package no longer attempts to call length<-() on\nNULL (during the bootstrap process).\nThe methods package correctly shows methods when there are\nmultiple methods with the same signature for the same generic (still\nnot fully supported, but at least the user can see them).\nsys.on.exit() is now always evaluated in the right frame. (From\nLionel Henry.)\nseq.POSIXt(*, by = \"<n> DSTdays\") now should work correctly in all\ncases and is faster. ()\n.C() when returning a logical vector now always maps values other\nthan FALSE and NA to TRUE (as documented).\nSubassignment with zero length vectors now coerces as documented\n().\nFurther, x <- numeric(); x[1] <- character() now signals an error\n‘replacement has length zero’ (or a translation of that) instead of\ndoing nothing.\n(Package parallel.) mclapply(), pvec() and mcparallel()\n(when mccollect() is used to collect results) no longer leave\nzombie processes behind.\nR CMD INSTALL <pkg> now produces the intended error message when,\ne.g., the LazyData field is invalid.\nas.matrix(dd) now works when the data frame dd contains a column\nwhich is a data frame or matrix, including a 0-column matrix/d.f. .\nmclapply(X, mc.cores) now follows its documentation and calls\nlapply() in case mc.cores = 1 also in the case mc.preschedule\nis false. ()\naggregate(<data.frame>, drop=FALSE) no longer calls the function\non <empty> parts but sets corresponding results to NA. (Thanks\nto Suharto Anggono’s patches in ).\nThe duplicated() method for data frames is now based on the list\nmethod (instead of string coercion). Consequently unique() is\nbetter distinguishing data frame rows, fixing and . The methods for\nmatrices and arrays are changed accordingly.\nCalling names() on an S4 object derived from \"environment\"\nbehaves (by default) like calling names() on an ordinary\nenvironment.\nread.table() with a non-default separator now supports quotes\nfollowing a non-whitespace character, matching the behavior of\nscan().\nparLapplyLB and parSapplyLB have been fixed to do load balancing\n(dynamic scheduling). This also means that results of computations\ndepending on random number generators will now really be\nnon-reproducible, as documented.\nIndexing a list using dollar and empty string (l$\"\") returns NULL.\nUsing usage{ data(<name>, package=\"<pkg>\") } no longer produces\nR CMD check warnings.\nmatch.arg() more carefully chooses the environment for\nconstructing default choices, fixing as proposed by Duncan\nMurdoch.\nDeparsing of consecutive ! calls is now consistent with deparsing\nunary - and + calls and creates code that can be reparsed\nexactly; thanks to a patch by Lionel Henry in . (As a side effect,\nthis uses fewer parentheses in some other deparsing involving !\ncalls.)\n\n\n\nCHANGES IN R 3.4.4\n\nNEW FEATURES\nSys.timezone() tries more heuristics on Unix-alikes and so is more\nlikely to succeed (especially on Linux). For the slowest method, a\nwarning is given recommending that TZ is set to avoid the search.\nThe version of LAPACK included in the sources has been updated to\n3.8.0 (for the routines used by R, a very minor bug-fix change).\nparallel::detectCores(logical = FALSE) is ignored on Linux\nsystems, since the information is not available with virtualized\nOSes.\n\n\nINSTALLATION on a UNIX-ALIKE\nconfigure will use pkg-config to find the flags to link to\njpeg if available (as it should be for the recently-released\njpeg-9c and libjpeg-turbo). (This amends the code added in R\n3.3.0 as the module name in jpeg-9c is not what that tested for.)\n\n\nDEPRECATED AND DEFUNCT\nSys.timezone(location = FALSE) (which was a stop-gap measure for\nWindows long ago) is deprecated. It no longer returns the value of\nenvironment variable TZ (usually a location).\nLegacy support of make macros such as CXX1X is formally\ndeprecated: use the CXX11 forms instead.\n\n\nBUG FIXES\npower.prop.test() now warns when it cannot solve the problem,\ntypically because of impossible constraints. ()\nremoveSource() no longer erroneously removes NULL in certain\ncases, thanks to Dénes Tóth.\nnls(‘NO [mol/l]‘ ~ f(t)) and nls(y ~ a) now work. (Partly from )\nR CMD build checks for GNU cp rather than assuming Linux has it.\n( says ‘Alpine Linux’ does not.)\nNon-UTF-8 multibyte character handling fixed more permanently ().\nsum(<large ints>, <stuff>) is more consistent. ()\nrf() and rbeta() now also work correctly when ncp is not\nscalar, notably when (partly) NA. ()\nis.na(NULL) no longer warns. ()\nR CMD INSTALL now correctly sets C++ compiler flags when all\nsource files are in sub-directories of src.\n\n\n\nCHANGES IN R 3.4.3\n\nINSTALLATION on a UNIX-ALIKE\nA workaround has been added for the changes in location of time-zone\nfiles in macOS 10.13 ‘High Sierra’ and again in 10.13.1, so the\ndefault time zone is deduced correctly from the system setting when\nR is configured with –with-internal-tzcode (the default on macOS).\nR CMD javareconf has been updated to recognize the use of a Java 9\nSDK on macOS.\n\n\nBUG FIXES\nraw(0) & raw(0) and raw(0) | raw(0) again return raw(0)\n(rather than logical(0)).\nintToUtf8() converts integers corresponding to surrogate code\npoints to NA rather than invalid UTF-8, as well as values larger\nthan the current Unicode maximum of 0x10FFFF. (This aligns with\nthe current RFC3629.)\nFix calling of methods on S4 generics that dispatch on ... when\nthe call contains ....\nFollowing Unicode ‘Corrigendum 9’, the UTF-8 representations of\nU+FFFE and U+FFFF are now regarded as valid by utf8ToInt().\nrange(c(TRUE, NA), finite = TRUE) and similar no longer return\nNA. (Reported by Lukas Stadler.)\nThe self starting function attr(SSlogis, \"initial\") now also works\nwhen the y values have exact minimum zero and is slightly changed in\ngeneral, behaving symmetrically in the y range.\nThe printing of named raw vectors is now formatted nicely as for\nother such atomic vectors, thanks to Lukas Stadler.\n\n\n\nCHANGES IN R 3.4.2\n\nNEW FEATURES\nSetting the LC_ALL category in Sys.setlocale() invalidates any\ncached locale-specific day/month names and the AM/PM indicator for\nstrptime() (as setting LC_TIME has since R 3.1.0).\nThe version of LAPACK included in the sources has been updated to\n3.7.1, a bug-fix release.\nThe default for tools::write_PACKAGES(rds_compress=) has been\nchanged to \"xz\" to match the compression used by CRAN.\nc() and unlist() are now more efficient in constructing the\nnames(.) of their return value, thanks to a proposal by Suharto\nAnggono. ()\n\n\nUTILITIES\nR CMD check checks for and R CMD build corrects CRLF line\nendings in shell scripts configure and cleanup (even on\nWindows).\n\n\nINSTALLATION on a UNIX-ALIKE\nThe order of selection of OpenMP flags has been changed: Oracle\nDeveloper Studio 12.5 accepts -fopenmp and -xopenmp but only the\nlatter enables OpenMP so it is now tried first.\n\n\nBUG FIXES\nwithin(List, rm(x1, x2)) works correctly again, including when\nList[[\"x2\"]] is NULL.\nregexec(pattern, text, *) now applies as.character(.) to its\nfirst two arguments, as documented.\nwrite.table() and related functions, writeLines(), and perhaps\nother functions writing text to connections did not signal errors\nwhen the writes failed, e.g. due to a disk being full. Errors will\nnow be signalled if detected during the write, warnings if detected\nwhen the connection is closed. ()\nrt() assumed the ncp parameter was a scalar. ()\nmenu(choices) with more than 10 choices which easily fit into one\ngetOption(\"width\")-line no longer erroneously repeats choices. ()\nlength()<- on a pairlist succeeds.\n(https://stat.ethz.ch/pipermail/r-devel/2017-July/074680.html)\nLanguage objects such as quote((\"n\")) or R functions are correctly\nprinted again, where R 3.4.1 accidentally duplicated the\nbackslashes.\nConstruction of names() for very large objects in c() and\nunlist() now works, thanks to Suharto Anggono’s patch proposals in\n.\nResource leaks (and similar) reported by Steve Grubb fixed. (, , , ,\n, )\nmodel.matrix(~1, mf) now gets the row names from mf also when\nthey differ from 1:nrow(mf), fixing thanks to the suggestion by\nSebastian Meyer.\nsigma(fm) now takes the correct denominator degrees of freedom for\na fitted model with NA coefficients. ()\nhist(x, \"FD\") no longer “dies” with a somewhat cryptic error\nmessage when x has extreme outliers or IQR() zero:\nnclass.FD(x) tries harder to find a robust bin width in the latter\ncase, and hist.default(*, breaks) now checks and corrects a too\nlarge breaks number. ()\ncallNextMethod() works for ... methods.\nqr.coef(qd, y) now has correct names also when qd is a complex\nQR or stems from qr(*, LAPACK=TRUE).\nSetting options(device = *) to an invalid function no longer\nsegfaults when plotting is initiated. ()\nencodeString(<very large string>) no longer segfaults. ()\nIt is again possible to use configure –enable-maintainer-mode\nwithout having installed notangle (it was required in R\n3.4.[01]).\nS4 method dispatch on ... calls the method by name instead of\n.Method (for consistency with default dispatch), and only attempts\nto pass non-missing arguments from the generic.\nreadRDS(textConnection(.)) works again. ()\n(1:n)[-n] no longer segfaults for n <- 2.2e9 (on a platform with\nenough RAM).\nx <- 1:2; tapply(x, list(x, x), function(x) \"\")[1,2] now correctly\nreturns NA. ()\nRunning of finalizers after explicit GC request moved from the R\ninterface do_gc to the C interface R_gc. This helps with\nreclaiming inaccessible connections.\nhelp.search(topic) and ??topic matching topics in vignettes with\nmultiple file name extensions (e.g., *.md.rsp but not *.Rmd)\nfailed with an error when using options(help_type = \"html\").\nThe X11 device no longer uses the Xlib backing store ().\narray(character(), 1) now gives (a 1D array with) NA as has been\ndocumented for a long time as in the other cases of zero-length\narray initialization and also compatibly with\nmatrix(character(), *). As mentioned there, this also fixes .\nsplineDesign(.., derivs = 4) no longer segfaults.\nfisher.test(*, hybrid=TRUE) now (again) will use the hybrid method\nwhen Cochran’s conditions are met, fixing .\n\n\n\nCHANGES IN R 3.4.1\n\nINSTALLATION on a UNIX-ALIKE\nThe deprecated support for PCRE versions older than 8.20 has been\nremoved.\n\n\nBUG FIXES\ngetParseData() gave incorrect column information when code\ncontained multi-byte characters. ()\nAsking for help using expressions like ?stats::cor() did not work.\n()\nreadRDS(url(....)) now works.\nR CMD Sweave again returns status = 0 on successful completion.\nVignettes listed in .Rbuildignore were not being ignored properly.\n()\nfile.mtime() no longer returns NA on Windows when the file or\ndirectory is being used by another process. This affected\ninstalled.packages(), which is now protected against this.\nR CMD INSTALL Windows .zip file obeys –lock and –pkglock\nflags.\n(Windows only) The choose.files() function could return incorrect\nresults when called with multi = FALSE. ()\naggregate(<data.frame>, drop = FALSE) now also works in case of\nnear-equal numbers in by. ()\nfourfoldplot() could encounter integer overflow when calculating\nthe odds ratio. ()\nparse() no longer gives spurious warnings when extracting srcrefs\nfrom a file not encoded in the current locale.\nThis was seen from R CMD check with inst/doc/*.R files, and\ncheck has some additional protection for such files.\nprint.noquote(x) now always returns its argument x (invisibly).\nNon-UTF-8 multibyte character sets were not handled properly in\nsource references. ()\n\n\n\nCHANGES IN R 3.4.0\n\nSIGNIFICANT USER-VISIBLE CHANGES\n(Unix-alike) The default methods for download.file() and url()\nnow choose \"libcurl\" except for file:// URLs. There will be\nsmall changes in the format and wording of messages, including in\nrare cases if an issue is a warning or an error. For example, when\nHTTP re-direction occurs, some messages refer to the final URL\nrather than the specified one.\nThose who use proxies should check that their settings are\ncompatible (see ?download.file: the most commonly used forms work\nfor both \"internal\" and \"libcurl\").\ntable() has been amended to be more internally consistent and\nbecome back compatible to R 2.7.2 again. Consequently,\ntable(1:2, exclude = NULL) no longer contains a zero count for\n<NA>, but useNA = \"always\" continues to do so.\nsummary.default() no longer rounds, but its print method does\nresulting in less extraneous rounding, notably of numbers in the ten\nthousands.\nfactor(x, exclude = L) behaves more rationally when x or L are\ncharacter vectors. Further, exclude = <factor> now behaves as\ndocumented for long.\nArithmetic, logic (&, |) and comparison (aka ‘relational’, e.g.,\n<, ==) operations with arrays now behave consistently, notably\nfor arrays of length zero.\nArithmetic between length-1 arrays and longer non-arrays had\nsilently dropped the array attributes and recycled. This now gives a\nwarning and will signal an error in the future, as it has always for\nlogic and comparison operations in these cases (e.g., compare\nmatrix(1,1) + 2:3 and matrix(1,1) < 2:3).\nThe JIT (‘Just In Time’) byte-code compiler is now enabled by\ndefault at its level 3. This means functions will be compiled on\nfirst or second use and top-level loops will be compiled and then\nrun. (Thanks to Tomas Kalibera for extensive work to make this\npossible.)\nFor now, the compiler will not compile code containing explicit\ncalls to browser(): this is to support single stepping from the\nbrowser() call.\nJIT compilation can be disabled for the rest of the session using\ncompiler::enableJIT(0) or by setting environment variable\nR_ENABLE_JIT to 0.\nxtabs() works more consistently with NAs, also in its result no\nlonger setting them to 0. Further, a new logical option addNA\nallows to count NAs where appropriate. Additionally, for the case\nsparse = TRUE, the result’s dimnames are identical to the\ndefault case’s.\nMatrix products now consistently bypass BLAS when the inputs have\nNaN/Inf values. Performance of the check of inputs has been\nimproved. Performance when BLAS is used is improved for\nmatrix/vector and vector/matrix multiplication (DGEMV is now used\ninstead of DGEMM).\nOne can now choose from alternative matrix product implementations\nvia options(matprod = ). The \"internal\" implementation is not\noptimized for speed but consistent in precision with other\nsummations in R (using long double accumulators where available).\n\"blas\" calls BLAS directly for best speed, but usually with\nundefined behavior for inputs with NaN/Inf.\n\n\nNEW FEATURES\nUser errors such as integrate(f, 0:1, 2) are now caught.\nAdd signature argument to debug(), debugonce(), undebug()\nand isdebugged() for more conveniently debugging S3 and S4\nmethods. (Based on a patch by Gabe Becker.)\nAdd utils::debugcall() and utils::undebugcall() for debugging\nthe function that would be called by evaluating the given\nexpression. When the call is to an S4 generic or standard S3\ngeneric, debugcall() debugs the method that would be dispatched. A\nnumber of internal utilities were added to support this, most\nnotably utils::isS3stdGeneric(). (Based on a patch by Gabe\nBecker.)\nAdd utils::strcapture(). Given a character vector and a regular\nexpression containing capture expressions, strcapture() will\nextract the captured tokens into a tabular data structure, typically\na data.frame.\nstr() and strOptions() get a new option drop.deparse.attr with\nimproved but changed default behaviour for expressions. For\nexpression objects x, str(x) now may remove extraneous white\nspace and truncate long lines.\nstr(<looooooooong_string>) is no longer very slow; inspired by\nMikko Korpela’s proposal in .\nstr(x)’s default method is more “accurate” and hence somewhat more\ngenerous in displaying character vectors; this will occasionally\nchange R outputs (and need changes to some *.Rout(.save) files).\nFor a classed integer vector such as x <- xtabs(~ c(1,9,9,9)),\nstr(x) now shows both the class and \"int\", instead of only the\nlatter.\nisSymmetric(m) is much faster for large asymmetric matrices m\nvia pre-tests and a new option tol1 (with which strict back\ncompatibility is possible but not the default).\nThe result of eigen() now is of class \"eigen\" in the default\ncase when eigenvectors are computed.\nZero-length date and date-time objects (of classes \"POSIX[cl]?t\")\nnow print() “recognizably”.\nxy.coords() and xyz.coords() get a new setLab option.\nThe method argument of sort.list(), order() and sort.int()\ngains an \"auto\" option (the default) which should behave the same\nas before when method was not supplied.\nstopifnot(E, ..) now reports differences when E is a call to\nall.equal() and that is not true.\nboxplot(<formula>, *) gain optional arguments drop, sep, and\nlex.order to pass to split.default() which itself gains an\nargument lex.order to pass to interaction() for more\nflexibility.\nThe plot() method for ppr() has enhanced default labels (xmin\nand main).\nsample.int() gains an explicit useHash option (with a back\ncompatible default).\nidentical() gains an ignore.srcref option which drops \"srcref\"\nand similar attributes when true (as by default).\ndiag(x, nrow = n) now preserves typeof(x), also for logical,\ninteger and raw x (and as previously for complex and numeric).\nsmooth.spline() now allows direct specification of lambda, gets\na hatvalues() method and keeps tol in the result, and optionally\nparts of the internal matrix computations.\naddNA() is faster now, e.g. when applied twice. (Part of .)\nNew option rstandard(<lm>, type = \"predicted\") provides the\n“PRESS”–related leave-one-out cross-validation errors for linear\nmodels.\nAfter seven years of deprecation, duplicated factor levels now\nproduce a warning when printed and an error in levels<- instead of\na warning.\nInvalid factors, e.g., with duplicated levels (invalid but\nconstructable) now give a warning when printed, via new function\n.valid.factor().\nsessionInfo() has been updated for Apple’s change in OS naming as\nfrom ‘10.12’ (‘macOS Sierra’ vs ‘OS X El Capitan’).\nIts toLatex() method now includes the running component.\noptions(interrupt=) can be used to specify a default action for\nuser interrupts. For now, if this option is not set and the error\noption is set, then an unhandled user interrupt invokes the error\noption. (This may be dropped in the future as interrupt conditions\nare not error conditions.)\nIn most cases user interrupt handlers will be called with a\n\"resume\" restart available. Handlers can invoke this restart to\nresume computation. At the browser prompt the r command will\ninvoke a \"resume\" restart if one is available. Some read\noperations cannot be resumed properly when interrupted and do not\nprovide a \"resume\" restart.\nRadix sort is now chosen by method = \"auto\" for sort.int() for\ndouble vectors (and hence used for sort() for unclassed double\nvectors), excluding ‘long’ vectors.\nsort.int(method = \"radix\") no longer rounds double vectors.\nThe default and data.frame methods for stack() preserve the\nnames of empty elements in the levels of the ind column of the\nreturn value. Set the new drop argument to TRUE for the previous\nbehavior.\nSpeedup in simplify2array() and hence sapply() and mapply()\n(for the case of names and common length > 1), thanks to Suharto\nAnggono’s .\ntable(x, exclude = NULL) now sets useNA = \"ifany\" (instead of\n\"always\"). Together with the bug fixes for this case, this\nrecovers more consistent behaviour compatible to older versions\nof R. As a consequence, summary() for a logical vector no longer\nreports (zero) counts for NA when there are no NAs.\ndump.frames() gets a new option include.GlobalEnv which allows\nto also dump the global environment, thanks to Andreas Kersting’s\nproposal in .\nsystem.time() now uses message() instead of cat() when\nterminated early, such that suppressMessages() has an effect;\nsuggested by Ben Bolker.\ncitation() supports inst/CITATION files from package source\ntrees, with lib.loc pointing to the directory containing the\npackage.\ntry() gains a new argument outFile with a default that can be\nmodified via options(try.outFile = .), useful notably for\nSweave.\nThe unexported low-level functions in package parallel for passing\nserialized R objects to and from forked children now support long\nvectors on 64-bit platforms. This removes some limits on\nhigher-level functions such as mclapply() (but returning gigabyte\nresults from forked processes via serialization should be avoided\nif at all possible).\nConnections now print() without error even if invalid, e.g. after\nhaving been destroyed.\napropos() and find(simple.words = FALSE) no longer match object\nnames starting with . which are known to be internal objects (such\nas .__S3MethodsTable__.).\nConvenience function hasName() has been added; it is intended to\nreplace the common idiom !is.null(x$name) without the usually\nunintended partial name matching.\nstrcapture() no longer fixes column names nor coerces strings to\nfactors (suggested by Bill Dunlap).\nstrcapture() returns NA for non-matching values in x\n(suggested by Bill Dunlap).\nsource() gets new optional arguments, notably exprs; this is\nmade use of in the new utility function withAutoprint().\nsys.source() gets a new toplevel.env argument. This argument is\nuseful for frameworks running package tests; contributed by Tomas\nKalibera.\nSys.setFileTime() and file.copy(copy.date = TRUE) will set\ntimestamps with fractions of seconds on platforms/filesystems which\nsupport this.\n(Windows only.) file.info() now returns file timestamps including\nfractions of seconds; it has done so on other platforms since R\n2.14.0. (NB: some filesystems do not record modification and access\ntimestamps to sub-second resolution.)\nThe license check enabled by options(checkPackageLicense = TRUE)\nis now done when the package’s namespace is first loaded.\nppr() and supsmu() get an optional trace argument, and\nppr(.., sm.method = ..spline) is no longer limited to sample size\n.\nThe POSIXct method for print() gets optional tz and usetz\narguments, thanks to a report from Jennifer S. Lyon.\nNew function check_packages_in_dir_details() in package tools\nfor analyzing package-check log files to obtain check details.\nPackage tools now exports function CRAN_package_db() for\nobtaining information about current packages in the CRAN package\nrepository, and several functions for obtaining the check status of\nthese packages.\nThe (default) Stangle driver Rtangle allows annotate to be a\nfunction and gets a new drop.evalFALSE option.\nThe default method for quantile(x, prob) should now be monotone in\nprob, even in border cases, see .\nbug.report() now tries to extract an email address from a\nBugReports field, and if there is none, from a Contacts field.\nThe format() and print() methods for object.size() results get\nnew options standard and digits; notably, standard = \"IEC\" and\nstandard = \"SI\" allow more standard (but less common)\nabbreviations than the default ones, e.g. for kilobytes. (From\ncontributions by Henrik Bengtsson.)\nIf a reference class has a validity method, validObject will be\ncalled automatically from the default initialization method for\nreference classes.\ntapply() gets new option default = NA allowing to change the\npreviously hardcoded value.\nread.dcf() now consistently interprets any ‘whitespace’ to be\nstripped to include newlines.\nThe maximum number of DLLs that can be loaded into R e.g. via\ndyn.load() can now be increased by setting the environment\nvariable R_MAX_NUM_DLLS before starting R.\nAssigning to an element of a vector beyond the current length now\nover-allocates by a small fraction. The new vector is marked\ninternally as growable, and the true length of the new vector is\nstored in the truelength field. This makes building up a vector\nresult by assigning to the next element beyond the current length\nmore efficient, though pre-allocating is still preferred. The\nimplementation is subject to change and not intended to be used in\npackages at this time.\nLoading the parallel package namespace no longer sets or changes\nthe .Random.seed, even if R_PARALLEL_PORT is unset.\nNB: This can break reproducibility of output, and did for a CRAN\npackage.\nMethods \"wget\" and \"curl\" for download.file() now give an R\nerror rather than a non-zero return value when the external command\nhas a non-zero status.\nEncoding name \"utf8\" is mapped to \"UTF-8\". Many implementations\nof iconv accept \"utf8\", but not GNU libiconv (including the\nlate 2016 version 1.15).\nsessionInfo() shows the full paths to the library or executable\nfiles providing the BLAS/LAPACK implementations currently in use\n(not available on Windows).\nThe binning algorithm used by bandwidth selectors bw.ucv(),\nbw.bcv() and bw.SJ() switches to a version linear in the input\nsize n for n > nb/2. (The calculations are the same, but for\nlarger n/nb it is worth doing the binning in advance.)\nThere is a new option PCRE_study which controls when\ngrep(perl = TRUE) and friends ‘study’ the compiled pattern.\nPreviously this was done for 11 or more input strings: it now\ndefaults to 10 or more (but most examples need many more for the\ndifference from studying to be noticeable).\ngrep(perl = TRUE) and friends can now make use of PCRE’s\nJust-In-Time mechanism, for PCRE 8.20 on platforms where JIT is\nsupported. It is used by default whenever the pattern is studied\n(see the previous item). (Based on a patch from Mikko Korpela.)\nThis is controlled by a new option PCRE_use_JIT.\nNote that in general this makes little difference to the speed, and\nmay take a little longer: its benefits are most evident on strings\nof thousands of characters. As a side effect it reduces the chances\nof C stack overflow in the PCRE library on very long strings\n(millions of characters, but see next item).\nWarning: segfaults were seen using PCRE with JIT enabled on 64-bit\nSparc builds.\nThere is a new option PCRE_limit_recursion for grep(perl = TRUE)\nand friends to set a recursion limit taking into account R’s\nestimate of the remaining C stack space (or 10000 if that is not\navailable). This reduces the chance of C stack overflow, but because\nit is conservative may report a non-match (with a warning) in\nexamples that matched before. By default it is enabled if any input\nstring has 1000 or more bytes. ()\ngetGraphicsEvent() now works on X11(type = \"cairo\") devices.\nThanks to Frederick Eaton (for reviving an earlier patch).\nThere is a new argument onIdle for getGraphicsEvent(), which\nallows an R function to be run whenever there are no pending\ngraphics events. This is currently only supported on X11 devices.\nThanks to Frederick Eaton.\nThe deriv() and similar functions now can compute derivatives of\nlog1p(), sinpi() and similar one-argument functions, thanks to a\ncontribution by Jerry Lewis.\nmedian() gains a formal ... argument, so methods with extra\narguments can be provided.\nstrwrap() reduces indent if it is more than half width rather\nthan giving an error. (Suggested by Bill Dunlap.)\nWhen the condition code in if(.) or while(.) is not of length\none, an error instead of a warning may be triggered by setting an\nenvironment variable, see the help page.\nFormatting and printing of bibliography entries (bibentry) is more\nflexible and better documented. Apart from setting\noptions(citation.bibtex.max = 99) you can also use\nprint(<citation>, bibtex=TRUE) (or format(..)) to get the BibTeX\nentries in the case of more than one entry. This also affects\ncitation(). Contributions to enable style = \"html+bibtex\" are\nwelcome.\n\n\nC-LEVEL FACILITIES\nEntry points R_MakeExternalPtrFn and R_ExternalPtrFn are now\ndeclared in header Rinternals.h to facilitate creating and\nretrieving an R external pointer from a C function pointer without\nISO C warnings about the conversion of function pointers.\nThere was an exception for the native Solaris C++ compiler to the\ndropping (in R 3.3.0) of legacy C++ headers from headers such as\nR.h and Rmath.h — this has now been removed. That compiler has\nstrict C++98 compliance hence does not include extensions in its\n(non-legacy) C++ headers: some packages will need to request C++11\nor replace non-C++98 calls such as lgamma: see §1.6.4 of ‘Writing\nR Extensions’.\nBecause it is needed by about 70 CRAN packages, headers R.h and\nRmath.h still declare\nstd;\nwhen included on Solaris.\nWhen included from C++, the R headers now use forms such as\nstd::FILE directly rather than including the line\nstd::FILE;\nC++ code including these headers might be relying on the latter.\nHeaders R_ext/BLAS.h and R_ext/Lapack.h have many improved\ndeclarations including const for double-precision complex\nroutines. Inter alia this avoids warnings when passing ‘string\nliteral’ arguments from C++11 code.\nHeaders for Unix-only facilities R_ext/GetX11Image.h,\nR_ext/QuartzDevice.h and R_ext/eventloop.h are no longer\ninstalled on Windows.\nNo-longer-installed headers GraphicsBase.h, RGraphics.h,\nRmodules/RX11.h and Rmodules/Rlapack.h which had a LGPL license\nno longer do so.\nHAVE_UINTPTR_T is now defined where appropriate by Rconfig.h so\nthat it can be included before Rinterface.h when CSTACK_DEFNS is\ndefined and a C compiler (not C++) is in use. Rinterface.h now\nincludes C header stdint.h or C++11 header cstdint where needed.\nPackage tools has a new function\npackage_native_routine_registration_skeleton() to assist adding\nnative-symbol registration to a package. See its help and §5.4.1 of\n‘Writing R Extensions’ for how to use it. (At the time it was added\nit successfully automated adding registration to over 90% of CRAN\npackages which lacked it. Many of the failures were newly-detected\nbugs in the packages, e.g. 50 packages called entry points with\nvarying numbers of arguments and 65 packages called entry points not\nin the package.)\n\n\nINSTALLATION on a UNIX-ALIKE\nreadline headers (and not just the library) are required unless\nconfiguring with –with-readline=no.\nconfigure now adds a compiler switch for C++11 code, even if the\ncompiler supports C++11 by default. (This ensures that g++ 6.x\nuses C++11 mode and not its default mode of C++14 with ‘GNU\nextensions’.)\nThe tests for C++11 compliance are now much more comprehensive. For\ngcc < 4.8, the tests from R 3.3.0 are used in order to maintain the\nsame behaviour on Linux distributions with long-term support.\nAn alternative compiler for C++11 is now specified with CXX11, not\nCXX1X. Likewise C++11 flags are specified with CXX11FLAGS and\nthe standard (e.g., -std=gnu++11) is specified with CXX11STD.\nconfigure now tests for a C++14-compliant compiler by testing some\nbasic features. This by default tries flags for the compiler\nspecified by CXX11, but an alternative compiler, options and\nstandard can be specified by variables CXX14, CXX14FLAGS and\nCXX14STD (e.g., -std=gnu++14).\nThere is a new macro CXXSTD to help specify the standard for C++\ncode, e.g. -std=c++98. This makes it easier to work with compilers\nwhich default to a later standard: for example, with\nCXX=g++6 CXXSTD=-std=c++98 configure will select commands for\ng++ 6.x which conform to C++11 and C++14 where specified but\notherwise use C++98.\nSupport for the defunct IRIX and OSF/1 OSes and Alpha CPU has been\nremoved.\nconfigure checks that the compiler specified by $CXX $CXXFLAGS\nis able to compile C++ code.\nconfigure checks for the required header sys/select.h (or\nsys/time.h on legacy systems) and system call select and aborts\nif they are not found.\nIf available, the POSIX 2008 system call utimensat will be used by\nSys.setFileTime() and file.copy(copy.date = TRUE). This may\nresult in slightly more accurate file times. (It is available on\nLinux and FreeBSD but not macOS.)\nThe minimum version requirement for libcurl has been reduced to\n7.22.0, although at least 7.28.0 is preferred and earlier versions\nare little tested. (This is to support Debian 7 ‘Wheezy’ LTS and\nUbuntu ‘Precise’ 12.04 LTS, although the latter is close to\nend-of-life.)\nconfigure tests for a C++17-compliant compiler. The tests are\nexperimental and subject to change in the future.\n\n\nINCLUDED SOFTWARE\n(Windows only) Tcl/Tk version 8.6.4 is now included in the binary\nbuilds. The tcltk*.chm help file is no longer included; please\nconsult the online help at http://www.tcl.tk/man/ instead.\nThe version of LAPACK included in the sources has been updated to\n3.7.0: no new routines have been added to R.\n\n\nPACKAGE INSTALLATION\nThere is support for compiling C++14 or C++17 code in packages on\nsuitable platforms: see ‘Writing R Extensions’ for how to request\nthis.\nThe order of flags when LinkingTo other packages has been changed\nso their include directories come earlier, before those specified in\nCPPFLAGS. This will only have an effect if non-system include\ndirectories are included with -I flags in CPPFLAGS (and so not\nthe default -I/usr/local/include which is treated as a system\ninclude directory on most platforms).\nPackages which register native routines for .C or .Fortran need\nto be re-installed for this version (unless installed with R-devel\nSVN revision r72375 or later).\nMake variables with names containing CXX1X are deprecated in\nfavour of those using CXX11, but for the time being are still made\navailable via file etc/Makeconf. Packages using them should be\nconverted to the new forms and made dependent on R (>= 3.4.0).\n\n\nUTILITIES\nRunning R CMD check –as-cran with _R_CHECK_CRAN_INCOMING_REMOTE_\nfalse now skips tests that require remote access. The remaining\n(local) tests typically run quickly compared to the remote tests.\nR CMD build will now give priority to vignettes produced from\nfiles in the vignettes directory over those in the inst/doc\ndirectory, with a warning that the latter are being ignored.\nR CMD config gains a –all option for printing names and values\nof all basic configure variables.\nIt now knows about all the variables used for the C++98, C++11 and\nC++14 standards.\nR CMD check now checks that output files in inst/doc are newer\nthan the source files in vignettes.\nFor consistency with other package subdirectories, files named *.r\nin the tests directory are now recognized as tests by\nR CMD check. (Wish of .)\nR CMD build and R CMD check now use the union of R_LIBS and\n.libPaths(). They may not be equivalent, e.g., when the latter is\ndetermined by R_PROFILE.\nR CMD build now preserves dates when it copies files in preparing\nthe tarball. (Previously on Windows it changed the dates on all\nfiles; on Unix, it changed some dates when installing vignettes.)\nThe new option R CMD check –no-stop-on-test-error allows running\nthe remaining tests (under tests/) even if one gave an error.\nCheck customization via environment variables to detect side\neffects of .Call() and .External() calls which alter their\narguments is described in §8 of the ‘R Internals’ manual.\nR CMD check now checks any BugReports field to be non-empty and\na suitable single URL.\nR CMD check –as-cran now NOTEs if the package does not register\nits native routines or does not declare its intentions on (native)\nsymbol search. (This will become a WARNING in due course.)\n\n\nDEPRECATED AND DEFUNCT\n(Windows only) Function setInternet2() is defunct.\nInstallation support for readline emulations based on editline\n(aka libedit) is deprecated.\nUse of the C/C++ macro NO_C_HEADERS is defunct and silently\nignored.\nunix.time(), a traditional synonym for system.time(), has been\ndeprecated.\nstructure(NULL, ..) is now deprecated as you cannot set attributes\non .\nHeader Rconfig.h no longer defines SUPPORT_OPENMP; instead use\n_OPENMP (as documented for a long time).\n(C-level Native routine registration.) The deprecated styles\nmember of the R_CMethodDef and R_FortranMethodDef structures has\nbeen removed. Packages using these will need to be re-installed for\nR 3.4.0.\nThe deprecated support for PCRE versions older than 8.20 will be\nremoved in R 3.4.1. (Versions 8.20–8.31 will still be accepted but\nremain deprecated.)\n\n\nBUG FIXES\nGetting or setting body() or formals() on non-functions for now\nsignals a warning and may become an error for setting.\nmatch(x, t), duplicated(x) and unique(x) work as documented\nfor complex numbers with NAs or NaNs, where all those containing\nNA do match, whereas in the case of NaN’s both real and\nimaginary parts must match, compatibly with how print() and\nformat() work for complex numbers.\ndeparse(<complex>, options = \"digits17\") prints more nicely now,\nmostly thanks to a suggestion by Richie Cotton.\nRotated symbols in plotmath expressions are now positioned correctly\non x11(type = \"Xlib\"). ()\nas<-() avoids an infinite loop when a virtual class is interposed\nbetween a subclass and an actual superclass.\nFix level propagation in unlist() when the list contains\nzero-length lists or factors.\nFix S3 dispatch on S4 objects when the methods package is not\nattached.\nInternal S4 dispatch sets .Generic in the method frame for\nconsistency with standardGeneric(). ()\nFix order(x, decreasing = TRUE) when x is an integer vector\ncontaining MAX_INT. Ported from a fix Matt Dowle made to .\nFix caching by callNextMethod(), resolves and .\ngrouping() puts NAs last, to be consistent with the default\nbehavior of order().\nPoint mass limit cases: qpois(-2, 0) now gives NaN with a\nwarning and qgeom(1, 1) is 0. ()\ntable() no longer drops an \"NaN\" factor level, and better obeys\nexclude = <chr>, thanks to Suharto Anggono’s patch for . Also, in\nthe case of exclude = NULL and NAs, these are tabulated\ncorrectly (again).\nFurther, table(1:2, exclude = 1, useNA = \"ifany\") no longer\nerroneously reports <NA> counts.\nAdditionally, all cases of empty exclude are equivalent, and\nuseNA is not overwritten when specified (as it was by\nexclude = NULL).\nwilcox.test(x, conf.int=TRUE) no longer errors out in cases where\nthe confidence interval is not available, such as for x = 0:2.\ndroplevels(f) now keeps <NA> levels when present.\nIn integer arithmetic, NULL is now treated as integer(0) whereas\nit was previously treated as double(0).\nThe radix sort considers NA_real_ and NaN to be equivalent in\nrank (like the other sort algorithms).\nWhen index.return=TRUE is passed to sort.int(), the radix sort\ntreats NAs like sort.list() does (like the other sort\nalgorithms).\nWhen in tabulate(bin, nbin) length(bin) is larger than the\nmaximal integer, the result is now of type double and hence no\nlonger silently overflows to wrong values. ()\nas.character.factor() respects S4 inheritance when checking the\ntype of its argument. ()\nThe factor method for print() no longer sets the class of the\nfactor to NULL, which would violate a basic constraint of an S4\nobject.\nformatC(x, flag = f) allows two new flags, and signals an error\nfor invalid flags also in the case of character formatting.\nReading from file(\"stdin\") now also closes the connection and\nhence no longer leaks memory when reading from a full pipe, thanks\nto Gábor Csárdi, see thread starting at\nhttps://stat.ethz.ch/pipermail/r-devel/2016-November/073360.html.\nFailure to create file in tempdir() for compressed pdf()\ngraphics device no longer errors (then later segfaults). There is\nnow a warning instead of error and compression is turned off for the\ndevice. Thanks to Alec Wysoker ().\nAsking for methods() on \"|\" returns only S3 methods. See\nhttps://stat.ethz.ch/pipermail/r-devel/2016-December/073476.html.\ndev.capture() using Quartz Cocoa device (macOS) returned invalid\ncomponents if the back-end chose to use ARGB instead of RGBA image\nformat. (Reported by Noam Ross.)\nseq(\"2\", \"5\") now works too, equivalently to \"2\":\"5\" and\nseq.int().\nseq.int(to = 1, by = 1) is now correct, other cases are integer\n(instead of double) when seq() is integer too, and the\n\"non-finite\" error messages are consistent between seq.default()\nand seq.int(), no longer mentioning NaN etc.\nrep(x, times) and rep.int(x, times) now work when times is\nlarger than the largest value representable in an integer vector. ()\ndownload.file(method = \"libcurl\") does not check for URL existence\nbefore attempting downloads; this is more robust to servers that do\nnot support HEAD or range-based retrieval, but may create empty or\nincomplete files for aborted download requests.\nBandwidth selectors bw.ucv(), bw.bcv() and bw.SJ() now avoid\ninteger overflow for large sample sizes.\nstr() no longer shows \"list output truncated\", in cases that\nlist was not shown at all. Thanks to Neal Fultz ()\nFix for cairo_pdf() (and svg() and cairo_ps()) when replaying\na saved display list that contains a mix of grid and graphics\noutput. (Report by Yihui Xie.)\nThe str() and as.hclust() methods for \"dendrogram\" now also\nwork for deeply nested dendrograms thanks to non-recursive\nimplementations by Bradley Broom.\nsample() now uses two uniforms for added precision when the\nuniform generator is Knuth-TAOCP, Knuth-TAOCP-2002, or a\nuser-defined generator and the population size is or greater.\nIf a vignette in the vignettes directory is listed in\n.Rbuildignore, R CMD build would not include it in the tarball,\nbut would include it in the vignette database, leading to a check\nwarning. ()\ntools::latexToUtf8() infinite looped on certain inputs. ()\nterms.formula() ignored argument names when determining whether\ntwo terms were identical. ()\ncallNextMethod() was broken when called from a method that\naugments the formal arguments of a primitive generic.\nCoercion of an S4 object to a vector during sub-assignment into a\nvector failed to dispatch through the as.vector() generic (often\nleading to a segfault).\nFix problems in command completion: Crash () and junk display in\nWindows, handling special characters in filenames on all systems.\n\n\n\nCHANGES IN R 3.3.3\n\nNEW FEATURES\nChanges when redirection of a http:// URL to a https:// URL is\nencountered:\nThe internal methods of download.file() and url() now report\nthat they cannot follow this (rather than failing silently).\n(Unix-alike) download.file(method = \"auto\") (the default)\nre-tries with method = \"libcurl\".\n(Unix-alike) url(method = \"default\") with an explicit open\nargument re-tries with method = \"libcurl\". This covers many of\nthe usages, e.g. readLines() with a URL argument.\n\n\n\nINSTALLATION on a UNIX-ALIKE\nThe configure check for the zlib version is now robust to\nversions longer than 5 characters, including 1.2.11.\n\n\nUTILITIES\nEnvironmental variable _R_CHECK_TESTS_NLINES_ controls how\nR CMD check reports failing tests (see §8 of the ‘R Internals’\nmanual).\n\n\nDEPRECATED AND DEFUNCT\n(C-level Native routine registration.) The undocumented styles\nfield of the components of R_CMethodDef and R_FortranMethodDef\nis deprecated.\n\n\nBUG FIXES\nvapply(x, *) now works with long vectors x. ()\nisS3method(\"is.na.data.frame\") and similar are correct now. ()\ngrepRaw(<long>, <short>, fixed = TRUE) now works, thanks to a\npatch by Mikko Korpela. ()\nPackage installation into a library where the package exists via\nsymbolic link now should work wherever Sys.readlink() works,\nresolving .\n\"Cincinnati\" was missing an \"n\" in the precip dataset.\nFix buffer overflow vulnerability in pdf() when loading an\nencoding file. Reported by Talos (TALOS-2016-0227).\ngetDLLRegisteredRoutines() now produces its warning correctly when\nmultiple DLLs match, thanks to Matt Dowle’s .\nSys.timezone() now returns non-NA also on platforms such as\nUbuntu 14.04.5 LTS, thanks to Mikko Korpela’s .\nformat(x) for an illegal \"POSIXlt\" object x no longer\nsegfaults.\nmethods(f) now also works for f \"(\" or \"{\".\n(Windows only) dir.create() did not check the length of the path\nto create, and so could overflow a buffer and crash R. ()\nOn some systems, very small hexadecimal numbers in hex notation\nwould underflow to zero. ()\npmin() and pmax() now work again for ordered factors and\n0-length S3 classed objects, thanks to Suharto Anggono’s and .\nbug.report() did not do any validity checking on a package’s\nBugReports field. It now ignores an empty field, removes leading\nwhitespace and only attempts to open http:// and https:// URLs,\nfalling back to emailing the maintainer.\nBandwidth selectors bw.ucv() and bw.SJ() gave incorrect answers\nor incorrectly reported an error (because of integer overflow) for\ninputs longer than 46341. Similarly for bw.bcv() at length 5793.\nAnother possible integer overflow is checked and may result in an\nerror report (rather than an incorrect result) for much longer\ninputs (millions for a smooth distribution).\nfindMethod() failed if the active signature had expanded beyond\nwhat a particular package used. (Example with packages and on CRAN.)\nqbeta() underflowed too early in some very asymmetric cases. ()\nR CMD Rd2pdf had problems with packages with non-ASCII titles in\n.Rd files (usually the titles were omitted).\n\n\n\nCHANGES IN R 3.3.2\n\nNEW FEATURES\nextSoftVersion() now reports the version (if any) of the\nreadline library in use.\nThe version of LAPACK included in the sources has been updated to\n3.6.1, a bug-fix release including a speedup for the non-symmetric\ncase of eigen().\nUse options(deparse.max.lines=) to limit the number of lines\nrecorded in .Traceback and other deparsing activities.\nformat(<AsIs>) looks more regular, also for non-character atomic\nmatrices.\nabbreviate() gains an option named = TRUE.\nThe online documentation for package methods is extensively\nrewritten. The goals are to simplify documentation for basic use, to\nnote old features not recommended and to correct out-of-date\ninformation.\nCalls to setMethod() no longer print a message when creating a\ngeneric function in those cases where that is natural: S3 generics\nand primitives.\n\n\nINSTALLATION and INCLUDED SOFTWARE\nVersions of the readline library >= 6.3 had been changed so that\nterminal window resizes were not signalled to readline: code has\nbeen added using a explicit signal handler to work around that (when\nR is compiled against readline >= 6.3). ()\nconfigure works better with Oracle Developer Studio 12.5.\n\n\nUTILITIES\nR CMD check reports more dubious flags in files\nsrc/Makevars[.in], including -w and -g.\nR CMD check has been set up to filter important warnings from\nrecent versions of gfortran with -Wall -pedantic: this now\nreports non-portable GNU extensions such as out-of-order\ndeclarations.\nR CMD config works better with paths containing spaces, even those\nof home directories (as reported by Ken Beath).\n\n\nDEPRECATED AND DEFUNCT\nUse of the C/C++ macro NO_C_HEADERS is deprecated (no C headers\nare included by R headers from C++ as from R 3.3.0, so it should no\nlonger be needed).\n\n\nBUG FIXES\nThe check for non-portable flags in R CMD check could be stymied\nby src/Makevars files which contained targets.\n(Windows only) When using certain desktop themes in Windows 7 or\nhigher, could cause Rterm to stop accepting input. (; patch\nsubmitted by Jan Gleixner.)\npretty(d, ..) behaves better for date-time d ().\nWhen an S4 class name matches multiple classes in the S4 cache,\nperform a dynamic search in order to obey namespace imports. This\nshould eliminate annoying messages about multiple hits in the class\ncache. Also, pass along the package from the ClassExtends object\nwhen looking up superclasses in the cache.\nsample(NA_real_) now works.\nPackages using non-ASCII encodings in their code did not install\ndata properly on systems using different encodings.\nmerge(df1, df2) now also works for data frames with column names\n\"na.last\", \"decreasing\", or \"method\". ()\ncontour() caused a segfault if the labels argument had length\nzero. (Reported by Bill Dunlap.)\nunique(warnings()) works more correctly, thanks to a new\nduplicated.warnings() method.\nfindInterval(x, vec = numeric(), all.inside = TRUE) now returns\n0s as documented. (Reported by Bill Dunlap.)\n(Windows only) R CMD SHLIB failed when a symbol in the resulting\nlibrary had the same name as a keyword in the .def file. ()\npmax() and pmin() now work with (more ?) classed objects, such\nas \"Matrix\" from the package, as documented for a long time.\naxis(side, x = D) and hence Axis() and plot() now work\ncorrectly for \"Date\" and time objects D, even when “time goes\nbackward”, e.g., with decreasing xlim. (Reported by William May.)\nstr(I(matrix(..))) now looks as always intended.\nplot.ts(), the plot() method for time series, now respects\ncex, lwd and lty. (Reported by Greg Werbin.)\nparallel::mccollect() now returns a named list (as documented)\nwhen called with wait = FALSE. (Reported by Michel Lang.)\nIf a package added a class to a class union in another package,\nloading the first package gave erroneous warnings about “undefined\nsubclass”.\nc()’s argument use.names is documented now, as belonging to the\n(C internal) default method. In “parallel”, argument recursive is\nalso moved from the generic to the default method, such that the\nformal argument list of base generic c() is just (...).\nrbeta(4, NA) and similarly rgamma() and rnbinom() now return\nNaN’s with a warning, as other r<dist>(), and as documented. ()\nUsing options(checkPackageLicense = TRUE) no longer requires\nacceptance of the licence for non-default standard packages such as\ncompiler. (Reported by Mikko Korpela.)\nsplit(<very_long>, *) now works even when the split off parts are\nlong. ()\nmin() and max() now also work correctly when the argument list\nstarts with character(0). ()\nSubsetting very large matrices (prod(dim(.)) >= 2^31) now works\nthanks to Michael Schubmehl’s .\nbartlett.test() used residual sums of squares instead of\nvariances, when the argument was a list of lm objects. (Reported\nby Jens Ledet Jensen).\nplot(<lm>, which = *) now correctly labels the contour lines for\nthe standardized residuals for which = 6. It also takes the\ncorrect in case of singularities (also for which = 5). ()\nxtabs(~ exclude) no longer fails from wrong scope, thanks to\nSuharto Anggono’s .\nReference class calls to methods() did not re-analyse previously\ndefined methods, meaning that calls to methods defined later would\nfail. (Reported by Charles Tilford).\nfindInterval(x, vec, left.open = TRUE) misbehaved in some cases.\n(Reported by Dmitriy Chernykh.)\n\n\n\nCHANGES IN R 3.3.1\n\nBUG FIXES\nR CMD INSTALL and hence install.packages() gave an internal\nerror installing a package called description from a tarball on a\ncase-insensitive file system.\nmatch(x, t) (and hence x %in% t) failed when x was of length\none, and either character and x and t only differed in their\nEncoding or when x and t where complex with NAs or NaNs.\n(.)\nunloadNamespace(ns) also works again when ns is a ‘namespace’,\nas from getNamespace().\nrgamma(1, Inf) or rgamma(1, 0, 0) no longer give NaN but the\ncorrect limit.\nlength(baseenv()) is correct now.\npretty(d, ..) for date-time d rarely failed when \"halfmonth\"\ntime steps were tried () and on ‘inaccurate’ platforms such as\n32-bit Windows or a configuration with –disable-long-double; see\ncomment #15 of .\nIn text.default(x, y, labels), the rarely(?) used default for\nlabels is now correct also for the case of a 2-column matrix x\nand missing y.\nas.factor(c(a = 1L)) preserves names() again as in R < 3.1.0.\nstrtrim(\"\"[0], 0[0]) now works.\nUse of Ctrl-C to terminate a reverse incremental search started by\nCtrl-R in the readline-based Unix terminal interface is now\nsupported when R was compiled against readline >= 6.0 (Ctrl-G\nalways worked). ()\ndiff(<difftime>) now keeps the \"units\" attribute, as subtraction\nalready did, .\n\n\n\nCHANGES IN R 3.3.0\n\nSIGNIFICANT USER-VISIBLE CHANGES\nnchar(x, *)’s argument keepNA governing how the result for NAs\nin x is determined, gets a new default keepNA = NA which returns\nNA where x is NA, except for type = \"width\" which still\nreturns 2, the formatting / printing width of NA.\nAll builds have support for https: URLs in the default methods for\ndownload.file(), url() and code making use of them.\nUnfortunately that cannot guarantee that any particular https: URL\ncan be accessed. For example, server and client have to successfully\nnegotiate a cryptographic protocol (TLS/SSL, …) and the server’s\nidentity has to be verifiable via the available certificates.\nDifferent access methods may allow different protocols or use\nprivate certificate bundles: we encountered a https: CRAN mirror\nwhich could be accessed by one browser but not by another nor by\ndownload.file() on the same Linux machine.\n\n\nNEW FEATURES\nThe print method for methods() gains a byclass argument.\nNew functions validEnc() and validUTF8() to give access to the\nvalidity checks for inputs used by grep() and friends.\nExperimental new functionality for S3 method checking, notably\nisS3method().\nAlso, the names of the R ‘language elements’ are exported as\ncharacter vector tools::langElts.\nstr(x) now displays \"Time-Series\" also for matrix (multivariate)\ntime-series, i.e. when is.ts(x) is true.\n(Windows only) The GUI menu item to install local packages now\naccepts *.tar.gz files as well as *.zip files (but defaults to\nthe latter).\nNew programmeR’s utility function chkDots().\nD() now signals an error when given invalid input, rather than\nsilently returning NA. (Request of John Nash.)\nformula objects are slightly more “first class”: e.g., formula()\nor new(\"formula\", y ~ x) are now valid. Similarly, for \"table\",\n\"ordered\" and \"summary.table\". Packages defining S4 classes with\nthe above S3/S4 classes as slots should be reinstalled.\nNew function strrep() for repeating the elements of a character\nvector.\nrapply() preserves attributes on the list when how = \"replace\".\nNew S3 generic function sigma() with methods for extracting the\nestimated standard deviation aka “residual standard deviation” from\na fitted model.\nnews() now displays R and package news files within the HTML help\nsystem if it is available. If no news file is found, a visible\nNULL is returned to the console.\nas.raster(x) now also accepts raw arrays x assuming values in\n0:255.\nSubscripting of matrix/array objects of type \"expression\" is now\nsupported.\ntype.convert(\"i\") now returns a factor instead of a complex value\nwith zero real part and missing imaginary part.\nGraphics devices cairo_pdf() and cairo_ps() now allow\nnon-default values of the cairographics ‘fallback resolution’ to be\nset.\nThis now defaults to 300 on all platforms: that is the default\ndocumented by cairographics, but apparently was not used by all\nsystem installations.\nfile() gains an explicit method argument rather than implicitly\nusing getOption(\"url.method\", \"default\").\nThanks to a patch from Tomas Kalibera, x[x != 0] is now typically\nfaster than x[which(x != 0)] (in the case where x has no NAs,\nthe two are equivalent).\nread.table() now always uses the names for a named colClasses\nargument (previously names were only used when colClasses was too\nshort). (In part, wish of .)\n(Windows only) download.file() with default method = \"auto\" and\na ftps:// URL chooses \"libcurl\" if that is available.\nThe out-of-the box Bioconductor mirror has been changed to one using\nhttps://: use chooseBioCmirror() to choose a http:// mirror if\nrequired.\nThe data frame and formula methods for aggregate() gain a drop\nargument.\navailable.packages() gains a repos argument.\nThe undocumented switching of methods for url() on https: and\nftps: URLs is confined to method = \"default\" (and documented).\nsmoothScatter() gains a ret.selection argument.\nqr() no longer has a ... argument to pass additional arguments\nto methods.\n[ has a method for class \"table\".\nIt is now possible (again) to replayPlot() a display list snapshot\nthat was created by recordPlot() in a different R session.\nIt is still not a good idea to use snapshots as a persistent storage\nformat for R plots, but it is now not completely silly to use a\nsnapshot as a format for transferring an R plot between two R\nsessions.\nThe underlying changes mean that packages providing graphics devices\n(e.g., , , , ) will need to be reinstalled.\nCode for restoring snapshots was contributed by Jeroen Ooms and JJ\nAllaire.\nSome testing code is available at\nhttps://github.com/pmur002/R-display-list.\ntools::undoc(dir = D) and codoc(dir = D) now also work when D\nis a directory whose normalizePath()ed version does not end in the\npackage name, e.g. from a symlink.\nabbreviate() has more support for multi-byte character sets – it\nno longer removes bytes within characters and knows about Latin\nvowels with accents. It is still only really suitable for (most)\nEuropean languages, and still warns on non-ASCII input.\nabbreviate(use.classes = FALSE) is now implemented, and that is\nmore suitable for non-European languages.\nmatch(x, table) is faster (sometimes by an order of magnitude)\nwhen x is of length one and incomparables is unchanged, thanks\nto Peter Haverty ().\nMore consistent, partly not back-compatible behavior of NA and\nNaN coercion to complex numbers, operations less often resulting\nin complex NA (NA_complex_).\nlengths() considers methods for length and [[ on x, so it\nshould work automatically on any objects for which appropriate\nmethods on those generics are defined.\nThe logic for selecting the default screen device on OS X has been\nsimplified: it is now quartz() if that is available even if\nenvironment variable DISPLAY has been set by the user.\nThe choice can easily be overridden via environment variable\nR_INTERACTIVE_DEVICE.\nOn Unix-like platforms which support the getline C library\nfunction, system(*, intern = TRUE) no longer truncates (output)\nlines longer than 8192 characters, thanks to Karl Millar. ()\nrank() gains a ties.method = \"last\" option, for convenience (and\nsymmetry).\nregmatches(invert = NA) can now be used to extract both\nnon-matched and matched substrings.\ndata.frame() gains argument fix.empty.names;\nas.data.frame.list() gets new cut.names, col.names and\nfix.empty.names.\nplot(x ~ x, *) now warns that it is the same as plot(x ~ 1, *).\nrecordPlot() has new arguments load and attach to allow\npackage names to be stored as part of a recorded plot.\nreplayPlot() has new argument reloadPkgs to load/attach any\npackage names that were stored as part of a recorded plot.\nS4 dispatch works within calls to .Internal(). This means explicit\nS4 generics are no longer needed for unlist() and as.vector().\nOnly font family names starting with \"Hershey\" (and not \"Her\" as\nbefore) are given special treatment by the graphics engine.\nS4 values are automatically coerced to vector (via as.vector)\nwhen subassigned into atomic vectors.\nfindInterval() gets a left.open option.\nThe version of LAPACK included in the sources has been updated to\n3.6.0, including those ‘deprecated’ routines which were previously\nincluded. Ca 40 double-complex routines have been added at the\nrequest of a package maintainer.\nAs before, the details of what is included are in\nsrc/modules/lapack/README and this now gives information on\nearlier additions.\ntapply() has been made considerably more efficient without\nchanging functionality, thanks to proposals from Peter Haverty and\nSuharto Anggono. ()\nmatch.arg(arg) (the one-argument case) is faster; so is\nsort.int(). ()\nThe format method for object_size objects now also accepts\n“binary” units such as \"KiB\" and e.g., \"Tb\". (Partly from .)\nProfiling now records calls of the form foo::bar and some similar\ncases directly rather than as calls to <Anonymous>. Contributed by\nWinston Chang.\nNew string utilities startsWith(x, prefix) and\nendsWith(x, suffix). Also provide speedups for some\ngrepl(\"^...\", *) uses (related to proposals in ).\nReference class finalizers run at exit, as well as on garbage\ncollection.\nAvoid parallel dependency on stats for port choice and random\nnumber seeds. ()\nThe radix sort algorithm and implementation from (forder) replaces\nthe previous radix (counting) sort and adds a new method for\norder(). Contributed by Matt Dowle and Arun Srinivasan, the new\nalgorithm supports logical, integer (even with large values), real,\nand character vectors. It outperforms all other methods, but there\nare some caveats (see ?sort).\nThe order() function gains a method argument for choosing\nbetween \"shell\" and \"radix\".\nNew function grouping() returns a permutation that stably\nrearranges data so that identical values are adjacent. The return\nvalue includes extra partitioning information on the groups. The\nimplementation came included with the new radix sort.\nrhyper(nn, m, n, k) no longer returns NA when one of the three\nparameters exceeds the maximal integer.\nswitch() now warns when no alternatives are provided.\nparallel::detectCores() now has default logical = TRUE on all\nplatforms – as this was the default on Windows, this change only\naffects Sparc Solaris.\nOption logical = FALSE is now supported on Linux and recent\nversions of OS X (for the latter, thanks to a suggestion of Kyaw\nSint).\nhist() for \"Date\" or \"POSIXt\" objects would sometimes give\nmisleading labels on the breaks, as they were set to the day before\nthe start of the period being displayed. The display format has been\nchanged, and the shift of the start day has been made conditional on\nright = TRUE (the default). ()\nR now uses a new version of the logo (donated to the R Foundation by\nRStudio). It is defined in .svg format, so will resize without\nunnecessary degradation when displayed on HTML pages—there is also\na vector PDF version. Thanks to Dirk Eddelbuettel for producing the\ncorresponding X11 icon.\nNew function .traceback() returns the stack trace which\ntraceback() prints.\nlengths() dispatches internally.\ndotchart() gains a pt.cex argument to control the size of points\nseparately from the size of plot labels. Thanks to Michael Friendly\nand Milan Bouchet-Valat for ideas and patches.\nas.roman(ch) now correctly deals with more diverse character\nvectors ch; also arithmetic with the resulting roman numbers works\nin more cases. ()\nprcomp() gains a new option rank. allowing to directly aim for\nless than min(n,p) PC’s. The summary() and its print() method\nhave been amended, notably for this case.\ngzcon() gains a new option text, which marks the connection as\ntext-oriented (so e.g. pushBack() works). It is still always\nopened in binary mode.\nThe import() namespace directive now accepts an argument except\nwhich names symbols to exclude from the imports. The except\nexpression should evaluate to a character vector (after substituting\nsymbols for strings). See Writing R Extensions.\nNew convenience function Rcmd() in package tools for invoking\nR CMD tools from within R.\nNew functions makevars_user() and makevars_site() in package\ntools to determine the location of the user and site specific\nMakevars files for customizing package compilation.\n\n\nUTILITIES\nR CMD check has a new option –ignore-vignettes for use with\nnon-Sweave vignettes whose VignetteBuilder package is not\navailable.\nR CMD check now by default checks code usage (via ) with only\nthe base package attached. Functions from default packages other\nthan base which are used in the package code but not imported are\nreported as undefined globals, with a suggested addition to the\nNAMESPACE file.\nR CMD check –as-cran now also checks DOIs in package CITATION\nand Rd files.\nR CMD Rdconv and R CMD Rd2pdf each have a new option\n–RdMacros=pkglist which allows Rd macros to be specified before\nprocessing.\n\n\nDEPRECATED AND DEFUNCT\nThe previously included versions of zlib, bzip2, xz and PCRE\nhave been removed, so suitable external (usually system) versions\nare required (see the ‘R Installation and Administration’ manual).\nThe unexported and undocumented Windows-only devices cairo_bmp(),\ncairo_png() and cairo_tiff() have been removed. (These devices\nshould be used as e.g. bmp(type = \"cairo\").)\n(Windows only) Function setInternet2() has no effect and will be\nremoved in due course. The choice between methods \"internal\" and\n\"wininet\" is now made by the method arguments of url() and\ndownload.file() and their defaults can be set via options. The\nout-of-the-box default remains \"wininet\" (as it has been since R\n3.2.2).\n[<- with an S4 value into a list currently embeds the S4 object\ninto its own list such that the end result is roughly equivalent to\nusing [[<-. That behavior is deprecated. In the future, the S4\nvalue will be coerced to a list with as.list().\nPackage tools’ functions package.dependencies(), pkgDepends(),\netc are deprecated now, mostly in favor of package_dependencies()\nwhich is both more flexible and efficient.\n\n\nINSTALLATION and INCLUDED SOFTWARE\nSupport for very old versions of valgrind (e.g., 3.3.0) has been\nremoved.\nThe included libtool script (generated by configure) has been\nupdated to version 2.4.6 (from 2.2.6a).\nlibcurl version 7.28.0 or later with support for the https\nprotocol is required for installation (except on Windows).\nBSD networking is now required (except on Windows) and so\ncapabilities(\"http/ftp\") is always true.\nconfigure uses pkg-config for PNG, TIFF and JPEG where this is\navailable. This should work better with multiple installs and with\nthose using static libraries.\nThe minimum supported version of OS X is 10.6 (‘Snow Leopard’): even\nthat has been unsupported by Apple since 2012.\nThe configure default on OS X is –disable-R-framework: enable\nthis if you intend to install under /Library/Frameworks and use\nwith R.app.\nThe minimum preferred version of PCRE has since R 3.0.0 been 8.32\n(released in Nov 2012). Versions 8.10 to 8.31 are now deprecated\n(with warnings from configure), but will still be accepted until R\n3.4.0.\nconfigure looks for C functions __cospi, __sinpi and __tanpi\nand uses these if cospi etc are not found. (OS X is the main\ninstance.)\n(Windows) R is now built using gcc 4.9.3. This build will require\nrecompilation of at least those packages that include C++ code, and\npossibly others. A build of R-devel using the older toolchain will\nbe temporarily available for comparison purposes.\nDuring the transition, the environment variable R_COMPILED_BY has\nbeen defined to indicate which toolchain was used to compile R (and\nhence, which should be used to compile code in packages). The\nCOMPILED_BY variable described below will be a permanent\nreplacement for this.\n(Windows) A make and R CMD config variable named COMPILED_BY\nhas been added. This indicates which toolchain was used to compile R\n(and hence, which should be used to compile code in packages).\n\n\nPACKAGE INSTALLATION\nThe make macro AWK which used to be made available to files such\nas src/Makefile is no longer set.\n\n\nC-LEVEL FACILITIES\nThe API call logspace_sum introduced in R 3.2.0 is now remapped as\nan entry point to Rf_logspace_sum, and its first argument has\ngained a const qualifier. ()\nCode using it will need to be reinstalled.\nSimilarly, entry point log1pexp also defined in Rmath.h is\nremapped there to Rf_log1pexp\nR_GE_version has been increased to 11.\nNew API call R_orderVector1, a faster one-argument version of\nR_orderVector.\nWhen R headers such as R.h and Rmath.h are called from C++ code\nin packages they include the C++ versions of system headers such as\n<cmath> rather than the legacy headers such as <math.h>.\n(Headers Rinternals.h and Rinterface.h already did, and\ninclusion of system headers can still be circumvented by defining\nNO_C_HEADERS, including as from this version for those two\nheaders.)\nThe manual has long said that R headers should be included within an\nextern \"C\" block, and almost all the packages affected by this\nchange were doing so.\nIncluding header S.h from C++ code would fail on some platforms,\nand so gives a compilation error on all.\nThe deprecated header Rdefines.h is now compatible with defining\nR_NO_REMAP.\nThe connections interface now includes a function\nR_GetConnection() which allows packages implementing connections\nto convert R connection objects to Rconnection handles. Code\nwhich previously used the low-level R-internal getConnection()\nentry point should switch.\n\n\nBUG FIXES\nC-level asChar(x) is fixed for when x is not a vector, and it\nreturns \"TRUE\"/\"FALSE\" instead of \"T\"/\"F\" for logical\nvectors.\nThe first arguments of .colSums() etc (with an initial dot) are\nnow named x rather than X (matching colSums()): thus error\nmessages are corrected.\nA coef() method for class \"maov\" has been added to allow\nvcov() to work with multivariate results. ()\nmethod = \"libcurl\" connections signal errors rather than\nretrieving HTTP error pages (where the ISP reports the error).\nxpdrows.data.frame() was not checking for unique row names; in\nparticular, this affected assignment to non-existing rows via\nnumerical indexing. ()\ntail.matrix() did not work for zero rows matrices, and could\nproduce row “labels” such as \"[1e+05,]\".\nData frames with a column named \"stringsAsFactors\" now format and\nprint correctly. ()\ncor() is now guaranteed to return a value with absolute value less\nthan or equal to 1. ()\nArray subsetting now keeps names(dim(.)).\nBlocking socket connection selection recovers more gracefully on\nsignal interrupts.\nThe data.frame method of rbind() construction row.names works\nbetter in borderline integer cases, but may change the names\nassigned. ()\n(X11 only) getGraphicsEvent() miscoded buttons and missed mouse\nmotion events. ()\nmethods(round) now also lists round.POSIXt.\ntar() now works with the default files = NULL. ()\nJumps to outer contexts, for example in error recovery, now make\nintermediate jumps to contexts where on.exit() actions are\nestablished instead of trying to run all on.exit() actions before\njumping to the final target. This unwinds the stack gradually,\nreleases resources held on the stack, and significantly reduces the\nchance of a segfault when running out of C stack space. Error\nhandlers established using withCallingHandlers() and\noptions(\"error\") specifications are ignored when handling a C\nstack overflow error as attempting one of these would trigger a\ncascade of C stack overflow errors. (These changes resolve .)\nThe spacing could be wrong when printing a complex array. (Report\nand patch by Lukas Stadler.)\npretty(d, n, min.n, *) for date-time objects d works again in\nborder cases with large min.n, returns a labels attribute also\nfor small-range dates and in such cases its returned length is\ncloser to the desired n. () Additionally, it finally does cover\nthe range of d, as it always claimed.\ntsp(x) <- NULL did not handle correctly objects inheriting from\nboth \"ts\" and \"mts\". ()\ninstall.packages() could give false errors when\noptions(\"pkgType\") was \"binary\". (Reported by Jose Claudio\nFaria.)\nA bug fix in R 3.0.2 fixed problems with locator() in X11, but\nintroduced problems in Windows. Now both should be fixed. ()\ndownload.file() with method = \"wininet\" incorrectly warned of\ndownload file length difference when reported length was unknown. ()\ndiag(NULL, 1) crashed because of missed type checking. ()\n\n\n\nCHANGES IN R 3.2.5\n\nBUG FIXES\nformat.POSIXlt() behaved incorrectly in R 3.2.4. E.g. the output\nof\nformat(as.POSIXlt(paste0(1940:2000, \"-01-01\"), tz = \"CET\"), usetz = TRUE)\nended in two \"CEST\" time formats.\n\n\n\nCHANGES IN R 3.2.4\n\nNEW FEATURES\ninstall.packages() and related functions now give a more\ninformative warning when an attempt is made to install a base\npackage.\nsummary(x) now prints with less rounding when x contains\ninfinite values. (Request of .)\nprovideDimnames() gets an optional unique argument.\nshQuote() gains type = \"cmd2\" for quoting in cmd.exe in\nWindows. (Response to .)\nThe data.frame method of rbind() gains an optional argument\nstringsAsFactors (instead of only depending on\ngetOption(\"stringsAsFactors\")).\nsmooth(x, *) now also works for long vectors.\ntools::texi2dvi() has a workaround for problems with the\ntexi2dvi script supplied by texinfo 6.1.\nIt extracts more error messages from the LaTeX logs when in\nemulation mode.\n\n\nUTILITIES\nR CMD check will leave a log file build_vignettes.log from the\nre-building of vignettes in the .Rcheck directory if there is a\nproblem, and always if environment variable\n_R_CHECK_ALWAYS_LOG_VIGNETTE_OUTPUT_ is set to a true value.\n\n\nDEPRECATED AND DEFUNCT\nUse of SUPPORT_OPENMP from header Rconfig.h is deprecated in\nfavour of the standard OpenMP define _OPENMP.\n(This has been the recommendation in the manual for a while now.)\nThe make macro AWK which is long unused by R itself but recorded\nin file etc/Makeconf is deprecated and will be removed in R 3.3.0.\nThe C header file S.h is no longer documented: its use should be\nreplaced by R.h.\n\n\nBUG FIXES\nkmeans(x, centers = <1-row>) now works. ()\nVectorize() now checks for clashes in argument names. ()\nfile.copy(overwrite = FALSE) would signal a successful copy when\nnone had taken place. ()\nngettext() now uses the same default domain as gettext(). ()\narray(.., dimnames = *) now warns about non-list dimnames and,\nfrom R 3.3.0, will signal the same error for invalid dimnames as\nmatrix() has always done.\naddmargins() now adds dimnames for the extended margins in all\ncases, as always documented.\nheatmap() evaluated its add.expr argument in the wrong\nenvironment. ()\nrequire() etc now give the correct entry of lib.loc in the\nwarning about an old version of a package masking a newer required\none.\nThe internal deparser did not add parentheses when necessary, e.g.\nbefore [] or [[]]. (Reported by Lukas Stadler; additional fixes\nincluded as well).\nas.data.frame.vector(*, row.names=*) no longer produces\n‘corrupted’ data frames from row names of incorrect length, but\nrather warns about them. This will become an error.\nurl connections with method = \"libcurl\" are destroyed properly.\n()\nwithCallingHandler() now (again) handles warnings even during S4\ngeneric’s argument evaluation. ()\ndeparse(..., control = \"quoteExpressions\") incorrectly quoted\nempty expressions. ()\nformat()ting datetime objects (\"POSIX[cl]?t\") could segfault or\nrecycle wrongly. ()\nplot.ts(<matrix>, las = 1) now does use las.\nsaveRDS(*, compress = \"gzip\") now works as documented. ()\n(Windows only) The Rgui front end did not always initialize the\nconsole properly, and could cause R to crash. ()\ndummy.coef.lm() now works in more cases, thanks to a proposal by\nWerner Stahel (). In addition, it now works for multivariate linear\nmodels (\"mlm\", ) thanks to a proposal by Daniel Wollschlaeger.\nThe as.hclust() method for \"dendrogram\"s failed often when there\nwere ties in the heights.\nreorder() and midcache.dendrogram() now are non-recursive and\nhence applicable to somewhat deeply nested dendrograms, thanks to a\nproposal by Suharto Anggono in .\ncor.test() now calculates very small p values more accurately\n(affecting the result only in extreme not statistically relevant\ncases). ()\nsmooth(*, do.ends=TRUE) did not always work correctly in R\nversions between 3.0.0 and 3.2.3.\npretty(D) for date-time objects D now also works well if\nrange(D) is (much) smaller than a second. In the case of only one\nunique value in D, the pretty range now is more symmetric around\nthat value than previously.\nSimilarly, pretty(dt) no longer returns a length 5 vector with\nduplicated entries for Date objects dt which span only a few\ndays.\nThe figures in help pages such as ?points were accidentally\ndamaged, and did not appear in R 3.2.3. ()\navailable.packages() sometimes deleted the wrong file when\ncleaning up temporary files. ()\nThe X11() device sometimes froze on Red Hat Enterprise Linux 6. It\nnow waits for MapNotify events instead of Expose events, thanks\nto Siteshwar Vashisht. ()\n[dpqr]nbinom(*, size=Inf, mu=.) now works as limit case, for ‘dpq’\nas the Poisson. ()pnbinom() no longer loops infinitely in border cases.\napproxfun(*, method=\"constant\") and hence ecdf() which calls the\nformer now correctly “predict” NaN values as NaN.\nsummary.data.frame() now displays NAs in Date columns in all\ncases. ()\n\n\n\nCHANGES IN R 3.2.3\n\nNEW FEATURES\nSome recently-added Windows time zone names have been added to the\nconversion table used to convert these to Olson names. (Including\nthose relating to changes for Russia in Oct 2014, as in .)\n(Windows) Compatibility information has been added to the manifests\nfor Rgui.exe, Rterm.exe and Rscript.exe. This should allow\nwin.version() and Sys.info() to report the actual Windows\nversion up to Windows 10.\nWindows \"wininet\" FTP first tries EPSV / PASV mode rather than\nonly using active mode (reported by Dan Tenenbaum).\nwhich.min(x) and which.max(x) may be much faster for logical and\ninteger x and now also work for long vectors.\nThe ‘emulation’ part of tools::texi2dvi() has been somewhat\nenhanced, including supporting quiet = TRUE. It can be selected by\ntexi2dvi = \"emulation\".\n(Windows) MiKTeX removed its texi2dvi.exe command in Sept 2015:\ntools::texi2dvi() tries texify.exe if it is not found.\n(Windows only) Shortcuts for printing and saving have been added to\nmenus in Rgui.exe. (Request of .)\nloess(..., iterTrace=TRUE) now provides diagnostics for robustness\niterations, and the print() method for summary(<loess>) shows\nslightly more.\nThe included version of PCRE has been updated to 8.38, a bug-fix\nrelease.\nView() now displays nested data frames in a more friendly way.\n(Request with patch in .)\n\n\nINSTALLATION and INCLUDED SOFTWARE\nThe included configuration code for libintl has been updated to\nthat from gettext version 0.19.5.1 — this should only affect how\nan external library is detected (and the only known instance is\nunder OpenBSD). (Wish of .)\nconfigure has a new argument –disable-java to disable the checks\nfor Java.\nThe configure default for MAIN_LDFLAGS has been changed for the\nFreeBSD, NetBSD and Hurd OSes to one more likely to work with\ncompilers other than gcc (FreeBSD 10 defaults to clang).\nconfigure now supports the OpenMP flags -fopenmp=libomp (clang)\nand -qopenmp (Intel C).\nVarious macros can be set to override the default behaviour of\nconfigure when detecting OpenMP: see file config.site.\nSource installation on Windows has been modified to allow for MiKTeX\ninstallations without texi2dvi.exe. See file MkRules.dist.\n\n\nBUG FIXES\nregexpr(pat, x, perl = TRUE) with Python-style named capture did\nnot work correctly when x contained NA strings. ()\nThe description of dataset ToothGrowth has been\nimproved/corrected. ()\nmodel.tables(type = \"means\") and hence TukeyHSD() now support\n\"aov\" fits without an intercept term. ()\nclose() now reports the status of a pipe() connection opened\nwith an explicit open argument. ()\nCoercing a list without names to a data frame is faster if the\nelements are very long. ()\n(Unix-only) Under some rare circumstances piping the output from\nRscript or R -f could result in attempting to close the input\nfile twice, possibly crashing the process. ()\n(Windows) Sys.info() was out of step with win.version() and did\nnot report Windows 8.\ntopenv(baseenv()) returns baseenv() again as in R 3.1.0 and\nearlier. This also fixes compilerJIT(3) when used in .Rprofile.\ndetach()ing the methods package keeps .isMethodsDispatchOn()\ntrue, as long as the methods namespace is not unloaded.\nRemoved some spurious warnings from configure about the\npreprocessor not finding header files. ()\nrchisq(*, df=0, ncp=0) now returns 0 instead of NaN, and\ndchisq(*, df=0, ncp=*) also no longer returns NaN in limit cases\n(where the limit is unique). ()\npchisq(*, df=0, ncp > 0, log.p=TRUE) no longer underflows (for ncp\n> ~60).\nnchar(x, \"w\") returned -1 for characters it did not know about\n(e.g. zero-width spaces): it now assumes 1. It now knows about most\nzero-width characters and a few more double-width characters.\nHelp for which.min() is now more precise about behavior with\nlogical arguments. ()\nThe print width of character strings marked as \"latin1\" or\n\"bytes\" was in some cases computed incorrectly.\nabbreviate() did not give names to the return value if minlength\nwas zero, unlike when it was positive.\n(Windows only) dir.create() did not always warn when it failed to\ncreate a directory. ()\nWhen operating in a non-UTF-8 multibyte locale (e.g. an East Asian\nlocale on Windows), grep() and related functions did not handle\nUTF-8 strings properly. ()\nread.dcf() sometimes misread lines longer than 8191 characters.\n(Reported by Hervé Pagès with a patch.)\nwithin(df, ..) no longer drops columns whose name start with a\n\".\".\nThe built-in HTTP server converted entire Content-Type to\nlowercase including parameters which can cause issues for multi-part\nform boundaries ().\nModifying slots of S4 objects could fail when the methods package\nwas not attached. ()\nsplineDesign(*, outer.ok=TRUE) (splines) is better now (), and\ninterpSpline() now allows sparse=TRUE for speedup with non-small\nsizes.\nIf the expression in the traceback was too long, traceback() did\nnot report the source line number. (Patch by Kirill Müller.)\nThe browser did not truncate the display of the function when\nexiting with options(\"deparse.max.lines\") set. ()\nWhen bs(*, Boundary.knots=) had boundary knots inside the data\nrange, extrapolation was somewhat off. (Patch by Trevor Hastie.)\nvar() and hence sd() warn about factor arguments which are\ndeprecated now. ()\nloess(*, weights = *) stored wrong weights and hence gave slightly\nwrong predictions for newdata. ()\naperm(a, *) now preserves names(dim(a)).\npoly(x, ..) now works when either raw=TRUE or coef is\nspecified. ()\ndata(package=*) is more careful in determining the path.\nprettyNum(*, decimal.mark, big.mark): fixed bug introduced when\nfixing .\n\n\n\nCHANGES IN R 3.2.2\n\nSIGNIFICANT USER-VISIBLE CHANGES\nIt is now easier to use secure downloads from https:// URLs on\nbuilds which support them: no longer do non-default options need to\nbe selected to do so. In particular, packages can be installed from\nrepositories which offer https:// URLs, and those listed by\nsetRepositories() now do so (for some of their mirrors).\nSupport for https:// URLs is available on Windows, and on other\nplatforms if support for libcurl was compiled in and if that\nsupports the https protocol (system installations can be expected\nto do). So https:// support can be expected except on rather old\nOSes (an example being OS X ‘Snow Leopard’, where a non-system\nversion of libcurl can be used).\n(Windows only) The default method for accessing URLs via\ndownload.file() and url() has been changed to be \"wininet\"\nusing Windows API calls. This changes the way proxies need to be set\nand security settings made: there have been some reports of ftp:\nsites being inaccessible under the new default method (but the\nprevious methods remain available).\n\n\nNEW FEATURES\ncmdscale() gets new option list. for increased flexibility when\na list should be returned.\nconfigure now supports texinfo version 6.0, which (unlike the\nchange from 4.x to 5.0) is a minor update. (Wish of .)\n(Non-Windows only) download.file() with default method = \"auto\"\nnow chooses \"libcurl\" if that is available and a https:// or\nftps:// URL is used.\n(Windows only) setInternet2(TRUE) is now the default. The\ncommand-line option –internet2 and environment variable\nR_WIN_INTERNET2 are now ignored.\nThus by default the \"internal\" method for download.file() and\nurl() uses the \"wininet\" method: to revert to the previous\ndefault use setInternet2(FALSE).\nThis means that https:// URLs can be read by default by\ndownload.file() (they have been readable by file() and url()\nsince R 3.2.0).\nThere are implications for how proxies need to be set (see\n?download.file).\nchooseCRANmirror() and chooseBioCmirror() now offer HTTPS\nmirrors in preference to HTTP mirrors. This changes the\ninterpretation of their ind arguments: see their help pages.\ncapture.output() gets optional arguments type and split to\npass to sink(), and hence can be used to capture messages.\n\n\nC-LEVEL FACILITIES\nHeader Rconfig.h now defines HAVE_ALLOCA_H if the platform has\nthe alloca.h header (it is needed to define alloca on Solaris\nand AIX, at least: see ‘Writing R Extensions’ for how to use it).\n\n\nINSTALLATION and INCLUDED SOFTWARE\nThe libtool script generated by configure has been modified to\nsupport FreeBSD >= 10 ().\n\n\nBUG FIXES\nThe HTML help page links to demo code failed due to a change in R\n3.2.0. ()\nIf the na.action argument was used in model.frame(), the\noriginal data could be modified. ()\ngetGraphicsEvent() could cause a crash if a graphics window was\nclosed while it was in use. ()\nmatrix(x, nr, nc, byrow = TRUE) failed if x was an object of\ntype \"expression\".\nstrptime() could overflow the allocated storage on the C stack\nwhen the timezone had a non-standard format much longer than the\nstandard formats. (Part of .)\noptions(OutDec = s) now signals a warning (which will become an\nerror in the future) when s is not a string with exactly one\ncharacter, as that has been a documented requirement.\nprettyNum() gains a new option input.d.mark which together with\nother changes, e.g., the default for decimal.mark, fixes some\nformat()ting variants with non-default getOption(\"OutDec\") such\nas in .\ndownload.packages() failed for type equal to either \"both\" or\n\"binary\". (Reported by Dan Tenenbaum.)\nThe dendrogram method of labels() is much more efficient for\nlarge dendrograms, now using rapply(). (Comment #15 of )\nThe \"port\" algorithm of nls() could give spurious errors.\n(Reported by Radford Neal.)\nReference classes that inherited from reference classes in another\npackage could invalidate methods of the inherited class. Fixing this\nrequires adding the ability for methods to be “external”, with the\nobject supplied explicitly as the first argument, named .self. See\n\"Inter-Package Superclasses\" in the documentation.\nreadBin() could fail on the SPARC architecture due to alignment\nissues. (Reported by Radford Neal.)\nqt(*, df=Inf, ncp=.) now uses the natural qnorm() limit instead\nof returning NaN. ()\nAuto-printing of S3 and S4 values now searches for print() in the\nbase namespace and show() in the methods namespace instead of\nsearching the global environment.\npolym() gains a coefs = NULL argument and returns class \"poly\"\njust like poly() which gets a new simple=FALSE option. They now\nlead to correct predict()ions, e.g., on subsets of the original\ndata. ()\nrhyper(nn, <large>) now works correctly. ()\nttkimage() did not (and could not) work so was removed. Ditto for\ntkimage.cget() and tkimage.configure(). Added two Ttk widgets\nand missing subcommands for Tk’s image command: ttkscale(),\nttkspinbox(), tkimage.delete(), tkimage.height(),\ntkimage.inuse(), tkimage.type(), tkimage.types(),\ntkimage.width(). (, )\ngetClass(\"foo\") now also returns a class definition when it is\nfound in the cache more than once.\n\n\n\nCHANGES IN R 3.2.1\n\nNEW FEATURES\nutf8ToInt() now checks that its input is valid UTF-8 and returns\nNA if it is not.\ninstall.packages() now allows type = \"both\" with repos = NULL\nif it can infer the type of file.\nnchar(x, *) and nzchar(x) gain a new argument keepNA which\ngoverns how the result for NAs in x is determined. For\nnzchar() in general and nchar() in the R 3.2.x series, the\ndefault remains FALSE which is fully back compatible. From R\n3.3.0, nchar()’s default will change to keepNA = NA and you are\nadvised to consider this for code portability.\nnews() more flexibly extracts dates from package NEWS.Rd files.\nlengths(x) now also works (trivially) for atomic x and hence can\nbe used more generally as an efficient replacement of\nsapply(x, length) and similar.\nThe included version of PCRE has been updated to 8.37, a bug-fix\nrelease.\ndiag() no longer duplicates a matrix when extracting its diagonal.\nas.character.srcref() gains an argument to allow characters\ncorresponding to a range of source references to be extracted.\n\n\nBUG FIXES\nacf() and ccf() now guarantee values strictly in (instead of\nsometimes very slightly outside). .\nas.integer(\"111111111111\") now gives NA (with a warning) as it\ndoes for the corresponding numeric or negative number coercions.\nFurther, as.integer(M + 0.1) now gives M (instead of NA) when M\nis the maximal representable integer.\nOn some platforms nchar(x, \"c\") and nchar(x, \"w\") would return\nvalues (possibly NA) for inputs which were declared to be UTF-8\nbut were not, or for invalid strings without a marked encoding in a\nmulti-byte locale, rather than give an error. Additional checks have\nbeen added to mitigate this.\napply(a, M, function(u) c(X = ., Y = .)) again has dimnames\ncontaining \"X\" and \"Y\" (as in R < 3.2.0).\n(Windows only) In some cases, the –clean option to R CMD INSTALL\ncould fail. ()\n(Windows only) choose.files() would occasionally include\ncharacters from the result of an earlier call in the result of a\nlater one. ()\nA change in RSiteSearch() in R 3.2.0 caused it to submit invalid\nURLs. ()\nRscript and command line R silently ignored incomplete\nstatements at the end of a script; now they are reported as parse\nerrors. ()\nParse data for very long strings was not stored. ()\nplotNode(), the workhorse of the plot method for \"dendrogram\"s\nis no longer recursive, thanks to Suharto Anggono, and hence also\nworks for deeply nested dendrograms. ()\nThe parser could overflow internally when given numbers in\nscientific format with extremely large exponents. ()\nIf the CRAN mirror was not set, install.packages(type = \"both\")\nand related functions could repeatedly query the user for it. (Part\nof )\nThe low-level functions .rowSums() etc. did not check the length\nof their argument, so could segfault. ()\nThe quietly argument of library() is now correctly propagated\nfrom .getRequiredPackages2().\nUnder some circumstances using the internal PCRE when building R\nfrom source would cause external libs such as -llzma to be omitted\nfrom the main link.\nThe .Primitive default methods of the logic operators, i.e., !,\n& and |, now give correct error messages when appropriate, e.g.,\nfor ‘&‘(TRUE) or ‘!‘(). ()\ncummax(x) now correctly propagates NAs also when x is of type\ninteger and begins with an NA.\nsummaryRprof() could fail when the profile contained only two\nrecords. ()\nHTML vignettes opened using vignette() did not support links into\nthe rest of the HTML help system. (Links worked properly when the\nvignette was opened using browseVignettes() or from within the\nhelp system.)\narima(*, xreg = .) (for ) computes estimated variances based on a\nthe number of effective observations as in R version 3.0.1 and\nearlier. ()\nslotNames(.) is now correct for \"signature\" objects (mostly used\ninternally in methods).\nOn some systems, the first string comparison after a locale change\nwould result in NA.\n\n\n\nCHANGES IN R 3.2.0\n\nNEW FEATURES\nanyNA() gains a recursive argument.\nWhen x is missing and names is not false (including the default\nvalue), Sys.getenv(x, names) returns an object of class \"Dlist\"\nand hence prints tidily.\n(Windows.) shell() no longer consults the environment variable\nSHELL: too many systems have been encountered where it was set\nincorrectly (usually to a path where software was compiled, not\nwhere it was installed). R_SHELL, the preferred way to select a\nnon-default shell, can be used instead.\nSome unusual arguments to embedFonts() can now be specified as\ncharacter vectors, and the defaults have been changed accordingly.\nFunctions in the Summary group duplicate less. ()\n(Unix-alikes.) system(cmd, input = ) now uses\n‘shell-execution-environment’ redirection, which will be more\nnatural if cmd is not a single command (but requires a\nPOSIX-compliant shell). (Wish of )\nread.fwf() and read.DIF() gain a fileEncoding argument, for\nconvenience.\nGraphics devices can add attributes to their description in\n.Device and .Devices. Several of those included with R use a\n\"filepath\" attribute.\npmatch() uses hashing in more cases and so is faster at the\nexpense of using more memory. ()\npairs() gains new arguments to select sets of variables to be\nplotted against each other.\nfile.info(, extra_cols = FALSE) allows a minimal set of columns to\nbe computed on Unix-alikes: on some systems without\nproperly-configured caching this can be significantly faster with\nlarge file lists.\nNew function dir.exists() in package base to test efficiently\nwhether one or more paths exist and are directories.\ndput() and friends gain new controls hexNumeric and digits17\nwhich output double and complex quantities as, respectively, binary\nfractions (exactly, see sprintf(\"%a\")) and as decimals with up to\n17 significant digits.\nsave(), saveRDS() and serialize() now support ascii = NA\nwhich writes ASCII files using sprintf(\"%a\") for double/complex\nquantities. This is read-compatible with ascii = TRUE but avoids\nbinary->decimal->binary conversions with potential loss of\nprecision. Unfortunately the Windows C runtime’s lack of C99\ncompliance means that the format cannot be read correctly there in R\nbefore 3.1.2.\nThe default for formatC(decimal.mark =) has been changed to be\ngetOption(\"OutDec\"); this makes it more consistent with format()\nand suitable for use in print methods, e.g. those for classes\n\"density\", \"ecdf\", \"stepfun\" and \"summary.lm\".\ngetOption(\"OutDec\") is now consulted by the print method for class\n\"kmeans\", by cut(), dendrogram(), plot.ts() and quantile()\nwhen constructing labels and for the report from\nlegend(trace = TRUE).\n(In part, wish of .)\nprintNum() and hence format() and formatC() give a warning if\nbig.mark and decimal.mark are set to the same value (period and\ncomma are not uncommonly used for each, and this is a check that\nconventions have not got mixed).\nmerge() can create a result which uses long vectors on 64-bit\nplatforms.\ndget() gains a new argument keep.source which defaults to\nFALSE for speed (dput() and dget() are most often used for\ndata objects where this can make dget() many times faster).\nPackages may now use a file of common macro definitions in their\nhelp files, and may import definitions from other packages.\nA number of macros have been added in the new share/Rd directory\nfor use in package overview help pages, and promptPackage() now\nmakes use of them.\ntools::parse_Rd() gains a new permissive argument which converts\nunrecognized macros into text. This is used by\nutils:::format.bibentry to allow LaTeX markup to be ignored.\noptions(OutDec =) can now specify a multi-byte character, e.g.,\noptions(OutDec = \"u00b7\") in a UTF-8 locale.\nis.recursive(x) is no longer true when x is an external pointer,\na weak reference or byte code; the first enables all.equal(x, x)\nwhen x <- getClass(.).\nls() (aka objects()) and as.list.environment() gain a new\nargument sorted.\nThe \"source\" attribute (which has not been added to functions by R\nsince before R version 2.14.0) is no longer treated as special.\nFunction returnValue() has been added to give on.exit() code\naccess to a function’s return value for debugging purposes.\ncrossprod(x, y) allows more matrix coercions when x or y are\nvectors, now equalling t(x) %*% y in these cases (also reported by\nRadford Neal). Similarly, tcrossprod(x,y) and %*% work in more\ncases with vector arguments.\nUtility function dynGet() useful for detecting cycles, aka\ninfinite recursions.\nThe byte-code compiler and interpreter include new instructions that\nallow many scalar subsetting and assignment and scalar arithmetic\noperations to be handled more efficiently. This can result in\nsignificant performance improvements in scalar numerical code.\napply(m, 2, identity) is now the same as the matrix m when it\nhas named row names.\nA new function debuggingState() has been added, allowing to\ntemporarily turn off debugging.\nexample() gets a new optional argument run.donttest and\ntools::Rd2ex() a corresponding commentDonttest, with a default\nsuch that example(..) in help examples will run donttest code\nonly if used interactively (a change in behaviour).\nrbind.data.frame() gains an optional argument make.row.names,\nfor potential speedup.\nNew function extSoftVersion() to report on the versions of\nthird-party software in use in this session. Currently reports\nversions of zlib, bzlib, the liblzma from xz, PCRE, ICU, TRE\nand the iconv implementation.\nA similar function grSoftVersion() in package grDevices reports\non third-party graphics software.\nFunction tcltk::tclVersion() reports the Tcl/Tk version.\nCalling callGeneric() without arguments now works with primitive\ngenerics to some extent.\nvapply(x, FUN, FUN.VALUE) is more efficient notably for large\nlength(FUN.VALUE); as extension of .\nas.table() now allows tables with one or more dimensions of length\n0 (such as as.table(integer())).\nnames(x) <- NULL now clears the names of call and ... objects.\nlibrary() will report a warning when an insufficient dependency\nversion is masking a sufficient one later on the library search\npath.\nA new plot() method for class \"raster\" has been added.\nNew check_packages_in_dir_changes() function in package tools\nfor conveniently analyzing how changing sources impacts the check\nresults of their reverse dependencies.\nSpeed-up from Peter Haverty for ls() and\nmethods:::.requirePackage() speeding up package loading. ()\nNew get0() function, combining exists() and get() in one call,\nfor efficiency.\nmatch.call() gains an envir argument for specifying the\nenvironment from which to retrieve the ... in the call, if any;\nthis environment was wrong (or at least undesirable) when the\ndefinition argument was a function.\ntopenv() has been made .Internal() for speedup, based on Peter\nHaverty’s proposal in .\ngetOption() no longer calls options() in the main case.\nOptional use of libcurl (version 7.28.0 from Oct 2012 or later)\nfor Internet access:\ncapabilities(\"libcurl\") reports if this is available.\nlibcurlVersion() reports the version in use, and other details\nof the \"libcurl\" build including which URL schemes it\nsupports.\ncurlGetHeaders() retrieves the headers for http://,\nhttps://, ftp:// and ftps:// URLs: analysis of these\nheaders can provide insights into the ‘existence’ of a URL (it\nmight for example be permanently redirected) and is so used in\nR CMD check –as-cran.\ndownload.file() has a new optional method \"libcurl\" which\nwill handle more URL schemes, follow redirections, and allows\nsimultaneous downloads of multiple URLs.\nurl() has a new method \"libcurl\" which handles more URL\nschemes and follows redirections. The default method is\ncontrolled by a new option url.method, which applies also to\nthe opening of URLs via file() (which happens implicitly in\nfunctions such as read.table.)\nWhen file() or url() is invoked with a https:// or\nftps:// URL which the current method cannot handle, it\nswitches to a suitable method if one is available.\n\n(Windows.) The DLLs internet.dll and internet2.dll have been\nmerged. In this version it is safe to switch (repeatedly) between\nthe internal and Windows internet functions within an R session.\nThe Windows internet functions are still selected by flag\n–internet2 or setInternet2(). This can be overridden for an\nurl() connection via its new method argument.\ndownload.file() has new method \"wininet\", selected as the\ndefault by –internet2 or setInternet2().\nparent.env<- can no longer modify the parent of a locked namespace\nor namespace imports environment. Contributed by Karl Millar.\nNew function isNamespaceLoaded() for readability and speed.\nnames(env) now returns all the object names of an environment\nenv, equivalently to ls(env, all.names = TRUE, sorted = FALSE)\nand also to the names of the corresponding list,\nnames(as.list(env, all.names = TRUE)). Note that although\nnames() returns a character vector, the names have no particular\nordering.\nThe memory manager now grows the heap more aggressively. This\nreduces the number of garbage collections, in particular while data\nor code are loaded, at the expense of slightly increasing the memory\nfootprint.\nNew function trimws() for removing leading/trailing whitespace.\ncbind() and rbind() now consider S4 inheritance during S3\ndispatch and also obey deparse.level.\ncbind() and rbind() will delegate recursively to\nmethods::cbind2 (methods::rbind2) when at least one argument is\nan S4 object and S3 dispatch fails (due to ambiguity).\n(Windows.) download.file(quiet = FALSE) now uses text rather than\nWindows progress bars in non-interactive use.\nNew function hsearch_db() in package utils for building and\nretrieving the help search database used by help.search(), along\nwith functions for inspecting the concepts and keywords in the help\nsearch database.\nNew function .getNamespaceInfo(), a no-check version of\ngetNamespaceInfo() mostly for internal speedups.\nThe help search system now takes keyword entries in Rd files which\nare not standard keywords (as given in KEYWORDS in the R\ndocumentation directory) as concepts. For standard keyword entries\nthe corresponding descriptions are additionally taken as concepts.\nNew lengths() function for getting the lengths of all elements in\na list.\nNew function toTitleCase() in package tools, tailored to package\ntitles.\nThe matrix methods of cbind() and rbind() allow matrices as\ninputs which have or more elements. (For cbind(), wish of .)\nThe default method of image() has an explicit check for a numeric\nor logical matrix (which was always required).\nURLencode() will not by default encode further URLs which appear\nto be already encoded.\nBIC(mod) and BIC(mod, mod2) now give non-NA numbers for\narima() fitted models, as nobs(mod) now gives the number of\n“used” observations for such models. This fixes , quite differently\nthan proposed there.\nThe print() methods for \"htest\", \"pairwise.htest\" and\n\"power.htest\" objects now have a digits argument defaulting to\n(a function of) getOption(\"digits\"), and influencing all printed\nnumbers coherently. Unavoidably, this changes the display of such\ntest results in some cases.\nCode completion for namespaces now recognizes all loaded namespaces,\nrather than only the ones that are also attached.\nThe code completion mechanism can now be replaced by a\nuser-specified completer function, for (temporary) situations where\nthe usual code completion is inappropriate.\nunzip() will now warn if it is able to detect truncation when\nunpacking a file of 4GB or more (related to ).\nmethods() reports S4 in addition to S3 methods; output is\nsimplified when the class argument is used. .S3methods() and\nmethods::.S4methods() report S3 and S4 methods separately.\nHigher order functions such as the apply functions and Reduce()\nnow force arguments to the functions they apply in order to\neliminate undesirable interactions between lazy evaluation and\nvariable capture in closures. This resolves .\n\n\nINSTALLATION and INCLUDED SOFTWARE\nThe donttest sections of R’s help files can be tested bymake check TEST_DONTTEST=TRUE .\nIt is possible to request the use of system valgrind headers via\nconfigure option –with-system-valgrind-headers: note the\npossible future incompatibility of such headers discussed in the ‘R\nInstallation and Administration’ manual. (Wish of .)\nThe included version of liblzma has been updated to xz-utils\n5.0.7 (minor bug fixes from 5.0.5).\nconfigure options –with-system-zlib, –with-system-bzlib and\n–with-system-pcre are now the default. For the time being there is\nfallback to the versions included in the R sources if no system\nversions are found or (unlikely) if they are too old.\nLinux users should check that the -devel or -dev versions of\npackages zlib, bzip2/libbz2 and pcre as well as\nxz-devel/liblzma-dev (or similar names) are installed.\nconfigure by default looks for the texi2any script from\ntexinfo 5.1 or later, rather than the makeinfo program.\n(makeinfo is a link to the Perl script texi2any in texinfo\n5.x.)\nR CMD INSTALL gains an option –built-timestamp=STAMP allowing\n100% reproducible package building, thanks to Dirk Eddelbuettel.\n\n\nUTILITIES\nThere is support for testing the dontrun and donttest parts of\nexamples in packages.\ntools::testInstalledPackage() accepts new arguments\ncommentDontrun = FALSE and commentDonttest = FALSE.\nR CMD check gains options –run-dontrun and –run-donttest.\nThe HTML generated by tools::Rd2HTML() and tools::toHTML()\nmethods is now ‘XHTML 1.0 Strict’.\nThe compiler package’s utility function setCompilerOptions() now\nreturns the old values invisibly. The initial optimization level can\nalso be set with the environment variable R_COMPILER_OPTIMIZE.\nR CMD build adds a NeedsCompilation field if one is not already\npresent in the DESCRIPTION file.\nR CMD check gains option –test-dir to specify an alternative set\nof tests to run.\nR CMD check will now by default continue with testing after many\ntypes of errors, and will output a summary count of errors at the\nend if any have occurred.\nR CMD check now checks that the Title and Description fields\nare correctly terminated.\nR CMD check –as-cran now:\nchecks a README.md file can be processed: this needs pandoc\ninstalled.\nchecks the existence and accessibility of URLs in the\nDESCRIPTION, CITATION, NEWS.Rd and README.md files and\nin the help files (provided the build has libcurl support).\nreports non-ASCII characters in R source files when there is no\npackage encoding declared in the DESCRIPTION file.\nreports (apparent) S3 methods exported but not registered.\nreports overwriting registered S3 methods from base/recommended\npackages. (Such methods are replaced in the affected package for\nthe rest of the session, even if the replacing namespace is\nunloaded.)\nreports if the Title field does not appear to be in title case\n(see ‘Writing R Extensions’: there may be false positives, but\nnote that technical words should be single-quoted and will then\nbe accepted).\nMost of these checks can also be selected by environment variables:\nsee the ‘R Internals’ manual.\n\n\nC-LEVEL FACILITIES\nNew C API utility logspace_sum(logx[], n).\nEntry points rbinom_mu, rnbinom_mu and rmultinom are remapped\n(by default) to Rf_rbinom_mu etc. This requires packages using\nthem to be re-installed.\n.C(DUP = FALSE) and .Fortran(DUP = FALSE) are now ignored, so\narguments are duplicated if DUP = TRUE would do so. As their help\nhas long said, .Call() is much preferred.\nNew entry point R_allocLD, like R_alloc but guaranteed to have\nsufficient alignment for long double pointers.\nisPairList() now returns TRUE for DOTSXP.\n\n\nWINDOWS BUILD CHANGES A number of changes to the Windows build system\nare in development. The following are currently in place.\nInstallation using external binary distributions of zlib, bzip2,\nliblzma, pcre, libpng, jpeglib and libtiff is now\nrequired, and the build instructions have been revised.\nA new make target rsync-extsoft has been added to obtain copies\nof the external libraries from CRAN.\nBuilding the manuals now requires texi2any from texinfo 5.1 or\nlater. CRAN binary builds include the manuals, but by default builds\nfrom source will not, and they will be accessed from CRAN. See the\ncomments in src/gnuwin32/MkRules.dist for how to specify the\nlocation of texi2any.\n(Windows) Changes have been made to support an experimental Windows\ntoolchain based on GCC 4.9.2. The default toolchain continues to be\nbased on GCC 4.6.3, as the new toolchain is not yet stable enough. A\nchange to a new toolchain is expected during the R 3.2.x lifetime.\n\n\nPACKAGE INSTALLATION\n(Windows) The use of macro ZLIB_LIBS in file src/Makevars.win\n(which has not been documented for a long time) now requires an\nexternal libz.a to be available (it is part of the ‘goodies’ used\nto compile Windows binary packages). It would be simpler to use\n-lz instead.\nThe default for option pkgType on platforms using binary packages\nis now \"both\", so source packages will be tried if binary versions\nare not available or not up to date.\nThere are options for what install.packages(type = \"both\")\n(possibly called via update.packages()) will do if compilation\nof a source package is desirable: see ?options (under utils).\nIf you intend not to accept updates as source packages, you should\nuse update.packages(type = \"binary\").\n\n\nDEPRECATED AND DEFUNCT\ndownload.file(method = \"lynx\") is defunct.\nBuilding R using the included versions of zlib, bzip2, xz and\nPCRE is deprecated: these are frozen (bar essential bug-fixes) and\nwill be removed for R 3.3.0.\nThe configure option –with-valgrind-instrumentation=3 has been\nwithdrawn, as it did not work with recent valgrind headers: it is\nnow treated as level 2.\nThe MethodsList class in package methods had been deprecated in\nR 2.11.0 and is defunct now. Functions using it are defunct if they\nhad been deprecated in R 2.11.0, and are deprecated now, otherwise.\n\n\nBUG FIXES\nFixed two obscure bugs in pairlist subassignment, reported by\nRadford Neal as part of pqR issue 16.\nFixes for bugs in handling empty arguments and argument matching by\nname in log().\nall.equal() gains methods for environments and refClasses.\n[<- and [[<- gain S4 data.frame methods to avoid corruption of\nS4 class information by the S3 methods.\ncallNextMethod() should now work within a .local call when ...\nis absent from formals(.local).\ndput(pairlist(x)) generates a call to the pairlist constructor\ninstead of the list constructor.\nFix missing() when arguments are propagated through ... . ()\neigen(m) now defaults to symmetric = TRUE even when the dimnames\nare asymmetric if the matrix is otherwise symmetric. ()\nFix issues with forwarding ... through callGeneric() and\ncallNextMethod(). ()\ncallGeneric() now works after a callNextMethod().\nSubclass information is kept consistent when replacing an ordinary\nS4 class with an “old class” via the S4Class argument to\nsetOldClass(). Thus, for example, a data.frame is valid for a\nlist argument in the signature, and a factor is valid for\nvector arguments.\nIn qbeta() the inversion of pbeta() is much more sophisticated.\nThis works better in corner cases some of which failed completely\npreviously (), or were using too many iterations.\nAuto-printing no longer duplicates objects when printing is\ndispatched to a method.\nkmeans(x, k) would fail when nrow(x) >= 42949673. (Comment 6 of\n)\n‘Abbreviated’ locale-specific day and month names could have been\ntruncated in those rare locales where there are the same as the full\nnames.\nAn irrelevant warning message from updating subclass information was\nsilenced (the namespace would not be writable in this case).\n\n\n\nCHANGES IN R 3.1.3\n\nNEW FEATURES\nThe internal method of download.file() can now handle files larger\nthan 2GB on 32-bit builds which support such files (tested on 32-bit\nR running on 64-bit Windows).\nkruskal.test() warns on more types of suspicious input.\nThe as.dendrogram() method for \"hclust\" objects gains a check\nargument protecting against memory explosion for invalid inputs.\ncapabilities() has a new item long.double which indicates if the\nbuild uses a long double type which is longer than double.\nnlm() no longer modifies the callback argument in place (a new\nvector is allocated for each invocation, which mimics the implicit\nduplication that occurred in R < 3.1.0); note that this is a change\nfrom the previously documented behavior. ()\nicuSetCollate() now accepts locale = \"ASCII\" which uses the\nbasic C function strcmp and so collates strings byte-by-byte in\nnumerical order.\nsessionInfo() tries to report the OS version in use (not just that\ncompiled under, and including details of Linux distributions).\nmodel.frame() (used by lm() and many other modelling functions)\nnow warns when it drops contrasts from factors. (Wish of )\ninstall.packages() and friends now accept the value\ntype = \"binary\" as a synonym for the native binary type on the\nplatform (if it has one).\nSingle source or binary files can be supplied for\ninstall.packages(type = \"both\") and the appropriate type and\nrepos = NULL will be inferred.\nNew function pcre_config() to report on some of the configuration\noptions of the version of PCRE in use. In particular, this reports\nif regular expressions using p{xx} are supported.\n(Windows.) download.file(cacheOK = FALSE) is now supported when\ninternet2.dll is used.\nbrowseURL() has been updated to work with Firefox 36.0 which has\ndropped support for the -remote interface.\n\n\nINSTALLATION and INCLUDED SOFTWARE\nThe included version of PCRE has been updated to 8.36.\nconfigure accepts MAKEINFO=texi2any as another way to ensure\ntexinfo 5.x is used when both 5.x and 4.x are installed.\n\n\nUTILITIES\nR CMD check now checks the packages used in donttest sections of\nthe examples are specified in the DESCRIPTION file. (These are\nneeded to run the examples interactively.)\nR CMD check checks for the undeclared use of GNU extensions in\nMakefiles, and for Makefiles with a missing final linefeed.\nR CMD build will correct line endings in all Makefiles, not just\nthose in the src directory.\nR CMD check notes uses of library() and require() in package\ncode: see the section ‘Suggested packages’ of ‘Writing R Extensions’\nfor good practice.\n\n\nDEPRECATED AND DEFUNCT\nThe configure option –with-valgrind-instrumentation=3 is\ndeprecated and will be removed in R 3.2.0.\n\n\nBUG FIXES\n(Windows.) Rscript.exe was missing a manifest specifying the\nmodern style for common controls (e.g., the download progress bar).\nIf a package had extra documentation files but no vignette, the HTML\nhelp system produced an empty index page.\nThe parser now gives an error if a null character is included in a\nstring using Unicode escapes. ()\nqr.Q() failed on complex arguments due to pre-3.0(!) typo. ()\nabs() failed with named arguments when the argument was complex.\n()\n\"noquote\" objects may now be used as columns in data frames. ()\nSome values with extremely long names were printed incorrectly. ()\nExtremely large exponents on zero expressed in scientific notation\n(e.g. 0.0e50000) could give NaN. ()\ndownload.file() reported downloaded sizes as 0KB if less than 1MB,\nonly for R 3.1.2 and only on big-endian platforms.\nprompt() did not escape percent signs in the automatically\ngenerated usage section of help files.\ndrop.terms() dropped some of the attributes of the object it was\nworking with. ()\n(Windows.) The command completion in Rgui.exe messed up the\nconsole. ()\n(Windows.) The choose.files() command returned a blank string when\nthe user asked for a single file but cancelled the request. ()\nMath2 S4 group generics failed to correctly dispatch\n\"structure\"- and \"nonStructure\"-derived classes.\nloadNamespace() imposed undocumented restrictions on the\nversionCheck parameter. (Reported by Geoff Lee.)\nRare over-runs detected by AddressSanitizer in substr() and its\nreplacement version have been avoided.\nInter alia that fix gives the documented behaviour for\nsubstr(x, 1, 2) <- \"\" (subsequently reported as ).\nLoading packages incorrectly defining an S4 generic followed by a\nfunction of the same name caused an erroneous cyclic namespace\ndependency error.\nDeclared vignette encodings are now always passed to the vignette\nengine.\nPort Tomas Kalibera’s fix from R-devel that restores the\nloadMethod() fast path, effectively doubling the speed of S4\ndispatch.\npower.t.test() and power.prop.test() now make use of the\nextendInt option of uniroot() and hence work in more extreme\ncases. ()\nIf a package was updated and attached when its namespace was already\nloaded, it could end up with parts from one version and parts from\nthe other. ()\ntools:::.Rdconv() didn’t accept –encoding= due to a typo. ()\nUnix-alike builds without a suitable makeinfo were documented to\nlink the missing HTML manuals to CRAN, but did not.\nsave(*, ascii=TRUE) and load() now correctly deal with NaN’s.\n()\nsplit.Date() retains fractional representations while avoiding\nincomplete class propagation.\nR_ext/Lapack.h had not been updated for changes made by LAPACK to\nthe argument lists of its (largely internal) functions dlaed2 and\ndlaed3. ()\nRShowDoc(\"NEWS\", \"txt\") had not been updated for the layout\nchanges of R 3.1.0.\nThe xtfrm() method for class \"Surv\" has been corrected and its\ndescription expanded.\nmode(x) <- y would incorrectly evaluate x before changing its\nmode. ()\nbesselJ(1, 2^64) and besselY(..) now signal a warning, returning\nNaN instead of typically segfaulting. (Issue 3 of )\nHTML conversion of href markup in .Rd files did not remove the\nbackslash from % and so gave an invalid URL. In a related change,\nthe escape is now required in such URLs.\n\n\n\nCHANGES IN R 3.1.2\n\nNEW FEATURES\nembedFonts() now defaults to format = \"ps2write\" for .ps and\n.eps files. This is available in Ghostscript 9.x (since 2010)\nwhereas the previous default, format = \"pswrite\", was removed in\nGhostscript 9.10.\nFor consistency with [dpqr]norm(), [dp]lnorm(sdlog = 0) model a\npoint mass at exp(mulog) rather than return NaN (for an error).\ncapabilities() now reports if ICU is compiled in for use for\ncollation (it is only actually used if a suitable locale is set for\ncollation, and never for a C locale).\n(OS X only.) Package tcltk checks when loaded if it is linked\nagainst the CRAN X11-based Tcl/Tk and if so that the Tcl/Tk\ncomponent and the X11 libraries are installed. This allows more\ninformative error messages to be given advising the installation of\nthe missing component or of XQuartz.\nThe X11() device and X11-based versions of the data editor and\nviewer (invoked by edit() and View() for data frames and\nmatrices from command-line R) check that the X11 libraries are\ninstalled and if not advises installing XQuartz.\nicuSetCollate() allows locale = \"default\", and locale = \"none\"\nto use OS services rather than ICU for collation.\nEnvironment variable R_ICU_LOCALE can be used to set the default\nICU locale, in case the one derived from the OS locale is\ninappropriate (this is currently necessary on Windows).\nNew function icuGetCollate() to report on the ICU collation locale\nin use (if any).\nutils::URLencode() was updated to use unreserved and reserved\ncharacters from RFC 3986 (http://tools.ietf.org/html/rfc3986)\ninstead of RFC 1738.\nunique(warnings()) and c(warnings()) are now supported.\nThe Bioconductor ‘version’ used by setRepositories() now defaults\nto 3.0. (It can be set at runtime via environment variable\nR_BIOC_VERSION.)\nOmegahat is no longer listed as providing Windows binary packages,\ne.g. by setRepositories(). It has no binary packages available for\nR 3.1.x and those for earlier versions were 32-bit only.\n\n\nINSTALLATION and INCLUDED SOFTWARE\nThe configure script reports on the more important\ncapabilities/options which will not be compiled in.\nMore types of external BLAS are recognized by name in that report.\nWhen building R as a shared library, the -L${R_HOME}/lib${R_ARCH}\nflag is placed earlier in the link commands used during installation\nand when packages are installed: this helps ensure that the current\nbuild has priority if an R shared library has already been installed\nby e.g. install-libR in a library mentioned in LDFLAGS (and not\nin ‘your system’s library directory’ as documented). (Wish of .)\nLaTeX package upquote is no longer required for R’s use of\ninconsolata.\n(Windows only) If both 32- and 64-bit versions of R are installed,\nthe bin/R.exe and bin/Rscript.exe executables now run 64-bit R.\n(To run 32-bit R, overwrite these files with copies of\nbin/i386/Rfe.exe.)\n\n\nUTILITIES\nRunning R CMD check with _R_CHECK_DEPENDS_ONLY_ true now makes\nthe VignetteBuilder packages available even if they are listed in\nSuggests, since they are needed to recognise and process\nnon-Sweave vignettes.\nR CMD check now reports empty importFrom declarations in a\nNAMESPACE file, as these are common errors (writing\nimportFrom(``Pkg``) where import(``Pkg``) was intended).\nR CMD check now by default checks code usage directly on the\npackage namespace without loading and attaching the package and its\nsuggests and enhances. For good practice with packages in the\nSuggests field, see §1.1.3.1 of ‘Writing R Extensions’. For use of\nlazy-data objects in the package’s own code, see ?data.\n\n\nBUG FIXES\ndmultinom() did not handle non-finite probabilities correctly.\nprettyNum(x, zero.print=*) now also works when x contains NAs.\nA longstanding bug exhibited by nlminb() on Windows was traced to\na compiler bug in gcc 4.6.3; a workaround has been put in place. (\nand ).\nRendering of command in HTML versions of help pages has been\nimproved: this is particularly evident on the help page for\nINSTALL.\nas.hexmode(x) and as.octmode(x) now behave correctly for some\nnumeric x, e.g., c(NA, 1) or c(1, pi).\ndrop1() failed if the scope argument had no variables to drop.\n()\nedit() (and hence fix()) failed if an object had a non-character\nattribute named \"source\" (an attribute that had been used in R\nprior to version 2.14.0).\ncallGeneric() could fail if the generic had ... as a formal\nargument. ().\nForking in package parallel called C entry point exit in the\nchild. This was unsafe (_exit should have been called), and could\nflush stdin of the main R process (seen most often on Solaris).\nAs good practice, stdout is now flushed before forking a child.\nR objects such as list(‘ab‘ = 1) now print correctly.\ngetAnywhere(\"C_pbinom\") now returns correctly a single object\n(rather than unlisting it).\nThe confint() method for nls() fits failed it these has\nspecified parameter limits despite using an algorithm other than\n\"port\". ()\nSubclassing an S4 class failed if the class required arguments to\nthe generator, through its initialize() method.\nremoveSource() did not properly handle expressions containing\narguments that were supplied as missing, e.g. x[i,]. ()\nas.environment(list()) now works, and as.list() of such an\nenvironment is now the same as list(). ()\nSeveral tcltk functions failed when run in unusual environments.\n()\noptions(list()) now works (trivially). ()\nmerge(<dendrogram>, ..) now works correctly for two ‘independent’\ndendrograms (), and still compatibly via adjust = \"auto\" e.g.\nfor two branches of an existing dendrogram.\nThe plot method for \"hclust\" objects gets an optional argument\ncheck; when that is true (the default) it checks more carefully\nfor valid input.\n(Windows only) If a user chose to install 64 bit R but not 32 bit R,\nthe bin/R and bin/Rscript executables failed to run. ()\nVarious possible buffer overruns have been prevented, and missed\nmemory protection added. ()\nRscript no longer passes –args to R when there are no extra\n(“user”) arguments.\nobjects like getClass(\"refClass\")@prototype now print() and\nstr() without error.\nidentical() now also looks at the S4 bit.\nhist(x, breaks) is more robust in adding a small fuzz to few\nbreaks when some are very large. ()\nsub() and gsub() did not handle regular expressions like\n\"s{2,}\" properly if the text contained NA or non-ASCII elements\nin a UTF-8 locale. Part of this was due to a bug in the TRE library.\n()\nRShowDoc(\"NEWS\") now displays the PDF version.\nMatrices and arrays with last dimension zero did not print at all or\nincompletely. ()\nplot.histogram() and hence hist() now respect the xaxs, yaxs\nand lab graphics parameters. ()\nbw.SJ(x) and other bw.*() no longer segfault when x contains\nnon-finite values. ()\nR CMD Rd2pdf unintentionally ignored its –os option.\nThe internal method of download.file() was not reporting file\nsizes and progress correctly on files larger than 2GB (inherited\nfrom libxml2). This is corrected for 64-bit builds (32-bit\nplatforms may not support such files, but where possible will be\nsupported in future versions of R).\nWork around a bug in OS X Yosemite where key environment variables\nmay be duplicated causing issues in subprocesses. The duplicates are\nnow removed on R startup (via Rprofile). ()\nAdjust X11 auto-launch detection in DISPLAY on OS X to recognize\nlatest XQuartz.\n\n\n\nCHANGES IN R 3.1.1\n\nNEW FEATURES\nWhen attach() reports conflicts, it does so compatibly with\nlibrary() by using message().\nR CMD Sweave no longer cleans any files by default, compatibly\nwith versions of R prior to 3.1.0. There are new options –clean,\n–clean=default and –clean=keepOuts.\ntools::buildVignette() and tools::buildVignettes() with\nclean = FALSE no longer remove any created files.\nbuildvignette() gains a keep argument for more cleaning\ncustomization.\nThe Bioconductor ‘version’ used by setRepositories() can now be\nset by environment variable R_BIOC_VERSION at runtime, not just\nwhen R is installed. (It has been stated that Bioconductor will\nswitch from ‘version’ 2.14 to ‘version’ 3.0 during the lifetime of\nthe R 3.1 series.)\nError messages from bugs in embedded Sexpr code in Sweave\ndocuments now report the source location.\ntype.convert(), read.table() and similar read.*() functions\nget a new numerals argument, specifying how numeric input is\nconverted when its conversion to double precision loses accuracy.\nThe default value, \"allow.loss\" allows accuracy loss, as in R\nversions before 3.1.0.\nFor some compilers, integer addition could overflow without a\nwarning. R’s internal code for both integer addition and subtraction\nis more robust now. ()\nThe function determining the default number of knots for\nsmooth.spline() is now exported, as .nknots.smspl().\ndbeta(, a,b), pbeta(), qbeta() and rbeta() are now defined\nalso for , , or infinite and (where they typically returned NaN\nbefore).\nMany package authors report that the RStudio graphics device does\nnot work correctly with their package’s use of dev.new(). The new\noption dev.new(noRStudioGD = TRUE) replaces the RStudio override\nby the default device as selected by R itself, still respecting\nenvironment variables R_INTERACTIVE_DEVICE and R_DEFAULT_DEVICE.\nreadRDS() now returns visibly.\nModifying internal logical scalar constants now results in an error\ninstead of a warning.\ninstall.packages(repos = NULL) now accepts http:// or ftp://\nURLs of package archives as well as file paths, and will download as\nrequired. In most cases repos = NULL can be deduced from the\nextension of the URL.\nThe warning when using partial matching with the $ operator on\ndata frames is now only given when\noptions(\"warnPartialMatchDollar\") is TRUE.\nPackage help requests like package?foo now try the package foo\nwhether loaded or not.\nGeneral help requests now default to trying all loaded packages, not\njust those on the search path.\nAdded a new function promptImport(), to generate a help page for a\nfunction that was imported from another package (and presumably\nre-exported, or help would not be needed).\n\n\nINSTALLATION and INCLUDED SOFTWARE\nconfigure option –with-internal-tzcode can now be used with\nvariable rsharedir.\nThe included version of PCRE has been updated to 8.35.\nThere is a new target make uninstall-libR to remove an installed\nshared/static libR.\nmake install-libR now works if a sub-architecture is used,\nalthough the user will need to specify libdir differently for\ndifferent sub-architectures.\nThere is more extensive advice on which LaTeX packages are required\nto install R or to make package manuals (as done by R CMD check)\nin the ‘Writing R Extensions’ manual.\nCompilers/linkers were handling the visibility control in\nsrc/extra/xz inconsistently (and apparently in some cases\nincorrectly), so it has been simplified. ()\n(Windows) There is updated support for the use of ICU for collation:\nsee the ‘R Installation and Administration Manual’.\n\n\nBUG FIXES\ndbinom(x, n), pbinom(), dpois(), etc, are slightly less\nrestrictive in checking if n is integer-valued. (Wish of .)\npchisq(x, df, ncp, log.p = TRUE) is more accurate and no longer\nunderflows for small x and ncp < 80, e.g, for\npchisq(1e-5, df = 100, ncp = 1, log = TRUE). (Based on and a\nsuggestion by Roby Joehanes.)\nThe s (“step into”) command in the debugger would cause R to step\ninto expressions evaluated there, not just into functions being\ndebugged. ()\nThe C code used by strptime() rejected time-zone offsets of more\nthan +1200 (+1245, +1300 and +1400 can occur). ()\n(Windows only.) png(type = \"cairo\", antialias = \"gray\") was not\naccepted. ()\nUse of save(..., envir=) with named objects could fail. ()\nSweave() mis-parsed Sexpr expressions that contained\nbackslashes. ()\nThe return value from options(foo = NULL) was not the previous\nvalue of the option. ()\nenc2utf8() and enc2native() did not always mark the encoding of\nthe return values when it was known.\ndnbinom(x, size = <large>, mu, log = TRUE) no longer underflows to\n-Inf for large mu, thanks to a suggestion from Alessandro Mammana\n(MPI MolGen, Berlin).\npbeta(x, a, b, log = TRUE) no longer behaves discontinuously (in a\nsmall x-region) because of denormalized numbers. Also,\npbeta(1-1e-12, 1e30, 1.001, log=TRUE) now terminates “in real\ntime”.\nThe \"CRAN\" filter (see available.packages()) no longer removes\nduplicates other than of packages on CRAN, and does not fail if\nthere is no CRAN repository in getOption(\"repos\").\nThe device listing from dev2bitmap() and bitmap() was truncated\nto 1000 characters: modern versions of GhostScript on most platforms\nhave many more devices.\n(Windows.) Commands such as Sys.which() and pipe() which needed\nto find the full path to a command could segfault if the ‘long’ path\nname was much longer than the ‘short’ path name (which Sys.which()\nreturns), as the behaviour of the Windows API call had changed.\nR CMD build will fail with an error if one of the packages\nspecified in the VignetteBuilder field is not installed. (Without\nloading those packages it cannot be ascertained which files are\nintended to be vignettes. This means that the VignetteBuilder\npackages have to be installed for package checking too.) (Wish of .)\nMisguided attempts to use chull() with non-finite points now give\nan error (related to ).\nFor a formula with exactly 32 variables the 32nd variable was\naliased to the intercept in some C-level computations of terms, so\nthat for example attempting to remove it would remove the intercept\ninstead (and leave a corrupt internal structure). ()\nanyDuplicated() silently returned wrong values when the first\nduplicate was at an index which was too large to be stored in an\ninteger vector (although a lot of RAM and patience would have been\nneeded to encounter this).\ntools::Rd2ex(commentDontrun = FALSE) failed if the block had only\none line.\nHexadecimal constants such as 0x110p-5L which were incorrectly\nqualified by L were parsed incorrectly since R 3.0.0, with a\nslightly garbled warning. ()\nsystem() returned success on some platforms even if the system was\nunable to launch a process. ()\n(Windows Rgui console.) Unbuffered output was sometimes not output\nimmediately if the prompt was not on the last line of the console.\nThe built-in help server did not declare the encoding for the\nDESCRIPTION or other text files to be the package encoding, so\nnon-ASCII characters could be displayed incorrectly.\nR is now trying harder to not cleanup child processes that were not\nspawned by mcparallel() on platforms that provide information\nabout the source process of the SIGCHLD signal. This allows 3rd\nparty libraries to manage the exit status of children that they\nspawn without R interfering.\nmcmapply() was only parallelizing if the number of jobs was bigger\nthan the number of cores. It now parallelizes if the number of jobs\nis more than one.\nAuto-printing would re-evaluate its argument when trying to dispatch\nto a print method. This is now avoided when possible.\nUnserializing (including load() and readRDS()) could silently\nreturn incorrect numeric values from ASCII saves if there was a read\nerror.\ngetParseData() could return incorrect values for the parents of\nsome elements. (Reported by Andrew Redd.)\nAttempting to use data frames of 2^31 or more rows with merge()\nor to create a merged data frame of that size now gives a clearer\nerror message.\nparse() did not check its file argument was a connection if it\nwas not a character string, so e.g. parse(FALSE) attempted to read\nfrom stdin.\nNor did dump() and dput().\nThe \"help.try.all.packages\" option was ignored when the shortcut\nsyntax for help was used, e.g. ?foo.\nA potential segfault in string allocation has been fixed. (Found by\nRadford Neal.)\nPotential memory protection errors in sort() and D() have been\nfixed. (Found by Radford Neal.)\nFixed a lack of error checking in graphics event functions. (Found\nby Radford Neal; a different patch used here than the one in pqR.)\nnumericDeriv() sometimes miscalculated the gradient. (, reported\noriginally by Radford Neal)\n\n\n\nCHANGES IN R 3.1.0\n\nNEW FEATURES\ntype.convert() (and hence by default read.table()) returns a\ncharacter vector or factor when representing a numeric input as a\ndouble would lose accuracy. Similarly for complex inputs.\nIf a file contains numeric data with unrepresentable numbers of\ndecimal places that are intended to be read as numeric, specify\ncolClasses in read.table() to be \"numeric\".\ntools::Rdiff(useDiff = FALSE) is closer to the POSIX definition of\ndiff -b (as distinct from the description in the man pages of\nmost systems).\nNew function anyNA(), a version of any(is.na(.)) which is fast\nfor atomic vectors, based on a proposal by Tim Hesterberg. (Wish of\n.)\narrayInd(*, useNames = TRUE) and, analogously,\nwhich(*, arr.ind = TRUE) now make use of names(.dimnames) when\navailable.\nis.unsorted() now also works for raw vectors.\nThe \"table\" method for as.data.frame() (also useful as\nas.data.frame.table()) now passes sep and base arguments to\nprovideDimnames().\nuniroot() gets new optional arguments, notably extendInt,\nallowing to auto-extend the search interval when needed. The return\nvalue has an extra component, init.it.\nswitch(f, ...) now warns when f is a factor, as this typically\nhappens accidentally where the useR meant to pass a character\nstring, but f is treated as integer (as always documented).\nThe parser has been modified to use less memory.\nThe way the unary operators (+ - !) handle attributes is now more\nconsistent. If there is no coercion, all attributes (including\nclass) are copied from the input to the result: otherwise only\nnames, dims and dimnames are.\ncolorRamp() and colorRampPalette() now allow non-opaque colours\nand a ramp in opacity via the new argument alpha = TRUE.\n(Suggested by Alberto Krone-Martins, but optionally as there are\nexisting uses which expect only RGB values.)\ngrid.show.layout() and grid.show.viewport() get an optional\nvp.ex argument.\nThere is a new function find_gs_cmd() in the tools package to\nlocate a GhostScript executable. (This is an enhanced version of a\npreviously internal function there.)\nobject.size() gains a format() method.\nThere is a new family, \"ArialMT\", for the pdf() and\npostscript() devices. This will only be rendered correctly on\nviewers which have access to Monotype TrueType fonts (which are\nsometimes requested by journals).\nThe text and PDF news files, including NEWS and NEWS.2, have\nbeen moved to the doc directory.\ncombn(x, simplify = TRUE) now gives a factor result for factor\ninput x (previously user error). (Related to .)\nAdded utils::fileSnapshot() and utils::changedFiles() functions\nto allow snapshots and comparison of directories of files.\nmake.names(names, unique=TRUE) now tries to preserve existing\nnames. (Suggestion of .)\nNew functions cospi(x), sinpi(x), and tanpi(x), for more\naccurate computation of cos(pi*x), etc, both in R and the C API.\nUsing these gains accuracy in some cases, e.g., inside lgamma() or\nbesselI(). (Suggested by Morten Welinder in .)\nprint.table(x, zero.print = \".\") now also has an effect when x\nis not integer-valued.\nThere is more support to explore the system’s idea of time-zone\nnames. Sys.timezone() tries to give the current system setting by\nname (and succeeds at least on Linux, OS X, Solaris and Windows),\nand OlsonNames() lists the names in the system’s Olson database.\nSys.timezone(location = FALSE) gives the previous behaviour.\nPlatforms with a 64-bit time_t type are allowed to handle\nconversions between the \"POSIXct\" and \"POSIXlt\" classes for\ndate-times outside the 32-bit range (before 1902 or after 2037): the\nexisting workarounds are used on other platforms. (Note that\ntime-zone information for post-2037 is speculative at best, and the\nOS services are tested for known errors and so not used on OS X.)\nCurrently time_t is usually long and hence 64-bit on Unix-alike\n64-bit platforms: however in several cases the time-zone database is\n32-bit. For R for Windows it is 64-bit (for both architectures as\nfrom this version).\nThe \"save.defaults\" option can include a value for\ncompression_level. (Wish of .)\ncolSums() and friends now have support for arrays and data-frame\ncolumns with or more elements.\nas.factor() is faster when f is an unclassed integer vector (for\nexample, when called from tapply()).\nfft() now works with longer inputs, from the 12 million previously\nsupported up to 2 billion. ()\nComplex svd() now uses LAPACK subroutine ZGESDD, the complex\nanalogue of the routine used for the real case.\nSweave now outputs .tex files in UTF-8 if the input encoding is\ndeclared to be UTF-8, regardless of the local encoding. The UTF-8\nencoding may now be declared using a LaTeX comment containing the\nstring %SweaveUTF8 on a line by itself.\nfile.copy() gains a copy.date argument.\nPrinting of date-times will make use of the time-zone abbreviation\nin use at the time, if known. For example, for Paris pre-1940 this\ncould be LMT, PMT, WET or WEST. To enable this, the\n\"POSIXlt\" class has an optional component \"zone\" recording the\nabbreviation for each element.\nFor platforms which support it, there is also a component \"gmtoff\"\nrecording the offset from GMT where known.\n(On Windows, by default on OS X and optionally elsewhere.) The\nsystem C function strftime has been replaced by a more\ncomprehensive version with closer conformance to the POSIX 2008\nstandard.\ndnorm(x, log = FALSE) is more accurate (but somewhat slower) for\n|x| > 5; as suggested in .\nSome versions of the tiff() device have further compression\noptions.\nread.table(), readLines() and scan() have a new argument to\ninfluence the treatment of embedded nuls.\nAvoid duplicating the right hand side values in complex assignments\nwhen possible. This reduces copying of replacement values in\nexpressions such as Z$a <- a0 and ans[[i]] <- tmp: some package\ncode has relied on there being copies.\nAlso, a number of other changes to reduce copying of objects; all\ncontributed by or based on suggestions by Michael Lawrence.\nThe fast argument of KalmanLike(), KalmanRun() and\nKalmanForecast() has been replaced by update, which instead of\nupdating mod in place, optionally returns the updated model in an\nattribute \"mod\" of the return value.\narima() and makeARIMA() get a new optional argument SSinit,\nallowing the choice of a different tate pace initialization which\nhas been observed to be more reliable close to non-stationarity: see\n.\nwarning() has a new argument noBreaks., to simplify\npost-processing of output with options(warn = 1).\npushBack() gains an argument encoding, to support reading of\nUTF-8 characters using scan(), read.table() and related\nfunctions in a non-UTF-8 locale.\nall.equal.list() gets a new argument use.names which by default\nlabels differing components by names (if they match) rather than by\ninteger index. Saved R output in packages may need to be updated.\nThe methods for all.equal() and attr.all.equal() now have\nargument check.attributes after ... so it cannot be partially\nnor positionally matched (as it has been, unintentionally).\nA side effect is that some previously undetected errors of passing\nempty arguments (no object between commas) to all.equal() are\ndetected and reported.\nThere are explicit checks that check.attributes is logical,\ntolerance is numeric and scale is NULL or numeric. This\ncatches some unintended positional matching.\nThe message for all.equal.numeric() reports a\n\"scaled difference\" only for scale != 1.\nall.equal() now has a \"POSIXt\" method replacing the \"POSIXct\"\nmethod.\nThe \"Date\" and \"POSIXt\" methods of seq() allows\nby = \"quarter\" for completeness (by = \"3 months\" always worked).\nfile.path() removes any trailing separator on Windows, where they\nare invalid (although sometimes accepted). This is intended to\nenhance the portability of code written by those using POSIX file\nsystems (where a trailing / can be used to confine path matching\nto directories).\nNew function agrepl() which like grepl() returns a logical\nvector.\nfifo() is now supported on Windows. ()\nsort.list(method = \"radix\") now allows negative integers (wish of\n).\nSome functionality of print.ts() is now available in\n.preformat.ts() for more modularity.\nmcparallel() gains an option detach = TRUE which allows\nexecution of code independently of the current session. It is based\non a new estranged = TRUE argument to mcfork() which forks child\nprocesses such that they become independent of the parent process.\nThe pdf() device omits circles and text at extremely small sizes,\nsince some viewers were failing on such files.\nThe rightmost break for the \"months\", \"quarters\" and \"years\"\ncases of hist.POSIXlt() has been increased by a day. (Inter alia,\nfixes .)\nThe handling of DF[i,] <- a where i is of length 0 is improved.\n(Inter alia, fixes .)\nhclust() gains a new method \"ward.D2\" which implements Ward’s\nmethod correctly. The previous \"ward\" method is \"ward.D\" now,\nwith the old name still working. Thanks to research and proposals by\nPierre Legendre.\nThe sunspot.month dataset has been amended and updated from the\nofficial source, whereas the sunspots and sunspot.year datasets\nwill remain immutable. The documentation and source links have been\nupdated correspondingly.\nThe summary() method for \"lm\" fits warns if the fit is\nessentially perfect, as most of the summary may be computed\ninaccurately (and with platform-dependent values).\nProgrammers who use summary() in order to extract just a component\nwhich will be reliable (e.g., $cov.unscaled) should wrap their\ncalls in suppressWarnings().\n\n\nINSTALLATION and INCLUDED SOFTWARE\nThe included version of LAPACK has been updated to 3.5.0.\nThere is some support for parallel testing of an installation, by\nsetting TEST_MC_CORES to an integer greater than one to indicate\nthe maximum number of cores to be used in parallel. (It is worth\nspecifying at least 8 cores if available.) Most of these require a\nmake program (such as GNU make and dmake) which supports the\n$MAKE -j nproc syntax.\nExcept on Windows: the tests of standard package examples in\nmake check are done in parallel. This also applies to running\ntools::testInstalledPackages().\nThe more time-consuming regression tests are done in parallel.\nThe package checks in make check-devel and\nmake check-recommended are done in parallel.\nMore of make check will work if recommended packages are not\ninstalled: but recommended packages remain needed for thorough\nchecking of an R build.\nThe version of tzcode included in src/extra/tzone has been\nupdated. (Formerly used only on Windows.)\nThe included (64-bit) time-zone conversion code and Olson time-zone\ndatabase can be used instead of the system version: use configure\noption –with-internal-tzcode. This is the default on Windows and\nOS X. (Note that this does not currently work if a non-default\nrsharedir configure variable is used.)\n(It might be necessary to set environment variable TZ on OSes\nwhere this is not already set, although the system timezone is\ndeduced correctly on at least Linux, OS X and Windows.)\nThis option also switches to the version of strftime included in\ndirectory src/extra/tzone.\nconfigure now tests for a C++11-compliant compiler by testing some\nbasic features. This by default tries flags for the compiler\nspecified by CXX, but an alternative compiler, options and\nstandard can be specified by variables CXX1X, CXX1XFLAGS and\nCXX1XSTD (e.g., -std=gnu++11).\nR can now optionally be compiled to use reference counting instead\nof the NAMED mechanism by defining SWITCH_TO_REFCNT in\nRinternals.h. This may become the default in the future.\nThere is a new option –use-system-tre to use a suitable system\ntre library: at present this means a version from their git\nrepository, after corrections. (Wish of .)\n\n\nPACKAGE INSTALLATION\nThe CRANextra repository is no longer a default repository on\nWindows: all the binary versions of packages from CRAN are now on\nCRAN, although CRANextra contains packages from Omegahat and\nelsewhere used by CRAN packages.\nOnly vignettes sources in directory vignettes are considered to be\nvignettes and hence indexed as such.\nIn the DESCRIPTION file,\nX11\nis no longer recognized as valid. Use MIT or BSD_2_clause\ninstead, both of which need + file LICENSE.\nFor consistency, entries in .Rinstignore are now matched\ncase-insensitively on all platforms.\nHelp for S4 methods with very long signatures now tries harder to\nsplit the description in the Usage field to no more than 80\ncharacters per line (some packages had over 120 characters).\nR CMD INSTALL –build (not Windows) now defaults to the internal\ntar() unless R_INSTALL_TAR is set.\nThere is support for compiling C++11 code in packages on suitable\nplatforms: see ‘Writing R Extensions’.\nFake installs now install the contents of directory inst: some\npackages use this to install e.g. C++ headers for use by other\npackages that are independent of the package itself. Option\n–no-inst can be used to get the previous behaviour.\n\n\nDEBUGGING\nThe behaviour of the code browser has been made more consistent, in\npart following the suggestions in .\nCalls to browser() are now consistent with calls to the browser\ntriggered by debug(), in that will default to n rather than c.\nA new browser command s has been added, to “step into” function\ncalls.\nA new browser command f has been added, to “finish” the current\nloop or function.\nWithin the browser, the command help will display a short list of\navailable commands.\n\n\nUTILITIES\nOnly vignettes sources in directory vignettes are considered to be\nvignettes by R CMD check. That has been the preferred location\nsince R 2.14.0 and is now obligatory.\nFor consistency, R CMD build now matches entries in\n.Rbuildignore and vignettes/.install_extras case-insensitively\non all platforms (not just on Windows).\ncheckFF() (called by R CMD check by default) can optionally\ncheck foreign function calls for consistency with the registered\ntype and argument count. This is the default for\nR CMD check –as-cran or can be enabled by setting environment\nvariable _R_CHECK_FF_CALLS_ to registration (but is in any case\nsuppressed by –install=no). Because this checks calls in which\n.NAME is an R object and not just a literal character string, some\nother problems are detected for such calls.\nFunctions suppressForeignCheck() and dontCheck() have been added\nto allow package authors to suppress false positive reports.\nR CMD check –as-cran warns about a false value of the\nDESCRIPTION field BuildVignettes for Open Source packages, and\nignores it. (An Open Source package needs to have complete sources\nfor its vignettes which should be usable on a suitably well-equipped\nsystem).\nR CMD check –no-rebuild-vignettes is defunct:R CMD check –no-build-vignettes has been preferred since R 3.0.0.\nR CMD build –no-vignettes is defunct:R CMD build –no-build-vignettes has been preferred since R 3.0.0.\nR CMD Sweave and R CMD Stangle now process both Sweave and\nnon-Sweave vignettes. The tools::buildVignette() function has been\nadded to do the same tasks from within R.\nThe flags returned by R CMD config –ldflags and (where installed)\npkg-config –libs libR are now those needed to link a front-end\nagainst the (shared or static) R library.\nSweave.sty has a new option [inconsolata].\nR CMD check customizations such as _R_CHECK_DEPENDS_ONLY_ make\navailable packages only in LinkingTo only for installation, and\nnot for loading/runtime tests.\ntools::checkFF() reports on .C and .Fortran calls with\nDUP = FALSE if argument check_DUP is true. This is selected by\nR CMD check by default.\nR CMD check –use-gct can be tuned to garbage-collect less\nfrequently using gctorture2() via the setting of environment\nvariable _R_CHECK_GCT_N_.\nWhere supported, tools::texi2dvi() limits the number of passes\ntried to 20.\n\n\nC-LEVEL FACILITIES\n(Windows only) A function R_WaitEvent() has been added (with\ndeclaration in headerR.h) to block execution until the next event\nis received by R.\nRemapping in the Rmath.h header can be suppressed by defining\nR_NO_REMAP_RMATH.\nThe remapping of rround() in header Rmath.h has been removed:\nuse fround() instead.\nftrunc() in header Rmath.h is now a wrapper for the C99 function\ntrunc(), which might as well be used in C code: ftrunc() is\nstill needed for portable C++ code.\nThe never-documented remapping of prec() to fprec() in header\nRmath.h has been removed.\nThe included LAPACK subset now contains ZGESDD and ZGELSD.\nThe function LENGTH() now checks that it is only applied to vector\narguments. However, in packages length() should be used. (In R\nitself LENGTH() is a macro without the function overhead of\nlength().)\nCalls to SET_VECTOR_ELT() and SET_STRING_ELT() are now checked\nfor indices which are in-range: several packages were writing one\nelement beyond the allocated length.\nallocVector3 has been added which allows custom allocators to be\nused for individual vector allocations.\n\n\nDEPRECATED AND DEFUNCT\nchol(pivot = TRUE, LINPACK = TRUE) is defunct.\nArguments EISPACK for eigen() and LINPACK for chol(),\nchol2inv(), solve() and svd() are ignored: LAPACK is always\nused.\n.find.package() and .path.package() are defunct: only the\nversions without the initial dot introduced in R 2.13.0 have ever\nbeen in the API.\nPartial matching when using the $ operator on data frames now\nthrows a warning and may become defunct in the future. If partial\nmatching is intended, replace foo$bar by\nfoo[[\"bar\", exact = FALSE]].\nThe long-deprecated use of synopsis in the Usage section of\n.Rd files has been removed: such sections are now ignored (with a\nwarning).\npackage.skeleton()’s deprecated argument namespace has been\nremoved.\nMany methods are no longer exported by package stats. They are all\nregistered on their generic, which should be called rather than\ncalling a method directly.\nFunctions readNEWS() and checkNEWS() in package tools are\ndefunct.\ndownload.file(method = \"lynx\") is deprecated.\n.C(DUP = FALSE) and .Fortran(DUP = FALSE) are now deprecated,\nand may be disabled in future versions of R. As their help has long\nsaid, .Call() is much preferred.\nR CMD check notes such usages (by default).\nThe workaround of setting R_OSX_VALGRIND has been removed: it is\nnot needed in current valgrind.\n\n\nBUG FIXES\nCalling lm.wfit() with no non-zero weights gave an array-overrun\nin the Fortran code and a not very sensible answer. It is now\nspecial-cased with a simpler answer (no qr component).\nError messages involving non-syntactic names (e.g., as produced by\n‘r‘ when that object does not exist) now encode the control\ncharacters. (Reported by Hadley Wickham.)\ngetGraphicsEvent() caused 100% usage of one CPU in Windows. ()\nnls() with no start argument may now work inside another\nfunction (scoping issue).\npbeta() and similar work better for very large (billions) ncp.\nWhere time zones have changed abbreviations over the years, the\nsoftware tries to more consistently use the abbreviation appropriate\nto the time or if that is unknown, the current abbreviation. On some\nplatforms where the C function localtime changed the tzname\nvariables the reported abbreviation could have been that of the last\ntime converted.\nall.equal(list(1), identity) now works.\nBug fix for pushing viewports in grid (reported by JJ Allaire and\nKevin Ushey).\nNOTE for anyone poking around within the graphics engine display\nlist (despite the warnings not to) that this changes what is\nrecorded by grid on the graphics engine display list.\nExtra checks have been added for unit resolution and conversion in\ngrid, to catch instances of division-by-zero. This may introduce\nerror messages in existing code and/or produce a different result in\nexisting code (but only where a non-finite location or dimension may\nnow become zero).\nSome bugs in TRE have been corrected by updating from the git\nrepository. This allows R to be installed on some platforms for\nwhich this was a blocker ( suggests Linux on ARM and HP-UX).\n? applied to a call to an S4 generic failed in several cases. ()\nThe implicit S4 generics for primitives with ... in their argument\nlist were incorrect. ()\nBug fixes to methods::callGeneric(). ()\nThe bug fix to aggregrate() in introduced a new bug in the case of\nno grouping variables. ()\nIn rare cases printing deeply nested lists overran a buffer by one\nbyte and on a few platforms segfaulted. ()\nThe dendrogram method of as.dendrogram() was hidden accidentally,\n(), and order.dendrogram(d) gave too much for a leaf d. ()\nR would try to kill processes on exit that have pids ever used by a\nchild process spawned by mcparallel even though the current\nprocess with that pid was not actually its child.\ncophenetic() applied to a \"dendrogram\" object sometimes\nincorrectly returned a \"Labels\" attribute with dimensions. ()\nprintCoefmat() called from quite a few print() methods now obeys\nsmall getOption(\"width\") settings, line wrapping the\n\"signif. codes\" legend appropriately. ()\nmodel.matrix() assumed that the stored dimnames for a matrix was\nNULL or length 2, but length 1 occurred.\nThe clipping region for a device was sometimes used in base graphics\nbefore it was set.\n\n\n\nCHANGES IN R 3.0.3\n\nNEW FEATURES\nOn Windows there is support for making .texi manuals using\ntexinfo 5.0 or later: the setting is in file\nsrc/gnuwin32/MkRules.dist.\nA packaging of the Perl script and modules for texinfo 5.2 has\nbeen made available at http://www.stats.ox.ac.uk/pub/Rtools/.\nwrite.table() now handles matrices of or more elements, for those\nwith large amounts of patience and disc space.\nThere is a new function, La_version(), to report the version of\nLAPACK in use.\nThe HTML version of ‘An Introduction to R’ now has links to PNG\nversions of the figures.\nThere is some support to produce manuals in ebook formats. (See\ndoc/manual/Makefile. Suggested by Mauro Cavalcanti.)\nOn a Unix-alike Sys.timezone() returns NA if the environment\nvariable TZ is unset, to distinguish it from an empty string which\non some OSes means the UTC time zone.\nThe backtick may now be escaped in strings, to allow names\ncontaining them to be constructed, e.g. ‘“. ()\nread.table(), readLines() and scan() now warn when an embedded\nnul is found in the input. (Related to which was puzzled by the\nbehaviour in this unsupported case.)\n(Windows only.) file.symlink() works around the undocumented\nrestriction of the Windows system call to backslashes. (Wish of .)\nKalmanForecast(fast = FALSE) is now the default, and the help\ncontains an example of how fast = TRUE can be used in this\nversion. (The usage will change in 3.1.0.)\nstrptime() now checks the locale only when locale-specific formats\nare used and caches the locale in use: this can halve the time taken\non OSes with slow system functions (e.g., OS X).\nstrptime() and the format() methods for classes \"POSIXct\",\n\"POSIXlt\" and \"Date\" recognize strings with marked encodings:\nthis allows, for example, UTF-8 French month names to be read on\n(French) Windows.\niconv(to = \"utf8\") is now accepted on all platforms (some\nimplementations did already, but GNU libiconv did not: however\nconverted strings were not marked as being in UTF-8). The official\nname, \"UTF-8\" is still preferred.\navailable.packages() is better protected against corrupt metadata\nfiles. (A recurring problem with Debian package shogun-r: .)\nFinalizers are marked to be run at garbage collection, but run only\nat a somewhat safer later time (when interrupts are checked). This\ncircumvents some problems with finalizers running arbitrary code\nduring garbage collection (the known instances being running\noptions() and (C-level) path.expand() re-entrantly).\n\n\nINSTALLATION and INCLUDED SOFTWARE\nThe included version of PCRE has been updated to 8.34. This fixes\nbugs and makes the behaviour closer to Perl 5.18. In particular, the\nconcept of ‘space’ includes VT and hence agrees with POSIX’s.\n\n\nPACKAGE INSTALLATION\nThe new field SysDataCompression in the DESCRIPTION file allows\nuser control over the compression used for sysdata.rda objects in\nthe lazy-load database.\ninstall.packages(dependencies = value) for value = NA (the\ndefault) or value = TRUE omits packages only in LinkingTo for\nbinary package installs.\n\n\nC-LEVEL FACILITIES\nThe long undocumented remapping of rround() to Rf_fround() in\nheader Rmath.h is now formally deprecated: use fround()\ndirectly.\nRemapping of prec() and trunc() in the Rmath.h header has been\ndisabled in C++ code (it has caused breakage with libc++ headers).\n\n\nBUG FIXES\ngetParseData() truncated the imaginary part of complex number\nconstants. (Reported by Yihui Xie.)\ndbeta(x, a, b) with a or b within a factor of 2 of the largest\nrepresentable number could infinite-loop. (Reported by Ioannis\nKosmidis.)\nprovideDimnames() failed for arrays with a 0 dimension. ()\nrbind() and cbind() did not handle list objects correctly. ()\nreplayPlot() now checks if it is replaying a plot from the same\nsession.\nrasterImage() and grid.raster() now give error on an empty\n(zero-length) raster. (Reported by Ben North.)\nplot.lm() would sometimes scramble the labels in plot type 5. (\nand )\nmin() did not handle NA_character_ values properly. (Reported by\nMagnus Thor Torfason.)\n(Windows only.) readRegistry() would duplicate default values for\nkeys. ()\nstr(..., strict.width = \"cut\") did not handle it properly when\nmore than one line needed to be cut. (Reported by Gerrit Eichner.)\nRemoving subclass back-references when S4 classes were removed or\ntheir namespace unloaded had several bugs (e.g., ).\naggregate() could fail when there were too many levels present in\nthe by argument. ()\nnamespaceImportFrom() needed to detect primitive functions when\nchecking for duplicated imports (reported by Karl Forner).\ngetGraphicsEvent() did not exit when a user closed the graphics\nwindow. ()\nErrors in vignettes were not always captured and displayed properly.\n()\ncontour() could fail when dealing with extremely small z values.\n()\nSeveral functions did not handle zero-length vectors properly,\nincluding browseEnv(), format(), gl(), relist() and\nsummary.data.frame(). (E.g., )\nSweave() did not restore the R output to the console if it was\ninterrupted by a user in the middle of evaluating a code chunk.\n(Reported by Michael Sumner.)\nFake installs of packages with vignettes work again.\nIllegal characters in the input caused parse() (and thus\nsource()) to segfault. ()\nThe nonsensical use of nmax = 1 in duplicated() or unique() is\nnow silently ignored.\nqcauchy(p, *) is now fully accurate even when p is very close\nto 1. ()\nThe validmu() and valideta() functions in the standard glm()\nfamilies now also report non-finite values, rather than failing.\nSaved vignette results (in a .Rout.save file) were not being\ncompared to the new ones during R CMD check.\nDouble-clicking outside of the list box (e.g., on the scrollbar) of\na Tk listbox widget generated by tk_select.list() no longer causes\nthe window to close. ()\nImproved handling of edge cases in parallel::splitindices(). ()\nHTML display of results from help.search() and ?? sometimes\ncontained badly constructed links.\nc() and related functions such as unlist() converted raw vectors\nto invalid logical vectors. ()\n(Windows only) When a call to system2() specified one of stdin,\nstdout or stderr to be a file, but the command was not found\n(e.g., it contained its arguments, or the program was not on the\nPATH), it left the file open and unusable until R terminated.\n(Reported by Mathew McLean.)\nThe bmp() device was not recording res = NA correctly: it is now\nrecorded as 72 ppi.\nSeveral potential problems with compiler-specific behaviour have\nbeen identified using the ‘Undefined Behaviour Sanitizer’ in\nconjunction with the clang compiler.\nhcl() now honours NA inputs (previously they were mapped to\nblack).\nSome translations in base packages were being looked up in the main\ncatalog rather than that for the package.\nAs a result of the 3.0.2 change about ‘the last second before the\nepoch’, most conversions which should have given NA returned that\ntime. (The platforms affected include Linux and OS X, but not\nWindows nor Solaris.)\nrowsum() has more support for matrices and data frames with or\nmore elements. ()\npredict(<lm object>, interval = \"confidence\", scale = <something>)\nnow works. ()\nThe bug fix in 3.0.2 for was too aggressive, and sometimes removed\nspaces that should not have been removed. ()\nRunning R code in a tcltk callback failed to set the busy flag,\nwhich will be needed to tell OS X not to ‘App Nap’.\nThe code for date-times before 1902 assumed that the offset from GMT\nin 1902 was a whole number of minutes: that was not true of Paris\n(as recorded on some platforms).\nUsing Sys.setlocale to set LC_NUMERIC to \"C\" (to restore the\nsane behavior) no longer gives a warning.\ndeparse() now deparses complex vectors in a way that re-parses to\nthe original values. (, patch based on code submitted by Alex\nBertram.)\nIn some extreme cases (more than ) integer inputs to dpqrxxx()\nfunctions might have been rounded up by one (with a warning about\nbeing non-integer). ()\nPlotting symbol pch = 14 had the triangle upside down on some\ndevices (typically screen devices). The triangle is supposed to be\npoint up. (Reported by Bill Venables.)\ngetSrcref() did not work on method definitions if\nrematchDefinition() had been used.\nKalmanForecast(fast = FALSE) reported a (harmless) stack\nimbalance.\nThe count of observations used by KalmanRun() did not take missing\nvalues into account.\nIn locales where the abbreviated name of one month is a partial\nmatch for the full name of a later one, the %B format in\nstrptime() could fail. An example was French on OS X, where juin\nis abbreviated to jui and partially matches juillet. Similarly\nfor weekday names.\npbeta(x, a, b, log.p = TRUE) sometimes underflowed to zero for\nvery small and very differently sized a, b. ()\napprox() and approxfun() now handle infinite values with the\n\"constant\" method. ()\nstripchart() again respects reversed limits in xlim and ylim.\n()\n\n\n\nCHANGES IN R 3.0.2\n\nNEW FEATURES\nThe NEWS files have been re-organized.\nThis file contains news for R >= 3.0.0: news for the 0.x.y, 1.x.y\nand 2.x.y releases is in files NEWS.0, NEWS.1 and NEWS.2. The\nlatter files are now installed when R is installed. An HTML version\nof news from 2.10.0 to 2.15.3 is available as\ndoc/html/NEWS.2.html.\nsum() for integer arguments now uses an integer accumulator of at\nleast 64 bits and so will be more accurate in the very rare case\nthat a cumulative sum exceeds (necessarily summing more than 4\nmillion elements).\nThe example() and tools::Rd2ex() functions now have parameters\nto allow them to ignore dontrun markup in examples. (Suggested by\nPeter Solymos.)\nstr(x) is considerably faster for very large lists, or factors\nwith 100,000 levels, the latter as in .\ncol2rgb() now converts factors to character strings not integer\ncodes (suggested by Bryan Hanson).\ntail(warnings()) now works, via the new ‘[‘ method.\nThere is now support for the LaTeX style file zi4.sty which has in\nsome distributions replaced inconsolata.sty.\nunlist(x) now typically returns all non-list xs unchanged, not\njust the “vector” ones. Consequently, format(lst) now also works\nwhen the list lst has non-vector elements.\nThe tools::getVignetteInfo() function has been added to give\ninformation about installed vignettes.\nNew assertCondition(), etc. utilities in tools, useful for\ntesting.\nProfiling now records non-inlined calls from byte-compiled code to\nBUILTIN functions.\nVarious functions in stats and elsewhere that use non-standard\nevaluation are now more careful to follow the namespace scoping\nrules. E.g., stats::lm() can now find stats::model.frame() even\nif stats is not on the search path or if some package defines a\nfunction of that name.\nIf an invalid/corrupt .Random.seed object is encountered in the\nworkspace it is ignored with a warning rather than giving an error.\n(This allows R itself to rely on a working RNG, e.g. to choose a\nrandom port.)\nseq() and seq.int() give more explicit error messages if called\nwith invalid (e.g., NaN) inputs.\nWhen parse() finds a syntax error, it now makes partial parse\ninformation available up to the location of the error. (Request of\nReijo Sund.)\nMethods invoked by NextMethod() had a different dynamic parent to\nthe generic. This was causing trouble where S3 methods invoked via\nlazy evaluation could lose track of their generic. ()\nCode for the negative binomial distribution now treats the case\nsize == 0 as a one-point distribution at zero.\nabbreviate() handles without warning non-ASCII input strings which\nrequire no abbreviation.\nread.dcf() no longer has a limit of 8191 bytes per line. (Wish of\n.)\nformatC(x) no longer copies the class of x to the result, to\navoid misuse creating invalid objects as in . A warning is given if\na class is discarded.\nDataset npk has been copied from to allow more tests to be run\nwithout recommended packages being installed.\nThe initialization of the regression coefficients for non-degenerate\ndifferenced models in arima() has been changed and in some\nexamples avoids a local maximum. ()\ntermplot() now has an argument transform.x to control the\ndisplay of individual terms in the plot. ()\nformat() now supports digits = 0, to display nsmall decimal\nplaces.\nThere is a new read-only par() parameter called \"page\", which\nreturns a logical value indicating whether the next plot.new()\ncall will start a new page.\nProcessing Sweave and Rd documents to PDF now renders backticks and\nsingle quotes better in several instances, including in code and\nsamp expressions.\nutils::modifyList() gets a new argument keep.null allowing\nNULL components in the replacement to be retained, instead of\ncausing corresponding components to be deleted.\ntools::pkgVignettes() gains argument check; if set to TRUE, it\nwill warn when it appears a vignette requests a non-existent\nvignette engine.\n\n\nUTILITIES\nR CMD check –as-cran checks the line widths in usage and examples\nsections of the package Rd files.\nR CMD check –as-cran now implies –timings.\nR CMD check looks for command gfile if a suitable file is not\nfound. (Although file is not from GNU, OpenCSW on Solaris installs\nit as gfile.)\nR CMD build (with the internal tar) checks the permissions of\nconfigure and cleanup files and adds execute permission to the\nrecorded permissions for these files if needed, with a warning. This\nis useful on OSes and file systems which do not support execute\npermissions (notably, on Windows).\nR CMD build now weaves and tangles all vignettes, so suggested\npackages are not required during package installation if the source\ntarball was prepared with current R CMD build.\ncheckFF() (used by R CMD check) does a better job of detecting\ncalls from other packages, including not reporting those where a\nfunction has been copied from another namespace (e.g., as a default\nmethod). It now reports calls where .NAME is a symbol registered\nin another package.\nOn Unix-alike systems, R CMD INSTALL now installs packages group\nwritably whenever the library (lib.loc) is group writable. Hence,\nupdate.packages() works for other group members (suggested\noriginally and from a patch by Dirk Eddelbuettel).\nR CMD javareconf now supports the use of symbolic links for\nJAVA_HOME on platforms which have realpath. So it is now\npossible to use\nJAVA_HOME=/usr/lib/jvm/java-1.7.0\non a Linux system and record that value rather than the\nfrequently-changing full path such as\n/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.25.x86_64.\n(Windows only.) Rscript -e requires a non-empty argument for\nconsistency with Unix versions of R. (Also Rterm -e and R -e.)\nR CMD check does more thorough checking of declared packages and\nnamespaces. It reports\npackages declared in more than one of the Depends, Imports,\nSuggests and Enhances fields of the DESCRIPTION file.\nnamespaces declared in Imports but not imported from, neither\nin the NAMESPACE file nor using the :: nor ::: operators.\npackages which are used in library() or requires() calls in\nthe R code but were already put on the search path via\nDepends.\npackages declared in Depends not imported via the\nNAMESPACE file (except the standard packages). Objects used\nfrom Depends packages should be imported to avoid conflicts\nand to allow correct operation when the namespace is loaded but\nnot attached.\nobjects imported via ::: calls where :: would do.\nobjects imported by :: which are not exported.\nobjects imported by ::: calls which do not exist.\nSee ‘Writing R Extensions’ for good practice.\nR CMD check optionally checks for non-standard top-level files and\ndirectories (which are often mistakes): this is enabled for\n–as-cran.\nLaTeX style file upquote.sty is no longer included (the version\nwas several years old): it is no longer used in R. A much later\nversion is commonly included in LaTeX distributions but does not\nplay well with the ae fonts which are the default for Sweave\nvignettes.\nR CMD build makes more use of the build sub-directory of package\nsources, for example to record information about the vignettes.\nR CMD check analyses ::: calls.\n\n\nINSTALLATION and INCLUDED SOFTWARE\nThe macros used for the texinfo manuals have been changed to work\nbetter with the incompatible changes made in texinfo 5.x.\nThe minimum version for a system xz library is now 5.0.3 (was\n4.999). This is in part to avoid 5.0.2, which can compress in ways\nother versions cannot decompress.\nThe included version of PCRE has been updated to 8.33.\nThe included version of zlib has been updated to 1.2.8, a bug-fix\nrelease.\nThe included version of xz utils’s liblzma has been updated to\n5.0.5.\nSince javareconf (see above) is used when R is installed, a stable\nlink for JAVA_HOME can be supplied then.\nConfiguring with –disable-byte-compilation will override the\nDESCRIPTION files of recommended packages, which typically require\nbyte-compilation.\nMore of the installation and checking process will work even when\nTMPDIR is set to a path containing spaces, but this is not\nrecommended and external software (such as texi2dvi) may fail.\n\n\nPACKAGE INSTALLATION\nInstallation is aborted immediately if a LinkingTo package is not\ninstalled.\nR CMD INSTALL has a new option –no-byte-compile which will\noverride a ByteCompile field in the package’s DESCRIPTION file.\nLicense BSD is deprecated: use BSD_3_clause or BSD_2_clause\ninstead.\nLicense X11 is deprecated: use MIT or BSD_2_clause instead.\nVersion requirements for LinkingTo packages are now recognized:\nthey are checked at installation. (Fields with version requirements\nwere previously silently ignored.)\nThe limit of 500 S3method entries in a NAMESPACE file has been\nremoved.\nThe default ‘version’ of Bioconductor for its packages has been\nchanged to the upcoming 2.13, but this can be set by the\nenvironment variable R_BIOC_VERSION when R is installed.\n\n\nC-LEVEL FACILITIES\nRdefines.h has been tweaked so it can be included in C++ code\nafter R_ext/Boolean.h (which is included by R.h).\nNote that Rdefines.h is not kept up-to-date, and Rinternals.h is\npreferred for new code.\neval and applyClosure are now protected against package code\nsupplying an invalid rho.\n\n\nDEPRECATED AND DEFUNCT\nThe unused namespace argument to package.skeleton() is now\nformally deprecated and will be removed in R 3.1.0.\nplclust() is deprecated: use the plot() method for class\n\"hclust\" instead.\nFunctions readNEWS() and checkNEWS() in package tools are\ndeprecated (and they have not worked with current NEWS files for a\nlong time).\n\n\nDOCUMENTATION\n‘An Introduction to R’ has a new chapter on using R as a scripting\nlanguage including interacting with the OS.\n\n\nBUG FIXES\nhelp.request() could not determine the current version of R on\nCRAN. ()\nOn Windows, file.info() failed on root directories unless the path\nwas terminated with an explicit \".\". ()\nThe regmatches<-() replacement function mishandled results coming\nfrom regexpr(). ()\nThe help for setClass() and representation() still suggested the\ndeprecated argument representation=. ()\nR CMD config failed in an installed build of R 3.0.1 (only) when a\nsub-architecture was used. (Reported by Berwin Turlach.)\nOn Windows, the installer modified the etc/Rconsole and\netc/Rprofile.site files even when default options were chosen, so\nthe MD5 sums did not refer to the installed versions. (Reported by\nTal Galili.)\nplot(hclust(), cex =) respects cex again (and possibly others\nsimilarly). (Reported by Peter Langfelder.)\nIf multiple packages were checked by R CMD check, and one was\nwritten for a different OS, it would set –no-install for all\nfollowing packages as well as itself.\nqr.coef() and related functions did not properly coerce real\nvectors to complex when necessary. ()\nftable(a) now fixes up empty dimnames such that the result is\nprintable.\npackage.skeleton() was not starting its search for function\nobjects in the correct place if environment was supplied.\n(Reported by Karl Forner.)\nParsing code was changing the length field of vectors and confusing\nthe memory manager. ()\nThe Fortran routine ZHER2K in the reference BLAS had a comment-out\nbug in two places. This caused trouble with eigen() for Hermitian\nmatrices. ( and report from Robin Hankin)\nvignette() and browseVignettes() did not display non-Sweave\nvignettes properly.\nTwo warning/error messages have been corrected: the (optional)\nwarning produced by a partial name match with a pairlist, the error\nmessage from a zero-length argument to the : operator. (Found by\nRadford Neal; , )\nsvd() returned NULL rather than omitting components as\ndocumented. (Found by Radford Neal; )\nmclapply() and mcparallel() with silent = TRUE could break a\nprocess that uses stdout output unguarded against broken pipes\n(e.g., zip will fail silently). To work around such issues, they\nnow replace stdout with a descriptor pointed to /dev/null\ninstead. For this purpose, internal closeStdout and closeStderr\nfunctions have gained the to.null flag.\nlog(), signif() and round() now raise an error if a single\nnamed argument is not named x. ()\ndeparse() now deparses raw vectors in a form that is syntactically\ncorrect. ()\nThe jpeg driver in Sweave created a JPEG file, but gave it a\n.png extension. ()\nDeparsing of infix operators with named arguments is improved. ()\nmget(), seq.int() and numericDeriv() did not duplicate\narguments properly. (, , )\nkmeans(algorithm = \"Hartigan-Wong\") now always stops iterating in\nthe QTran stage. ().\nread.dcf() re-allocated incorrectly and so could segfault when\ncalled on a file with lines of more than 100 bytes.\nOn systems where mktime() does not set errno, the last second\nbefore the epoch could not be converted from POSIXlt to POSIXct.\n(Reported by Bill Dunlap.)\nadd1.glm() miscalculated F-statistics when df > 1. (Bill Dunlap,\n).\nstem() now discards infinite inputs rather than hanging. ()\nThe parser now enforces C99 syntax for floating point hexadecimal\nconstants (e.g., 0x1.1p0), rather than returning unintended values\nfor malformed constants. ()\nmodel.matrix() now works with very long LHS names (more than 500\nbytes). ()\nintegrate() reverts to the pre-2.12.0 behaviour: from 2.12.0 to\n3.0.1 it sometimes failed to achieve the requested tolerance and\nreported error estimates that were exceeded. ()\nstrptime() now handles %W fields with value 0. ()\nR is now better protected against people trying to interact with the\nconsole in startup code. ()\nSubsetting 1D arrays often lost dimnames ().\nUnary + on a logical vector did not coerce to integer, although\nunary - did.\nna.omit() and na.exclude() added a row to a zero-row data frame.\n()\nAll the (where necessary cut-down) vignettes are installed if R was\nconfigured with –without-recommended-packages.\nsource() did not display filenames when reporting syntax errors.\nSyntax error reports misplaced the caret pointing out the bad token.\n(Windows only) Starting R with R (instead of Rterm or Rgui)\nwould lose any zero-length strings from the command line arguments.\n()\nErrors in the encoding specified on the command line via\n–encoding=foo were not handled properly. ()\nIf x is a symbol, is.vector(x, \"name\") now returns TRUE, since\n\"name\" and \"symbol\" should be synonyms. (Reported by Hervé\nPagès.)\nR CMD rtags works on platforms (such as OS X) with a\nXSI-conformant shell command echo. ()\nis.unsorted(NA) returns false as documented (rather than NA).\nR CMD LINK did not know about sub-architectures.\nsystem() and system2() are better protected against users who\nmisguidedly have spaces in the temporary directory path.\nfile.show() and edit() are now more likely to work on file paths\ncontaining spaces. (Where external utilities are used, not the norm\non Windows nor in R.app which should previously have worked.)\nPackages using the methods package are more likely to work when\nthey import it but it is not attached. (Several parts of its C code\nwere looking for its R functions on the search path rather than in\nits namespace.)\nlgamma(-x) is no longer NaN for very small x.\n(Windows) system2() now respects specifying stdout and stderr\nas files if called from Rgui. ()\nClosing an x11() device whilst locator() or identify() is in\nprogress no longer hangs R. ()\nlist.dirs(full.names = FALSE) was not implemented. ()\nformat() sometimes added unnecessary spaces. ()\nall.equal(check.names = FALSE) would ignore the request to ignore\nthe names and would check them as attributes.\nThe symbol set by tools::Rd2txt_options(itemBullet=) was not\nrespected in some locales. ()\nmcMap() was not exported by package parallel. ()\nplot() for TukeyHSD objects did not balance dev.hold() and\ndev.flush() calls on multi-page plots. ()\n\n\n\nCHANGES IN R 3.0.1\n\nNEW FEATURES\nchooseCRANmirror() and chooseBioCmirror() gain an ind argument\n(like setRepositories()).\nmcparallel has a new argument mc.interactive which can modify\nthe interactive flag in the child process. The new default is\nFALSE which makes child processes non-interactive by default (this\nprevents lock-ups due to children waiting for interactive input).\nscan() now warns when end-of-file occurs within a quoted string.\ncount.fields() is now consistent with scan() in its handling of\nnewlines in quoted strings. Instead of triggering an error, this\nresults in the current line receiving NA as the field count, with\nthe next line getting the total count of the two lines.\nThe default method of image() will plot axes of the class of\nxlim and ylim (and hence of x and y if there is a suitable\nrange() method). Based on a suggestion of Michael Sumner.\nload() now has a verbose argument for debugging support, to\nprint the names of objects just before loading them.\nWhen loading a serialized object encounters a reference to a\nnamespace which cannot be loaded, this is replaced by a reference to\nthe global environment, with a warning.\npairs() gains a line.main option for title placement.\nThe remaining instances in which serialization to a raw vector was\nlimited to 2GB have been unlimited on a 64-bit platform, and in most\ncases serialization to a vector of more than 1GB will be\nsubstantially faster.\n\n\nUTILITIES\nR CMD config now make use of personal Makevars files under\n~/.R and a site file Makevars.site, in the same way as\nR CMD SHLIB and R CMD INSTALL. This makes the utility more\nuseful in package configure scripts.\nOn Windows finding the personal files may require the environment\nvariable HOME set.\nThe old behaviour can be obtained with the new options\n–no-user-files and –no-site-files.\n\n\nPACKAGE INSTALLATION\nAlternatives to the site and user customization files\nMakevars.site and ~/.R/Makevars can be specified via the\nenvironment variables R_MAKEVARS_SITE and R_MAKEVARS_USER\nrespectively. These can be used to suppress the use of the default\nfiles by setting an empty value (where possible) or a non-existent\npath.\n\n\nBUG FIXES\nsys.source() did not report error locations when\nkeep.source = TRUE.\nas.POSIXct.numeric was coercing origin using the tz argument\nand not \"GMT\" as documented ().\nThe active binding to assign fields in reference classes has been\ncleaned up to reduce dependence on the class’ package environment,\nalso fixing bug in initializing read-only fields (inspired by a\nreport from Hadley Wickham).\nstr(d) no longer gives an error when names(d) contain illegal\nmultibyte strings ().\nProfiling of built-in functions with line.profiling= TRUE did not\nrecord the line from which they were called.\ncitation(pkg) dropped the header and footer specified in the\nCITATION file ().\nQuotes were handled differently when reading the first line and\nreading the rest, so read.table() misread some files that\ncontained quote characters ().\ncat() with sep a character vector of length greater than one and\nmore than one argument was using separators inconsistently ().\nOn Windows in R 3.0.0, savePlot() failed because of an incorrect\ncheck on the argument count.\nunzip(list = TRUE) returned Names as a factor and not a\ncharacter vector (as documented) for the internal method. (Noticed\nby Sean O’Riordain.)\ncontourLines() now checks more comprehensively for conformance of\nits x, y and z arguments (it was used incorrectly in package\n).\nSaved graphics display lists are R version-specific. Attempting to\nload workspaces containing them (or some other version-specific\nobjects) aborted the load in R 3.0.0 and earlier; now it does a\npartial load and generates a warning instead.\nIn R 3.0.0, identify() and locator() did not record information\ncorrectly, so replaying a graph (e.g., by copying it to another\ndevice) would fail. ()\nCalling file.copy() or dirname() with the invalid input \"\"\n(which was being used in packages, despite not being a file path)\ncould have caused a segfault.\ndirname(\"\") is now \"\" rather than \".\" (unless it segfaulted).\nsupsmu() could read/write outside its input vectors for very short\ninputs (seen in package for n = 4).\nas.dendrogram()’s hclust method uses less memory and hence gets\nconsiderably faster for large (n ~ 1000) clusterings, thanks to\nDaniel Müllner. ()\nThe return value when all workers failed from\nparallel::mclapply(mc.preschedule = TRUE) was a list of strings\nand not of error objects. (Spotted by Karl Forner and Bernd Bischl.)\nIn R 3.0.0, when help() found multiple pages with the same alias,\nthe HTML display of all the selections was not produced. ()\nsplinefun(method=\"monoH.FC\") now produces a function with first\nargument named x and allows deriv=3, as documented. ()\nsummaryRprof() would only read the first chunksize lines of an\nRprof file produced with line.profiling=TRUE. By default, this\nis the first 100 seconds. ()\nlsfit() produced an incorrect error message when argument x had\nmore columns than rows or x had a different number of rows than\ny. (Spotted by Renaud Gaujoux.)\nBinary operations on equal length vectors copied the class name from\nthe second operand when the first had no class name, but did not set\nthe object bit. ()\nThe trace() method for reference generator objects failed after\nthose objects became function definitions.\nwrite.table() did not check that factors were constructed\ncorrectly, and so caused a segment fault when writing bad ones. ()\nThe internal HTTP server no longer chokes on POST requests without\nbody. It will also pass-through other request types for custom\nhandlers (with the method stored in Request-Method header) instead\nof failing.\n\n\n\nCHANGES IN R 3.0.0\n\nSIGNIFICANT USER-VISIBLE CHANGES\nPackages need to be (re-)installed under this version (3.0.0) of R.\nThere is a subtle change in behaviour for numeric index values and\nlarger. These never used to be legitimate and so were treated as\nNA, sometimes with a warning. They are now legal for long vectors\nso there is no longer a warning, and x[2^31] <- y will now extend\nthe vector on a 64-bit platform and give an error on a 32-bit one.\nIt is now possible for 64-bit builds to allocate amounts of memory\nlimited only by the OS. It may be wise to use OS facilities (e.g.,\nulimit in a bash shell, limit in csh), to set limits on\noverall memory consumption of an R process, particularly in a\nmulti-user environment. A number of packages need a limit of at\nleast 4GB of virtual memory to load.\n64-bit Windows builds of R are by default limited in memory usage to\nthe amount of RAM installed: this limit can be changed by\ncommand-line option –max-mem-size or setting environment variable\nR_MAX_MEM_SIZE.\nNegative numbers for colours are consistently an error: previously\nthey were sometimes taken as transparent, sometimes mapped into the\ncurrent palette and sometimes an error.\n\n\nNEW FEATURES\nidentical() has a new argument, ignore.environment, used when\ncomparing functions (with default FALSE as before).\nThere is a new option, options(CBoundsCheck=), which controls how\n.C() and .Fortran() pass arguments to compiled code. If true\n(which can be enabled by setting the environment variable\nR_C_BOUNDS_CHECK to yes), raw, integer, double and complex\narguments are always copied, and checked for writing off either end\nof the array on return from the compiled code (when a second copy is\nmade). This also checks individual elements of character vectors\npassed to .C().\nThis is not intended for routine use, but can be very helpful in\nfinding segfaults in package code.\nIn layout(), the limits on the grid size have been raised (again).\nNew simple provideDimnames() utility function.\nWhere methods for length() return a double value which is\nrepresentable as an integer (as often happens for package ), this is\nconverted to an integer.\nMatrix indexing of data frames by two-column numeric indices is now\nsupported for replacement as well as extraction.\nsetNames() now has a default for its object argument, useful for\na character result.\nStructTS() has a revised additive constant in the loglik\ncomponent of the result: the previous definition is returned as the\nloglik0 component. However, the help page has always warned of a\nlack of comparability of log-likelihoods for non-stationary models.\n(Suggested by Jouni Helske.)\nThe logic in aggregate.formula() has been revised. It is now\npossible to use a formula stored in a variable; previously, it had\nto be given explicitly in the function call.\ninstall.packages() has a new argument quiet to reduce the amount\nof output shown.\nSetting an element of the graphics argument lwd to a negative or\ninfinite value is now an error. Lines corresponding to elements with\nvalues NA or NaN are silently omitted.\nPreviously the behaviour was device-dependent.\nSetting graphical parameters cex, col, lty, lwd and pch in\npar() now requires a length-one argument. Previously some silently\ntook the first element of a longer vector, but not always when\ndocumented to do so.\nSys.which() when used with inputs which would be unsafe in a shell\n(e.g., absolute paths containing spaces) now uses appropriate\nquoting.\nas.tclObj() has been extended to handle raw vectors. Previously,\nit only worked in the other direction. (Contributed by Charlie\nFriedemann, .)\nNew functions cite() and citeNatbib() have been added, to allow\ngeneration of in-text citations from \"bibentry\" objects. A\ncite() function may be added to bibstyle() environments.\nA sort() method has been added for \"bibentry\" objects.\nThe bibstyle() function now defaults to setting the default\nbibliography style. The getBibstyle() function has been added to\nreport the name of the current default style.\nscatter.smooth() now has an argument lpars to pass arguments to\nlines().\npairs() has a new log argument, to allow some or all variables\nto be plotted on logarithmic scale. (In part, wish of .)\nsplit() gains a sep argument.\ntermplot() does a better job when given a model with interactions\n(and no longer attempts to plot interaction terms).\nThe parser now incorporates code from Romain Francois’ package, to\nsupport more detailed computation on the code, such as syntax\nhighlighting, comment-based documentation, etc. Functions\ngetParseData() and getParseText() access the data.\nThere is a new function rep_len() analogous to rep.int() for\nwhen speed is required (and names are not).\nThe undocumented use rep(NULL, length.out = n) for n > 0 (which\nreturns NULL) now gives a warning.\ndemo() gains an encoding argument for those packages with\nnon-ASCII demos: it defaults to the package encoding where there is\none.\nstrwrap() converts inputs with a marked encoding to the current\nlocale: previously it made some attempt to pass through as bytes\ninputs invalid in the current locale.\nSpecifying both rate and scale to [dpqr]gamma is a warning (if\nthey are essentially the same value) or an error.\nmerge() works in more cases where the data frames include\nmatrices. (Wish of .)\noptimize() and uniroot() no longer use a shared parameter object\nacross calls. (nlm(), nlminb() and optim() with numerical\nderivatives still do, as documented.)\nThe all.equal() method for date-times is now documented: times are\nregarded as equal (by default) if they differ by up to 1 msec.\nduplicated() and unique() gain a nmax argument which can be\nused to make them much more efficient when it is known that there\nare only a small number of unique entries. This is done\nautomatically for factors.\nFunctions rbinom(), rgeom(), rhyper(), rpois(), rnbinom(),\nrsignrank() and rwilcox() now return integer (not double)\nvectors. This halves the storage requirements for large simulations.\nsort(), sort.int() and sort.list() now use radix sorting for\nfactors of less than 100,000 levels when method is not supplied.\nSo does order() if called with a single factor, unless\nna.last = NA.\ndiag() as used to generate a diagonal matrix has been re-written\nin C for speed and less memory usage. It now forces the result to be\nnumeric in the case diag(x) since it is said to have ‘zero\noff-diagonal entries’.\nbacksolve() (and forwardsolve()) are now internal functions, for\nspeed and support for large matrices.\nMore matrix algebra functions (e.g., chol() and solve()) accept\nlogical matrices (and coerce to numeric).\nsample.int() has some support for : see its help for the\nlimitations.\nA different algorithm is used for\n(n, size, replace = FALSE, prob = NULL) for n > 1e7 and\nsize <= n/2. This is much faster and uses less memory, but does\ngive different results.\napproxfun() and splinefun() now return a wrapper to an internal\nfunction in the stats namespace rather than a .C() or .Call()\ncall. This is more likely to work if the function is saved and used\nin a different session.\nThe functions .C(), .Call(), .External() and .Fortran() now\ngive an error (rather than a warning) if called with a named first\nargument.\nSweave() by default now reports the locations in the source\nfile(s) of each chunk.\nclearPushBack() is now a documented interface to a long-existing\ninternal call.\naspell() gains filters for R code, Debian Control Format and\nmessage catalog files, and support for R level dictionaries. In\naddition, package utils now provides functions\naspell_package_R_files() and aspell_package_C_files() for spell\nchecking R and C level message strings in packages.\nbibentry() gains some support for “incomplete” entries with a\ncrossref field.\ngray() and gray.colors() finally allow alpha to be specified.\nmonthplot() gains parameters to control the look of the reference\nlines. (Suggestion of Ian McLeod.)\nAdded support for new %~% relation (“is distributed as”) in\nplotmath.\ndomain = NA is accepted by gettext() and ngettext(),\nanalogously to stop() etc.\ntermplot() gains a new argument plot = FALSE which returns\ninformation to allow the plots to be modified for use as part of\nother plots, but does not plot them. (Contributed by Terry Therneau,\n.)\nquartz.save(), formerly an undocumented part of R.app, is now\navailable to copy a device to a quartz() device. dev.copy2pdf()\noptionally does this for PDF output: quartz.save() defaults to\nPNG.\nThe default method of pairs() now allows text.panel = NULL and\nthe use of <foo>.panel = NULL is now documented.\nsetRefClass() and getRefClass() now return class generator\nfunctions, similar to setClass(), but still with the reference\nfields and methods as before (suggestion of Romain Francois).\nNew functions bitwNot(), bitwAnd(), bitwOr() and bitwXor(),\nusing the internal interfaces previously used for classes\n\"octmode\" and \"hexmode\".\nAlso bitwShiftL() and bitwShiftR() for shifting bits in elements\nof integer vectors.\nNew option \"deparse.cutoff\" to control the deparsing of language\nobjects such as calls and formulae when printing. (Suggested by a\ncomment of Sarah Goslee.)\ncolors() gains an argument distinct.\nNew demo(colors) and demo(hclColors), with utility functions.\nlist.files() (aka dir()) gains a new optional argument no..\nwhich allows to exclude \".\" and \"..\" from listings.\nMultiple time series are also of class \"matrix\"; consequently,\nhead(), e.g., is more useful.\nencodeString() preserves UTF-8 marked encodings. Thus if factor\nlevels are marked as UTF-8 an attempt is made to print them in UTF-8\nin RGui on Windows.\nreadLines() and scan() (and hence read.table()) in a UTF-8\nlocale now discard a UTF-8 byte-order-mark (BOM). Such BOMs are\nallowed but not recommended by the Unicode Standard: however\nMicrosoft applications can produce them and so they are sometimes\nfound on websites.\nThe encoding name \"UTF-8-BOM\" for a connection will ensure that a\nUTF-8 BOM is discarded.\nmapply(FUN, a1, ..) now also works when a1 (or a further such\nargument) needs a length() method (which the documented arguments\nnever do). (Requested by Hervé Pagès; with a patch.)\n.onDetach() is supported as an alternative to .Last.lib. Unlike\n.Last.lib, this does not need to be exported from the package’s\nnamespace.\nThe srcfile argument to parse() may now be a character string,\nto be used in error messages.\nThe format() method for ftable objects gains a method\nargument, propagated to write.ftable() and print(), allowing\nmore compact output, notably for LaTeX formatting, thanks to Marius\nHofert.\nThe utils::process.events() function has been added to trigger\nimmediate event handling.\nSys.which() now returns NA (not \"\") for NA inputs (related\nto ).\nThe print() method for class \"htest\" gives fewer trailing spaces\n(wish of ).\nAlso print output from HoltWinters(), nls() and others.\nloadNamespace() allows a version specification to be given, and\nthis is used to check version specifications given in the Imports\nfield when a namespace is loaded.\nsetClass() has a new argument, slots, clearer and less ambiguous\nthan representation. It is recommended for future code, but should\nbe back-compatible. At the same time, the allowed slot specification\nis slightly more general. See the documentation for details.\nmget() now has a default for envir (the frame from which it is\ncalled), for consistency with get() and assign().\nclose() now returns an integer status where available, invisibly.\n(Wish of .)\nThe internal method of tar() can now store paths too long for the\nustar format, using the (widely supported) GNU extension. It can\nalso store long link names, but these are much less widely\nsupported. There is support for larger files, up to the ustar\nlimit of 8GB.\nLocal reference classes have been added to package methods. These\nare a technique for avoiding unneeded copying of large components of\nobjects while retaining standard R functional behavior. See\n?LocalReferenceClasses.\nuntar() has a new argument restore_times which if false (not the\ndefault) discards the times in the tarball. This is useful if they\nare incorrect (some tarballs submitted to CRAN have times in a local\ntime zone or many years in the past even though the standard\nrequired them to be in UTC).\nreplayplot() cannot (and will not attempt to) replay plots\nrecorded under R < 3.0.0. It may crash the R session if an attempt\nis made to replay plots created in a different build of R >= 3.0.0.\nPalette changes get recorded on the display list, so replaying plots\n(including when resizing screen devices and using dev.copy()) will\nwork better when the palette is changed during a plot.\nchol(pivot = TRUE) now defaults to LAPACK, not LINPACK.\nThe parse() function has a new parameter keep.source, which\ndefaults to options(\"keep.source\").\nProfiling via Rprof() now optionally records information at the\nstatement level, not just the function level.\nThe Rprof() function now quotes function names in in its output\nfile on Windows, to be consistent with the quoting in Unix.\nProfiling via Rprof() now optionally records information about\ntime spent in GC.\nThe HTML help page for a package now displays non-vignette\ndocumentation files in a more accessible format.\nTo support options(stringsAsFactors = FALSE), model.frame(),\nmodel.matrix() and replications() now automatically convert\ncharacter vectors to factors without a warning.\nThe print method for objects of class \"table\" now detects tables\nwith 0-extents and prints the results as, e.g.,\n< table of extent 0 x 1 x 2 >. (Wish of .)\nDeparsing involving calls to anonymous functions has been made\ncloser to reversible by the addition of extra parentheses.\nThe function utils::packageName() has been added as a lightweight\nversion of methods::getPackageName().\nfind.package(lib.loc = NULL) now treats loaded namespaces\npreferentially in the same way as attached packages have been for a\nlong time.\nIn Windows, the Change Directory dialog now defaults to the current\nworking directory, rather than to the last directory chosen in that\ndialog.\navailable.packages() gains a \"license/restricts_use\" filter\nwhich retains only packages for which installation can proceed\nsolely based on packages which are guaranteed not to restrict use.\nNew check_packages_in_dir() function in package tools for\nconveniently checking source packages along with their reverse\ndependencies.\nR’s completion mechanism has been improved to handle help requests\n(starting with a question mark). In particular, help prefixes are\nnow supported, as well as quoted help topics. To support this,\ncompletion inside quotes are now handled by R by default on all\nplatforms.\nThe memory manager now allows the strategy used to balance garbage\ncollection and memory growth to be controlled by setting the\nenvironment variable R_GC_MEM_GROW. See ?Memory for more\ndetails.\n(‘For experts only’, as the introductory manual says.) The use of\nenvironment variables R_NSIZE and R_VSIZE to control the initial\n(= minimum) garbage collection trigger for number of cons cels and\nsize of heap has been restored: they can be overridden by the\ncommand-line options –min-nsize and –min-vsize; see ?Memory.\nOn Windows, the device name for bitmap devices as reported by\n.Device and .Devices no longer includes the file name. This is\nfor consistency with other platforms and was requested by the\nmaintainer.\nwin.metafile() still uses the file name: the exact form is used by\npackage .\nset.seed(NULL) re-initializes .Random.seed as done at the\nbeginning of the session if not already set. (Suggestion of Bill\nDunlap.)\nThe breaks argument in hist.default() can now be a function that\nreturns the breakpoints to be used (previously it could only return\nthe suggested number of breakpoints).\nFile share/licenses/licenses.db has some clarifications,\nespecially as to which variants of ‘BSD’ and ‘MIT’ is intended and\nhow to apply them to packages. The problematic licence\n‘Artistic-1.0’ has been removed.\n\n\nLONG VECTORS This section applies only to 64-bit platforms.\nThere is support for vectors longer than elements. This applies to\nraw, logical, integer, double, complex and character vectors, as\nwell as lists. (Elements of character vectors remain limited to\nbytes.)\nMost operations which can sensibly be done with long vectors work:\nothers may return the error ‘long vectors not supported yet’. Most\nof these are because they explicitly work with integer indices\n(e.g., anyDuplicated() and match()) or because other limits\n(e.g., of character strings or matrix dimensions) would be exceeded\nor the operations would be extremely slow.\nlength() returns a double for long vectors, and lengths can be set\nto or more by the replacement function with a double value.\nMost aspects of indexing are available. Generally double-valued\nindices can be used to access elements beyond .\nThere is some support for matrices and arrays with each dimension\nless than but total number of elements more than that. Only some\naspects of matrix algebra work for such matrices, often taking a\nvery long time. In other cases the underlying Fortran code has an\nunstated restriction (as was found for complex svd()).\ndist() can produce dissimilarity objects for more than 65536 rows\n(but for example hclust() cannot process such objects).\nserialize() to a raw vector is unlimited in size (except by\nresources).\nThe C-level function R_alloc can now allocate or more bytes.\nagrep() and grep() will return double vectors of indices for\nlong vector inputs.\nMany calls to .C() have been replaced by .Call() to allow long\nvectors to be supported (now or in the future). Regrettably several\npackages had copied the non-API .C() calls and so failed.\n.C() and .Fortran() do not accept long vector inputs. This is a\nprecaution as it is very unlikely that existing code will have been\nwritten to handle long vectors (and the R wrappers often assume that\nlength(x) is an integer).\nMost of the methods for sort() work for long vectors.\nrank(), sort.list() and order() support long vectors (slowly\nexcept for radix sorting).\nsample() can do uniform sampling from a long vector.\n\n\nPERFORMANCE IMPROVEMENTS\nMore use has been made of R objects representing registered entry\npoints, which is more efficient as the address is provided by the\nloader once only when the package is loaded.\nThis has been done for packages base, methods, splines and\ntcltk: it was already in place for the other standard packages.\nSince these entry points are always accessed by the R entry points\nthey do not need to be in the load table which can be substantially\nsmaller and hence searched faster. This does mean that .C /\n.Fortran / .Call calls copied from earlier versions of R may no\nlonger work – but they were never part of the API.\nMany .Call() calls in package base have been migrated to\n.Internal() calls.\nsolve() makes fewer copies, especially when b is a vector rather\nthan a matrix.\neigen() makes fewer copies if the input has dimnames.\nMost of the linear algebra functions make fewer copies when the\ninput(s) are not double (e.g., integer or logical).\nA foreign function call (.C() etc) in a package without a\nPACKAGE argument will only look in the first DLL specified in the\nNAMESPACE file of the package rather than searching all loaded\nDLLs. A few packages needed PACKAGE arguments added.\nThe @<- operator is now implemented as a primitive, which should\nreduce some copying of objects when used. Note that the operator\nobject must now be in package base: do not try to import it\nexplicitly from package methods.\n\n\nPACKAGE INSTALLATION\nThe transitional support for installing packages without namespaces\n(required since R 2.14.0) has been removed. R CMD build will still\nadd a namespace, but a .First.lib() function will need to be\nconverted.\nR CMD INSTALL no longer adds a namespace (so installation will\nfail), and a .First.lib() function in a package will be ignored\n(with an installation warning for now).\nAs an exception, packages without a R directory and no NAMESPACE\nfile can still be installed.\nPackages can specify in their DESCRIPTION file a line like\nyes\nto be installed on Windows with –force-biarch.\nPackage vignettes can now be processed by other engines besides\nSweave; see ‘Writing R Extensions’ and the tools::vignetteEngine\nhelp topic for details.\nThe *.R tangled source code for vignettes is now included in\ntarballs when R CMD build is used to produce them. In R 3.0.0,\n*.R files not in the sources will be produced at install time, but\neventually this will be dropped.\nThe package type \"mac.binary\" now looks in a path in the\nrepository without any Mac subtype (which used to be universal or\nleopard): it looks in bin/macosx/contrib/3.0 rather than\nbin/macosx/leopard/contrib/2.15). This is the type used for the\nCRAN binary distribution for OS X as from R 3.0.0.\nFile etc/Makeconf makes more use of the macros $(CC), $(CXX),\n$(F77) and $(FC), so the compiler in use can be changed by\nsetting just these (and if necessary the corresponding flags and\nFLIBS) in file ~/.R/Makevars.\nThis is convenient for those working with binary distributions of R,\ne.g. on OS X.\n\n\nUTILITIES\nR CMD check now gives a warning rather than a note if it finds\ncalls to abort, assert or exit in compiled code, and has been\nable to find the .o file in which the calls occur.\nSuch calls can terminate the R process which loads the package.\nThe location of the build and check environment files can now be\nspecified by the environment variables R_BUILD_ENVIRON and\nR_CHECK_ENVIRON, respectively.\nR CMD Sweave gains a –compact option to control possibly\nreducing the size of the PDF file it creates when –pdf is given.\nR CMD build now omits Eclipse’s .metadata directories, and\nR CMD check warns if it finds them.\nR CMD check now does some checks on functions defined within\nreference classes, including of .Call() etc calls.\nR CMD check –as-cran notes assignments to the global environment,\ncalls to data() which load into the global environment, and calls\nto attach().\nR CMD build by default uses the internal method of tar() to\nprepare the tarball. This is more likely to produce a tarball\ncompatible with R CMD INSTALL and R CMD check: an external tar\nprogram, including options, can be specified via the environment\nvariable R_BUILD_TAR.\ntools::massageExamples() is better protected against packages\nwhich re-define base functions such as cat() and get() and so\ncan cause R CMD check to fail when checking examples.\nR CMD javareconf has been enhanced to be more similar to the code\nused by configure.\nThere is now a test that a JNI program can be compiled (like\nconfigure did) and only working settings are used.\nIt makes use of custom settings from configuration recorded in\netc/javaconf.\nThe –no-vignettes argument of R CMD build has been renamed to\nthe more accurate –no-build-vignettes: its action has always been\nto (re)build vignettes and never omitted them.\nR CMD check accepts –no-build-vignettes as a preferred synonym\nfor –no-rebuild-vignettes.\n\n\nDEPRECATED AND DEFUNCT\nThe ENCODING argument to .C() is defunct. Use iconv() instead.\nThe .Internal(eval.with.vis) non-API function has been removed.\nSupport for the converters for use with .C() has been removed,\nincluding the oft misused non-API header R_ext/RConverters.h.\nThe previously deprecated uses of array() with a 0-length dim\nargument and tapply() with a 0-length INDEX list are now errors.\nTranslation packages are defunct.\nCalling rep() or rep.int() on a pairlist or other non-vector\nobject is now an error.\nSeveral non-API entry points have been transferred to packages\n(e.g., R_zeroin2) or replaced by different non-API entry points\n(e.g., R_tabulate).\nThe ‘internal’ graphics device invoked by\n.Call(\"R_GD_nullDevice\", package = \"grDevices\") has been removed:\nuse pdf(file = NULL) instead.\nThe .Fortran() entry point \"dqrls\" which has not been used by R\nsince version 2.15.1 is no longer available.\nFunctions traceOn() and traceOff() in package methods are now\ndefunct.\nFunction CRAN.packages() is finally defunct.\nUse of col2rgb(0) is defunct: use par(\"bg\") or NA instead.\nThe long-defunct functions Rd_parse(), anovalist.lm(),\ncategpry(), clearNames(), gammaCody(), glm.fit.null(),\nlm.fit.null(), lm.wfit.null(), manglePackageNames(),\nmauchley.test(), package.contents(), print.coefmat(),\nreshapeLong(), reshapeWide(), tkclose(), tkcmd(),\ntkfile.dir(), tkfile.tail(), tkopen(), tkputs(), tkread(),\ntrySilent() and zip.file.extract() have been removed entirely\n(but are still documented in the help system).\nThe unused dataPath argument to attachNamespace() has been\nremoved.\ngrid.prompt() has been removed: use devAskNewPage() instead.\nThe long-deprecated intensities component is no longer returned by\nhist().\nmean() for data frames and sd() for data frames and matrices are\ndefunct.\nchol(pivot = FALSE, LINPACK = TRUE), ch2inv(LINPACK = TRUE),\neigen(EISPACK = TRUE), solve(LINPACK = TRUE) and\nsvd(LINPACK = TRUE) are defunct: LAPACK will be used, with a\nwarning.\nThe keep.source argument to library() and require() is\ndefunct. This option needs to be set at install time.\nDocumentation for real(), as.real() and is.real() has been\nmoved to ‘defunct’ and the functions removed.\nThe maxRasters argument of pdf() (unused since R 2.14.0) has\nbeen removed.\nThe unused fontsmooth argument has been removed from the\nquartz() device.\nAll the (non-API) EISPACK entry points in R have been removed.\nchol(pivot = TRUE, LINPACK = TRUE) is deprecated.\nThe long-deprecated use of synopsis in the Usage section of\n.Rd files will be removed in R 3.1.0.\n.find.package() and .path.package() are deprecated: only the\npublic versions without the dot have ever been in the API.\nIn a package’s DESCRIPTION file,\nX11\nis deprecated, since it includes ‘Copyright (C) 1996 X Consortium’\nwhich cannot be appropriate for a current R package. Use ‘MIT’ or\n‘BSD_2_clause’ instead.\n\n\nCODE MIGRATION\nThe C code underlying base graphics has been migrated to the\ngraphics package (and hence no longer uses .Internal() calls).\nMost of the .Internal() calls used in the stats package have\nbeen migrated to C code in that package.\nThis means that a number of .Internal() calls which have been used\nby packages no longer exist, including .Internal(cor)\n.Internal(cov), .Internal(optimhess) and\n.Internal(update.formula).\nSome .External() calls to the base package (really to the R\nexecutable or shared library) have been moved to more appropriate\npackages. Packages should not have been using such calls, but some\ndid (mainly those used by integrate()).\n\n\nPACKAGE parallel\nThere is a new function mcaffinity() which allows getting or\nsetting the CPU affinity mask for the current R process on systems\nthat supports this (currently only Linux has been tested\nsuccessfully). It has no effect on systems which do not support\nprocess affinity. Users are not expected to use this function\ndirectly (with the exception of fixing libraries that break affinity\nsettings like OpenBLAS) – the function is rather intended to\nsupport affinity control in high-level parallel functions. In the\nfuture, R may supplement lack of affinity control in the OS by its\nown bookkeeping via mcaffinity() related to processes and\nthreads it spawns.\nmcparallel() has a new argument mc.affinity which attempts to\nset the affinity of the child process according to the specification\ncontained therein.\nThe port used by socket clusters is chosen randomly: this should\nhelp to avoid clashes observed when two users of a multi-user\nmachine try to create a cluster at the same time. To reproduce the\nprevious behaviour set environment variable R_PARALLEL_PORT to\n10187.\n\n\nC-LEVEL FACILITIES\nThere has been some minor re-organization of the non-API header\nfiles. In particular, Rinternals.h no longer includes the non-API\nheader R_exts/PrtUtil.h, and that no longer includes\nR_exts/Print.h.\nPassing NULL to .C() is now an error.\n.C() and .Fortran() now warn if \"single\" arguments are used\nwith DUP = FALSE, as changes to such arguments are not returned to\nthe caller.\nC entry points R_qsort and R_qsort_I now have start and end\nas size_t to allow them to work with longer vectors on 64-bit\nplatforms. Code using them should be recompiled.\nA few recently added C entry points were missing the remapping to\nRf_, notably [dpq]nbinom_mu.\nSome of the interface pointers formerly available only to R.app\nare now available to front-ends on all Unix-alikes: one has been\nadded for the interface to View().\nPACKAGE = \"\" is now an error in .C() etc calls: it was always\ncontrary to the documentation.\nEntry point rcont2 has been migrated to package stats and so is\nno longer available.\nR_SVN_REVISION in Rversion.h is now an integer (rather than a\nstring) and hence usable as e.g. #if R_SVN_REVISION < 70000.\nThe entry points rgb2hsv and hsv2rgb have been migrated to\npackage grDevices and so are no longer available.\nR_GE_version has been increased to 10 and name2col removed\n(use R_GE_str2col instead). R internal colour codes are now\ndefined using the typedef rcolor.\nThe REPROTECT macro now checks that the protect index is valid.\nSeveral non-API entry points no longer used by R have been removed,\nincluding the Fortran entry points chol, chol2inv, cg, ch\nand rg, and the C entry points Brent_fmin, fft_factor and\nfft_work.\nIf a .External call is registered with a number of arguments\n(other than -1), the number of arguments passed is checked for\neach call (as for other foreign function calls).\nIt is now possible to write custom connection implementations\noutside core R using R_ext/Connections.h. Please note that the\nimplementation of connections is still considered internal and may\nchange in the future (see the above file for details).\n\n\nINTERNATIONALIZATION\nThe management of translations has been converted to R code: see\n?tools::update_pkg_po.\nThe translations for the R interpreter and RGui.exe are now part\nof the base package (rather than having sources in directory po\nand being installed to share/locale). Thus the base package\nsupports three translation domains, R-base, R and RGui.\nThe compiled translations which ship with R are all installed to the\nnew package translations for easier updating. The first package of\nthat name found on .libPaths() at the start of the R session will\nbe used. (It is possible messages will be used before .libPaths()\nis set up in which case the default translations will be used: set\nenvironment variable R_TRANSLATIONS to point to the location of\nthe intended translations package to use this right from the\nstart.)\nThe translations form a separate group in the Windows installer, so\ncan be omitted if desired.\nThe markup for many messages has been changed to make them easier to\ntranslate, incorporating suggestions from Łukasz Daniel.\n\n\nINSTALLATION\nThere is again support for building without using the C ‘long\ndouble’ type. This is required by C99, but system implementations\ncan be slow or flawed. Use configure option\n–disable-long-double.\nmake pdf and make install-pdf now make and install the full\nreference index (including all base and recommended packages).\nThe ‘reference manual’ on the Windows GUI menu and included in the\ninstaller is now the full reference index, including all base and\nrecommended packages.\nR help pages and manuals have no ISBNs because ISBN rules no longer\nallow constantly changing content to be assigned an ISBN.\nThe Windows installer no longer installs a Start Menu link to the\nstatic help pages; as most pages are generated dynamically, this led\nto a lot of broken links.\nAny custom settings for Java configuration are recorded in file\netc/javaconf for subsequent use by R CMD javareconf.\nThere is now support for makeinfo version 5.0 (which requires a\nslightly different .texi syntax).\nThe minimum versions for –use-system-zlib and –use-system-pcre\nare now tested as 1.2.5 and 8.10 respectively.\nOn Windows, the stack size is reduced to 16MB on 32-bit systems:\nmisguided users were launching many threads without controlling the\nstack size.\nconfigure no longer looks for file ~/.Rconfig: ~/.R/config has\nlong been preferred.\n\n\nBUG FIXES\nWhen R CMD build is run in an encoding other than the one\nspecified in the package’s DESCRIPTION file it tries harder to\nexpand the authors@R field in the specified encoding. ()\nIf R CMD INSTALL is required to expand the authors@R field of\nthe DESCRIPTION file, it tries harder to do so in the encoding\nspecified for the package (rather than using ASCII escapes).\nFix in package grid for pushing a viewport into a layout cell,\nwhere the layout is within a viewport that has zero physical width\nOR where the layout has zero total relative width (likewise for\nheight). The layout column widths (or row heights) in this case were\nbeing calculated with non-finite values. (Reported by Winston\nChang.)\nsolve(A, b) for a vector b gave the answer names from\ncolnames(A) for LINPACK = TRUE but not in the default case.\nLa.svd() accepts logical matrices (as documented, and as svd()\ndid).\nlegend() now accepts negative pch values, in the same way\npoints() long has.\nParse errors when installing files now correctly display the name of\nthe file containing the bad code.\nIn Windows, tcltk windows were not always properly constructed. ()\nThe internal functions implementing parse(), tools::parseLatex()\nand tools::parse_Rd() were not reentrant, leading to errors in\nrare circumstances such as a garbage collection triggering a\nrecursive call.\nField assignments in reference class objects via $<- were not\nbeing checked because the magic incantation to turn methods on for\nthat primitive operator had been inadvertently omitted.\nsetHook(hookname, value, action=\"replace\") set the hook to be the\nvalue, rather than a list containing the value as documented. ()\nIf a package used a NEWS.Rd file, the main HTML package index page\ndid not link to it. (Reported by Dirk Eddelbuettel.)\nThe primitive implementation of @<- was not checking the class of\nthe replacement. It now does a check, quicker but less general than\nslot<-. See the help.\nsplit(x, f) now recycles classed objects x in the same way as\nvectors. (Reported by Martin Morgan.)\npbeta(.28, 1/2, 2200, lower.tail=FALSE, log.p=TRUE) is no longer\n-Inf; ditto for corresponding pt() and pf() calls, such as\npt(45, df=5000, lower.tail=FALSE, log.p=TRUE). ()\nThe Windows graphics device would crash R if a user attempted to\nload the graphics history from a variable that was not a saved\nhistory. ()\nThe workspace size for the predict() method for loess() could\nexceed the maximum integer size. (Reported by Hiroyuki Kawakatsu.)\nftable(x, row.vars, col.vars) now also works when the *.vars\narguments are (integer or character vectors) of length zero.\nCalling cat() on a malformed UTF-8 string could cause the Windows\nGUI to lock up. ()\nremoveClass(cc) gave \"node stack overflow\" for some class\ndefinitions containing \"array\" or \"matrix\".\n\n\n\nCHANGES in previous versions\nOlder news can be found in text format in files NEWS.0, NEWS.1\nand NEWS.2 in the doc directory. News in HTML format for R\nversions from 2.10.0 to 2.15.3 is in doc/html/NEWS.2.html.\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2019-2-conectaR/",
    "title": "Conference Report: ConectaR 2019",
    "description": "The 'Conference Report: ConectaR 2019' article from the 2019-2 issue.",
    "author": [
      {
        "name": "Marcela Alfaro Córdoba",
        "url": {}
      },
      {
        "name": "Agustín Gómez Meléndez",
        "url": {}
      },
      {
        "name": "Frans van Dunné",
        "url": {}
      },
      {
        "name": "Jacob van Etten",
        "url": {}
      }
    ],
    "date": "2019-12-01",
    "categories": [],
    "contents": "\n\n1 About the event\nConectaR 2019: Encuentro de Usuarios R en Latinoamérica, took place\nduring January 24-26, 2019 at the University of Costa Rica, in San José,\nCosta Rica. It was the first event in Central America endorsed by The R\nFoundation, and it was held completely in Spanish. The majority of the\nattendants were from Costa Rica (85%), but we had participants from 12\ncountries: Costa Rica, Guatemala, Peru, Colombia, Mexico, Argentina,\nUruguay, Chile, Spain, the Netherlands, France and the USA. The\nthree-day event consisted of talks, workshops, and poster sessions.\nThe primary purpose of ConectaR conference was to provide a space to\ncreate a community among R users in industry, academia, citizen science\nand teaching. In this way, we aim to encourage the use of R, promote\nlearning and advance the development of R packages adapted to our\nregional needs.\nConectaR 2019 was organized by the University of Costa Rica -through the\nSchool of Statistics, the Development Observatory, and the Research\nCenter for Pure and Applied Mathematics- the company ixpantia, and the\nresearch institution Bioversity International. The initiative originated\nthanks to the encouragement of Heather Turner, who contacted several\nnetworks in the region, through the R Users Groups, R-ladies groups and\nother connections.\nFrom the 150 registered participants, \\(33\\%\\) were female and \\(23\\%\\) were\nfull time students. Professionals from finance, government and data\ncompanies were present, as well as faculty members from all four major\nuniversities in the country. The event was possible thanks to the effort\nof a team of about 50 people including 4 chairs, a 23-member scientific\ncommittee and a motivated group of 23 volunteers.\nFigure 1: The logo of ConectaR.2 Conference program\nThe first two days of the conference were dedicated to talks (invited\nand contributed) and poster presentations. On the third day of the event\n(a Saturday) four workshops ran in parallel: two during the morning and\ntwo during the afternoon.\nFigure 2: Picture from the\nevent.The event had four invited talks: two that were in person and two via\nvideo conference. Edgar Ruiz from RStudio, was the first keynote. He\ngave a remarkably clear explanation about how to use R and Spark for\nData Science. During the afternoon, Maëlle Salmon from rOpenSci and\nLocke Data, presented the second keynote (remote), where she talked\nabout the ROpenSci initiative (https://ropensci.org/), and about her\nexperience curating R packages. She gave the audience tips on how to\nwrite R packages, a clear explanation on the importance of citing,\ncurating and recognizing R packages as part of the scientific process.\nDuring the second day of the event, Robert Hijmans from UC Davis,\nexplained the use of R for spatial data science, and talked about his\nexperience using R for scientific production and teaching, including the\ncreation of new packages. His talk ended with an invitation to translate\nthe material from his web page into Spanish: https://rspatial.org/. To\nclose the last day of talks, Antonio Vasquez Brust from Buenos Aires\nUniversity (UBA), Argentina gave a detailed description on how to use R\nand Open Data to understand our cities. His discussion encouraged good\npractices in visualization as well as a conversation about city planning\nusing R when Open Data is available.\nA panel named “Connecting data innovation initiatives in Latin America\nwith R” was facilitated by Diego May (ixpantia) during the second day of\nthe event. The intention of the panel was to have professionals talk\nabout the opportunities and challenges around the use of R in their\ndifferent work contexts. Alexia Pacheco of ICE, the largest utility\ncompany in Costa Rica, explained how data science and R has pervaded\ntheir work since its origin. Jacob van Etten (Bioversity International)\nexplained how R is used in a multi-country team in an international\nagricultural research institute. It has provided important opportunities\nfor quick methodological innovation to support a large citizen science\ninitiative. Alvaro Pabón of Finsocial Colombia, explained how he has set\nup a data science team in a Colombian company, the challenges to build\nthis capacity and the support needed for it.\nEleven contributed talks and fourteen posters were presented during the\nevent. The selection process had two stages: during the first one, the\nreviewers gave recommendations to the authors on how to improve their\nabstract, and during the second stage, the talks that had a satisfactory\nlevel were accepted. The posters were then reviewed by the chairs to\nensure all of them had a satisfactory level. Two out of the eleven\ncontributed talks and six out of the fourteen posters were presented by\nwomen.\nThe topics of the contributed talks followed the four themes of the\nconference. First government and citizen science, where we saw how shiny\napps are used at the Costa Rican national comptroller’s office. We also\nheard how the national statistics office is transitioning from SPSS to\nR. In the industry track a talk about the transition from Excel to R at\nthe national insurance institute showed how this has lead to significant\nreduction in time spent on data processing. In academia the\nvisualization and analysis of complex climate data took center stage in\ntwo separate talks. The teaching track included a fun example of how to\npredict the outcome of soccer matches, and showcased experiences from\nMexico of the power of R as a didactic tool in statistics and\nmathematics.\nAfter the last break of the first day, the poster session was opened and\naccompanied by the conference cocktail reception. As organizers we felt\nstrongly about including sufficient opportunities for people to mingle\nand talk. The posters were well visited and led to spirited discussions.\nThe conference dinner had a lower attendance than the reception, but\nserved its purpose just as well in offering an opportunity for people in\nthe community to connect and re-connect.\nDuring the last day of the event four workshops were held, each of which\nmanaged to attract full classrooms:\nCrear API’s con código R usando plumber by Frans van Dunné.\nDocumentos dinámicos, trabajo colaborativo y control de versiones\ncon Rmarkdown y GitHub by Natalia da Silva.\nAnálisis de texto by Riva Quiroga.\nIntroducción al análisis Bayesiano con aplicaciones en STAN by\nIgnacio Álvarez-Castro.\nConectaR served to connect different communities, announce exciting\nprojects and to create new ones. Examples are the visit and help of two\nof the three chairs of LatinR to teach workshops and their LatinR2019\nannouncement during the closing remarks of ConectaR. Also, Riva Quiroga\nexplained details about the R4DS translation project\n(https://es.r4ds.hadley.nz) to the community, and Frans van Dunné\nasked for volunteers to start the (already advanced) Plumber translation\nproject (https://github.com/fontanero-api/).\nCommunities outside R were also involved, such as Women in Engineering,\nwho organized an introduction to R workshop for its members two months\nafter the event, with the help of Marcela Alfaro Córdoba. DataLatam did\nseveral interviews for their podcast thanks\nto the connections established during ConectaR, and the School of\nStatistics made the first arrangements to invite Edgar Ruiz to give a\nweek of workshops to its students and faculty in June.\n3 Evaluation\nAn evaluation questionnaire was circulated after the event, and \\(70\\%\\)\nof the participants filled it out. The results were overwhelmingly\npositive, having a median rate of 5 (on a scale from 1=bad job to 5=good\njob) for all the questions, with very small variability in each\ndistribution. A word cloud of the comment section of the questionnaire\nwas constructed and is shown in Figure 3, where it\nis clear that positive words such as excellent (excelente), good (bien,\nbueno) and quality (calidad) were among the most used in the comments.\nFigure 3: Word cloud for the evaluation\ncomments.4 Corporate Sponsors\nConectaR was possible thanks to the main sponsors: INCAE Business\nSchool, R Consortium, RStudio, Inc., Hivos Latinoamerica, The Trust for\nthe Americas. Also, a small job fair was organized parallel to the\nconference, in which the some of the main sponsors participated, along\nwith companies like McKinsey \\(\\&\\) Company, Alteryx, Growth Acceleration\nand Partners, ThermoFisher Scientific and ixpantia.\n5 Other Events and Future Steps\nFuture plans for the chairs of ConectaR include ConectaR 2021, where the\nexpectation is to improve the network with communities in Mexico,\nColombia, Panamá, and search for funding sources to overcome our most\nimportant limitation for this edition: lack of funding to cover travel\nexpenses. Also, the organization of more local events such as a Datathon\nfor 2020, is on the agenda. The idea is to gather momentum to get\ndifferent R communities from the region to participate in a\nvisualization competition, inspired in Open Data from the Costa Rican\nGovernment.\n6 Further information\nConectaR materials: https://github.com/ConectaR2019.\nTwitter account: @conecta_R,\n#ConectaR2019.\nWebpage: http://www.conectar2019.ucr.ac.cr\nFacebook account:\nconectar2019\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2019-2-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2019-2 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2019-12-01",
    "categories": [],
    "contents": "\n\n\nIn the past 4 months, 632 new packages were added to the CRAN package\nrepository. 27 packages were unarchived and 182 were archived. The\nfollowing shows the growth of the number of active packages in the CRAN\npackage repository:\nimageOn 2019-12-31, the number of active packages was around 15227.\nChanges in the CRAN Repository Policy\nThe Checklist for CRAN\nsubmissions\nnow says the following:\nMake the Description as informative as possible for potential new\nusers of your package. If in doubt, make the Description longer\nrather than shorter, but try to avoid redundancies such as\nrepetitions of the package name.\nWrite function names including parentheses as in foo() but without\nquotes.\nCRAN package submissions\nCRAN mirror security\nCurrently, there are 97 official CRAN mirrors, 67 of which provide both\nsecure downloads via https and use secure mirroring from the CRAN\nmaster (via rsync through ssh tunnels). Since the R 3.4.0 release,\nchooseCRANmirror() offers these mirrors in preference to the others\nwhich are not fully secured (yet).\nNew CRAN task views\nTracking\n\nTopic: Processing and Analysis of Tracking Data. Maintainer: Rocío\nJoo, Matthew E. Boone, Michael Sumner and Mathieu Basille. Packages:\nBBMM,\nBayesianAnimalTracker,\nEMbC,\nFLightR,\nGGIR,\nGeoLight,\nPhysicalActivity,\nSDLfilter,\nSiMRiv,\nSimilarityMeasures,\nTrackReconstruction,\nTrajDataMining,\nVTrack,\nacc,\naccelerometry,\nadehabitatHR,\nadehabitatLT\\(^*\\),\namt,\nanimalTrack,\nanipaths,\nargosfilter,\nbcpa,\nbsam,\ncaribou,\ncrawl,\nctmcmove,\nctmm,\ndiveMove,\nfoieGras,\nm2b,\nmarcher,\nmkde,\nmomentuHMM,\nmove\\(^*\\),\nmoveHMM,\nmoveVis,\nmoveWindSpeed,\nnparACT,\npawacc,\nrecurse,\nrpostgisLT,\nrsMove,\nsegclust2d,\nsmam,\nspatsoc,\ntrackdem,\ntrackeR,\ntrajectories,\ntrajr,\ntrip,\ntripEstimation,\nwildlifeDI.\n\n(* = core package)\nNew packages in CRAN task views\nChemPhys\n\nRadData,\nradsafer.\n\nDistributions\n\nMomTrunc,\nOwenQ,\nTruncatedNormal,\ndistr6,\ndistributions3,\nparameters,\nspam,\ntruncdist.\n\nEconometrics\n\ndurmod,\nlpirfs.\n\nHighPerformanceComputing\n\nRxODE.\n\nHydrology\n\nFedData,\nVICmodel,\nbaseflow,\nechor,\nnasapower,\nopenair.\n\nMachineLearning\n\nmlr3.\n\nMetaAnalysis\n\nBayesCombo,\nCopulaDTA,\nEValue,\nGENMETA,\nGMCM,\nHSROC,\nKenSyn,\nMBNMAdose,\nMBNMAtime,\nNMAoutlier,\nPRISMAstatement,\nPublicationBias,\nRBesT,\nRcmdrPlugin.MA,\nSingleCaseES,\nbaggr,\ncatmap,\neffectsize,\nharmonicmeanp,\njarbes,\nmc.heterogeneity,\nmetaBLUE,\nmetacart,\nmetapro,\nmixmeta,\nnmadb.\n\nMissingData\n\nMatchThem.\n\nNumericalMathematics\n\nHypergeoMat,\nSQUAREM,\ncalculus,\ncommonsMath,\ndaarem,\nfreealg,\njack,\nkubik,\nmatlib,\nmbend,\nturboEM,\nwedge.\n\nOfficialStatistics\n\nMatchThem,\nRJDemetra,\ndiyar,\nsimPop,\ntidyqwi.\n\nOptimization\n\nGPareto,\nJaya,\nOOR,\nSCOR,\nnonneg.cg,\nroptim.\n\nPharmacokinetics\n\nRxODE,\nnlmixr.\n\nPsychometrics\n\nconquestr,\njrt,\npsychonetrics.\n\nReproducibleResearch\n\nDataPackageR,\nProjectTemplate,\nRSuite,\nRepoGenerator,\nadapr,\ncabinets,\ndrake,\nexreport,\nhere,\nmadrat,\nmakeProject,\norderly,\nprodigenr,\nprojects,\nrenv,\nrepo,\nreports,\nreprestools,\nstorr,\ntinyProject,\nusethis,\nworkflowr,\nzoon.\n\nSpatioTemporal\n\nAtmRay,\nEMbC,\nSDLfilter,\nSiMRiv,\nSpaTimeClus,\namt,\nanipaths,\nbsam,\ncaribou,\neyelinker,\neyetracking,\neyetrackingR,\nfoieGras,\ngazepath,\nmarcher,\nmdftracks,\nmomentuHMM,\nmousetrack,\nmousetrap,\nmoveVis,\nmoveWindSpeed,\nmovecost,\noce,\nopentraj,\npsyosphere,\nrerddapXtracto,\nriverdist,\nrpostgisLT,\nrsMove,\nsaccades,\nspatsoc,\nstampr,\nstplanr,\ntrackdem,\ntrackdf,\ntrackeRapp,\ntrajectories,\ntrajr.\n\nTeachingStatistics\n\nBetaBit,\nDALEX,\nHH,\ncar,\ncarData,\neffects,\nregtools,\nresampledata.\n\nTimeSeries\n\nVARshrink,\nfable\\(^*\\),\nfeasts\\(^*\\),\nforecastML,\nfpp3,\nnsarfima,\nsazedR.\n\ngR\n\nbnclassify,\nmgm,\nqgraph,\nsna.\n\n(* = core package)\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2019-2-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2019-2 issue.",
    "author": [
      {
        "name": "Michael J. Kane",
        "url": {}
      }
    ],
    "date": "2019-12-01",
    "categories": [],
    "contents": "\n\nOn behalf of the editorial board, I am pleased to present Volume 12,\nIssue 1 of the R Journal and my second issue as the Editor in Chief.\nSince the last issue Simon Urbanek has joined the editorial board and we\nhave made a few structural changes. First, the R Foundation has approved\nthe R Journal having Associate Editors. This change will allow us to\naddress the increase in submission volume. The addition of the new AE\npositions should help alleviate some of the workload the editors have\nbeen dealing with and will result in shorter turn-around times for\nsubmissions. Second, complete issues of the R Journal will no longer be\npublished in a single pdf. The build process for the document was\ncomplex and time consuming and we were not seeing the volume of download\nthat would justify the effort. Individual articles are still available\nand the issue layout is still shown in the “Current Issue” section of\nthe web page.\n1 In this issue\nNews from the R Foundation is included in this issue along with an\nupdate from the The R Foundation’s histoRicalg project, which documents\nhistoric and historical numerical algorithms and provides reference\nimplementations in R. In addition, a reprint documenting the history of\nR, which was initially published in the History of Programming\nLanguages. Finally, this issue features 25 contributed research articles\nthat have been categorized below.\nPapers focusing on performance and novel, domain-specific applications:\n“Comparing namedCapture with other R packages for regular\nexpressions\n“cvcrand: a Package for Covariate-constrained Randomization and\nthe Clustered Permutation Test for Cluster Randomization Trials\n“Indoor Positioning and Fingerprinting: The R package ipft\nData preprocessing, imputation, validation, and exploration:\n“jomo: a Flexible Package for Two-level Joint Modelling Multiple\nImputation”\n“auditor: an R Package for Model-Agnostic Visual Validation and\nDiagnostics”\n“Fitting tails by the empirical residual coefficient of variation:\nThe ercv package”\n“The Landscape of R Packages for Automated Exploratory Data\nAnalysis”\n“The R Package trafo for Transforming Linear Regression Models”\n“orthoDr: semiparametric dimension reduction via orthogonality\nconstrained optimization”\nSpatial statistics:\n“spGARCH: An R Package for Spatial and Spatiotemporal ARCH models”\n“The IDSpatialStats R package: Quantifying spatial dependence of\ninfectious disease spread”\n“Using Web Services to Work with Geodata in R”\nTime-series analysis and finance:\n“lpirfs: An R-package to estimate impulse response functions by\nlocal projections”\n“Time Series Forecasting with KNN in R: the tsfknn Package”\n“rollmatch: An R Package for Rolling Entry Matching”\n“BondValuation: An R Package for Fixed Coupon Bond Analysis”\n“Modeling regimes with extremes: the bayesdfa package for\nidentifying and forecasting common trends and anomalies in\nmultivariate time-series data”\nClustering:\n“roahd Package: Robust Analysis of High Dimensional Data”\n“PPCI: an R Package for Cluster Identification using Projection\nPursuit”\n“ConvergenceClubs: A Package for Performing the Phillips and Sul’s\nClub Convergence Clustering Procedure”\n“biclustermd: An R Package for Biclustering with Missing Values”\nAnd supervised modeling:\n“dr4pl: A stable convergence algorithm for the 4 Parameter\nLogistic model”\n“coxed: An R Package for Computing Duration Based Quantities from\nthe Cox Proportional Hazards Model”\n“Analysis of Multivariate Data and Repeated Measures Designs with\nthe R Package MANOVA.RM”\n“Associative Classification in R: arc, arulesCBA, and rCBA”\n“HCmodelSets: An R Package for Specifying Sets of Well-fitting\nModels in High Dimensions”\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2019-2-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2019-2 issue.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2019-12-01",
    "categories": [],
    "contents": "\n1 Donations and members\nMembership fees and donations received between 2019-09-05 and\n2020-02-24.\nDonations\nAmy Tzu-Yu Chen (United States) Murat D (France) Charles Geyer (United\nStates) Susan Gruber (United States) Francesco Maria Lo Russo (Italy)\nSøren Lophaven (Denmark) J+Brian Loria (United States) Heramb Modak\n(India) Nikola Motik (Croatia) Kem Phillips (United States) Nick Redell\n(United States) Ravinderpal Vaid (United States) Dr. Alfred Wagner\n(Germany) Merck Research Laboratories, Kenilwort (United States)\nSupporting benefactors\nThomas Levine (United States) b-data GmbH, Winterthur (Switzerland)\nSupporting institutions\nFumihiko Makiyama (Japan) Code Ocean, Jenkintown (United States)\nSupporting members\nAntoniade Ciprian Alexandru (Romania) Tim Appelhans (Germany) Srinivas B\n(India) Michael Blanks (United States) Gordon Blunt (United Kingdom)\nShannon Callan (United States) Gilberto Camara (Brazil) Susan M Carlson\n(United States) Michael Chirico (United States) Gerard Conaghan (United\nKingdom) Terry Cox (United States) Robin Crockett (United Kingdom)\nRobert Daly (Australia) Gergely Daroczi (Hungary) Steph de Silva\n(Australia) Ajit de Silva (United States) Elliott Deal (United States)\nJasja Dekker (Netherlands) Michael Dorman (Israel) Johan Eklund (Sweden)\nShalese Fitzgerald (United States) Neil Frazer (United States) Keita\nFukasawa (Japan) Laura Gabrysiak (United States) J. Antonio García\n(Mexico) Brian Gramberg (Netherlands) Krushi Gurudu (United States)\nHlynur Hallgrímsson (Iceland) Joe Harwood (United Kingdom) Bela Hausmann\n(Austria) Arnošt Komárek (Czechia) Miha Kosmac (United Kingdom) Jan\nHerman Kuiper (United Kingdom) Hoonjeong Kwon (Republic of Korea) Mauro\nLepore (United States) Chin Soon Lim (Singapore) Daniel McNichol (United\nStates) Tore Christian Michaelsen (Norway) Guido (Germany) Yoshinobu\nNakahashi (Japan) Dan Orsholits (Switzerland) George Ostrouchov (United\nStates) Antonio Paez (Canada) Peter Perez (United States) Elgin Perry\n(United States) Fergus Reig Gracia (Spain) Ingo Ruczinski (United\nStates) Antonio J. Saez-Castillo (Spain) Pieta Schofield (United\nKingdom) Jagat Sheth (United States) Rachel Smith-Hunter (United States)\nBerthold Stegemann (Germany) Tobias Strapatsas (Germany) Robert Szabo\n(Sweden) Waldemar T Talen (United States) Koray Tascilar (Germany)\nMichael Tiefelsdorf (United States) Uku Vainik (Estonia) Marcus Vollmer\n(Germany) Jaap Walhout (Netherlands) Sandra Ware (Australia)\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2019-1-ch/",
    "title": "R News",
    "description": "The 'R News' article from the 2019-1 issue.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2019-06-01",
    "categories": [],
    "contents": "\n\nThis article is converted from a Legacy LaTeX article using the texor package. The pdf version is the official version. To report a problem with the html, refer to CONTRIBUTE on the R Journal homepage.\nThis article includes tables which may not be properly formatted. This article includes figures which have not been given correct alternative text.\n\n\n1 CHANGES IN R 3.6.1\n\nINSTALLATION on a UNIX-ALIKE\nThe default detection of the shell variable libNN is overridden\nfor derivatives of Debian Linux, some of which have started to have\na ‘/usr/lib64’ directory. (E.g. Ubuntu 19.04.) As before, it can be\nspecified in ‘config.site’.\n\n\nUTILITIES\nR CMD knows the values of AR and RANLIB, often set for LTO builds.\n\n\nBUG FIXES\nOn Windows, GUI package installation via menuInstallPkgs() works\nagain, thanks to Len Weil’s and Duncan Murdoch’s PR#17556.\nquasi(*, variance = list(..)) now works more efficiently, and\nshould work in all cases fixing PR#17560. Further,\nquasi(var = mu(1-mu)) and quasi(var = \"mu 3̂\") now work, and\nquasi(variance = \"log(mu)\") now gives a correct error message.\nCreation of lazy loading database during package installation is\nagain robust to Rprofile changing the current working directory\n(PR#17559).\nboxplot(y   f, horizontal=TRUE) now produces correct x- and\ny-labels.\nrbind.data.frame() allows to keep <NA> levels from factor\ncolumns (PR#17562) via new option factor.exclude.\nAdditionally, it works in one more case with matrix-columns which\nhad been reported on 2017-01-16 by Krzysztof Banas.\nCorrect messaging in C++ pragma checks in tools code for\nR CMD check, fixing PR#17566 thanks to Xavier Robin.\nprint()ing and auto-printing no longer differs for functions with a\nuser defined print.function, thanks to Bill Dunlap’s report.\nOn Windows, writeClipboard(.., format = <n>) now does correctly\npass format to the underlying C code, thanks to a bug report (with\npatch) by Jenny Bryan.\nas.data.frame() treats 1D arrays the same as vectors, PR#17570.\nImprovements in smoothEnds(x, *) working with NAs (towards\nrunmed() working in that case, in the next version of R).\nvcov(glm(<quasi>), dispersion = *) works correctly again, fixing\nPR#17571 thanks to Pavel Krivitsky.\nR CMD INSTALL of binary packages on Windows now works also with\nper-directory locking.\nR CMD INSTALL and install.packages() on Windows are now more\nrobust against a locked file in an earlier installation of the\npackage to be installed. The default value of option install.lock on\nWindows has been changed to TRUE.\nOn Unix alikes (when readline is active), only expand tilde ( )\nfile names starting with a tilde, instead of almost all tildes.\n\n2 OTHER RECENT SIGNIFICANT CHANGES IN R\nThere were two important, user-visible changes in version 3.6.0:\nSerialization format version 3 becomes the default for serialization\nand saving of the workspace\n(save(), serialize(), saveRDS(), compiler::cmpfile()). Serialized\ndata in format 3 cannot be read by versions of R prior to version\n3.5.0. Serialization format version 2 is still supported and can be\nselected by version = 2 in the save/serialization functions. The\ndefault can be changed back for the whole R session by setting\nenvironment variables R_DEFAULT_SAVE_VERSION and\nR_DEFAULT_SERIALIZE_VERSION to 2. For maximal back-compatibility,\nfiles vignette.rds and partial.rdb generated by R CMD build are\nin serialization format version 2, and resave by default produces\nfiles in serialization format version 2 (unless the original is\nalready in format version 3).\nThe default method for generating from a discrete uniform\ndistribution (used in sample(), for instance) has been changed.\nThis addresses the fact, pointed out by Ottoboni and Stark, that the\nprevious method made sample() noticeably non-uniform on large\npopulations. See PR#17494 for a discussion. The previous method can\nbe requested using RNGkind() or RNGversion() if necessary for\nreproduction of old results. Thanks to Duncan Murdoch for\ncontributing the patch and Gabe Becker for further assistance.\nThe output of RNGkind() has been changed to also return the kind\nused by sample().\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2019-1-cran/",
    "title": "Changes on CRAN",
    "description": "The \"Changes on CRAN\" article from the 2019-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2019-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2019-1-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2019-1 issue.",
    "author": [
      {
        "name": "Norm Matloff",
        "url": {}
      }
    ],
    "date": "2019-06-01",
    "categories": [],
    "contents": "\n\nThis article is converted from a Legacy LaTeX article using the texor package. The pdf version is the official version. To report a problem with the html, refer to CONTRIBUTE on the R Journal homepage.\nThis article includes tables which may not be properly formatted. This article includes figures which have not been given correct alternative text.\n\n\nThe editorial board and I are pleased to present the latst issue of the\nR Journal.\nWe apologize that this issue has been so late in publication. As this is\nmy first issue as Editor-in-Chief, I must personally thank Roger Bivand\nand John Verzani, the two previous EiCs, for their guidance in the\ntechnical aspects of putting an issue together.\nThe good news, though, is that publication should be much more timely in\nthe future, due to improved internal technical documentation and the\nhiring of the journal’s first-ever editorial assistants, Stephanie\nKobakian and Mitchell O’Hara-Wild. We are thankful to the R Consortium\nfor a grant supporting the assistants (https://rjpilot.netlify.com).\nThis issue is chock full of interesting papers, many of them on\nintriguing, unusual topics. For those of us whose connection to R goes\nback to the old S days, it is quite gratifying to see the wide diversity\nof application areas in which R has been found productive.\nRegular readers of this journal are aware of a change in policy that\nbegan January 2017, under which we are moving away from a paradigm in\nwhich a typical article is merely an extended user’s manual for the\nauthor’s R package.\nTo be sure, most articles will continue to be tied to specific packages.\nBut we hope for broader coverage, and even the package-specific articles\nshould emphasize aspects such as technical challenges the package needed\nto overcome, how it compares in features and performance to similar\npackages, and so on. As described in the announcement:\n\nShort introductions to contributed R packages that are already\navailable on CRAN or Bioconductor, and going beyond package vignettes\nin aiming to provide broader context and to attract a wider readership\nthan package users. Authors need to make a strong case for such\nintroductions, based for example on novelty in implementation and use\nof R, or the introduction of new data structures representing general\narchitectures that invite re-use.\n\nClearly, there is some subjectivity in assessing these criteria, and\nviews will vary from one handling editor to the next. But this is the\ncurrent aim of the journal, so please keep it in mind in your\nsubmissions.\nWe wish the journal to further evolve in two more senses:\nIn 2016, the American Statistical Assocation released a dramatic\npolicy statement, seriously questioning the general usefulness and\npropriety of p-values. Though the statement did not call for a ban\non the practice, it did have a strong theme that p-values should be\nused more carefully and less often. Many of us, of course, had been\nadvocating a move away from p-values for years. We wish authors of\nfuture submissions to the journal to be mindful of the ASA policy\nstatement. We hope for reduced emphasis on hypothesis testing, and\nin articles that do include testing, proper consideration of power\ncalculation.\nIn the interest of reproducibility—a requirement already imposed\nby the journal on article submissions—we will require that any\nreal datasets used as examples in an article must be provided. Note\nthat this will mean that datasets with privacy issues or datasets of\nextremely large size should not be used in an article.\nFinally, we note our deep appreciation for the anonymous reviewers. A\njournal is only as good as its reviewers, and most reviews are quite\nthoughtful and useful. If a handling editor solicits your review for a\npaper, please make some time for it. And if you must decline the\nrequest, a reply to that effect would be quite helpful; don’t just\ndiscard the editor’s e-mail message. The handling editors are quite\nbusy, and it is unfair to both them and the authors to have the editors\nwait until they must conclude you will not reply, causing unnecessary\ndelay.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2019-1-foundation/",
    "title": "R Foundation News",
    "description": "The \"R Foundation News\" article from the 2019-1 issue.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2019-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2018-2-bioc/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2018-2 issue.",
    "author": [
      {
        "name": "Bioconductor Core Team",
        "url": {}
      }
    ],
    "date": "2018-12-01",
    "categories": [],
    "contents": "\n\nThe Bioconductor project provides tools\nfor the analysis and comprehension of high-throughput genomic data.\nBioconductor 3.8 was released on 31 October, 2018. It is compatible\nwith R 3.5.2 and consists of 1649 software packages, 360 experiment data\npackages, and 941 up-to-date annotation packages. The release\nannouncement includes\ndescriptions of 95 new software packages and updated NEWS files for many\nadditional packages.\nStart using Bioconductor by installing the most recent version of R\nand evaluating the commands\n  if (!requireNamespace(\"BiocManager\"))\n      install.packages(\"BiocManager\")\n  BiocManager::install()\nInstall additional packages and dependencies, e.g.,\nSingleCellExperiment,\nwith\n  BiocManager::install(\"SingleCellExperiment\")\nAdditional installation instructions\nare available. Docker and\nAmazon images\nprovide an effective on-ramp for power users to rapidly obtain access to\nstandardized and scalable computing environments. Key resources include:\nThe bioconductor.org web site to\ninstall, learn, use, and develop Bioconductor packages.\nA listing of available\nsoftware, linking to pages\ndescribing each package.\nA question-and-answer style user support\nsite and developer-oriented\nmailing list.\nThe F1000Research Bioconductor\nchannel for\npeer-reviewed Bioconductor work flows.\nOur package\nsubmission\nrepository for open technical review of new packages.\nThe Bioconductor community\nslack for in-depth\nconversation about Bioconductor software use and development.\nKey training resources include common\nworkflows\nand last year’s conference workshop\nbooklet. Our annual\nconference will be on June 24\nthrough 27, 2019 in New York City, with a line-up of morning scientific\ntalks and afternoon user-oriente hands-on workshops, as well as a\ndeveloper day, starting to take shape.\n\n\nBioconductor packages used\nSingleCellExperiment\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2018-2-ch/",
    "title": "Changes in R",
    "description": "The 'Changes in R' article from the 2018-2 issue.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2018-12-01",
    "categories": [],
    "contents": "\n\nCHANGES IN R 3.5.2\n\nPACKAGE INSTALLATION\nNew macro CXX_VISIBILITY analogous to C_VISIBILITY (which\nseveral packages have been misusing for C++ code) for the default\nC++ compiler (but not necessarily one used for non-default C++\ndialects like C++14).\n\n\nTESTING\nThe random number generator tests in tests/p-r-random-tests.R no\nlonger fail occasionally as they now randomly sample from\n“certified” random seeds.\n\n\nBUG FIXES\nThe \"glm\" method of drop1() miscalculated the score test\n(test=\"Rao\") when the model contained an offset.\nLinear multiple empty models such as lm(y ~ 0) now have a\ncorrectly dimensioned empty coefficient matrix; reported by Brett\nPresnell.\nvcov(<empty mlm>) and hence confint() now work (via a\nconsistency change in summary.lm()).\nconfint(<multiple lm()>) now works correctly; reported on R-devel\nby Steven Pav.\nquade.test() now also works correctly when its arguments are not\nyet sorted along groups, fixing\nPR#15842.\nInstallation on a Unix-alike tries harder to link to the pthread\nlibrary where required (rather than relying on OpenMP to provide it:\nconfiguring with –disable-openmp was failing on some Linux\nsystems).\nThe data.frame method for print(x) is fast now also for large\ndata frames x and got an optional argument max, thanks to\nsuggestions by Juan Telleria.\nhist() no longer integer overflows in very rare cases, fixing\nPR#17450.\nuntar() ignored a character compressed argument: however many\nexternal tar programs ignore the flags which should have been set\nand automagically choose the compression type, and if appropriate\ngzip or bzip2 compression would have been chosen from the magic\nheader of the tarball.\nzapsmall(x) now works for more “number-like” objects.\nThe tools-internal function called from R CMD INSTALL now gets a\nwarnOption = 1 argument and only sets options(warn = warnOption)\nwhen that increases the warning level\n(PR#17453).\nAnalogously, the tools-internal function called from R CMD check\ngets a warnOption = 1 argument and uses the larger of that and\ngetOption(\"warn\"), also allowing to be run with increased warning\nlevel.\nParse data now have deterministic parent nodes\n(PR#16041).\nCalling match() with length one x and POSIXlt table gave a\nsegfault\n(PR#17459).\nFork clusters could hang due to a race condition in cluster\ninitialization (makeCluster()).\nnextn(n) now also works for larger n and no longer loops\ninfinitely for e.g, n <- 214e7.\ncooks.distance() and rstandard() now work correctly for multiple\nlinear models (\"mlm\").\npolym() and corresponding lm() prediction now also work for a\nboundary \"vector\" case fixing\nPR#17474,\nreported by Alexandre Courtiol.\nWith a very large number of variables terms() could segfault\n(PR#17480).\ncut(rep(0, 7)) now works, thanks to Joey Reid and Benjamin Tyner\n(PR#16802).\ndownload.file(*, method = \"curl\", cacheOK = FALSE) should work now\non Windows, thanks to Kevin Ushey’s patch in\nPR#17323.\nduplicated(<dataframe with ’f’>) now works, too, thanks to Andreas\nKersting’s\nPR#17485;\nditto for anyDuplicated().\nlegend(*, cex = 1:2) now works less badly.\nThe print() method for POSIXct and POSIXlt now correctly obeys\ngetOption(\"max.print\"), fixing a long-standing typo, and it also\ngets a corresponding optional max argument.\nUnserialization of raw vectors serialized in ASCII representation\nnow works correctly.\n<data frame>[TRUE, <new>] <- list(c1, c2) now works correctly,\nthanks to Suharto Anggono’s\nPR#15362\nand Emil Bode’s patch in\nPR#17504.\nseq.int(*, by=by, length=n) no longer wrongly “drops fractional\nparts” when by is integer, thanks to Suharto Anggono’s report\nPR#17506.\nBuffering is disabled for file() connections to non-regular files\n(like sockets), as well as fifo() and pipe() connections. Fixes\nPR#17470,\nreported by Chris Culnane.\n\nCHANGES IN R 3.5.1\n\nBUG FIXES\nfile(\"stdin\") is no longer considered seekable.\ndput() and dump() are no longer truncating when\noptions(deparse.max.lines = *) is set.\nCalls with an S3 class are no longer evaluated when printed, fixing\npart of\nPR#17398,\nthanks to a patch from Lionel Henry.\nAllow file argument of Rscript to include space even when it is\nfirst on the command line.\ncallNextMethod() uses the generic from the environment of the\ncalling method. Reported by Hervé Pagès with well documented\nexamples.\nCompressed file connections are marked as blocking.\noptim(*, lower = c(-Inf, -Inf)) no longer warns (and switches the\nmethod), thanks to a suggestion by John Nash.\npredict(fm, newdata) is now correct also for models where the\nformula has terms such as splines::ns(..) or stats::poly(..),\nfixing\nPR#17414,\nbased on a patch from Duncan Murdoch.\nsimulate.lm(glm(*, gaussian(link = <non-default>))) has been\ncorrected, fixing\nPR#17415\nthanks to Alex Courtiol.\nunlist(x) no longer fails in some cases of nested empty lists.\nReported by Steven Nydick.\nqr.coef(qr(<all 0, w/ colnames>)) now works. Reported by Kun Ren.\nThe radix sort is robust to vectors with >1 billion elements (but\nlong vectors are still unsupported). Thanks to Matt Dowle for the\nfix.\nTerminal connections (e.g., stdin) are no longer buffered. Fixes\nPR#17432.\ndeparse(x), dput(x) and dump() now respect c()’s argument\nnames recursive and use.names, e.g., for\nx <- setNames(0, \"recursive\"), thanks to Suharto Anggono’s\nPR#17427.\nUnbuffered connections now work with encoding conversion. Reported\nby Stephen Berman.\n.Renviron on Windows with Rgui is again by default searched for\nin user documents directory when invoked via the launcher icon.\nReported by Jeroen Ooms.\nprintCoefmat() now also works with explicit right=TRUE.\nprint.noquote() now also works with explicit quote=FALSE.\nThe default method for pairs(.., horInd=*, verInd=*) now gets the\ncorrect order, thanks to reports by Chris Andrews and Gerrit\nEichner. Additionally, when horInd or verInd contain only a\nsubset of variables, all the axes are labeled correctly now.\nagrep(\"..|..\", .., fixed=FALSE) now matches when it should, thanks\nto a reminder by Andreas Kolter.\nstr(ch) now works for more invalid multibyte strings.\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2018-2-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2018-2 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2018-12-01",
    "categories": [],
    "contents": "\n\nIn the past 6 months, 1029 new packages were added to the CRAN package\nrepository. 68 packages were unarchived, 122 archived, and one removed.\nThe following shows the growth of the number of active packages in the\nCRAN package repository:\n\nOn 2018-12-31, the number of active packages was around 13592.\nChanges in the CRAN Repository Policy\nThe Policy now\nsays the following:\nPackages which use Internet resources should fail gracefully with an\ninformative message if the resource is not available (and not give a\ncheck warning nor error).\nCRAN package submissions\nDuring the last 6 months (July to December 2018), CRAN received 10259\npackage submissions. For these, 16830 actions took place of which 11618\n(69%) were auto processed actions and 5212 (31%) manual actions.\nMinus some special cases, a summary of the auto-processed and manually\ntriggered actions follows:\naction\narchive\ninspect\npending\npretest\npublish\nrecheck\nauto\n2731\n4341\n460\n0\n3148\n938\nmanual\n1902\n70\n286\n145\n2262\n547\nThese include the final decisions for the submissions which were\naction\narchive\npublish\nauto\n2562 (26.1%)\n2779 (28.3%)\nmanual\n1861 (18.9%)\n2620 (26.7%)\nwhere we only count those as auto processed whose publication happened\nautomatically in all steps.\nCRAN mirror security\nCurrently, there are 100 official CRAN mirrors, 68 of which provide both\nsecure downloads via https and use secure mirroring from the CRAN\nmaster (via rsync through ssh tunnels). Since the R 3.4.0 release,\nchooseCRANmirror() offers these mirrors in preference to the others\nwhich are not fully secured (yet).\nNew CRAN task views\nDatabases\n\nTopic: Databases with R. Maintainer: Yuan Tang. Packages:\nDBI\\(^*\\),\nDBItest,\nMonetDBLite,\nR4CouchDB,\nRCassandra,\nRGreenplum,\nRH2,\nRJDBC,\nRMariaDB,\nRMySQL,\nROracle,\nRPostgreSQL,\nRPostgres,\nRPresto,\nRSQLite,\nRcppRedis,\nTScompare,\nbigrquery,\ndbfaker,\ndbplyr,\ndplyr,\ndplyr.teradata,\nelastic,\nfilehashSQLite,\nimplyr,\ninfluxdbr,\nliteq,\nmongolite,\nodbc\\(^*\\),\npivot,\npointblank,\npool,\nredux,\nrpostgis,\nsqldf,\ntidyr,\nuptasticsearch.\n\nMissingData\n\nTopic: Missing Data. Maintainer: Julie Josse, Nicholas Tierney and\nNathalie Vialaneix (r-miss-tastic team). Packages:\nAmelia\\(^*\\),\nBaBooN,\nBaylorEdPsych,\nCALIBERrfimpute,\nCMF,\nCRTgeeDR,\nCVThresh,\nCoImp,\nDMwR,\nDTWBI,\nDTWUMI,\nDescTools,\nDiffusionRimp,\nDrImpute,\nFHDI,\nFamEvent,\nFastImputation,\nForImp,\nGSE,\nGenForImp,\nHaplin,\nHardyWeinberg,\nHmisc,\nHotDeckImputation,\nJointAI,\nMissMech,\nMixedDataImpute,\nNNLM,\nNPBayesImputeCat,\nOpenMx,\nPSIMEX,\nPSM,\nPST,\nQTLRel,\nQtools,\nRNAseqNet,\nROptSpace,\nRmagic,\nRphylopars,\nSNPassoc,\nStAMPP,\nStatMatch,\nStratifiedRF,\nTAM,\nTAR,\nTVsMiss,\nTestDataImputation,\nTippingPoint,\nTreePar,\nTreeSim,\nVIM\\(^*\\),\nVIMGUI,\nVarSelLCM,\nWaverR,\naccelmissing,\nade4,\nalleHap,\nbrlrmr,\ncat,\ncdparcoord,\ncobalt,\ncutoffR,\ndejaVu,\ndenoiseR,\ndils,\ndlookr,\neigenmodel,\nexperiment,\nextracat,\nfastLink,\nfilling,\nforecast,\ngapfill,\ngsynth,\nhmi,\nhot.deck\\(^*\\),\nicdGLM,\nicenReg,\nidealstan,\nidem,\nimputePSF,\nimputeTS\\(^*\\),\nimputeTestbench,\nipw,\njomo\\(^*\\),\nlavaan,\nltm,\nmdmb,\nmemisc,\nmi,\nmice\\(^*\\),\nmiceFast,\nmiceMNAR,\nmiceadds,\nmicemd,\nmirt,\nmissForest,\nmissMDA\\(^*\\),\nmitml,\nmitools,\nmix,\nnaniar\\(^*\\),\nnipals,\nnorm,\npadr,\npan,\nphylin,\nplsRglm,\npowerlmm,\nprefmod,\nprophet,\npseval,\nrandomForest,\nreddPrec,\nrobCompositions,\nrobustrao,\nrsem,\nrtop,\nsamon,\nsbart,\nsbgcop,\nscorecardModelUtils,\nsimputation,\nsjlabelled,\nsjmisc,\nsmcfcs,\nsoftImpute\\(^*\\),\nspacetime,\nsptemExp,\nstlplus,\nswgee,\ntabplot,\ntidyimpute,\ntimeSeries,\ntsibble,\nwNNSel,\nwrangle,\nxts,\nyaImpute\\(^*\\),\nzCompositions,\nzoo.\n\n(* = core package)\nNew packages in CRAN task views\nChemPhys\n\nATmet,\nMALDIrppa,\nNISTunits,\nconstants,\nerrors,\nfingerprint,\nmeasurements,\nmetRology,\nspectralAnalysis,\nunits.\n\nCluster\n\nMixAll.\n\nDifferentialEquations\n\ndiffeqr,\nsundialr.\n\nDistributions\n\nWrapped,\nbivariate,\npgdraw.\n\nEconometrics\n\nbife,\nnse.\n\nFinance\n\nPeerPerformance,\ncrseEventStudy,\nriskParityPortfolio.\n\nHighPerformanceComputing\n\nbigstatsr,\nqsub.\n\nMetaAnalysis\n\nMetaStan,\nMetaSubtract,\ndfmeta,\nmetamedian,\nofGEM,\npuniform.\n\nNumericalMathematics\n\nchebpol,\nfreegroup.\n\nOfficialStatistics\n\nBayesSAE,\nRRreg,\nSmallCountRounding,\ncensus,\ncensusGeography,\nemdi,\nidbr,\nipumsr,\nnoncensus,\nsae,\ntidycensus.\n\nOptimization\n\ncaRamel,\nlbfgsb3c,\nnilde,\nosqp.\n\nPhylogenetics\n\napex,\naphid,\nbrms,\nbrranching,\necospat,\nentropart,\nenveomics.R,\nhisse,\nmetacoder,\nnodiv,\npicante,\nwarbleR.\n\nPsychometrics\n\nNetworkToolbox,\nTreeBUGS,\ncNORM,\nequateMultiple,\nifaTools,\nmudfold.\n\nSpatial\n\nRPostgreSQL,\ncartogram,\ngeogrid,\ngeometa,\ngeonapi,\ngeosapi,\ninlmisc,\nlandscapemetrics,\nleaflet,\nlwgeom,\nows4R,\nrnaturalearth,\nstars.\n\nTimeSeries\n\nARCensReg,\nFKF,\nGNAR,\nNTS,\nRTransferEntropy,\nTSEntropies,\nchangepoint.mv,\ndsa,\nggTimeSeries,\ngmvarkit,\ngraphicalVAR,\nimputePSF,\nimputeTestbench,\nmgm,\nmultDM,\nrollRegres,\nsugrrants,\nsym.arma,\ntbrf.\n\nWebTechnologies\n\nHIBPwned,\nLendingClub,\nOpenML,\nRSauceLabs,\nRSocrata,\nRcrawler,\nWikidataQueryServiceR,\nZillowR,\najv,\nanalogsea,\naws.polly,\naws.s3,\naws.sns,\nbanR,\nbirdnik,\nbrandwatchR,\ncolourlovers,\ncrminer,\ncrplyr,\ncrul\\(^*\\),\ncrunch,\ncrunchy,\ndocuSignr,\nduckduckr,\nfacebook.S4,\nfauxpas,\nfeedeR,\nfulltext,\nganalytics,\ngdns,\ngeonapi,\ngeosapi,\ngh,\ngiphyr,\ngoogleComputeEngineR,\ngoogleLanguageR,\nhtm2txt,\nhtmltidy,\nhtmltools,\nhttpcode,\nhttptest,\ninternetarchive,\niptools,\njs,\njstor,\nlanguagelayeR,\nmapsapi,\nmathpix,\nndjson,\nnotifyme,\nowmr,\nows4R,\npivotaltrackR,\nplotly,\npostlightmercury,\nradiant,\nrapiclient,\nrcoreoa,\nrcrossref,\nrdpla,\nrdrop2,\nrefimpact,\nreqres,\nrerddap,\nrestfulr,\nrhub,\nrjsonapi,\nroadoi,\nrobotstxt,\nroutr,\nrpinterest,\nrtweet,\nrwars,\nsecuritytxt,\nseleniumPipes,\nsparkbq,\nspiderbar,\nswagger,\ntidyRSS,\ntrelloR,\ntuber,\ntubern,\nubeR,\nudapi,\nvalidatejsonr,\nvcr\\(^*\\),\nvkR,\nwebmockr\\(^*\\),\nxslt.\n\n(* = core package)\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2018-2-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2018-2 issue.",
    "author": [
      {
        "name": "John Verzani",
        "url": {}
      }
    ],
    "date": "2018-12-01",
    "categories": [],
    "contents": "\n\nOn behalf of the editorial board, I am pleased to present Volume 10,\nIssue 2 of the R Journal.\nThis issue covers a wide range of topics through its \\(37\\) articles. As\nis typical, many of these are related to packages that provide tools for\nnew statistical modeling in R. Examples in this issue include\n\"clustMixType: User-Friendly Clustering of Mixed-Type Data in R\" by\nSzepannek and \"BNSP: an R Package for Fitting Bayesian Semiparametric\nRegression Models and Variable Selection\" by Papageorgiou.\nSeveral contributions highlight new packages that enhance and extend\nexisting modeling areas. Examples of this are \"Forecast Combinations in\nR using the ForecastComb Package\" by Weiss, Raviv, and Roetzer;\n\"testforDEP: An R Package for Modern Distribution-free Tests and\nVisualization Tools for Independence\" by Miecznikowski, Hsu, Chen, and\nVexler; \"NetworkToolbox: Methods and Measures for Brain, Cognitive,\nand Psychometric Network Analysis in R\" by Christensen; and\n\"bnclassify: Learning Bayesian Network Classifiers\" by Mihaljevic,\nBielza, and Larrañaga\".\nSome of the contributions include easier interfaces to modeling, such as\n\"SARIMA Analysis and Automated Model Reports with BETS, an R\nPackage\" by Speranza, Ferreira, and da Costa and \"ShinyItemAnalysis\nfor Teaching Psychometrics and to Enforce Routine Analysis of\nEducational Tests\" by Martinková and Drabinová.\nOther modeling topics are estimation, as in \"SMM: An R Package for\nEstimation and Simulation of Discrete-time semi-Markov Models\" by\nVergne, Barbu, Bérard, Cellier, and Sautreuil; missing data, as in\n\"Profile Likelihood Estimation of the Correlation Coefficient in the\nPresence of Left, Right or Interval Censoring and Missing Data\" by Li,\nGillespie, Shedden, and Gillespie; and large data, as with\n\"Basis-Adaptive Selection Algorithm in dr-package\" by Yoo.\nIncluded in this volume are two submissions extending R’s visualization\ncapabilities: \"ggplot2 Compatible Quantile-Quantile Plots in R\" by\nLoy, Almeida, and Hofmann and \"Geospatial Point Density\" by\nEvangelista and Beskow.\nSeveral new tools are described in the articles. New takes on some\nprogramming idioms are given in \"Dot-Pipe: an S3 Extensible Pipe for\nR\" by Mount and Zumel; some libraries from other languages have been\nported over, such as described in \"sdpt3r: Semidefinite Quadratic\nLinear Programming in R\" by Rahman; and interfaces to other languages\nare detailed in \"jsr223: A Java Platform Integration for R with\nProgramming Languages Groovy, JavaScript, JRuby, Jython, and Kotlin\" by\nGilbert and Dahl and \"RcppMsgPack: MsgPack Headers and Interface\nFunctions for R\" by Eddelbuettel and Ching.\nAs usual, we have a few application areas represented in this issue, for\nexample \"stplanr: A Package for Transport Planning\" by Lovelace and\nEllison.\nFinally, as much as the R Journal helps put some sense of order to R’s\necosystem, it can’t possibly cover the tremendous growth (CRAN grew to\n13,592 packages by year’s end; Bioconductor reports 1649 software\npackages). Silge, Nash, and Graves provide some insight in \"Navigating\nthe R Package Universe.\"\nThere are notes from several conferences included. These highlight R’s\nexpanded reach into Latin America and Poland in addition to its reach\ninto the pharmaceutical and medical professions. The are also the usual\nreports about changes to CRAN, Bioconductor, and R; and a report from\nthe R Foundation.\nThis year, Di Cook joins the Editorial Board, as Roger Bivand rotates\noff. I extend my thanks to Roger for his many contributions. His efforts\nnow allow us to add digital object identifiers (DOIs) for R Journal\narticles. I am very excited about all that Di will bring. She is already\noff and running, securing funding from the R Foundation that will allow\nthe journal to have some paid assistance. I also wish to acknowledge the\nhard work of Norm Matloff and Olivia Lau. The R Journal’s popularity has\ngrown–the two volumes of 2018 are over 1100 printed pages–and these\ntwo were instrumental in managing the growth.\nFinally, I would like to thank the many reviewers that made this edition\npossible. In my view, one of the biggest contributions of the R Journal\nis to provide peer review for R’s sprawling package ecosystem and this\nonly happens through the dedicated, informed, volunteer efforts of the\nreviewers.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2018-2-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2018-2 issue.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2018-12-01",
    "categories": [],
    "contents": "\n1 Donations and members\nMembership fees and donations received between 2018-08-13 and\n2019-01-07.\nDonations\nPedro Albuquerque (France), Robert Baskin (United States), Shalese\nFitzgerald (United States), Michael Forster (Austria), Brian Gough\n(United Kingdom), Gen KOBAYASHI (Japan), Ravinderpal Vaid (United\nStates), and Novartis Pharma AG, (Basel, Switzerland)\nSupporting benefactors\nJay Raol (United States) and b-data GmbH, (Zürich, Switzerland)\nSupporting institutions\nGeneral Counsel Metrics, LLC, PRINCETON (United States), Marine\nScotland, (Aberdeen City Aberdeen, United Kingdom), and vizGet,\n(Autrans, France)\nSupporting members\nTim Appelhans (Germany), Joaquín Baquer-Miravete (Spain), Marcel\nBaumgartner (Switzerland), Daniel Booth (Australia), Petr Bouchal (Czech\nRepublic), Florian Brezina (Germany), Robert Daly (Australia), Steph de\nSilva (Australia), Ajit de Silva (United States), Jasja Dekker\n(Netherlands), Shaban Demirel (United States), Lukman Edwindra\n(Indonesia), Arturo Erdely (Mexico), Michael Feyder (United States),\nNaohiro Furutani (Japan), Jan Galkowski (United States), Krushi Gurudu\n(United States), Karl Habermeier (United States), Joe Harwood (United\nKingdom), Bela Hausmann (Austria), Joshua Hruzik (Germany), Abner\nHuertas (Guatemala), Ken Ikeda (Japan), Larry Jamner (United States),\nKnut Helge Jensen (Norway), Woojune Jung (Korea, Republic of), June Kee\nKim (Korea, Republic of), Miha Kosmac (United Kingdom), Jan Herman\nKuiper (United Kingdom), Yannick Lelu (France), Chin Soon Lim\n(Singapore), Michael Mahoney (United States), Daniel McNichol (United\nStates), Guido (Germany), Yoshinobu Nakahashi (Japan), Vialaneix\nNathalie (France), Michael Neale (United States), Mark Niemann-Ross\n(United States), Berk Orbay (Turkey), Dan Orsholits (Switzerland), Mucio\nOsorio (Mexico), Floris Padt (Netherlands), Peter Perez (United States),\nElgin Perry (United States), Que Binh Phung (France), Emma Rand (United\nKingdom), Ma Reader (United Kingdom), Kun Ren (China), Marty Rose\n(United States), Ingo Ruczinski (United States), Antonio J.\nSaez-Castillo (Spain), Sarah Shakil (Canada), Jagat Sheth (United\nStates), Kevin Shook (Canada), Rachel Smith-Hunter (United States),\nTobias Strapatsas (Germany), Robert Szabo (Sweden), Koray Tascilar\n(Germany), Uku Vainik (Estonia), Jaime Vera (Colombia), Marcus Vollmer\n(Germany), Jaap Walhout (Netherlands), Sandra Ware (Australia), Nan Xiao\n(United States), Metin Yazici (Turkey), and Victor Zurkowski (Canada)\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2018-2-latinR/",
    "title": "Conference Report: LatinR 2018",
    "description": "The 'Conference Report: LatinR 2018' article from the 2018-2 issue.",
    "author": [
      {
        "name": "Laura Acion",
        "url": {}
      },
      {
        "name": "Natalia da Silva",
        "url": {}
      },
      {
        "name": "Riva Quiroga",
        "url": {}
      }
    ],
    "date": "2018-12-01",
    "categories": [],
    "contents": "\n\n1 Conference summary\nLatinR <- Latin American Conference about the Use of R in Research + Development\n(LatinR) was an international conference which goal was bringing\ntogether the Latin American R community. LatinR took place for the first\ntime at the Universidad de Palermo in Buenos Aires, Argentina, on\nSeptember 3 to 5, 2018. About 100 participants from more than 10\ndifferent countries (e.g., Argentina, Uruguay, Chile, Peru, Ecuador,\nBrazil, Costa Rica, Venezuela, Spain, United States, Canada) attended\nLatinR.\nLatinR will be an annual meeting that will rotate among different\ncountries in Latin America. LatinR 2019 will be hosted by the\nUniversidad Católica de Chile in Santiago de Chile on September 25 to\n27.\n2 Getting started\nUp to now, Latin America never hosted a useR! conference. Until 2017,\nonly Brazil, the biggest Latin American country, had some events\ngathering the local R community (i.e., R Day - Encontro Nacional de\nUsuários do R and SER - International Seminar on Statistics with R).\nOn October 25, 2017, an announcement was made by Heather Turner on the R\nUser Group (RUG) Organizers Slack: \"the R Foundation Conference\nCommittee would like to see academic-focused R events in regions not\ncurrently covered by useR!\" In less than a week, a group of academic\nLatin American R-Ladies organized their first conference call to start\nthinking about how this challenge could be achieved. This fast response\nwas not the result of mere chance, but the consequence of a year in\nwhich the R community grew stronger in South America. By mid-November,\neverything was set up: a name, a place, a date, and a motivated\ninternational organizing committee.\nTo ease the organizational load of its first edition, LatinR 2018 was\nhosted within the 47th Argentinean Meetings of Informatics and\nOperational Research (JAIIO). JAIIO usually includes about 13\nsimultaneous meetings over five days and is organized by the Argentinean\nInformatics Society (SADIO). The 47th JAIIO was not only the\norganizational umbrella under which LatinR 2018 took place but also the\nfirst time JAIIO had a Code of Conduct (CoC). The CoC was requested by\nthe R Foundation, one of LatinR endorsers, and was written by LatinR\norganizers for all meetings within JAIIO.\n3 Program\nLatinR had three official languages: Spanish, Portuguese, and English.\nIt received submissions in the three languages and had presentations\nalso in all three languages. September 3rd was dedicated to three\nhalf-day hands-on tutorials:\nNatalia da Silva: Static and interactive visualization with ggplot2\nand plotly\nAndrés Farall: Introduction to deep learning with R\nJenny Bryan: How to repeat yourself with purrr\nLatinR 2018 also had two outstanding plenary talks: \"The Zen and the\nArt of Workflow Maintenance\" by Jenny Bryan and \"Aprender a Computar\nvs. Computar para Aprender\" by Walter Sosa Escudero. Bryan presented\nthe interaction between Statistics and Data Science and several\npractical tips to learn, improve, and maintain good data workflows with\nR. On the other hand, Sosa Escudero showed some examples about how\nteaching statistics can benefit by incorporating R programming in\ntheoretical Statistics courses. Both plenary talks complemented each\nother and left a clear message about the need to embrace changes both\nwhen teaching and practicing Statistics and Data Science.\nLatinR received 93 abstracts from several different countries. Only 62\nabstracts were accepted, 32 of them were 15-minute oral presentations\nand the rest of the accepted abstracts were presented in a poster\nsession. Figure 1 shows a bar plot with the abstract\nsubmission country distribution based on first author origin. Most of\nthe submissions were from South America (Argentina, Uruguay, Peru, and\nBrazil). Nine out of the 32 oral presentations (28%) were conducted by\nwomen or other under-represented minorities (URM) in the R community.\nSeventeen out of the 30 posters (56%) had women or URM as first authors\nand out of the 8 invited talks, 6 were presented by women (75%). That\nis, out of all 40 oral presentations, 38% were presented by women or\nURM.\nFigure 1: LatinR 2018 abstract submission distribution by first author\ncountryTopics presented included applications of R in academic and industry\nsettings throughout a wide number of fields such as Data Science,\nStatistics, Informatics, Biological and Health Sciences, Atmospheric\nSciences, Social Sciences, Humanities, Economics, and Creativity. Talks\nand posters encompassed, among others, new R packages, innovative uses\nof R in Education, R visualization tools, and open data analysis with R.\nThe program also included presentations by members of vibrant\ncommunities within the R ecosystem such as Global and Latin American\nR-Ladies and The Carpentries. One of LatinR tracks during Wednesday\nmorning was a summary tutorial about how to become a Carpentries\ninstructor including 28 attendees. Wednesday was the moment of rOpenSci\nrepresented by Maëlle Salmon via teleconference and a live Q&A session\nled by Jenny Bryan. R user groups were also represented on Wednesday by\nJoshua Kunst from the Santiago de Chile RUG. The Spanish-speaking\ncommunity efforts for translating R for Data Science (R4DS) (Wickham and Grolemund 2017) was\nalso presented by Riva Quiroga, one of the project leaders.\nLatinR had a very important networking role. For instance, its three\nchairs, almost all its organizers, volunteers, and many community\nmembers (such as those working on the translation of R4DS) who were used\nto working together virtually, got to meet in person for the first time\nduring the conference. Additionally, LatinR impulsed the community in\nthe region in the form of at least three new RUGs that just launched in\nRosario, Montevideo, and Buenos Aires.\nLatinR also collaborated in a JAIIO-wide activity that debated during\ntwo hours the participation of women in sciences, technology, engineer\nand math. Six women from varied backgrounds presented their views about\nthis topic and discussed them with the attendees.\n4 Scientific and organizing committees\nLatinR was possible thanks to the effort of a highly motivated and\ncompromised team of about 80 people including: 3 chairs (100% women from\n3 Latin American countries), a 36-member scientific committee (44% women\nor URM; representing 8 countries around the globe), the SADIO organizing\nteam (88% women), and a 16-member LatinR organizing committee (88%\nwomen; representing 6 Latin American countries). In addition, a highly\nmotivated group of 15 volunteers (66% women) helped the conference run\nsmoothly. Among all these people, Yanina Bellini Saibene, Elio\nCampitelli, Paola Corrales, and Florencia D’Andrea received the Chairs’\nRecognition Award for their outstanding and continuous contribution\nsince the very beginning of LatinR.\n5 Sponsors\nLatinR was also possible to the following sponsors: RStudio, Fundación\nSadosky, Escuelas Argentinas de Nuevas Tecnologı́as, R Consortium,\nDataCamp, and IBM Argentina.\n6 Further information\nVideo of Jenny Bryan plenary talk: https://bit.ly/2EIRaEs\nVideo of Walter Sosa Escudero plenary talk: https://bit.ly/2RfwW6F\nLatinR presentations:\nhttps://github.com/LatinR/presentaciones-LatinR2018\nTwitter account: @LatinR_Conf #LatinR2018\nWebpage: http://latin-r.com\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\nH. Wickham and G. Grolemund. R for data science: Import, tidy, transform, visualize, and model data. Sebastopol, CA, USA: O’Reilly Media, Inc., 2017. URL https://r4ds.had.co.nz/. ISBN-13 978-1491910399.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2018-2-R_Medicine/",
    "title": "Conference Report: R / Medicine Report ",
    "description": "The 'Conference Report: R / Medicine Report ' article from the 2018-2 issue.",
    "author": [
      {
        "name": "Joseph Rickert",
        "url": {}
      },
      {
        "name": "Naras Balasubramanian",
        "url": {}
      },
      {
        "name": "Michael Kane",
        "url": {}
      }
    ],
    "date": "2018-12-01",
    "categories": [],
    "contents": "\n\nR has found widespread use and is flourishing in bioinformatics, the\npharmaceutical industry, clinical trials, and basic science labs. While\nR is being adopted in clinical informatics, its potential has not yet\nbeen realized. We believe R will fundamentally transform the space\nbecause of its strengths in making new methods available, the\navailability of tools for reproducible research, its interfaces to other\nlanguages, and it’s ability to disseminate new approaches through web\ninterfaces and packaging for rapid prototyping of ideas and\nimplementations.\nMoreover, while large number of clinicians, scientists, and\nstatisticians contribute to data driven medical science, communication\nbetween individuals working in similar areas has been limited. The goals\nof the R Medicine working group, and the annual R / Medicine conference,\nare: (1) to form an international community that can help to facilitate\ncollaboration and awareness of developments in the field; and (2) to do\na better job of integrating data scientists into medical research to\nform more meaningful collaborations with clinicians.\nR / Medicine 2018\nThe inaugural conference, R / Medicine 2018 (https://bit.ly/2Hzpm76),\nwas held on September 7th and 8th at a venue just off the Yale\nUniversity campus. The conference was produced by the Yale School of\nPublic Health and the Department of Biostatistics. Sponsors included the\nR Consortium, Medidata Inc., The New England Statistical Society, and\nRStudio.\nKeynotes and Talks\nFour keynote addresses were delivered: Robert Tibshirani of Stanford\nUniversity spoke about predicting platelet demand at the Stanford Blood\nCenter (https://bit.ly/2B3xWFi). Victoria Stodden of the University of\nIllinois at Urbana-Champaign presented Computational Reproducibility in\nMedical Research: Toward Open Code and Data\n(https://stanford.io/2UlAqWF). Michael Lawrence of Genentech and the R\nCore Group presented Scientific software in-the-large\n(https://bit.ly/2RU7rg4). And. Dr. Harlan Krumholz of Yale University\nand the Yale-New Haven Hospital presented Dream Crazy: Imagine the\nPossibilities of Data Science in Medicine.\nAdditional talks ranged from tutorials on Shiny and Stan to\npresentations on reproducible research and tidy models, analyzing\ngenomic data and more. For a complete list of talks refer to the\nconference website. A high point of the conference was the closing\nroundtable discussion with the theme Bridging the Two Cultures. This\nconsidered how the professional representing the statistical and\nclinical points of view may conceptualize and approach medical\nchallenges in very different ways. For a fuller account of this\ndiscussion and the conference as a whole see https://bit.ly/2Myn5rm.\nOrganizing and Program Committees\nThe conference organizing committee consisted of: Beth Atkinson, The\nMayo Clinic; Denise Esserman, Yale University; Michael Kane, Yale\nUniversity (Conference Chair); Balasubramanian Narasimhan (Naras),\nStanford University; Joseph Rickert, RStudio; and Hongyu Zhao, Yale\nUniversity.\nThe program committee was composed of Denise Esserman (Program Chair),\nBeth Atkinson, Michael Kane, Balasubramanian Narasimhan, and Hongyu Zhao\nR / Medicine 2019\nR / Medicine 2019 will be held at Yale University from September 19th\nthrough September 21st. The conference goal is to grow the community and\nnurture the conversation about developing useful clinical research and\noperational solutions. The conference organizers invite clinicians,\nstatistical researchers and others who have an interest in promoting R\nin clinical practice and medical research to participate however they\ncan. We also invite interested organizations to consider sponsoring R /\nMedicine 2019. Please watch the website below for announcements\nregarding abstract submissions, sponsorship opportunities and important\ndates.\nR / Medicine 2019 conference website: https://r-medicine.com/\nTwitter: #rmedicine\nFor information:\nr-medicine@protonmail.com\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2018-2-R_Pharma/",
    "title": "Conference Report: R / Pharma 2018",
    "description": "The 'Conference Report: R / Pharma 2018' article from the 2018-2 issue.",
    "author": [
      {
        "name": "Joseph Rickert",
        "url": {}
      }
    ],
    "date": "2018-12-01",
    "categories": [],
    "contents": "\n\nThe R / Pharma conference began as grass-roots initiative led by data\nscientists working in the pharmaceutical industry to promote the use of\nR in Pharma, and to establish and share best practices. The founding\nmembers organized the project as an R Consortium working group, and\nundertook the ambitious task of launching an annual conference\nenvisioned as a relatively small, collegial, industry-oriented event\nwith a strong scientific program.\nInaugural Conference\nThe inaugural conference, R / Pharma 2018 (https://bit.ly/2RVKKI8)\nheld on August 16th and 17th at Harvard University attracted a\nrepresentatives from academia, government, and industry.\nFigure 1: R / Pharma 2018 participantsKeynotes (https://bit.ly/2SdvMNd) were presented by Lilliam Rosario of\nthe FDA’s Center for Drug Evaluation and Research, Michael Lawrence\nGenentech/Roche and the R Core Group, and Max Kuhn and Joe Cheng from\nRStudio.\nOver forty-five talks and workshops were delivered with topics ranging\nfrom reproducible research, regulatory constraints and considerations,\nand package administration to scaling R for production. A considerable\nnumber of talks emphasized the development of production-grade Shiny\napplications. Although considerably larger than most of the Shiny\napplications developed, Roche’s 500,000 line application, which was\npresented at the conference and subsequently written up in a post\n(https://bit.ly/2NeXKFJ), reflects a common use case. Abstracts for\nthe talks are available (https://bit.ly/2CUTEeG).\nOrganizing Committee\nMelvin Munsaka - AbbVie; Bella Fang and Min Lee - Amgen; Eric Nantz -\nEli Lilly; Elena Rantou and Paul Schuette - FDA; Elizabeth Hess -\nHarvard; James Black, Reinhold Koch, and Michael Lawrence - Genentech /\nRoche; Edward Louzier - Merck; Michael Blanks - PPD; Phil Bowsher -\nRStudio; and Harvey Lieberman - Sanofi.\nProgram Committee\nCo-chairs for the program committee were Bella Feng - Amgen, John Sims -\nPfizer, and Ryan Benz - SocalBioinformatics.\nProgram committee leads included: Melvin Munsaka - AbbVie; Robert\nEngle - Biogen; Elena Rantou and Paul Schuette - FDA; Elizabeth Hess -\nHarvard University; James Black and Reinhold Koch - Genentech/Roche;\nPaulo Bargo - Johnson & Johnson; Eric Nantz - Eli Lilly; Edward\nLauzier - Merck; Xiao Ni- Novartis; Thomas Tensfeldt - Pfizer; and\nHarvey Lieberman - Sanofi.\nR / Pharma 2019\nR / Pharma 2019 will be held on August 21, 22, and 23, 2019 at Harvard\nUniversity. In a response to attendee feedback, a third day is being\nplanned for workshops. Please watch the conference website for more\ninformation as it becomes available.\nR / Pharma 2019 conference website: http://rinpharma.com/\nTwitter: #rinpharma\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2018-2-serIII/",
    "title": "Conference Report: SER III",
    "description": "The 'Conference Report: SER III' article from the 2018-2 issue.",
    "author": [
      {
        "name": "Ariel Levy",
        "url": {}
      },
      {
        "name": "Luciane F. Alcoforado",
        "url": {}
      },
      {
        "name": "Orlando Celso Longo",
        "url": {}
      }
    ],
    "date": "2018-12-01",
    "categories": [],
    "contents": "\n\nIntroduction\nSER is a multidisciplinary event, which integrates professionals,\nstudents, and practioners from most diversified knowledge areas who make\nuse of data analysis. The first edition took place on May 2016 as the\ninitiative of a group of professors from the Fluminense Federal\nUniversity, partners of other Institutions, and was supported by CAPES\n(Coordination for higher Education Staff Development). SER event was\nrecognized by the R foundation (2018)1 for its pioneering in Latin\nAmerica in bringing together an expressive number of R users.\nFrom its very first beginning, the motivation was to bring together\nthose who wish to learn, R users, and to spread R language knowledge\nthrough the Federal Fluminense University, UFF. Organizers came up with\nthe first event title: SER, Seminários de Estatística com R, notice that\nser means to be in Portuguese. Soon, they discovered the borders of\ntheir ambition were too shy, as some other institutions, even from\nabroad, joined the project. The event name had changed but the acronym\nwas kept.\nAfter the resounding success of the two prior editions the third\nInternational Seminars of Statistics with R, III SER, took place, may,\n\\(22^{nd}\\) - \\(24^{th}\\), 2018 at Federal Fluminense University - Niterói -\nRio de Janeiro. In this issue the event call was: R for Science\nIntegration Challenge. A high level event program was presented,\ndiversified in themes, and with a remarkable feminine touch, represented\nin talks by Julia Silge, Jesse Maegan, Gabriela de Queiroz, Luciane\nAlcoforado, Becky Pattinson, Nicole Barros, Cristiane Ramos, and Karla\nEsquerre.\nThe program had 517 attendees, 357 freebies for beginners in the R basic\nmini-course, 27 speakers from different regions and countries, 7\nauthorities present among coordinators, pro-rectors, and unit directors.\nFifty papers were selected by the scientific committee and presented\nduring the oral contributor and poster sessions, in the morning of the\nthird day, involving about 144 authors from 31 institutions.\nPre-conference Tutorials\nThe first day of the event occurred at the Administration Faculty in\nValonguinho Campus, consisted of nine, sold out, R tutorials in\ndiversified themes:\nJurimetry - Julio Trecenti, ABJ;\nImporting and Wrangling Financial Data in R - Wilson Freitas, B3;\nInteractive 2D and 3D Graphics in R using OpenGL Tools - Alex Laier\nBordingon, UFF;\nDynamic Reports - Cassio Freitas, ENCE;\nMy first R package - Steven Dutt Ross, UNIRIO;\nBayesian Inference - Alexandre Silva, UNIRIO;\nRegression Models for Politomous Data - José Rodrigo de Morais, UFF;\nWeb Scrapping Using rvest Package - Karla Esquerre & Adelmo Filho,\nUFBA;\nMining and Modeling Text Using Tidy Data Principles - Julia Silge,\nStack Overflow.\nThe Conference\nThe opening day, at the Praia Vermelha Campus, began with Prof. Levy and\nguests in a relaxed warm-up where they discussed how they learn and\nteach R. After showing and commenting on several books, articles,\ncourses, and posts on twitter and slack, the message left was: “In R we\nare all apprentices in different stages.”\nThe event opening was attended by officials from UFF and ENCE. Prof.\nVitor Francisco Ferreira, currently Research Pro-Rector and\nrepresentative of UFF Rector, as well as authorities, congratulated\nLuciane Alcoforado and the other organizers for their excellent work at\nevent organization. Prof. Fábio Barboza Passos, current director of the\nEngineering Faculty, reinforced the importance for a market culture\nchange over free software usage, which is to be achieved by its\ndissemination over the academic community. He also pointed out that data\nwrangling and reports reaches all areas of knowledge in which R language\nstands out. He concludes that this event is to be shown as a positive\nresult on how a relationship between at least 3 faculties within UFF and\nseveral other Universities and Institutions demonstrates that\ncollaboration works.\nThe keynote opening talk was given by prof. Luciane Alcoforado, SER\nGeneral Coordinator, exposing how the event organizer team has been\nworking on the challenge of integrating the community around the\ndissemination of the R language. The main target audience for this\nproject are beginners in the R language, most of them undergraduate\nstudents for whom the project mission is to embrace, and for which\nseveral courses and activities all developed in Portuguese. One of these\nactivities, within this event issue, was a free online mini course with\n400 attendees. This concluded by inviting the public to visit the event\nsite where several articles and code bases that have been produced since\nthe first event issue is deposited.\nThe following talks dealt with varied topics with strong interaction\nbetween the speakers and the audience.\nJesse Mostipak, Teaching Trust, brought up one of the biggest\nshortcomings for both teachers and learners of data science in R: the\noften unspoken prerequisite skills and content knowledge necessary to\nsuccessfully apply R to data science problems. She taught us strategies\nto more effectively bring learners up to speed, while, for learners, how\nto develop strategies to identify and address their own knowledge gaps.\nShe shared strategies from a data-driven culture that can be immediately\nimplemented with groups of any size in order to more quickly develop\ndata science skills in R.\nR-Ladies project was the subject for Gabriela de Queiroz talk. She was\nso emphatic in presenting the spread throughout the world, seeking to\ndefend and encouraging the increase of women’s participation in the\nfield of data science with the use of the R-language, that succeeded in\nmotivating Noelle Camello in establishing the new Niterói chapter2.\nBecky Pattinson, Lancaster University and UFF, approached the ageing\npopulation problem which is faced by many countries in the world,\nincluding Brazil. Using a nationally representative sample from the 2008\nPNAD, she demonstrated how they developed measurement models for the\nhealth and economic well-being of older people (aged 60+ years old).\nClustering older individuals by sector, multilevel structural equation\nmodeling provided greater understanding of the challenges for the older\npeople of Brazil. This understanding allows for the development of\npolicies that are efficient in the application of resources in the care\nof older people. Analyses were conducted using the MplusAutomation\npackage in R for data formatting and estimation of the multilevel SEM in\nMplus (Version 6); a commercial SEM program. In clustering individuals\nby sector, the model had a different structure of latent variables at\nthe sector level. Strong associations existed between health and\neconomic well-being and demographic variables of both individuals and\nsectors had significant effect on health and economic well-being.\nDaniel Takata, researcher from ENCE/IBGE, discuss how to handle\ndistributions that present heavy tail, without assumptions on the\npresence of moments, by introducing procedures for applications in R and\nthe stable package.\nGareth McCray, Keele University, followed in video conference explaining\nthe rationale behind and the utility of Item Response Theory (IRT), a\nspecific family of psychometric models for creating continuous score\nvariables from binary or ordinal responses to sets of test items or\nquestionnaire questions. IRT models have distinct advantages for score\ncreation over other scale creation methods, e.g., Classical Test Theory\n(CTT). Different data structures call for different types of IRT model\nand the presenter briefly sketched out the landscape of this family of\nmodels. Following, he discussed how to apply the various models using\nvarious R packages.\nIn sequence, the most antecipated lecture of the day, Julia Silge, data\nscientist at Stack Overflow, with her brilliance, taught us how to\nmanipulate, summarize, and visualize text characteristics using the\nmethods and R packages from the tidy tool ecosystem. These tools are\nhighly effective for many analytical questions that allow analysts to\nintegrate natural language processing into effective workflows already\nin wide use. We explored how to implement approaches such as sentiment\nanalysis of texts, measuring tf-idf, and finding word vectors.\nSurprising the audience and closing the second day talks, Rodrigo\nHartmann, a practitioner data scientist at Casa & Video, showed us the\nevolution in the use of the Shiny package with several set up details\nfor installations and some business applications.\nThe activities ended with the evening of autographs, Julia Silge signing\n\"Text Mining with R\", Pedro Ferreira autographing \"Analysis of Time\nSeries in R\", and Luciane Alcoforado autographing \"Introduction to R\nusing Basic Statistics.\"\nThe second day morning was reserved for the poster and the oral\ncontributors sections.\nThe afternoon started with Prof. Maysa Magalhães (ENCE) as the\nspokesperson for the honor to the illustrious Prof. Djalma Pessoa, one\nof the precursors of the use of the R language in Brazil. Currently\nretired, Prof. Djalma Pessoa says that R is the only computational tool\nthat he knows how to use and that has always resisted the use of other\nstatistical programs, attracting other people to R. After his retirement\nhe thought he would do nothing else, but today he works even harder due\nto the help he provides to R users.\nIn sequence, the contributors awards section took place, almost a\ntradition in our events.\nThe third day presentations begun with Leonardo and Jonatha, UFF\nStatistical students, who reported on their experience in the academic\nworld by encouraging colleagues to study R every day, search for new\npackages, look at available documentation, participate in projects and\nevents such as SER. Followed by Prof. Marcelo Perlin (UFRGS), he\nintroduced his GetHFData package, which downloads and aggregates high\nfrequency trading data for Brazilian instruments directly from B3, the\nBrazilian stock exchange.\nClosing the III SER lectures, Prof. Karla Esquerre quickly introduced\nthe GAMMA Group, an extension project for data analysis in UFBA. Tassio\nBarreto showed how to communicate with R codes through the tidyverse\npackage using his passion, cinema. His presentation was permeated by\nmovie quotes.\nThe event closure was made official by Prof. Orlando Longo current\ncoordinator of the Post-Graduation Program in Civil Engineering at UFF,\nwho highlighted the importance of new partnerships for the continuation\nof the next SER.\nThe awards\nPoster Section\nHugo Henrique Oliveira, Adriane Caroline Portela, Denise Nunes\nViola - Use of Software R as a Tool for Teaching and Learning of\nCombinatory Analysis.\nLuiz Fernando Guilhem Nassif Maia, Alinne de Carvalho Veiga, Renata\nSouza Bueno - Brazilian Musical Genres Similarity Analysis Using Web\nScraping and Text Mining with R.\nLucas José Gonçalves Freitas, Marcelo dos Santos Ventura -\nCryptocurrency and an Application for Linear Hyperbolic Models.\nOral Contributors Section\nAndrea Ugolini and Juan Carlos Reboredo - Multivariate Conditional\nQuantile Dependence Between Energy Prices and Clean Energy Stock\nReturns.\nSilvio Augusto Jr. and Vinícius Basseto Félix - Brazilian Spotify\nRankings Survival Analysis: Differences Between Domestic and Foreign\nArtists.\nArthur Rios de Azevedo, Anderson Ara, Mariana Yukari Noguti and\nAngela Ernestina Cardoso de Brito - Shiny Application: Intersection\nBetween Gender, Class and Race in 2016 ENEM.\nTestimonials\n\"Beyond programming and statistics, SER was a bright moment to meet and\nbe inspired by people who make our praxis so challenging and\npleasurable. This kind of connection is what makes difference for the\nnew ones and builds a strong foundation for data science culture in\nBrazil\" Adelmo FIlho.\n\"I was so happy to be introduced to the vibrant R community in Brazil\nvia SER. It was a pleasure to meet professors, industry professionals,\nand students using R in their daily work and context\" Julia Silge.\n\"Participating in SER was an absolutely joyful experience. The event\nwas well-organized, the presentations covered a wide variety of topics,\nand the networking opportunities were a wonderful time to share a\npassion for R amongst peers\" Jesse Mostipak.\n\"I had difficulty in the beginning, I had never installed any program\nin my life, I needed help but I was winning the challenge gradually,\nbeing encouraged by my daughter. I confess that I enjoyed the joke and\nfor me it was a possibility to keep the mind active and break the\nroutine. I am retired, I am over 70 years old, and I like challenges.\nThe usefulness of the course for me is to show that it does not matter\nthe age but the desire to search for the new one always\" ( An anonymous\nstudent of the basic course).\nOrganizing Committee\nOrlando Celso Longo - PPGEC/UFF, Luciane Ferreira Alcoforado -\nPPGEC/UFF, Ariel Levy - PPGAD/UFF, José Rodrigo de Moraes - IME/UFF,\nAlex Laier Bordingon - IME/UFF, Manuel Febrero Bande - Un. de Santiago\nde Compostela/ Spain, Steven Dutt Ross - UNIRIO\nScientific Committee\nWenceslao Gonzalez Manteiga - Un. Santiago de Compostela - SP, Manuel\nFebrero Bande - Un. Santiago de Compostela - SP, Luís Torgo - Un. do\nPorto - PT, Jorge Passamani Zubelli - IMPA - BR, Orlando Celso Longo -\nUFF - BR, Luciane Ferreira Alcoforado - UFF - BR, Ariel Levy - UFF - BR,\nSteven Dutt Ross - UNIRIO - BR, Pedro Costa Ferreira - FGV/IBRE - BR,\nMaysa Sacramento de Magalhães - ENCE/IBGE - BR, Djalma Galvão Carneiro\nPessoa - ENCE/IBGE - BR, José Rodrigo de Moraes - UFF - BR, Ludmilla da\nSilva Viana Jacobson - UFF - BR, Carlos Alberto Pereira Soares - UFF -\nBR, Assed Naked Haddad - UFRJ - BR\nFurther Information\nSeveral pictures and more can be seen in our home page or in facebook.\nConference homepage: http://www.ser.uff.br\nFacebook page: https://www.facebook.com/eventoser.uff/\ne-mail: ser.uff.br@gmail.com\nNext SER\nNext SER will take place in May 21-23rd 2019, we require(You).\nFigure 1: SER logo.\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\nhttps://rforwards-auto.github.io/blog/2018/02/05/r-in-latin-america/↩︎\nA week after SER, we wish her success.\n\n↩︎\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2018-2-whyR/",
    "title": "Conference Report: Why R? 2018",
    "description": "The 'Conference Report: Why R? 2018' article from the 2018-2 issue.",
    "author": [
      {
        "name": "Michał Burdukiewicz",
        "url": {}
      },
      {
        "name": "Marta Karas",
        "url": {}
      },
      {
        "name": "Leon Eyrich Jessen",
        "url": {}
      },
      {
        "name": "Marcin Kosiński",
        "url": {}
      },
      {
        "name": "Bernd Bischl",
        "url": {}
      },
      {
        "name": "Stefan ",
        "url": {}
      }
    ],
    "date": "2018-12-01",
    "categories": [],
    "contents": "\n\nFigure 1: Why R? 2018 conference banner used for social media\npromotion. The background displays banks of the Odra river in Wroclaw –\nthe city of Poland where the conference was\nheld.1 Why R? 2018 conference\nThe primary purpose of the Why R? 2018 conference was to provide R\nprogramming language enthusiasts with an opportunity to meet and discuss\nexperiences in R software development and analysis applications, for\nboth academia and industry professionals. The event was held 2-5 August,\n2018 in a city of Wroclaw, a strong academic and business center of\nPoland. The total of approximately 250 people from 6 countries attended\nthe main conference event. Additionally, approximately 540 R users\nattended the pre-meetings in eleven cities across Europe\n(Figure 2).\n Why R? 2018 conference is the continuation of the Why R?’s first\nedition that took place Sep 27-29, 2017 at the Warsaw University of\nTechnology in Warsaw (Poland). Given the success of the first event,\nthis year’s conference extended its program concept and scope;\nimportantly, Why R? 2018 conference was held as international.\nFigure 2: Locations and dates of the Why R? 2018 main conference\nevent and 11 Why R?-branded\npre-meetings.2 Conference program\nThe format of the conference was aimed at exposing participants to\nrecent developments in the R language, as well as a wide range of\napplication examples. It consisted of workshops, invited talks,\nfield-specific series of talks, lighting-talks, special interest groups,\nand a full-day programming hackathon.\n \nThe conference program had a strong focus on machine learning techniques\nand applications, with mlr (Bischl, M. Lang, L. Kotthoff, J. Schiffner, J. Richter, E. Studerus, G. Casalicchio, and Z. M. Jones 2016) R package – an interface to a\nlarge number of classification and regression methods – being\nemphasized in a number of presentations, as well as employed during\nworkshops and the hackathon provided by the mlr team. The scope of\nconference program included statistical methodology, data visualization,\nR code performance, building products based on data analyses, and R’s\nrole in academia / industry.\n \nThe event offered extensive networking opportunities. The cocktail party\nwas held at the conference venue on the 2nd conference day. In addition,\nconvenient location in the close proximity of the old town market square\nfacilitated many informal gatherings that were happening each conference\nday.\n3 Why R? Pre-meetings\nThe novel idea of pre-meetings has proved to be successful in\npopularizing Why R? conference in the international community of R\nusers. Eleven pre-meetings took place in Czech Republic, Denmark,\nGermany, Poland, and Sweden in the run-up to the Why R? main event.\nThe pre-meetings either constituted a part of another conference, one\nday-long workshop and discussion event, or a meeting of a local R user\ngroup.\n \nAs R provides a versatile framework for reproducible research in\ndifferent scientific domains\n(Gentleman and D. Temple Lang 2007; Gandrud 2013; Leeper 2014; Liu and S. Pounds 2014; Rödiger, M. Burdukiewicz, K. A. Blagodatskikh, and P. Schierack 2015),\nwe considered the Why R? pre-meetings as a great opportunity to convey\nand popularize R as an analytics tool in groups of professionals from\ndifferent fields. The pre-meeting held at International Biotechnology\nInnovation Days (IBID), an open-access conference held 23-25 May, 2018\nat the Brandenburg University of Technology Cottbus - Senftenberg\n(Senftenberg, Germany)1 is an example where the R came in close\ncontact with scientist from other domains. IBID brought together\nspecialists and experts in the fields of bioanalytics, biomedical and\ntranslational research, autoimmune diagnostics, digitalization, and\nengineering; hence it posed an excellent platform to promote R and the\nWhy R? 2018 conference.\n4 Workshops\nWhy R? 2018 conference had a wide portfolio of workshops:\nMaps in R by Piotr Sobczyk (OLX Group). Piotr showed how to\ncreate spatial data visualization efficiently in the R. He gave a\nplenty of tips to follow, pitfalls to avoid and a number of useful\nhacks. Starting from a basic plot function, he covered the usage of\nggplot2 as well as R packages that use interactive javascript\nlibraries to prepare data reports.\niDash - Make your R slides awesome with xaringan by Mikołaj\nOlszewski (iDash) and Mikołaj Bogucki (iDash). The workshop\nintroduced the xaringan (Xie, C. T. Ekstrøm, D. Lang, G. Aden-Buie, O. P. B. C. in rmarkdown/templates/xaringan/resources/default.css), P. Schratz, and S. Lopp 2018) package – an\nalternative approach to preparing a slide deck. The xaringan\npackage allows customizing each slide entirely and previewing slides\ndynamically in RStudio; moreover, the export of the slide deck\n(natively in HTML) to a pixel-perfect PDF is fairly easy. As\nxaringan also uses RMarkdown, it allows for reproducible results.\nJumping Rivers - Shiny Basics and Advanced Shiny by Roman\nPopat (Jumping Rivers). The instructor Roman Popat from Jumping\nRivers conducted two workshops. In the first (Shiny Basics), he gave\nan introduction to creating interactive visualizations of data using\nShiny. Here, participants learned how to use rmarkdown and\nhtmlwidgets; input and output bindings to interact with R data\nstructures; and input widgets and render functions to create\ncomplete page layouts using shiny and shiny dashboard. The advanced\nShiny workshop explored how to add functionality to shiny apps using\njavascript packages and code. In particular, it was showed how one\nmight deal with routines in a Shiny application that take a long\ntime to run and how to provide a good experience for simultaneous\nusers of an app. Finally, the instructor showed how to create a\nstandalone web server API to the R code and how to integrate the use\nof it into a Shiny application using the plumber\n(Technology, LLC, J. Allen, F. van Dunné, S. Vandewoude, and S. Software (swagger-ui) 2018) package.\nDALEX - Descriptive mAchine Learning EXplanations by Mateusz\nStaniak(Uniwersytet Wrocławski). THe workshop covered tools for\nexploration, validation, and explanation of complex machine learning\nmodels. The packages explored in this workshop include mlr\n(Bischl, M. Lang, L. Kotthoff, J. Schiffner, J. Richter, E. Studerus, G. Casalicchio, and Z. M. Jones 2016), DALEX (Biecek 2018), live (Staniak and P. Biecek 2018),\nFactorMerger (Sitko and P. Biecek 2017), archivist (Biecek and M. Kosinski 2017), pdp\n(Greenwell 2017) and ALEPlot (Apley 2018).\nConstructing scales from survey questions by Tomasz Żółtak\n(Educational Research Institute in Warsaw, Poland). Tomasz showed\nhow to create scales based on sets of categorical variables using\nCategorical Exploratory/Confirmatory Factor Analysis (CEFA / CCFA)\nand IRT models. He used models with bi-factor rotation to deal with\ndifferent forms of asking questions and corrected for differences in\na style of answering questions asked using a Likert scale. In\naddition, it was showed how to correct self-assessment\nknowledge/skill indicators using fake items.\nFrom RS data to knowledge – Remote Sensing in R by Bartłomiej\nKraszewski (Forest Research Institute, Poland). Remote sensing data\nfrom different sensors is a rich source of information for studying\nthe natural environment, natural phenomena and monitoring some\nextreme phenomena, such as floods. Bartłomiej presented R language\npackages that can be used to work with remote sensing data. These\nincluded (a) for geographic information system analysis: rgdal\n(Bivand, T. Keitt, B. Rowlingson, E. Pebesma, M. Sumner, R. Hijmans, E. Rouault, F. Warmerdam, J. Ooms, and C. Rundel 2018), rgeos (Bivand, C. Rundel, E. Pebesma, R. Stuetz, K. O. Hufthammer, P. Giraudoux, M. Davis, and S. Santilli 2018) and sf\n(Pebesma, R. Bivand, E. Racine, M. Sumner, I. Cook, T. Keitt, R. Lovelace, H. Wickham, J. Ooms, and K. Müller 2018); (b) for raster data processing: raster\n(Hijmans, J. van Etten, J. Cheng, M. Mattiuzzi, M. Sumner, J. A. Greenberg, O. P. Lamigueiro, A. Bevan, E. B. Racine, A. Shortridge, and A. Ghosh 2017); (c) for Airborne LaserScanning data\nprocessing: the lidR (Roussel, D. A. R. the documentation), F. D. B. F. a. bugs improved catalog features), and A. S. M. I. lassnags) 2018) package.\nIntroduction to Deep Learning with Keras in R by Michał Maj\n(Appsilon Data Science). The workshop covered many important aspects\nof Deep Learning with the Keras in R, including sequential model\nbuilding, performing data ingestion and using pre-trained models and\nperforming fine-tuning. The keras (Allaire, F. Chollet, RStudio, Google, Y. Tang, D. Falbel, W. V. D. Bijl, and M. Studer 2018) R package\nwas explored.\n5 Invited talks\nThe invited talks topics included domain knowledge from statistics,\ncomputer science, natural sciences, and economics. The speakers list\npresents as follows:\nTomasz Niedzielski (University of Wroclaw): Forecasting streamflow\nusing the HydroProg system developed in R,\nDaria Szmurło (McKinsey & Company): The age of automation – What\ndoes it mean for data scientists?,\nAgnieszka Suchwałko (Wroclaw University of Technology): Project\nevolution – from university to commerce,\nBernd Bischl (Ludwig-Maximilians-University of Munich): Machine\nlearning in R,\nArtur Suchwałko (QuantUp): A business view on predictive modeling:\ngoals, assumptions, implementation,\nMaciej Eder (Institute of Polish Language): New advances in text\nmining: exploring word embeddings,\nThomas Petzoldt (Dresden University of Technology): Simulation of\ndynamic models in R,\nLeon Eyrich Jessen (Technical University of Denmark): Deep Learning\nwith R using TensorFlow.\n6 Special Interest Groups\nThree Special Interest Groups were organized to facilitate\ntopic-specific discussion between conference participants.\nDiversity in Data Science, moderated by R-Ladies Warsaw, aimed\nto discuss boosting the diversity of R community and inspire members\nof affinity groups to pursue careers in data science.\nThe Career planning in data science, moderated by Artur\nSuchwałko (QuantUp) and Marcin Kosiński (Why R? Foundation), gave\nparticipants a chance to learn from experienced R enthusiasts about\ntheir career paths.\nTeaching of data science, moderated by Leon Eyrich Jessen\n(Technical University of Denmark) and Stefan (Brandenburg Technical\nUniversity Cottbus-Senftenberg), gathered data science experts from\nacademia an industry to share their experiences and discuss\nchallenges and solutions in teaching different concepts of data\nscience.\n7 Conference organizers\nThe quality of the scientific program of the conference was the\nachievement of Marcin Kosiński, Alicja Gosiewska, Aleksandra Grudziąż,\nMalte Grosser, Andrej-Nikolai Spiess, Przemysław Gagat, Joanna Szyda,\nPaweł Mackiewicz, Bartosz Sękiewicz, Przemysław Biecek, Piotr Sobczyk,\nMarta Karaś, Marcin Krzystanek, Marcin Łukaszewicz, Agnieszka Borsuk -\nDe Moor, Jarosław Chilimoniuk, Michał Maj, and Michał Kurtys. The\norganization was in the hands of Michał Burdukiewicz (chair).\nThe organizers want to acknowledge R user groups from Berlin,\nCopenhagen, Cracow, Hamburg, Munich, Poznan, Prague, Stockholm, TriCity,\nWroclaw, and Warsaw.\n8 Acknowledgements\nWe would like to say thank you to all the sponsors, the University of\nWrocław, Wrocław Center of Biotechnology Consortium, the local\norganizers of the pre-meetings, the mlr team, and student helpers.\n9 Additional information\nWhy R? 2018 website http://whyr.pl/2018 Corporate sponsors:\nMcKinsey & Company, Wrocław Center for Biotechnology, KRUK S.A., iDash\ns.c., R Consortium, WLOG Solutions, Jumping Rivers Ltd., RStudio, Inc.,\nAnalyxGmbH, and Pearson IOKI.\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\nJ. J. Allaire, F. Chollet, RStudio, Google, Y. Tang, D. Falbel, W. V. D. Bijl, and M. Studer. keras: R Interface to ’Keras’, Apr. . 2018. URL https://CRAN.R-project.org/package=keras.\n\n\nD. Apley. ALEPlot: Accumulated Local Effects (ALE) Plots and Partial Dependence (PD) Plots, May . 2018. URL https://CRAN.R-project.org/package=ALEPlot.\n\n\nP. Biecek and M. Kosinski. archivist: An R package for managing, recording and restoring data analysis results. Journal of Statistical Software 82 (11): doi10.18637/jss.v082.i11, 2017.\n\n\nP. Biecek. DALEX: Descriptive mAchine Learning EXplanations, June . 2018. URL https://CRAN.R-project.org/package=DALEX.\n\n\nB. Bischl, M. Lang, L. Kotthoff, J. Schiffner, J. Richter, E. Studerus, G. Casalicchio, and Z. M. Jones. mlr: Machine learning in r. Journal of Machine Learning Research 17(170):, 2016. URL http://jmlr.org/papers/v17/15-066.html.\n\n\nR. Bivand, C. Rundel, E. Pebesma, R. Stuetz, K. O. Hufthammer, P. Giraudoux, M. Davis, and S. Santilli. rgeos: Interface to Geometry Engine - Open Source (’GEOS’), June natexlabb. 2018. URL https://CRAN.R-project.org/package=rgeos.\n\n\nR. Bivand, T. Keitt, B. Rowlingson, E. Pebesma, M. Sumner, R. Hijmans, E. Rouault, F. Warmerdam, J. Ooms, and C. Rundel. rgdal: Bindings for the ’Geospatial’ Data Abstraction Library, June natexlaba. 2018. URL https://CRAN.R-project.org/package=rgdal.\n\n\nC. Gandrud. Reproducible Research with R and RStudio. Chapman; Hall/CRC July, 2013.\n\n\nR. Gentleman and D. Temple Lang. Statistical Analyses and Reproducible Research. Journal of Computational; Graphical Statistics 16(1): Mar ISSN 1061-8600 1537-2715 doi10.1198/106186007X178663, 2007. URL http://www.tandfonline.com/doi/abs/10.1198/106186007X178663.\n\n\nB. M. Greenwell. pdp: An r package for constructing partial dependence plots. The R Journal 9 (1):, 2017. URL https://journal.r-project.org/archive/2017/RJ-2017-016/index.html.\n\n\nR. J. Hijmans, J. van Etten, J. Cheng, M. Mattiuzzi, M. Sumner, J. A. Greenberg, O. P. Lamigueiro, A. Bevan, E. B. Racine, A. Shortridge, and A. Ghosh. raster: Geographic Data Analysis and Modeling, Nov. . 2017. URL https://CRAN.R-project.org/package=raster.\n\n\nT. J. Leeper. Archiving Reproducible Research with R and Dataverse. The R Journal 6 (1): June, 2014. URL http://journal.r-project.org/archive/2014-1/leeper.pdf.\n\n\nZ. Liu and S. Pounds. An R package that automatically collects and archives details for reproducible computing. BMC Bioinformatics 15 (1): 138 May ISSN 1471-2105 doi10.1186/1471-2105-15-138, 2014. URL http://www.biomedcentral.com/1471-2105/15/138/abstract.\n\n\nE. Pebesma, R. Bivand, E. Racine, M. Sumner, I. Cook, T. Keitt, R. Lovelace, H. Wickham, J. Ooms, and K. Müller. sf: Simple Features for R, May . 2018. URL https://CRAN.R-project.org/package=sf.\n\n\nS. Rödiger, M. Burdukiewicz, K. A. Blagodatskikh, and P. Schierack. R as an Environment for the Reproducible Analysis of DNA Amplification Experiments. The R Journal 7 (2):, 2015. URL http://journal.r-project.org/archive/2015-1/RJ-2015-1.pdf.\n\n\nJ.-R. Roussel, D. A. R. the documentation), F. D. B. F. a. bugs improved catalog features), and A. S. M. I. lassnags). lidR: Airborne LiDAR Data Manipulation and Visualization for Forestry Applications, June . 2018. URL https://CRAN.R-project.org/package=lidR.\n\n\nA. Sitko and P. Biecek. The Merging Path Plot: adaptive fusing of k-groups with likelihood-based model selection, . 2017. URL https://arxiv.org/abs/1709.04412.\n\n\nM. Staniak and P. Biecek. Explanations of model predictions with live and breakDown packages. ArXiv e-prints Apr, 2018. URL https://arxiv.org/abs/1804.01955.\n\n\nT. Technology, LLC, J. Allen, F. van Dunné, S. Vandewoude, and S. Software (swagger-ui). plumber: An API Generator for R, June . 2018. URL https://CRAN.R-project.org/package=plumber.\n\n\nY. Xie, C. T. Ekstrøm, D. Lang, G. Aden-Buie, O. P. B. C. in rmarkdown/templates/xaringan/resources/default.css), P. Schratz, and S. Lopp. xaringan: Presentation Ninja, Feb. . 2018. URL https://CRAN.R-project.org/package=xaringan.\n\n\nhttp://web.archive.org/web/20180701084524/https://ibid-2018.b2match.io/\n\n↩︎\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2018-1-bioc/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2018-1 issue.",
    "author": [
      {
        "name": "Bioconductor Core Team",
        "url": {}
      }
    ],
    "date": "2018-06-01",
    "categories": [],
    "contents": "\n\nThe Bioconductor project provides tools\nfor the analysis and comprehension of high-throughput genomic data.\nBioconductor 3.7 was released on 1 May, 2018. It is compatible with R\n3.5.1 and consists of 1560 software packages, 342 experiment data\npackages, and 919 up-to-date annotation packages. The release\nannouncement includes\ndescriptions of 98 new software packages and updated NEWS files for many\nadditional packages. Start using Bioconductor by installing the most\nrecent version of R and evaluating the commands\n  source(\"https://bioconductor.org/biocLite.R\")\n  biocLite()\nInstall additional packages and dependencies, e.g.,\nSingleCellExperiment,\nwith\n  BiocInstaller::biocLite(\"SingleCellExperiment\")\nDocker and\nAmazon images\nprovide an effective on-ramp for power users to rapidly obtain access to\nstandardized and scalable computing environments. Key resources include:\nThe bioconductor.org web site to\ninstall, learn, use, and develop Bioconductor packages.\nA listing of available\nsoftware, linking to pages\ndescribing each package.\nA question-and-answer style user support\nsite and developer-oriented\nmailing list.\nThe F1000Research Bioconductor\nchannel for\npeer-reviewed Bioconductor work flows.\nOur package\nsubmission\nrepository for open technical review of new packages.\nOur annual conference will be on\nJuly 25 (‘Developer Day’), 26, and 27, 2018, in Toronto, Canada, and\nfeatures an exceptional line-up of morning scientific talks and\nafternoon hands-on workshops.\n\n\nBioconductor packages used\nSingleCellExperiment\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2018-1-ch/",
    "title": "Changes in R",
    "description": "The 'Changes in R' article from the 2018-1 issue.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2018-06-01",
    "categories": [],
    "contents": "\n\nCHANGES IN R 3.5.0 patched\n\nBUG FIXES\nfile(\"stdin\") is no longer considered seekable.\ndput() and dump() are no longer truncating when\noptions(deparse.max.lines = *) is set.\nCalls with an S3 class are no longer evaluated when printed, fixing\npart of\nPR#17398,\nthanks to a patch from Lionel Henry.\nAllow file argument of Rscript to include space even when it is\nfirst on the command line.\ncallNextMethod() uses the generic from the environment of the\ncalling method. Reported by Hervé Pagès with well documented\nexamples.\nCompressed file connections are marked as blocking.\noptim(*, lower = c(-Inf, -Inf)) no longer warns (and switches the\nmethod), thanks to a suggestion by John Nash.\npredict(fm, newdata) is now correct also for models where the\nformula has terms such as splines::ns(..) or stats::poly(..),\nfixing\nPR#17414,\nbased on a patch from Duncan Murdoch.\nsimulate.lm(glm(*, gaussian(link = <non-default>))) has been\ncorrected, fixing\nPR#17415\nthanks to Alex Courtiol.\nunlist(x) no longer fails in some cases of nested empty lists.\nReported by Steven Nydick.\nqr.coef(qr(<all 0, w/ colnames>)) now works. Reported by Kun Ren.\nThe radix sort is robust to vectors with >1 billion elements (but\nlong vectors are still unsupported). Thanks to Matt Dowle for the\nfix.\nTerminal connections (e.g., stdin) are no longer buffered. Fixes\nPR#17432.\ndeparse(x), dput(x) and dump() now respect c()’s argument\nnames recursive and use.names, e.g., for\nx <- setNames(0, \"recursive\"), thanks to Suharto Anggono’s\nPR#17427.\nUnbuffered connections now work with encoding conversion. Reported\nby Stephen Berman.\n.Renviron on Windows with Rgui is again by default searched for\nin user documents directory when invoked via the launcher icon.\nReported by Jeroen Ooms.\nprintCoefmat() now also works with explicit right=TRUE.\nprint.noquote() now also works with explicit quote=FALSE.\nThe default method for pairs(.., horInd=*, verInd=*) now gets the\ncorrect order, thanks to reports by Chris Andrews and Gerrit\nEichner. Additionally, when horInd or verInd contain only a\nsubset of variables, all the axes are labeled correctly now.\nagrep(\"..|..\", .., fixed=FALSE) now matches when it should, thanks\nto a reminder by Andreas Kolter.\nstr(ch) now works for more invalid multibyte strings.\n\nCHANGES IN R 3.5.0\n\nSIGNIFICANT USER-VISIBLE CHANGES\nAll packages are by default byte-compiled on installation. This\nmakes the installed packages larger (usually marginally so) and may\naffect the format of messages and tracebacks (which often exclude\n.Call and similar).\n\n\nNEW FEATURES\n\n\nUTILITIES\ninstall.packages() for source packages now has the possibility to\nset a ‘timeout’ (elapsed-time limit). For serial installs this uses\nthe timeout argument of system2(): for parallel installs it\nrequires the timeout utility command from GNU coreutils.\nIt is now possible to set ‘timeouts’ (elapsed-time limits) for most\nparts of R CMD check via environment variables documented in the\n‘R Internals’ manual.\nThe ‘BioC extra’ repository which was dropped from Bioconductor 3.6\nand later has been removed from setRepositories(). This changes\nthe mapping for 6–8 used by setRepositories(ind=).\nR CMD check now also applies the settings of environment variables\n_R_CHECK_SUGGESTS_ONLY_ and _R_CHECK_DEPENDS_ONLY_ to the\nre-building of vignettes.\nR CMD check with environment variable _R_CHECK_DEPENDS_ONLY_ set\nto a true value makes test-suite-management packages available and\n(for the time being) works around a common omission of\nrmarkdown from\nthe VignetteBuilder field.\n\n\nINSTALLATION on a UNIX-ALIKE\nSupport for a system Java on macOS has been removed — install a\nfairly recent Oracle Java (see ‘R Installation and Administration’\n§C.3.2).\nconfigure works harder to set additional flags in SAFE_FFLAGS\nonly where necessary, and to use flags which have little or no\neffect on performance.\nIn rare circumstances it may be necessary to override the setting of\nSAFE_FFLAGS.\nC99 functions expm1, hypot, log1p and nearbyint are now\nrequired.\nconfigure sets a -std flag for the C++ compiler for all\nsupported C++ standards (e.g., -std=gnu++11 for the C++11\ncompiler). Previously this was not done in a few cases where the\ndefault standard passed the tests made (e.g. clang 6.0.0 for\nC++11).\n\n\nC-LEVEL FACILITIES\n‘Writing R Extensions’ documents macros MAYBE_REFERENCED,\nMAYBE_SHARED and MARK_NOT_MUTABLE that should be used by package\nC code instead NAMED or SET_NAMED.\nThe object header layout has been changed to support merging the\nALTREP branch. This requires re-installing packages that use\ncompiled code.\n‘Writing R Extensions’ now documents the R_tryCatch,\nR_tryCatchError, and R_UnwindProtect functions.\nNAMEDMAX has been raised to 3 to allow protection of intermediate\nresults from (usually ill-advised) assignments in arguments to\nBUILTIN functions. Package C code using SET_NAMED may need to\nbe revised.\n\n\nDEPRECATED AND DEFUNCT\nSys.timezone(location = FALSE) is defunct, and is ignored (with a\nwarning).\nmethods:::bind_activation() is defunct now; it typically has been\nunneeded for years.\nThe undocumented ‘hidden’ objects .__H__.cbind and .__H__.rbind\nin package base are deprecated (in favour of cbind and\nrbind).\nThe declaration of pythag() in Rmath.h has been removed — the\nentry point has not been provided since R 2.14.0.\n\n\nBUG FIXES\nprintCoefmat() now also works without column names.\nThe S4 methods on Ops() for the \"structure\" class no longer\ncause infinite recursion when the structure is not an S4 object.\nnlm(f, ..) for the case where f() has a \"hessian\" attribute\nnow computes \\(LL' = H + \\mu I\\) correctly.\n(PR#17249).\nAn S4 method that “rematches” to its generic and overrides the\ndefault value of a generic formal argument to NULL no longer drops\nthe argument from its formals.\nRscript can now accept more than one argument given on the #!\nline of a script. Previously, one could only pass a single argument\non the #! line in Linux.\nConnections are now written correctly with encoding \"UTF-16LE\".\n(PR#16737).\nEvaluation of ..0 now signals an error. When ..1 is used and\n... is empty, the error message is more appropriate.\n(Windows mainly.) Unicode code points which require surrogate pairs\nin UTF-16 are now handled. All systems should properly handle\nsurrogate pairs, even those systems that do not need to make use of\nthem.\n(PR#16098)\nstopifnot(e, e2, ...) now evaluates the expressions sequentially\nand in case of an error or warning shows the relevant expression\ninstead of the full stopifnot(..) call.\npath.expand() on Windows now accepts paths specified as\nUTF-8-encoded character strings even if not representable in the\ncurrent locale.\n(PR#17120)\nline(x, y) now correctly computes the medians of the left and\nright group’s x-values and in all cases reproduces straight lines.\nExtending S4 classes with slots corresponding to special attributes\nlike dim and dimnames now works.\nFix for legend() when fill has multiple values the first of\nwhich is NA (all colours used to default to par(fg)).\n(PR#17288)\ninstalled.packages() did not remove the cached value for a library\ntree that had been emptied (but would not use the old value, just\nwaste time checking it).\nThe documentation for installed.packages(noCache = TRUE)\nincorrectly claimed it would refresh the cache.\naggregate(<data.frame>) no longer uses spurious names in some\ncases.\n(PR#17283)\nobject.size() now also works for long vectors.\npackageDescription() tries harder to solve re-encoding issues,\nnotably seen in some Windows locales. This fixes the citation()\nissue in\nPR#17291.\npoly(<matrix>, 3) now works, thanks to prompting by Marc Schwartz.\nreadLines() no longer segfaults on very large files with embedded\n’\\\\0’ (aka ‘nul’) characters.\n(PR#17311)\nns() (package splines) now also works for a single\nobservation. interpSpline() gives a more friendly error message\nwhen the number of points is less than four.\ndist(x, method = \"canberra\") now uses the correct definition; the\nresult may only differ when x contains values of differing signs,\ne.g. not for 0-1 data.\nmethods:::cbind() and methods:::rbind() avoid deep recursion,\nthanks to Suharto Anggono via\nPR#17300.\nArithmetic with zero-column data frames now works more consistently;\nissue raised by Bill Dunlap.\nArithmetic with data frames gives a data frame for ^ (which\npreviously gave a numeric matrix).\npretty(x, n) for large n or large diff(range(x)) now works\nbetter (though it was never meant for large n); internally it uses\nthe same rounding fuzz (1e-10) as seq.default() — as it did up\nto 2010-02-03 when both were 1e-7.\nInternal C-level R_check_class_and_super() and hence\nR_check_class_etc() now also consider non-direct super classes and\nhence return a match in more cases. This e.g., fixes behaviour of\nderived classes in package\nMatrix.\nReverted unintended change in behavior of return calls in\non.exit expressions introduced by stack unwinding changes in R\n3.3.0.\nAttributes on symbols are now detected and prevented; attempt to add\nan attribute to a symbol results in an error.\nfisher.test(*, workspace = <n>) now may also increase the internal\nstack size which allows larger problem to be solved, fixing\nPR#1662.\nThe methods package no longer directly copies slots\n(attributes) into a prototype that is of an “abnormal” (reference)\ntype, like a symbol.\nThe methods package no longer attempts to call length<-() on\nNULL (during the bootstrap process).\nThe methods package correctly shows methods when there are\nmultiple methods with the same signature for the same generic (still\nnot fully supported, but at least the user can see them).\nsys.on.exit() is now always evaluated in the right frame. (From\nLionel Henry.)\nseq.POSIXt(*, by = \"<n> DSTdays\") now should work correctly in all\ncases and is faster.\n(PR#17342)\n.C() when returning a logical vector now always maps values other\nthan FALSE and NA to TRUE (as documented).\nSubassignment with zero length vectors now coerces as documented\n(PR#17344).\nFurther, x <- numeric(); x[1] <- character() now signals an error\nreplacement has length zero (or a translation of that) instead of\ndoing nothing.\n(Package parallel.) mclapply(), pvec() and mcparallel()\n(when mccollect() is used to collect results) no longer leave\nzombie processes behind.\nR CMD INSTALL <pkg> now produces the intended error message when,\ne.g., the LazyData field is invalid.\nas.matrix(dd) now works when the data frame dd contains a column\nwhich is a data frame or matrix, including a 0-column matrix/d.f. .\nmclapply(X, mc.cores) now follows its documentation and calls\nlapply() in case mc.cores = 1 also in the case mc.preschedule\nis false.\n(PR#17373)\naggregate(<data.frame>, drop=FALSE) no longer calls the function\non <empty> parts but sets corresponding results to NA. (Thanks\nto Suharto Anggono’s patches in\nPR#17280).\nThe duplicated() method for data frames is now based on the list\nmethod (instead of string coercion). Consequently unique() is\nbetter distinguishing data frame rows, fixing\nPR#17369\nand\nPR#17381.\nThe methods for matrices and arrays are changed accordingly.\nCalling names() on an S4 object derived from \"environment\"\nbehaves (by default) like calling names() on an ordinary\nenvironment.\nread.table() with a non-default separator now supports quotes\nfollowing a non-whitespace character, matching the behavior of\nscan().\nparLapplyLB and parSapplyLB have been fixed to do load balancing\n(dynamic scheduling). This also means that results of computations\ndepending on random number generators will now really be\nnon-reproducible, as documented.\nIndexing a list using dollar and empty string (l$\"\") returns NULL.\nUsing \\\\usage{ data(<name>, package=\"<pkg>\") } no longer\nproduces R CMD check warnings.\nmatch.arg() more carefully chooses the environment for\nconstructing default choices, fixing\nPR#17401\nas proposed by Duncan Murdoch.\nDeparsing of consecutive ! calls is now consistent with deparsing\nunary - and + calls and creates code that can be reparsed\nexactly; thanks to a patch by Lionel Henry in\nPR#17397.\n(As a side effect, this uses fewer parentheses in some other\ndeparsing involving ! calls.)\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2018-1-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2018-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2018-06-01",
    "categories": [],
    "contents": "\n\n\nIn the past 7 months, 1178 new packages were added to the CRAN package\nrepository. 18 packages were unarchived, 493 archived and none removed.\nThe following shows the growth of the number of active packages in the\nCRAN package repository:\n\nOn 2018-06-30, the number of active packages was around 12582.\nChanges in the CRAN checks\nThe package check pages now also show issues found by checks with\nalternative BLAS/LAPACK implementations (ATLAS, MKL and OpenBLAS),\nprovided by Brian D. Ripley (see\nhttps://www.stats.ox.ac.uk/pub/bdr/Rblas/README.txt for more\ninformation).\nChanges in the CRAN submission pipeline\nPackage maintainers who submitted packages this year found the automated\nsubmission system has been extended again. Incoming packages are\nautomatically checked under both Linux and Windows. Based on these\nchecks, the auto-check service (and in later steps possibly a CRAN team\nmember) will take one of several actions:\narchive\n\nreject the package, if the package does not pass the checks cleanly\nand the problem are not likely to be false positives.\n\ninspect\n\ntriggers a manual inspection of the package, this always happens for\nfirst time submissions and also for packages that show possible\nproblems that are likely to be false positives. In both cases some\nhuman action is required.\n\npending\n\nif a decision is pending a response from the package maintainer: If\nan additional issue was present in the package that we cannot check\nfor in the incoming checks (such as the BLAS issues mentioned in the\nsection above), the maintainer is automatically asked whether these\nissues have been fixed. Same is true for change of maintainer (or\nmaintainer’s mail address) where the old maintainer (old address) is\nautomatically asked to confirm the maintainer change. The answers\nhave to be processed manually.\n\npretest\n\nduring a manual inspection, a human may trigger a new auto-check of\nthe package for various reasons, e.g., after problems in the initial\ncheck or after updates of dependencies.\n\npublish\n\npublish the package, if the package is already well established on\nCRAN, passes the checks cleanly, and does not have any reverse\ndependencies.\n\nrecheck\n\nif the package cleanly passes the checks and has at least one\nreverse dependency, this action moves the package into a queue for\nauto-checking the package’s reverse dependencies. If the check\nstatus of at least one of the package’s reverse dependencies changes\nto a worse state, the maintainer is asked whether this is expected\nand the other maintainers of affected packages have been informed\nand hence action pending is triggered. If no change to a worse\nstate is discovered, the next action is publish.\n\nAll these actions include an informative e-mail message to the package\nmaintainer. The package is also moved to a corresponding subdirectory of\nthe incoming directory on CRAN. Once an action is inspect or\npending, a CRAN team member will trigger the next action. The\nadditional directory pretest is the one that contains the yet\nunprocessed packages.\nDuring June 2018, CRAN received 2122 package submissions. For these,\n3571 actions took place of which 2433 (68.1%) were auto processed\nactions and 1138 (31.9%) manual actions.\nMinus some special cases, a summary of the auto-processed and manually\ntriggered actions follows:\n\naction\narchive\ninspect\npending\npretest\npublish\nrecheck\nauto\n530\n890\n118\n0\n664\n231\nmanual\n412\n36\n81\n50\n449\n110\n\nThese include the final decisions for the submissions which were as\nfollows:\n\naction\narchive\npublish\nauto\n470 (23.6%)\n578 (29.0%)\nmanual\n410 (20.6%)\n535 (26.8%)\n\nwhere we only count those as auto processed whose publication happened\nautomatically in all steps.\nThe large number of 1467 manual action items (not counting additional\nmail communication) shows that even more automation is needed and will\nfollow.\nAs the CRAN team is no longer able to respond to individual help\nrequests or being involved in lengthy discussions for exceptions, please\nreally use the corresponding mailing lists such as R-package-devel (see\nhttps://www.r-project.org/mail.html).\nChanges in the CRAN Repository Policy\nThe Policy now\nsays the following:\nCRAN hosts packages in publication quality and is not a development\nplatform. A package’s contribution has to be non-trivial.\nPackages should not write in the user’s home filespace (including\nclipboards), nor anywhere else on the file system apart from the R\nsession’s temporary directory (or during installation in the\nlocation pointed to by TMPDIR: and such usage should be cleaned\nup). Installing into the system’s R installation (e.g., scripts to\nits bin directory) is not allowed.\nPackages should not attempt to disable compiler diagnostics.\nUploads must be source tarballs created by R CMD build and\nfollowing the PACKAGE``_``VERSION``.tar.gz naming scheme. This\nshould be done with current R-patched or the current release of R.\nFor packages which have recently been archived, a snapshot of the\nCRAN results page at the time of archival may be available under\nhttps://cran-archive.r-project.org/web/checks/. (Note that only a\nfew of the links from the snapshot will work: normally those to\nlisted ‘Alternative issues’ will.)\nCRAN package repository archive\nAs of 2018-07, a full CRAN mirror takes about 176 G, which is quite a\nlot, in particular taking into account that a considerable part is not\nneeded for current versions of R and contributed packages. CRAN mirrors\nalready only provide Mac and Windows binaries for R versions not older\nthan 5 years (currently, from R 3.0 onwards), with disk usages of 65 G\n(about 39%) and 46 G (about 26%), respectively, for Mac and Windows.\nOlder versions are available from the CRAN archive service available at\nhttps://CRAN-archive.R-project.org (but not the CRAN mirrors). For the\nCRAN package repository, sources currently use 52 G, with 44 G used for\narchived (non-current) versions. Given that the source archive area\ntakes up about 25% of the whole CRAN mirror area, with material most\nlikely needed only very occasionally, we will thus move the source\narchive area to the CRAN archive server during 2018-08. Archived source\npackages can then be obtained directly via\nhttps://CRAN-archive.R-project.org/src/contrib/Archive, and of course\nvia the “Old sources” download links on the package web pages on every\nCRAN mirror.\nCRAN mirror security\nCurrently, there are 100 official CRAN mirrors, 66 of which provide both\nsecure downloads via https and use secure mirroring from the CRAN\nmaster (via rsync through ssh tunnels). Since the R 3.4.0 release,\nchooseCRANmirror() offers these mirrors in preference to the others\nwhich are not fully secured (yet).\nNew packages in CRAN task views\nBayesian\n\nopenEBGM,\ntRophicPosition.\n\nClinicalTrials\n\nInformativeCensoring,\nMediana,\nThreeArmedTrials,\nclusterPower,\ncrmPack,\ndfped,\ndfpk,\newoc,\ngsbDesign.\n\nDifferentialEquations\n\nQPot,\ncOde,\ndMod,\nphaseR,\nrODE,\nrodeo,\nrpgm.\n\nDistributions\n\nMittagLeffleR,\ncoga,\nhyper2.\n\nEconometrics\n\nOrthoPanels,\ndlsem,\npder,\nwooldridge,\nzTree.\n\nExperimentalDesign\n\nDoE.MIParray,\nFMC,\nMBHdesign,\nPBIBD,\nbioOED,\nedesign,\nidefix,\nminimalRSD,\nodr,\noptbdmaeAT,\noptrcdmaeAT,\nrsurface,\nsFFLHD,\nskpr\\(^*\\),\nsoptdmaeA,\nunrepx.\n\nExtremeValue\n\nPOT.\n\nFunctionalData\n\ncovsep,\ndenseFLMM,\nfreqdom.fda,\nftsspec.\n\nHighPerformanceComputing\n\nSim.DiffProc,\ndrake,\nparSim.\n\nMachineLearning\n\nICEbox,\neffects,\nggRandomForests,\npdp,\nplotmo,\ntensorflow.\n\nMetaAnalysis\n\nCIAAWconsensus,\nConfoundedMeta,\nMetaSubtract,\nRandMeta,\nTFisher,\nclubSandwich,\neffsize,\nforestmodel,\ngetmstatistic,\nmetaBMA,\nmetacart,\nmetaforest,\nnmaINLA,\npsychmeta,\nratesci,\nrma.exact.\n\nNaturalLanguageProcessing\n\nalineR,\nore,\nrel,\nstm,\nstringdist.\n\nNumericalMathematics\n\nPythonInR,\nSnakeCharmR,\nXR,\nXRJulia,\nXRPython,\nexpint,\nfeather,\nfindpython,\nfourierin,\ninterp,\nlogOfGamma,\nreticulate,\ntripack.\n\nOptimization\n\nABCoptim,\nCVXR,\nManifoldOptim,\nRtnmin,\nSACOBRA,\ncolf,\nconeproj,\necr,\nflacco,\nmetaheuristicOpt,\nmize,\nn1qn1,\nompr,\noptimr,\noptimsimplex,\nquadprogXT,\nsdpt3r.\n\nPharmacokinetics\n\nRxODE.\n\nPhylogenetics\n\ntreeplyr.\n\nPsychometrics\n\nCTTShiny,\nEFAutilities,\nMIIVsem,\nPLmixed,\ndexter,\numx.\n\nSpatial\n\nspm,\nspsann.\n\nSpatioTemporal\n\nFLightR,\nsf,\nsigloc.\n\nTimeSeries\n\ndLagM,\nfpp2,\nfreqdom,\nfreqdom.fda,\nftsa,\nfuntimes,\ninfluxdbr,\nodpc,\nsweep,\ntimetk,\ntscount,\nwktmo.\n\nWebTechnologies\n\ngtrendsR.\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2018-1-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2018-1 issue.",
    "author": [
      {
        "name": "John Verzani",
        "url": {}
      }
    ],
    "date": "2018-06-01",
    "categories": [],
    "contents": "\n\nOn behalf of the Editorial Board, I am pleased to present Volume 10,\nIssue 1 of the R Journal. This issue contains 36 contributed articles.\nThe majority of which cover new or newly enhanced packages on CRAN.\nAs of writing, CRAN has over 12,500 contributed packages. Including\nBioConductor packages, there are over 14,000 packages readily\ninstallable for R users. Despite the large combined size of the\nrepositories, there are still numerous new contributions made each year,\nas highlighted in the note “Changes on Cran.” The majority of\nsubmissions to the R Journal cover add-on packages for R. In this issue\nover a dozen articles are focused on newly developed packages for\napplied statistical modeling. As examples, the article by Wurm and\nRathouz describes their gldrm package for semiparametric\ngeneralized linear models; the article by Kim, Zhang, and Zhou describes\ntheir MGLM package for multivariate categorical data; and\nGarcia-Donato and Forte’s article present their BayesVarSel\npackage. For hypothesis tests there are articles on the HHG\npackage for non-parametric independence tests; and an article describing\nthe onewaytests package, which provides an interface to numerous\noneway tests. We have several articles on imputation, including\ndescriptions of the ImputeRobust, FHDI, and\nimputeTestbench packages.\nSeveral contributions are related to managing complexity, either in data\nor computational time. The article by Happ, Harrar, and Bathke on their\nHRM package discusses challenges arising in high-dimensional\nlongitudinal data; Kraemer, Reichstein, and Mahecha write about their\npackages dimRed and coRanking which enhance R’s dimension\nreduction facilities; and Liu and Quertermous describe their sinib\npackage for precise calculations of a useful probability distribution.\nThough packages on CRAN do come and go, many are constantly improved and\nupdated. A few articles discuss enhancements to existing packages, for\nexample we have Burkner’s article on improvements to his brms\npackage. For years, spatial data has been analyzed by R users with the\nsp package. One of sp’s authors, Pebesma, describes the\nimportant new package sf in the article “Simple Features for R”\nfor spatial data. This package is more tightly coupled to standard\nrepresentations of such data. Spatial data users will also be interested\nin the article describing rpostgis about using a data base add on\nfor spatial data within R.\nThe Editorial Board has encouraged submissions with comparisons and\nbenchmarking of available packages on CRAN, as in some instances\npackages offer overlapping features. In this edition we have a few\ncontributions providing overviews. As an example, the “Collections in R”\narticle by Barry reviews several packages providing support, in addition\nto base R, for various type of collections.\nFinally, as R continues to provide value to more and more disciplines,\nthere are a large number of field-specific articles. Examples, among\nmany, include the article on PortfolioOptim and its application to\noptimizing financial portfolios; the article on the mopa package\nand its application to climate data; and the article on the rtip\npackage and its application to income data.\nIn addition the News and Notes section contains the usual updates on\nCRAN, the Bioconductor project, and several conferences that have\nhighlighted R’s usage.\nI’d like to thank Roger Bivand for his excellent leadership as editor in\nchief for the past two issues, welcome Olivia Lau to the Editorial\nBoard, and say farewell to Michael Lawrence from the Editorial Board.\nFinally, I’d like to thank the enormous number of reviewers who have\nhelped significantly shape the articles contained herein. Their\npeer-review is invaluable and always most appreciated.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2018-1-erums/",
    "title": "Conference Report: eRum 2018",
    "description": "The 'Conference Report: eRum 2018' article from the 2018-1 issue.",
    "author": [
      {
        "name": "Gergely Daróczi",
        "url": {}
      }
    ],
    "date": "2018-06-01",
    "categories": [],
    "contents": "\n\n1 Conference Summary\nThe European R Users Meeting (eRum) is an international conference that\naims at bringing together users of the R language living in Europe – in\nthe years when the useR! conference is hosted outside of the continent.\nThe first eRum conference was held in 2016 in Poznan, Poland with around\n250 attendees and 20 sessions spanning over 3 days, including more than\n80 speakers. Around that time, we also held a smaller conference in\nBudapest: the first satRday event happened with 25 speakers and almost\n200 attendees from 19 countries in 2016.\nThe eRum 2018 conference is heritage of these two successful\nconferences: originally planned for 400-500 attendees from all around\nEurope, we ended up having 450 registrations from 39 countries – mostly\nfrom Germany and Hungary (15%), Poland, Austria, Netherlands and United\nKingdom (10%), many other European countries, and for example Argentina,\nSouth Africa and New Zealand as well.\n2 Tutorials\nThe conference started on May 14, 2018 with 3-6 hours workshops in the\nmorning and in the afternoon as well on 7 parallel tracks – including\ntopics from machine learning, writing and improving R packages, data\nvisualization, handling spatial data and text mining. This day was\nhosted at the Central European University.\n3 Scientific Program\nThe great success of the conference was mainly due to the high quality\nlineup of speakers: Achim Zeileis, Martin Mächler, Nathalie\nVilla-Vialaneix, Stefano Maria Iacus and Roger Bivand were our keynotes\nspeakers; Arthur Charpentier, Barbara Borges Ribeiro, Colin Gillespie,\nErin LeDell, Henrik Bengtsson, Jeroen Ooms, Mark van der Loo, Matthias\nTempl, Olga Mierzwa-Sulima, Przemyslaw Biecek and Szilard Pafka\npresented invited talks on the two main days of the conference on May\n15-16, 2018 in the Akvarium Klub that is a cultural center located under\na pool, in the center of Budapest.\nThe contributed presentations were picked from the more than 150\nsubmissions that we have received for the Call for Papers, and the final\nconference program included 30 regular talks (18 mins), 24 lightning\ntalks (5 mins), 8 Shiny demos and 22 posters.\nThe oral presentations were split into two parallel sessions (except for\nthe keynotes), and all the talks were live-streamed and the video\nrecordings are still available on the Hungarian RUG’s YouTube channel\nalong with the presented slides on the conference homepage.\n4 Social Programs\nThe Welcome Reception offered networking opportunity for the more than\n400 attendees with a light dinner, also combined with a poster session\nand a Shiny demo session in a concert room with a huge LED wall. The\nConference Dinner was hosted on a boat cruise showing the riverside of\nthe Danube both at daytime and on the way back at night as well, and\nsome traditional Hungarian dishes were served with a nice selection of\nwines. The local R-Ladies chapter also hosted a meetup with almost 100\nattendees featuring 6 talks and a networking opportunity with pizza and\ndrinks to all interested parties.\n5 Sponsors\nAs the conference ticket prices were kept as low as possible to make it\naffordable to all attendees (eg early-bird student tickets were priced\nat $50 for 3 days including catering), we are grateful to all our\nPlatinum (RStudio), Gold (Mango Solutions, Microsoft, Quantide), Silver\n(H2O.ai, Emarsys, Open Analytics, Budapest BI Forum) and Bronze (WLOG\nSolutions, Jumping Rivers, R Consosritum, Upshift R Kft, R-bloggers)\nsponsors for contributing almost 1/4 of the overall conference budget.\n6 Organizers\nThe Program Committee included 15 members form the Hungarian R User\nGroup, organizers of eRum 2016, R Forwards, R Ladies and other European\nR User Groups: Adolfo Alvarez (Poland), Ágnes Salánki (Hungary), Andrew\nLowe (Hungary), Bence Arató (Hungary), Branko Kovač (Serbia), Eszter\nWindhager-Pokol (Hungary), Gergely Daróczi (Hungary), Heather Turner\n(UK), Kevin O’Brien (Ireland), Imre Kocsis (Hungary), László (Hungary),\nMaciej Beresewicz (Poland), Mariachiara Fortuna (Italy), Przemyslaw\nBiecek (Poland) and Szilárd Pafka (USA). The local Organizing Committee\nwas lead by Gergely Daróczi, and the legal and accounting background was\nprovided by Upshift R Kft for this nonprofit conference.\n7 Further Information\nConference homepage: http://2018.erum.io\nTwitter account: https://twitter.com/erum2018\nTalk abstracts, video recordings and slides:\nhttp://2018.erum.io/#talk-abstracts\nYouTube playlist of all eRum 2018 talks:\nhttps://www.youtube.com/watch?list=PLUBl0DoLa5SAo_XRnkQA5GtEORg9K7kMh\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2018-1-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2018-1 issue.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2018-06-01",
    "categories": [],
    "contents": "\n1 Donations and members\nMembership fees and donations received between 2017-12-01 and\n2018-06-23.\nDonations\nShaban Demirel (United States)\nYves Deville (France)\nDanilo Godone (Italy)\nReigo Hendrikson (Estonia)\nJ. Brian Loria (United States)\nJoerg Maeder (Switzerland)\nJoni Oksanen (Finland)\nRavinderpal Vaid (United States)\nMerck Research Laboratories, Kenilwort (United States)\nZurich R Courses, Zurich (Switzerland)\nSupporting benefactors\nb-data GmbH, Zurich (Switzerland)\nBrigham Young University, Provo (United States)\nKansai University, Fac of Commerce, Suita (Japan)\nMirai Solutions GmbH, Zürich (Switzerland)\nSupporting institutions\nGeneral Counsel Metrics, LLC, Princeton (United States)\nSupporting members\nDouglas Adamoski (Brazil)\nAyala S. Allon (Israel)\nJustin Bem (Gabon)\nFlorian Brezina (Germany)\nJiddu Broersma (Netherlands)\nMichael Cantrall (United States)\nRobin Crockett (United Kingdom)\nJorge de la Vega G (Mexico)\nArturo Erdely (Mexico)\nSamuel Frame (Canada)\nJan Marvin Garbuszus (Germany)\nJ. Antonio García (Mexico)\nSusan Gruber (United States)\nEugene Horber (Switzerland)\nLandon Jensen (United States)\nStephen Kaluzny (United States)\nSebastian Koehler (Germany)\nLuca La Rocca (Italy)\nThomas Levine (United States)\nFabio Marroni (Italy)\nHans Mielke (Germany)\nSteffen Moritz (Germany)\nAlfredo Páez Jiménez (Spain)\nElgin Perry (United States)\nCasper Petersen (Denmark)\nLaurent Schüpbach (Switzerland)\nAndrás Tajti (Hungary)\nMarius Teodosiu (Romania)\nPari Viswanathan (India)\nChatchavan Wacharamanotham (Switzerland)\nBrandon Weinberg (United States)\nDouglas Zickuhr (Ireland)\nJoachim Zuckarelli (Germany)\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2018-1-rday/",
    "title": "R Day report",
    "description": "The 'R Day report' article from the 2018-1 issue.",
    "author": [
      {
        "name": "Fernando P. Mayer",
        "url": {}
      },
      {
        "name": "Walmes M. Zeviani",
        "url": {}
      },
      {
        "name": "Wagner H. Bonat",
        "url": {}
      },
      {
        "name": "Elias T. Krainski",
        "url": {}
      },
      {
        "name": "Paulo J. Ribeiro Jr",
        "url": {}
      }
    ],
    "date": "2018-06-01",
    "categories": [],
    "contents": "\n\n1 About\nR Day1 - National Meeting of R Users, took place on May, 22, 2018 at\nFederal University of Paraná (UFPR), Curitiba, Brazil. It was the first\nevent in Brazil endorsed by The R Foundation.\n2 The event\nR Day was planned as a satellite event of the 63rd RBRAS Annual\nMeeting2 of the Brazilian Region of The International Biometric\nSociety3. Paraná Federal University (UFPR) was selected on 2016 to\nhost the meeting.\nThe R Day was considered as a UFPR extension event, and as such it was\nnon-profitable and with no registration fees. There were 295 subscribed\nparticipants. Figure 1 shows how they split between\nstudents, professional and others.\nFigure 1: Number of subscribers by\ncategory.Figure 2 shows the spread of the participants’ home\nlocations, for 88 of those who have opted for make geocoding information\navailable on the subscription form. There was quite a spread, with all\nof the five country regions represented, an encouraging achievement\nconsidering the continental distances within the country. The fact the\nevent was an RBRAS satellite helped to gather a wider audience.\nFigure 2: Home locations of the\nparticipants.An important feature was that the event was meant to be guided by the\ncommunity, opened for proposals for oral presentations and tutorials for\nwhich there were 25 and 14 proposals, respectively. Time and space\nrestrictions allowed for the selections of 18 oral presentations and 8\ntutorials contemplating a diversity of topics related to R.\nThree speakers were invited by the organising committee. Paulo\nJustiniano Ribeiro Jr, senior lecture at the Department of Statistics at\nUFPR and LEG member gave an historical review mixed with his own\nexperiences which are highly connected with the history of R in Brazil.\nThe full video of his talk was made available at Youtube4. Figure\n3 captures a moment of Professor Paulo’s talk, reckon to be\ninfluential on the dissemination of R in Brazil.\nFigure 3: Prof. Paulo Justiniano (LEG) on the opening\nsession.Rondon de Andrade Porto, data scientist at the Conselho Nacional de\nJustiça - CNJ (National Justice Council), showed how R is used to\ngenerate a large volume of visualizations and dynamic reports on the\nCNJ.\nThe R Day final talk was made by Gabriela de Queiroz (via webconference)\nwho can be seen in Figure 4. Gabriela is the founder of\nR Ladies and told us how it all started and how it became an important\ncommunity for the diffusion of R in Brazil and worldwide. It was such an\ninspiring talk that a few days later, the R Ladies Curitiba chapter was\nfounded5.\nFigure 4: Gabriela de Queiroz (R Ladies) on the closing\nsession.The number of participants, well above our expectations, and all the\npositive and enthusiastic feedbacks shows a clear demand for events\ngathering the community of R users in Brazil. The existing community is\nlarge, diverse and spread around the country. The objective is to\npromote regular R Day events for sharing expert knowledge and\nexperience, and stimulate and strength relationships and networks.\nFigure 5 shows some of the participants who were there\nafter the closing session.\nFigure 5: Some participants of R Day after the closing\nsession.Photos of the event are available at LEG’s page on Facebook6. Slides,\nscripts and other materials used by the presenters are available at R\nDay7 web page.\n3 Next steps\nAs R Day was so well received by the general community and by RBRAS\nmeeting participants, the initial idea is to make R Day a regular\nsatellite event. RBRAS meetings lasts for 3 days in even years, and for\n5 days in odd years, and each year occurs in a different city of the\ncountry. That way, in even years, R Day could be organized in the city\nhosting the event. In odd years, we plan to make R Day in Curitiba, in a\ndate that does not overlap with the RBRAS meeting, and maybe with 2 days\nduration.\n4 Acknowledgements\nWe especially thank “The R Foundation” for endorsing R Day, particularly\nto Heather Turner, who contacted us and was always very kind and helpful\nto make this happen.\nWe thank all participants and the presenters, who offered to come\nvoluntarily to make R Day a great event. Also, we would like to thank\nour sponsors8, who provided the financial support for coffee breaks.\nWe also thank RBRAS for the partnership and support in making R Day a\nsatellite event of its annual meeting.\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\nhttp://rday.leg.ufpr.br↩︎\nhttp://www.rbras.org.br/rbras63/↩︎\nhttps://www.biometricsociety.org/↩︎\nhttps://www.youtube.com/watch?v=fnGvDEkjZy0↩︎\nhttps://www.meetup.com/pt-BR/rladies-curitiba↩︎\nhttps://www.facebook.com/leg.ufpr↩︎\nhttp://rday.leg.ufpr.br/materiais.html↩︎\nhttp://rday.leg.ufpr.br/apoio.html\n\n↩︎\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2017-2-bioc/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2017-2 issue.",
    "author": [
      {
        "name": "Bioconductor Core Team",
        "url": {}
      }
    ],
    "date": "2017-12-01",
    "categories": [],
    "contents": "\n\nThe Bioconductor project provides tools for\nthe analysis and comprehension of high-throughput genomic data.\nBioconductor 3.6 was released on 31 October, 2017. It is compatible with\nR 3.4.3 and consists of 1473 software packages, 326 experiment data\npackages, and 911 up-to-date annotation packages. The release\nannouncement includes\ndescriptions of 100 new software packages, and updated NEWS files for\nmany additional packages. Start using Bioconductor by installing the\nmost recent version of R and evaluating the commands\n  source(\"https://bioconductor.org/biocLite.R\")\n  biocLite()\nInstall additional packages and dependencies, e.g.,\nBiocFileCache,\nwith\n  BiocInstaller::biocLite(\"BiocFileCache\")\nDocker and\nAmazon\nimages provide a very effective on-ramp for power users to rapidly\nobtain access to standardized and scalable computing environments. Key\nresources include:\nThe bioconductor.org web site to\ninstall, learn, use, and develop Bioconductor packages.\nA listing of available\nsoftware, linking to pages\ndescribing each package.\nA question-and-answer style user support\nsite and developer-oriented\nmailing list.\nThe F1000Research Bioconductor\nchannel for\npeer-reviewed Bioconductor work flows.\nOur package\nsubmission\nrepository for open technical review of new packages.\nOur annual\nconference,\nstill in the planning stages, will be on July 25 (‘Developer Day’), 26,\nand 27, in Toronto, Canada.\n\n\nBioconductor packages used\nBiocFileCache\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2017-2-ch/",
    "title": "Changes in R",
    "description": "The 'Changes in R' article from the 2017-2 issue.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2017-12-01",
    "categories": [],
    "contents": "\n\nCHANGES IN R 3.4.3\n\nINSTALLATION on a UNIX-ALIKE\nA workaround has been added for the changes in location of time-zone\nfiles in macOS 10.13 ‘High Sierra’ and again in 10.13.1, so the\ndefault time zone is deduced correctly from the system setting when\nR is configured with –with-internal-tzcode (the default on macOS).\nR CMD javareconf has been updated to recognize the use of a Java 9\nSDK on macOS.\n\n\nBUG FIXES\nraw(0) & raw(0) and raw(0) | raw(0) again return raw(0)\n(rather than logical(0)).\nintToUtf8() converts integers corresponding to surrogate code\npoints to NA rather than invalid UTF-8, as well as values larger\nthan the current Unicode maximum of 0x10FFFF. (This aligns with\nthe current RFC3629.)\nFix calling of methods on S4 generics that dispatch on ... when\nthe call contains ....\nFollowing Unicode ‘Corrigendum 9’, the UTF-8 representations of\nU+FFFE and U+FFFF are now regarded as valid by utf8ToInt().\nrange(c(TRUE, NA), finite = TRUE) and similar no longer return\nNA. (Reported by Lukas Stadler.)\nThe self starting function attr(SSlogis, \"initial\") now also works\nwhen the y values have exact minimum zero and is slightly changed in\ngeneral, behaving symmetrically in the y range.\nThe printing of named raw vectors is now formatted nicely as for\nother such atomic vectors, thanks to Lukas Stadler.\n\nCHANGES IN R 3.4.2\n\nNEW FEATURES\nSetting the LC_ALL category in Sys.setlocale() invalidates any\ncached locale-specific day/month names and the AM/PM indicator for\nstrptime() (as setting LC_TIME has since R 3.1.0).\nThe version of LAPACK included in the sources has been updated to\n3.7.1, a bug-fix release.\nThe default for tools::write_PACKAGES(rds_compress=) has been\nchanged to \"xz\" to match the compression used by CRAN.\nc() and unlist() are now more efficient in constructing the\nnames(.) of their return value, thanks to a proposal by Suharto\nAnggono.\n(PR#17284)\n\n\nUTILITIES\nR CMD check checks for and R CMD build corrects CRLF line\nendings in shell scripts configure and cleanup (even on\nWindows).\n\n\nINSTALLATION on a UNIX-ALIKE\nThe order of selection of OpenMP flags has been changed: Oracle\nDeveloper Studio 12.5 accepts -fopenmp and -xopenmp but only the\nlatter enables OpenMP so it is now tried first.\n\n\nBUG FIXES\nwithin(List, rm(x1, x2)) works correctly again, including when\nList[[\"x2\"]] is NULL.\nregexec(pattern, text, *) now applies as.character(.) to its\nfirst two arguments, as documented.\nwrite.table() and related functions, writeLines(), and perhaps\nother functions writing text to connections did not signal errors\nwhen the writes failed, e.g. due to a disk being full. Errors will\nnow be signalled if detected during the write, warnings if detected\nwhen the connection is closed.\n(PR#17243)\nrt() assumed the ncp parameter was a scalar.\n(PR#17306)\nmenu(choices) with more than 10 choices which easily fit into one\ngetOption(\"width\")-line no longer erroneously repeats choices.\n(PR#17312)\nlength()<- on a pairlist succeeds.\n(https://stat.ethz.ch/pipermail/r-devel/2017-July/074680.html)\nLanguage objects such as quote((\"\\\\n\")) or R functions are\ncorrectly printed again, where R 3.4.1 accidentally duplicated the\nbackslashes.\nConstruction of names() for very large objects in c() and\nunlist() now works, thanks to Suharto Anggono’s patch proposals in\nPR#17292.\nResource leaks (and similar) reported by Steve Grubb fixed.\n(PR#17314,\nPR#17316,\nPR#17317,\nPR#17318,\nPR#17319,\nPR#17320)\nmodel.matrix(~1, mf) now gets the row names from mf also when\nthey differ from 1:nrow(mf), fixing\nPR#14992\nthanks to the suggestion by Sebastian Meyer.\nsigma(fm) now takes the correct denominator degrees of freedom for\na fitted model with NA coefficients.\n(PR#17313)\nhist(x, \"FD\") no longer “dies” with a somewhat cryptic error\nmessage when x has extreme outliers or IQR() zero:\nnclass.FD(x) tries harder to find a robust bin width \\(h\\) in the\nlatter case, and hist.default(*, breaks) now checks and corrects a\ntoo large breaks number.\n(PR#17274)\ncallNextMethod() works for ... methods.\nqr.coef(qd, y) now has correct names also when qd is a complex\nQR or stems from qr(*, LAPACK=TRUE).\nSetting options(device = *) to an invalid function no longer\nsegfaults when plotting is initiated.\n(PR#15883)\nencodeString(<very large string>) no longer segfaults.\n(PR#15885)\nIt is again possible to use configure –enable-maintainer-mode\nwithout having installed notangle (it was required in R\n3.4.[01]).\nS4 method dispatch on ... calls the method by name instead of\n.Method (for consistency with default dispatch), and only attempts\nto pass non-missing arguments from the generic.\nreadRDS(textConnection(.)) works again.\n(PR#17325)\n(1:n)[-n] no longer segfaults for n <- 2.2e9 (on a platform with\nenough RAM).\nx <- 1:2; tapply(x, list(x, x), function(x) \"\")[1,2] now correctly\nreturns NA.\n(PR#17333)\nRunning of finalizers after explicit GC request moved from the R\ninterface do_gc to the C interface R_gc. This helps with\nreclaiming inaccessible connections.\nhelp.search(topic) and ??topic matching topics in vignettes with\nmultiple file name extensions (e.g., *.md.rsp but not *.Rmd)\nfailed with an error when using options(help_type = \"html\").\nThe X11 device no longer uses the Xlib backing store\n(PR#16497).\narray(character(), 1) now gives (a 1D array with) NA as has been\ndocumented for a long time as in the other cases of zero-length\narray initialization and also compatibly with\nmatrix(character(), *). As mentioned there, this also fixes\nPR#17333.\nsplineDesign(.., derivs = 4) no longer segfaults.\nfisher.test(*, hybrid=TRUE) now (again) will use the hybrid method\nwhen Cochran’s conditions are met, fixing\nPR#16654.\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2017-2-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2017-2 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2017-12-01",
    "categories": [],
    "contents": "\n\nIn the past 6 months, 1244 new packages were added to the CRAN package\nrepository. 19 packages were unarchived, 55 archived and 3 removed. The\nfollowing shows the growth of the number of active packages in the CRAN\npackage repository:\n\nOn 2017-11-30, the number of active packages was around 11875.\nChanges in the CRAN checks\nThe package check pages now also show issues found by checks of\ncorruption of constants (provided by Tomáš Kalibera).\nChanges in the CRAN submission pipeline\nPackage maintainers who submitted packages this year found the automated\nsubmission system accepted or rejected some packages automatically while\nother packages went into a manual inspection queue. The number of false\npositives that led to wrong rejections has been reduced. Given the\nsystem is pretty stable now, we will go a step further and also\nauto-accept packages with reverse dependencies where the check status of\nall reverse dependencies checked is not worse than before. So far\nincoming checks in CRAN have been performed on a single platform (Linux\nor Windows) only. While (incoming) checks are improved all the time, we\nwill shortly have both Linux and Windows systems analyzing packages\nbefore publishing automatically.\nCRAN received 2087 package submissions in November 2017, i.e., around 70\nsubmissions a day. Hence the CRAN team is no longer able to respond to\nindividual help requests or be involved in lengthy discussions for\nexceptions. Please really use the corresponding mailing lists such as\nR-package-devel (see https://www.r-project.org/mail.html).\nChanges in the CRAN Repository Policy\nThe Policy now\nsays the following:\nCRAN packages should use only the public API. Hence they should not\nuse entry points not declared as API in installed headers nor\n.Internal() nor .Call() etc. calls to base packages. Also, :::\nshould not be used to access undocumented/internal objects in base\npackages (nor should other means of access be employed).\nPackages should not attempt to disable compiler diagnostics.\nAll correspondence with CRAN must be sent to\nCRAN-submissions@R-project.org\n(not members of the team) and be in plain text ASCII (and not HTML).\nIn addition, the Policy now also points to a new Checklist for CRAN\nsubmissions.\nCRAN mirror security\nCurrently, there are 95 official CRAN mirrors, 58 of which (about 61%)\nprovide both secure downloads via https and use secure mirroring\nfrom the CRAN master (via rsync through ssh tunnels). Since the R 3.4.0\nrelease, chooseCRANmirror() offers these mirrors in preference to the\nothers which are not fully secured (yet).\nHyperlinks in package DESCRIPTION files on CRAN\nFor package authors specified via an Authors@R field in the\nDESCRIPTION file, ORCID identifiers (see https://orcid.org/ for more\ninformation) can be provided via elements named ORCID in the comment\nargument of the person() calls, e.g.,\nperson(\"Achim\", \"Zeileis\", comment = c(ORCID = \"0000-0003-0918-3766\")).\nThese identifiers will then be hyperlinked in the CRAN package web pages\nto the corresponding ORCID pages. See, e.g., the page for package ctv.\nWindows binaries\nStarting with R 3.4.3, Jeroen Ooms\nmaintains the Windows base R binaries and the toolchain for building\nboth R and contributed packages on Windows.\nNew packages in CRAN task views\nBayesian\n\nopenEBGM, tRophicPosition.\n\nClinicalTrials\n\nInformativeCensoring, Mediana, ThreeArmedTrials,\nclusterPower, crmPack, dfped, dfpk, ewoc, gsbDesign.\n\nDifferentialEquations\n\nQPot, cOde, dMod, phaseR, rODE, rodeo, rpgm.\n\nDistributions\n\nMittagLeffleR, coga, hyper2.\n\nEconometrics\n\nOrthoPanels, dlsem, pder, wooldridge, zTree.\n\nExperimentalDesign\n\nDoE.MIParray, FMC, MBHdesign, PBIBD, bioOED, edesign,\nidefix, minimalRSD, odr, optbdmaeAT, optrcdmaeAT,\nrsurface, sFFLHD, skpr\\(^*\\), soptdmaeA, unrepx.\n\nExtremeValue\n\nPOT.\n\nFunctionalData\n\ncovsep, denseFLMM, freqdom.fda, ftsspec.\n\nHighPerformanceComputing\n\nSim.DiffProc, drake, parSim.\n\nMachineLearning\n\nICEbox, effects, ggRandomForests, pdp, plotmo,\ntensorflow.\n\nMetaAnalysis\n\nCIAAWconsensus, ConfoundedMeta, MetaSubtract, RandMeta,\nTFisher, clubSandwich, effsize, forestmodel,\ngetmstatistic, metaBMA, metacart, metaforest, nmaINLA,\npsychmeta, ratesci, rma.exact.\n\nNaturalLanguageProcessing\n\nalineR, ore, rel, stm, stringdist.\n\nNumericalMathematics\n\nPythonInR, SnakeCharmR, XR, XRJulia, XRPython, expint,\nfeather, findpython, fourierin, interp, logOfGamma,\nreticulate, tripack.\n\nOptimization\n\nABCoptim, CVXR, ManifoldOptim, Rtnmin, SACOBRA, colf,\nconeproj, ecr, flacco, metaheuristicOpt, mize, n1qn1,\nompr, optimr, optimsimplex, quadprogXT, sdpt3r.\n\nPharmacokinetics\n\nRxODE.\n\nPhylogenetics\n\ntreeplyr.\n\nPsychometrics\n\nCTTShiny, EFAutilities, MIIVsem, PLmixed, dexter, umx.\n\nSpatial\n\nspm, spsann.\n\nSpatioTemporal\n\nFLightR, sf, sigloc.\n\nTimeSeries\n\ndLagM, fpp2, freqdom, freqdom.fda, ftsa, funtimes,\ninfluxdbr, odpc, sweep, timetk, tscount, wktmo.\n\nWebTechnologies\n\ngtrendsR.\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2017-2-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2017-2 issue.",
    "author": [
      {
        "name": "Roger Bivand",
        "url": {}
      }
    ],
    "date": "2017-12-01",
    "categories": [],
    "contents": "\n\nIn my editorial for the 2017–1 issue, I concentrated on tabulating the\nstatus of this journal with respect to its authors and reviewers\n(updated tables below). This time, I was prompted by an interesting\nblog\nposting\nby Jan Wijffels of BNOSAC, describing the use of the\nudpipe package to apply\nnatural language processing (NLP) to the CRAN package database available\nfrom tools::CRAN_package_db() since the release of R 3.4. The\ninteractive NLP searcher is\na dashboard permitting exploration of annotated CRAN package title and\ndescription NLP data.\nIt struck me that an analysis of abstracts of contributed research\narticles published in the R Journal would now be possible since the\nintroduction of article landing pages earlier this year, because the\nwebsite configuration\nfile\ncontaining the abstracts can be read using the\nyaml package. Jan Wijffels\nkindly and rapidly responded, providing an R Journal NLP\nsearch tool analogous to\nthe CRAN NLP search tool.\nFigure 1: Wordcloud for abstracts of contributed research articles:\nleft panel 53 articles 2012–2013, centre panel: 69 articles 2014–2015,\nright panel: 115 articles 2016–2017.Figure 1 shows total cumulative wordclouds for the last six\nyears in two-year slices, and indicates that we are, broadly,\nmaintaining topical consistency with a sustained focus on data. The\nsearch tool permits much more detailed exploration as well, such as term\nsearch to supplement web searches on site:journal.r-project.org.\nWhile we do not have on-site indexing or searching, a tab has been added\nfor news and notes contributions by issue. In this issue, two new\ncolumns are initiated, one for news and notes from\nForwards, starting with a report on the\nuseR! 2016 survey (see also\nforwards). The second\nnew column covers teaching R and teaching with R, and kicks off with a\nnote on linking teaching and reproducible research (see also the\nrevisit package). Progress in\nanswering Heather Turner’s appeal to help useRs navigate their way\nthrough the R world (editorial, 2011–1) is at best incremental, but\nprogress none the less. A year later, Martyn Plummer pointed out\n(editorial, 2012–1) that “it is worth spending some time browsing these\nsections in order to catch up on changes you may have missed.”\nFrom the publication of this issue, fuller benefits from the\nintroduction of landing pages may be realised through the addition of\ncitation page metadata tags, permitting search engines to index\ncontributed research articles more efficiently, thanks to a suggestion\nby Carl Boettiger. We expect to begin providing DOI for published\ncontributed research articles during 2018 as a further step towards\nincreasing the visibility of the valuable work published here.\nWe have already added links for supplementary matter (typically\nreproduction code) on article landing pages, for articles published in\nthis issue. Since the beginning of 2017, submissions were expected to\nprovide scripts permitting reviewers to run code without copying from\nthe manuscript, but previously this was only exceptionally the case, so\nit may not be practical to provide supplementary matter for articles\npublished in earlier issues.\nThe wisdom of the editors in choosing to consolidate, and become a\nlisted journal (see Peter Dalgaard’s editorial in 2010–1) is manifest\nin our current standing in Journal Citation Reports, with a 2016 impact\nfactor of \\(1.075\\), and a five-year score of \\(2.114\\). The steps being\ntaken by the editors and the R Foundation should enhance the\ndiscoverability and impact of work published here. It is fair to repeat\nfrom the 2010–1 editorial that “we need to show that we have a solid\nscientific standing with good editorial standards, giving submissions\nfair treatment and being able to publish on time.”\n\nTable 1: Submission outcomes 2009–2017, by year of submission.\n\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\nPublished\n26\n26\n26\n22\n31\n36\n51\n74\n24\nRejected\n11\n14\n11\n24\n29\n32\n53\n68\n55\nUnder review\n0\n0\n0\n0\n0\n0\n0\n2\n65\nTotal\n37\n40\n37\n46\n60\n68\n104\n144\n144\n\n\nTable 2: Published contributed articles 2009–2017, by year of\npublication.\n\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\nPage count\n109\n123\n123\n136\n362\n358\n479\n895\n1023\nArticle count\n18\n18\n20\n18\n35\n33\n36\n62\n68\nAverage length\n6.1\n6.8\n6.2\n7.6\n10.3\n10.8\n13.3\n14.4\n15.0\n\n\nTable 3: Median day count from acknowledgement to acceptance and\nonline publication 2013–2017, by year of publication.\n\n2013\n2014\n2015\n2016\n2017\nMedian\n347.0\n225.5\n212.5\n212.0\n244.0\n\n\n\nCRAN packages used\nudpipe, yaml, forwards\nCRAN Task Views implied by cited packages\nNaturalLanguageProcessing, WebTechnologies\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2017-2-forwards/",
    "title": "Forwards Column",
    "description": "The study presented here is a first attempt to capture the demographics and opinions of the R community, starting with the attendees of the useR! conference 2016. One aim of Forwards, the R Foundation taskforce on women and other under-represented groups, is to identify groups that are under-represented in the R community and to further stimulate ideas and take initiatives for widening their participation. Since R is an open-source software with various platforms for exchange, however, it is difficult to obtain information about its community -- let alone define this community in the first place. As a starting point, a survey was conducted with the attendees of the useR! conference 2016 to document their sociodemographic and computational backgrounds, experiences and opinions. The present paper gives an overview of the results of this first survey. Most of the analysis focuses on women participants, that are generally under-represented in STEM (Science, Technology, Engineering, Mathematics) disciplines, but the results also show a severe under-representation of minorities. A surprising finding concerns a gender difference with regard to the experience with R and the publication of R packages. We investigated possible reasons for this difference by the means of a logistic regression analysis. The self-evident limitations of this first survey are discussed and directions for future research as well as potential means for improvement are outlined.",
    "author": [
      {
        "name": "Stella Bollmann",
        "url": {}
      },
      {
        "name": "Dianne Cook",
        "url": {}
      },
      {
        "name": "Jasmine Dumas",
        "url": {}
      },
      {
        "name": "John Fox",
        "url": {}
      },
      {
        "name": "Julie Josse",
        "url": {}
      },
      {
        "name": "Oliver Keyes",
        "url": {}
      },
      {
        "name": "Carolin Strobl",
        "url": {}
      },
      {
        "name": "Heather Turner",
        "url": {}
      },
      {
        "name": "Rudolf Debelak",
        "url": {}
      }
    ],
    "date": "2017-12-01",
    "categories": [],
    "contents": "\n\nForwards is a task force that was set up by the R Foundation in 2015 to\naddress the under-representation of women that has since widened its\nscope to encompass other under-represented groups. The task force is\norganised as a core team comprising leaders from a number of sub-teams\nthat focus on particular aspects:\nCommunity\n\nGeneral outreach to help people from under-represented groups get\ninto R and develop as useRs. Members have represented the task force\nat events such as AlterConf, Trans*Code\nInternational Transgender Day of Visibility\nHackathon,\nNational Federation of the Blind\nConvention, and Society for\nAdvancement of Chicanos/Hispanics and Native Americans in\nScience. The team promotes outreach schemes\nsuch as NASA Datanauts\nand works alongside others in the R community seeking to widen\nparticipation, such as R-Ladies or other\nsub-teams, for example co-ordinating the diversity scholarship\nscheme for useR! 2017.\n\nConferences\n\nWith a particular focus on R Foundation conferences, this team\nliaises with the organizers/program committee on policies and\ninclusion initiatives. For example this team initiated the\nconference buddy scheme for useR! 2017 and collaborated with\nR-Ladies to host a special session for newcomers.\n\nOn-ramps\n\nCreating paths for useRs to develop their skills and make\ncontributions to the R/Bioconductor package ecosystem. Activities\nhave included speaking at the useR! 2017 newcomer session and\nR-Ladies meetings on collaborative coding.\n\nSocial Media\n\nManaging the Twitter account and\nthe recently started\nFacebook group\nto support people from under-represented groups. Maintaining the\nwebsite and co-ordinating the blog.\n\nSurveys\n\nRunning and analysing community surveys; publishing corresponding\nreports and data. For example, this team ran a survey at useR! 2016\nto find out about the demographics, programming experience and\ncommunity involvement of useR! attendees.\n\nTeaching\n\nWorking on methodology, materials and workshops designed for\nunder-represented groups. In particular, this team have developed\nmaterials for two workshops: one aimed at high school girls, on\ncreating a data analysis web application and another aimed at women,\non package development. So far these workshops have been run in\nAustralia and New Zealand, with repeats planned for Europe and North\nAmerica.\n\nThis new column provides an outlet for news about the work of the task\nforce as well as more detailed reports. This inaugural column presents\nan article on the results of the useR! 2016 survey.\n1 A First Survey on the Diversity of the R Community\nThe R environment for statistical computing is an open-source project\nfor data analysis. It provides an opportunity for users worldwide to\nbenefit from an extensive number of software tools for a wide spectrum\nof data analysis and also allows users to participate in the project.\nThis participation may take many forms. Beginners may attend tutorials\non data analysis with R and contribute through their feedback while\nadvanced users may write their own code and even publish it on one of\nthe public repositories. As a whole, we will refer to the participants\nof the R project as the “R community” – but be assured of our awareness\nthat this community is very hard to grasp.\nSeveral studies have already investigated important aspects of the R\ncommunity. A central place in the development of R is taken by the R\nCore Team. It is responsible for the development of the basic R software\nand the maintenance of infrastructure which is necessary for its\ndistribution. Several interesting aspects of the organization and work\nof the R Core Team have been summarized by Fox (2009), who conducted a\nseries of interviews with its members. Mair, E. Hofmann, K. Gruber, R. Hatzinger, A. Zeileis, and K. Hornik (2015) investigated the\nmotivation and values of the authors of R software packages published on\nthe CRAN, Bioconductor and R-Forge repositories by the means of a\nquestionnaire. Like the R Core Team, package authors are a well-defined\nsubgroup of the R community that is quite easily accessible because\ntheir names are made public. However, very little is known about the\nremaining part of the R community, which consists of regular R users as\nwell as developers who have not published R packages on public\nrepositories so far. They are usually anonymous and can not be directly\naddressed.\nTherefore, in a first attempt to start gathering information on the R\ncommunity, we turned to a subsample of the community that was more\nclearly defined, namely the attendees of the useR! conference 2016, held\nin Stanford, CA. The advantage of the useR! conference as a platform for\nthe survey – besides feasibility – was that it is attended by both R\nusers and R developers, which is an important prerequisite for getting a\nbroader insight than the previous studies on R Core members and CRAN\npackage developers.\nYet we are fully aware that the useR! attendees are not a representative\nsample from the R community as a whole, because conference attendance\nitself depends on a variety of resources. This is particularly true for\nan expensive location like Stanford. Therefore, in this study we don’t\nclaim that our results can be generalized to other parts of the R\ncommunity – nevertheless they tell us something about a quite relevant\npart of this community.\nSpeaking in terms of study design, we can only consider the useR!\nattendees – not the R community as a whole – as the population, from\nwhich again only a sample answered the questionnaire. We did, however,\nachieve a rather high return rate of 455/904 and also checked the\nrepresentativeness of this sample as compared to the population of useR!\nattendees with respect to demographic information provided at or derived\nfrom registration1. Like most studies, we found that women were\nslightly more willing to participate in the survey compared to men,\nhowever this imbalance only becomes relevant when men and women differ\nin their responses, in which case we present results for men and women\nseparately.\nAll attendees of the useR! conference 2016 received an invitation to\nparticipate in the survey. The questionnaire was presented online and\ncontained 26 questions, which concerned demographic information,\nexperience with and opinions about R, and involvement in the R\ncommunity. Our results will be presented in two sections: In the first\nsection, we report results on the demographic data. In the second\nsection, we summarize the responses concerning the participants’ usage\nof R and their involvement in the R community.\nThe main goal of the survey was to obtain information from R users and\ndevelopers that may help in setting up more inclusive infrastructure for\nthe usage, development and teaching of R. The results may also point out\nprerequisites for successfully developing R expertise and hopefully\ninitiate a dialogue with under-represented subgroups of the R community\nin order to help them formulate their needs.\nWhile the initial focus of the survey, as well as the task force itself,\nwas on addressing the under-representation of women, we did also\ninvestigate the representation of minority groups identified by race and\nsexuality. We will show that these minorities are severely\nunder-represented. However, for a detailed statistical analysis the\ngroup sizes were so small that conclusions would have been questionable\nand identifiability of individual respondents would have become an\nissue.\nGiven that this survey was the first attempt towards addressing a\nbroader part of the R community, both the structure of the questionnaire\nand its analysis are of a rather explorative nature. This, together with\nthe above-mentioned fact that the respondents are a representative\nsample from the attendees, but not necessarily from the R community as a\nwhole, has led us to formulate any conclusions carefully and emphasize\neffect sizes rather than significance in our statistical analysis.\nBased on the work of Cohen (1988), we calculated Cohen’s Omega as an\neffect size measure for describing associations between categorical\nvariables. Cohen also provided guidelines for interpreting these\nmeasures: For Cohen’s Omega, values around 0.1 correspond to a small\neffect, values around 0.3 correspond to a medium effect, and values\naround 0.5 correspond to a large effect. For all results presented here,\na Cohen’s Omega of 0.13 or higher also corresponded to a p-value below\n0.05.\nDemographic information\nThe sample consists of 455 respondents. We first investigated the basic\ncharacteristics of this sample, which include the age of the\nrespondents, the number of women and men respondents, and the\neducational level of the respondents, as well as variables related to\nunder-represented groups. Unless noted otherwise, all reported\npercentages refer to the relative size compared to the entire sample of\n455 respondents.\nMost respondents identified as men or women: an extremely small number\nof attendees had a gender outside the binary, but are not included in\nthis analysis to avoid risking identifying them without their consent.\nOf the remaining respondents, 169 (37.22%) identified as women. 27\nrespondents (5.93%) reported to identify as members of the LGBT\ncommunity, whereas 11 respondents (2.42%) did not reply to this\nquestion. When asked about their ethnicity and country of origin, a wide\narray of responses was given. We used a free text field in order to\navoid deficiencies in standard race classification systems, which may\nnot represent the respondents’ identity. The open answer format does,\nhowever, make summarizing the results more difficult, so for this\nanalysis we did compare the free answers to a standard classification\nsystem. There were 409 responses on the subject of racial identity. This\nnumber was used as the reference for the following percentages: 302\nrespondents (73.83%) identified as White/Caucasian. Only 7 attendees\n(1.71%) identified as Black, Native American (including Pacific\nIslanders) or Middle Eastern.\nTo put this in context, more respondents identified primarily as Jewish\n(8 responses, corresponding to 1.96%), than as Black, Middle Eastern or\nNative American combined. Of the other attendees, 67 (16.38%) fell\nwithin what the standard American Federal criteria would class as Asian,\n12 (2.93%) as Hispanic/Latinx, and the remainder as mixed-race.\nGiven these results, there appears to be a severe under-representation\nof non-white attendees compared to the general population. These results\nmight further indicate an under-representation of members of the LGBT\ncommunity, although this question is more difficult to address. In the\nadult population of the United States, around 3.5% of the adult\npopulation consider themselves as part of the LBGT community, as was\nshown in the report of Gates (2011). However, these figures might\nconstitute a severe underestimation, as was argued by Coffman, L. C. Coffman, and K. M. M. Ericson (1950). We are not\nable to further investigate these minorities and their possible reasons\nfor not attending the conference for two reasons: First, the small\nsample sizes of the under-represented groups would make it difficult to\ngeneralize any conclusions. Still we do not find it justified to merge\nethnic minorities into larger groups just for the sake of the analysis.\nSecond, if a group consists of very few attendees, reporting more\ndetailed findings could compromise the anonymity of individual\nrespondents. Therefore, the remaining analysis will focus only on gender\ndifferences.\nWe do, however, want to point out that the under-representation of\nnon-white attendees we found in the useR! survey was more severe than we\nwould have expected and led to a broadening of the focus of the task\nforce to represent not only the concerns of women but also of other\nunder-represented groups, be they identified by race, gender, sexuality,\nclass, or disability.\nWith respect to gender differences, we found that women and men\nrespondents differed with regard to their age (approximated from their\nbirth year, see Figure 1), but not with regard to\ntheir educational level (with response options “max. secondary school”,\n“undergraduate degree”, “Masters degree”, “Doctorate” and “Professional\ndegree”).\nFigure 1: Approximate age of useR! 2016\nattendees.The median birth year of men respondents was earlier than that of women\nrespondents, with men respondents on average being in their early 40s\nand women respondents being in their mid-30s.\nTherefore, when comparing women and men respondents in the remainder of\nthe analysis, care should be taken with the interpretation of gender\ndifferences in bivariate analyses, because they might be confounded with\nage differences.\nGender differences were indeed found in the reported employment status\nof the respondents (see Figure 2): A higher rate of\nmen respondents tended to be employed in industry or to be permanently\nemployed in academia. On the other hand, a higher rate of women\nrespondents tended to be students. Part of these differences might be\ndue to the age differences reported earlier.\nNote that here and in all following figures comparing the answers of men\nand women respondents, the graphs display conditional relative\nfrequencies of answering in a certain category given the gender.\nAccordingly, the percentages within one gender add up to 100% (missing\nvalues are not considered).\nFigure 2: Employment status.116 respondents (25.49%) reported to be caregivers for children or adult\ndependents on a regular basis, with men attendees being more likely to\nbe caregivers than women attendees. 28.97% of the men respondents\nreported to be caregivers, while only 21.83% of the women respondents\ndid. Even though this difference was relatively small (Omega = 0.08), we\ndecided to report it since it demonstrates the self-selection effect\ninherent in this study: Our sample contained only those members of the R\ncommunity who were able to attend the useR! conference in Stanford (and\nwere also willing to answer the questionnaire).\nAt first glance, the fact that men respondents were more likely than\nwomen to be caregivers may sound like the R community might have\novercome traditional role models already. But the more probable\ninterpretation, that is also supported by the free text answers, is that\ntraditional role models do still make it easier for men to leave\nchildren at home with their partner (if applicable) than for women to do\nthe same, resulting in a self-selection effect in which women with\nchildren are less likely to be able to attend – and as a result women\nwho do attend are less likely to be caregivers.\nThis again reflects the general problem of this survey: We cannot draw\nany conclusion about reasons why women or other under-represented groups\ndid not attend the conference, since we do not have any information on\nthem.\nOpinion on R\nAfter having reported demographical information about the useR! sample,\nwe now report our findings on the opinions reported by the respondents\ntowards R and working with R. Since the demographic information reported\nin the last section suggested that women respondents came from a\ndifferent professional background than men respondents, we were\nparticularly interested in further gender differences in their opinion\ntowards R.\nA first question was whether the respondents would recommend R to\nfriends or colleagues as a programming language to learn. This was\nagreed to by 418 (91.87%) respondents, while 21 (4.62%) respondents\ndisagreed and 19 (4.18%) respondents did not answer. Asked about their\nnumber one argument for or against learning R by selecting one argument\nfrom a list, numerous responses were given. We summarized these reponses\ndiscarding all answers that were given less than 10 times – this left\nonly arguments for using R. Figure 3 summarizes these\nmost frequently given answers.\nFigure 3: Number one argument for using RThese data seem to suggest that the respondents would recommend learning\nR because of it being a good tool for statistical analyses, followed by\nits use as a tool for reproducible research. Men and women respondents\ndid not differ in their willingness to recommend to learn R, or in their\narguments for or against R (note, however, that for the arguments the\ncell frequencies may have been too small for a valid analysis).\nFurther questions of the survey asked the respondents to indicate to\nwhat extent they agreed with certain statements about R.\nFigure 4 summarizes the responses to the statements\nthat\nWriting R is fun.\nWriting R is considered cool or interesting by my peers.\nWriting R is difficult.\nWriting R is a monotonous task.\nPercentages are in reference to the number of all given answers to the\nrespective question.\nFigure 4: useR! 2016 attendees opinions on writing\nR.We did not find any gender differences in these questions. Attendees of\nthe useR! conference – unsurprisingly – regard R mostly as something\nfun and interesting and not very monotonous or difficult.\nIt seems interesting to note that a large part (160 respondents, 35.16%)\nof the sample reported to use R not only in a professional or\neducational setting, but also in their free time. When compared with men\nrespondents, women respondents tend to use R less often in their free\ntime, and more often in an educational or professional setting (see\nFigure 5). Percentages again add up to 100% for each\ngender respectively, while missing values are not considered.\nFigure 5: Primary purpose of using R.In a chi square test, we found a medium effect size (Cohen’s Omega =\n0.25) for this gender difference.\nGiven that the higher share of R usage in their free time might also\ncorrespond to longer exposure times for men, which might again affect\nsubjective or objective expertise as well as self-confidence for\nactively participating in activities like package writing, it might be\nworth investigating the factors behind this different usage behavior –\nbe they motivational or due to structural differences like inequal\ndistributions of household or childcare duties – in future research.\nExperience with R\nA significant part of the survey concerned the respondents’ experience\nof working with R. Generally, the respondents tended to be rather\nexperienced R users. 369 respondents (81.10%) reported that they had\nalready worked with R for 2 years or longer, with 338 respondents\n(74.29%) stating that they had already had programming experience before\nworking with R.\nSince women respondents tended to be younger, it could be expected that\nthey would also have shorter experience in working with R. As can be\nseen in Figure 6, our analysis shows that this is indeed\nthe case (Omega = 0.19). Again, percentages add up to 100 per gender.\nFigure 6: Length of R usage.There were also gender differences when the respondents were asked about\ntheir previous programming experience before using R (Omega = 0.18).\nWhile 82.25% of the men who answered this question reported to have\nprevious programming experience, the corresponding percentage among\nwomen was 66.06%.\nA related question concerned whether the respondents use only existing\nfunctions of R or whether they also write and publish their own\nfunctions. A majority of the respondents (389, 85.49%) reported to have\nwritten R functions for their own use. A smaller part of the sample\n(253, 55.60% of the respondents who answered) reported to have written\ntheir own R package or have contributed to an R package. 155 respondents\n(33.07% of the respondents who answered) reported to have published\ntheir own R packages on CRAN. These results are further illustrated in\nFigure 7. Percentages in this plot are in reference to the\nrespective gender again. They do not add up to 100% for each group\nthough because multiple answers per person were possible. Notably, men\nwere more predominant when it comes to R package development.\nFigure 7: Usage types of R.So far, our results indicate that women respondents tended to be younger\nand have used R for a shorter amount of time than men respondents.\nFurthermore, we found that women respondents have contributed to R\npackages less often. From these bivariate analyses, however, we cannot\nassess whether the gender difference in package development is\nconfounded with the usage length and programming experience, or whether\nthere are gender differences beyond these effects, that may again be\nconfounded with the younger age of the women participants. Therefore, in\nthe next section we conduct a multiple logistic regression model to\nassess the partial effects of gender and the experience variables on\npackage writing.\nModeling gender differences in contribution to R packages\nAs was outlined in the previous sections, women respondents were less\nlikely to contribute to R packages, but also tended to have less\nprogramming experience and a shorter length of R usage. The observed\ngender differences in the contribution to R packages could be confounded\nwith these variables.\nIn order to assess the partial effects of these and further variables,\nwe employed a logistic regression model. It should be clearly stated\nthat this was a fully exploratory analysis, as no clear hypotheses about\nthe factors affecting R package contributions in the general R community\nwere available to guide the design of the survey or this statistical\nanlysis. As will be outlined in the following, we explored the\nassociation between package contributions and those survey variables\nthat seemed plausible.\nIn the logistic regression models, we predicted whether someone had\ncontributed to an R package in any form (i.e., the categories\n“contribute to packages”, “have written package” and “written and\nreleased package” from Figure 7 were combined to form\nresponse category 1). Different models were compared, with contribution\nto R packages as outcome variable and gender, length of R usage and\nprevious programming experience as a first set of candidate\npredictors. Length of R usage was coded as an ordered factor variable\nthat consists of 5 response categories that correspond to less than 1\nyear, 1-2 years, 2-5 years, 5-10 years, and 10 or more years. Previous\nprogramming experience was coded as a dichotomous variable indicating\nwhether someone had previous programming experience before using R or\nnot.\nThe results were inconclusive as to whether gender differences remain\nafter accounting for the differences in length of R usage. With respect\nto AIC, the model with length of R usage and gender as predictors\nwas the best model, whereas the BIC and the Likelihood ratio test\npreferred the model with only length of R usage as a predictor. The\nvariable previous programming experience had no additional effect and\nwas excluded by all criteria. From this first logistic regression\nanalysis, it looked like a large part – but maybe not all – of the\ngender differences in the contribution to R packages were caused by\ndifferences in the length of R usage (with women showing shorter usage\nlengths, as displayed in Figure  6).\nTo explore potential effects of additional survey variables, we also\nincluded employment status, purpose of R usage and community in\nthe analysis. Employment status was coded as a factor variable with\neight different categories like in Figure 2. Purpose\nof R usage is the factor variable from Figure 5, and\ncommunity is a binary variable indicating whether someone stated to\nfeel as part of the R community or not (with descriptive statistics for\nthis variable presented in the next section).\nThe logistic regression model with gender, length of R usage,\nemployment status and community had the lowest AIC and was also the\nbest model according to the Likelihood ratio test. The BIC again\npreferred the more sparse model without gender. Purpose of R usage\ndid not improve model fit for any of the criteria.\nWith respect to the interpretation of the effects of the additional\nvariables included in this model, for employment status we find that\npeople working permanently and non-permanently in academia contribute\nmost to R packages, whereas those working in government/non-profit and\nindustry are slightly less likely to contribute to R packages. Feeling\nas part of the R community goes along with contributing more to R\npackages. Of course, the direction of this association may also be the\nother way round, since people who have already contributed to R packages\nare more likely to feel as part of the R community.\nAgain, the analysis does not give a clear answer to the question whether\nany gender differences in package contributions remain beyond the\ndifferences already captured by the other predictor variables. Any\nremaining differences might depend on a variety of other individual and\nstructural factors, such as differences in motivation or\nself-confidence, in access to information, or in networking and peer\nsupport for contributing to R packages. After this first exploratory\nstudy, it would be very interesting to further question women R users\nthat are on the verge of becoming R developers what might be keeping\nthem back – as well as asking men R users that did cross over and\nbecome developers what helped them take that step.\nThe respondents as part of the R community\nA final set of questions in the survey concerned the role of the\nrespondents as part of the R community. Asked whether they considered\nthemselves to be part of the R community, 361 (79.34%) respondents\nagreed, whereas 69 (15.16%) respondents disagreed and 28 (6.15%)\nrespondents did not answer. Men and women respondents did feel as part\nof the R community to a comparable extent.\nThe respondents further reported to use a variety of resources to\nsupport their work with R. The respective question in the survey\nprovided a list of possible resources, and also allowed the respondents\nto enter additional resources that were not listed as free text. Among\nthe listed resources, StackOverflow and the R mailing list were the most\nfrequently used resources. We found no gender differences here.\nReporting only given answers that were chosen more than 4 times for\nbrevity, the results are displayed in Figure 8.\nFigure 8: Resources men and women use to support their work with\nR.Further asked about their preferred medium for R community news, the\nrespondents most frequently chose the website (24.18%) and the mailing\nlists (21.10%). Other selected options were blog (18.02%), Twitter\n(15.16%) and Facebook (4.62%). Given these preferences, communication\nacross a range of media is necessary to be confident in reaching a large\nproportion of R users and developers. A sizeable proportion (7.91%) did\nnot select any option, so does not have a preference or is not\ninterested in R community news. Nonetheless, as conference participants,\nthey may receive some news in person.\nWe further investigated whether men and women respondents differed with\nregard to their preference of individual resources. Therefore, we tested\nfor every single response category of the previous question whether the\nrelative frequency with which it was selected differed between men and\nwomen respondents. When correcting for multiple testing, none of them\nwas statistically significant.\nAmong the 455 respondents of the survey, 163 (35.82%) respondents\nreported that they attend meetings of a R user group, whereas 268\n(58.90%) responded that they did not, and 27 (5.93%) respondents did not\nreply. Among the 163 respondents attending R user group meetings, 134\n(82.21%) respondents indicated that they attended a general user group,\nwhereas 16 (9.82%) respondents reported that they visited a user group\nwithin a university. Other types of user groups were less often named.\nThe respondents who did not visit R user group meetings were further\nasked about their reasons for this decision. Again, the respondents\ncould answer this question by either selecting statements from a list or\nby entering new statements. The arguments that were chosen most\nfrequently were that the respondents were too busy or that no active\nuser group was available.\nFinally, we investigated whether men and women respondents differed with\nrespect to their attendance of R user group meetings, and how these\nmeetings could be made more attractive for new attendees. In a first\nstep, we found gender differences with regard to the reported attendance\nof R user group meetings. Men respondents reported to attend R user\ngroup meetings more often than women respondents with a small to medium\neffect (Omega = 0.21).\nIn a second step, we investigated gender differences to the question\nwhat measure would make the respondent more likely to attend user group\nmeetings. For the individual response options, the following differences\nwere found (only those answers are listed that were chosen by at least\n10 respondents, with n indicating the total number of respondents that\nchose the respective option):\nNew R user group near me (n = 122): no gender differences (Omega =\n0.02)\nNew R user group near me aimed at my demographic (n = 31): More\npositive responses by women respondents with a small effect (Omega =\n0.19)\nFree local introductory R workshops (n = 61): no gender differences\n(Omega = 0.02)\nPaid local advanced R workshops (n = 61): no gender differences\n(Omega = 0.08)\nR workshop at conference in my domain (n = 73): no gender\ndifferences (Omega = 0.08)\nR workshop aimed at my demographic (n = 20): More positive responses\nby women respondents with a small effect (Omega = 0.12)\nMentoring (e.g. first CRAN submission/useR! abstract\nsubmission/GitHub contribution) (n = 87): no gender differences\n(Omega = 0.09)\nOnline forum to discuss R-related issues (n = 62): More positive\nresponses by women respondents with a small effect (Omega = 0.14)\nOnline support group for my demographic (n = 18): More positive\nresponses by women respondents with a small effect (Omega = 0.15)\nThese answers indicate that most people who do not attend user group\nmeetings do not have a user group near them or (as was suggested by free\ntext answers) do not know that there are user groups. Other measures\nthat could help to make people attend user group meetings would be R\nworkshops at conferences in their domain, an online forum or local R\nworkshops of different kinds. When it comes to gender differences, women\nmight be more attracted by user groups explicitly aiming at women, but\nmight also hint in the direction of women being less willing or less\nable or both to spend their free time with R, as we have seen in an\nearlier question.\nDiscussion\nOur results draw a complex picture of the sample of attendees who agreed\nto respond to our survey. When looking at the sample as a whole, the\nrespondents to this survey tended to have programming experience prior\nto working with R, and usually used R for 2 or more years. Most\nrespondents further wrote their own R code, either to create functions\nfor their own work or to contribute to R packages. Moreover, the average\nrespondent had a positive opinion towards working with R. These results\nare not very surprising, given that this sample was collected among the\nattendants of a useR! conference. However, as no comparable results on\nthe community of R users have been published so far, these findings are\nnevertheless valuable. Future studies could use the results reported\nhere as a benchmark for the evaluation of long-term developments in the\nR community.\nIn accordance with the initial question of the taks force, we did find\nthat women were under-represented at the useR! conference 2016 – but\neven more strikingly, that non-white users were even more severely\nunder-represented.\nWhen looking at gender differences in more detail, results from three\nareas of the questionnaire stand out, that may however be confounded as\ndiscussed above. First, women respondents tended to be younger and have\nshorter experience in R usage than men respondents. Second, women used R\nless in their free time and contributed less to R packages. Third, women\nagreed less to feeling part of the R community.\nThe results of the exploratory logistic regression analysis suggest that\nthe survey questions captured some factors associated with gender\ndifferences in contributions to R packages, such as the length of R\nusage, employment in academia and a feeling of belonging to the R\ncommunity, that were positively associated with contributing to R\npackages. Yet the results were not conclusive as to whether there may be\nfurther gender differences, for example due to personal or structural\nfactors, that may discourage women from writing R packages and would be\nimportant to investigate.\nAn additional hierarchical cluster analysis of the same data found three\ndifferent groups of people: The first group (around 38% of the sample)\nare experienced R users, who tend to be men, from academia and people\nwith doctorate. They use R not only in a professional setting, but also\nfor recreational purposes. The second group (around 57% of the sample)\nare intermediately experienced users who use R for less than 2 years and\nmainly apply existing packages. They tend to be female, and are either\nundergraduates or have a master degree. They are using R mainly in\nprofessional or educational settings. The last group (around 3% of the\nsample) are the least experienced users who are using R during their\nfree time. Details on this analysis as well as further multivariate\nanalyses of the data can be found at UseR! 2016 R community: a\nmultivariate\nanalysis\nand UseR! 2016 participants: a multivariate\nanalysis.\nAn anonymised form of the survey data, which minimises disclosure risk\nby excluding some demographic variables and recoding others, is\navailable on CRAN\n(forwards). This data\nset includes aggregated versions of all demographic variables used in\nthe logistic regression analysis and the majority of demographic\nvariables used to aid interpretation in the multivariate analysis. Apart\nfrom the suppression of a small number of data values and a few free\ntext variables that contained sensitive/identifying information, the\nresponses to the programming and community questions are provided as\nrecorded.\nAs stated already in the beginning of this text, due to the limitations\nof the study design, the results from the conference sample might not\ngeneralize to other subgroups of the R community, in particular not to\nthose individuals who could not attend the conference due to factors\nassociated with their being part of an under-represented group. Further\nstudies are necessary to try to obtain a better picture of the R\ncommunity as a whole.\nMoreover, several topics which could be of further interest for the\nsupport of R users had not yet been included in the survey in order to\nkeep it as short as possible. Further potentially interesting questions\ninclude, besides the ones already mentioned above, for example, what\nprogramming languages R users had already used before they started\nworking with R, whether being in contact with other users that\ncontribute to R packages makes it more likely to contribute to R\npackages oneself, etc.\nStill the answers from this questionnaire give some indication to\nmeasures that could be taken to advance the participation of women, for\nexample that user groups and other means of exchange explicitly\ntargeting women might make them more accessible. Even though this would\nbe methodologically challenging both due to the unspecific nature of the\nR community and the confounding of any interventions with different\ndevelopments over time, it would be important to evaluate the\ndevelopment of under-represented groups over time.\nThe fact that women useR! attendees are on average younger and have\nlower R usage lengths might stimulate the hope that, once they reach the\nage and experience of their men counterparts, any gender differences\nmight disappear automatically. However, this may not be the case, since\nmultivariate analyses (see for instance Josse and H. Turner (2016)) tend to suggest that\nafter adjusting for the age, women are still less involved in the R\ncommunity. We still expect that if the R community and the opportunities\nto contribute are not equally attractive for women, they will not have\nthe motivation to develop the skills to become contributors.\nAlthough our initial framing looked specifically at gender as an axis of\nexclusion, the results show that race, not gender, is the area where\nthere is the greatest disparity, and it is vital that inclusivity\nefforts factor this in. While the survey results give some ideas for\nimproving inclusion in general, specific efforts should be made to reach\nout to people from under-represented races, for example through\ndiversity scholarships, invited conference contributions, or invitations\nto serve in community roles. Further information on who is\nunder-represented, and for what reason, would support such efforts.\n\nCRAN packages used\nforwards\nCRAN Task Views implied by cited packages\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\nK. B. Coffman, L. C. Coffman, and K. M. M. Ericson. The size of the LGBT population and the magnitude of anti-Gay sentiment are substantially underestimated. Working Paper 8 National Bureau of Economic Research October2013, 1950. URL http://www.nber.org/papers/w19508.\n\n\nJ. Cohen. Statistical power analysis for the behavioral sciences Lawrence Earlbaum Associates. Lawrence Erlbaum Associates Hillsdale NJ 2 edition, 1988.\n\n\nJ. Fox. Aspects of the social organization and trajectory of the R project. The R Journal 1 (2):, 2009.\n\n\nG. J. Gates. How many people are lesbian, gay, bisexual, and transgender?, Apr. . 2011. URL http://williamsinstitute.law.ucla.edu/wp-content/uploads/Gates-How-Many-People-LGBT-Apr-2011.pdf.\n\n\nJ. Josse and H. Turner. useR! participants and the R community: a multivariate analysis, June 2017. 2016. URL https://forwards.github.io/docs/MCA/community/useR2016/survey/.\n\n\nP. Mair, E. Hofmann, K. Gruber, R. Hatzinger, A. Zeileis, and K. Hornik. Motivation, values, and work design as drivers of participation in the R open source project for statistical computing. Proceedings of the National Academy of Sciences of the UnitedStates of America 112 (48):, 2015. URL https://doi.org/10.1073/pnas.1506047112.\n\n\nFor more detail see our supplementary report Non-Responses in the\nUseR! 2016\nSurvey\n\n↩︎\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2017-2-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2017-2 issue.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2017-12-01",
    "categories": [],
    "contents": "\n1 Donations and members\nMembership fees and donations received between 2017-06-16 and\n2017-12-01.\nDonations\nYahaya Nazoumou (Niger)\nJørgen Raffnsøe (Denmark)\nRomuald Riem (France)\nRenan Silverio (Brazil)\nAppstam Consulting GmbH, Berlin (Germany)\nSpängler IQAM Invest GmbH, Salzburg (Austria)\nSupporting benefactors\nThomas Dangl (Austria)\nTransmitting Science, Barcelona (Spain)\nSupporting members\nAyala S. Allon (Israel)\nMichael Blanks (United States)\nGilberto Camara (Brazil)\nJorge de la Vega (Mexico)\nElliott Deal (United States)\nKristina Dietz (United Kingdom)\nCharles Geyer (United States)\nMichael Griffiths (United States)\nKen Ikeda (Japan)\nArtem Ilievskiy (Russia)\nJUNE KEE KIM (South Korea)\nFelix Kluxen (Germany)\nSebastian Kreutzer (France)\nPawel R. Kulawiak (Germany)\nChel Hee Lee (Canada)\nDetlef Lehmann (Germany)\nGorka Navarrete (Chile)\nMatt Parker (United States)\nGerard Pennefather (Singapore)\nAlfonso Reyes (United States)\nCarlos Erwin Rodríguez Hernández Vela (Mexico)\nJoshua Rosenstein (United States)\nFabian Scheipl (Germany)\nSurendra Singh (United Kingdom)\nEaro Wang (Australia)\nDave Williams (United Kingdom)\nKisung You (United States)\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2017-2-insurance/",
    "title": "Conference Report: R in Insurance 2017",
    "description": "The 'Conference Report: R in Insurance 2017' article from the 2017-2 issue.",
    "author": [
      {
        "name": "Nicolas Baradel",
        "url": {}
      },
      {
        "name": "Christophe Dutang",
        "url": {}
      },
      {
        "name": "Caroline Hillairet",
        "url": {}
      }
    ],
    "date": "2017-12-01",
    "categories": [],
    "contents": "\n\n1 Conference summary\nThe fifth R in Insurance conference took place at Ecole Nationale de la\nStatistique et de l’Administration Economique (ENSAE, one of the leading\nFrench graduate schools in the fields of statistics, economics, finance\nand actuarial science) Paris on 8 June 2017. This one-day conference\nfocused once more on the wide range of applications of R in insurance,\nactuarial science and beyond. The conference programme covered topics\nincluding reserving, pricing, loss modelling, the use of R in a\nproduction environment and also new statistical methods such as big data\nanalysis.\nThe audience of the conference included both practitioners (around 70%)\nand academics (30%) who are active or interested in the applications of\nR in Insurance. The fifth edition was a fair success with 128\nparticipants compared to the 100 participants of the fourth edition.\nFurthermore, it was a truly international event with speakers and\ndelegates from many different countries, including USA, Belgium,\nNetherlands, Switzerland, Germany, Italy, Qatar, UK, India and of course\nFrance. Overall, there were 17 speakers from USA, Belgium, Netherlands,\nSwitzerland, Italy, UK, India and France. The coffee breaks and the\nlunch time offered great networking opportunities, while the conference\ndinner at Musée d’Orsay closed on a high note this enlighting day.\nIn the first plenary session, Julie Seguela (from Covea) spoke about the\ntextual analysis of expert reports to increase knowledge of\ntechnological risks. She used open datasets from the ARIA database\n(Analysis, Research and Information about Accidents), which has\ncollected more than 40 000 technological accidents, between 1995 and\n2015 in France, susceptible to damage public health or safety, etc. Text\nmining techniques and some helpful visualization packages were used on\nexpert reports detailing circumstances, causes and consequences of these\naccidents. This master class talk highlighted how various R packages can\ninteract to achieve our goal.\nThis plenary talk was followed by two sessions to close the morning. The\nfirst session focused on big data analytics emphasizing new usage in the\ninsurance industry. Then, the second session consisted of a series of\nlightning talks about R packages or R modelling. Thereafter, the\nafternoon started with the third session on non-life insurance with\nspeeches rather theoretical on non-life reserving or vine copulas. The\nfourth and last session followed with topics in life insurance.\nIn the closing plenary talk, Katrien Antonio (Professor of Actuarial\nScience at KU Leuven, Belgium) presented recent development and\nchallenges in non-life reserving. In order to be able to fulfill future\nliabilities, insurance companies approach micro-level reserving by using\ngranular, detailed data on the development of individual claims. In her\ntalk, she gave an overview of the research on micro-level reserving and\npresented ongoing developments of statistical modeling and data analytic\ntools for reserving with granular data. Her talk was illustrated on a\nlarge European dataset of liability claims (from private individuals)\nwith monthly exposures using R.\nAll conference presentations are available on the conference website athttps://rininsurance17.sciencesconf.org/.\n2 Scientific committee and sponsors\nThe members of the scientific committee were: Arthur\nCharpentier (University of\nAmsterdam and KU Leuven), Christophe Dutang\n(Université du Maine and Université Paris Dauphine, France), Markus\nGesmann (ChainLadder\nproject), Giorgio A.\nSpedicato\n(Unipol Gruppo Finanziario), Andreas\nTsanakas (Cass Business\nSchool).\nFinally, we are grateful to our sponsors\nRStudio, Verisk Insurance\nSolutions, Barnett\nWaddingham, Mirai\nSolutions,\nMilliman. This conference would not have been\npossible without their generous support.\n3 R in Insurance 2018\nWe are delighted to announce next year’s event already on 16 July 2018.\nFollowing three years in London, one year in Paris and one year in\nAmsterdam, the conference will go back to London, UK. Further details\nwill be published on https://insurancedatascience.org/.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2017-2-teaching/",
    "title": "R Teaching Column",
    "description": "The *revisit* package, developed as a collaborative tool for scientists, also serves as a tool for teaching statistics, in a manner that can be highly motivating for students. Using either the included case studies or datasets/code provided by the instructor, students can explore several alternate paths of analysis, such as the effects of including/excluding certain variables, employing different types of statistical methodology and so on. The package includes features that help students follow modern statistical standards and avoid various statistical errors, such as \"p-hacking\" and lack of attention to outlier data.",
    "author": [
      {
        "name": "Matthias Gehrke",
        "url": {}
      },
      {
        "name": "Reed Davis",
        "url": {}
      },
      {
        "name": "Norman Matloff",
        "url": {}
      },
      {
        "name": "Paul Thompson",
        "url": {}
      },
      {
        "name": "Tiffany Chen",
        "url": {}
      },
      {
        "name": "Emily Watkins",
        "url": {}
      },
      {
        "name": "Laurel Beckett",
        "url": {}
      }
    ],
    "date": "2017-12-01",
    "categories": [],
    "contents": "\n\n1 Invitation to collaborate\nWith this issue of the R Journal, there will be a section for teaching R\nand teaching using R as well as for empirical research on teaching R.\nTeaching material\nA GitHub repository will be setup where the teaching material can be\naccessed. All material should be under some licence of Creative Commons\nto allow re-use. Please prepare a short text describing your material.\nFor a sample, see the description by Norman Matloff et al. (below) of\nclass room material he is using.\nResearch on teaching R\nSome research is considering the relative success of different\napproaches to teaching R and teaching statistics with R. For example,\nsee some contributions on the recent useR!2017 in Brussels (Gert\nJanssenwill et al., The analysis of R learning styles with\nR, Matthias Gehrke and Karsten Luebke, A\nquasi-experiment for the influence of the user interface on the\nacceptance of R). The R Journal is interested in\nreceiving such submissions.\nTechnical details\nThis column will appear before this GitHub repository is established, so\nonly links to an existing cooperating\nrepository and\nmailing list can\nbe provided at this time. Subsequent columns will provide full technical\ndetails or links to such details.\n2 The ‘revisit’ Package As a Teaching Tool\nOverview\nThe R package revisit was developed in response to the recent concern\nover reproducibility in research, especially problems related to\nstatistical analysis (Baker 2016). The motivation and methods are\ndetailed in Matloff, R. Davis, L. Beckett, and P. Thompson (2017), but in this paper we turn to teaching.\nThe package has both text and GUI versions, the latter being based on\nthe RStudio integrated development environment for R. It is currently at\nan early stage of development, with more features and refinements being\nadded continuously. It may be downloaded from\nhttps://github.com/matloff/revisit.\nOne can obtain a quick introduction to the package by starting it and\nrunning one of the case studies. To start the package in GUI form, click\nAddins in RStudio, and choose “Revisit”. The text version is not\ncolorful, but is more flexible. To run it, simply run\nlibrary(revisit). Use of the case studies will be introduced later in\nthis paper.\nAn excellent motivator: the Reinhart/Rogoff study controversy\nThe package includes a number of examples for student examination and\nparticipation. One of the case studies involves the controversial paper\nby Harvard economists C. Reinhart and K. Rogoff (Cassidy 2016). They had\nfound that nations with high budget deficits average a \\(-0.1\\)% growth\nrate in GDP. This finding had major impact on policymakers, with the\npaper attracting particular interest from the “deficit hawks” in the\nU.S. Congress. The Washington Post took to describing the finding as\n“consensus among economists.”\nBut when later researchers tried alternate analysis, the picture changed\nentirely. Some data had been excluded from the initial published\nanalysis, for what arguably were weak reasons. The original analysis\nalso had the flaw of giving equal weights to all nations, regardless of\nsize, as well as other aspects that some researchers considered flaws.\nWhen the alternate analysis was run, the figure \\(-0.1\\)% changed to\n+2.2%. Thus the original findings on deficit spending now seem\nquestionable. This leads to the theme in the present paper, use of\nrevisit for teaching.\nAt a talk given by one of the authors of the present paper (Matloff 2017),\nthe author was stunned at student reaction to the Reinhart/Rogoff\nexample. The students, all doing graduate work in science and\nengineering, were captivated by the fact that the study, which had had\nsuch influence on policy, may have been seriously flawed, with alternate\nanalyses of the same data yielding starkly different results. The\npotential of revisit as a teaching tool had been suggested earlier by\none of the other authors of the present paper, but the strong student\nreaction here dramatized the point.\nGeneral structure of the package\nThe package is structured as follows:\nA set of case studies for students to explore and modify (and to\nwhich instructors can add their own examples).\n“Statistical audit” warnings/advice given to students regarding\nstatistical best practices as they proceed in their analyses.\nA code management infrastructure to facilitate exploration of\nalternative analyses.\nThe case study approach\nThe package includes various case studies, consisting of data and code.\nThe latter comprises a complete, though possibly brief, analysis of the\ndata from start to finish — the code may include data configuration,\ndata cleaning, preliminary graphical analysis, predictor variable/model\nselection, and so on. Students can then try their own alternative\nanalyses. Most of the case studies are not as dramatic as Reinhart and\nRogoff, but each illustrates important concepts in data analysis.\nThere are just a few case studies included in the package currently, but\nmore are being added, and instructors will often prefer to use their own\ndata anyway. In many cases, the code will be minimal, affording the\nstudents even more opportunity for nonpassive thought and exploration.\nAssignments centered on the use of revisit can be very specific or\nmore open-ended, according to the instructor’s preference. Here are\npossible samples:\n“This assignment involves the Reinhart and Rogoff data, included in\nthe revisit package. Revisit the analysis with different\nweightings for the nations based on various factors.”\n“This assignment involves the famous Pima diabetes study. Some later\ninspection suggested that the data includes a number of erroneous\nvalues, such as impossible 0 values. Investigate this, say using\ngraphical means. Run a logistic regression model, with and without\nthe suspect data points, and compare the results. Also, the authors\nof the study used a neural network approach. Try using random\nforests, and compare to the authors’ level of predictive ability.”\n“This assignment analyzes the famous Forest Cover dataset, in which\none of seven cover types is predicted from variables such as\nHillside Shade at Noon. The given code tries prediction using, of\ncourse, the random forests method. The first 10 predictors are used.\nIn your alternate analysis, try using all 54 predictors. That is\nquite a bit, and even with over 500,000 observations, one must\nalways worry about overfitting; investigate that here.”\n“This assignment analyzes the Fong-Ouliaria currency data. The\nsupplied code fits a linear regression model, with a respectable\n\\(R^2\\) value. However, one can do better. First, explore this with\nsome of the graphical methods in the\nregtools package,\nand then try adding some quadratic and interaction terms to the\nmodel, and/or try a nonparametric regression approach.”\n“Here you will work with data from the 2000 Census, involving\nsalaries of programmers and engineers in Silicon Valley. One aspect\nof interest is the gender issue — are women paid less than\ncomparable men? A preliminary regression analysis indicates a\ndifference of over $10,000, for fixed age and educational level.\nBut much more needs to be done. For instance, what happens when\noccupation is factored in, and when the non-monotonic relation of\nwage and age is accounted for? Investigate such questions.”\nWe are continuing to add case studies. At this early stage, the list\nincludes:\nUCI Pima diabetes data (Lichman 2017)\nZavodny guestworker data (Zavodny 2011)\nReinhart and Rogoff (Cassidy 2016)\nMovieLens (Harper and J. A. Konstan 2015)\nFong-Ouliaria currency data (Fong and S. Ouliaris 1995)\nUCI forest cover data (Lichman 2017)\nSalary data on programmers and engineers, Silicon Valley, 2000\nCensus\nWe anticipate that instructors will typically develop their own case\nstudies. We encourage them to contribute these to revisit.\nTo load a case study in the GUI, just select the desired one from the\nCase Studies window. The code will then be loaded, ready to run. For the\ntext version, at present this is done as in this example, for the\nCurrency data:\nfname <- system.file('CaseStudies/Currency/currency.R',package='revisit')\nloadb(fname) \nA “statistical audit”\nOne of the most important features of revisit is that it plays the\nrole of a “statistical audit,” in much the same way that tax preparation\nsoftware might warn of questionable claims in a tax return.\nMuch of this is accomplished by wrapper functions provided by revisit.\nFor instance, if the student wishes to form a confidence interval for a\nmean in R, she might use t.test(). But in revisit she can instead\nuse t.test.rv(). Instead of lm() she can call lm.rv(), a wrapper\nfor lm() that adds “statistical audit” functionality.\nThe wrapper lm.rv()\nAs noted, this function calls lm() and returns an object of class\n\"lm\", but with additional functionality. At present this takes on two\nforms:\nIt checks whether the response variable takes on only two values, in\nwhich case the function suggests a logistic model using glm():\n> y <- c(1,0,1)\n> x <- 1:3\n> d <- data.frame(y,x)\n> lm.rv(y ~ x,d)\n...\nCoefficients:\n(Intercept)            x  \n     0.6667       0.0000  \n\nWarning message:\nIn lm.rv(y ~ x, user.data = d) :\n  only 2 distinct Y values; consider a logistic model\nIt runs a parallel analysis, i.e. with the same formula and data as\nthe lm() call, but with median (Minimum Absolute Deviation)\nregression, implemented with rq() from the\nquantreg package.\nFor instance, with the salary case study, one might run:\n> lm.rv(wageinc ~ age+sex+ms+phd,user.data=pe)\nmax. prop. difference, linear median regression: 0.3221592 \nlarger values, may indicate outlier or model fit issues\n\nCall:\nlm(formula = formula, data = user.data)\n\nCoefficients:\n(Intercept)          age          sex           ms          phd  \n    53286.4        441.4     -12343.6      18363.6      27770.3  \nThere is more than a 32% difference in the two model fits, which\nturns out to be in the age coefficient. (The rq() coefficients are\navailable as a component $rqc of the \"lm\" object returned by\nlm.rv().) As noted, this may indicate issues with outliers or\nmodel fit.\n“Audits” of signficance testing\nThe package aims to reduce p-hacking by monitoring the number of\ninference actions — p-values, confidence intervals — the student has\naccumulated in his/her analysis, and may issue a warning that the\nstudent should consider employing multiple-inference methods. For the\nlatter, at present the package offers just Bonferroni’s Method, but more\nwill be added (Hsu 1996).\nMoreover, the package responds to the dramatic 2016 announcement by the\nAmerican Statistical Assocation (Wasserstein and N. A. Lazar 2016), which warned on the overuse of\np-values. Though this problem had been common knowledge for many years\n(Freedman, R. Pisani, and R. Purves 1978; Jones and N. Matloff 1986; Ziliak and D. McCloskey 2008), the ASA announcement gave new urgency to\nthe issue. The revisit package takes an active role in encouraging\nstudents not to rely much on p-values in the first place. Confidence\ninterval-based analysis is preferred.\nHere is the code for t.test.rv():\n> t.test.rv\nfunction (x, y, alpha = 0.05, bonf = 1) \n{\n    alpha <- alpha/bonf\n    tout <- t.test(x, y, conf.level = 1 - alpha)\n    muhat1 <- tout$estimate[1]\n    muhat2 <- tout$estimate[2]\n    tout$p.value <- tout$p.value * bonf\n    rvenv$pcount <<- rvenv$pcount + 1\n    if (tout$p.value < alpha && muhat1 != 0) {\n        if (abs(muhat1 - muhat2)/abs(muhat1) < rvenv$smalleffect) \n            warning(paste(\"small p-value but effect size\", \n            \"could be of little practical interest\"))\n    }\n    tout\n}\nHere the argument bonf is a multiplicative factor used to expand\nconfidence interval widths for Bonferroni corrections, as seen in the\nabove code.\nNote the incrementing of rvenv$pcount. This is the global count (which\nincludes potential confidence intervals) alluded to earlier, to be used\nin the warning that the user should consider multiple inference\nmethods.1 Note too that the code may warn the student that there was\na “small p-value but effect size could be of little practical interest.”\nOther wrappers\nSteering students (and their instructors) to confidence intervals\ninstead of p-values can be difficult not only in terms of breaking\nhabits, but also in technical terms. Consider the log-linear model. for\ninstance. Most packages perform log-lin solely from a hypothesis testing\npoint of view. R’s stats::loglin() function, for instance, will not\nprovide standard errors, and only provides point estimates on request.\nOur package will go further, offering point estimates and standard\nerrors for estimated cell probabilities. As the user steps through the\nmodel hierarchy, at a certain point it will become clear that the\nestimates are not changing in important ways, and one can stop the model\nselection process. This will be accomplished by the “Poisson\ntrick”(Christensen 2013), in conjunction with R’s glm() function.\nGenerating and managing alternative analyses\nAfter a student selects an example from the Case Study menu, the package\nloads the desired code and data, and enters the code into the package’s\nvisual text editor. The student can now edit and run the revised code,\nincluding just a partial run, up to a given line.\nThe latter capability is especially useful. Say the code consists of 32\nlines, and line 11 is of interest to the student. The student can direct\nrevisit to run lines 1-10 of the code, then pause. At that point the\nstudent can try executing an alternative to line 11, by executing the\nalternative line in the Console box, which provides direct access to the\nRStudio R console in which execution takes place. The student can then\nresume execution of the code starting from line 12. This allows the\nstudent to quickly try alternative code without actually changing the\ncontents of the text editor.\nIn generating various alternative analyses, the student can save the\ninteresting ones, each version in a different file, but all managed\nconveniently by revisit. Borrowing from software engineering\nterminology, each of these files is called a branch.\nExample: Pima diabetes study\nLet’s start with a simple and quite well-known example, the Pima\ndiabetes data. The authors (Baker 2016) used a form of neural networks\nto predict diabetes from variables such as BMI and insulin. To keep\nthings simple, though, we will not engage in prediction analysis here.\nUpon launching revisit in the GUI, a new window associated with the\nRStudio session then pops up, and the screen then looks like Figure\n1. Pima is the first case study listed.\nThe included code here consists of just forming confidence intervals\ncomparing diabetic and nondiabetic groups, on each of the eight\npredictor variables. The student can choose to run the entire code or\njust a part; say she chooses the former. The confidence intervals can\nthen be seen in the R console portion of the RStudio window (Figure\n2).\nAt this point, the student may ask, “What if we make the Bonferroni\ncorrection here?” Although she could edit line 15 in the revisit text\neditor window to\ntmp <- t.test.rv(diab[ ,i], nondiab[ ,i])$conf.int\nand then re-run, if this is just a tentative change, she could avoid\nchanging the code, by entering the above into the Console box, as seen\nin Figure 3. As expected, the confidence intervals\nbecome wider (not shown). If the student wishes to make further changes,\nshe may now wish to make the above change in the text editor, and\npossibly save the new code into a new branch.\nAfter the Pima dataset was curated, there were reports of erroneous\nvalues in some data points. To investigate this, one might run the\ndiscparcoord() function from the package\ncdparcoord, included\nin revisit:\ndiscparcoord(pima,k=769)\nHere the second argument specifies forming the graph on all 769 records\nin the data.2\nThe resulting graph will be displayed in the Viewer pane in the RStudio\nwindow. In the text version, the student would run the above directly,\nin which case the graph appears in the student’s Web browser.\nThe result is shown in Figure 4. This is a parallel\ncoordinates plot (Inselberg 2009). Each data point is displayed as a\nsegmented line connecting dots at heights given by the values of the\nvariables in that data point.3\nThe results are rather striking. We see that there are data points\nhaving the impossible value of 0 for variables such as glucose and blood\npressure. Indeed, there are some data points with multiple 0s. Clearly\nthe student will need to remove some of the data points, and re-run the\nanalyses.\nThe student may wish to create multiple versions of the code, e.g. in\nthis case, code with and without the erroneous points. The revisit\npackage facilitates this, creating branches 0, 1, 2 and so on of the\ncode.\nFuture development\nAs mentioned, a number of wrapper functions are planned, as well as\nexpanding the “statistical audit” features of existing wrappers. Much\nmore graphical analyis is slated.\nThe number of case studies will continue to grow.\nConclusions\nThe revisit package facilitates nonpassive, hands-on exploration of\nstatistical and data analytic methodology on real data. The students\nlearn that even published data is not sacrosanct, and that alternate\nanalysis can yield additional insight into the phenomena under study.\nStatistical methodology pervades almost every conceivable aspect of our\nworld today. In addition to the students’ possible future usage of\nstatistics in professional roles, educators should prepare them to act\nas informed, critical thinkers in their roles as citizens and consumers.\nWe hope that revisit can play a part in achieving such goals.\nIt is also hoped that instructors and students will contribute\nsuggestions for improvement, including pull requests on GitHub. These,\nand of course new datasets, would be highly appreciated.\nAcknowledgements\nWe are grateful to Bohdan Khomtchouk for inviting one of the authors to\nspeak on revisit at the inaugural meeting of the Stanford R Group, and\nto Karen Wu for a careful reading of the manuscript.\nFigure 1: Opening screen.Figure 2: Ordinary CIs.Figure 3: Console box.Figure 4: Parallel coordinates view.\nCRAN packages used\nregtools, quantreg, cdparcoord, freqparcoord\nCRAN Task Views implied by cited packages\nEconometrics, Environmetrics, Optimization, ReproducibleResearch, Robust, Survival, TeachingStatistics\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\nM. Baker. 1,500 scientists lift the lid on reproducibility. Nature 533 (7604): May, 2016. URL https://doi.org/10.1038/533452a.\n\n\nJ. Cassidy. The Reinhart and Rogoff Controversy: a Summing Up. The New Yorker 533 Apr, 2016. URL https://doi.org/10.1038/533452a.\n\n\nR. Christensen. Log-Linear Models. Springer Texts in Statistics Springer New York, 2013.\n\n\nW. M. Fong and S. Ouliaris. Spectral tests of the martingale hypothesis for exchange rates. Journal of Applied Econometrics 10 (3):, 1995. URL https://doi.org/10.1002/jae.3950100304.\n\n\nD. Freedman, R. Pisani, and R. Purves. Statistics. Norton, 1978.\n\n\nF. M. Harper and J. A. Konstan. The MovieLens datasets: History and context. ACM Trans Interact Intell Syst. 5 (4):19::19 Dec, 2015. URL https://doi.org/10.1145/2827872.\n\n\nJ. Hsu. Multiple Comparisons: Theory and Methods. Taylor & Francis, 1996.\n\n\nA. Inselberg. Parallel Coordinates: Visual Multidimensional Geometry and Its Applications. Advanced series in agricultural sciences Springer New York, 2009.\n\n\nD. Jones and N. Matloff. Statistical hypothesis testing in biology: a contradiction in terms. J of Economic Entomology 79 (5): Oct, 1986.\n\n\nM. Lichman. UCI machine learning repository, . 2017. URL http://archive.ics.uci.edu/ml.\n\n\nN. Matloff. “revisit”: an R Package for Taming the Reproducibility Problem (Stanford University R Users Group). public lecture, 2017. URL http://heather.cs.ucdavis.edu/StanfordR.pdf.\n\n\nN. Matloff, R. Davis, L. Beckett, and P. Thompson. revisit: a workflow tool for data science, . 2017. URL https://arxiv.org/abs/1708.04789.\n\n\nR. L. Wasserstein and N. A. Lazar. The asa’s statement on p-values: Context, process, and purpose. The American Statistician 70 (2):, 2016. URL https://doi.org/10.1080/00031305.2016.1154108.\n\n\nM. Zavodny. Immigration and american jobs, . 2011. URL http://www.aei.org/wp-content/uploads/2011/12/-immigration-and-american-jobs_144002688962.pdf.\n\n\nS. Ziliak and D. McCloskey. The Cult of Statistical Significance: How the Standard Error Costs Us Jobs, Justice, and Lives. University of Michigan Press, 2008.\n\n\nTechnically switching to multiple inference methods midstream like\nthis does not fully solve the problem, as the probabilistic behavior\nof the analysis now is conditional on having made the switch.\nHowever, this is a general problem in statistical analysis, far\nbeyond the scope of revisit. For instance, typically an analyst\nwill perform graphical analysis of the data before embarking on\nformal inference analysis, again resulting in a conditional setting.↩︎\nThe cdparcoord package generally displays only the most\nfrequently-appearing tuples, rather than the full dataset of all\ntuples.↩︎\nVarious functions for parallel coordinates plotting are available\nin both base R and CRAN. As noted, what sets these apart from\ncdparcoord and its “cousin”\nfreqparcoord is\nthat the latter two display only frequently-appearing points. This\nis aimed at avoiding the “black screen problem,” which occurs when\nwe have so many data points that their representations fill the\nscreen, rendering the graph useless.\n\n↩︎\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2017-2-useR2017/",
    "title": "Conference Report: useR!2017",
    "description": "The 'Conference Report: useR!2017' article from the 2017-2 issue.",
    "author": [
      {
        "name": "Tobias Verbeke",
        "url": {}
      }
    ],
    "date": "2017-12-01",
    "categories": [],
    "contents": "\n\n1 Introduction\nAfter a very successful 2016 edition in Stanford (US), the useR\nconference invited the R community to meet from July 4 to July 7 in\nBrussels (Belgium), heart of Europe. The response was extraordinary:\n1175 people (of 54 nationalities) travelled the globe to join for a week\nof intense exchange and discussion. The conference was held in the Wild\nGallery which was – for the occasion – the exclusive territory of R\naficionados with many co-hosted events including DSC 2017, RIOT 2017 and\nan R Foundation meeting.\nAn important theme throughout the conference was to be welcoming and\ninclusive. In this respect 25 diversity scholarships were awarded and\nnewbies were welcomed at a newbies session the evening before the\ntutorial day. Dedicated childcare was organized for the youngest R\nenthusiasts and besides the regular hacking and relaxing space, a\nbreast-feeding area and quiet zone were foreseen.\nThe program consisted of 16 pre-conference tutorials, 6 invited talks,\n147 oral presentations, 70 lightning talks and 70 poster sessions. The\nsocial program included a welcome reception, poster reception and\nconference dinner where a stand-up comedian offered an introduction to\nBelgium and a well known beer sommelier revealed the secrets of Belgian\nbeers to a very receptive audience (914 liters to be precise).\n2 Pre-conference tutorials\nThe pre-conference tutorials were free and open to all attendees.\nOpenML: Connecting R to the Machine Learning Platform OpenML –\nJoaquin Vanschoren, Heidi Seibold and Bernd Bischl\nSports Analytics with R – Stephanie Kovalchik\nEnvironmental Modeling using R – Karline Soetaert and Thomas\nPetzoldt\nIntroduction to parallel computing with R – Hana Sevcikova\nIntroduction to Bayesian inference with JAGS – Martyn Plummer\nR Package Development with R-hub – Gabor Csardi\npurrr – Charlotte Wickham\nSpatial Data in R: New Directions – Edzer Pebesma\nExtending R with C++: Motivation, Introduction and Examples – Dirk\nEddelbuettel\nEfficient R Programming – Colin Gillespie\nIntroduction to Optimal Changepoint Detection Algorithms – Toby\nDylan Hocking and Rebecca Killick\nData Carpentry: Open and Reproducible Research with R: Colin Rundel,\nMine Cetinkaya-Rundel\ndata.table for Beginners – Arun Srinivasan\nDose-response analysis using R – Signe M. Jensen and Christian Ritz\nGeospatial Visualization using R – Bhaskar V. Karambelkar\nIntroduction to Natural Language Processing with R – Taylor Arnold\nand Lauren Tilton\n3 Invited talks\nAs befits an R conference, the invited talks kept statistics and\ncomputing in balance with the following keynote speakers:\nStructural Equation Modeling: Models, Software and Stories – Yves\nRosseel\nTeaching Data Science to new useRs – Mine Cetinkaya-Rundel\nDose-Response Analysis: Considering Dose both as Qualitative Factor\nand Quantitative Covariate, using R – Ludwig Hothorn\nParallel Computation in R: What We Want, and How We (Might) Get It\n– Norm Matloff\nR Tools for the Analysis of Complex Heterogeneous Data – Isabella\nGollini\n20 Years of CRAN – Uwe Ligges\n4 Contributed sessions\nFourty-two sessions were held in six parallel tracks demonstrating the\never rich diversity of R usage with contributions in Bioinformatics,\nBusiness and Management, Clustering, Community Data management, Data\nreproducibility, Education, GIS, Graphics, HPC, Kaleidoscope, Lightning\nTalks (six sessions!), Machine Learning, Medical statistics, Methods,\nMethods in Business, Missing Data, Packages, Programming, Shiny, Social,\nStatistical Modelling, Text Mining and Web.\n5 Conference organizers\nThe quality of the scientific program of the conference was the\nachievement of Ziv Shkedy (chair), Heather Turner (chair), Michela\nBattauz, Przemyslaw Biecek, Roger Bivand, Di Cook, Dirk Eddelbuettel,\nBettina Gruen, Torsten Hothorn, Julie Josse, Helena Kotthaus and Tobias\nVerbeke. The organization was in the hands of Tobias Verbeke (chair),\nZiv Shkedy, Heather Turner and Matthias Verbeke.\n6 Additional information\nConference website\nhttps://user2017.brussels/\nVideo Recordings\nhttps://channel9.msdn.com/Events/useR-international-R-User-conferences/useR-International-R-User-2017-Conference\nAftermovie\nhttps://youtu.be/YWF6nbUTRao\nSponsors\nhttps://user2017.brussels/sponsors\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2017-1-bioc/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2017-1 issue.",
    "author": [
      {
        "name": "Bioconductor Core Team",
        "url": {}
      }
    ],
    "date": "2017-06-01",
    "categories": [],
    "contents": "\n\nThe Bioconductor project provides tools for\nthe analysis and comprehension of high-throughput genomic data.\nBioconductor 3.5 was released on 25 April, 2017. It is compatible with R\n3.4 and consists of 1383 software packages, 316 experiment data\npackages, and 911 up-to-date annotation packages. The release\nannouncement includes\ndescriptions of 88 new packages, and updated NEWS files for many\nadditional packages. Start using Bioconductor by installing the most\nrecent version of R and evaluating the commands\n  source(\"https://bioconductor.org/biocLite.R\")\n  biocLite()\nInstall additional packages and dependencies, e.g.,\nAnnotationHub,\nwith\n  BiocInstaller::biocLite(\"AnnotationHub\")\nDocker and\nAmazon\nimages provides a very effective on-ramp for power users to rapidly\nobtain access to standardized and scalable computing environments. Key\nresources include:\nbioconductor.org to install, learn, use,\nand develop Bioconductor packages.\nA listing of available\nsoftware, linked to pages\ndescribing each package.\nA question-and-answer style user support\nsite and developer-oriented\nmailing list.\nThe F1000Research Bioconductor\nchannel for\npeer-reviewed Bioconductor work flows.\nOur package\nsubmission\nrepository for open technical review of new packages.\nOur annual conference, BioC 2017: Where Software and Biology\nConnect,\nwill be on June 26 (‘developer day’), 27 and 28, in Boston, MA.\n\n\nBioconductor packages used\nAnnotationHub\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2017-1-ch/",
    "title": "Changes in R",
    "description": "The 'Changes in R' article from the 2017-1 issue.",
    "author": [
      {
        "name": "The R Core Team",
        "url": {}
      }
    ],
    "date": "2017-06-01",
    "categories": [],
    "contents": "\n\nCHANGES IN R 3.4.1\n\nINSTALLATION on a UNIX-ALIKE\nThe deprecated support for PCRE versions older than 8.20 has been\nremoved.\n\n\nBUG FIXES\ngetParseData() gave incorrect column information when code\ncontained multi-byte characters.\n(PR#17254)\nAsking for help using expressions like ?stats::cor() did not work.\n(PR#17250)\nreadRDS(url(....)) now works.\nR CMD Sweave again returns status = 0 on successful completion.\nVignettes listed in .Rbuildignore were not being ignored properly.\n(PR#17246)\nfile.mtime() no longer returns NA on Windows when the file or\ndirectory is being used by another process. This affected\ninstalled.packages(), which is now protected against this.\nR CMD INSTALL Windows .zip file obeys –lock and –pkglock\nflags.\n(Windows only) The choose.files() function could return incorrect\nresults when called with multi = FALSE.\n(PR#17270)\naggregate(<data.frame>, drop = FALSE) now also works in case of\nnear-equal numbers in by.\n(PR#16918)\nfourfoldplot() could encounter integer overflow when calculating\nthe odds ratio.\n(PR#17286)\nparse() no longer gives spurious warnings when extracting srcrefs\nfrom a file not encoded in the current locale.\nThis was seen from R CMD check with inst/doc/*.R files, and\ncheck has some additional protection for such files.\nprint.noquote(x) now always returns its argument x (invisibly).\nNon-UTF-8 multibyte character sets were not handled properly in\nsource references.\n(PR#16732)\n\nCHANGES IN R 3.4.0\n\nSIGNIFICANT USER-VISIBLE CHANGES\n(Unix-alike) The default methods for download.file() and url()\nnow choose \"libcurl\" except for file:// URLs. There will be\nsmall changes in the format and wording of messages, including in\nrare cases if an issue is a warning or an error. For example, when\nHTTP re-direction occurs, some messages refer to the final URL\nrather than the specified one.\nThose who use proxies should check that their settings are\ncompatible (see ?download.file: the most commonly used forms work\nfor both \"internal\" and \"libcurl\").\ntable() has been amended to be more internally consistent and\nbecome back compatible to R \\(\\le\\) 2.7.2 again. Consequently,\ntable(1:2, exclude = NULL) no longer contains a zero count for\n<NA>, but useNA = \"always\" continues to do so.\nsummary.default() no longer rounds, but its print method does\nresulting in less extraneous rounding, notably of numbers in the ten\nthousands.\nfactor(x, exclude = L) behaves more rationally when x or L are\ncharacter vectors. Further, exclude = <factor> now behaves as\ndocumented for long.\nArithmetic, logic (&, |) and comparison (aka ‘relational’, e.g.,\n<, ==) operations with arrays now behave consistently, notably\nfor arrays of length zero.\nArithmetic between length-1 arrays and longer non-arrays had\nsilently dropped the array attributes and recycled. This now gives a\nwarning and will signal an error in the future, as it has always for\nlogic and comparison operations in these cases (e.g., compare\nmatrix(1,1) + 2:3 and matrix(1,1) < 2:3).\nThe JIT (‘Just In Time’) byte-code compiler is now enabled by\ndefault at its level 3. This means functions will be compiled on\nfirst or second use and top-level loops will be compiled and then\nrun. (Thanks to Tomas Kalibera for extensive work to make this\npossible.)\nFor now, the compiler will not compile code containing explicit\ncalls to browser(): this is to support single stepping from the\nbrowser() call.\nJIT compilation can be disabled for the rest of the session using\ncompiler::enableJIT(0) or by setting environment variable\nR_ENABLE_JIT to 0.\nxtabs() works more consistently with NAs, also in its result no\nlonger setting them to 0. Further, a new logical option addNA\nallows to count NAs where appropriate. Additionally, for the case\nsparse = TRUE, the result’s dimnames are identical to the\ndefault case’s.\nMatrix products now consistently bypass BLAS when the inputs have\nNaN/Inf values. Performance of the check of inputs has been\nimproved. Performance when BLAS is used is improved for\nmatrix/vector and vector/matrix multiplication (DGEMV is now used\ninstead of DGEMM).\nOne can now choose from alternative matrix product implementations\nvia options(matprod = ). The \"internal\" implementation is not\noptimized for speed but consistent in precision with other\nsummations in R (using long double accumulators where available).\n\"blas\" calls BLAS directly for best speed, but usually with\nundefined behavior for inputs with NaN/Inf.\n\n\nNEW FEATURES\nUser errors such as integrate(f, 0:1, 2) are now caught.\nAdd signature argument to debug(), debugonce(), undebug()\nand isdebugged() for more conveniently debugging S3 and S4\nmethods. (Based on a patch by Gabe Becker.)\nAdd utils::debugcall() and utils::undebugcall() for debugging\nthe function that would be called by evaluating the given\nexpression. When the call is to an S4 generic or standard S3\ngeneric, debugcall() debugs the method that would be dispatched. A\nnumber of internal utilities were added to support this, most\nnotably utils::isS3stdGeneric(). (Based on a patch by Gabe\nBecker.)\nAdd utils::strcapture(). Given a character vector and a regular\nexpression containing capture expressions, strcapture() will\nextract the captured tokens into a tabular data structure, typically\na data.frame.\nstr() and strOptions() get a new option drop.deparse.attr with\nimproved but changed default behaviour for expressions. For\nexpression objects x, str(x) now may remove extraneous white\nspace and truncate long lines.\nstr(<looooooooong_string>) is no longer very slow; inspired by\nMikko Korpela’s proposal in\nPR#16527.\nstr(x)’s default method is more “accurate” and hence somewhat more\ngenerous in displaying character vectors; this will occasionally\nchange R outputs (and need changes to some *.Rout(.save) files).\nFor a classed integer vector such as x <- xtabs(~ c(1,9,9,9)),\nstr(x) now shows both the class and \"int\", instead of only the\nlatter.\nisSymmetric(m) is much faster for large asymmetric matrices m\nvia pre-tests and a new option tol1 (with which strict back\ncompatibility is possible but not the default).\nThe result of eigen() now is of class \"eigen\" in the default\ncase when eigenvectors are computed.\nZero-length date and date-time objects (of classes \"POSIX[cl]?t\")\nnow print() “recognizably”.\nxy.coords() and xyz.coords() get a new setLab option.\nThe method argument of sort.list(), order() and sort.int()\ngains an \"auto\" option (the default) which should behave the same\nas before when method was not supplied.\nstopifnot(E, ..) now reports differences when E is a call to\nall.equal() and that is not true.\nboxplot(<formula>, *) gain optional arguments drop, sep, and\nlex.order to pass to split.default() which itself gains an\nargument lex.order to pass to interaction() for more\nflexibility.\nThe plot() method for ppr() has enhanced default labels (xmin\nand main).\nsample.int() gains an explicit useHash option (with a back\ncompatible default).\nidentical() gains an ignore.srcref option which drops \"srcref\"\nand similar attributes when true (as by default).\ndiag(x, nrow = n) now preserves typeof(x), also for logical,\ninteger and raw x (and as previously for complex and numeric).\nsmooth.spline() now allows direct specification of lambda, gets\na hatvalues() method and keeps tol in the result, and optionally\nparts of the internal matrix computations.\naddNA() is faster now, e.g. when applied twice. (Part of\nPR#16895.)\nNew option rstandard(<lm>, type = \"predicted\") provides the\n“PRESS”–related leave-one-out cross-validation errors for linear\nmodels.\nAfter seven years of deprecation, duplicated factor levels now\nproduce a warning when printed and an error in levels<- instead of\na warning.\nInvalid factors, e.g., with duplicated levels (invalid but\nconstructable) now give a warning when printed, via new function\n.valid.factor().\nsessionInfo() has been updated for Apple’s change in OS naming as\nfrom ‘10.12’ (‘macOS Sierra’ vs ‘OS X El Capitan’).\nIts toLatex() method now includes the running component.\noptions(interrupt=) can be used to specify a default action for\nuser interrupts. For now, if this option is not set and the error\noption is set, then an unhandled user interrupt invokes the error\noption. (This may be dropped in the future as interrupt conditions\nare not error conditions.)\nIn most cases user interrupt handlers will be called with a\n\"resume\" restart available. Handlers can invoke this restart to\nresume computation. At the browser prompt the r command will\ninvoke a \"resume\" restart if one is available. Some read\noperations cannot be resumed properly when interrupted and do not\nprovide a \"resume\" restart.\nRadix sort is now chosen by method = \"auto\" for sort.int() for\ndouble vectors (and hence used for sort() for unclassed double\nvectors), excluding ‘long’ vectors.\nsort.int(method = \"radix\") no longer rounds double vectors.\nThe default and data.frame methods for stack() preserve the\nnames of empty elements in the levels of the ind column of the\nreturn value. Set the new drop argument to TRUE for the previous\nbehavior.\nSpeedup in simplify2array() and hence sapply() and mapply()\n(for the case of names and common length > 1), thanks to Suharto\nAnggono’s\nPR#17118.\ntable(x, exclude = NULL) now sets useNA = \"ifany\" (instead of\n\"always\"). Together with the bug fixes for this case, this\nrecovers more consistent behaviour compatible to older versions\nof R. As a consequence, summary() for a logical vector no longer\nreports (zero) counts for NA when there are no NAs.\ndump.frames() gets a new option include.GlobalEnv which allows\nto also dump the global environment, thanks to Andreas Kersting’s\nproposal in\nPR#17116.\nsystem.time() now uses message() instead of cat() when\nterminated early, such that suppressMessages() has an effect;\nsuggested by Ben Bolker.\ncitation() supports inst/CITATION files from package source\ntrees, with lib.loc pointing to the directory containing the\npackage.\ntry() gains a new argument outFile with a default that can be\nmodified via options(try.outFile = .), useful notably for\nSweave.\nThe unexported low-level functions in package parallel for passing\nserialized R objects to and from forked children now support long\nvectors on 64-bit platforms. This removes some limits on\nhigher-level functions such as mclapply() (but returning gigabyte\nresults from forked processes via serialization should be avoided\nif at all possible).\nConnections now print() without error even if invalid, e.g. after\nhaving been destroyed.\napropos() and find(simple.words = FALSE) no longer match object\nnames starting with . which are known to be internal objects (such\nas .__S3MethodsTable__.).\nConvenience function hasName() has been added; it is intended to\nreplace the common idiom !is.null(x$name) without the usually\nunintended partial name matching.\nstrcapture() no longer fixes column names nor coerces strings to\nfactors (suggested by Bill Dunlap).\nstrcapture() returns NA for non-matching values in x\n(suggested by Bill Dunlap).\nsource() gets new optional arguments, notably exprs; this is\nmade use of in the new utility function withAutoprint().\nsys.source() gets a new toplevel.env argument. This argument is\nuseful for frameworks running package tests; contributed by Tomas\nKalibera.\nSys.setFileTime() and file.copy(copy.date = TRUE) will set\ntimestamps with fractions of seconds on platforms/filesystems which\nsupport this.\n(Windows only.) file.info() now returns file timestamps including\nfractions of seconds; it has done so on other platforms since R\n2.14.0. (NB: some filesystems do not record modification and access\ntimestamps to sub-second resolution.)\nThe license check enabled by options(checkPackageLicense = TRUE)\nis now done when the package’s namespace is first loaded.\nppr() and supsmu() get an optional trace argument, and\nppr(.., sm.method = ..spline) is no longer limited to sample size\n\\(n \\le 2500\\).\nThe POSIXct method for print() gets optional tz and usetz\narguments, thanks to a report from Jennifer S. Lyon.\nNew function check_packages_in_dir_details() in package tools\nfor analyzing package-check log files to obtain check details.\nPackage tools now exports function CRAN_package_db() for\nobtaining information about current packages in the CRAN package\nrepository, and several functions for obtaining the check status of\nthese packages.\nThe (default) Stangle driver Rtangle allows annotate to be a\nfunction and gets a new drop.evalFALSE option.\nThe default method for quantile(x, prob) should now be monotone in\nprob, even in border cases, see\nPR#16672.\nbug.report() now tries to extract an email address from a\nBugReports field, and if there is none, from a Contacts field.\nThe format() and print() methods for object.size() results get\nnew options standard and digits; notably, standard = \"IEC\" and\nstandard = \"SI\" allow more standard (but less common)\nabbreviations than the default ones, e.g. for kilobytes. (From\ncontributions by Henrik Bengtsson.)\nIf a reference class has a validity method, validObject will be\ncalled automatically from the default initialization method for\nreference classes.\ntapply() gets new option default = NA allowing to change the\npreviously hardcoded value.\nread.dcf() now consistently interprets any ‘whitespace’ to be\nstripped to include newlines.\nThe maximum number of DLLs that can be loaded into R e.g. via\ndyn.load() can now be increased by setting the environment\nvariable R_MAX_NUM_DLLS before starting R.\nAssigning to an element of a vector beyond the current length now\nover-allocates by a small fraction. The new vector is marked\ninternally as growable, and the true length of the new vector is\nstored in the truelength field. This makes building up a vector\nresult by assigning to the next element beyond the current length\nmore efficient, though pre-allocating is still preferred. The\nimplementation is subject to change and not intended to be used in\npackages at this time.\nLoading the parallel package namespace no longer sets or changes\nthe .Random.seed, even if R_PARALLEL_PORT is unset.\nNB: This can break reproducibility of output, and did for a CRAN\npackage.\nMethods \"wget\" and \"curl\" for download.file() now give an R\nerror rather than a non-zero return value when the external command\nhas a non-zero status.\nEncoding name \"utf8\" is mapped to \"UTF-8\". Many implementations\nof iconv accept \"utf8\", but not GNU libiconv (including the\nlate 2016 version 1.15).\nsessionInfo() shows the full paths to the library or executable\nfiles providing the BLAS/LAPACK implementations currently in use\n(not available on Windows).\nThe binning algorithm used by bandwidth selectors bw.ucv(),\nbw.bcv() and bw.SJ() switches to a version linear in the input\nsize n for n > nb/2. (The calculations are the same, but for\nlarger n/nb it is worth doing the binning in advance.)\nThere is a new option PCRE_study which controls when\ngrep(perl = TRUE) and friends ‘study’ the compiled pattern.\nPreviously this was done for 11 or more input strings: it now\ndefaults to 10 or more (but most examples need many more for the\ndifference from studying to be noticeable).\ngrep(perl = TRUE) and friends can now make use of PCRE’s\nJust-In-Time mechanism, for PCRE \\(\\ge\\) 8.20 on platforms where JIT\nis supported. It is used by default whenever the pattern is\nstudied (see the previous item). (Based on a patch from Mikko\nKorpela.)\nThis is controlled by a new option PCRE_use_JIT.\nNote that in general this makes little difference to the speed, and\nmay take a little longer: its benefits are most evident on strings\nof thousands of characters. As a side effect it reduces the chances\nof C stack overflow in the PCRE library on very long strings\n(millions of characters, but see next item).\nWarning: segfaults were seen using PCRE with JIT enabled on 64-bit\nSparc builds.\nThere is a new option PCRE_limit_recursion for grep(perl = TRUE)\nand friends to set a recursion limit taking into account R’s\nestimate of the remaining C stack space (or 10000 if that is not\navailable). This reduces the chance of C stack overflow, but because\nit is conservative may report a non-match (with a warning) in\nexamples that matched before. By default it is enabled if any input\nstring has 1000 or more bytes.\n(PR#16757)\ngetGraphicsEvent() now works on X11(type = \"cairo\") devices.\nThanks to Frederick Eaton (for reviving an earlier patch).\nThere is a new argument onIdle for getGraphicsEvent(), which\nallows an R function to be run whenever there are no pending\ngraphics events. This is currently only supported on X11 devices.\nThanks to Frederick Eaton.\nThe deriv() and similar functions now can compute derivatives of\nlog1p(), sinpi() and similar one-argument functions, thanks to a\ncontribution by Jerry Lewis.\nmedian() gains a formal ... argument, so methods with extra\narguments can be provided.\nstrwrap() reduces indent if it is more than half width rather\nthan giving an error. (Suggested by Bill Dunlap.)\nWhen the condition code in if(.) or while(.) is not of length\none, an error instead of a warning may be triggered by setting an\nenvironment variable, see the help page.\nFormatting and printing of bibliography entries (bibentry) is more\nflexible and better documented. Apart from setting\noptions(citation.bibtex.max = 99) you can also use\nprint(<citation>, bibtex=TRUE) (or format(..)) to get the BibTeX\nentries in the case of more than one entry. This also affects\ncitation(). Contributions to enable style = \"html+bibtex\" are\nwelcome.\n\n\nC-LEVEL FACILITIES\nEntry points R_MakeExternalPtrFn and R_ExternalPtrFn are now\ndeclared in header Rinternals.h to facilitate creating and\nretrieving an R external pointer from a C function pointer without\nISO C warnings about the conversion of function pointers.\nThere was an exception for the native Solaris C++ compiler to the\ndropping (in R 3.3.0) of legacy C++ headers from headers such as\nR.h and Rmath.h — this has now been removed. That compiler has\nstrict C++98 compliance hence does not include extensions in its\n(non-legacy) C++ headers: some packages will need to request C++11\nor replace non-C++98 calls such as lgamma: see §1.6.4 of ‘Writing\nR Extensions’.\nBecause it is needed by about 70 CRAN packages, headers R.h and\nRmath.h still declare\nstd;\nwhen included on Solaris.\nWhen included from C++, the R headers now use forms such as\nstd::FILE directly rather than including the line\nstd::FILE;\nC++ code including these headers might be relying on the latter.\nHeaders R_ext/BLAS.h and R_ext/Lapack.h have many improved\ndeclarations including const for double-precision complex\nroutines. Inter alia this avoids warnings when passing ‘string\nliteral’ arguments from C++11 code.\nHeaders for Unix-only facilities R_ext/GetX11Image.h,\nR_ext/QuartzDevice.h and R_ext/eventloop.h are no longer\ninstalled on Windows.\nNo-longer-installed headers GraphicsBase.h, RGraphics.h,\nRmodules/RX11.h and Rmodules/Rlapack.h which had a LGPL license\nno longer do so.\nHAVE_UINTPTR_T is now defined where appropriate by Rconfig.h so\nthat it can be included before Rinterface.h when CSTACK_DEFNS is\ndefined and a C compiler (not C++) is in use. Rinterface.h now\nincludes C header stdint.h or C++11 header cstdint where needed.\nPackage tools has a new function\npackage_native_routine_registration_skeleton() to assist adding\nnative-symbol registration to a package. See its help and §5.4.1 of\n‘Writing R Extensions’ for how to use it. (At the time it was added\nit successfully automated adding registration to over 90% of CRAN\npackages which lacked it. Many of the failures were newly-detected\nbugs in the packages, e.g. 50 packages called entry points with\nvarying numbers of arguments and 65 packages called entry points not\nin the package.)\n\n\nINSTALLATION on a UNIX-ALIKE\nreadline headers (and not just the library) are required unless\nconfiguring with –with-readline=no.\nconfigure now adds a compiler switch for C++11 code, even if the\ncompiler supports C++11 by default. (This ensures that g++ 6.x\nuses C++11 mode and not its default mode of C++14 with ‘GNU\nextensions’.)\nThe tests for C++11 compliance are now much more comprehensive. For\ngcc < 4.8, the tests from R 3.3.0 are used in order to maintain the\nsame behaviour on Linux distributions with long-term support.\nAn alternative compiler for C++11 is now specified with CXX11, not\nCXX1X. Likewise C++11 flags are specified with CXX11FLAGS and\nthe standard (e.g., -std=gnu++11 is specified with CXX11STD.\nconfigure now tests for a C++14-compliant compiler by testing some\nbasic features. This by default tries flags for the compiler\nspecified by CXX11, but an alternative compiler, options and\nstandard can be specified by variables CXX14, CXX14FLAGS and\nCXX14STD (e.g., -std=gnu++14).\nThere is a new macro CXXSTD to help specify the standard for C++\ncode, e.g. -std=c++98. This makes it easier to work with compilers\nwhich default to a later standard: for example, with\nCXX=g++6 CXXSTD=-std=c++98 configure will select commands for\ng++ 6.x which conform to C++11 and C++14 where specified but\notherwise use C++98.\nSupport for the defunct IRIX and OSF/1 OSes and Alpha CPU has been\nremoved.\nconfigure checks that the compiler specified by $CXX $CXXFLAGS\nis able to compile C++ code.\nconfigure checks for the required header sys/select.h (or\nsys/time.h on legacy systems) and system call select and aborts\nif they are not found.\nIf available, the POSIX 2008 system call utimensat will be used by\nSys.setFileTime() and file.copy(copy.date = TRUE). This may\nresult in slightly more accurate file times. (It is available on\nLinux and FreeBSD but not macOS.)\nThe minimum version requirement for libcurl has been reduced to\n7.22.0, although at least 7.28.0 is preferred and earlier versions\nare little tested. (This is to support Debian 7 ‘Wheezy’ LTS and\nUbuntu ‘Precise’ 12.04 LTS, although the latter is close to\nend-of-life.)\nconfigure tests for a C++17-compliant compiler. The tests are\nexperimental and subject to change in the future.\n\n\nINCLUDED SOFTWARE\n(Windows only) Tcl/Tk version 8.6.4 is now included in the binary\nbuilds. The tcltk*.chm help file is no longer included; please\nconsult the online help at http://www.tcl.tk/man/ instead.\nThe version of LAPACK included in the sources has been updated to\n3.7.0: no new routines have been added to R.\n\n\nPACKAGE INSTALLATION\nThere is support for compiling C++14 or C++17 code in packages on\nsuitable platforms: see ‘Writing R Extensions’ for how to request\nthis.\nThe order of flags when LinkingTo other packages has been changed\nso their include directories come earlier, before those specified in\nCPPFLAGS. This will only have an effect if non-system include\ndirectories are included with -I flags in CPPFLAGS (and so not\nthe default -I/usr/local/include which is treated as a system\ninclude directory on most platforms).\nPackages which register native routines for .C or .Fortran need\nto be re-installed for this version (unless installed with R-devel\nSVN revision r72375 or later).\nMake variables with names containing CXX1X are deprecated in\nfavour of those using CXX11, but for the time being are still made\navailable via file etc/Makeconf. Packages using them should be\nconverted to the new forms and made dependent on R (>= 3.4.0).\n\n\nUTILITIES\nRunning R CMD check –as-cran with _R_CHECK_CRAN_INCOMING_REMOTE_\nfalse now skips tests that require remote access. The remaining\n(local) tests typically run quickly compared to the remote tests.\nR CMD build will now give priority to vignettes produced from\nfiles in the vignettes directory over those in the inst/doc\ndirectory, with a warning that the latter are being ignored.\nR CMD config gains a –all option for printing names and values\nof all basic configure variables.\nIt now knows about all the variables used for the C++98, C++11 and\nC++14 standards.\nR CMD check now checks that output files in inst/doc are newer\nthan the source files in vignettes.\nFor consistency with other package subdirectories, files named *.r\nin the tests directory are now recognized as tests by\nR CMD check. (Wish of\nPR#17143.)\nR CMD build and R CMD check now use the union of R_LIBS and\n.libPaths(). They may not be equivalent, e.g., when the latter is\ndetermined by R_PROFILE.\nR CMD build now preserves dates when it copies files in preparing\nthe tarball. (Previously on Windows it changed the dates on all\nfiles; on Unix, it changed some dates when installing vignettes.)\nThe new option R CMD check –no-stop-on-test-error allows running\nthe remaining tests (under tests/) even if one gave an error.\nCheck customization via environment variables to detect side\neffects of .Call() and .External() calls which alter their\narguments is described in §8 of the ‘R Internals’ manual.\nR CMD check now checks any BugReports field to be non-empty and\na suitable single URL.\nR CMD check –as-cran now NOTEs if the package does not register\nits native routines or does not declare its intentions on (native)\nsymbol search. (This will become a WARNING in due course.)\n\n\nDEPRECATED AND DEFUNCT\n(Windows only) Function setInternet2() is defunct.\nInstallation support for readline emulations based on editline\n(aka libedit) is deprecated.\nUse of the C/C++ macro NO_C_HEADERS is defunct and silently\nignored.\nunix.time(), a traditional synonym for system.time(), has been\ndeprecated.\nstructure(NULL, ..) is now deprecated as you cannot set attributes\non NULL.\nHeader Rconfig.h no longer defines SUPPORT_OPENMP; instead use\n_OPENMP (as documented for a long time).\n(C-level Native routine registration.) The deprecated styles\nmember of the R_CMethodDef and R_FortranMethodDef structures has\nbeen removed. Packages using these will need to be re-installed for\nR 3.4.0.\nThe deprecated support for PCRE versions older than 8.20 will be\nremoved in R 3.4.1. (Versions 8.20–8.31 will still be accepted but\nremain deprecated.)\n\n\nBUG FIXES\nGetting or setting body() or formals() on non-functions for now\nsignals a warning and may become an error for setting.\nmatch(x, t), duplicated(x) and unique(x) work as documented\nfor complex numbers with NAs or NaNs, where all those containing\nNA do match, whereas in the case of NaN’s both real and\nimaginary parts must match, compatibly with how print() and\nformat() work for complex numbers.\ndeparse(<complex>, options = \"digits17\") prints more nicely now,\nmostly thanks to a suggestion by Richie Cotton.\nRotated symbols in plotmath expressions are now positioned correctly\non x11(type = \"Xlib\").\n(PR#16948)\nas<-() avoids an infinite loop when a virtual class is interposed\nbetween a subclass and an actual superclass.\nFix level propagation in unlist() when the list contains\nzero-length lists or factors.\nFix S3 dispatch on S4 objects when the methods package is not\nattached.\nInternal S4 dispatch sets .Generic in the method frame for\nconsistency with standardGeneric().\n(PR#16929)\nFix order(x, decreasing = TRUE) when x is an integer vector\ncontaining MAX_INT. Ported from a fix Matt Dowle made to\ndata.table.\nFix caching by callNextMethod(), resolves\nPR#16973\nand\nPR#16974.\ngrouping() puts NAs last, to be consistent with the default\nbehavior of order().\nPoint mass limit cases: qpois(-2, 0) now gives NaN with a\nwarning and qgeom(1, 1) is 0.\n(PR#16972)\ntable() no longer drops an \"NaN\" factor level, and better obeys\nexclude = <chr>, thanks to Suharto Anggono’s patch for\nPR#16936.\nAlso, in the case of exclude = NULL and NAs, these are tabulated\ncorrectly (again).\nFurther, table(1:2, exclude = 1, useNA = \"ifany\") no longer\nerroneously reports <NA> counts.\nAdditionally, all cases of empty exclude are equivalent, and\nuseNA is not overwritten when specified (as it was by\nexclude = NULL).\nwilcox.test(x, conf.int=TRUE) no longer errors out in cases where\nthe confidence interval is not available, such as for x = 0:2.\ndroplevels(f) now keeps <NA> levels when present.\nIn integer arithmetic, NULL is now treated as integer(0) whereas\nit was previously treated as double(0).\nThe radix sort considers NA_real_ and NaN to be equivalent in\nrank (like the other sort algorithms).\nWhen index.return=TRUE is passed to sort.int(), the radix sort\ntreats NAs like sort.list() does (like the other sort\nalgorithms).\nWhen in tabulate(bin, nbin) length(bin) is larger than the\nmaximal integer, the result is now of type double and hence no\nlonger silently overflows to wrong values.\n(PR#17140)\nas.character.factor() respects S4 inheritance when checking the\ntype of its argument.\n(PR#17141)\nThe factor method for print() no longer sets the class of the\nfactor to NULL, which would violate a basic constraint of an S4\nobject.\nformatC(x, flag = f) allows two new flags, and signals an error\nfor invalid flags also in the case of character formatting.\nReading from file(\"stdin\") now also closes the connection and\nhence no longer leaks memory when reading from a full pipe, thanks\nto Gábor Csárdi, see thread starting at\nhttps://stat.ethz.ch/pipermail/r-devel/2016-November/073360.html.\nFailure to create file in tempdir() for compressed pdf()\ngraphics device no longer errors (then later segfaults). There is\nnow a warning instead of error and compression is turned off for the\ndevice. Thanks to Alec Wysoker\n(PR#17191).\nAsking for methods() on \"|\" returns only S3 methods. See\nhttps://stat.ethz.ch/pipermail/r-devel/2016-December/073476.html.\ndev.capture() using Quartz Cocoa device (macOS) returned invalid\ncomponents if the back-end chose to use ARGB instead of RGBA image\nformat. (Reported by Noam Ross.)\nseq(\"2\", \"5\") now works too, equivalently to \"2\":\"5\" and\nseq.int().\nseq.int(to = 1, by = 1) is now correct, other cases are integer\n(instead of double) when seq() is integer too, and the\n\"non-finite\" error messages are consistent between seq.default()\nand seq.int(), no longer mentioning NaN etc.\nrep(x, times) and rep.int(x, times) now work when times is\nlarger than the largest value representable in an integer vector.\n(PR#16932)\ndownload.file(method = \"libcurl\") does not check for URL existence\nbefore attempting downloads; this is more robust to servers that do\nnot support HEAD or range-based retrieval, but may create empty or\nincomplete files for aborted download requests.\nBandwidth selectors bw.ucv(), bw.bcv() and bw.SJ() now avoid\ninteger overflow for large sample sizes.\nstr() no longer shows \"list output truncated\", in cases that\nlist was not shown at all. Thanks to Neal Fultz\n(PR#17219)\nFix for cairo_pdf() (and svg() and cairo_ps()) when replaying\na saved display list that contains a mix of grid and graphics\noutput. (Report by Yihui Xie.)\nThe str() and as.hclust() methods for \"dendrogram\" now also\nwork for deeply nested dendrograms thanks to non-recursive\nimplementations by Bradley Broom.\nsample() now uses two uniforms for added precision when the\nuniform generator is Knuth-TAOCP, Knuth-TAOCP-2002, or a\nuser-defined generator and the population size is \\(2^{25}\\) or\ngreater.\nIf a vignette in the vignettes directory is listed in\n.Rbuildignore, R CMD build would not include it in the tarball,\nbut would include it in the vignette database, leading to a check\nwarning.\n(PR#17246)\ntools::latexToUtf8() infinite looped on certain inputs.\n(PR#17138)\nterms.formula() ignored argument names when determining whether\ntwo terms were identical.\n(PR#17235)\ncallNextMethod() was broken when called from a method that\naugments the formal arguments of a primitive generic.\nCoercion of an S4 object to a vector during sub-assignment into a\nvector failed to dispatch through the as.vector() generic (often\nleading to a segfault).\nFix problems in command completion: Crash\n(PR#17222)\nand junk display in Windows, handling special characters in\nfilenames on all systems.\n\nCHANGES IN R 3.3.3\n\nNEW FEATURES\nChanges when redirection of a http:// URL to a https:// URL is\nencountered:\nThe internal methods of download.file() and url() now report\nthat they cannot follow this (rather than failing silently).\n(Unix-alike) download.file(method = \"auto\") (the default)\nre-tries with method = \"libcurl\".\n(Unix-alike) url(method = \"default\") with an explicit open\nargument re-tries with method = \"libcurl\". This covers many of\nthe usages, e.g. readLines() with a URL argument.\n\n\n\nINSTALLATION on a UNIX-ALIKE\nThe configure check for the zlib version is now robust to\nversions longer than 5 characters, including 1.2.11.\n\n\nUTILITIES\nEnvironmental variable _R_CHECK_TESTS_NLINES_ controls how\nR CMD check reports failing tests (see §8 of the ‘R Internals’\nmanual).\n\n\nDEPRECATED AND DEFUNCT\n(C-level Native routine registration.) The undocumented styles\nfield of the components of R_CMethodDef and R_FortranMethodDef\nis deprecated.\n\n\nBUG FIXES\nvapply(x, *) now works with long vectors x.\n(PR#17174)\nisS3method(\"is.na.data.frame\") and similar are correct now.\n(PR#17171)\ngrepRaw(<long>, <short>, fixed = TRUE) now works, thanks to a\npatch by Mikko Korpela.\n(PR#17132)\nPackage installation into a library where the package exists via\nsymbolic link now should work wherever Sys.readlink() works,\nresolving\nPR#16725.\n\"Cincinnati\" was missing an \"n\" in the precip dataset.\nFix buffer overflow vulnerability in pdf() when loading an\nencoding file. Reported by Talos (TALOS-2016-0227).\ngetDLLRegisteredRoutines() now produces its warning correctly when\nmultiple DLLs match, thanks to Matt Dowle’s\nPR#17184.\nSys.timezone() now returns non-NA also on platforms such as\nUbuntu 14.04.5 LTS, thanks to Mikko Korpela’s\nPR#17186.\nformat(x) for an illegal \"POSIXlt\" object x no longer\nsegfaults.\nmethods(f) now also works for f \"(\" or \"{\".\n(Windows only) dir.create() did not check the length of the path\nto create, and so could overflow a buffer and crash R.\n(PR#17206)\nOn some systems, very small hexadecimal numbers in hex notation\nwould underflow to zero.\n(PR#17199)\npmin() and pmax() now work again for ordered factors and\n0-length S3 classed objects, thanks to Suharto Anggono’s\nPR#17195\nand\nPR#17200.\nbug.report() did not do any validity checking on a package’s\nBugReports field. It now ignores an empty field, removes leading\nwhitespace and only attempts to open http:// and https:// URLs,\nfalling back to emailing the maintainer.\nBandwidth selectors bw.ucv() and bw.SJ() gave incorrect answers\nor incorrectly reported an error (because of integer overflow) for\ninputs longer than 46341. Similarly for bw.bcv() at length 5793.\nAnother possible integer overflow is checked and may result in an\nerror report (rather than an incorrect result) for much longer\ninputs (millions for a smooth distribution).\nfindMethod() failed if the active signature had expanded beyond\nwhat a particular package used. (Example with packages\nXR and\nXRJulia on CRAN.)\nqbeta() underflowed too early in some very asymmetric cases.\n(PR#17178)\nR CMD Rd2pdf had problems with packages with non-ASCII titles in\n.Rd files (usually the titles were omitted).\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2017-1-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2017-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2017-06-01",
    "categories": [],
    "contents": "\n\nIn the past 4 months, 794 new packages were added to the CRAN package\nrepository. 16 packages were unarchived, 98 archived and 1 removed. The\nfollowing shows the growth of the number of active packages in the CRAN\npackage repository:\n\nOn 2017-05-31, the number of active packages was around 10727.\nChanges in the CRAN checks\nIn addition to the results for the regular check runs and the valgrind,\nASAN and UBSAN tests of memory access errors provided by Brian Ripley,\nthe package check pages now also show additional issues found by tests\nwithout long double (also provided by Brian Ripley) and checks of native\ncode (C/C++) based on static code analysis, currently reporting\npotential errors in the use of PROTECT (provided by Tomáš Kalibera).\nChanges in the CRAN submission pipeline\nIn the light of the many submissions of new and updated packages\nreceived every day, CRAN is in transition to a more and more automated\nsubmission system. Package maintainers may experience that their\npackages are auto-accepted in case a well established package without\nother packages depending on it passes the checks without problems. Some\npackages will undergo a manual inspection as before, but it may also\nhappen a package is auto-rejected in case problems occur. In case you\nstrongly believe the auto-rejection is a false positive, the procedure\nof contacting the CRAN team is explained in the rejection message.\nChanges in the CRAN Repository Policy\nThe following items were added to the\nPolicy:\nCRAN versions of packages should work with the current CRAN and\nBioconductor releases of dependent packages and not anticipate nor\nrecommend development versions of such packages on other\nrepositories.\nDownloads of additional software or data as part of package\ninstallation or startup should only use secure download mechanisms\n(e.g., https or ftps).\nCRAN mirror security\nCurrently, there are 97 official CRAN mirrors, 51 of which provide both\nsecure downloads via https and use secure mirroring from the CRAN\nmaster (via rsync through ssh tunnels). Since the R 3.4.0 release,\nchooseCRANmirror() offers these mirrors in preference to the others\nwhich are not fully secured (yet).\nCRAN tools\nSince R 3.4.0, package tools exports function CRAN_package_db() for\nobtaining information about current packages in the CRAN package\nrepository, and several functions for obtaining the check status of\nthese packages. See ?tools::CRAN_package_db for more information.\nHyperlinks in package DESCRIPTION files on CRAN\nThe CRAN package web page shows important information about the package\nand gives the package’s Description. Package maintainers are now\nencouraged to insert web links and links to relevant publications they\nwant to cite in order to explain the package’s content by using the\nfollowing formats (all enclosed in <...>) that will cause automatical\ninsertions of the corresponding links:\nClassical web hyperlinks\n\nshould be given as the URL enclosed in <...>, e.g., write\n<https://www.R-project.org>.\n\nDigital Object Identifier System (DOI)\n\nentries to link to a publication should be given in the form\n<DOI:10.xxxx...>.\n\narXiv.org\n\ne-prints without a DOI (yet) should be referred to using their arXiv\nidentifier enclosed in <...>, e.g., <arXiv:1501.00001> or\n<arXiv:0706.0001v2>.\n\nNew CRAN task views\nFunctionalData\n\nTopic: Functional Data Analysis. Maintainer: Fabian Scheipl.\nPackages: FDboost\\(^*\\), Funclustering, GPFDA, MFPCA,\nRFgroove, classiFunc, dbstats, fda\\(^*\\), fda.usc\\(^*\\),\nfdaPDE, fdakma, fdapace\\(^*\\), fdasrvf\\(^*\\), fdatest,\nfdcov, fds, flars, fpca, freqdom, ftsa\\(^*\\), funData,\nfunFEM, funHDDC, funcy\\(^*\\), geofd, growfunctions,\npcdpca, rainbow, refund\\(^*\\), refund.shiny, refund.wave,\nroahd, sparseFLMM, switchnpreg, warpMix.\n\n(* = core package)\nNew packages in CRAN task views\nBayesian\n\nBayesVarSel, NetworkChange, bridgesampling, deBInfer,\ngRain, revdbayes.\n\nCluster\n\nidendr0, prcr.\n\nDistributions\n\nRenext, kernelboot, revdbayes.\n\nEconometrics\n\nREndo, margins, pco, rdlocrand.\n\nExtremeValue\n\nRenext, revdbayes.\n\nFinance\n\nBCC1997, BLModel, PortfolioOptim, RcppQuantuccia,\nSim.DiffProc, rpatrec, rpgm.\n\nMachineLearning\n\nLTRCtrees, MXM, RLT, RcppDL, darch, deepnet,\ngradDescent, opusminer, wsrf, xgboost.\n\nMetaAnalysis\n\nCPBayes, metafuse, metavcov, metaviz, surrosurv.\n\nOfficialStatistics\n\nhaven, micEconIndex, missForest.\n\nPharmacokinetics\n\nNonCompart, PKNCA, PKgraph, PKreport, cpk, dfpk,\nmrgsolve, ncappc, ncar, nmw, pkr, scaRabee.\n\nPhylogenetics\n\nidendr0, nLTT, phylocanvas.\n\nPsychometrics\n\nAnalyzeFMRI, BTLLasso, ThreeWay, eegkit, ica, multiway,\nmunfold.\n\nSpatial\n\nFRK, sperrorest, spind, spmoran, starma.\n\nTimeSeries\n\ndataseries, mafs, prophet, robustarima.\n\nWebTechnologies\n\nRMixpanel.\n\ngR\n\nDiagrammeR.\n\n(* = core package)\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2017-1-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2017-1 issue.",
    "author": [
      {
        "name": "Roger Bivand",
        "url": {}
      }
    ],
    "date": "2017-06-01",
    "categories": [],
    "contents": "\n\nThis new issue, Volume 9, Issue 1, of the R Journal contains 33\ncontributed research articles, like the second issue of 2016. Most of\nthe articles present R packages, and cover a very wide range of uses of\nR. Our journal continues to be critically dependent on its readers,\nauthors, reviewers and editors. Annual submission numbers have grown\nmarkedly, but the rate of growth is less than that of the number of CRAN\npackages. Table 1 shows the outcomes of submitted\ncontributed articles by year of submission. The proportion of\nsubmissions reaching publication has been roughly half since 2012.\n\nTable 1: Submission outcomes 2009–2016, by year of submission.\n\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\nPublished\n26\n26\n26\n22\n31\n36\n51\n58\nRejected\n11\n14\n11\n24\n29\n32\n53\n64\nUnder review\n0\n0\n0\n0\n0\n0\n0\n19\nTotal\n37\n40\n37\n46\n60\n68\n104\n141\n\nIn order to try to restore some balance to the inflow of submissions,\nthe kinds of articled solicited were clarified in January 2017. Articles\nintroducing CRAN or Bioconductor packages — the most common kind of\nsubmission — should now provide broader context. We would like to\nencourage the submission of reviews and proposals, comparisons and the\nbenchmarking of alternative implementations, and presentations of\napplications demonstrating how new or existing techniques can be applied\nin an area of current interest using R.\n\nTable 2: Published contributed articles 2009–2016, by year of\npublication.\n\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\nPage count\n109\n123\n123\n136\n362\n358\n479\n895\nArticle count\n18\n18\n20\n18\n35\n33\n36\n62\nAverage length\n6.1\n6.8\n6.2\n7.6\n10.3\n10.8\n13.3\n14.4\n\nNot only has the number of submissions increased, but the length of\npublished articles has also increased (see Table 2). The\napparent jump from 2012 to 2013 may be associated with the change from a\ntwo column to a single column format, but page counts have risen,\nincreasing the workload of reviewers and editors. We only have\nconsistent records of the time taken to process accepted contributed\narticles for the 2013–2016 period. Again, the excellent work done by\nour generous reviewers and my very hard-working predecessors and\nespecially Michael Lawrence last year, is evident in holding median\ntimes from receipt to publication online to a little over 200 days, as\nTable 3 shows.\n\nTable 3: Median day count from acknowledgement to acceptance and\nonline publication 2013–2016, by year of publication.\n\n2013\n2014\n2015\n2016\nMedian\n347.0\n225.5\n212.5\n212.0\n\nUsing gender\n(Blevins and Mullen 2015; Mullen 2016) and\ngenderizeR\n(Wais 2016a,b), it is also possible to use author given\nnames1 to try to monitor author diversity; affiliation location has\nnot yet been successfully examined. Table 4 shows that there\nremains plenty to do to reflect the strengths of our community\nadequately2.\n\nTable 4: Authors of published articles 2009–2016, by year of\npublication; women/men split based on author given names.\n\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\nWomen\n5\n9\n8\n6\n10\n18\n27\n32\nMen\n32\n30\n33\n27\n62\n55\n55\n121\nUnknown\n3\n5\n3\n3\n7\n4\n9\n10\n\nIn addition to re-framing the description of the kinds of articles we\ninvite authors to contribute to our journal, work has been done on our\nwebsite. Its appearance has been brought into line with that of the main\nR project website, and articles are reached through “landing” pages\ncontaining the abstract and citatation information as well as listings\nof CRAN and Bioconductor packages cited in the article. So far very few\ncontributed articles associate themselves directly with CRAN Task Views,\nso these are inferred from cited CRAN packages and listed on the landing\npages. Further progress in helping to make work published in our journal\nmore accessible is planned.\nI hope you continue to enjoy and benefit from reading work published in\nour journal.\n\nCRAN packages used\ngender, genderizeR\nCRAN Task Views implied by cited packages\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\nC. Blevins and L. Mullen. Jane, John \\(\\ldots\\) Leslie? A historical method for algorithmic gender prediction. Digital Humanities Quarterly, 9: 2015. URL http://www.digitalhumanities.org/dhq/vol/9/3/000223/000223.html.\n\n\nL. Mullen. Gender: Predict gender from names using historical data. 2016. URL https://github.com/ropensci/gender. R package version 0.5.1.\n\n\nK. Wais. Gender Prediction Methods Based on First Names with genderizeR. The R Journal, 8(1): 17–37, 2016a. URL https://journal.r-project.org/archive/2016/RJ-2016-002/index.html.\n\n\nK. Wais. genderizeR: Gender prediction based on first names. 2016b. URL https://CRAN.R-project.org/package=genderizeR. R package version 2.0.0.\n\n\nThe articles describing the packages used here stress the\nuncertainty involved in binary assignment.↩︎\nAlthough relative binary proportions do not differ greatly from\nthose shown by a recent survey of useR participants\n(https://forwards.github.io/blog/2017/01/13/mapping-users/), the\nNorwegian context of the editor suggests that complacency or change\nof focus are unhelpful.\n\n↩︎\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2017-1-erum/",
    "title": "Conference Report: European R Users Meeting 2016",
    "description": "The 'Conference Report: European R Users Meeting 2016' article from the 2017-1 issue.",
    "author": [
      {
        "name": "Maciej Beręsewicz",
        "url": {}
      },
      {
        "name": "Adolfo Alvarez",
        "url": {}
      },
      {
        "name": "Przemysław Biecek",
        "url": {}
      },
      {
        "name": "Marcin K. Dyderski",
        "url": {}
      },
      {
        "name": "Marcin Kosiński",
        "url": {}
      },
      {
        "name": "Jakub Nowosad",
        "url": {}
      },
      {
        "name": "Kamil Rotter",
        "url": {}
      },
      {
        "name": "Alicja Szabelska-Beręsewicz",
        "url": {}
      },
      {
        "name": "Marcin Szymkowiak",
        "url": {}
      },
      {
        "name": "Łukasz Wawrowski",
        "url": {}
      },
      {
        "name": "Joanna Zyprych-Walczak",
        "url": {}
      }
    ],
    "date": "2017-06-01",
    "categories": [],
    "contents": "\n\n1 Introduction\nThe European R Users Meeting (eRum) 2016 was an international conference\naimed at integrating users of the R language. eRum 2016 was held between\nOctober 12 and 14, 2016, in Poznań, Poland at Poznań University of\nEconomics and Business (http://erum.ue.poznan.pl/).\nThe main purpose of eRum was to integrate R users from Europe and\nprovide a platform for sharing experiences between academics and\npractitioners. We wanted to give the participants the possibility to\npresent various applications of R, get to know different R packages and\nget involved in a broader collaboration. In addition, we wanted to\ncreate an opportunity for R users who were not able to participate in\nUseR 2016 that was held in Stanford, CA, USA.\nThe conference was organized by the Students Scientific Association\n‘Estymator’, the Department of Statistics of Poznań University of\nEconomics and Business and the Department of Mathematical and\nStatistical Methods of Poznań University of Life Sciences. The\nsupporting organizers were two local groups of R enthusiasts - PAZUR -\nPoznań R Users Group and SER - Warsaw R Users Group. eRum hosted 82\nspeakers from over 20 countries. Over 250 participants took part in 12\nparallel sessions devoted to methodology, business, R packages, data\nworkflow, bioR, lightning talks, and education learning. Beside the\nparallel sessions the conference featured 10 invited talks.\nWe are looking forward to the next European R Users Meeting in 2018 and\nwe encourage anyone interested in organizing an eRum event in their\ncountry to get in touch with us.\n2 The Organizing Committee\nTo ensure the Organizing Committee was as diverse as possible, its\nchair, Maciej Beręsewicz from Poznań University of Economics and\nBusiness and Statistical Office in Poznań had invited people from\ndifferent fields of science and business:\nAdolfo Alvarez, Analyx,\nPrzemysław Biecek, MIM University of Warsaw, MiNI Warsaw University\nof Technology,\nMarcin Dyderski, Institute of Dendrology of the Polish Academy of\nSciences, Poznań University of Life Sciences,\nMarcin Kosiński, Warsaw R Enthusiasts,\nJakub Nowosad, Adam Mickiewicz University in Poznań, University of\nCincinnati,\nKamil Rotter, Poznań University of Economics and Business,\nAlicja Szabelska-Beręsewicz, Poznań University of Life Sciences,\nMarcin Szymkowiak, Poznań University of Economics and Business,\nŁukasz Wawrowski, Poznań University of Economics and Business,\nJoanna Zyprych-Walczak, Poznań University of Life Sciences.\n3 Pre-conference workshops\nTen workshops were held at Poznań University of Life Sciences and in the\nStatistical Office in Poznań during the first day of eRum 2016 (October\n12th 2016). They were divided into two sessions.\nMorning session:\nAn introduction to R (in Polish) held by Adam Dąbrowski\nPredictive modeling with R held by Artur Suchwałko\nData Visualization using R held by Matthias Templ\nTime series forecasting with R held by Adam Zagdański\nR for expression profiling by Next Generation Sequencing held by\nPaweł Łabaj\nAfternoon session:\nIntroduction to Bayesian Statistics with R and Stan held by Rasmus\nBååth\nSmall Area Estimation with R held by Virgilio Gómez-Rubio\nR for industry and business: Statistical tools for quality control\nand improvement held by Emilio L. Cano\nAn introduction to changepoint models using R held by Rebecca\nKillick\nVisualising spatial data with R: from ‘base’ to ‘shiny’ held by\nRobin Lovelace\nAltogether the workshops were attended by 150 people. The workshops\ndedicated to Bayesian Statistics with R and Stan and Predictive modeling\nwith R turned out to be the most popular ones - each attracted as many\nas 40 attendees.\n4 Invited speakers\nThere were five plenary sessions, each featuring two invited speakers.\nThe speaker roster was balanced in terms of nationality (5 from Poland,\n5 from abroad), gender (6 males, 4 females), institution (7 from\nacademia, 3 from business) and topic (5 methodology, 5 tools or misc).\nWe were honored to host the following invited speakers: Rasmus Bååth\n(Lund University), Przemysław Biecek (University of Warsaw),\nRomain Francois (Consulting Datactive), Marek Gagolewski (Polish\nAcademy of Sciences), Jakub Glinka (GfK Data Lab), Ulrike \n(Beuth University of Applied Sciences), Katarzyna Kopczewska\n(University of Warsaw), Katarzyna Stapor (Silesian University of\nTechnology), Matthias Templ (Vienna University of Technology),\nHeather Turner (University of Warwick).\nAll invited talks were recorded and are available as a youtube playlist\nat\nhttp://www.youtube.com/playlist?list=PLCsJUtCRSFbejqCqAURNVOFFpoDCMeuO5.\nThe book of abstracts, presentations from all sessions, posters and\nother documents associated with eRum 2016 are available at\nhttps://github.com/eRum2016/.\n5 Trivia\nThe conference speakers cited 179 R packages. The most popular included:\nggplot2,\nshiny,\ndplyr,\ncaret,\nleaflet,\nsp,\ncluster,\ne1071,\nknitr,\nmagrittr,\nrandomForest,\nRcpp,\nrgdal,\nrgeos,\nrmarkdown,\nrstan,\nSparkR.\nThanks to our platinum sponsor McKinsey it was possible to organize a\nsocial event which included a conference dinner at Poznań’s Municipal\nStadium together with a tour of the Stadium.\nGroup photos taken on the first day of the conference can be found here\nhttps://www.goo.gl/X0QfZ5.\nAfter the conference some of the participants took part in a sightseeing\ntour of Poznań, which was organized on 15th of October.\n6 Acknowledgements\nWe would like to thank the Faculty of Informatics and Electronic Economy\nPoznan University of Economics and Business and our sponsors (McKinsey,\nMicrosoft, eoda, Analyx, tidk, DataCamp, WLOG solutions, Quantide and\nRstudio) for their financial support, which was used to organize daily\nlunches, coffee breaks and a social program featuring a conference\ndinner at the Municipal Stadium in Poznań.\nSpecial thanks to Klaudia Korniluk\nfor her outstanding work on the logo of eRum 2016 and coming up with the\nidea of \"R heros\". We also thank R-Bloggers and SmartedPoland for\ntheir support in spreading the word about eRum 2016 in the Internet.\nIn addition we would like to thank Prof. Elżbieta Gołata, Prof. Grażyna\nDehnel, Prof. Idzi Siatkowski, Prof. Anita Dobek and directors of the\nStatistical Office in Poznań (dr Jacek Kowalewski and dr Tomasz\nKlimanek) for their support in organizing the conference.\n\n\nCRAN packages used\nggplot2, shiny, dplyr, caret, leaflet, sp, cluster, e1071, knitr, magrittr, randomForest, Rcpp, rgdal, rgeos, rmarkdown, rstan, SparkR\nCRAN Task Views implied by cited packages\nBayesian, Cluster, Databases, Distributions, Environmetrics, HighPerformanceComputing, MachineLearning, MissingData, MixedModels, ModelDeployment, NumericalMathematics, Phylogenetics, Psychometrics, ReproducibleResearch, Robust, Spatial, SpatioTemporal, TeachingStatistics, WebTechnologies\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2017-1-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2017-1 issue.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2017-06-01",
    "categories": [],
    "contents": "\n1 Donations and members\nMembership fees and donations received between 2017-03-15 and\n2017-06-15.\nDonations\nEmilio Ciccone (Italy)\nGuillaume Coqueret (France)\nYves Deville (France)\nKen Ikeda (Japan)\nKuniaki Kawahara (Japan)\nKem Phillips (United States)\nJoshua Rosenstein (United States)\nStefan Wyder (Switzerland)\nSupporting benefactors\nBrigham Young University, Provo (United States)\nDisplayr, Glebe (Australia)\nSupporting institutions\nBC Cancer Agency, Vancouver (Canada)\nEMBL, Heidelberg (Germany)\nInstitute of Mathematical Statistics, Beachwood (United States)\nSupporting members\nAbdulrahman Al-Qasem (Saudi Arabia)\nPhilippe Baril Lecavalier (Canada)\nMarcel Baumgartner (Switzerland)\nMorten Braüner (Denmark)\nAndrew Brown (United States)\nIan Cook (United States)\nRobin Crockett (United Kingdom)\nGábor Csárdi (United Kingdom)\nGergely Daróczi (Hungary)\nJames Davis (United States)\nAjit de Silva (United States)\nDubravko Dolic (Germany)\nSandrine Dudoit (United States)\nJoran Elias (United States)\nDaniel Emaasit (United States)\nSoo-Heang Eo (South Korea)\nArturo Erdely (Mexico)\nHubert Eser (Austria)\nJohn Fox (Canada)\nCarl Ganz (United States)\nJan Marvin Garbuszus (Germany)\nJ. Antonio García (Mexico)\nMatthieu Gousseff (France)\nArthur W. Green (United States)\nPhilippe Grosjean (Belgium)\nHlynur Hallgrímsson (Iceland)\nBela Hausmann (Austria)\nKieran Healy (United States)\nJim Hester (United States)\nHans Hlynsson (United Kingdom)\nRick Hubbard (United States)\nMichael Johansson (Puerto Rico)\nStephen Kaluzny (United States)\nChristian Keller (Switzerland)\nSebastian Koehler (Germany)\nKatarzyna Kopczewska (Poland)\nAlexander Kowarik (Austria)\nDiego Kuonen (Switzerland)\nCaleb Lareau (United States)\nAndy Liaw (United States)\nIan Lyttle (United States)\nBen Marwick (United States)\nShigeru Mase (Japan)\nDieter Menne (Germany)\nDavid Monterde (Spain)\nGuido (Germany)\nBob Muenchen (United States)\nHannes Mühleisen (Netherlands)\nJoris Muller (France)\nMichihiro Nakamura (Japan)\nAnthony OFarrell (United States)\nLudvig Renbo Olsen (Denmark)\nGeorge Ostrouchov (United States)\nMatthew Pancia (United States)\nMarc Pelath (United States)\nJohn Pellman (United States)\nLauf Peter (Germany)\nErik Petrovski (Denmark)\nThomas Petzoldt (Germany)\nJonas Ranstam (Sweden)\nPaulo Justiniano Ribeiro Jr (Brazil)\nMarty Rose (United States)\nPeter Ruckdeschel (Germany)\nBob Rudis (United States)\nManel Salamero (Spain)\nKenneth Spriggs (United States)\nJulian Stander (United Kingdom)\nBerthold Stegemann (Germany)\nNicholas Tierney (Australia)\nCaoimhin Ua Buachalla (Ireland)\nShinya Uryu (Japan)\nMauricio Vargas (United States)\nSteven Vasquez-Grinnell (United States)\nBoris Veytsman (United States)\nVincent Vinh-Hung (Martinique)\nDaehler Werner (Switzerland)\nJordan White (United States)\nAndy Wills (United Kingdom)\nNan Xiao (United States)\nHiroaki Yutani (Japan)\nTomas Zelinsky (Slovakia)\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2016-2-bioc/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2016-2 issue.",
    "author": [
      {
        "name": "Bioconductor Core Team",
        "url": {}
      }
    ],
    "date": "2016-12-01",
    "categories": [],
    "contents": "\n\nThe Bioconductor project provides tools for\nthe analysis and comprehension of high-throughput genomic data.\nBioconductor 3.4 was released on 18 October, 2016. It is compatible with\nR 3.3 and consists of 1296 software packages, 309 experiment data\npackages, and 933 up-to-date annotation packages. The release\nannouncement includes\ndescriptions of 101 new packages, and updated NEWS files for many\nadditional packages. Start using Bioconductor by installing the most\nrecent version of R and evaluating the commands\n  source(\"https://bioconductor.org/biocLite.R\")\n  biocLite()\nInstall additional packages and dependencies, e.g.,\nAnnotationHub,\nwith\n  BiocInstaller::biocLite(\"AnnotationHub\")\nDocker and\nAmazon\nimages provide a very effective on-ramp for power users to rapidly\nobtain access to standardized and scalable computing environments. Key\nresources include:\nbioconductor.org to install, learn, use,\nand develop Bioconductor packages.\nA listing of available\nsoftware, linked to pages\ndescribing each package.\nA question-and-answer style user support\nsite and developer-oriented\nmailing list.\nThe F1000Research Bioconductor\nchannel for\npeer-reviewed Bioconductor work flows.\nOur package\nsubmission\nrepository for open technical review of new packages.\nOur annual conference, BioC 2017: Where Software and Biology\nConnect,\nwill be on June 26 (‘developer day’), 27 and 28, in Boston, MA.\n\n\nBioconductor packages used\nAnnotationHub\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2016-2-ch/",
    "title": "Changes in R",
    "description": "The 'Changes in R' article from the 2016-2 issue.",
    "author": [
      {
        "name": "The R Core Team",
        "url": {}
      }
    ],
    "date": "2016-12-01",
    "categories": [],
    "contents": "\n\nCHANGES IN R 3.3.2 patched\n\nNEW FEATURES\nThe internal methods of download.file() and url() now report if\nthey are unable to follow the redirection of a http:// URL to a\nhttps:// URL (rather than failing silently).\n\n\nINSTALLATION on a UNIX-ALIKE\nThe configure check for the zlib version is now robust to\nversions longer than 5 characters, including 1.2.10.\n\n\nUTILITIES\nEnvironmental variable _R_CHECK_TESTS_NLINES_ controls how\nR CMD check reports failing tests (see §8 of the ‘R Internals’\nmanual).\n\n\nBUG FIXES\nrep(x, times) and rep.int(x, times) now both work also when\ntimes is larger than the maximal integer, including when it is of\nlength greater than one.\n(PR#16932)\nvapply(x, *) now works with long vectors x.\n(PR#17174)\nisS3method(\"is.na.data.frame\") and similar are correct now.\n(PR#17171)\ngrepRaw(<long>, <short>, fixed = TRUE) now works, thanks to a\npatch by Mikko Korpela.\n(PR#17132)\nPackage installation into a library where the package exists via\nsymbolic link now should work wherever () works, resolving\nPR#16725.\n\"Cincinnati\" was missing an \"n\" in the precip dataset.\nFix buffer overflow vulnerability in pdf() when loading an\nencoding file. Reported by Talos (TALOS-2016-0227).\ngetDLLRegisteredRoutines() now produces its warning correctly when\nmultiple DLLs match, thanks to Matt Dowle’s\nPR#17184.\nSys.timezone() now returns non-NA also on platforms such as\nUbuntu 14.04.5 LTS, thanks to Mikko Korpela’s\nPR#17186.\nformat(x) for an illegal \"POSIXlt\" object x no longer\nsegfaults.\nmethods(f) now also works for f \"(\" or \"{\".\n(Windows only) dir.create() did not check the length of the path\nto create, and so could overflow a buffer and crash R.\n(PR#17206)\nOn some systems, very small hexadecimal numbers in hex notation\nwould underflow to zero.\n(PR#17199)\npmin() and pmax() now work again for ordered factors and\n0-length S3 classed objects, thanks to Suharto Anggono’s\nPR#17195\nand\nPR#17200.\nbug.report() did not do any validity checking on a package’s\nBugReports field. It now ignores an empty field, removes leading\nwhitespace and only attempts to open http:// and https:// URLs,\nfalling back to emailing the maintainer.\nBandwidth selectors bw.ucv() and bw.SJ() gave incorrect answers\nor incorrectly reported an error (because of integer overflow) for\ninputs longer than 46341. Similarly for bw.bcv() at length 5793.\nAnother possible integer overflow is checked and may result in an\nerror report (rather than an incorrect result) for much longer\ninputs (millions for a smooth distribution).\nfindMethod failed if the active signature had expanded beyond what\na particular package used. (Example with packages\nXR and\nXRJulia on CRAN).\nqbeta() underflowed too early in some very asymmetric cases.\n(PR#17178)\n\nCHANGES IN R 3.3.2\n\nNEW FEATURES\nextSoftVersion() now reports the version (if any) of the\nreadline library in use.\nThe version of LAPACK included in the sources has been updated to\n3.6.1, a bug-fix release including a speedup for the non-symmetric\ncase of eigen().\nUse options(deparse.max.lines=) to limit the number of lines\nrecorded in .Traceback and other deparsing activities.\nformat(<AsIs>) looks more regular, also for non-character atomic\nmatrices.\nabbreviate() gains an option named = TRUE.\nThe online documentation for package methods is extensively\nrewritten. The goals are to simplify documentation for basic use, to\nnote old features not recommended and to correct out-of-date\ninformation.\nCalls to setMethod() no longer print a message when creating a\ngeneric function in those cases where that is natural: S3 generics\nand primitives.\n\n\nINSTALLATION and INCLUDED SOFTWARE\nVersions of the readline library >= 6.3 had been changed so that\nterminal window resizes were not signalled to readline: code has\nbeen added using a explicit signal handler to work around that (when\nR is compiled against readline >= 6.3).\n(PR#16604)\nconfigure works better with Oracle Developer Studio 12.5.\n\n\nUTILITIES\nR CMD check reports more dubious flags in files\nsrc/Makevars[.in], including -w and -g.\nR CMD check has been set up to filter important warnings from\nrecent versions of gfortran with -Wall -pedantic: this now\nreports non-portable GNU extensions such as out-of-order\ndeclarations.\nR CMD config works better with paths containing spaces, even those\nof home directories (as reported by Ken Beath).\n\n\nDEPRECATED AND DEFUNCT\nUse of the C/C++ macro NO_C_HEADERS is deprecated (no C headers\nare included by R headers from C++ as from R 3.3.0, so it should no\nlonger be needed).\n\n\nBUG FIXES\nThe check for non-portable flags in R CMD check could be stymied\nby src/Makevars files which contained targets.\n(Windows only) When using certain desktop themes in Windows 7 or\nhigher, could cause Rterm to stop accepting input.\n(PR#14406;\npatch submitted by Jan Gleixner.)\npretty(d, ..) behaves better for date-time d\n(PR#16923).\nWhen an S4 class name matches multiple classes in the S4 cache,\nperform a dynamic search in order to obey namespace imports. This\nshould eliminate annoying messages about multiple hits in the class\ncache. Also, pass along the package from the ClassExtends object\nwhen looking up superclasses in the cache.\nsample(NA_real_) now works.\nPackages using non-ASCII encodings in their code did not install\ndata properly on systems using different encodings.\nmerge(df1, df2) now also works for data frames with column names\n\"na.last\", \"decreasing\", or \"method\".\n(PR#17119)\ncontour() caused a segfault if the labels argument had length\nzero. (Reported by Bill Dunlap.)\nunique(warnings()) works more correctly, thanks to a new\nduplicated.warnings() method.\nfindInterval(x, vec = numeric(), all.inside = TRUE) now returns\n0s as documented. (Reported by Bill Dunlap.)\n(Windows only) R CMD SHLIB failed when a symbol in the resulting\nlibrary had the same name as a keyword in the .def file.\n(PR#17130)\npmax() and pmin() now work with (more ?) classed objects, such\nas \"Matrix\" from the\nMatrix package, as\ndocumented for a long time.\naxis(side, x = D) and hence Axis() and plot() now work\ncorrectly for \"Date\" and time objects D, even when “time goes\nbackward”, e.g., with decreasing xlim. (Reported by William May.)\nstr(I(matrix(..))) now looks as always intended.\nplot.ts(), the plot() method for time series, now respects\ncex, lwd and lty. (Reported by Greg Werbin.)\nparallel::mccollect() now returns a named list (as documented)\nwhen called with wait = FALSE. (Reported by Michel Lang.)\nIf a package added a class to a class union in another package,\nloading the first package gave erroneous warnings about “undefined\nsubclass”.\nc()’s argument use.names is documented now, as belonging to the\n(C internal) default method. In “parallel”, argument recursive is\nalso moved from the generic to the default method, such that the\nformal argument list of base generic c() is just (...).\nrbeta(4, NA) and similarly rgamma() and rnbinom() now return\nNaN’s with a warning, as other r<dist>(), and as documented.\n(PR#17155)\nUsing options(checkPackageLicense = TRUE) no longer requires\nacceptance of the licence for non-default standard packages such as\ncompiler. (Reported by Mikko Korpela.)\nsplit(<very_long>, *) now works even when the split off parts are\nlong.\n(PR#17139)\nmin() and max() now also work correctly when the argument list\nstarts with character(0).\n(PR#17160)\nSubsetting very large matrices (prod(dim(.)) >= 2^31) now works\nthanks to Michael Schubmehl’s\nPR#17158.\nbartlett.test() used residual sums of squares instead of\nvariances, when the argument was a list of lm objects. (Reported\nby Jens Ledet Jensen).\nplot(<lm>, which = *) now correctly labels the contour lines for\nthe standardized residuals for which = 6. It also takes the\ncorrect \\(p\\) in case of singularities (also for which = 5).\n(PR#17161)\nxtabs(~ exclude) no longer fails from wrong scope, thanks to\nSuharto Anggono’s\nPR#17147.\nReference class calls to methods() did not re-analyse previously\ndefined methods, meaning that calls to methods defined later would\nfail. (Reported by Charles Tilford).\nfindInterval(x, vec, left.open = TRUE) misbehaved in some cases.\n(Reported by Dmitriy Chernykh.)\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2016-2-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2016-2 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2016-12-01",
    "categories": [],
    "contents": "\n\n1 CRAN growth\nIn the past 6 months, 1169 new packages were added to the CRAN package\nrepository. 18 packages were unarchived and 36 archived. The following\nshows the growth of the number of active packages in the CRAN package\nrepository:\n\nAround 2017-01-27, the number of active packages went above 10000!\n2 New CRAN task views\nExtremeValue\n\nTopic: Extreme Value Analysis. Maintainer: Christophe Dutang, Kevin\nJaunatre. Packages: QRM, RTDE, ReIns, SpatialExtremes,\nVGAM, copula, evd\\(^*\\), evdbayes, evir\\(^*\\), extRemes,\nextremeStat, extremefit, fExtremes, ismev, lmom,\nlmomRFA, lmomco, mev, texmex.\n\n(* = core package)\n3 New packages in CRAN task views\nBayesian\n\nBAS, Boom, BoomSpikeSlab, LaplacesDemon, abn,\nbayesImageS, bayesmeta, bsts, nimble.\n\nChemPhys\n\nenpls, wccsom.\n\nClinicalTrials\n\nThreeGroups.\n\nCluster\n\nADPclust, CEC, bmixture, clustMixType, edci, largeVis.\n\nDifferentialEquations\n\nSim.DiffProc.\n\nDistributions\n\nCompositional, QRM, ReIns, bmixture.\n\nEconometrics\n\nExtremeBounds, clubSandwich, clusterSEs, decompr, gvc,\npwt9, rdd, rddtools, rdrobust.\n\nExperimentalDesign\n\nBOIN, BayesMAMS, CombinS, GroupSeq, ICAOD, JMdesign,\nOBsMD, OptimaRegion, OptimalDesign, PGM2, PwrGSD,\nRPPairwiseDesign, SLHD, ThreeArmedTrials, VNM, acebayes,\nbinseqtest, choiceDes, crmPack, designGLMM, designmatch,\ndesplot, dfcomb, dfcrm, dfmta, dfpk, docopulae,\ndynaTree, easypower, ez, gset, hiPOD, ibd,\nminimaxdesign, optDesignSlopeInt, ph2bayes, ph2bye, pid,\npowerAnalysis, powerGWASinteraction, powerbydesign,\nqualityTools, seqDesign, ssize.fdr, ssizeRNA, vdg.\n\nFinance\n\nDowd, FinancialMath, GetHFData, GetTDData, InfoTrad,\nMSGARCH, NetworkRiskMeasures, PortfolioEffectHFT,\nQuantTools, factorstochvol, fmdates, pinbasic, ragtop,\nsharpeRratio, tidyquant.\n\nHighPerformanceComputing\n\nbatchtools, pbapply, permGPU.\n\nMachineLearning\n\nbiglasso, gmum.r, rnn, spa.\n\nMedicalImaging\n\nMorpho\\(^*\\), RNifti\\(^*\\), Rvcg\\(^*\\), adaptsmoFMRI,\nbayesImageS, divest\\(^*\\), edfReader\\(^*\\), eegkit\\(^*\\).\n\nMetaAnalysis\n\nMetaAnalyser, MetaIntegrator, esc, metaplotr.\n\nNaturalLanguageProcessing\n\nPGRdup, gutenbergr, hunspell, monkeylearn, mscstexta4r,\nmscsweblm4r, phonics, quanteda, tesseract, text2vec,\ntidytext, tokenizers.\n\nNumericalMathematics\n\nRSpectra, rmumps, schumaker.\n\nOfficialStatistics\n\nBIFIEsurvey, CalibrateSSB, Frames2, GeomComb, MBHdesign,\nPracTools, RRTCS, RcmdrPlugin.sampling, gridsample,\nmapStats, panelaggregation, quantification, rpms, rspa,\nsamplesize4surveys, srvyr, surveybootstrap, surveydata,\nsurveyoutliers, svyPVpack.\n\nPhylogenetics\n\noutbreaker, phyext2, phyloTop, rmetasim, rotl.\n\nPsychometrics\n\nBayesFM, BayesLCA, BigSEM, CAvariants, ClustVarLV,\nDistatisR, GDINA, IRTpp, LNIRT, LVMMCOR, LatentREGpp,\nMCAvariants, MLCIRTwithin, SEMID, SOD,\nSparseFactorAnalysis, TestDataImputation, aspect, cIRT,\ncabootcrs, cds, cncaGUI, cocor, covLCA, ctsem, dlsem,\nedstan, elasticnet, emIRT, esaBcv, faoutlier, fourPNO,\ngSEM, gtheory, immer, influence.SEM, irtDemo, lba,\nlcda, lsl, ltbayes, nsprcomp, optiscale, paran,\npiecewiseSEM, plotSEMM, regsem, rsem, semGOF, semdiag,\nsemtree, smds, soc.ca, sparseSEM, subscore, superMDS,\nxxIRT.\n\nSocialSciences\n\noptmatch.\n\nSpatial\n\nExceedanceTools, RQGIS, dggridR\\(^*\\), gear, geojson,\ngeojsonio, ggsn, postGIStools, rgbif, rpostgis, sf\\(^*\\),\nsmacpod, smerc, spacom, spselect.\n\nSpatioTemporal\n\nCARBayesST, GeoLight, SimilarityMeasures.\n\nSurvival\n\nAHR, APtools, AdapEnetClass, BayesPiecewiseICAR, Biograph,\nCFC, Coxnet, Cyclops, ELYP, FamEvent, GORCure, GSSE,\nICBayes, ICGOR, InformativeCensoring, JointModel,\nLTRCtrees, LexisPlotR, PenCoxFrail, SSRMST, SimHaz,\nSimSCRPiecewise, SurvCorr, SurvLong, SurvRank,\nSurvRegCensCov, TP.idm, TransModel, addhazard, asaur,\nbnnSurvival, cmprskQR, compareC, condSURV, controlTest,\ncoxsei, crrp, crskdiag, discSurv, emplik2, fastpseudo,\nflexPM, flexrsurv, frailtySurv, gcerisk, glmnet, gte,\nhdnom, icRSF, icenReg, imputeYn, intercure, isoph,\njackknifeKME, joint.Cox, landest, mexhaz, miCoPTCM,\nmsmtools, npsurv, pch, plac, popEpi, ranger, reReg,\nreda, rstpm2, smcure, survMisc, survRM2, survminer,\ntdROC, thregI, tranSurv, uniah.\n\nTimeSeries\n\nBETS, BigVAR, GAS, GeomComb, InspectChangepoint, Tcomp,\nWaveletComp, cointReg, dCovTS, dynr, ecm,\nfactorstochvol, forecastHybrid, gdpc, ggseas, mclcar,\nonlineCPD, opera, pcdpca, pdc, robets, roll, rucrdtw,\nscoringRules, seasonalview, smooth, sparsevar, spectral,\nstR, thief, tsdisagg2, tswge, uroot, x13binary.\n\nWebTechnologies\n\nROpenFIGI, RSmartlyIO, RStripe, anametrix, dataone,\ndatarobot, europepmc, fiery, geoparser, googleAnalyticsR,\ngoogleCloudStorageR, htmltab, jqr, jsonvalidate,\nmscstexta4r, mscsweblm4r, nomadlist, openadds, opencage,\nosi, osmplotr, placement, plumber, rgeospatialquality,\nrosetteApi, uaparserjs.\n\n(* = core package)\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2016-2-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2016-2 issue.",
    "author": [
      {
        "name": "Michael Lawrence",
        "url": {}
      }
    ],
    "date": "2016-12-01",
    "categories": [],
    "contents": "\n\nOn behalf of the editorial board, I am pleased to publish Volume 8,\nIssue 2 of the R Journal. This issue contains 33 contributed research\narticles. Each of them either presents an R package, a specific\nextension of an R package or applications using R packages available\nfrom the Comprehensive R Archive Network (CRAN,\nhttp:://CRAN.R-project.org). This issue highlights the breadth and\ndepth of the R package ecosystem, covering advances in statistical\ncomputing and visualization, as well as novel applications of R in\nspecific domains. The authors have described a small but representative\nsample of the now more than 11000 packages distributed through CRAN and\nBioconductor.\nAs usual the bulk of this issue presents advancements in the field of\napplied statistics, including multipleNCC for inverse probability\nweighting of nested case-control data, SimCorMultRes for simulating\ncorrelated categorical responses, Qtools for quantile inference, and\nMLCIRTwithin for discovering latent traits in questionnaire responses.\nThe CAVariants package implements multiple methods for correspodence\nanalysis, and hdm provides tools for computing uncertainty in\nhigh-dimensional, sparse models. There are articles describing how to\nanalyze normal tolerance intervals with the tolerance package, perform\nassociated kernel estimation using ake, evaluate principal surrages\nwith pseval, find subgroups using evolutionary fuzzy methods\nimplemented in SDEFSR, and use the distance covariance function to\nanalyze time series data with dCovTS. Further articles describe\nquantreg.nonpar for quantile regression with non-parametric series,\nmicompr for multivariate independent comparison of observations,\nWeDiBaDis for weighted discrimant analysis, TSDist for computing\ndistances for time series, condSURV for estimating conditional\nsurvival functions, and mctest for testing collinearity between\nregressors.\nWe are fortunate to present a number of data visualization packages\nincluding: rnrfa for viewing data from the UK National River Flow\nArchive, easyROC, a GUI for analyzing ROC curves, geozoo for\ngenerating libraries of high-dimensional shapes, and ggfortify for\ngetting data into shape for plotting.\nResearchers continue to find new ways to apply R to scientific pursuits,\nincluding QPot for understanding how stochasticity affects systems of\ndifferential equations, nmfgpu4R for large scale non-negative matrix\nfactorization (NMF) using GPUs, and the units package for computing on\nscientific units. Applications to biology include TRONCO for modeling\ntumor progression and ACSNMineR for detecting module enrichment and\ndepletion. Other applications include diverse for analyzing diversity\nin complex systems, comf for analyzing thermal comfort data, water\nfor estimating evapotranspiration from satellite images, eiCompare for\ncomparing ecological inference estimates, particularly in the context of\nanalyzing voting patterns, mixtox for assessing the toxicity of\nchemical mixtures, tigris for accessing geographic data from the US\nCensus, and rPref for computing Pareto frontiers, useful for\nimplementing preference-based database queries.\nIn addition the News and Notes section contains the usual updates on the\nR Foundation, CRAN and the Bioconductor project.\nI hope you enjoy the issue.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2016-2-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2016-2 issue.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2016-12-01",
    "categories": [],
    "contents": "\n1 Donations and new members\nNew benefectors\nINWT Statistics, Germany\nDonations\nRadosav Andric, in memory of Ramiro Zurkowski, Canada\nGreater Good, Netherlands\nKoen-Woong Moon, Korea\nDaniel Neumann, Germany\nSchukat Electronic Vertriebs GmbH, Germany\nSomewhat Retired, USA\nRichard Vlasimsky, IMIDEX, USA\nNew supporting institutions\nInference Technologies, Czech Republic\nNew supporting members\nAyala S. Allon, Israel\nMichael Hahsler, USA\nMatthias Häni, Switzerland\nChristian Kohlberg, Germany\nWojciech Niemczyk, Poland\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2016-1-bioconductor/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2016-1 issue.",
    "author": [
      {
        "name": "Bioconductor Core Team",
        "url": {}
      }
    ],
    "date": "2016-06-01",
    "categories": [],
    "contents": "\n\nThe Bioconductor project provides tools for\nthe analysis and comprehension of high-throughput genomic data. The 1211\nsoftware packages available in Bioconductor can be viewed at\nhttp://bioconductor.org/packages/. Navigate packages using ‘biocViews’\nterms and title search. Each package has an html page with a\ndescription, links to vignettes, reference manuals, and usage\nstatistics. Start using Bioconductor version 3.3 by installing R 3.3.1\nand evaluating the commands\n  source(\"https://bioconductor.org/biocLite.R\")\n  biocLite()\nInstall additional packages and dependencies, e.g.,\nAnnotationHub,\nwith\n  source(\"https://bioconductor.org/biocLite.R\")\n  biocLite(\"AnnotationHub\")\nContinued availability of Bioconductor\nDocker and\nAmazon\nimages provides a very effective on-ramp for power users to rapidly\nobtain access to standardized and scalable computing environments.\n1 Bioconductor 3.3 Release Highlights\nBioconductor 3.3 was released on 4 April, 2016. It is compatible with R\n3.3 and consists of 1211 software packages, 293 experiment data\npackages, and 916 up-to-date annotation packages. There are 107 new\nsoftware packages and many updates and improvements to existing\npackages. The release\nannouncement includes\ndescriptions of new packages and updated NEWS files provided by package\nmaintainers.\nOur collection of microarray, transcriptome and organism-specific\nannotation packages use the ‘select’ interface (keys, columns,\nkeytypes) to access static information on gene annotations (org.*\npackages) and gene models (TxDb.* packages); these augment packages\nfor querying web-based resources. The\nAnnotationHub\ncontinues to complement our traditional offerings with diverse whole\ngenome annotations from Ensembl, ENCODE, dbSNP, UCSC, and elsewhere;\nexample uses are described in the AnnotationHub\nHow-To\nvignette.\n2 User support\nThe Bioconductor project web site helps\norient users and developers to the project. It includes essential\ninformation for software\ninstallation, detailed landing pages\nfor each package (e.g.,\nhttps://bioconductor.org/packages/GenomicRanges) including links to\ncurrent manuals and vignettes, extensive training\nmaterial, and links to\nthe current literature. A\nrecent innovation has been the development of the Bioconductor F1000\npublishing channel for\nacademic publication of work flows and other extended software use\ncases.\nThe project support site is a\nquestion-and-answer forum where users can easily search for existing\nsolutions or pose specific questions about use of Bioconductor packages.\nThe support site is quite active, with expert responses often within a\nmatter of hours. It is very helpful, when asking about error messages,\nto ensure that your Bioconductor installation is correct (using\nBiocInstaller::biocValid()) and current (include the output of\nsessionInfo() in your question), that the question includes code\nchunks that someone else can evaluate to reproduce the problem (e.g.,\nusing code or data from example pages of package manuals), and that the\nerror message and traceback() output are included.\nBioconductor holds an annual user conference each summer, this year in\nconjunction with UseR! 2016. Conference\nresources\n(talks and workshops) are available.\n3 Developer support\nA very natural progression in the R and Bioconductor community is from\nuser to package developer, transforming your knowledge and domain\nexpertise into software that others can use. The Bioconductor web site\nincludes developer resources to\nhelp this transition. The Bioconductor developer mailing\nlist provides a forum\ndedicated to developer-related questions.\nNew packages are now submitted to Bioconductor using an open review\nmodel. Prospective authors develop their package and, when ready, open\nan issue on the public\nContributions github\nrepository. Packages are then built and checked across Linux, Mac, and\nWindows platforms for conformance to R (R CMD check) and Bioconductor\n(using the\nBiocCheck\npackage) standards. Once the package is in good shape, a member of the\nBioconductor core team performs a preview of the package. The preview\nidentifies technical issues that are not easy to detect automatically.\nA key strength of the Bioconductor project is the use of well-defined\nobjects (especially from the\nGenomicRanges\ninfrastructure) to represent data; this encourages software re-use and\nenables end-user interoperability between packages. For this reason, the\ntechnical review often leads to suggestions for data representations and\ninterfaces that use Bioconductor objects rather than general-purpose\ncontainers such as a data.frame.\n4 Forthcoming activities\nForthcoming Bioconductor events\ninclude an Asian workshop\nworkshop and\ndeveloper meeting (3-4 November,\nBrisbane, Australia) and European\ndeveloper conference (6-7\nDecember, Basel, Switzerland) developer conferences, as well as global\ntraining opportunities.\nThe next Bioconductor release will occur in October, 2016.\n\n\nBioconductor packages used\nAnnotationHub, BiocCheck, GenomicRanges\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2016-1-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2016-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2016-06-01",
    "categories": [],
    "contents": "\n\nIn the past 8 months, 1322 new packages were added to the CRAN package\nrepository. 43 packages were unarchived, 48 archived, 1 package had to\nbe removed. The following shows the growth of the number of active\npackages in the CRAN package repository:\n\nAt the R Foundation’s General Assembly after UseR! 2016 in Stanford, the\nCRAN team asked for help, in particular for processing package\nsubmissions. Dirk Eddelbüttel, Duncan Murdoch, Deepayan Sarkar, and\nDuncan Temple Lang volunteered. Duncan Murdoch is already actively\nprocessing incoming CRAN submissions; expect other changes over the\ncoming months.\nNew packages in CRAN task views\nChemPhys\n\nEEM, titrationCurves, webchem.\n\nCluster\n\nevclust, genie, treeClust.\n\nDistributions\n\nEnvStats, KScorrect, bridgedist, extraDistr, extremefit,\nmarg, mclust.\n\nEconometrics\n\nrUnemploymentData, wbstats.\n\nFinance\n\nFRAPO, XBRL, bootTimeInference, derivmkts, finreportr,\nobAnalytics.\n\nHighPerformanceComputing\n\nLaF, RcppParallel, doFuture, future.BatchJobs, gpuR,\nh2o, randomForestSRC, sprint.\n\nMachineLearning\n\nOneR, SIS, SuperLearner, evclass, h2o, hdm.\n\nMetaAnalysis\n\naltmeta, bayesmeta, bmeta, gmeta, hetmeta, metansue,\nweightr.\n\nNumericalMathematics\n\nconicfit, madness, matrixcalc, permutations.\n\nOfficialStatistics\n\nconvey, icarus.\n\nOptimization\n\ncmaesr, nlmrt, parma, psoptim, rCMA, rLindo, scs,\nsmoof.\n\nPsychometrics\n\nShinyItemAnalysis, blavaan\\(^*\\), bpca, difNLR, dualScale,\nmetaSEM, quickpsy, wCorr.\n\nReproducibleResearch\n\nDT, HTMLUtils, Kmisc, RefManageR, ReporteRs,\nSortableHTMLTables, apaStyle, archivist, checkpoint,\ncompareGroups, connect3, formatR, formattable, highlight,\nhighr, htmlTable, htmltools, humanFormat, kfigr,\nknitLatex, knitcitations, latex2exp, lazyWeave, lubridate,\nminiCRAN, packrat, prettyunits, rbundler, resumer,\nrmarkdown, rprintf, tufterhandout, ztable.\n\nRobust\n\nroahd.\n\nSpatial\n\nHSAR, ProbitSpatial, RNetCDF, S2sls, SpatialPosition,\nWatersheds, cartography, cleangeo, diseasemapping,\ngdalUtils, geoaxe, geostatsp, igraph, ipdw, lawn,\nlctools, magclass, mapmisc, mapview, ncdf4, quickmapr,\nrecmap, shp2graph, spanel, statebins, stplanr.\n\nSpatioTemporal\n\nVTrack, trackeR.\n\nTimeSeries\n\nForecastCombinations, M4comp, VARsignR, ZRA, carx,\nsleekts, stlplus, tsPI.\n\nWebTechnologies\n\nApacheLogProcessor, AzureML, FastRWeb, GAR, RAdwords,\nRGoogleFit, ROpenWeatherMap, RSclient, RYandexTranslate,\nRZabbix, Rblpapi, Rexperigen, Rmonkey, Rserve, V8,\nWikiSocio, WikidataR, WufooR, abbyyR, aws.signature,\nbackblazer, bigrquery, boxr, captr, clarifai,\ncurlconverter, cymruservices, ddeploy, discgolf, fbRads,\nfitbitScraper, fitcoach, genderizeR, geocodeHERE, git2r,\ngitlabr, googlesheets, graphTweets, gsheet, httpcache,\nhttping, instaR, jug, livechatR, longurl, lucr, mime,\noai, osrm, pdftables, rLTP, randNames, rdatacite,\nrequest, restimizeapi, rgeolocate, rio, rorcid, rrefine,\nrvest, searchConsoleR, sendmailR, soql, telegram,\nthreewords, tidyjson, transcribeR, tweet2r, urlshorteneR,\nwebreadr, webshot, wikipediatrend, xml2, yummlyr.\n\n(* = core package)\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2016-1-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2016-1 issue.",
    "author": [
      {
        "name": "Michael Lawrence",
        "url": {}
      }
    ],
    "date": "2016-06-01",
    "categories": [],
    "contents": "\n\nOn behalf of the editorial board, I am pleased to publish Volume 8,\nIssue 1 of the R Journal. This issue contains 27 contributed research\narticles. Each of them either presents an R package, a specific\nextension of an R package or applications using R packages available\nfrom the Comprehensive R Archive Network (CRAN,\nhttp:://CRAN.R-project.org). It thus provides a small but current\ncross-section of the burgeoning R ecosystem.\nInterest in developing graphical user interfaces and visualization tools\non top of R, and integrating R with the web, continues to grow, as\nevidenced by the articles on the Social Network Analysis Survey\nFramework, a Shiny interface to the OpenMX modeling software, and the\nmapmisc package for visualizing geographic data. This issue also\nincludes articles on R interfaces to cloud-based data resources (the\nsbtools package), and a system for crowd-sourcing data preprocessing\nchores (the MTurkR package).\nTrue to the roots of R, the bulk of this issue presents advancements in\nthe field of applied statistics, including the crch package for modeling\ncensored and truncated data, new improvements in the mclust package for\nfitting Gaussian mixture models, the scmamp package for comparing the\nperformance of multiple algorithms, the rTableICC for randomly\ngenerating contingency tables, the clere package for variable clustering\nin high dimensions, the FWDselect package for forward model selection,\nthe metaplus package for analyzing robust meta-analyses, the hiddenf\npackage for exploring interaction effects in factorial studies, the\nstatmod package for calculating probabilities with the inverse Gaussian\ndistribution, the clustering.sc.dp package for clustering with\nsequential constraints and a review of R-based methods for\nnon-parametric testing of interactions in two-way factorial designs.\nThe diversity of the R ecosystem is such that packages are available for\nmany highly focused subfields. Examples in this issue include the stylo\npackage for performing stylometry studies, the CryptRndTest package for\nanalyzing randomness in cryptography, the quickpsy package for function\nfitting in psychometrics, SWMPr for analyzing estuary data, FieldSim for\nsimulating Gaussian fields (e.g., in image analysis), progenyClust for\nprogeny clustering, keyplayer for finding key players in social\nnetworks, DECIPHER for deciphering biological sequence data, GMDH for\nshort term forcasting with neural networks, and gstat for\nspatio-temporal interpolation of geostatistics data.\nBefore the user can apply these tools, the data must first be imported\ninto R and munged into a shape that is amenable to analysis. We present\nseveral packages for importing and munging data, namely: SchemaOnRead, a\ngeneralized data import framework supporting numerous common file types,\nmultiple packages for working with web logs (webreadr, urltools, iptools\nand rgeolocate), and the genderizeR package for predicting gender from\nfirst names.\nIn addition the News and Notes section contains the usual updates on\nCRAN and the Bioconductor project.\nI hope you enjoy the issue.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2016-1-r-changes/",
    "title": "Changes in R",
    "description": "The 'Changes in R' article from the 2016-1 issue.",
    "author": [
      {
        "name": "The R Core Team",
        "url": {}
      }
    ],
    "date": "2016-06-01",
    "categories": [],
    "contents": "\n\nCHANGES IN R 3.3.1 patched\n\nNEW FEATURES\nextSoftVersion() now reports the version (if any) of the\nreadline library in use.\nConvenience function hasName() has been added; it is intended to\nreplace the common idiom !is.null(x$name) without the usually\nunintended partial name matching.\nThe version of LAPACK included in the sources has been updated to\n3.6.1, a bug-fix release including a speedup for the non-symmetric\ncase of eigen().\nUse options(deparse.max.lines) to limit the number of lines\nrecorded in .Traceback and other deparsing activities.\n\n\nINSTALLATION and INCLUDED SOFTWARE\nVersions of the readline library >= 6.3 had been changed so that\nterminal window resizes were not signalled to readline: code has\nbeen added using a explicit signal handler to work around that (when\nR is compiled against readline >= 6.3).\n(PR#16604)\nconfigure works better with Oracle Developer Studio 12.5.\n\n\nUTILITIES\nR CMD check reports more dubious flags in files\nsrc/Makevars[.in], including -w and -g.\nR CMD check has been set up to filter important warnings from\nrecent versions of gfortran with -Wall -pedantic: this now\nreports non-portable GNU extensions such as out-of-order\ndeclarations.\n\n\nBUG FIXES\nThe check for non-portable flags in R CMD check could be stymied\nby src/Makevars files which contained targets.\n(Windows only) When using certain desktop themes in Windows 7 or\nhigher, could cause Rterm to stop accepting input.\n(PR#14406;\npatch submitted by Jan Gleixner.)\npretty(d, ..) behaves better for date-time d\n(PR#16923).\nWhen a class name matches multiple classes in the cache, perform a\ndynamic search in order to obey namespace imports. This should\neliminate annoying messages about multiple hits in the class cache.\nAlso, pass along the package from the ClassExtends object when\nlooking up superclasses in the cache.\nsample(NA_real_) now works.\nPackages using non-ASCII encodings in their code did not install\ndata properly on systems using different encodings.\nmerge(df1, df2) now also works for data frames with column names\n\"na.last\", \"decreasing\", or \"method\".\n(PR#17119)\ncontour() caused a segfault if the labels argument had length\nzero. (Reported by Bill Dunlap.)\nunique(warnings()) works more correctly, thanks to a new\nduplicated.warnings() method.\nfindInterval(x, vec = numeric(), all.inside = TRUE) now returns\n0s as documented. (Reported by Bill Dunlap.)\n(Windows only) R CMD SHLIB failed when a symbol in the resulting\nlibrary had the same name as a keyword in the .def file.\n(PR#17130)\npmax() and pmin() now work with (more ?) classed objects, such\nas \"Matrix\" from the\nMatrix package, as\ndocumented for a long time.\naxis(side, x = D) and hence Axis() and plot() now work\ncorrectly for \"Date\" and time objects D, even when “time goes\nbackward”, e.g., with decreasing xlim. (Reported by William May).\n\nCHANGES IN R 3.3.1\n\nBUG FIXES\nR CMD INSTALL and hence install.packages() gave an internal\nerror installing a package called description from a tarball on a\ncase-insensitive file system.\nmatch(x, t) (and hence x %in% t) failed when x was of length\none, and either character and x and t only differed in their\nEncoding or when x and t where complex with NAs or NaNs.\n(PR#16885.)\nunloadNamespace(ns) also works again when ns is a ‘namespace’,\nas from getNamespace().\nrgamma(1, Inf) or rgamma(1, 0, 0) no longer give NaN but the\ncorrect limit.\nlength(baseenv()) is correct now.\npretty(d, ..) for date-time d rarely failed when \"halfmonth\"\ntime steps were tried\n(PR#16923)\nand on ‘inaccurate’ platforms such as 32-bit Windows or a\nconfiguration with –disable-long-double; see comment #15 of\nPR#16761.\nIn text.default(x, y, labels), the rarely(?) used default for\nlabels is now correct also for the case of a 2-column matrix x\nand missing y.\nas.factor(c(a = 1L)) preserves names() again as in R < 3.1.0.\nstrtrim(\"\"[0], 0[0]) now works.\nUse of Ctrl-C to terminate a reverse incremental search started by\nCtrl-R in the readline-based Unix terminal interface is now\nsupported when R was compiled against readline >= 6.0 (Ctrl-G\nalways worked).\n(PR#16603)\ndiff(<difftime>) now keeps the \"units\" attribute, as subtraction\nalready did,\nPR#16940.\n\nCHANGES IN R 3.3.0\n\nSIGNIFICANT USER-VISIBLE CHANGES\nnchar(x, *)’s argument keepNA governing how the result for NAs\nin x is determined, gets a new default keepNA = NA which returns\nNA where x is NA, except for type = \"width\" which still\nreturns 2, the formatting / printing width of NA.\nAll builds have support for https: URLs in the default methods for\ndownload.file(), url() and code making use of them.\nUnfortunately that cannot guarantee that any particular https: URL\ncan be accessed. For example, server and client have to successfully\nnegotiate a cryptographic protocol (TLS/SSL, …) and the server’s\nidentity has to be verifiable via the available certificates.\nDifferent access methods may allow different protocols or use\nprivate certificate bundles: we encountered a https: CRAN mirror\nwhich could be accessed by one browser but not by another nor by\ndownload.file() on the same Linux machine.\n\n\nNEW FEATURES\nThe print method for methods() gains a byclass argument.\nNew functions validEnc() and validUTF8() to give access to the\nvalidity checks for inputs used by grep() and friends.\nExperimental new functionality for S3 method checking, notably\nisS3method().\nAlso, the names of the R ‘language elements’ are exported as\ncharacter vector tools::langElts.\nstr(x) now displays \"Time-Series\" also for matrix (multivariate)\ntime-series, i.e. when is.ts(x) is true.\n(Windows only) The GUI menu item to install local packages now\naccepts *.tar.gz files as well as *.zip files (but defaults to\nthe latter).\nNew programmeR’s utility function chkDots().\nD() now signals an error when given invalid input, rather than\nsilently returning NA. (Request of John Nash.)\nformula objects are slightly more “first class”: e.g., formula()\nor new(\"formula\", y ~ x) are now valid. Similarly, for \"table\",\n\"ordered\" and \"summary.table\". Packages defining S4 classes with\nthe above S3/S4 classes as slots should be reinstalled.\nNew function strrep() for repeating the elements of a character\nvector.\nrapply() preserves attributes on the list when how = \"replace\".\nNew S3 generic function sigma() with methods for extracting the\nestimated standard deviation aka “residual standard deviation” from\na fitted model.\nnews() now displays R and package news files within the HTML help\nsystem if it is available. If no news file is found, a visible\nNULL is returned to the console.\nas.raster(x) now also accepts raw arrays x assuming values in\n0:255.\nSubscripting of matrix/array objects of type \"expression\" is now\nsupported.\ntype.convert(\"i\") now returns a factor instead of a complex value\nwith zero real part and missing imaginary part.\nGraphics devices cairo_pdf() and cairo_ps() now allow\nnon-default values of the cairographics ‘fallback resolution’ to be\nset.\nThis now defaults to 300 on all platforms: that is the default\ndocumented by cairographics, but apparently was not used by all\nsystem installations.\nfile() gains an explicit method argument rather than implicitly\nusing getOption(\"url.method\", \"default\").\nThanks to a patch from Tomas Kalibera, x[x != 0] is now typically\nfaster than x[which(x != 0)] (in the case where x has no NAs,\nthe two are equivalent).\nread.table() now always uses the names for a named colClasses\nargument (previously names were only used when colClasses was too\nshort). (In part, wish of\nPR#16478.)\n(Windows only) download.file() with default method = \"auto\" and\na ftps:// URL chooses \"libcurl\" if that is available.\nThe out-of-the box Bioconductor mirror has been changed to one using\nhttps://: use chooseBioCmirror() to choose a http:// mirror if\nrequired.\nThe data frame and formula methods for aggregate() gain a drop\nargument.\navailable.packages() gains a repos argument.\nThe undocumented switching of methods for url() on https: and\nftps: URLs is confined to method = \"default\" (and documented).\nsmoothScatter() gains a ret.selection argument.\nqr() no longer has a ... argument to pass additional arguments\nto methods.\n[ has a method for class \"table\".\nIt is now possible (again) to replayPlot() a display list snapshot\nthat was created by recordPlot() in a different R session.\nIt is still not a good idea to use snapshots as a persistent storage\nformat for R plots, but it is now not completely silly to use a\nsnapshot as a format for transferring an R plot between two R\nsessions.\nThe underlying changes mean that packages providing graphics devices\n(e.g., Cairo,\nRSvgDevice,\ncairoDevice,\ntikzDevice) will\nneed to be reinstalled.\nCode for restoring snapshots was contributed by Jeroen Ooms and JJ\nAllaire.\nSome testing code is available at\nhttps://github.com/pmur002/R-display-list.\ntools::undoc(dir = D) and codoc(dir = D) now also work when D\nis a directory whose normalizePath()ed version does not end in the\npackage name, e.g. from a symlink.\nabbreviate() has more support for multi-byte character sets – it\nno longer removes bytes within characters and knows about Latin\nvowels with accents. It is still only really suitable for (most)\nEuropean languages, and still warns on non-ASCII input.\nabbreviate(use.classes = FALSE) is now implemented, and that is\nmore suitable for non-European languages.\nmatch(x, table) is faster (sometimes by an order of magnitude)\nwhen x is of length one and incomparables is unchanged, thanks\nto Peter Haverty\n(PR#16491).\nMore consistent, partly not back-compatible behavior of NA and\nNaN coercion to complex numbers, operations less often resulting\nin complex NA (NA_complex_).\nlengths() considers methods for length and [[ on x, so it\nshould work automatically on any objects for which appropriate\nmethods on those generics are defined.\nThe logic for selecting the default screen device on OS X has been\nsimplified: it is now quartz() if that is available even if\nenvironment variable DISPLAY has been set by the user.\nThe choice can easily be overridden via environment variable\nR_INTERACTIVE_DEVICE.\nOn Unix-like platforms which support the getline C library\nfunction, system(*,intern = TRUE) no longer truncates (output)\nlines longer than 8192 characters, thanks to Karl Millar.\n(PR#16544)\nrank() gains a ties.method = \"last\" option, for convenience (and\nsymmetry).\nregmatches(invert = NA) can now be used to extract both\nnon-matched and matched substrings.\ndata.frame() gains argument fix.empty.names;\nas.data.frame.list() gets new cut.names, col.names and\nfix.empty.names.\nplot(x ~ x, *) now warns that it is the same as plot(x ~ 1, *).\nrecordPlot() has new arguments load and attach to allow\npackage names to be stored as part of a recorded plot.\nreplayPlot() has new argument reloadPkgs to load/attach any\npackage names that were stored as part of a recorded plot.\nS4 dispatch works within calls to .Internal(). This means explicit\nS4 generics are no longer needed for unlist() and as.vector().\nOnly font family names starting with \"Hershey\" (and not \"Her\" as\nbefore) are given special treatment by the graphics engine.\nS4 values are automatically coerced to vector (via as.vector) when\nsubassigned into atomic vectors.\nfindInterval() gets a left.open option.\nThe version of LAPACK included in the sources has been updated to\n3.6.0, including those ‘deprecated’ routines which were previously\nincluded. Ca 40 double-complex routines have been added at the\nrequest of a package maintainer.\nAs before, the details of what is included are in\nsrc/modules/lapack/README and this now gives information on\nearlier additions.\ntapply() has been made considerably more efficient without\nchanging functionality, thanks to proposals from Peter Haverty and\nSuharto Anggono.\n(PR#16640)\nmatch.arg(arg) (the one-argument case) is faster; so is\nsort.int().\n(PR#16640)\nThe format method for object_size objects now also accepts\n“binary” units such as \"KiB\" and e.g., \"Tb\". (Partly from\nPR#16649.)\nProfiling now records calls of the form foo::bar and some similar\ncases directly rather than as calls to <Anonymous>. Contributed by\nWinston Chang.\nNew string utilities startsWith(x, prefix) and\nendsWith(x, suffix). Also provide speedups for some\ngrepl(\"^...\",*) uses (related to proposals in\nPR#16490).\nReference class finalizers run at exit, as well as on garbage\ncollection.\nAvoid parallel dependency on stats for port choice and random\nnumber seeds.\n(PR#16668)\nThe radix sort algorithm and implementation from\ndata.table\n(forder) replaces the previous radix (counting) sort and adds a\nnew method for order(). Contributed by Matt Dowle and Arun\nSrinivasan, the new algorithm supports logical, integer (even with\nlarge values), real, and character vectors. It outperforms all other\nmethods, but there are some caveats (see ?sort).\nThe order() function gains a method argument for choosing\nbetween \"shell\" and \"radix\".\nNew function grouping() returns a permutation that stably\nrearranges data so that identical values are adjacent. The return\nvalue includes extra partitioning information on the groups. The\nimplementation came included with the new radix sort.\nrhyper(nn, m, n, k) no longer returns NA when one of the three\nparameters exceeds the maximal integer.\nswitch() now warns when no alternatives are provided.\nparallel::detectCores() now has default logical = TRUE on all\nplatforms – as this was the default on Windows, this change only\naffects Sparc Solaris.\nOption logical = FALSE is now supported on Linux and recent\nversions of OS X (for the latter, thanks to a suggestion of Kyaw\nSint).\nhist() for \"Date\" or \"POSIXt\" objects would sometimes give\nmisleading labels on the breaks, as they were set to the day before\nthe start of the period being displayed. The display format has been\nchanged, and the shift of the start day has been made conditional on\nright = TRUE (the default).\n(PR#16679)\nR now uses a new version of the logo (donated to the R Foundation by\nRStudio). It is defined in .svg format, so will resize without\nunnecessary degradation when displayed on HTML pages—there is also\na vector PDF version. Thanks to Dirk Eddelbuettel for producing the\ncorresponding X11 icon.\nNew function .traceback() returns the stack trace which\ntraceback() prints.\nlengths() dispatches internally.\ndotchart() gains a pt.cex argument to control the size of points\nseparately from the size of plot labels. Thanks to Michael Friendly\nand Milan Bouchet-Valat for ideas and patches.\nas.roman(ch) now correctly deals with more diverse character\nvectors ch; also arithmetic with the resulting roman numbers works\nin more cases.\n(PR#16779)\nprcomp() gains a new option rank. allowing to directly aim for\nless than min(n,p) PC’s. The summary() and its print() method\nhave been amended, notably for this case.\ngzcon() gains a new option text, which marks the connection as\ntext-oriented (so e.g. pushBack() works). It is still always\nopened in binary mode.\nThe import() namespace directive now accepts an argument except\nwhich names symbols to exclude from the imports. The except\nexpression should evaluate to a character vector (after substituting\nsymbols for strings). See Writing R Extensions.\nNew convenience function Rcmd() in package tools for invoking\nR CMD tools from within R.\nNew functions makevars_user() and makevars_site() in package\ntools to determine the location of the user and site specific\nMakevars files for customizing package compilation.\n\n\nUTILITIES\nR CMD check has a new option –ignore-vignettes for use with\nnon-Sweave vignettes whose VignetteBuilder package is not\navailable.\nR CMD check now by default checks code usage (via\ncodetools) with\nonly the base package attached. Functions from default packages\nother than base which are used in the package code but not\nimported are reported as undefined globals, with a suggested\naddition to the NAMESPACE file.\nR CMD check –as-cran now also checks DOIs in package CITATION\nand Rd files.\nR CMD Rdconv and R CMD Rd2pdf each have a new option\n–RdMacros=pkglist which allows Rd macros to be specified before\nprocessing.\n\n\nDEPRECATED AND DEFUNCT\nThe previously included versions of zlib, bzip2, xz and PCRE\nhave been removed, so suitable external (usually system) versions\nare required (see the ‘R Installation and Administration’ manual).\nThe unexported and undocumented Windows-only devices cairo_bmp(),\ncairo_png() and cairo_tiff() have been removed. (These devices\nshould be used as e.g. bmp(type = \"cairo\").)\n(Windows only) Function setInternet2() has no effect and will be\nremoved in due course. The choice between methods \"internal\" and\n\"wininet\" is now made by the method arguments of url() and\ndownload.file() and their defaults can be set via options. The\nout-of-the-box default remains \"wininet\" (as it has been since R\n3.2.2).\n[<- with an S4 value into a list currently embeds the S4 object\ninto its own list such that the end result is roughly equivalent to\nusing [[<-. That behavior is deprecated. In the future, the S4\nvalue will be coerced to a list with as.list().\nPackage tools’ functions package.dependencies(), pkgDepends(),\netc are deprecated now, mostly in favor of package_dependencies()\nwhich is both more flexible and efficient.\n\n\nINSTALLATION and INCLUDED SOFTWARE\nSupport for very old versions of valgrind (e.g., 3.3.0) has been\nremoved.\nThe included libtool script (generated by configure) has been\nupdated to version 2.4.6 (from 2.2.6a).\nlibcurl version 7.28.0 or later with support for the https\nprotocol is required for installation (except on Windows).\nBSD networking is now required (except on Windows) and so\ncapabilities(\"http/ftp\") is always true.\nconfigure uses pkg-config for PNG, TIFF and JPEG where this is\navailable. This should work better with multiple installs and with\nthose using static libraries.\nThe minimum supported version of OS X is 10.6 (‘Snow Leopard’): even\nthat has been unsupported by Apple since 2012.\nThe configure default on OS X is –disable-R-framework: enable\nthis if you intend to install under /Library/Frameworks and use\nwith R.app.\nThe minimum preferred version of PCRE has since R 3.0.0 been 8.32\n(released in Nov 2012). Versions 8.10 to 8.31 are now deprecated\n(with warnings from configure), but will still be accepted until R\n3.4.0.\nconfigure looks for C functions __cospi, __sinpi and __tanpi\nand uses these if cospi etc are not found. (OS X is the main\ninstance.)\n(Windows) R is now built using gcc 4.9.3. This build will require\nrecompilation of at least those packages that include C++ code, and\npossibly others. A build of R-devel using the older toolchain will\nbe temporarily available for comparison purposes.\nDuring the transition, the environment variable R_COMPILED_BY has\nbeen defined to indicate which toolchain was used to compile R (and\nhence, which should be used to compile code in packages). The\nCOMPILED_BY variable described below will be a permanent\nreplacement for this.\n(Windows) A make and R CMD config variable named COMPILED_BY\nhas been added. This indicates which toolchain was used to compile R\n(and hence, which should be used to compile code in packages).\n\n\nPACKAGE INSTALLATION\nThe make macro AWK which used to be made available to files such\nas src/Makefile is no longer set.\n\n\nC-LEVEL FACILITIES\nThe API call logspace_sum introduced in R 3.2.0 is now remapped as\nan entry point to Rf_logspace_sum, and its first argument has\ngained a const qualifier.\n(PR#16470)\nCode using it will need to be reinstalled.\nSimilarly, entry point log1pexp also defined in Rmath.h is\nremapped there to Rf_log1pexp\nR_GE_version has been increased to 11.\nNew API call R_orderVector1, a faster one-argument version of\nR_orderVector.\nWhen R headers such as R.h and Rmath.h are called from C++ code\nin packages they include the C++ versions of system headers such as\n<cmath> rather than the legacy headers such as <math.h>.\n(Headers Rinternals.h and Rinterface.h already did, and\ninclusion of system headers can still be circumvented by defining\nNO_C_HEADERS, including as from this version for those two\nheaders.)\nThe manual has long said that R headers should not be included\nwithin an extern \"C\" block, and almost all the packages affected\nby this change were doing so.\nIncluding header S.h from C++ code would fail on some platforms,\nand so gives a compilation error on all.\nThe deprecated header Rdefines.h is now compatible with defining\nR_NO_REMAP.\nThe connections API now includes a function R_GetConnection()\nwhich allows packages implementing connections to convert R\nconnection objects to Rconnection handles used in the API. Code\nwhich previously used the low-level R-internal getConnection()\nentry point should switch to the official API.\n\n\nBUG FIXES\nC-level asChar(x) is fixed for when x is not a vector, and it\nreturns \"TRUE\"/\"FALSE\" instead of \"T\"/\"F\" for logical\nvectors.\nThe first arguments of .colSums() etc (with an initial dot) are\nnow named x rather than X (matching colSums()): thus error\nmessages are corrected.\nA coef() method for class \"maov\" has been added to allow\nvcov() to work with multivariate results.\n(PR#16380)\nmethod = \"libcurl\" connections signal errors rather than\nretrieving HTTP error pages (where the ISP reports the error).\nxpdrows.data.frame() was not checking for unique row names; in\nparticular, this affected assignment to non-existing rows via\nnumerical indexing.\n(PR#16570)\ntail.matrix() did not work for zero rows matrices, and could\nproduce row “labels” such as \"[1e+05,]\".\nData frames with a column named \"stringsAsFactors\" now format and\nprint correctly.\n(PR#16580)\ncor() is now guaranteed to return a value with absolute value less\nthan or equal to 1.\n(PR#16638)\nArray subsetting now keeps names(dim(.)).\nBlocking socket connection selection recovers more gracefully on\nsignal interrupts.\nThe data.frame method of rbind() construction row.names works\nbetter in borderline integer cases, but may change the names\nassigned.\n(PR#16666)\n(X11 only) getGraphicsEvent() miscoded buttons and missed mouse\nmotion events.\n(PR#16700)\nmethods(round) now also lists round.POSIXt.\ntar() now works with the default files = NULL.\n(PR#16716)\nJumps to outer contexts, for example in error recovery, now make\nintermediate jumps to contexts where on.exit() actions are\nestablished instead of trying to run all on.exit() actions before\njumping to the final target. This unwinds the stack gradually,\nreleases resources held on the stack, and significantly reduces the\nchance of a segfault when running out of C stack space. Error\nhandlers established using withCallingHandlers() and\noptions(\"error\") specifications are ignored when handling a C\nstack overflow error as attempting one of these would trigger a\ncascade of C stack overflow errors. (These changes resolve\nPR#16753.)\nThe spacing could be wrong when printing a complex array. (Report\nand patch by Lukas Stadler.)\npretty(d, n, min.n, *) for date-time objects d works again in\nborder cases with large min.n, returns a labels attribute also\nfor small-range dates and in such cases its returned length is\ncloser to the desired n.\n(PR#16761)\nAdditionally, it finally does cover the range of d, as it always\nclaimed.\ntsp(x) <- NULL did not handle correctly objects inheriting from\nboth \"ts\" and \"mts\".\n(PR#16769)\ninstall.packages() could give false errors when\noptions(\"pkgType\") was \"binary\". (Reported by Jose Claudio\nFaria.)\nA bug fix in R 3.0.2 fixed problems with locator() in X11, but\nintroduced problems in Windows. Now both should be fixed.\n(PR#15700)\ndownload.file() with method = \"wininet\" incorrectly warned of\ndownload file length difference when reported length was unknown.\n(PR#16805)\ndiag(NULL, 1) crashed because of missed type checking.\n(PR#16853)\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2016-1-user2016/",
    "title": "Conference Report: useR! 2016",
    "description": "The 'Conference Report: useR! 2016' article from the 2016-1 issue.",
    "author": [
      {
        "name": "Joseph Rickert",
        "url": {}
      }
    ],
    "date": "2016-06-01",
    "categories": [],
    "contents": "\n\n1 Overview\nThe 12th international R user conference, useR! 2016, took place at\nStanford University, Stanford CA from June 27 through June 30th. Hosted\nby the Stanford University Department of Statistics and the Stanford\nLibraries, the conference took place at the Frances Arrillaga Alumni\nCenter, on the surrounding lawns and in several adjacent buildings. The\nfloor to ceiling windows of the larger conference rooms, the garden\nlocations for coffee and meals and the beautiful weather contributed to\nmaking the event a classic California experience.\nOriginally planned for 750 people, a slight increase over the 660\nattendee total for last year’s conference in Denmark, useR! 2016 sold\nout completely during the first few weeks. Although the final attendee\nlist eventually topped out at just over 900 people, it nevertheless\nexcluded many from both academia and industry who were seeking tickets.\nTo mitigate the disappointment, the conference organizers arranged to\n“live stream” the keynote sessions over the internet and to record many\nof the contributed talks. Many thanks to Microsoft Corporation which\nprovided the expertise and financing for the video recording, and to\nmany other corporate sponsors who made possible student scholarships,\ndaily free lunches, a continuous flow of coffee and fruit juices, and a\nsocial program that included a cocktail reception and a Hornblower Yacht\ncruise on the San Francisco Bay.\nThe Gordon and Betty Moore foundation helped fund 17 Diversity\nScholarship awards overseen by a committee consisting of Scott\nChamberlain, Amy Lee, Gabriela de Queiroz and Karthik Ram (chair). In\naddition, the American Statistical Association provided funds to award\n$2,500 each to two outstanding young useRs, Helen Ogden (University of\nWarwick) and Tong He (Simon Fraser University) chosen by the Program\nCommittee.\nThe program consisted of 18 pre-conference tutorials, 6 invited talks,\n146 oral presentations, 45 lightning talks and 60 poster sessions.\n2 Pre-conference Tutorials\nThe pre-conference tutorials were free and open to all attendees.\nRegression Modeling Strategies and the rms Package - Frank Harrell\nUsing Git and GitHub with R, RStudio, and R Markdown - Jennifer\nBryan\nEffective Shiny Programming - Joe Cheng\nMissing Value Imputation with R - Julie Josse\nExtracting data from the web APIs and beyond - Scott Chamberlain,\nGarrett Grolemund and Karthik Ram\nNinja Moves with data.table - Learn by Doing in a Cookbook Style\nWorkshop - Matt Dowle and Arun Srinivasan\nNever Tell Me the Odds! Machine Learning with Class Imbalances - Max\nKuhn\nMoRe than woRds, Text and Context: Language Analytics in Finance\nwith R - Sanjiv Das and Karthik Mokashi\nHandling and Analyzing Spatial, Spatiotemporal and Movement Data -\nEdzer Pebesma\nMachine Learning Algorithmic Deep Dive- Erin LeDell\nIntroduction to SparkR- Hossein Falaki and Shivaram Venkataraman\nUsing R with Jupyter Notebooks for Reproducible Research - Andrie de\nVries and Micheleen Harris\nUnderstanding and Creating Interactive Graphics - Claus Thorn\nEkstrøm and Toby Dylan Hocking\nGenome-Wide Association Analysis and Post-Analytic Interrogation\nwith R - Andrea S. Foulkes\nAn Introduction to Bayesian Inference using R Interfaces to Stan -\nBen Goodrich\nSmall Area Estimation with R - Virgilio Gómez Rubio\nDynamic Documents with R Markdown- Yihui Xie\n3 Invited talks\nThe invited, plenary talks began with a retrospective look at the\ndevelopment of the S and R languages, discussed topics concerned with\ngood programming practice and touched on topics essential to the\ndeveloping field of Data Science.\nForty years of S - Richard Becker\nLiterate Programming - Donald Knuth\nTowards a grammar of interactive graphics - Hadley Wickham\nFlexible and Interpretable Regression Using Convex Penalties -\nDaniela Witten\nStatistical Thinking in a Data Science Course - Deborah Nolan\nRCloud - Collaborative Environment for Visualization and Big Data\nAnalytics - Simon Urbanek\n4 Contributed Sessions\nThe contributed talks were organized into 5 parallel tracks with\nsessions devoted to: Bayesian Statistics, Bioinformatics, Case Studies,\nDatabases, Generalized Mixed Models, Graphics, Packages and Development,\nPerformance, R in Business, R and Other Languages, Regression,\nReproducible Research, Spatial Statistics, Statistical Methods,\nStatistics and Big Data, Teaching and sessions devoted to our sponsors,\nmiscellaneous talks organized under Kaleidoscope sessions and lightning\ntalks.\n5 Conference Organizers\nThe strong, diverse technical program was the work of program committee\nmembers Jenny Bryan, Dianne Cook, Peter Dalgaard, Dirk Eddelbuettel,\nSusan Holmes, Torsten Hothorn, Julie Josse (Chair), Patrick Mair, Jeroen\nOoms, Hilary Parker, Hana Ševčíková, Torben Tvedebrink and Heather\nTurner.\nThe conference would not have been possible without the tireless work of\nBalasubramanian Narasimhan who led the organizing committee: John\nChambers, Sandrine Dudoit, Trevor Hastie, Susan Holmes, Simon Jackman,\nOlivia Lau, Nicholas Lewin-Koh, Norman Matloff, Jacqueline Meulman,\nBalasubramanian Narasimhan, Karthik Ram, Joseph Rickert and Duncan\nTemple Lang. The cheerful presence and help provided by student\nvolunteers chosen from the R community helped make the conference a\npleasant experience for all attendees.\n6 Additional Information\nuseR!2106 website\n\nhttp://user2016.org/\n\nVideo recordings\n\nhttps://channel9.msdn.com/Events/useR-international-R-User-conference/useR2016\n\nCorporate sponsors\n\nhttp://user2016.org/#sponsors\n\nTutorial perspective\n\nhttp://blog.revolutionanalytics.com/2016/06/the-user-2016-tutorials.html\n\nPackage perspective\n\nhttp://blog.revolutionanalytics.com/2016/06/the-r-packages-of-user-2016.html\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2015-2-bioconductor/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2015-2 issue.",
    "author": [
      {
        "name": "Bioconductor Team",
        "url": {}
      }
    ],
    "date": "2015-12-01",
    "categories": [],
    "contents": "\n\nThe Bioconductor project provides tools for\nthe analysis and comprehension of high-throughput genomic data. The 1104\nsoftware packages available in Bioconductor can be viewed at\nhttp://bioconductor.org/packages/. Navigate packages using ‘biocViews’\nterms and title search. Each package has an html page with a\ndescription, links to vignettes, reference manuals, and usage\nstatistics. Start using Bioconductor version 3.2 by installing R 3.2.3\nand evaluating the commands\n  source(\"http://bioconductor.org/biocLite.R\")\n  biocLite()\nInstall additional packages and dependencies, e.g.,\nAnnotationHub,\nwith\n  source(\"http://bioconductor.org/biocLite.R\")\n  biocLite(\"AnnotationHub\")\n1 Bioconductor 3.2 Release Highlights\nBioconductor 3.2 was released on 14 October 2015. It is compatible with\nR 3.2 and consists of 1104 software packages, 257 experiment data\npackages, and 917 up-to-date annotation packages. There are 80 new\nsoftware packages and many updates and improvements to existing\npackages. The release\nannouncement includes\ndescriptions of new packages and updated NEWS files provided by package\nmaintainers.\nOur collection of microarray, transcriptome and organism-specific\nannotation packages use the ‘select’ interface (keys, columns,\nkeytypes) to access static information on gene annotations (org.*\npackages) and gene models (TxDb.* packages); these augment packages\nsuch as\nbiomaRt\nfor interactive querying of web-based resources. The AnnotationHub\ncontinues to complement our traditional offerings with diverse whole\ngenome annotations from Ensembl, ENCODE, dbSNP, UCSC, and elsewhere;\nexample uses are described in the AnnotationHub\nHow-To\nvignette.\n2 Other activities\nThe Bioconductor project has moved from the Fred Hutchinson Cancer\nResearch Center to Roswell Park Cancer Institute, in Buffalo, NY. The\ntransition has brought with it many challenges and opportunities,\nincluding the departure of some long-term project personnel and the\naddition of new team members. In particular, Marc Carlson, Sonali Arora\nand Paul Shannon were instrumental in the design and implementation of\nAnnotationHub (and annotations in general), tools for biological\nnetwork analysis, educational material and many other areas. The\nBioconductor community is grateful to them for their many valuable\ncontributions.\nThe Bioconductor F1000 research\nchannel is a\nrecently-launched forum for publication of task-oriented work flows. The\nchannel is peer-reviewed, providing authors with a compelling venue for\ndissemination of their analysis methods. Users gain fully reproducible\ndescriptions of tasks that cover current, genome-scale analysis problem\nfrom start to finish.\nThe Bioconductor support forum plays\nan increasing important role in providing with timely, knowledgeable,\nand accurate answers to user questions. A particularly valuable feature\nis the opportunity for community members to announce tutorial and other\navailability, such as Bioconductor for Genomic Data\nScience offered by long-term\ncontributor Kasper D. Hansen. A highlight of the Bioconductor European\nDeveloper Meeting, held in Cambridge, UK on 7 and 8 December, was\nrecognition of the contributions Aaron Lun and Michael Love make to the\nsuccess of the Bioconductor support forum through their patient and\nknowledgeable responses to diverse user questions.\nContinued availability of Bioconductor\nDocker and\nAmazon\nimages provides a very effective on-ramp for power users to rapidly\nobtain access to standardized and scalable computing environments.\nDocker images are available for release and development versions of\nBioconductor, with analysis-specific images pre-loaded with packages\nrelevant to common analysis scenarios, e.g., of sequencing, microarray,\nflow cell, or proteomic data. Both Amazon and Docker images include\nRstudio Server for easy web-browser based access.\nNew Bioconductor package contributors are encouraged to consult the\npackage\nguidelines and\nsubmission\nsections of the Bioconductor web site, and use the\nBiocCheck\npackage, in addition to R CMD check, for guidance on conforming to\nBioconductor package standards. New package submissions are\nautomatically built across Linux, Mac, and Windows platforms, providing\nan opportunity to address cross-platform issues; many new package\ncontributors take advantage of this facility to refine their package\nbefore it is subject to technical preview. Keep abreast of packages\nadded to the ‘devel’ branch and other activities by following\n@Bioconductor on Twitter.\nThe Bioconductor web site advertises training and community\nevents, including the BioC 2016,\nthe Bioconductor annual conference, to be held in Stanford, CA,\nimmediately before the annual useR! conference, Friday through Sunday,\n24–25 June.\n\n\nBioconductor packages used\nAnnotationHub, biomaRt, BiocCheck\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2015-2-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2015-2 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2015-12-01",
    "categories": [],
    "contents": "\n\nNew packages in CRAN task views\nBayesian\n\neco, rstan.\n\nChemPhys\n\ncompositions.\n\nClinicalTrials\n\nsamplesize.\n\nCluster\n\nBayesLCA, NbClust, dbscan, longclust.\n\nDistributions\n\nBivarP, CompGLM, Compounding, DiscreteLaplace,\nDiscreteWeibull, EMMIXskew, ExtDist, FMStable, GIGrvg,\nGenBinomApps, GenOrd, HAC, JohnsonDistribution, LIHNPSD,\nMM, MitISEM, MixedTS, NormalLaplace, ORDER2PARENT,\nOrdNor, PerMallows, SCI, TTmoment, csn, degreenet,\ndirmult, disclap, emg, fpow, frmqa, gambin, gb,\ngldist, kolmim, logitnorm, minimax, mnormpow, mvprpb,\nnCDunnett, polyaAeppli, poweRlaw, qmap, rtdists,\nsfsmisc, skellam, symmoments, vines.\n\nEconometrics\n\ngets, midasr, sfa, spfrontier, ssfa.\n\nEnvironmetrics\n\neco, mra.\n\nExperimentalDesign\n\nALTopt, Crossover, EngrExpt, LDOD, MAMS, MaxPro,\nOPDOE, OptGS, OptInterim, PopED, VdgRsm, agridat,\nbcrm, blockTools, blocksdesign, daewr, designGG, geospt,\noapackage, pipe.design, rodd, simrel, sp23design,\ntoxtestD.\n\nFinance\n\nFatTailsR, PortRisk, Rblpapi, covmat, credule.\n\nHighPerformanceComputing\n\nflowr, future, partDSA, toaster.\n\nMachineLearning\n\nFCNN4R, Rborist, ranger.\n\nMetaAnalysis\n\nMetaPath, RcmdrPlugin.RMTCJags, etma, joint.Cox,\nmeta4diag, metaSEM, metagear, xmeta.\n\nMultivariate\n\ncwhmisc, delt, knncat.\n\nNaturalLanguageProcessing\n\nstringi, textreuse.\n\nNumericalMathematics\n\nPade, lamW, mvQuad.\n\nOfficialStatistics\n\nhot.deck, mipfp.\n\nOptimization\n\nECOSolveR, NlcOptim, Rdsdp, bvls, copulaedas, kofnGA,\nlbfgsb3, matchingR, nls2, nnls, onls, qap, tabuSearch.\n\nPhylogenetics\n\nSigTree, markophylo, pmc.\n\nPsychometrics\n\nOpenMx, pwrRasch.\n\nReproducibleResearch\n\npapeR.\n\nSocialSciences\n\nAmelia, MCMCglmm\\(^*\\), PAFit, PSAgraphics, RSiena,\nVGAM\\(^*\\), VIM, arm, betareg, biglm, catspec,\ndemography, dispmod, elrm, ergm, influence.ME, logistf,\nlogmult, lsmeans\\(^*\\), mi\\(^*\\), mlogit, multgee,\nmultiplex, nlstools, norm, np, simpleboot, statnet,\nvisreg.\n\nSpatial\n\nOasisR, rgrass7, spBayesSurv, spatsurv, tmap.\n\nSpatioTemporal\n\nSTMedianPolish, ctmcmove, ctmm, moveHMM, rsatscan.\n\nSurvival\n\ndynpred, glrt, parfm, survJamda.\n\nTimeSeries\n\nEMD, LSTS, PCA4TS, Rlibeemd, TSMining, Wats, ZIM,\nautovarCore, bentcableAR, changepoint, dtwclust, ecp,\nfanplot, hht, imputeTS, jmotif, mlVAR, spectral.methods,\ntseriesEntropy, wbsts.\n\nWebTechnologies\n\nRSocrata, bigml, googlePublicData, htmltab, pxweb,\nrsnps.\n\ngR\n\nBDgraph, FBFsearch, huge, ndtv, networkDynamic.\n\n(* = core package)\n1 New contributed packages\nACDm\n\nTools for Autoregressive Conditional Duration Models. Author: Markus\nBelfrage.\n\nACSNMineR\n\nGene Enrichment Analysis from ACSN Maps or Gmt Files. Authors: Paul\nDeveau [aut, cre], Eric Bonnet [aut].\n\nACSWR\n\nA Companion Package for the Book “A Course in Statistics with R”.\nAuthor: Prabhanjan Tattar.\n\nAF\n\nModel-Based Estimation of Confounder-Adjusted Attributable\nFractions. Authors: Elisabeth Dahlqwist and Arvid Sjolander.\n\nAFM\n\nAtomic Force Microscope Image Analysis. Authors: Mathieu Beauvais\n[aut, cre], Irma Liascukiene [aut], Jessem Landoulsi [aut].\n\nAHR\n\nEstimation and Testing of Average Hazard Ratios. Author: Matthias\nBrueckner.\n\nANOM\n\nAnalysis of Means. Author: Philip Pallmann.\n\nAPSIM\n\nGeneral Utility Functions for the ‘Agricultural Production Systems\nSimulator’. Author: Justin Fainges.\n\nART\n\nAligned Rank Transform for Nonparametric Factorial Analysis. Author:\nPablo J. Villacorta.\n\nAdaptGauss\n\nGaussian Mixture Models (GMM). Authors: Michael Thrun, Onno\nHansen-Goos, Rabea Griese, Catharina Lippmann, Jorn Lotsch, Alfred\nUltsch.\n\nAggregateR\n\nAggregate Numeric, Date and Categorical Variables by an ID. Authors:\nMatthias Bogaert, Michel Ballings, Dirk Van den Poel.\n\nAlgebraicHaploPackage\n\nHaplotype Two Snips Out of a Paired Group of Patients. Author: Jan\nWolfertz.\n\nArgumentCheck\n\nImproved Communication to Users with Respect to Problems in Function\nArguments. Author: Benjamin Nutter.\n\nAssocTests\n\nGenetic Association Studies. Authors: Lin Wang [aut], Wei Zhang\n[aut], Qizhai Li [aut], Weicheng Zhu [ctb].\n\nAutoModel\n\nAutomated Hierarchical Multiple Regression with Assumptions\nChecking. Author: Alex Lishinski.\n\nAutoregressionMDE\n\nMinimum Distance Estimation in Autoregressive Model. Author: Jiwoong\nKim.\n\nAzureML\n\nDiscover, Publish and Consume Web Services on Microsoft Azure\nMachine Learning. Authors: Raymond Laghaeian [aut, cre], Brianna\nGerads [aut], Ritika Ravichandra [aut], Alex Wang [aut].\n\nBCEE\n\nThe Bayesian Causal Effect Estimation Algorithm. Authors: Denis\nTalbot, Geneviève Lefebvre, Juli Atherton.\n\nBEDMatrix\n\nMatrices Backed by Binary PED Files (PLINK). Authors: Alexander\nGrueneberg [aut, cre], Lian Lian [ctb], Gustavo de los Campos\n[ctb].\n\nBIGDAWG\n\nCase-Control Analysis of Multi-Allelic Loci. Authors: Derek Pappas,\nSteve Mack, Jill Hollenbach.\n\nBTLLasso\n\nModelling Heterogeneity in Paired Comparison Data. Author: Gunther\nSchauberger.\n\nBagidis\n\nBAses GIving DIStances. Author: Catherine Timmermans.\n\nBayesBD\n\nBayesian Boundary Detection in Images. Author: Meng Li.\n\nBayesMAMS\n\nDesigning Bayesian Multi-Arm Multi-Stage Studies. Authors: Philip\nPallmann, Amanda Turner.\n\nBiTrinA\n\nBinarization and Trinarization of One-Dimensional Data. Authors:\nStefan Mundus, Christoph Müssel, Florian Schmid, Ludwig Lausser,\nTamara J. Blätte, Martin Hopfensitz, Hans A. Kestler.\n\nBiocomb\n\nFeature Selection and Classification with the Embedded Validation\nProcedures for Biomedical Data Analysis. Authors: Natalia\nNovoselova, Junxi Wang, Frank Pessler, Frank Klawonn.\n\nBlossom\n\nStatistical Comparisons with Distance-Function Based Permutation\nTests. Authors: Marian Talbert, Jon Richards, Paul Mielke, and Brian\nCade.\n\nCALF\n\nCoarse Approximation Linear Function. Authors: Stephanie Lane [aut,\ncre], Clark Jeffries [aut], Diana Perkins [aut].\n\nCANSIM2R\n\nDirectly Extracts Complete CANSIM Data Tables. Author: Marco Lugo.\n\nCOMBIA\n\nSynergy/Antagonism Analyses of Drug Combinations. Author: Muhammad\nKashif.\n\nCTTShiny\n\nClassical Test Theory via Shiny. Authors: William Kyle Hamilton\n[aut, cre], Atsushi Mizumoto [aut].\n\nCUB\n\nA Class of Mixture Models for Ordinal Data. Authors: Maria Iannario,\nDomenico Piccolo.\n\nCUSUMdesign\n\nCompute Decision Interval and Average Run Length for CUSUM Charts.\nAuthors: Douglas M. Hawkins, David H. Olwell, Boxiang Wang.\n\nCanopy\n\nAccessing Intra-Tumor Heterogeneity and Tracking Longitudinal and\nSpatial Clonal Evolutionary History by Next-Generation Sequencing.\nAuthors: Yuchao Jiang, Nancy R. Zhang.\n\nCensMixReg\n\nCensored Linear Mixture Regression Models. Authors: Luis Benites\nSanchez, Victor Hugo Lachos.\n\nChannelAttribution\n\nMarkov Model for the Online Multi-Channel Attribution Problem.\nAuthor: Davide Altomare.\n\nCircOutlier\n\nDetecting of Outliers in Circular Regression. Authors: Azade\nGhazanfarihesari, Majid Sarmad.\n\nClamR\n\nTime Series Modeling for Climate Change Proxies. Author: Jonathan M.\nLees.\n\nClustGeo\n\nClustering of Observations with Geographical Constraints. Authors:\nAmaury Labenne, Marie Chavent, Vanessa Kuentz-Simonet and Jerome\nSaracco.\n\nClusterStability\n\nAssessment of Stability of Individual Objects or Clusters in\nPartitioning Solutions. Authors: Etienne Lord, Francois-Joseph\nLapointe, and Vladimir Makarenkov.\n\nCombine\n\nGame-Theoretic Probability Combination. Authors: Alaa Ali, Marta\nPadilla and David R. Bickel.\n\nCommT\n\nComparative Phylogeographic Analysis using the Community Tree\nFramework. Author: Michael Gruenstaeudl.\n\nCompR\n\nPaired Comparison Data Analysis. Author: Michel Semenou.\n\nCompareCausalNetworks\n\nInterface to Diverse Estimation Methods of Causal Networks. Authors:\nChristina Heinze, Nicolai Meinshausen.\n\nComplexAnalysis\n\nNumerically Evaluate Integrals and Derivatives (also Higher Order)\nof Vector- And Complex-Valued Functions. Author: Char Leung.\n\nConsRank\n\nCompute the Median Ranking(s) According to the Kemeny’s Axiomatic\nApproach. Authors: Antonio D’Ambrosio, Sonia Amodio.\n\nCopyNumber450kCancer\n\nBaseline Correction for Copy Number Data from Cancer Samples.\nAuthor: Nour-al-dain Marzouka [aut, cre].\n\nCoxPlus\n\nCox Regression (Proportional Hazards Model) with Multiple Causes and\nMixed Effects. Author: Jing Peng.\n\nCryptRndTest\n\nStatistical Tests for Cryptographic Randomness. Author: Haydar\nDemirhan.\n\nD3M\n\nTwo Sample Test with Wasserstein Metric. Author: Yusuke Matsui &\nTeppei Shimamura.\n\nDCchoice\n\nAnalyzing Dichotomous Choice Contingent Valuation Data. Authors:\nTomoaki Nakatani [aut, cph] (original developer), Hideo Aizaki\n[aut, cre] (code patches), Kazuo Sato [ctb] (theoretical part of\nthe manual).\n\nDIFboost\n\nDetection of Differential Item Functioning (DIF) in Rasch Models by\nBoosting Techniques. Author: Gunther Schauberger.\n\nDJL\n\nDistance Measure Based Judgment and Learning. Author: Dong-Joon Lim.\n\nDRIP\n\nDiscontinuous Regression and Image Processing. Author: Yicheng Kang.\n\nDT\n\nA Wrapper of the JavaScript Library ‘DataTables’. Authors: Yihui Xie\n[aut, cre], Joe Cheng [ctb], jQuery contributors [ctb, cph]\n(jQuery in htmlwidgets/lib), SpryMedia Limited [ctb, cph]\n(DataTables in htmlwidgets/lib), Brian Reavis [ctb, cph]\n(selectize.js in htmlwidgets/lib), Leon Gersen [ctb, cph]\n(noUiSlider in htmlwidgets/lib), Bartek Szopka [ctb, cph]\n(jquery.highlight.js in htmlwidgets/lib), RStudio Inc [cph]. In\nview:\nReproducibleResearch.\n\nDTRlearn\n\nLearning Algorithms for Dynamic Treatment Regimes. Authors: Ying\nLiu, Yuanjia Wang, Donglin Zeng.\n\nDYM\n\nDid You Mean? Author: Kosei Abe.\n\nDataLoader\n\nImport Multiple File Types. Authors: Srivenkatesh Gandhi, Kreshnaa\nRaam S Bethusamy.\n\nDiffusionRgqd\n\nInference and Analysis for Generalized Quadratic Diffusions.\nAuthors: Etienne A.D. Pienaar [aut, cre], Melvin M. Varughese\n[ctb].\n\nDirectional\n\nDirectional Statistics. Authors: Michail Tsagris, Giorgos Athineou.\n\nDynTxRegime\n\nMethods for Estimating Dynamic Treatment Regimes. Authors: S. T.\nHolloway, E. B. Laber, K. A. Linn, B. Zhang, M. Davidian, and A. A.\nTsiatis.\n\nECOSolveR\n\nEmbedded Conic Solver in R. Authors: Anqi Fu [aut],\nBalasubramanian Narasimhan [aut, cre]. In view:\nOptimization.\n\nEDFIR\n\nEstimating Discrimination Factors. Authors: Alex Bond and Robert\nRobere.\n\nEEM\n\nRead and Preprocess Fluorescence Excitation-Emission Matrix (EEM)\nData. Author: Vipavee Trivittayasil.\n\nEGRETci\n\nExploration and Graphics for RivEr Trends (EGRET) Confidence\nIntervals. Authors: Robert Hirsch [aut], Laura DeCicco [aut,\ncre].\n\nELMR\n\nExtreme Machine Learning (ELM). Author: Alessio Petrozziello [aut,\ncre].\n\nEMbC\n\nExpectation-Maximization Binary Clustering. Authors: Joan Garriga,\nJohn R.B. Palmer, Aitana Oltra, Frederic Bartumeus.\n\nEPGLM\n\nGaussian Approximation of Bayesian Binary Regression Models. Author:\nJames Ridgway.\n\nESKNN\n\nEnsemble of Subset of K-Nearest Neighbours Classifiers for\nClassification and Class Membership Probability Estimation. Authors:\nAsma Gul, Aris Perperoglou, Zardad Khan, Osama Mahmoud, Werner\nAdler, Miftahuddin Miftahuddin, and Berthold Lausen.\n\nEditImputeCont\n\nSimultaneous Edit-Imputation for Continuous Microdata. Authors:\nQuanli Wang, Hang J. Kim, Jerome P. Reiter, Lawrence H. Cox and\nAlan F. Karr.\n\nEloChoice\n\nPreference Rating for Visual Stimuli Based on Elo Ratings. Author:\nChristof Neumann.\n\nEpiBayes\n\nImplements Hierarchical Bayesian Models for Epidemiological\nApplications. Authors: Matthew Branan, Marta Remmenga, Lori\nGustafson, Jennifer Hoeting.\n\nEstHer\n\nEstimation of Heritability in High Dimensional Sparse Linear Mixed\nModels using Variable Selection. Authors: Anna Bonnet and Celine\nLevy-Leduc.\n\nEurosarcBayes\n\nBayesian Single Arm Sample Size Calculation Software. Author: Peter\nDutton.\n\nExplainPrediction\n\nExplanation of Predictions for Classification and Regression Models.\nAuthor: Marko Robnik-Sikonja.\n\nFACTMLE\n\nMaximum Likelihood Factor Analysis. Authors: Koulik Khamaru, Rahul\nMazumder.\n\nFCGR\n\nFatigue Crack Growth in Reliability. Authors: Antonio Meneses,\nSalvador Naya, Javier Tarrio-Saavedra, Ignacio Lopez-Ullibarri.\n\nFCNN4R\n\nFast Compressed Neural Networks for R. Author: Grzegorz Klima. In\nview:\nMachineLearning.\n\nFENmlm\n\nFixed Effects Nonlinear Maximum Likelihood Models. Author: Laurent\nBerge.\n\nFIACH\n\nRetrospective Noise Control for fMRI. Author: Tim Tierney.\n\nFSA\n\nFunctions for Simple Fisheries Stock Assessment Methods. Author:\nDerek Ogle [aut, cre].\n\nFSAdata\n\nData to Support Fish Stock Assessment (FSA) Package. Author: Derek\nOgle [aut, cre].\n\nFastBandChol\n\nFast Estimation of a Covariance Matrix by Banding the Cholesky\nFactor. Author: Aaron Molstad.\n\nFastGP\n\nEfficiently Using Gaussian Processes with Rcpp and RcppEigen.\nAuthors: Giri Gopalan, Luke Bornn.\n\nFastKM\n\nA Fast Multiple-Kernel Method Based on a Low-Rank Approximation.\nAuthors: Rachel Marceau, Wenbin Lu, Michele M. Sale, Bradford B.\nWorrall, Stephen R. Williams, Fang-Chi Hsu, Jung-Ying Tzeng, and\nShannon T. Holloway.\n\nFgmutils\n\nForest Growth Model Utilities. Authors: Clayton Vieira Fraga, Ana\nPaula Simiqueli, Wagner Amorim da Silva Altoe.\n\nForecastCombinations\n\nForecast Combinations. Author: Eran Raviv. In view:\nTimeSeries.\n\nFractalParameterEstimation\n\nEstimation of Parameters p and q for Randomized Sierpinski Carpet\nfor [p-p-p-q]-Model. Author: Philipp Hermann.\n\nFragman\n\nFragment Analysis in R. Authors: Giovanny Covarrubias-Pazaran, Luis\nDiaz-Garcia, Brandon Schlautman, Walter Salazar, Juan Zalapa.\n\nFuzzyLP\n\nFuzzy Linear Programming. Authors: Carlos A. Rabelo [aut, cre],\nPablo J. Villacorta [ctb].\n\nGERGM\n\nEstimation and Fit Diagnostics for Generalized Exponential Random\nGraph Models. Authors: Matthew J. Denny, James D. Wilson, Skyler\nCranmer, Bruce A. Desmarais, Shankar Bhamidi.\n\nGFD\n\nTests for General Factorial Designs. Authors: Sarah Friedrich, Frank\nKonietschke, Markus Pauly.\n\nGSSE\n\nGenotype-Specific Survival Estimation. Authors: Baosheng Liang,\nYuanjia Wang and Donglin Zeng.\n\nGenCAT\n\nGenetic Class Association Testing (GenCAT). Authors: Eric Reed, Sara\nNuñez, Jing Qian, Andrea Foulkes.\n\nGeneralOaxaca\n\nBlinder-Oaxaca Decomposition for Generalized Linear Model. Authors:\nAurelien Nicosia and Simon Baillargeon-Ladouceur.\n\nGeoBoxplot\n\nGeographic Box Plot. Author: Ao Li.\n\nGiANT\n\nGene Set Uncertainty in Enrichment Analysis. Authors: Florian\nSchmid, Christoph Müssel, Johann M. Kraus, Hans A. Kestler.\n\nGoslate\n\nGoslate Interface. Authors: Author: Florian Schwendinger [aut,\ncre], Kurt Hornik [cbt], Zhou Qiang [cph].\n\nGrace\n\nGraph-Constrained Estimation and Hypothesis Testing. Author: Sen\nZhao.\n\nGroupTest\n\nMultiple Testing Procedure for Grouped Hypotheses. Author: Zhigen\nZhao.\n\nGsymPoint\n\nEstimation of the Generalized Symmetry Point, an Optimal Cutpoint in\nContinuous Diagnostic Tests. Authors: Mónica López-Ratón, Carmen\nCadarso-Suárez, Elisa M. Molanes-López, Emilio Letón.\n\nHBglm\n\nHierarchical Bayesian Regression for GLMs. Authors: Asad Hasan,\nAlireza S. Mahani.\n\nHDGLM\n\nTests for High Dimensional Generalized Linear Models. Author: Bin\nGuo.\n\nHMDHFDplus\n\nRead HMD and HFD Data from the Web. Authors: Tim Riffe, Carl Boe,\nJosh Goldstein.\n\nHRM\n\nHigh-Dimensional Repeated Measures. Authors: Martin Happ [aut,\ncre], Harrar W. Solomon [aut], Arne C. Bathke [aut].\n\nHarvest.Tree\n\nHarvest the Classification Tree. Author: Bingyuan Liu/Yan Yuan/Qian\nShi.\n\nHiCfeat\n\nMultiple Logistic Regression for 3D Chromatin Domain Border\nAnalysis. Author: Raphael Mourad.\n\nHydeNet\n\nHybrid Bayesian Networks Using R and JAGS. Authors: Jarrod E. Dalton\nand Benjamin Nutter.\n\nICBayes\n\nBayesian Semiparametric Models for Interval-Censored Data. Authors:\nChun Pan, Bo Cai, Lianming Wang, and Xiaoyan Lin.\n\nICC.Sample.Size\n\nCalculation of Sample Size and Power for ICC. Authors: Alasdair\nRathbone [aut, cre], Saurabh Shaw [aut], Dinesh Kumbhare\n[aut].\n\nIDTurtle\n\nIdentify Turtles by their Plastral Biometries. Author: Aitor\nValdeon.\n\nIRISMustangMetrics\n\nStatistics and Metrics for Seismic Data. Authors: Jonathan Callahan\n[aut, cre], Rob Casey [aut], Mary Templeton [aut].\n\nIRISSeismic\n\nClasses and Methods for Seismic Data Analysis. Authors: Jonathan\nCallahan [aut, cre], Rob Casey [aut], Mary Templeton [aut].\n\nITEMAN\n\nClassical Item Analysis. Author: Cengiz Zopluoglu.\n\nIalsaSynthesis\n\nSynthesizing Information Across Collaborating Research. Authors:\nWill Beasley [aut, cre], Andrey Koval [aut], Integrative\nAnalysis of Longitudinal Studies of Aging (IALSA) [cph].\n\nImportExport\n\nImport and Export Data. Authors: Roger Pros, Isaac Subirana, Joan\nVila.\n\nInformation\n\nData Exploration with Information Theory (Weight-of-Evidence and\nInformation Value). Author: Larsen Kim [aut, cre].\n\nInformationValue\n\nPerformance Analysis and Companion Functions for Binary\nClassification Models. Author: Selva Prabhakaran.\n\nIntegratedJM\n\nJoint Modelling of the Gene-Expression and Bioassay Data, Taking\nCare of the Effect Due to a Fingerprint Feature. Authors: Rudradev\nSengupta, Nolen Joy Perualila.\n\nInterSIM\n\nSimulation of Inter-Related Genomic Datasets. Authors: Prabhakar\nChalise, Rama Raghavan, Brooke Fridley.\n\nJGEE\n\nJoint Generalized Estimating Equation Solver. Author: Gul Inan.\n\nJPEN\n\nCovariance and Inverse Covariance Matrix Estimation Using Joint\nPenalty. Author: Ashwini Maurya.\n\nJRF\n\nJoint Random Forest (JRF) for the Simultaneous Estimation of\nMultiple Related Networks. Authors: Francesca Petralia [aut, cre],\nPei Wang [aut], Zhidong Tu [aut], Won-min Song [aut], Adele\nCutler [ctb], Leo Breiman [ctb], Andy Liaw [ctb], Matthew\nWiener [ctb].\n\nJacobiEigen\n\nClassical Jacobi Eigensolution Algorithm. Author: Bill Venables.\n\nKERE\n\nExpectile Regression in Reproducing Kernel Hilbert Space. Authors:\nYi Yang, Teng Zhang, Hui Zou.\n\nKoulMde\n\nKoul’s Minimum Distance Estimation in Linear Regression and\nAutoregression Model. Author: Jiwoong Kim [aut, cre].\n\nLANDD\n\nLiquid Association for Network Dynamics Detection. Authors:\nShangzhao Qiu, Yan Yan, Tianwei Yu.\n\nLFDR.MLE\n\nEstimation of the Local False Discovery Rates by Type II Maximum\nLikelihood Estimation. Authors: Ye Yang, Marta Padilla, Alaa Ali,\nKyle Leckett, Zhenyu Yang, Zuojing Li, Corey M. Yanofsky and\nDavid R. Bickel.\n\nLGEWIS\n\nTests for Genetic Association/Gene-Environment Interaction in\nLongitudinal Gene-Environment-Wide Interaction Studies. Authors:\nZihuai He, Seunggeun Lee, Bhramar Mukherjee, Min Zhang.\n\nLGRF\n\nSet-Based Tests for Genetic Association in Longitudinal Studies.\nAuthor: Zihuai He.\n\nLOGIT\n\nFunctions, Data and Code for Binary and Binomial Data. Authors:\nJoseph M Hilbe, Rafael S. de Souza.\n\nLPM\n\nLinear Parametric Models Applied to Hydrological Series. Authors:\nCorrado Tallerini [aut, cre], Salvatore Grimaldi [aut].\n\nLRcontrast\n\nDose Response Signal Detection under Model Uncertainty. Author:\nKevin Kokot.\n\nLSDinterface\n\nReading LSD Results (.res) Files. Author: Marcelo C. Pereira.\n\nLSTS\n\nLocally Stationary Time Series. Authors: Ricardo Olea, Wilfredo\nPalma, Pilar Rubio. In view:\nTimeSeries.\n\nLangevin\n\nLangevin Analysis in One and Two Dimensions. Authors: Philip Rinn\n[aut, cre], Pedro G. Lind [aut], David Bastine [ctb].\n\nLaplaceDeconv\n\nLaplace Deconvolution with Noisy Discrete Non-Equally Spaced\nObservations on a Finite Time Interval. Authors: Yves Rozenholc and\nMarianna Pensky.\n\nLibra\n\nLinearized Bregman Algorithms for Generalized Linear Models.\nAuthors: Feng Ruan, Jiechao Xiong and Yuan Yao.\n\nLifeHist\n\nLife History Models of Individuals. Author: Ruben H. Roa-Ureta.\n\nLightningR\n\nTools for Communication with Lightning-Viz Server. Author: Ermlab.\n\nLinearRegressionMDE\n\nMinimum Distance Estimation in Linear Regression Model. Author:\nJiwoong Kim [aut, cre].\n\nLinkedMatrix\n\nColumn-Linked and Row-Linked Matrices. Authors: Gustavo de los\nCampos [aut], Alexander Grueneberg [aut, cre].\n\nLncMod\n\nPredicting Modulator and Functional/Survival Analysis. Authors:\nYongsheng Li,Zishan Wang,Juan Xu*,Xia Li*.\n\nLotkasLaw\n\nRuns Lotka’s Law which is One of the Special Applications of Zipf’s\nLaw. Authors: Kenneth Buker [aut, cre], Dr. Alon Friedman [ctb].\n\nMANCIE\n\nMatrix Analysis and Normalization by Concordant Information\nEnhancement. Authors: Tao Wang, Chongzhi Zang.\n\nMBTAr\n\nAccess Data from the Massachusetts Bay Transit Authority (MBTA) Web\nAPI. Author: Justin de Benedictis-Kessner [aut, cre].\n\nMCDM\n\nMulti-Criteria Decision Making Methods. Author: Blanca A. Ceballos\nMartin.\n\nMDimNormn\n\nMulti-Dimensional MA Normalization for Plate Effect. Author:\nMun-Gwan Hong.\n\nMFAg\n\nMultiple Factor Analysis (MFA). Author: Paulo Cesar Ossani Marcelo\nAngelo Cirillo.\n\nMIXFIM\n\nEvaluation of the FIM in NLMEMs using MCMC. Authors: Marie-Karelle\nRiviere-Jourdan and France Mentre.\n\nMLCIRTwithin\n\nLatent Class Item Response Theory Models Under Within-Item\nMulti-Dimensionality. Authors: Francesco Bartolucci, Silvia Bacci.\n\nMM2S\n\nSingle-Sample Classifier of Medulloblastoma Subtypes for\nMedulloblastoma Patient Samples, Mouse Models, and Cell Lines.\nAuthors: Deena M.A. Gendoo, Benjamin Haibe-Kains.\n\nMM2Sdata\n\nGene Expression Datasets for the ‘MM2S’ Package. Authors: Deena M.A.\nGendoo, Benjamin Haibe-Kains.\n\nMMWRweek\n\nConvert Dates to MMWR Day, Week, and Year. Author: Jarad Niemi.\n\nMRQoL\n\nMinimal Clinically Important Difference and Response Shift Effect\nfor Health-Related Quality of Life. Author: Ahmad Ousmen.\n\nMScombine\n\nCombine Data from Positive and Negative Ionization Mode Finding\nCommon Entities. Author: Monica Calderon-Santiago.\n\nMVT\n\nEstimation and Testing for the Multivariate t-Distribution. Author:\nFelipe Osorio.\n\nManlyMix\n\nManly Mixture Modeling and Model-Based Clustering. Authors: Xuwen\nZhu [aut, cre], Volodymyr Melnykov [aut], Michael Hutt [ctb,\ncph] (NM optimization in c), Stephen Moshier [ctb, cph] (eigen\ncalculations in c), Rouben Rostamian [ctb, cph] (memory allocation\nin c).\n\nMatchLinReg\n\nCombining Matching and Linear Regression for Causal Inference.\nAuthors: Alireza S. Mahani, Mansour T.A. Sharabiani.\n\nMaxentVariableSelection\n\nSelecting the Best Set of Relevant Environmental Variables along\nwith the Optimal Regularization Multiplier for Maxent Niche\nModeling. Author: Alexander Jueterbock.\n\nMediana\n\nClinical Trial Simulations. Authors: Gautier Paux, Alex Dmitrienko.\n\nMethylCapSig\n\nDetection of Differentially Methylated Regions using MethylCap-Seq\nData. Authors: Deepak N. Ayyala, David E. Frankhouser,\nJavkhlan-Ochir Ganbat, Guido Marcucci, Ralf Bundschuh, Pearlly Yan\nand Shili Lin.\n\nMixedPoisson\n\nMixed Poisson Models. Authors: Alicja Wolny-Dominiak and Michal\nTrzesiok.\n\nMoTBFs\n\nLearning Hybrid Bayesian Networks using Mixtures of Truncated Basis\nFunctions. Authors: Inmaculada Pérez-Bernabé, Antonio Salmerón.\n\nMonoPhy\n\nAllows to Explore Monophyly (or Lack of it) of Taxonomic Groups in a\nPhylogeny. Author: Orlando Schwery.\n\nMotilityLab\n\nQuantitative Analysis of Motion. Authors: Katharina Dannenberg,\nJeffrey Berry, Johannes Textor.\n\nMultiGHQuad\n\nMultidimensional Gauss-Hermite Quadrature. Author: Karel Kroeze.\n\nMvBinary\n\nModelling Multivariate Binary Data with Blocks of Specific\nOne-Factor Distribution. Authors: Matthieu Marbac and Mohammed\nSedki.\n\nNCA\n\nNecessary Condition Analysis. Author: Jan Dul.\n\nNEpiC\n\nNetwork Assisted Algorithm for Epigenetic Studies Using Mean and\nVariance Combined Signals. Author: Peifeng Ruan.\n\nNIPTeR\n\nFast and Accurate Trisomy Prediction in Non-Invasive Prenatal\nTesting. Author: Dirk de Weerd.\n\nNetSwan\n\nNetwork Strengths and Weaknesses Analysis. Author: Serge Lhomme.\n\nNlcOptim\n\nSolve Nonlinear Optimization with Nonlinear Constraints. Authors:\nXianyan Chen, Xiangrong Yin. In view:\nOptimization.\n\nNostalgiR\n\nAdvanced Text-Based Plots. Author: Hien D. Nguyen.\n\nOBsMD\n\nObjective Bayesian Model Discrimination in Follow-Up Designs.\nAuthor: Marta Nai Ruscone based on Laura Deldossi’s code.\n\nOECD\n\nSearch and Extract Data from the OECD. Author: Eric Persson [aut,\ncre].\n\nOTE\n\nOptimal Trees Ensembles for Regression, Classification and Class\nMembership Probability Estimation. Authors: Zardad Khan, Asma Gul,\nAris Perperoglou, Osama Mahmoud, Werner Adler, Miftahuddin and\nBerthold Lausen.\n\nOasisR\n\nOutright Tool for the Analysis of Spatial Inequalities and\nSegregation. Author: Mihai Tivadar. In view:\nSpatial.\n\nOptGS\n\nNear-Optimal and Balanced Group-Sequential Designs for Clinical\nTrials with Continuous Outcomes. Authors: James Wason [aut, cre],\nJohn Burkardt [ctb]. In view:\nExperimentalDesign.\n\nOptiQuantR\n\nSimplifies and Automates Analyzing and Reporting OptiQuant’s log\nData. Author: Joao Pinelo Silva [aut, cre].\n\nOriGen\n\nFast Spatial Ancestry via Flexible Allele Frequency Surfaces.\nAuthors: John Michael O Ranola, John Novembre, and Kenneth Lange.\n\nOrthoPanels\n\nDynamic Panel Models with Orthogonal Reparameterization of Fixed\nEffects. Authors: Davor Cubranic [aut, cre], Mark Pickup [aut],\nPaul Gustafson [aut], Geoffrey Evans [aut].\n\nPCA4TS\n\nSegmenting Multiple Time Series by Contemporaneous Linear\nTransformation. Authors: Jinyuan Chang, Bin Guo and Qiwei Yao. In\nview: TimeSeries.\n\nPKNCA\n\nPerform Pharmacokinetic Non-Compartmental Analysis. Authors: Bill\nDenney, Clare Buckeridge.\n\nPRIMsrc\n\nPRIM Survival Regression Classification. Authors: Jean-Eudes Dazard\n[aut, cre], Michael Choe [ctb], Michael LeBlanc [ctb], Alberto\nSantana [ctb].\n\nPabonLasso\n\nPabon Lasso Graphs and Comparing Situations of a Unit in Two\nDifferent Times. Authors: H Nezami and H Tabesh and AA Azarian.\n\nPade\n\nPadé Approximant Coefficients. Author: Avraham Adler [aut, cph,\ncre]. In view:\nNumericalMathematics.\n\nPanelCount\n\nRandom Effects and/or Sample Selection Models for Panel Count Data.\nAuthor: Jing Peng.\n\nParallelPC\n\nParalellised Versions of Constraint Based Causal Discovery\nAlgorithms. Authors: Thuc Duy Le, Tao Hoang, Shu Hu, and Liang\nZhang.\n\nPasha\n\nPreprocessing of Aligned Sequences from HTS Analyses. Authors:\nRomain Fenouil, Nicolas Descostes, Lionel Spinelli, Jean-Christophe\nAndrau.\n\nPerc\n\nUsing Percolation and Conductance to Find Information Flow Certainty\nin a Direct Network. Authors: Kevin Fujii [aut], Jian Jin [aut,\ncre], Aaron Shev [aut], Brianne Beisner [aut], Brenda McCowan\n[aut, cph], Hsieh Fushing [aut, cph].\n\nPharmacoGx\n\nAnalysis of Large-Scale Pharmacogenomic Data. Authors: Petr Smirnov,\nZhaleh Safikhani, Benjamin Haibe-Kains.\n\nPhxnlme\n\nRun Phoenix NLME and Perform Post-Processing. Authors: Chay Ngee Lim\n[aut,cre], Shuang Liang [aut], Kevin Feng [aut,cre], Grygoriy\nVasilinin [aut], Angela Birnbaum [aut,ths], Jason Chittenden\n[aut], Bob Leary [ctb], Ana Henry [ctb], Mike Dunlavey\n[ctb], Samer Mouksassi [com].\n\nPlotPrjNetworks\n\nUseful Networking Tools for Project Management. Author: Javier\nCeligueta Muñoz.\n\nPortfolioEffectEstim\n\nHigh Frequency Price Estimators by PortfolioEffect. Authors: Andrey\nKostin [aut, cre], Aleksey Zemnitskiy [aut], Oleg Nechaev\n[aut].\n\nPortfolioEffectHFT\n\nHigh Frequency Portfolio Analytics by PortfolioEffect. Authors:\nAleksey Zemnitskiy [aut, cre], Andrey Kostin [aut], Oleg Nechaev\n[aut], Craig Otis and others [ctb, cph] (OpenFAST library),\nDaniel Lemire, Muraoka Taro and others [ctb, cph] (JavaFastPFOR\nlibrary), Joe Walnes, Jorg Schaible and others [ctb, cph] (XStream\nlibrary), Dain Sundstrom [ctb, cph] (Snappy library), Extreme!\nLab, Indiana University [ctb, cph] (XPP3 library), The Apache\nSoftware Foundation [ctb, cph] (Apache Log4j and Commons Lang\nlibraries), Google, Inc. [ctb, cph] (GSON library), Free Software\nFoundation [ctb, cph] (GNU Trove and GNU Crypto libraries). In\nview: Finance.\n\nProNet\n\nBiological Network Construction, Visualization and Analyses.\nAuthors: Xiang-Yun Wu and Xia-Yu Xia.\n\nProTrackR\n\nManipulate and Play ‘ProTracker’ Modules. Author: Pepijn de Vries\n[aut, cre, dtc].\n\nPsiHat\n\nSeveral Local False Discovery Rate Estimators. Authors: Alaa Ali,\nKyle Leckett, Marta Padilla, David R. Bickel (contributions from\nBradley Efron, Brit B. Turnbull, Balasubramanian Narasimhan from\npackage locfdr).\n\nPythonInR\n\nUse Python from Within R. Author: Florian Schwendinger [aut, cre].\n\nQPot\n\nQuasi-Potential Analysis for Stochastic Differential Equations.\nAuthors: Christopher Moore [aut], Christopher Stieha [aut, cre],\nBen Nolting [aut], Maria Cameron [aut], Karen Abbott [aut],\nJames Gregson [cph] (author of expression_parser library:\nhttps://github.com/jamesgregson/expression_parser).\n\nQuantumClone\n\nClustering Mutations using High Throughput Sequencing (HTS) Data.\nAuthor: Paul Deveau [aut, cre].\n\nRClone\n\nPartially Clonal Populations Analysis. Authors: Sophie Arnaud-Haond\n[aut], Diane Bailleul [aut, cre], CLONIX [ctb].\n\nRCriteo\n\nLoading Criteo Data into R. Author: Johannes Burkhardt.\n\nRFormatter\n\nR Source Code Formatter. Author: Benjamin Fischer [aut, cre].\n\nRGoogleAnalyticsPremium\n\nUnsampled Data in R for Google Analytics Premium Accounts. Author:\nJalpa Joshi Dave.\n\nRKlout\n\nFetch Klout Scores for Twitter Users. Author: Binayak Goswami.\n\nRMixpanel\n\nR API for Mixpanel. Author: Meinhard Ploner.\n\nRNaviCell\n\nVisualization of High-Throughput Data on Large-Scale Biological\nNetworks. Authors: Eric Bonnet [aut, cre], Paul Deveau [aut].\n\nRNeo4j\n\nNeo4j Driver for R. Author: Nicole White.\n\nROMIplot\n\nPlots Surfaces of Rates of Mortality Improvement. Authors: Roland\nRau, Tim Riffe.\n\nROptimizely\n\nR Optimizely API. Authors: Keerthi Chandra [aut, cre], Chris\nJohannessen [aut], Siddharth Somayajula [ctb].\n\nRRNA\n\nSecondary Structure Plotting for RNA. Author: JP Bida.\n\nRStoolbox\n\nTools for Remote Sensing Data Analysis. Authors: Benjamin Leutner\n[cre, aut], Ned Horning [aut].\n\nRViennaCL\n\nViennaCL C++ Header Files. Author: Charles Determan Jr.\n\nRateDistortion\n\nRoutines for Solving Rate-Distortion Problems. Author: Chris R.\nSims.\n\nRblpapi\n\nR Interface to Bloomberg. Authors: Whit Armstrong, Dirk Eddelbuettel\nand John Laing. In view:\nFinance.\n\nRcereal\n\nC++ Header Files of ‘cereal’. Authors: Wush Wu, Randolph Voorhies,\nand Shane Grant.\n\nRcppFaddeeva\n\n‘Rcpp’ Bindings for the ‘Faddeeva’ Package. Authors: Baptiste Auguie\n[aut, cre], Dirk Eddelbuettel [aut], Steven G. Johnson [aut]\n(Author of Faddeeva).\n\nRcppShark\n\nR Interface to the Shark Machine Learning Library. Author: Aydin\nDemircioglu.\n\nRedditExtractoR\n\nReddit Data Extraction Toolkit. Author: Ivan Rivera.\n\nRelatedness\n\nAn Algorithm to Infer Relatedness. Author: Fabien Laporte.\n\nRepeatABEL\n\nGWAS for Multiple Observations on Related Individuals. Author: Lars\nRonnegard.\n\nRevEcoR\n\nReverse Ecology Analysis on Microbiome. Authors: Yang Cao, Fei Li.\n\nRip46\n\nUtils for IP4 and IP6 Addresses. Author: Neal Fultz.\n\nRobustEM\n\nRobust Mixture Modeling Fitted via Spatial-EM Algorithm for\nModel-Based Clustering and Outlier Detection. Authors: Aishat Aloba,\nKai Yu, Xin Dang, Yixin Chen, and Henry Bart Jr.\n\nRphylopars\n\nPhylogenetic Comparative Tools for Missing Data and Within-Species\nVariation. Authors: Eric W. Goolsby, Jorn Bruggeman, Cecile Ane.\n\nRsurrogate\n\nRobust Estimation of the Proportion of Treatment Effect Explained by\nSurrogate Marker Information. Author: Layla Parast.\n\nRtwalk\n\nThe R Implementation of the ‘t-walk’ MCMC Algorithm. Author: J\nAndres Christen.\n\nRxODE\n\nFacilities for Simulating from ODE-Based Models. Authors: Melissa\nHallow [aut, cre], Wenping Wang [aut], David A. James [aut].\n\nSACCR\n\nSA Counterparty Credit Risk under Basel III. Author: Tasos Grivas.\n\nSACOBRA\n\nSelf-Adjusting COBRA. Authors: Wolfgang Konen [aut], Samineh\nBagheri [cre, aut], Patrick Koch [aut].\n\nSAGA\n\nSoftware for the Analysis of Genetic Architecture. Authors: Heath\nBlackmon and Jeffery P. Demuth.\n\nSALTSampler\n\nEfficient Sampling on the Simplex. Authors: Hannah Director, Scott\nVander Wiel, James Gattiker.\n\nSDR\n\nSubgroup Discovery Algorithms for R. Authors: Angel M. Garcia [aut,\ncre], Pedro Gonzalez [aut, cph], Cristobal J. Carmona [aut,\ncph], Francisco Charte [ctb].\n\nSEHmodel\n\nSpatial Exposure-Hazard Model for Exposure and Impact Assessment on\nExposed Individuals. Authors: Marc Bourotte [ctb], Melen Leclerc\n[aut], Jean-Francois Rey [aut, cre], Samuel Soubeyrand [ctb],\nEmily Walker [aut].\n\nSHELF\n\nTools to Support the Sheffield Elicitation Framework (SHELF).\nAuthor: Jeremy Oakley.\n\nSIBER\n\nStable Isotope Bayesian Ellipses in R. Authors: Andrew Jackson and\nAndrew Parnell.\n\nSOPIE\n\nNon-Parametric Estimation of the Off-Pulse Interval of a Pulsar.\nAuthor: Willem Daniel Schutte.\n\nSPCALDA\n\nA New Reduced-Rank Linear Discriminant Analysis Method. Authors:\nYue S. Niu, Ning Hao, and Bin Dong.\n\nSSRMST\n\nSample Size Calculation using Restricted Mean Survival Time. Author:\nMiki Horiguchi.\n\nSTAND\n\nStatistical Analysis of Non-Detects. Authors: E. L. Frome and D. P.\nFrome.\n\nSTI\n\nCalculation of the Standardized Temperature Index. Author: Marc\nFasel [aut, cre].\n\nSTMedianPolish\n\nSpatio-Temporal Median Polish. Authors: William Martinez, Carlos\nMelo. In view:\nSpatioTemporal.\n\nSchemaOnRead\n\nAutomated Schema on Read. Author: Michael North [aut, cre].\n\nSejong\n\nKoNLP static dictionaries and Sejong project resources. Author:\nHeewon Jeon.\n\nSensMixed\n\nAnalysis of Sensory and Consumer Data in a Mixed Model Framework.\nAuthors: Alexandra Kuznetsova [aut, cre], Per Bruun Brockhoff\n[aut, ths], Rune Haubo Bojesen Christensen [aut].\n\nShapeChange\n\nChange-Point Estimation using Shape-Restricted Splines. Authors:\nXiyue Liao and Mary C Meyer.\n\nShrinkage\n\nSeveral Shrinkage Effect-Size Estimators. Authors: Corey M.\nYanofsky, Zahra Montazeri, Marta Padilla, Alaa Ali and David R.\nBickel.\n\nSimDesign\n\nStructure for Organizing Monte Carlo Simulation Designs. Author:\nPhil Chalmers [aut, cre].\n\nSimHaz\n\nSimulated Survival and Hazard Analysis for Time-Dependent Exposure.\nAuthors: Danyi Xiong, Teeranan Pokaprakarn, Hiroto Udagawa, Nusrat\nRabbee.\n\nSimReg\n\nSimilarity Regression Functions. Author: Daniel Greene.\n\nSocialMediaLab\n\nTools for Collecting Social Media Data and Generating Networks for\nAnalysis. Author: Timothy Graham & Robert Ackland.\n\nSofi\n\nInterfaz interactiva con fines didacticos. Author: Jose D. Loera.\n\nSoyNAM\n\nSoybean Nested Association Mapping Dataset. Authors: Alencar Xavier,\nWilliam Beavis, James Specht, Brian Diers, Reka Howard, William\nMuir, Katy Rainey.\n\nSpaDES\n\nDevelop and Run Spatially Explicit Discrete Event Simulation Models.\nAuthors: Alex M Chubaty [aut, cre], Eliot J B McIntire [aut],\nSteve Cumming [ctb], Her Majesty the Queen in Right of Canada, as\nrepresented by the Minister of Natural Resources Canada [cph].\n\nSparseFactorAnalysis\n\nScaling Count and Binary Data with Sparse Factor Analysis. Authors:\nMarc Ratkovic, In Song Kim, John Londregan, and Yuki Shiraito.\n\nSparseLearner\n\nSparse Learning Algorithms Using a LASSO-Type Penalty for\nCoefficient Estimation and Model Prediction. Authors: Pi Guo,\nYuantao Hao.\n\nStMoMo\n\nStochastic Mortality Modelling. Authors: Andres Villegas, Pietro\nMillossovich, Vladimir Kaishev.\n\nStockChina\n\nReal-Time Stock Price & Volume in China Market. Author: Xiaodong\nDeng.\n\nSuperExactTest\n\nExact Test and Visualization of Multi-Set Intersections. Authors:\nMinghui Wang, Yongzhong Zhao and Bin Zhang.\n\nSurvRank\n\nRank Based Survival Modelling. Author: Michael Laimighofer [aut,\ncre, ctb].\n\nSwarmSVM\n\nEnsemble Learning Algorithms Based on Support Vector Machines.\nAuthors: Tong He, Aydin Demircioglu.\n\nSyncMove\n\nSubsample Temporal Data to Synchronal Events and Compute the MCI.\nAuthors: Martin Rimmler [aut, cre], Thomas Mueller [aut].\n\nTCGA2STAT\n\nSimple TCGA Data Access for Integrated Statistical Analysis in R.\nAuthors: Ying-Wooi Wan, Genevera I. Allen, Matthew L. Anderson,\nZhandong Liu.\n\nTLBC\n\nTwo-Level Behavior Classification. Author: Katherine Ellis.\n\nTMB\n\nTemplate Model Builder: A General Random Effect Tool Inspired by\nADMB. Authors: Kasper Kristensen [aut, cre, cph], Brad Bell\n[cph], Hans Skaug [ctb], Arni Magnusson [ctb], Casper Berg\n[ctb], Anders Nielsen [ctb], Martin Maechler [ctb], Theo\nMichelot [ctb], Mollie Brooks [ctb], Cole Monnahan [ctb].\n\nTMDb\n\nAccess to TMDb API - Apiary. Author: Andrea Capozio.\n\nTOC\n\nTotal Operating Characteristic Curve and ROC Curve. Authors:\nRobert G. Pontius, Alí Santacruz, Amin Tayyebi, Benoit Parmentier,\nKangping Si.\n\nTP.idm\n\nEstimation of Transition Probabilities for the Illness-Death Model.\nAuthors: Vanesa Balboa-Barreiro, Jacobo de Una-Alvarez and Luis\nMeira-Machado.\n\nTRADER\n\nTree Ring Analysis of Disturbance Events in R. Authors: Pavel\nFibich, Jan Altman, Tuomas Aakala, Jiri Dolezal.\n\nTSMining\n\nMining Univariate and Multivariate Motifs in Time-Series Data.\nAuthor: Cheng Fan. In view:\nTimeSeries.\n\nTSTr\n\nTernary Search Tree for Auto-Completion and Spell Checking. Authors:\nRicardo Merino [aut, cre], Samantha Fernandez [ctb].\n\nTTS\n\nMaster Curve Estimates Corresponding to Time-Temperature\nSuperposition. Authors: Antonio Meneses, Salvador Naya, Javier\nTarrio-Saavedra.\n\nTauStar\n\nEfficient Computation of the t* Statistic of Bergsma and Dassios\n(2014). Authors: Luca Weihs [aut, cre], Emin Martinian [ctb]\n(Created the red-black tree library included in package.).\n\nTestingSimilarity\n\nBootstrap Test for Similarity of Dose Response Curves Concerning the\nMaximum Absolute Deviation. Author: Kathrin Moellenhoff.\n\nTipDatingBeast\n\nUsing Tip Dates with Phylogenetic Trees in BEAST. Authors: Adrien\nRieux, Camilo Khatchikian.\n\nTmisc\n\nTurner Miscellaneous. Author: Stephen Turner.\n\nTraitspace\n\nA Predictive Model for Trait Based Community Assembly of Plant\nSpecies. Authors: Chaitanya Joshi, Xin Li, Daniel Laughlin.\n\nTransModel\n\nFit Linear Transformation Models for Censored Data. Authors: Jie\nZhou, Jiajia Zhang, Wenbin Lu.\n\nTruncatedNormal\n\nTruncated Multivariate Normal. Author: Zdravko I. Botev.\n\nUncerIn2\n\nImplements Models of Uncertainty into the Interpolation Functions.\nAuthor: Tomas Burian.\n\nUpSetR\n\nA More Scalable Alternative to Venn and Euler Diagrams for\nVisualizing Intersecting Sets. Authors: Jake Conway [cre], Nils\nGehlenborg [aut].\n\nVTrack\n\nA Collection of Tools for the Analysis of Remote Acoustic Telemetry\nData. Authors: Ross G. Dwyer, Mathew E. Watts, Hamish A. Campbell &\nCraig E. Franklin.\n\nWiSEBoot\n\nWild Scale-Enhanced Bootstrap. Authors: Megan Heyman, Snigdhansu\nChatterjee.\n\nWikidataR\n\nAPI Client Library for ‘Wikidata’. Authors: Oliver Keyes [aut,\ncre], Christian Graul [ctb].\n\nWufooR\n\nR Wrapper for the ‘Wufoo.com’ - The Form Building Service. Author:\nJohn Malc.\n\nXHWE\n\nX Chromosome Hardy-Weinberg Equilibrium. Authors: Xiao-Ping You,\nQi-Lei Zou, Jian-Long Li, Ji-Yuan Zhou.\n\nXMRF\n\nMarkov Random Fields for High-Throughput Genetics Data. Authors:\nYing-Wooi Wan, Genevera I. Allen, Yulia Baker, Eunho Yang, Pradeep\nRavikumar, Zhandong Liu.\n\nZRA\n\nDynamic Plots for Time Series Forecasting. Author: David Beiner.\n\naTSA\n\nAlternative Time Series Analysis. Author: Debin Qiu.\n\nabbyyR\n\nAccess to Abbyy Optical Character Recognition (OCR) API. Author:\nGaurav Sood [aut, cre].\n\nabcrf\n\nApproximate Bayesian Computation via Random Forests. Authors:\nJean-Michel Marin [aut], Pierre Pudlo [aut, cre], Christian P.\nRobert [ctb].\n\nabodOutlier\n\nAngle-Based Outlier Detection. Author: Jose Jimenez.\n\nacmeR\n\nImplements ACME Estimator of Bird and Bat Mortality by Wind\nTurbines. Authors: Robert Wolpert [aut, cre], Jacob Coleman\n[aut].\n\naddhazard\n\nFit Additive Hazards Models for Survival Analysis. Authors: Jie\n(Kate) Hu [aut, cre], Norman Breslow [aut], Gary Chan [aut].\n\nalineR\n\nAlignment of Phonetic Sequences Using the ‘ALINE’ Algorithm.\nAuthors: Sean Downey [aut, cre], Guowei Sun [aut].\n\nameco\n\nEuropean Commission Annual Macro-Economic (AMECO) Database. Author:\nEric Persson [aut, cre].\n\nanalogsea\n\nInterface to ‘Digital Ocean’. Authors: Scott Chamberlain [aut,\ncre], Hadley Wickham [aut], Winston Chang [aut], RStudio\n[cph].\n\nanonymizer\n\nAnonymize Data Containing Personally Identifiable Information.\nAuthor: Paul Hendricks [aut, cre].\n\naop\n\nAdverse Outcome Pathway Analysis. Author: Lyle D. Burgoon.\n\napaStyle\n\nGenerate APA Tables for MS Word. Author: Jort de Vreeze [aut,\ncre]. In view:\nReproducibleResearch.\n\napaTables\n\nCreate American Psychological Association (APA) Style Tables.\nAuthor: David Stanley [aut, cre].\n\nappnn\n\nAmyloid Propensity Prediction Neural Network. Authors: Carlos\nFamília, Sarah R. Dennison, Alexandre Quintas, David A. Phoenix.\n\napricom\n\nTools for the a Priori Comparison of Regression Modelling\nStrategies. Authors: Romin Pajouheshnia [aut, cre], Wiebe Pestman\n[aut], Rolf Groenwold [aut].\n\narqas\n\nApplication in R for Queueing Analysis and Simulation. Author: Borja\nVarela.\n\nartfima\n\nFit ARTFIMA Model. Authors: A. I. McLeod, Farzad Sabzikar, Mark M.\nMeerschaert.\n\nasdreader\n\nReading ASD Binary Files in R. Author: Pierre Roudier [aut, cre].\n\nasht\n\nApplied Statistical Hypothesis Tests. Author: Michael P. Fay.\n\nasremlPlus\n\nAugments the Use of ‘Asreml’ in Fitting Mixed Models. Author: Chris\nBrien.\n\nassertive.base\n\nA Lightweight Core of the ‘assertive’ Package. Authors: Richard\nCotton [aut, cre], Sunkyu Choi [trl], Ivanka Skakun [trl],\nGergely Daroczi [trl], Anton Antonov [trl], Hisham Ben Hamidane\n[trl], Anja Billing [trl], Aditya Bhagwat [trl], Rasmus Baath\n[trl], Mine Cetinkaya-Rundel [trl], Aspasia Chatziefthymiou\n[trl].\n\nassertive.code\n\nAssertions to Check Properties of Code. Author: Richard Cotton\n[aut, cre].\n\nassertive.data\n\nAssertions to Check Properties of Data. Author: Richard Cotton\n[aut, cre].\n\nassertive.data.uk\n\nAssertions to Check Properties of Strings. Author: Richard Cotton\n[aut, cre].\n\nassertive.data.us\n\nAssertions to Check Properties of Strings. Author: Richard Cotton\n[aut, cre].\n\nassertive.datetimes\n\nAssertions to Check Properties of Dates and Times. Author: Richard\nCotton [aut, cre].\n\nassertive.files\n\nAssertions to Check Properties of Files. Author: Richard Cotton\n[aut, cre].\n\nassertive.matrices\n\nAssertions to Check Properties of Matrices. Author: Richard Cotton\n[aut, cre].\n\nassertive.models\n\nAssertions to Check Properties of Models. Author: Richard Cotton\n[aut, cre].\n\nassertive.numbers\n\nAssertions to Check Properties of Numbers. Author: Richard Cotton\n[aut, cre].\n\nassertive.properties\n\nAssertions to Check Properties of Variables. Author: Richard Cotton\n[aut, cre].\n\nassertive.reflection\n\nAssertions for Checking the State of R. Author: Richard Cotton\n[aut, cre].\n\nassertive.sets\n\nAssertions to Check Properties of Sets. Author: Richard Cotton\n[aut, cre].\n\nassertive.strings\n\nAssertions to Check Properties of Strings. Author: Richard Cotton\n[aut, cre].\n\nassertive.types\n\nAssertions to Check Types of Variables. Author: Richard Cotton\n[aut, cre].\n\nautovarCore\n\nAutomated Vector Autoregression Models and Networks. Author: Ando\nEmerencia [aut, cre]. In view:\nTimeSeries.\n\naverisk\n\nCalculation of Average Population Attributable Fractions and\nConfidence Intervals. Author: John Ferguson [aut, cre].\n\nbWGR\n\nBagging Whole-Genome Regression. Authors: Alencar Xavier, William\nMuir, Katy Rainey.\n\nbackShift\n\nLearning Causal Cyclic Graphs from Unknown Shift Interventions.\nAuthor: Christina Heinze.\n\nbackpipe\n\nBackward Pipe Operator. Authors: Christopher Brown [cre, aut],\nDecision Patterns [cph].\n\nbacktestGraphics\n\nInteractive Graphics for Portfolio Data. Authors: David Kane, Ziqi\nLu, Fan Zhang, Miller Zijie Zhu.\n\nbacr\n\nBayesian Adjustment for Confounding. Author: Chi Wang.\n\nbapred\n\nBatch Effect Removal (in Phenotype Prediction using Gene Data).\nAuthors: Roman Hornung, David Causeur.\n\nbatman\n\nConvert Categorical Representations of Logicals to Actual Logicals.\nAuthors: Oliver Keyes [aut, cre], Ruben C. Arslan [ctb],\nChristopher Akiki [ctb], Mine Cetinkaya-Rundel [ctb], Peter\nMeissner [ctb], Ilaria Prosdocimi [ctb], Thomas Leeper [ctb],\nAmy Lee [ctb], Adolfo Álvarez [ctb].\n\nbatteryreduction\n\nAn R Package for Data Reduction by Battery Reduction. Authors:\nChunqiao Luo [aut, cre], Ralph D’Agostino [aut].\n\nbcRep\n\nAdvanced Analysis of B Cell Receptor Repertoire Data. Author: Julia\nBischof.\n\nbcrypt\n\n‘Blowfish’ Password Hashing Algorithm. Authors: Jeroen Ooms [cre,\naut], Damien Miller [cph], Niels Provos [cph].\n\nbdots\n\nBootstrapped Differences of Time Series. Authors: Michael Seedorff,\nJacob Oleson, Grant Brown, Joseph Cavanaugh, and Bob McMurray.\n\nbedr\n\nGenomic Region Processing using Tools Such as Bedtools, Bedops and\nTabix. Authors: Daryl Waggott, Syed Haider, Emilie Lalonde, Clement\nFung, Paul C. Boutros.\n\nbetalink\n\nBeta-Diversity Within a Metaweb of Species Interactions. Author:\nTimothee Poisot.\n\nbimixt\n\nEstimates Mixture Models for Case-Control Data. Authors: Michelle\nWinerip, Garrick Wallstrom, Joshua LaBaer.\n\nbiomartr\n\nFunctional Annotation and Biological Data Retrieval with R. Author:\nHajk-Georg Drost.\n\nblavaan\n\nBayesian Latent Variable Analysis. Authors: Edgar Merkle [aut,\ncre], Yves Rosseel [aut].\n\nbmeta\n\nA Package for Bayesian Meta-Analysis and Meta-Regression. Authors:\nTao Ding, Gianluca Baio.\n\nbnclassify\n\nLearning Discrete Bayesian Network Classifiers from Data. Authors:\nMihaljevic Bojan [aut, cre], Bielza Concha [aut], Larranaga\nPedro [aut], Wickham Hadley [ctb] (some code extracted from\nmemoise package). In view:\nMachineLearning.\n\nbnstruct\n\nBayesian Network Structure Learning from Data with Missing Values.\nAuthors: Francesco Sambo [aut, cre], Alberto Franzin [aut].\n\nbrotli\n\nA Compression Format Optimized for the Web. Authors: Jeroen Ooms\n[aut, cre], Google, Inc [aut, cph] (Brotli C++ library).\n\nbrr\n\nBayesian Inference on the Ratio of Two Poisson Rates. Author:\nStéphane Laurent.\n\nbrranching\n\nFetch Phylogenies from Many Sources. Author: Scott Chamberlain\n[aut, cre].\n\nbssn\n\nBirnbaum-Saunders Model Based on Skew-Normal Distribution. Authors:\nRocio Paola Maehara and Luis Benites Sanchez.\n\nbtergm\n\nTemporal Exponential Random Graph Models by Bootstrapped\nPseudolikelihood. Authors: Philip Leifeld [aut, cre], Skyler J.\nCranmer [ctb], Bruce A. Desmarais [ctb].\n\ncaRpools\n\nCRISPR AnalyzeR for Pooled CRISPR Screens. Authors: Jan Winter,\nFlorian Heigwer.\n\ncalACS\n\nCount All Common Subsequences. Author: Alan Gu.\n\ncamtrapR\n\nCamera Trap Data Management and Preparation of Occupancy and Spatial\nCapture-Recapture Analyses. Authors: Juergen Niedballa [aut, cre],\nAlexandre Courtiol [aut], Rahel Sollmann [aut], John Mathai\n[ctb], Seth Timothy Wong [ctb], An The Truong Nguyen [ctb],\nAzlan bin Mohamed [ctb], Andrew Tilker [ctb], Andreas Wilting\n[ctb, ths].\n\ncaptioner\n\nNumbers Figures and Creates Simple Captions. Author: Letaw Alathea\n[aut, cre].\n\ncaptr\n\nClient for the Captricity API. Author: Gaurav Sood [aut, cre].\n\ncardioModel\n\nCardiovascular Safety Exposure-Response Modeling in Early-Phase\nClinical Studies. Authors: Daniela J Conrado [aut, cre], William S\nDenney [aut], Gregory J Hather [aut], Danny Chen [ctb].\n\ncartography\n\nThematic Cartography. Authors: Timothée Giraud [cre, aut], Nicolas\nLambert [aut].\n\ncate\n\nHigh Dimensional Factor Analysis and Confounder Adjusted Testing and\nEstimation. Authors: Jingshu Wang [aut], Qingyuan Zhao [aut,\ncre].\n\ncausaldrf\n\nTools for Estimating Causal Dose Response Functions. Authors:\nDouglas Galagate [cre], Joseph Schafer [aut].\n\ncdcfluview\n\nRetrieve U.S. Flu Season Data from the CDC FluView Portal. Author:\nBob Rudis.\n\nchunked\n\nChunkwise Text-File Processing for ‘dplyr’. Author: Edwin de Jonge.\n\nckanr\n\nClient for the Comprehensive Knowledge Archive Network (‘CKAN’) API.\nAuthors: Scott Chamberlain [aut, cre], Imanuel Costigan [ctb],\nWush Wu [ctb], Florian Mayer [ctb].\n\nclarifai\n\nAccess to Clarifai API. Author: Gaurav Sood [aut, cre].\n\ncleangeo\n\nCleaning Geometries from Spatial Objects. Author: Emmanuel Blondel.\n\nclimtrends\n\nStatistical Methods for Climate Sciences. Author: Jose Gama [aut,\ncre].\n\nclipr\n\nRead and Write from the System Clipboard. Authors: Matthew Lincoln\n[aut, cre], Louis Maddox [ctb].\n\nclisymbols\n\nUnicode Symbols at the R Prompt. Authors: Gabor Csardi [aut, cre],\nSindre Sorhus [aut].\n\nclogitboost\n\nBoosting Conditional Logit Model. Authors: Haolun Shi [aut, cre],\nGuosheng Yin [aut].\n\nclttools\n\nCentral Limit Theorem Experiments (Theoretical and Simulation).\nAuthors: Simiao Ye, Jingning Mei.\n\ncmsaf\n\nTools for CM SAF Netcdf Data. Author: Steffen Kothe.\n\ncnmlcd\n\nMaximum Likelihood Estimation of a Log-Concave Density Function.\nAuthors: Yu Liu, Yong Wang.\n\ncoala\n\nA Framework for Coalescent Simulation. Authors: Paul Staab [aut,\ncre, cph], Dirk Metzler [ths].\n\ncodyn\n\nCommunity Dynamics Metrics. Authors: Lauren Hallett [aut],\nSydney K. Jones [aut], Andrew A. MacDonald [aut], Dan F. B.\nFlynn [aut], Peter Slaughter [aut], Julie Ripplinger [aut],\nScott L. Collins [aut], Corinna Gries [aut], Matthew B. Jones\n[aut, cre].\n\ncolorhcplot\n\nColorful Hierarchical Clustering Dendrograms. Author: Damiano\nFantini.\n\ncometExactTest\n\nExact Test from the Combinations of Mutually Exclusive Alterations\n(CoMEt) Algorithm. Authors: Max Leiserson [aut, cre], Hsin-Ta Wu\n[aut], Fabio Vandin [ctb], Vivian Hsiao [ctb], Benjamin\nRaphael [ctb].\n\nconover.test\n\nConover-Iman Test of Multiple Comparisons Using Rank Sums. Author:\nAlexis Dinno.\n\ncontoureR\n\nContouring of Non-Regular Three-Dimensional Data. Author: Nicholas\nHamilton.\n\ncontrolTest\n\nMedian Comparison for Two-Sample Right-Censored Survival Data.\nAuthor: Eric Kawaguchi.\n\nconvoSPAT\n\nConvolution-Based Nonstationary Spatial Modeling. Author: Mark D.\nRisser [aut, cre].\n\ncord\n\nCommunity Estimation in G-Models via CORD. Authors: Xi (Rossi) LUO,\nFlorentina Bunea, Christophe Giraud.\n\ncoreNLP\n\nWrappers Around Stanford CoreNLP Tools. Authors: Taylor Arnold,\nLauren Tilton.\n\ncorkscrew\n\nPreprocessor for Data Modeling. Authors: Navin Loganathan [aut],\nMohan Manivannan [aut], Santhosh Sasanapuri [aut, cre],\nLatentView Analytics [ctb].\n\ncorregp\n\nFunctions and Methods for Correspondence Regression. Author: Koen\nPlevoets [aut, cre].\n\ncovBM\n\nBrownian Motion Processes for ‘nlme’ Models. Author: Oliver Stirrup\n[aut, cre].\n\ncovmat\n\nCovariance Matrix Estimation. Author: Rohit Arora. In view:\nFinance.\n\ncowplot\n\nStreamlined Plot Theme and Plot Annotations for ‘ggplot2’. Authors:\nClaus O. Wilke [aut, cre], Hadley Wickham [cph].\n\ncowsay\n\nMessages, Warnings, Strings with Ascii Animals. Authors: Scott\nChamberlain [aut, cre], Tyler Rinker [aut], Thomas Leeper\n[aut], Noam Ross [aut], Rich FitzJohn [aut], Carson Sievert\n[aut], Kiyoko Gotanda [aut], Andy Teucher [aut], Karl Broman\n[aut], Franz-Sebastian Krah [aut].\n\ncpgen\n\nParallelized Genomic Prediction and GWAS. Author: Claas Heuer.\n\ncreditr\n\nCredit Default Swaps in R. Authors: Heidi Chen, Yuanchu Dang, David\nKane, Yang Lu, Skylar Smith, Kanishka Malik, and Miller Zijie Zhu.\n\ncredule\n\nCredit Default Swap Functions. Authors: Bertrand Le Nezet [cre,\naut, cph], Richard Brent [ctb, cph], John Burkardt [ctb, cph].\nIn view: Finance.\n\ncrmPack\n\nObject-Oriented Implementation of CRM Designs. Authors: Daniel\nSabanes Bove, Wai Yin Yeung, Giuseppe Palermo, Thomas Jaki.\n\ncrop\n\nGraphics Cropping Tool. Author: Marius Hofert [aut, cre].\n\ncrrp\n\nPenalized Variable Selection in Competing Risks Regression. Author:\nZhixuan Fu.\n\ncrskdiag\n\nDiagnostics for Fine and Gray Model. Author: Jianing Li.\n\ncruts\n\nInterface to Climatic Research Unit Time-Series Version 3.21 Data.\nAuthor: Benjamin M. Taylor.\n\nctmcmove\n\nModeling Animal Movement with Continuous-Time Discrete-Space Markov\nChains. Author: Ephraim Hanks. In view:\nSpatioTemporal.\n\nctmm\n\nContinuous-Time Movement Modeling. Authors: Chris H. Fleming\nand J. M. Calabrese. In view:\nSpatioTemporal.\n\nctsem\n\nContinuous Time Structural Equation Modelling. Authors: Manuel\nVoelkle [aut, cph] (Original development of continuous time model\nspecification within OpenMx, advisor for further development), Han\nOud [aut, cph] (Original development of continuous time model\nspecification within OpenMx), Charles Driver [aut, cre, cph]\n(Further development of continuous time model specification within\nOpenMx, package development, documentation and maintenance).\n\ncvxbiclustr\n\nConvex Biclustering Algorithm. Authors: Eric C. Chi, Genevera I.\nAllen, Richard G. Baraniuk.\n\ncycleRtools\n\nTools for Cycling Data Analysis. Author: Jordan Mackie [aut, cre].\n\ncymruservices\n\nQuery Team Cymru IP Address, Autonomous System Number (ASN), Border\nGateway Protocol (BGP), Bogon and Malware Hash Data Services.\nAuthor: Bob Rudis [aut, cre].\n\nd3heatmap\n\nInteractive Heat Maps Using ‘htmlwidgets’ and ‘D3.js’. Authors: Joe\nCheng [aut, cre], Tal Galili [aut], RStudio, Inc. [cph],\nMichael Bostock [ctb, cph] (D3.js library), Justin Palmer [ctb,\ncph] (d3.tip library).\n\ndMod\n\nDynamic Modeling and Parameter Estimation in ODE Models. Author:\nDaniel Kaschek.\n\ndad\n\nThree-Way Data Analysis Through Densities. Authors: Rachid Boumaza,\nPierre Santagostini, Smail Yousfi, Sabine Demotes-Mainard.\n\ndatafsm\n\nEstimating Finite State Machine Models from Data. Authors: Nay\nJohn J. [cre, aut], Gilligan Jonathan M. [aut].\n\ndataonderivatives\n\nEasily Source Publicly Available Data on Derivatives. Author:\nImanuel Costigan [aut, cre].\n\ndatastepr\n\nAn Implementation of a SAS-Style Data Step. Author: Brandon Taylor.\n\ndbscan\n\nDensity Based Clustering of Applications with Noise (DBSCAN) and\nRelated Algorithms. Authors: Michael Hahsler [aut, cre, cph],\nSunil Arya [ctb, cph], David Mount [ctb, cph]. In view:\nCluster.\n\ndc3net\n\nInferring Disease Networks via Differential Network Inference.\nAuthor: Gokmen Altay.\n\nddR\n\nDistributed Data Structures in R. Authors: Edward Ma, Indrajit Roy,\nMichael Lawrence.\n\ndeformula\n\nIntegration of One-Dimensional Functions with Double Exponential\nFormulas. Author: Hiroyuki Okamura.\n\ndequer\n\nAn R ‘Deque’ Container. Author: Drew Schmidt [aut, cre].\n\ndescriber\n\nDescribe Data in R Using Common Descriptive Statistics. Author: Paul\nHendricks [aut, cre].\n\ndesiR\n\nDesirability Functions for Ranking, Selecting, and Integrating Data.\nAuthor: Stanley E. Lazic.\n\ndetector\n\nDetect Data Containing Personally Identifiable Information. Author:\nPaul Hendricks [aut, cre].\n\ndiezeit\n\nR Interface to the ZEIT ONLINE Content API. Author: Christian Graul.\n\ndiffr\n\nDisplay Differences Between Two Files using Codediff Library.\nAuthor: John Muschelli [aut, cre].\n\ndina\n\nBayesian Estimation of DINA Model. Author: Steven Andrew Culpepper\n[aut, cph, cre].\n\ndistcomp\n\nComputations over Distributed Data without Aggregation. Authors:\nBalasubramanian Narasimhan [aut, cre], Marina Bendersky [aut],\nSam Gross [aut], Terry M. Therneau [ctb], Thomas Lumley [ctb].\n\ndiverse\n\nDiversity Measures for Complex Systems. Authors: Miguel R. Guevara,\nDominik Hartmann, Marcelo Mendoza.\n\ndml\n\nDistance Metric Learning in R. Authors: Yuan Tang, Gao Tao, Xiao\nNan.\n\ndocopulae\n\nOptimal Designs for Copula Models. Author: Andreas Rappold [aut,\ncre].\n\ndocxtractr\n\nExtract Data Tables from Microsoft Word Documents. Author: Bob Rudis\n[aut, cre].\n\ndotwhisker\n\nDot-and-Whisker Plots of Regression Results. Authors: Frederick\nSolt, Yue Hu.\n\ndownscale\n\nDownscaling Species Occupancy. Author: Charles Marsh [aut, cre].\n\ndrLumi\n\nMultiplex Immunoassays Data Analysis. Authors: Hector Sanz [aut,\ncre], John Aponte [aut], Jaroslaw Harezlak [aut], Yan Dong\n[aut], Magdalena Murawska [aut], Clarissa Valim [aut],\nAintzane Ayestaran [ctb], Ruth Aguilar [ctb], Gemma Moncunill\n[ctb].\n\ndtwSat\n\nTime-Weighted Dynamic Time Warping for Remote Sensing Time Series\nAnalysis. Author: Victor Maus [aut, cre].\n\ndtwclust\n\nTime Series Clustering with Dynamic Time Warping. Author: Alexis\nSarda-Espinosa. In view:\nTimeSeries.\n\neasyVerification\n\nEnsemble Forecast Verification for Large Datasets. Authors: Jonas\nBhend [aut, cre], Jacopo Ripoldi [ctb], Claudia Mignani [ctb],\nIrina Mahlstein [ctb], Rebecca Hiller [ctb], Christoph Spirig\n[ctb], Mark Liniger [ctb], Andreas Weigel [ctb], Joaqu’in\nBedia Jimenez [ctb], Matteo De Felice [ctb].\n\neasypower\n\nSample Size Estimation for Experimental Designs. Author: Aaron\nMcGarvey.\n\necospace\n\nSimulating Community Assembly and Ecological Diversification Using\nEcospace Frameworks. Author: Phil Novack-Gottshall [aut, cre].\n\necotoxicology\n\nMethods for Ecotoxicology. Author: Jose Gama [aut, cre, trl].\n\nedgar\n\nPlatform for EDGAR Filing Management. Authors: Gunratan Lonare,\nBharat Patil.\n\nedgebundleR\n\nCircle Plot with Bundled Edges. Authors: Garth Tarr [aut, cre],\nEllis Patrick [aut], Kent Russell [ctb].\n\neel\n\nExtended Empirical Likelihood. Authors: Fan Wu and Yu Zhang.\n\neemR\n\nTools for Pre-Processing Emission-Excitation-Matrix (EEM). Author:\nPhilippe Massicotte [aut, cre].\n\nefflog\n\nThe Causal Effects for a Causal Loglinear Model. Author: Gloria\nGheno [aut, cre].\n\nelasso\n\nEnhanced Least Absolute Shrinkage and Selection Operator Regression\nModel. Author: Pi Guo.\n\nepandist\n\nStatistical Functions for the Censored and Uncensored Epanechnikov\nDistribution. Author: Mathias Borritz Milfeldt [aut, cre].\n\nepanetReader\n\nRead Epanet Files into R. Author: Bradley J. Eck.\n\nepiDisplay\n\nEpidemiological Data Display Package. Author: Virasakdi\nChongsuvivatwong.\n\nepifit\n\nFlexible Modelling Functions for Epidemiological Data Analysis.\nAuthors: Kazutaka Doi [aut,cre], Kei Sakabe [ctb], Masataka\nTaruri [ctb].\n\nerp.easy\n\nEvent-Related Potential (ERP) Data Exploration Made Easy. Author:\nTravis Moore [aut, cre].\n\netma\n\nEpistasis Test in Meta-Analysis (ETMA). Author: Chin Lin. In view:\nMetaAnalysis.\n\nexreport\n\nFast, Reliable and Elegant Reproducible Research. Authors: Jacinto\nArias [aut, cre], Javier Cozar [aut].\n\nextremogram\n\nEstimation of Extreme Value Dependence for Time Series Data.\nAuthors: Nadezda Frolova, Ivor Cribben.\n\neyetrackingR\n\nEye-Tracking Data Analysis. Authors: Jacob Dink [aut, cre], Brock\nFerguson [aut].\n\nezec\n\nEasy Interface to Effective Concentration Calculations. Authors:\nZhian N. Kamvar [cre, aut], Niklaus J. Grunwald [ths, ctb].\n\nezsummary\n\nSummarise Data in the Quick and Easy Way. Author: Hao Zhu [aut,\ncre].\n\nfancycut\n\nA Fancy Version of ‘base::cut’. Author: Adam Rich [aut, cre].\n\nfastdigest\n\nFast, Low Memory-Footprint Digests of R Objects. Authors: Gabriel\nBecker, Bob Jenkins (SpookyHash algorithm and C++ implementation).\n\nfasttime\n\nFast Utility Function for Time Parsing and Conversion. Author: Simon\nUrbanek.\n\nfavnums\n\nA Dataset of Favourite Numbers. Authors: Oliver Keyes [aut, cre],\nAlex Bellos [cph].\n\nfilematrix\n\nFile-Backed Matrix Class with Convenient Read and Write Access.\nAuthor: Andrey Shabalin.\n\nflacco\n\nFeature-Based Landscape Analysis of Continuous and Constraint\nOptimization Problems. Authors: Pascal Kerschke [aut, cre], Jan\nDagefoerde [aut].\n\nflexPM\n\nFlexible Parametric Models for Censored and Truncated Data. Author:\nPaolo Frumento.\n\nflowDiv\n\nCytometric Diversity Indices from ‘FlowJo’ Workspaces. Authors:\nBruno M.S. Wanderley, María Victoria Quiroga, André M. Amado,\nFernando Unrein.\n\nflows\n\nFlow Selection and Analysis. Authors: Timothée Giraud [cre, aut],\nLaurent Beauguitte [aut], Marianne Guérois [ctb].\n\nforestmodel\n\nForest Plots from Regression Models. Author: Nick Kennedy.\n\nfourPNO\n\nBayesian 4 Parameter Item Response Model. Author: Steven Andrew\nCulpepper [aut, cre].\n\nfrailtySurv\n\nGeneral Semiparametric Shared Frailty Model. Authors: John V. Monaco\n[aut, cre], Malka Gorfine [aut], Li Hsu [aut].\n\nfranc\n\nDetect the Language of Text. Authors: Gabor Csardi, Titus Wormer,\nMaciej Ceglowski, Jacob R. Rideout, and Kent S. Johnson.\n\nfreqdom\n\nFrequency Domain Analysis for Multivariate Time Series. Authors:\nHormann S., Kidzinski L.\n\nftsspec\n\nSpectral Density Estimation and Comparison for Functional Time\nSeries. Author: Shahin Tavakoli [aut, cre].\n\nfulltext\n\nFull Text of Scholarly Articles Across Many Data Sources. Author:\nScott Chamberlain [aut, cre].\n\nfunctools\n\nFunctional Programming in R. Author: Paul Hendricks [aut, cre].\n\nfuncy\n\nFunctional Clustering Algorithms. Authors: Christina Yassouridis\n[aut, cre], Dominik Ernst [ctb], Madison Giacofci [ctb],\nSophie Lambert-Lacroix [ctb], Guillemette Marot [ctb], Franck\nPicard [ctb], Nicoleta Serban [ctb], Huijing Jiang [ctb],\nGareth James [ctb], Catherine Sugar [ctb], Hans-Georg Mueller\n[ctb], Jie Peng [ctb], Chiou Jeng-Min [ctb], Pai-Ling Li\n[ctb].\n\nfungible\n\nFungible Coefficients and Monte Carlo Functions. Authors: Niels G.\nWaller and Jeff Jones.\n\nfunr\n\nSimple Utility Providing Terminal Access to all R Functions. Author:\nSahil Seth [aut, cre].\n\nfuture\n\nA Future API for R. Author: Henrik Bengtsson [aut, cre, cph]. In\nview:\nHighPerformanceComputing.\n\ngamsel\n\nFit Regularization Path for Generalized Additive Models. Authors:\nAlexandra Chouldechova and Trevor Hastie.\n\ngaston\n\nGenetic Data Manipulation (Quality Control, GRM and LD Computations,\nPCA), Linear Mixed Models (AIREML Algorithm), Association Testing.\nAuthor: Hervé Perdry & Claire Dandine-Roulland.\n\ngdtools\n\nUtilities for Graphical Rendering. Authors: David Gohel [aut,\ncre], Hadley Wickham [aut], Jeroen Ooms [ctb], Yixuan Qiu\n[ctb], RStudio [cph].\n\ngendist\n\nGenerated Probability Distribution Models. Author: Shaiful Anuar Abu\nBakar.\n\ngenerator\n\nGenerate Data Containing Fake Personally Identifiable Information.\nAuthor: Paul Hendricks [aut, cre].\n\ngeo\n\nDraw and Annotate Maps, Especially Charts of the North Atlantic.\nAuthors: Hoskuldur Bjornsson, Sigurdur Thor Jonsson, Arni Magnusson,\nand Bjarki Thor Elvarsson.\n\ngeoknife\n\nWeb-Processing of Large Gridded Datasets. Authors: Jordan Read\n[aut, cre], Jordan Walker [aut], Alison Appling [aut], David\nBlodgett [aut], Emily Read [aut], Luke Winslow [aut].\n\ngeosptdb\n\nSpatio-Temporal; Inverse Distance Weighting and Radial Basis\nFunctions with Distance-Based Regression. Authors: Carlos Melo,\nOscar Melo.\n\ngesis\n\nR Client for GESIS Data Catalogue (DBK). Author: Eric Persson [aut,\ncre].\n\ngetMet\n\nGet Meteorological Data for Hydrological Modeling. Authors: Andrew\nSommerlot [aut, cre], Daniel Fuka [aut], Zachary Easton [aut].\n\nggfortify\n\nData Visualization Tools for Statistical Analysis Results. Authors:\nMasaaki Horikoshi and Yuan Tang.\n\nggplot2movies\n\nMovies Data. Authors: Hadley Wickham [aut, cre], RStudio [cph].\n\nggsn\n\nNorth Symbols and Scale Bars for Maps Created with ‘ggplot2’ or\n‘ggmap’. Author: Oswaldo Santos Baquero [aut, cre].\n\ngimms\n\nDownload and Process GIMMS NDVI3g Data. Author: Florian Detsch.\n\ngitlabr\n\nAccess to the Gitlab API. Author: Jirka Lewandowski [aut, cre].\n\ngkmSVM\n\nGapped-Kmer Support Vector Machine. Author: Mahmoud Ghandi.\n\nglamlasso\n\nLasso Penalization in Large Scale Generalized Linear Array Models.\nAuthor: Adam Lund.\n\nglm.ddR\n\nDistributed ‘glm’ for Big Data using ‘ddR’ API. Authors: Vishrut\nGupta, Arash Fard.\n\nglobals\n\nIdentify Global Objects in R Expressions. Author: Henrik Bengtsson\n[aut, cre, cph].\n\nglycanr\n\nTools for Analysing N-Glycan Data. Author: Ivo Ugrina [aut, cre].\n\ngmapsdistance\n\nDistance and Travel Time Between Two Points from Google Maps.\nAuthor: Rodrigo Azuero Melo.\n\ngmum.r\n\nGMUM Machine Learning Group Package. Authors: Wojciech Czarnecki,\nStanislaw Jastrzebski, Marcin Data, Igor Sieradzki, Mateusz\nBruno-Kaminski, Karol Jurek, Piotr Kowenzowski, Michal Pletty,\nKonrad Talik, Maciej Zgliczynski.\n\ngmwm\n\nGeneralized Method of Wavelet Moments. Authors: James Balamuta\n[aut, cph], Stephane Guerrier [ctb, cre, cph], Roberto Molinari\n[ctb, cph], Wenchao Yang [ctb].\n\ngofCopula\n\nGoodness-of-Fit Tests for Copulae. Authors: Ostap Okhrin, Shulin\nZhang, Qian M. Zhou, Simon Trimborn.\n\ngoogleAuthR\n\nEasy Authentication with Google OAuth2 APIs. Author: Mark Edmondson\n[aut, cre].\n\ngooglesheets\n\nManage Google Spreadsheets from R. Authors: Jennifer Bryan [aut,\ncre], Joanna Zhao [aut].\n\ngpuR\n\nGPU Functions for R Objects. Author: Charles Determan Jr. In view:\nHighPerformanceComputing.\n\ngquad\n\nG Quadruplex Motif Prediction Tool. Author: Hannah O. Ajoge.\n\ngraticule\n\nMeridional and Parallel Lines for Maps. Author: Michael D. Sumner\n[aut, cre].\n\ngrowthcurver\n\nSimple Metrics to Summarize Growth Curves. Author: Kathleen\nsprouffske [aut, cre].\n\ngrpregOverlap\n\nPenalized Regression Models with Overlapping Grouped Covariates.\nAuthors: Yaohui Zeng, Patrick Breheny.\n\ngtrendsR\n\nR Functions to Perform and Display Google Trends Queries. Authors:\nPhilippe Massicotte [aut, cre], Dirk Eddelbuettel [aut].\n\ngyriq\n\nKinship-Adjusted Survival SNP-Set Analysis. Authors: Martin Leclerc\nand Lajmi Lakhal Chaieb.\n\nhashids\n\nGenerate Short Unique YouTube-Like IDs (Hashes) from Integers.\nAuthors: Alex Shum [aut, cre], Ivan Akimov [aut] (original\nauthor of hashids – implemented in javascript), David Aurelio\n[ctb] (implemented hashids in python 2 and 3).\n\nhashr\n\nHash R Objects to Integers Fast. Authors: Mark van der Loo [aut,\ncre], Paul Hsieh [ctb].\n\nhdnom\n\nNomograms for High-Dimensional Cox Models. Authors: Miaozhu Li, Nan\nXiao.\n\nhierband\n\nConvex Banding of the Covariance Matrix. Authors: Jacob Bien,\nFlorentina Bunea, and Luo Xiao.\n\nhighmean\n\nTwo-Sample Tests for High-Dimensional Mean Vectors. Authors: Lifeng\nLin and Wei Pan.\n\nhindexcalculator\n\nH-Index Calculator using Data from a Web of Science (WoS) Citation\nReport. Author: Sepand Alavifard [aut, cre].\n\nhit\n\nHierarchical Inference Testing. Author: Jonas Klasen [aut, cre].\n\nhomomorpheR\n\nHomomorphic Computations in R. Author: Balasubramanian Narasimhan\n[aut, cre].\n\nhotspot\n\nSoftware Hotspot Analysis. Author: Csaba Farago.\n\nhqreg\n\nRegularization Paths for Huber Loss Regression and Quantile\nRegression Penalized by Lasso or Elastic-Net. Author: Congrui Yi.\n\nhttpcode\n\nHTTP Status Code Helper. Author: Scott Chamberlain [aut, cre].\n\nhumaniformat\n\nA Parser for Human Names. Author: Oliver Keyes.\n\niLaplace\n\nImproved Laplace Approximation for Integrals of Unimodal Functions.\nAuthors: Erlis Ruli [aut, cre], Nicola Sartori [aut], Laura\nVentura [aut].\n\niNEXT\n\nInterpolation and Extrapolation for Species Diversity.\nAuthors: T. C. Hsieh, K. H. Ma and Anne Chao.\n\niaQCA\n\nThe Irvine Robustness Assessment for Qualitative Comparative\nAnalysis. Authors: C. Ben Gibson [aut, cre], Burrel Vann Jr\n[aut].\n\nicsw\n\nInverse Compliance Score Weighting. Authors: Peter M. Aronow, Dean\nEckles and Kyle Peyton.\n\nidendr0\n\nInteractive Dendrograms. Author: Tomas Sieger.\n\nidm\n\nIncremental Decomposition Methods. Authors: Alfonso Iodice D’ Enza\n[aut], Angelos Markos [aut, cre], Davide Buttarazzi [ctb].\n\nifaTools\n\nToolkit for Item Factor Analysis with OpenMx. Author: Joshua N.\nPritikin [cre, aut].\n\nimPois\n\nImprecise Inferential Framework for Poisson Sampling Model. Authors:\nChel Hee Lee [aut, cre, cph], Mikelis Bickis [aut, ths, cph].\n\nimager\n\nImage Processing Library Based on CImg. Authors: Simon Barthelme\n[aut, cre], Antoine Cecchi [ctb].\n\nimmer\n\nItem Response Models for Multiple Ratings. Authors: Alexander\nRobitzsch [aut, cre], Jan Steinfeld [aut].\n\nimputeMissings\n\nImpute Missing Values in a Predictive Context. Authors: Matthijs\nMeire, Michel Ballings, Dirk Van den Poel.\n\nimputeTS\n\nTime Series Missing Value Imputation. Author: Steffen Moritz. In\nview: TimeSeries.\n\ninbreedR\n\nAnalysing Inbreeding Based on Genetic Markers. Authors: Martin A.\nStoffel [aut, cre], Mareike Esser [aut].\n\ninegiR\n\nIntegrate INEGI’s (Mexican Stats Office) API with R. Author: Eduardo\nFlores.\n\ninfluenceR\n\nSoftware Tools to Quantify Structural Importance of Nodes in a\nNetwork. Authors: Jacobs Simon [aut], Khanna Aditya [aut, cre],\nMadduri Kamesh [ctb], Bader David [ctb].\n\ninjectoR\n\nR Dependency Injection. Author: Lev Kuznetsov.\n\ninstaR\n\nAccess to Instagram API via R. Authors: Pablo Barbera [aut, cre],\nTiago Dantas [ctb], Jonne Guyt [ctb].\n\ninteractionTest\n\nCalculates Critical Test Statistics to Control False Discovery and\nFamilywise Error Rates in Marginal Effects Plots. Authors: Justin\nEsarey and Jane Lawrence Sumner.\n\ninterplot\n\nPlot the Effects of Variables in Interaction Terms. Authors:\nFrederick Solt, Yue Hu.\n\ninvLT\n\nInversion of Laplace-Transformed Functions. Author: Christopher\nBarry.\n\nioncopy\n\nCalling Copy Number Alterations in Amplicon Sequencing Data. Author:\nJan Budczies.\n\niotools\n\nI/O Tools for Streaming. Authors: Simon Urbanek, Taylor Arnold.\n\nipflasso\n\nIntegrative Lasso with Penalty Factors. Authors: Anne-Laure\nBoulesteix, Mathias Fuchs.\n\niptools\n\nManipulate, Validate and Resolve IP Addresses. Authors: Bob Rudis\n[aut, cre], Oliver Keyes [aut].\n\nisoph\n\nIsotonic Proportional Hazards Model. Authors: Yunro Chung [cre],\nAnastasia Ivanova, Michael G. Hudgens and Jason P. Fine.\n\njetset\n\nOne-to-One Gene-Probeset Mapping for Affymetrix Human Microarrays.\nAuthors: Qiyuan Li, Aron Eklund.\n\njmotif\n\nTools for Time Series Analysis Based on Symbolic Aggregate\nDicretization. Author: Pavel Senin [aut, cre]. In view:\nTimeSeries.\n\njrvFinance\n\nBasic Finance; NPV/IRR/Annuities/Bond-Pricing; Black Scholes.\nAuthor: Jayanth Varma [aut, cre].\n\njug\n\nCreate a Simple Web API for your R Functions. Author: Bart Smeets.\n\njvnVaR\n\nValue at Risk. Author: Hung Vu.\n\nkdecopula\n\nKernel Smoothing for Bivariate Copula Densities. Author: Thomas\nNagler [aut, cre].\n\nkergp\n\nGaussian Process Laboratory. Authors: Yves Deville, David\nGinsbourger, Olivier Roustant. Contributors: Nicolas Durrande.\n\nkernDeepStackNet\n\nKernel Deep Stacking Networks. Authors: Thomas Welchowski and\nMatthias Schmid.\n\nkerndwd\n\nDistance Weighted Discrimination (DWD) and Kernel Methods. Authors:\nBoxiang Wang, Hui Zou.\n\nkeyplayer\n\nLocating Key Players in Social Networks. Author: Weihua An; Yu-Hsin\nLiu.\n\nkeypress\n\nWait for a Key Press in a Terminal. Author: Gabor Csardi [aut,\ncre].\n\nkineticF\n\nFramework for the Analysis of Kinetic Visual Field Data. Author:\nDipesh E Patel & Mario Cortina-Borja.\n\nkmeans.ddR\n\nDistributed k-Means for Big Data using ‘ddR’ API. Authors: Vishrut\nGupta, Arash Fard.\n\nknitLatex\n\nKnitr Helpers — Mostly Tables. Author: John Shea [aut, cre]. In\nview:\nReproducibleResearch.\n\nksrlive\n\nIdentify Kinase Substrate Relationships Using Dynamic Data. Author:\nWesta Domanova.\n\nkwb.hantush\n\nCalculation of Groundwater Mounding Beneath an Infiltration Basin.\nAuthor: Michael Rustler.\n\nlabelrank\n\nPredicting Rankings of Labels. Authors: Artur Aiguzhinov [cre],\nCarlos Soares [aut].\n\nlandest\n\nLandmark Estimation of Survival and Treatment Effect. Author: Layla\nParast.\n\nlandsat8\n\nLandsat 8 Imagery Rescaled to Reflectance, Radiance and/or\nTemperature. Author: Alexandre dos Santos.\n\nlasvmR\n\nA Simple Wrapper for the LASVM Solver. Author: Aydin Demircioglu.\n\nlatex2exp\n\nUse LaTeX Expressions in Plots. Author: Stefano Meschiari [aut,\ncre]. In view:\nReproducibleResearch.\n\nlcopula\n\nLiouville Copulas. Authors: Leo Belzile [aut, cre], Christian\nGenest [aut, ctb], Alexander J. McNeil [ctb], Johanna G.\nNeslehova [ctb].\n\nldamatch\n\nMultivariate Condition Matching by Backwards Elimination Using\nLinear Discriminant Analysis. Authors: Kyle Gorman [aut, cre],\nGeza Kiss [ctb].\n\nldatuning\n\nTuning of the LDA Models Parameters. Author: Murzintcev Nikita\n[aut, cre].\n\nleaflet\n\nCreate Interactive Web Maps with the JavaScript ‘Leaflet’ Library.\nAuthors: Joe Cheng [aut, cre], Yihui Xie [aut], Hadley Wickham\n[ctb], jQuery Foundation and contributors [ctb, cph] (jQuery\nlibrary), Vladimir Agafonkin [ctb, cph] (Leaflet library),\nCloudMade [cph] (Leaflet library), Leaflet contributors [ctb]\n(Leaflet library), Leaflet Providers contributors [ctb, cph]\n(Leaflet Providers plugin), RStudio [cph].\n\nlearNN\n\nExamples of Neural Networks. Author: Bastiaan Quast [aut, cre].\n\nlfda\n\nLocal Fisher Discriminant Analysis. Author: Yuan Tang with great\ncontributions from Zachary Deane-Mayer.\n\nlift\n\nCompute the Top Decile Lift and Plot the Lift Curve. Authors: Steven\nHoornaert, Michel Ballings, Dirk Van den Poel.\n\nliftr\n\nDockerize R Markdown Documents. Authors: Miaozhu Li [ctb], Tengfei\nYin [ctb], Nan Xiao [aut, cre].\n\nlikelihoodAsy\n\nFunctions for Likelihood Asymptotics. Authors: Ruggero Bellio and\nDonald Pierce.\n\nlira\n\nLInear Regression in Astronomy. Author: Mauro Sereno.\n\nlistWithDefaults\n\nList with Defaults. Author: Russell S. Pierce.\n\nlittler\n\nR at the Command-Line via ‘r’. Author: Dirk Eddelbuettel.\n\nlogisticPCA\n\nBinary Dimensionality Reduction. Author: Andrew J. Landgraf.\n\nlongurl\n\nExpand Short URLs Using the ‘LongURL’ API. Author: Bob Rudis [aut,\ncre].\n\nloo\n\nEfficient Leave-One-Out Cross-Validation and WAIC for Bayesian\nModels. Authors: Aki Vehtari [aut], Andrew Gelman [aut], Jonah\nGabry [cre, aut], Juho Piironen [ctb], Ben Goodrich [ctb].\n\nlookupTable\n\nLook-Up Tables using S4. Authors: Enzo Jia [aut, cre], Marc Maier\n[aut].\n\nlpbrim\n\nLP-BRIM Bipartite Modularity. Authors: Timothee Poisot, Daniel B\nStouffer.\n\nlqr\n\nRobust Linear Quantile Regression. Authors: Christian E. Galarza,\nLuis Benites, Victor H. Lachos.\n\nlrgs\n\nLinear Regression by Gibbs Sampling. Author: Adam Mantz.\n\nlsei\n\nSolving Least Squares Problems under Equality/Inequality\nConstraints. Authors: Yong Wang [aut, cre], Charles L. Lawson\n[aut], Richard J. Hanson [aut].\n\nlsl\n\nLatent Structure Learning. Author: Po-Hsien Huang [aut, cre].\n\nlucr\n\nCurrency Formatting and Conversion. Author: Oliver Keyes.\n\nlulcc\n\nLand Use Change Modelling in R. Author: Simon Moulds.\n\nluzlogr\n\nLightweight Logging for R Scripts. Author: Ben Bond-Lamberty [aut,\ncre].\n\nmHG\n\nMinimum-Hypergeometric Test. Author: Kobi Perl.\n\nmaGUI\n\nA Graphical User Interface for Microarray Data Analysis. Authors:\nDhammapal Bharne, Praveen Kant, Vaibhav Vindal.\n\nmagclass\n\nData Class and Tools for Handling Spatial-Temporal Data. Authors:\nJan Philipp Dietrich, Benjamin Bodirsky, Misko Stevanovic, Lavinia\nBaumstark, Christoph Bertram, Markus Bonsch, Anastasis Giannousakis,\nFlorian Humpenoeder, David Klein, Ina Neher, Michaja Pehl, Anselm\nSchultes.\n\nmarketeR\n\nEnhanced Analytics for Marketers Navigating the Ocean of Web Data.\nAuthor: Felix Mikaelian.\n\nmarkophylo\n\nMarkov Chain Models for Phylogenetic Trees. Authors: Utkarsh J. Dang\nand G. Brian Golding. In view:\nPhylogenetics.\n\nmatlabr\n\nAn Interface for MATLAB using System Calls. Author: John Muschelli.\n\nmatlib\n\nMatrix Functions for Teaching and Learning Linear Algebra and\nMultivariate Statistics. Authors: Michael Friendly [aut, cre],\nJohn Fox [ctb], Georges Monette [ctb].\n\nmcemGLM\n\nMaximum Likelihood Estimation for Generalized Linear Mixed Models.\nAuthor: Felipe Acosta Archila.\n\nmerTools\n\nTools for Analyzing Mixed Effect Regression Models. Authors:\nJared E. Knowles [aut, cre], Carl Frederick [aut].\n\nmeta4diag\n\nMeta-Analysis for Diagnostic Test Studies. Authors: Jingyi Guo and\nAndrea Riebler. In view:\nMetaAnalysis.\n\nmetaSEM\n\nMeta-Analysis using Structural Equation Modeling. Author: Mike W.-L.\nCheung. In view:\nMetaAnalysis.\n\nmetafuse\n\nFused Lasso Approach in Regression Coefficient Clustering. Authors:\nLu Tang, Peter X.K. Song.\n\nmetansue\n\nMeta-Analysis of Studies with Non Statistically-Significant\nUnreported Effects. Author: Joaquim Radua.\n\nmeteR\n\nFitting and Plotting Tools for the Maximum Entropy Theory of Ecology\n(METE). Authors: Andy Rominger, Cory Merow.\n\nmeteo\n\nSpatio-Temporal Analysis and Mapping of Meteorological Observations.\nAuthors: Milan Kilibarda, Aleksandar Sekulic, Tomislav Hengl, Edzer\nPebesma, Benedikt Graeler.\n\nmetricsgraphics\n\nCreate Interactive Charts with the JavaScript ‘MetricsGraphics’\nLibrary. Authors: Bob Rudis [aut, cre], Ali Almossawi [ctb, cph]\n(MetricsGraphics library), Hamilton Ulmer [ctb, cph]\n(MetricsGraphics library), Mozilla [cph] (MetricsGraphics\nlibrary), jQuery Foundation and contributors [ctb, cph] (jQuery\nlibrary).\n\nmev\n\nMultivariate Extreme Value Distributions. Author: Leo Belzile [aut,\ncre].\n\nmgm\n\nEstimating Mixed Graphical Models. Author: Jonas Haslbeck.\n\nmhde\n\nMinimum Hellinger Distance Test for Normality. Authors: Paul W.\nEslinger [aut, cre], Heather Orr [aut, ctb].\n\nmidrangeMCP\n\nMultiples Comparisons Procedures Based on Studentized Midrange and\nRange Distributions. Authors: Ben Deivide [cre], Daniel Furtado\n[aut].\n\nmissDeaths\n\nCorrectly Analyse Disease Recurrence with Missing at Risk\nInformation using Population Mortality. Authors: Tomaz Stupnik\n[aut, cre], Maja Pohar Perme [aut].\n\nmixtox\n\nCurve Fitting and Mixture Toxicity Assessment. Author: Xiangwei Zhu.\n\nmlVAR\n\nMulti-Level Vector Autoregression. Authors: Sacha Epskamp, Marie K.\nDeserno and Laura F. Bringmann. In view:\nTimeSeries.\n\nmldr.datasets\n\nR Ultimate Multilabel Dataset Repository. Authors: David Charte\n[cre], Francisco Charte [aut].\n\nmlma\n\nMultilevel Mediation Analysis. Authors: Qingzhao Yu, Bin Li.\n\nmlsjunkgen\n\nUse the MLS Junk Generator Algorithm to Generate a Stream of\nPseudo-Random Numbers. Author: Steve Myles [aut, cre].\n\nmmc\n\nMultivariate Measurement Error Correction. Author: Jaejoon Song.\n\nmmtfa\n\nModel-Based Clustering and Classification with Mixtures of Modified\nt Factor Analyzers. Authors: Jeffrey L. Andrews, Paul D. McNicholas,\nand Mathieu Chalifour.\n\nmodQR\n\nMultiple-Output Directional Quantile Regression. Authors: Miroslav\nŠiman [aut], Pavel Boček [aut, cre].\n\nmodelObj\n\nA Model Object Framework for Regression Analysis. Author: Shannon T.\nHolloway.\n\nmogavs\n\nMultiobjective Genetic Algorithm for Variable Selection in\nRegression. Authors: Tommi Pajala [aut, cre], Pekka Malo [aut],\nAnkur Sinha [aut], Timo Kuosmanen [ctb].\n\nmolaR\n\nDental Surface Complexity Measurement Tools. Authors: James D.\nPampush [aut, cre, cph], Julia M. Winchester [aut, cph], Paul E.\nMorse [aut, cph], Alexander Q. Vining [aut, cph].\n\nmomr\n\nMining Metaomics Data (MetaOMineR). Authors: Edi Prifti, Emmanuelle\nLe Chatelier.\n\nmonogeneaGM\n\nGeometric Morphometric Analysis of Monogenean Anchors. Author: Tsung\nFei Khang.\n\nmonographaR\n\nTaxonomic Monographs Tools. Author: Marcelo Reginato.\n\nmoveHMM\n\nAnimal Movement Modelling using Hidden Markov Models. Authors: Theo\nMichelot, Roland Langrock, Toby Patterson, Eric Rexstad. In view:\nSpatioTemporal.\n\nmplot\n\nGraphical Model Stability and Variable Selection Procedures.\nAuthors: Garth Tarr [aut, cre], Samuel Mueller [aut], Alan Welsh\n[aut].\n\nmri\n\nModified Rand Index (1 and 2.1 and 2.2) and Modified Adjusted Rand\nIndex (1 and 2.1 and 2.2). Author: Marjan Cugmas.\n\nms.sev\n\nPackage for Calculation of ARMSS, Local MSSS and Global MSSS.\nAuthors: Helga Westerlind, Ali Manouchehrinia.\n\nmultiwave\n\nEstimation of Multivariate Long-Memory Models Parameters. Authors:\nSophie Achard [aut, cre], Irene Gannaz [aut].\n\nmvQuad\n\nMethods for Multivariate Quadrature. Author: Constantin Weiser (HHU\nof Duesseldorf / Germany). In view:\nNumericalMathematics.\n\nmvtboost\n\nTree Boosting for Multivariate Outcomes. Author: Patrick Miller\n[aut, cre].\n\nnbconvertR\n\nVignette Engine Wrapping IPython Notebooks. Author: Philipp Angerer.\n\nnhanesA\n\nNHANES Data Retrieval. Author: Christopher Endres.\n\nnivm\n\nNoninferiority Tests with Variable Margins. Author: Michael P. Fay.\n\nnlnet\n\nNonlinear Network Reconstruction and Clustering Based on DCOL\n(Distance Based on Conditional Ordered List). Authors: Haodong Liu,\nTianwei Yu.\n\nnlrr\n\nNon-Linear Relative Risk Estimation and Plotting. Author: Yiqiang\nZhan [aut, cre].\n\nnomclust\n\nHierarchical Nominal Clustering Package. Authors: Sulc Zdenek,\nRezankova Hana.\n\nnparACT\n\nNon-Parametric Measures of Actigraphy Data. Author: Christine Blume\nNayantara Santhi Manuel Schabus.\n\nnpregfast\n\nNonparametric Estimation of Regression Models with Factor-by-Curve\nInteractions. Authors: Marta Sestelo [aut, cre], Nora M.\nVillanueva [aut], Javier Roca-Pardinas [aut].\n\nnpsf\n\nNonparametric and Stochastic Efficiency and Productivity Analysis.\nAuthors: Oleg Badunenko [aut, cre], Yaryna Kolomiytseva [aut],\nPavlo Mozharovskyi [aut].\n\nnpsurv\n\nNon-Parametric Survival Analysis. Author: Yong Wang.\n\noaColors\n\nOpenAnalytics Colors Package. Author: Jason Waddell.\n\noaPlots\n\nOpenAnalytics Plots Package. Authors: Jason Waddell, Willem\nLigtenberg.\n\noai\n\nGeneral Purpose ‘Oai-PMH’ Services Client. Author: Scott Chamberlain\n[aut, cre].\n\noapackage\n\nOrthogonal Array Package. Author: Pieter Thijs Eendebak. In view:\nExperimentalDesign.\n\nodds.converter\n\nBetting Odds Conversion. Author: Marco Blume.\n\noglmx\n\nEstimation of Ordered Generalized Linear Models. Author: Nathan\nCarroll.\n\nolctools\n\nOpen Location Code Handling in R. Author: Oliver Keyes.\n\nonewaytests\n\nOne-Way Independent Groups Design. Authors: Osman Dag, Anil\nDolgun, N. Meric Konar.\n\noptCluster\n\nDetermine Optimal Clustering Algorithm and Number of Clusters.\nAuthors: Michael Sekula, Somnath Datta, and Susmita Datta.\n\noptigrab\n\nCommand-Line Parsing for an R World. Author: Christopher Brown.\n\noptismixture\n\nOptimal Mixture Weights in Multiple Importance Sampling. Authors:\nHera Y. He, Art B. Owen.\n\nordinalNet\n\nPenalized Ordinal Regression. Author: Mike Wurm [aut, cre].\n\nosrm\n\nInterface Between R and the OpenStreetMap-Based Routing Service\nOSRM. Author: Timothée Giraud [cre, aut].\n\npAnalysis\n\nBenchmarking and Rescaling R2 using Noise Percentile Analysis.\nAuthors: Joseph G Kreke, Sangeet Khemlani, Greg Trafton.\n\npackagetrackr\n\nTrack R Package Downloads from RStudio’s CRAN Mirror. Author: Jirka\nLewandowski.\n\npackcircles\n\nCircle Packing. Authors: Michael Bedward [aut, cre], David\nEppstein [aut] (Original author of Python code for graph-based\ncircle packing ported to C++ for this package).\n\npaco\n\nProcrustes Application to Cophylogenetic Analysis. Authors: Juan\nAntonio Balbuena, Timothee Poisot, Matthew Hutchinson, Fernando\nCagua.\n\npageviews\n\nAn API Client for Wikimedia Traffic Data. Author: Oliver Keyes.\n\npalettetown\n\nUse Pokemon Inspired Colour Palettes. Author: Tim Lucas.\n\npalr\n\nColour Palettes for Data. Author: Michael D. Sumner [aut, cre].\n\npangaear\n\nClient for the ‘Pangaea’ Database. Authors: Scott Chamberlain [aut,\ncre], Kara Woo [aut], Andrew MacDonald [aut], Naupaka Zimmerman\n[aut], Gavin Simpson [aut].\n\nparallelML\n\nA Parallel-Voting Algorithm for many Classifiers. Author: Wannes\nRosiers (InfoFarm).\n\nparams\n\nSimplify Parameters. Authors: Sahil Seth [aut, cre], Yihui Xie\n[ctb] (kable from knitr R/table.R).\n\nparsec\n\nPartial Orders in Socio-Economics. Authors: Alberto Arcagni [aut,\ncre], Marco Fattore [ctb].\n\npatPRO\n\nVisualizing Temporal Microbiome Data. Authors: Hannigan GD, Loesche\nMA, Hodkinson BP, Mehta S, Grice EA.\n\npbdZMQ\n\nProgramming with Big Data – Interface to ZeroMQ. Authors: Wei-Chen\nChen [aut, cre], Drew Schmidt [aut], Whit Armstrong [ctb]\n(some functions are modified from the rzmq for backward\ncompatibility), Brian Ripley [ctb] (C code of shellexec), R Core\nteam [ctb] (some functions are modified from the R source code).\n\npcadapt\n\nPrincipal Component Analysis for Outlier Detection. Authors:\nKeurcien Luu, Michael G.B. Blum.\n\npch\n\nPiecewise Constant Hazards Models for Censored and Truncated Data.\nAuthor: Paolo Frumento.\n\npco\n\nPanel Cointegration Tests. Author: Georgi Marinov.\n\npersonograph\n\nPictographic Representation of Treatment Effects. Authors: Joel\nKuiper [aut, cre], Iain Marshall [aut].\n\nphonenumber\n\nConvert Letters to Numbers and Back as on a Telephone Keypad.\nAuthor: Steve Myles [aut, cre].\n\nphyext2\n\nAn Extension (for Package ‘SigTree’) of Some of the Classes in\nPackage ‘phylobase’. Author: J. Conrad Stack.\n\nphylometrics\n\nEstimating Statistical Errors of Phylogenetic Metrics. Authors: Xia\nHua, Lindell Bromham.\n\nphylosignal\n\nExploring the Phylogenetic Signal in Continuous Traits. Author:\nFrancois Keck.\n\nphyndr\n\nMatches Tip and Trait Data. Authors: Rich FitzJohn, Matt Pennell and\nWill Cornwell.\n\npid\n\nProcess Improvement using Data. Author: Kevin Dunn [aut, cre].\n\npiecewiseSEM\n\nPiecewise Structural Equation Modeling. Author: Jon Lefcheck.\n\npinnacle.API\n\nA Wrapper for the Pinnacle Sports API. Authors: Marco Blume,\nNicholas Jhirad, Amine Gassem.\n\npixiedust\n\nTables so Beautifully Fine-Tuned You Will Believe It’s Magic.\nAuthor: Benjamin Nutter [aut, cre].\n\npkgconfig\n\nPrivate Configuration for R Packages. Author: Gabor Csardi.\n\npla\n\nParallel Line Assays. Author: Jens Henrik Badsberg.\n\nplfMA\n\nA GUI to View, Design and Export Various Graphs of Data. Authors:\nDhammapal Bharne, Vaibhav Vindal.\n\nplotly\n\nCreate Interactive Web Graphics via Plotly’s JavaScript Graphing\nLibrary. Authors: Carson Sievert [aut, cre], Chris Parmer [aut,\ncph], Toby Hocking [aut], Scott Chamberlain [aut], Karthik Ram\n[aut], Marianne Corvellec [aut], Pedro Despouy [aut].\n\npnea\n\nParametric Network Enrichment Analysis. Authors: Mirko Signorelli,\nVeronica Vinciotti and Ernst C. Wit.\n\npnf\n\nPrime Numbers and Integer Factorization. Author: Abby Rothway.\n\npoisson\n\nSimulating Homogenous & Non-Homogenous Poisson Processes. Authors:\nKristian Brock [aut], Daniel Slade [ctb].\n\npolyfreqs\n\nBayesian Population Genomics in Autopolyploids. Author: Paul\nBlischak [aut, cre].\n\npopEpi\n\nFunctions for Epidemiological Analysis using Population Data.\nAuthors: J Miettinen, M Rantanen, K Seppa, J Pitkaniemi.\n\npopprxl\n\nRead GenAlEx Files Directly from Excel. Author: Zhian N. Kamvar\n[cre, aut].\n\npraise\n\nPraise Users. Authors: Gabor Csardi, Sindre Sorhus.\n\nprclust\n\nPenalized Regression-Based Clustering Method. Authors: Chong Wu, Wei\nPan.\n\nprepdat\n\nPreparing Experimental Data for Statistical Analysis. Authors:\nAyala S. Allon [aut, cre], Roy Luria [aut], Jim Grange [ctb],\nNachshon Meiran [ctb].\n\npreprocomb\n\nTools for Preprocessing Combinations. Author: Markus Vattulainen.\n\nprettymapr\n\nScale Bar, North Arrow, and Pretty Margins in R. Author: Dewey\nDunnington.\n\nprimes\n\nGenerate and Test for Prime Numbers. Author: Oliver Keyes.\n\nprism\n\nAccess Data from the Oregon State Prism Climate Project. Authors:\nHart Edmund [aut, cre], Kendon Bell [aut].\n\npro\n\nPoint-Process Response Model for Optogenetics. Authors: Xi (Rossi)\nLUO with contributions from Dylan Small and Vikaas Sohal.\n\nprofilr\n\nQuickly Profile Data in R. Author: Paul Hendricks [aut, cre].\n\nprogenyClust\n\nFinding the Optimal Cluster Number Using Progeny Clustering. Author:\nC.W. Hu.\n\nprop.comb.RR\n\nAnalyzing Combination of Proportions and Relative Risk. Authors:\nMaria Alvarez and Javier Roca-Pardinas.\n\nproton\n\nThe Proton Game. Authors: Przemysław Biecek [aut, cre], Witold\nChodor [trl], Foundation SmarterPoland.pl [cph].\n\nprozor\n\nMinimal Protein Set Explaining Peptide Spectrum Matches. Author:\nWitold Wolski.\n\npscore\n\nStandardizing Physiological Composite Risk Endpoints. Author:\nJoshua F. Wiley.\n\nptycho\n\nBayesian Variable Selection with Hierarchical Priors. Authors:\nLaurel Stell and Chiara Sabatti.\n\npurge\n\nPurge Training Data from Models. Authors: Marc Maier [cre],\nChaoqun Jia [ctb], MassMutual Advanced Analytics [aut].\n\npurrr\n\nFunctional Programming Tools. Authors: Hadley Wickham [aut, cre],\nLionel Henry [ctb], RStudio [cph].\n\npweight\n\nP-Value Weighting. Authors: Edgar Dobriban [aut, cre], Kristen\nFortney [aut].\n\npwrRasch\n\nStatistical Power Simulation for Testing the Rasch Model. Authors:\nTakuya Yanagida [cre, aut], Jan Steinfeld [aut], Thomas Kiefer\n[ctb]. In view:\nPsychometrics.\n\npystr\n\nPython String Methods in R. Author: Nicole White.\n\nqap\n\nHeuristics for the Quadratic Assignment Problem (QAP). Authors:\nMichael Hahsler [aut, cre, cph], Franz Rendl [ctb, cph]. In\nview:\nOptimization.\n\nqlcData\n\nProcessing Data for Quantitative Language Comparison (QLC). Author:\nMichael Cyosuw.\n\nqlcVisualize\n\nVisualization for Quantitative Language Comparison (QLC). Author:\nMichael Cysouw.\n\nqrage\n\nTools that Create D3 JavaScript Force Directed Graph from R.\nAuthors: Shingo Yamamoto [aut, cre], RStudio, Inc. [cph],\nMichael Bostock [ctb, cph] (D3.js library), jQuery Foundation\n[cph] (jQuery library and jQuery UI library), jQuery contributors\n[ctb, cph] (jQuery library), jQuery UI contributors [ctb, cph]\n(jQuery UI library).\n\nqrcode\n\nQRcode Generator for R. Author: Victor Teh.\n\nqrjoint\n\nJoint Estimation in Linear Quantile Regression. Author: Surya\nTokdar.\n\nqtlcharts\n\nInteractive Graphics for QTL Experiments. Authors: Karl W Broman\n[aut, cre], Michael Bostock [ctb, cph] (d3.js library in\nhtmlwidgets/lib), Justin Palmer [ctb, cph] (d3.tip library in\nhtmlwidgets/lib), Cynthia Brewer [cph] (ColorBrewer library in\nhtmlwidgets/lib), Mark Harrower [cph] (ColorBrewer library in\nhtmlwidgets/lib), The Pennsylvania State University [cph]\n(ColorBrewer library in htmlwidgets/lib), jQuery Foundation [cph]\n(jQuery library in htmlwidgets/lib), jQuery contributors [ctb]\n(jQuery library in htmlwidgets/lib), jQuery UI contributors [ctb]\n(jQuery UI library in htmlwidgets/lib).\n\nqualvar\n\nImplements Indices of Qualitative Variation Proposed by Wilcox\n(1973). Author: Joel Gombin.\n\nquantable\n\nStreamline Descriptive Analysis of Quantitative Data Matrices.\nAuthor: Witold Wolski.\n\nquantileDA\n\nQuantile Classifier. Authors: Christian Hennig, Cinzia Viroli.\n\nquickmapr\n\nQuickly Map and Explore Spatial Data. Author: Jeffrey W. Hollister\n[aut, cre].\n\nqut\n\nQuantile Universal Threshold. Authors: Jairo Diaz, Sylvain Sardy,\nCaroline Giacobino, Nick Hengartner.\n\nrAmCharts\n\nJavaScript Charts API Tool. Authors: Jeffery Petit [aut, cre],\nAntanas Marcelionis [aut, cph] (‘AmCharts’ library in th directory\nhtmlwidgets/lib/amcharts), Benoit Thieurmel [aut, ctb],\nDataKnowledge [ctb] (See official web site at\nhttp://www.datak.fr).\n\nrGroovy\n\nGroovy Language Integration. Author: Thomas P. Fuller.\n\nrPowerSampleSize\n\nSample Size Computations Controlling the Type-II Generalized\nFamily-Wise Error Rate. Authors: Pierre Lafaye de Micheaux, Benoit\nLiquet and Jeremie Riou.\n\nradiomics\n\nRadiomic Image Processing Toolbox. Author: Joel Carlson.\n\nrafalib\n\nConvenience Functions for Routine Data Exploration. Authors:\nRafael A. Irizarry and Michael I. Love.\n\nrandomForest.ddR\n\nDistributed ‘randomForest’ for Big Data using ‘ddR’ API. Authors:\nVishrut Gupta, Arash Fard, Winston Li, Matthew Saltz.\n\nrandomizeR\n\nRandomization for Clinical Trials. Authors: Thi Mui Pham [ctb],\nDavid Schindler [aut], Diane Uschner [aut, cre].\n\nranger\n\nA Fast Implementation of Random Forests. Author: Marvin N. Wright.\nIn view:\nMachineLearning.\n\nrase\n\nRange Ancestral State Estimation for Phylogeography and Comparative\nAnalyses. Authors: Ignacio Quintero [aut, cre], Forrest W.\nCrawford [aut], Petr Keil [aut].\n\nrcanvec\n\nAccess and Plot CanVec and CanVec+ Data for Rapid Basemap Creation\nin Canada. Author: Dewey Dunnington.\n\nrchess\n\nChess Move, Generation/Validation, Piece Placement/Movement, and\nCheck/Checkmate/Stalemate Detection. Author: Joshua Kunst.\n\nrcrypt\n\nSymmetric File Encryption Using GPG. Author: Brett Klamer [aut,\ncre].\n\nrddtools\n\nToolbox for Regression Discontinuity Design (‘RDD’). Authors:\nMatthieu Stigler [aut], Bastiaan Quast [aut, cre].\n\nreReg\n\nRecurrent Event Regression. Author: Sy Han (Steven) Chiou.\n\nrecoder\n\nA Simple and Flexible Recoder. Author: Ali Sanaei.\n\nreda\n\nRecurrent Event Data Analysis. Authors: Wenjie Wang [aut, cre],\nHaoda Fu [aut], Jun Yan [ctb].\n\nrefund.shiny\n\nInteractive Plotting for Functional Data Analyses. Authors: Julia\nWrobel [aut, cre], Jeff Goldsmith [aut].\n\nrelen\n\nCompute Relative Entropy. Author: Soeren Braehmer.\n\nrepijson\n\nTools for Handling EpiJSON (Epidemiology Data) Files. Authors: Andy\nSouth [aut, cre], Thomas Finnie [aut], Ellie Sherrard-Smith\n[aut], Ana Bento [aut], Thibaut Jombart [aut].\n\nrepo\n\nA Resource Manager for R Objects. Author: Francesco Napolitano.\n\nreservoir\n\nTools for Analysis, Design, and Operation of Water Supply Storages.\nAuthors: Sean Turner [aut, cre], Stefano Galelli [aut].\n\nresumer\n\nBuild Resumes with R. Author: Jared Lander [aut, cre]. In view:\nReproducibleResearch.\n\nrgeolocate\n\nIP Address Geolocation. Authors: Oliver Keyes [aut, cre], Drew\nSchmidt [aut], David Robinson [ctb], Maxmind, Inc. [cph],\nPascal Gloor [cph].\n\nrglwidget\n\n‘rgl’ in ‘htmlwidgets’ Framework. Author: Duncan Murdoch.\n\nrhandsontable\n\nInterface to the ‘Handsontable.js’ Library. Authors: Jonathan Owen\n[aut, cre, cph], Jeff Allen [ctb], Yihui Xie [ctb], Enzo\nMartoglio [ctb], Warpechowski Marcin [ctb, cph] (Handsontable.js\nlibrary), Handsoncode sp. z o.o. [ctb, cph] (Handsontable.js\nlibrary), Aisch Gregor [ctb, cph] (Chroma.js library), Wood Tim\n[ctb, cph] (Moment.js library), Chernev Iskren [ctb, cph]\n(Moment.js library), Moment.js contributors [ctb, cph] (Moment.js\nlibrary), Bushell David [ctb, cph] (Pikaday.js library), jQuery\nFoundation [ctb, cph] (jQuery.js library), Splunk Inc [ctb, cph]\n(Sparkline.js library).\n\nridigbio\n\nInterface to the iDigBio Data API. Authors: Francois Michonneau\n[aut, cph], Matthew Collins [aut, cre], Scott Chamberlain\n[ctb].\n\nriskR\n\nRisk Management. Author: Marcelo Brutti Righi.\n\nrleafmap\n\nInteractive Maps with R and Leaflet. Author: Francois Keck.\n\nrnetcarto\n\nFast Network Modularity and Roles Computation by Simulated Annealing\n(Rgraph C Library Wrapper for R). Authors: Guilhem Doulcier [aut,\ncre] (R bindings, current implementation of the simulated annealing\nalgorithm), Roger Guimera [ctb] (Author of the original rgraph\nlibrary), Daniel B. Stouffer [aut, ths].\n\nrnn\n\nRecurrent Neural Network. Author: Bastiaan Quast [aut, cre].\n\nrollply\n\nMoving-Window Add-on for ‘plyr’. Author: Alexandre Genin.\n\nrosm\n\nPlot Raster Map Tiles from Open Street Map and Other Sources.\nAuthors: Dewey Dunnington [aut, cre], Timothée Giraud [ctb].\n\nrotl\n\nInterface to the ‘Open Tree of Life’ API. Authors: Francois\nMichonneau [aut, cre], Joseph Brown [aut], David Winter [aut].\n\nrpca\n\nRobustPCA: Decompose a Matrix into Low-Rank and Sparse Components.\nAuthor: Maciek Sykulski [aut, cre].\n\nrpdo\n\nPacific Decadal Oscillation Index. Authors: Joe Thorley [aut,\ncre], Nathan Mantua [aut, dtc], Steven R. Hare [aut, dtc].\n\nrpivotTable\n\nBuild Powerful Pivot Tables and Dynamically Slice & Dice your Data.\nAuthors: Enzo Martoglio [aut, cre] (R interface), Nicolas kruchten\n[ctb, cph] (pivottable library).\n\nrpnf\n\nPoint and Figure Package. Author: Sascha Herrmann.\n\nrrepast\n\nInvoke ‘Repast Simphony’ Simulation Models. Authors: Antonio Prestes\nGarcia [aut, cre], Alfonso Rodriguez-Paton [aut, ths].\n\nrscopus\n\nScopus Database API Interface. Author: John Muschelli.\n\nrsggm\n\nRobust Sparse Gaussian Graphical Modeling via the Gamma-Divergence.\nAuthor: Kei Hirose.\n\nrstan\n\nR Interface to Stan. Authors: Jiqiang Guo [aut], Daniel Lee\n[ctb], Krzysztof Sakrejda [ctb], Jonah Gabry [aut], Ben\nGoodrich [cre, aut], Joel de Guzman [cph] (Boost), Eric Niebler\n[cph] (Boost), Thomas Heller [cph] (Boost), John Fletcher\n[cph] (Boost). In view:\nBayesian.\n\nrstatscn\n\nR Interface for China National Data. Author: Xuehui YANG.\n\nrstpm2\n\nFlexible Link-Based Survival Models. Authors: Mark Clements [aut,\ncre], Xing-Rong Liu [aut], Paul Lambert [ctb].\n\nrsvd\n\nRandomized Singular Value Decomposition. Author: N. Benjamin\nErichson [aut, cre].\n\nrtimes\n\nClient for New York Times APIs. Author: Scott Chamberlain [aut,\ncre].\n\nrtkore\n\nSTK++ Core Library Integration to R using Rcpp. Authors: Serge\nIovleff [aut, cre], Parmeet Bhatia [ctb].\n\nrtson\n\nTyped JSON. Author: Alexandre Maurel.\n\nrunittotestthat\n\nConvert ‘RUnit’ Test Functions into ‘testthat’ Tests. Author:\nRichard Cotton [aut, cre].\n\nrusda\n\nInterface to USDA Databases. Author: Franz-Sebastian Krah.\n\nrwirelesscom\n\nBasic Wireless Communications Simulation. Author: Alberto Gutierrez\n[aut, cre].\n\nrwunderground\n\nR Interface to Weather Underground API. Author: Alex Shum.\n\nsSDR\n\nTools Developed for Structured Sufficient Dimension Reduction\n(sSDR). Authors: Yang Liu, Francesca Chiaromonte, Bing Li.\n\nsValues\n\nMeasures of the Sturdiness of Regression Coefficients. Author:\nCarlos Cinelli.\n\nsatellite\n\nVarious Functions for Handling and Manipulating Remote Sensing Data.\nAuthors: Thomas Nauss, Hanna Meyer, Florian Detsch, Tim Appelhans.\n\nsbmSDP\n\nSemidefinite Programming for Fitting Block Models of Equal Block\nSizes. Author: Arash A. Amini.\n\nscatterD3\n\nD3 JavaScript Scatterplot from R. Author: Julien Barnier [aut,\ncre].\n\nschumaker\n\nSchumaker Shape-Preserving Spline. Authors: Stuart Baumann [aut,\ncre], Margaryta Klymak[ctb].\n\nscmamp\n\nStatistical Comparison of Multiple Algorithms in Multiple Problems.\nAuthors: Borja Calvo [aut, cre], Guzman Santafe [aut].\n\nscore\n\nA Package to Score Behavioral Questionnaires. Author: Jaejoon Song.\n\nscorer\n\nQuickly Score Models. Author: Paul Hendricks [aut, cre].\n\nsdPrior\n\nScale-Dependent Hyperpriors in Structured Additive Distributional\nRegression. Author: Nadja Klein.\n\nsearchConsoleR\n\nGoogle Search Console APIv3 R Client. Authors: Mark Edmondson [aut,\ncre], Jennifer Bryan [ctb].\n\nseeclickfixr\n\nAccess Data from the SeeClickFix Web API. Authors: Justin de\nBenedictis-Kessner [aut, cre], Christian Lemp [ctb].\n\nseismic\n\nPredict Information Cascade by Self-Exciting Point Process. Authors:\nHera He, Murat Erdogdu, Qingyuan Zhao.\n\nsejmRP\n\nAn Information About Deputies and Votings in Polish Diet. Authors:\nPiotr Smuda [aut, cre], Przemyslaw Biecek [aut], Tomasz\nMikolajczyk [ctb].\n\nselectiveInference\n\nTools for Selective Inference. Authors: Ryan Tibshirani, Rob\nTibshirani, Jonathan Taylor, Joshua Loftus, Stephen Reid.\n\nsgRSEA\n\nEnrichment Analysis of CRISPR/Cas9 Knockout Screen Data. Authors:\nJungsik Noh, Beibei Chen.\n\nshinystan\n\nInteractive Visual and Numerical Diagnostics and Posterior Analysis\nfor Bayesian Models. Authors: Jonah Gabry [aut, cre], Stan\nDevelopment Team [ctb], Michael Andreae [ctb], Michael\nBetancourt [ctb], Bob Carpenter [ctb], Yuanjun Gao [ctb],\nAndrew Gelman [ctb], Ben Goodrich [ctb], Daniel Lee [ctb],\nDongying Song [ctb], Rob Trangucci [ctb].\n\nsignalHsmm\n\nPredict Presence of Signal Peptides. Authors: Michal Burdukiewicz\n[cre, aut], Piotr Sobczyk [aut].\n\nsimest\n\nConstrained Single Index Model Estimation. Authors: Arun Kumar\nKuchibhotla, Rohit Kumar Patra.\n\nsimmer\n\nJust Let it Simmer. Authors: Bart Smeets [aut], Iñaki Ucar [aut,\ncre].\n\nsimmr\n\nA Stable Isotope Mixing Model. Author: Andrew Parnell.\n\nsimplr\n\nBasic Symbolic Expression Simplification. Authors: Oliver Flasch\n[aut, cre], Felix Gorschlueter [aut], Leo Liberti [ctb].\n\nsimr\n\nPower Analysis for Generalised Linear Mixed Models by Simulation.\nAuthors: Peter Green, Catriona MacLeod.\n\nsinaplot\n\nAn Enhanced Chart for Simple and Truthful Representation of Single\nObservations over Multiple Classes. Authors: Nikos Sidiropoulos\n[aut, cre], Sina Hadi Sohi [aut], Nicolas Rapin [aut],\nFrederik Otzen Bagger [aut].\n\nsisal\n\nSequential Input Selection Algorithm. Author: Mikko Korpela [aut,\ncre].\n\nsmallarea\n\nFits a Fay Herriot Model. Author: Abhishek Nandy.\n\nsmerc\n\nStatistical Methods for Regional Counts. Author: Joshua French.\n\nsmint\n\nSmooth Multivariate Interpolation for Gridded and Scattered Data.\nAuthors: Yves Deville Yann Richet. Fortran codes by William Thacker,\nManjula Iyer Jingwei Zhang, Laynet Watson, Jeffrey Birch, Manjula\nIyer, Michael Berry and Robert Renka. Fortran codes by Alain Hebert.\n\nsnn\n\nStabilized Nearest Neighbor Classifier. Authors: Wei Sun, Xingye\nQiao, and Guang Cheng.\n\nsodavis\n\nSODA: Main and Interaction Effects Selection for Discriminant\nAnalysis and Logistic Regression. Authors: Yang Li, Jun S. Liu.\n\nsodium\n\nA Modern and Easy-to-Use Crypto Library. Author: Jeroen Ooms.\n\nsolidearthtide\n\nSolid Earth Tide Computation. Authors: Jose Gama [aut, cre],\nDennis Milbert [aut, cph].\n\nspTDyn\n\nSpatially Varying and Spatio-Temporal Dynamic Linear Models.\nAuthors: K. Shuvo Bakar, Philip Kokic, Huidong Jin.\n\nspanel\n\nSpatial Panel Data Models. Author: Taha Zaghdoudi.\n\nsparsereg\n\nSparse Bayesian Models for Regression, Subgroup Analysis, and Panel\nData. Authors: Marc Ratkovic and Dustin Tingley.\n\nspatialfil\n\nApplication of 2D Convolution Kernel Filters to Matrices or 3D\nArrays. Authors: Nicola Dinapoli, Roberto Gatta.\n\nspduration\n\nSplit-Population Duration (Cure) Regression. Authors: Andreas Beger\n[aut, cre], Daina Chiba [aut], Daniel Hill [aut], Nils\nMetternich [aut], Shahryar Minhas [aut], Michael Ward [cph].\n\nspeciesgeocodeR\n\nPrepare Species Distributions for the Use in Phylogenetic Analyses.\nAuthor: Alexander Zizka [aut, cre].\n\nspecmine\n\nMetabolomics and Spectral Data Analysis and Mining. Authors:\nChristopher Costa, Marcelo Maraschin, Miguel Rocha.\n\nspectrino\n\nSpectra Visualization, Organizer and Data Preparation. Author:\nTeodor Krastev.\n\nspinyReg\n\nSparse Generative Model and Its EM Algorithm. Authors: Charles\nBouveyron, Julien Chiquet, Pierre Latouche, Pierre-Alexandre Mattei.\n\nspm12r\n\nWrapper Functions for SPM (Statistical Parametric Mapping) Version\n12 from the Wellcome Trust Centre for Neuroimaging. Author: John\nMuschelli.\n\nspoccutils\n\nUtilities for Use with ‘spocc’. Author: Scott Chamberlain [aut,\ncre].\n\nspsann\n\nOptimization of Sample Configurations using Spatial Simulated\nAnnealing. Authors: Alessandro Samuel-Rosa [aut, cre], Lucia\nHelena Cunha dos Anjos [ths], Gustavo de Mattos Vasques [ths],\nGerard B M Heuvelink [ths], Edzer Pebesma [ctb], Jon Skoien\n[ctb], Joshua French [ctb], Pierre Roudier [ctb], Dick Brus\n[ctb], Murray Lark [ctb].\n\nspsi\n\nShape-Preserving Uni-Variate and Bi-Variate Spline Interpolation.\nAuthors: Szymon Sacher & Andrew Clausen. Excerpts adapted from\nFortran code Copyright (C) Paolo Costantini.\n\nsscor\n\nRobust Correlation Estimation and Testing Based on Spatial Signs.\nAuthors: Alexander Duerre [aut, cre], Daniel Vogel [aut].\n\nstarma\n\nModelling Space Time AutoRegressive Moving Average (STARMA)\nProcesses. Author: Felix Cheysson.\n\nstationaRy\n\nGet Hourly Meteorological Data from Global Stations. Author: Richard\nIannone [aut, cre].\n\nstatnetWeb\n\nA Graphical User Interface for Network Modeling with ‘Statnet’.\nAuthors: Emily Beylerian [cre, aut], Kirk Li [ctb], Samuel\nJenness [ctb], Martina Morris [ctb].\n\nsteadyICA\n\nICA and Tests of Independence via Multivariate Distance Covariance.\nAuthors: Benjamin B. Risk and Nicholas A. James and David S.\nMatteson.\n\nstmBrowser\n\nStructural Topic Model Browser. Authors: Michael K. Freeman, Jason\nChuang, Margaret E. Roberts, Brandon M. Stewart and Dustin Tingley.\n\nstplanr\n\nSustainable Transport Planning. Authors: Robin Lovelace [aut,\ncre], Richard Ellison [aut] (Author of various functions), Barry\nRowlingson [aut] (Author of overline), Nick Bearman [aut]\n(Co-author of gclip).\n\nstringgaussnet\n\nPPI and Gaussian Network Construction from Transcriptomic Analysis\nResults Integrating a Multilevel Factor. Authors: Emmanuel Chaplais,\nHenri-Jean Garchon.\n\nsubscore\n\nSubScore Computing Functions in Classical Test Theory. Authors:\nShenghai Dai [aut, cre], Xiaolin Wang [aut], Dubravka Svetina\n[aut].\n\nsubspace\n\nInterface to OpenSubspace. Authors: Marwan Hassani [aut, cre],\nMatthias Hansen [aut], Emmanuel Müller [ctb], Ira Assent\n[ctb], Stephan Günnemann [ctb], Timm Jansen [ctb], Thomas\nSeidl [ctb], University of Waikato [ctb, cph].\n\nsurveyeditor\n\nGenerate a Survey that can be Completed by Survey Respondents.\nAuthor: Char Leung.\n\nsurveyplanning\n\nSurvey Planning Tools. Authors: Juris Breidaks [aut, cre], Martins\nLiberts [aut], Janis Jukams [aut].\n\nsvgPanZoom\n\nR ‘Htmlwidget’ to Add Pan and Zoom to Almost any R Graphic. Authors:\nAnders Riutta et. al. [aut, cph] (svg-pan-zoom.js BSD-licensed\nlibrary in htmlwidgets/lib), Jorik Tangelder [aut, cph] (hammer.js\nMIT-licensed touch library in htmlwidgets/lib), Kent Russell [aut,\ncre] (R interface to svg-pan-zoom.js).\n\nsvs\n\nTools for Semantic Vector Spaces. Author: Koen Plevoets [aut,\ncre].\n\nswirlify\n\nA Toolbox for Writing ‘swirl’ Courses. Authors: Sean Kross [aut,\ncre], Nick Carchedi [aut], Chih-Cheng Liang [ctb], Wush Wu\n[ctb].\n\nswitchr\n\nInstalling, Managing, and Switching Between Distinct Sets of\nInstalled Packages. Author: Gabriel Becker[aut, cre].\n\nswitchrGist\n\nPublish Package Manifests to GitHub Gists. Author: Gabriel Becker\n[aut, cre].\n\ntaber\n\nSplit and Recombine Your Data. Author: Seth Wenchel [aut, cre,\ncph].\n\ntablaxlsx\n\nWrite Formatted Tables in Excel Workbooks. Author: Jesus Maria\nRodriguez Rodriguez.\n\ntailloss\n\nEstimate the Probability in the Upper Tail of the Aggregate Loss\nDistribution. Authors: Isabella Gollini [aut, cre], Jonathan\nRougier [ctb].\n\ntextreuse\n\nDetect Text Reuse and Document Similarity. Author: Lincoln Mullen\n[aut, cre]. In view:\nNaturalLanguageProcessing.\n\ntgcd\n\nThermoluminescence Glow Curve Deconvolution. Authors: Jun Peng\n[aut, cre], Jorge More [ctb], Burton Garbow [ctb], Kenneth\nHillstrom [ctb], John Burkardt [ctb], Linda R. Petzold [ctb],\nAlan C. Hindmarsh [ctb], R. Woodrow Setzer [ctb].\n\ntglm\n\nBinary Regressions under Independent Student-t Priors. Author:\nYingbo Li.\n\nthreewords\n\nRepresent Precise Coordinates in Three Words. Author: Oliver Keyes.\n\ntigris\n\nLoad Census TIGER/Line Shapefiles into R. Authors: Kyle Walker\n[aut, cre], Bob Rudis [ctb].\n\ntimedelay\n\nTime Delay Estimation for Stochastic Time Series of Gravitationally\nLensed Quasars. Authors: Hyungsuk Tak, Kaisey Mandel, David A. van\nDyk, Vinay L. Kashyap, Xiao-Li Meng, and Aneta Siemiginowska.\n\ntitanic\n\nTitanic Passenger Survival Data Set. Author: Paul Hendricks [aut,\ncre].\n\ntmlenet\n\nTargeted Maximum Likelihood Estimation for Network Data. Authors:\nOleg Sofrygin [aut, cre], Mark J. van der Laan [aut].\n\ntmod\n\nTranscriptional Module Analysis. Author: January Weiner.\n\ntmvnsim\n\nTruncated Multivariate Normal Simulation. Author: Samsiddhi\nBhattacjarjee.\n\ntnam\n\nTemporal Network Autocorrelation Models (TNAM). Authors: Philip\nLeifeld [aut, cre], Skyler J. Cranmer [ctb].\n\ntolBasis\n\nFundamental Definitions and Utilities of the Time Oriented Language\n(TOL). Author: Pedro Gea.\n\ntracheideR\n\nStandardize Tracheidograms. Author: Filipe Campelo.\n\ntraits\n\nSpecies Trait Data from Around the Web. Authors: Scott Chamberlain\n[aut, cre], Zachary Foster [aut], Ignasi Bartomeus [aut],\nDavid LeBauer [aut], David Harris [aut].\n\ntranscribeR\n\nAutomated Transcription of Audio Files Through the HP IDOL API.\nAuthors: Christopher Lucas, Dean Knox, Dustin Tingley, Thomas\nScanlan, Shiv Sunil, Michael May, Angela Su.\n\ntranslateSPSS2R\n\nToolset for Translating SPSS-Syntax to R-Code. Authors: Andreas\nWygrabek [aut, cre], Bastian Wiessner [aut], eoda GmbH [cph].\n\ntranslation.ko\n\nR Manuals Literally Translated in Korean. Authors: Chel Hee Lee\n[aut, cre], Edward Kang [ctb], Sunyoung Kim [ctb], Heather Kim\n[ctb].\n\ntreescape\n\nStatistical Exploration of Landscapes of Phylogenetic Trees.\nAuthors: Thibaut Jombart [aut], Michelle Kendall [aut, cre],\nJacob Almagro-Garcia [aut], Caroline Colijn [aut].\n\ntrib\n\nAnalysing and Visualizing Tribology Measurements. Authors: Gokce\nMehmet Ay [aut, cre], Osman Nuri Celik [ths].\n\ntrimr\n\nAn Implementation of Common Response Time Trimming Methods. Author:\nJames Grange [aut, cre].\n\ntsPI\n\nImproved Prediction Intervals for ARIMA Processes and Structural\nTime Series. Author: Jouni Helske. In view:\nTimeSeries.\n\ntseriesEntropy\n\nEntropy Based Analysis and Tests for Time Series. Author: Simone\nGiannerini. In view:\nTimeSeries.\n\ntsna\n\nTools for Temporal Social Network Analysis. Authors: Skye\nBender-deMoll [aut, cre], Martina Morris [aut], James Moody\n[ctb].\n\ntuber\n\nClient for the YouTube API. Author: Gaurav Sood [aut, cre].\n\ntumgr\n\nTumor Growth Rate Analysis. Author: Julia Wilkerson.\n\ntweet2r\n\nTwitter Collector and Export to ‘postGIS’. Author: Pau Aragó.\n\nukgasapi\n\nAPI for UK Gas Market Information. Author: Timothy Wong [aut,\ncre].\n\numx\n\nHelper Functions for Structural Equation Modelling in OpenMx.\nAuthor: Timothy C Bates [aut, cre].\n\nunfoldr\n\nStereological Unfolding for Spheroidal Particles. Authors: Markus\nBaaske [aut, cre], Felix Ballani [ctb].\n\nuniqueAtomMat\n\nFinding Unique or Duplicated Rows or Columns for Atomic Matrices.\nAuthor: Long Qu [aut, cre].\n\nunitedR\n\nAssessment and Evaluation of Formations in United. Author: David\nSchindler [aut, cre].\n\nuptimeRobot\n\nAccess the UptimeRobot Ping API. Author: Gabriele Baldassarre [aut,\ncre].\n\nurlshorteneR\n\nR Wrapper for the Bit.ly, Goo.gl and Is.gd URL Shortening Services.\nAuthor: John Malc.\n\nvalidate\n\nData Validation Infrastructure. Authors: Mark van der Loo [cre,\naut], Edwin de Jonge [aut], Paul Hsieh [ctb].\n\nvalottery\n\nResults from the Virginia Lottery Draw Games. Author: Clay Ford\n[cre, aut].\n\nvarhandle\n\nFunctions for Robust Variable Handling. Author: Mehrad Mahmoudian\n[aut, cre].\n\nvarian\n\nVariability Analysis in R. Authors: Joshua F. Wiley [aut, cre],\nElkhart Group Limited [cph].\n\nversions\n\nQuery and Install Specific Versions of Packages on CRAN. Author:\nNick Golding.\n\nvertexenum\n\nVertex Enumeration of Polytopes. Author: Robert Robere.\n\nvipor\n\nPlot Categorical Data Using Quasirandom Noise and Density Estimates.\nAuthors: Scott Sherrill-Mix, Erik Clarke.\n\nviridis\n\nMatplotlib Default Color Map. Authors: Simon Garnier [aut, cre],\nNoam Ross [ctb, cph] (Continuous scale), Bob Rudis [ctb, cph]\n(Combined scales).\n\nviridisLite\n\nDefault Color Maps from ‘matplotlib’ (Lite Version). Authors: Simon\nGarnier [aut, cre], Noam Ross [ctb, cph], Bob Rudis [ctb,\ncph].\n\nvisNetwork\n\nNetwork Visualization using ‘vis.js’ Library. Authors: Almende B.V.\n[aut, cph] (vis.js library in htmlwidgets/lib), Benoit Thieurmel\n[aut, cre] (R interface).\n\nvtreat\n\nSimple Variable Treatment. Authors: John Mount, Nina Zumel.\n\nwBoot\n\nwBootstrap Routines. Author: Neil A. Weiss.\n\nwPerm\n\nPermutation Tests. Author: Neil A. Weiss.\n\nwalkr\n\nRandom Walks in the Intersection of Hyperplanes and the N-Simplex.\nAuthors: Andy Yao, David Kane.\n\nwarbleR\n\nStreamline Bioacoustic Analysis. Authors: Marcelo Araya-Salas, Grace\nSmith Vidaurre, Hua Zhong.\n\nwater\n\nActual Evapotranspiration with Energy Balance Models. Authors:\nGuillermo Federico Olmedo [aut, cre], Samuel Ortega-Farias\n[aut], David Fonseca-Luengo [aut], Daniel de la Fuente-Saiz\n[aut], Fernando Fuentes Peñailillo [aut].\n\nwbsts\n\nMultiple Change-Point Detection for Nonstationary Time Series.\nAuthors: Karolos Korkas and Piotr Fryzlewicz. In view:\nTimeSeries.\n\nweatherr\n\nTools for Handling and Scrapping Instant Weather Forecast Feeds.\nAuthor: Stan Yip [aut, cre].\n\nwebreadr\n\nTools for Reading Formatted Access Log Files. Author: Oliver Keyes.\n\nwebuse\n\nImport Stata ‘webuse’ Datasets. Author: Thomas J. Leeper [aut,\ncre].\n\nwec\n\nWeighted Effect Coding. Authors: Rense Nieuwenhuis, Manfred te\nGrotenhuis, Ben Pelzer, Alexanter Schmidt, Ruben Konig, Rob Eisinga.\n\nweightTAPSPACK\n\nWeight TAPS Data. Authors: David G. Carlson, Michelle Torres, and\nTaeyong Park.\n\nwellknown\n\nConvert Between ‘WKT’ and ‘GeoJSON’. Author: Scott Chamberlain\n[aut, cre].\n\nwhoami\n\nUsername, Full Name, Email Address, ‘GitHub’ Username of the Current\nUser. Author: Gabor Csardi.\n\nwhoapi\n\nA ‘Whoapi’ API Client. Author: Oliver Keyes.\n\nwingui\n\nAdvanced Windows Functions. Author: Andrew Redd.\n\nwiod\n\nWorld Input Output Database 1995–2011. Author: Bastiaan Quast\n[aut, cre].\n\nwithr\n\nRun Code With Temporarily Modified Global State. Authors: Jim Hester\n[aut, cre], Kirill Müller [aut], Hadley Wickham [aut], Winston\nChang [aut], RStudio [cph].\n\nwoe\n\nComputes Weight of Evidence and Information Values. Author: Sudarson\nMothilal Thoppay.\n\nwordbankr\n\nAccessing the Wordbank Database. Authors: Mika Braginsky [aut,\ncre], Daniel Yurovsky [ctb], Michael Frank [ctb].\n\nwpp2015\n\nWorld Population Prospects 2015. Authors: Population Division,\nDepartment of Economic and Social Affairs, United Nations.\n\nwqs\n\nWeighted Quantile Sum Regression. Authors: Jenna Czarnota, David\nWheeler.\n\nxergm.common\n\nCommon Infrastructure for Extensions of Exponential Random Graph\nModels. Author: Philip Leifeld [aut, cre].\n\nxmeta\n\nA Toolbox for Multivariate Meta-Analysis. Authors: Yong Chen, Chuan\nHong, Haitao Chu. In view:\nMetaAnalysis.\n\nxseq\n\nAssessing Functional Impact on Gene Expression of Mutations in\nCancer. Authors: Jiarui Ding, Sohrab Shah.\n\nyakmoR\n\nA Simple Wrapper for the k-Means Library Yakmo. Author: Aydin\nDemircioglu.\n\nyummlyr\n\nR Bindings for Yummly API. Author: Roman Tsegelskyi.\n\nzetadiv\n\nFunctions to Compute Compositional Turnover Using Zeta Diversity.\nAuthors: Guillaume Latombe, Melodie A. McGeoch, Cang Hui.\n\n2 Other changes\nThe following packages were moved to the Archive: ABCExtremes,\nABCp2, AOfamilies, BHMSMAfMRI, Biograph, Brq, CALINE3,\nCARramps, CLAG, COP, CSS, Claddis, DBFTest, DPw,\nEMJumpDiffusion, ETAS, FluOMatic, GPlab, HWxtest, LGS,\nLVQTools, MADAM, MFDA, MGL, MMIX, McParre,\nMulticlasstesting, OPE, PBC, PERregress, PF, PIGShift,\nPKfit, RHive, RMediation, RcmdrPlugin.StatisticalURV, Rhh,\nSASxport, SE.IGE, SINGLE, SNPMClust, SPMS, Watersheds,\nWaveCD, WideLM, YourCast, ZeligGAM, ascrda, bayesclust,\nbdoc, bear, bigrf, biopara, branchLars, clustergas,\ncmprskQR, cobs99, correlate, datalist, db.r, diskmemoiser,\nemdatr, epi2loc, esotericR, evora, fuzzyMM, gbs,\nglassomix, gooJSON, gstudio, hlr, iFes, indicoio, ivivc,\nlmmfit, loe, magma, mixlow, netweavers, ngramr, nlADG,\npcrcoal, permGPU, permtest, phom, phyloTop, phylosim,\npolytomous, predfinitepop, pt, qlspack, qualityTools,\nrJavax, radiant, rawFasta, reccsim, repra, rgauges,\nringbuffer, ringscale, rlme, rpud, rrules, rspear,\nsignal.hsmm, spca, sqlshare, sse, stab, tdm, tslars,\nvarSelectIP, vectoptim, waterfall, weightedKmeans, wombsoft.\nThe following packages were resurrected from the Archive:\nAdapEnetClass, BAS, Barnard, DESP, MPCI, MetaPath, NHMSAR,\nOneArmPhaseTwoStudy, RAHRS, RBerkeley, REGENT, RPPanalyzer,\nRSpincalc, Rcell, RcmdrPlugin.Export, Rgbp, Rgnuplot, Rlof,\nSigTree, ThreeGroups, anoint, cems, cgwtools, colorscience,\nconicfit, cpm, cusp, delt, dprep, dynpred, edesign,\nedmr, flowr, geofd, googlePublicData, highriskzone, htmltab,\nimputeYn, ipw, jackknifeKME, locfdr, muRL, munsellinterpol,\nnordklimdata1, ocomposition, papeR, parfm, pgnorm, pmc,\nrbiouml, rknn, samplesize, skellam, spectral.methods,\ntoaster, wccsom, wikipediatrend, xgboost, xml2.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2015-2-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2015-2 issue.",
    "author": [
      {
        "name": "Bettina Grün",
        "url": {}
      }
    ],
    "date": "2015-12-01",
    "categories": [],
    "contents": "\n\nOn behalf of the editorial board, I am pleased to publish Volume 7,\nIssue 2 of the R Journal. This issue contains 20 contributed research\narticles and several contributions to the News and Notes section.\nIn the Contributed Research Articles section each of the articles\npresents an R package or new features of an existing R package which was\nextended. The articles cover different specialized statistical modeling\ntools, e.g., for regression with different distributions for the\ndependent variable, such as implemented by packages zoib for zero/one\ninflated beta regression and hermite for the generalized Hermite\ndistribution, or different data structures as provided by packages\nhglm for conditional and simultaneous autoregressive spatial models\nand apc for age-period-cohort analysis. In addition tools for program\nevaluation are provided by package pampe and quantization-based\nquantile regression by package QuantifQuantile. Other aspects of\nstatistical modeling are to perform variable selection or variable\ngrouping and are covered for example by packages VSURF, BSGS and\nClustVarLV or to determine dissimilarities between observations with\nspecial data structures as provided by packages treeClust and mmpp.\nOther areas in applied statistics, e.g., to determine optimal designs,\nsuitable sample sizes or perform uncertainty and sensitivity analysis\nare covered by packages ALTopt, PracTools and mtk. Diagnostic\ntools for approximate Bayesian computation are provided by package\nabctools; tools for dealing with multilabel datasets are contained in\npackage mldr. Visualization methods for pairwise comparisons, which\nare for example used when comparing algorithms in machine learning, are\ngiven in package SRCS.\nIn addition new areas of application of R are seized, e.g., by package\nrivr which provides the tools for undergraduate and graduate courses\nin open-channel hydraulics. Infrastructure in the area of numerical\nmathematics for evaluating the hypergeometric function is given in\npackage hypergeo and tools to help with coding in R are contained in\npackage GUIProfiler for profiling R code.\nOverall this collection of contributed research articles indicates the\nwide range of statistical methods from different areas currently covered\nby extension packages for R and the increasing possible use of R in new\nareas of application.\nIn addition the News and Notes section contains news by the R Consortium\nand the R Foundation providing some background information to the\nsetting up of the Consortium and its interaction with the R Foundation.\nIn addition a conference report on useR! 2015, the annual international\nR user conference, which took place from June 30 until July 3, 2015 in\nAalborg, Denmark and attracted 660 participants from 42 countries is\ngiven. Furthermore this section contains the usual updates on the\nBioconductor project, changes in R itself and CRAN. I hope you enjoy the\nissue.\nWith the end of the year, it is also time for a refresh of the editorial\nboard. Deepayan Sarkar is leaving the board after a four-year term. We\nwelcome John Verzani who is joining the editorial board in his place.\nPublishing this issue is my last act as Editor-in-Chief, with Michael\nLawrence taking over the job for the next year.\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2015-2-r-changes/",
    "title": "Changes in R",
    "description": "The 'Changes in R' article from the 2015-2 issue.",
    "author": [
      {
        "name": "The R Core Team",
        "url": {}
      }
    ],
    "date": "2015-12-01",
    "categories": [],
    "contents": "\n\nCHANGES IN R 3.2.3\n\nNEW FEATURES\nSome recently-added Windows time zone names have been added to the\nconversion table used to convert these to Olson names. (Including\nthose relating to changes for Russia in Oct 2014, as in PR#16503.)\n(Windows) Compatibility information has been added to the manifests\nfor Rgui.exe, Rterm.exe and Rscript.exe. This should allow\nwin.version() and Sys.info() to report the actual Windows\nversion up to Windows 10.\nWindows \"wininet\" FTP first tries EPSV / PASV mode rather than\nonly using active mode (reported by Dan Tenenbaum).\nwhich.min(x) and which.max(x) may be much faster for logical and\ninteger x and now also work for long vectors.\nThe ‘emulation’ part of tools::texi2dvi() has been somewhat\nenhanced, including supporting quiet = TRUE. It can be selected by\ntexi2dvi = \"emulation\".\n(Windows) MiKTeX removed its texi2dvi.exe command in Sept 2015:\ntools::texi2dvi() tries texify.exe if it is not found.\n(Windows only) Shortcuts for printing and saving have been added to\nmenus in Rgui.exe. (Request of PR#16572.)\nloess(..., iterTrace=TRUE) now provides diagnostics for robustness\niterations, and the print() method for summary(<loess>) shows\nslightly more.\nThe included version of PCRE has been updated to 8.38, a bug-fix\nrelease.\nView() now displays nested data frames in a more friendly way.\n(Request with patch in PR#15915.)\n\n\nINSTALLATION and INCLUDED SOFTWARE\nThe included configuration code for libintl has been updated to\nthat from gettext version 0.19.5.1 — this should only affect how\nan external library is detected (and the only known instance is\nunder OpenBSD). (Wish of PR#16464.)\nconfigure has a new argument –disable-java to disable the checks\nfor Java.\nThe configure default for MAIN_LDFLAGS has been changed for the\nFreeBSD, NetBSD and Hurd OSes to one more likely to work with\ncompilers other than gcc (FreeBSD 10 defaults to clang).\nconfigure now supports the OpenMP flags -fopenmp=libomp (clang)\nand -qopenmp (Intel C).\nVarious macros can be set to override the default behaviour of\nconfigure when detecting OpenMP: see file config.site.\nSource installation on Windows has been modified to allow for MiKTeX\ninstallations without texi2dvi.exe. See file MkRules.dist.\n\n\nBUG FIXES\nregexpr(pat, x, perl = TRUE) with Python-style named capture did\nnot work correctly when x contained NA strings. (PR#16484)\nThe description of dataset ToothGrowth has been\nimproved/corrected. (PR#15953)\nmodel.tables(type = \"means\") and hence TukeyHSD() now support\n\"aov\" fits without an intercept term. (PR#16437)\nclose() now reports the status of a pipe() connection opened\nwith an explicit open argument. (PR#16481)\nCoercing a list without names to a data frame is faster if the\nelements are very long. (PR#16467)\n(Unix-only) Under some rare circumstances piping the output from\nRscript or R -f could result in attempting to close the input\nfile twice, possibly crashing the process. (PR#16500)\n(Windows) Sys.info() was out of step with win.version() and did\nnot report Windows 8.\ntopenv(baseenv()) returns baseenv() again as in R 3.1.0 and\nearlier. This also fixes compilerJIT(3) when used in .Rprofile.\ndetach()ing the methods package keeps .isMethodsDispatchOn()\ntrue, as long as the methods namespace is not unloaded.\nRemoved some spurious warnings from configure about the\npreprocessor not finding header files. (PR#15989)\nrchisq(*, df=0, ncp=0) now returns 0 instead of NaN, and\ndchisq(*, df=0, ncp=*) also no longer returns NaN in limit cases\n(where the limit is unique). (PR#16521)\npchisq(*, df=0, ncp > 0, log.p=TRUE) no longer underflows (for ncp\n> ~60).\nnchar(x, \"w\") returned -1 for characters it did not know about\n(e.g. zero-width spaces): it now assumes 1. It now knows about most\nzero-width characters and a few more double-width characters.\nHelp for which.min() is now more precise about behavior with\nlogical arguments. (PR#16532)\nThe print width of character strings marked as \"latin1\" or\n\"bytes\" was in some cases computed incorrectly.\nabbreviate() did not give names to the return value if minlength\nwas zero, unlike when it was positive.\n(Windows only) dir.create() did not always warn when it failed to\ncreate a directory. (PR#16537)\nWhen operating in a non-UTF-8 multibyte locale (e.g. an East Asian\nlocale on Windows), grep() and related functions did not handle\nUTF-8 strings properly. (PR#16264)\nread.dcf() sometimes misread lines longer than 8191 characters.\n(Reported by Hervé Pagès with a patch.)\nwithin(df, ..) no longer drops columns whose name start with a\n\".\".\nThe built-in HTTP server converted entire Content-Type to\nlowercase including parameters which can cause issues for multi-part\nform boundaries (PR#16541).\nModifying slots of S4 objects could fail when the methods package\nwas not attached. (PR#16545)\nsplineDesign(*, outer.ok=TRUE) (splines) is better now\n(PR#16549), and interpSpline() now allows sparse=TRUE for\nspeedup with non-small sizes.\nIf the expression in the traceback was too long, traceback() did\nnot report the source line number. (Patch by Kirill Müller.)\nThe browser did not truncate the display of the function when\nexiting with options(\"deparse.max.lines\") set. (PR#16581)\nWhen bs(*, Boundary.knots=) had boundary knots inside the data\nrange, extrapolation was somewhat off. (Patch by Trevor Hastie.)\nvar() and hence sd() warn about factor arguments which are\ndeprecated now. (PR#16564)\nloess(*, weights = *) stored wrong weights and hence gave slightly\nwrong predictions for newdata. (PR#16587)\naperm(a, *) now preserves names(dim(a)).\npoly(x, ..) now works when either raw=TRUE or coef is\nspecified. (PR#16597)\ndata(package=*) is more careful in determining the path.\nprettyNum(*, decimal.mark, big.mark): fixed bug introduced when\nfixing PR#16411.\n\nCHANGES IN R 3.2.2\n\nSIGNIFICANT USER-VISIBLE CHANGES\nIt is now easier to use secure downloads from https:// URLs on\nbuilds which support them: no longer do non-default options need to\nbe selected to do so. In particular, packages can be installed from\nrepositories which offer https:// URLs, and those listed by\nsetRepositories() now do so (for some of their mirrors).\nSupport for https:// URLs is available on Windows, and on other\nplatforms if support for libcurl was compiled in and if that\nsupports the https protocol (system installations can be expected\nto do). So https:// support can be expected except on rather old\nOSes (an example being OS X ‘Snow Leopard’, where a non-system\nversion of libcurl can be used).\n(Windows only) The default method for accessing URLs via\ndownload.file() and url() has been changed to be \"wininet\"\nusing Windows API calls. This changes the way proxies need to be set\nand security settings made: there have been some reports of ftp:\nsites being inaccessible under the new default method (but the\nprevious methods remain available).\n\n\nNEW FEATURES\ncmdscale() gets new option list. for increased flexibility when\na list should be returned.\nconfigure now supports texinfo version 6.0, which (unlike the\nchange from 4.x to 5.0) is a minor update. (Wish of PR#16456.)\n(Non-Windows only) download.file() with default method = \"auto\"\nnow chooses \"libcurl\" if that is available and a https:// or\nftps:// URL is used.\n(Windows only) setInternet2(TRUE) is now the default. The\ncommand-line option –internet2 and environment variable\nR_WIN_INTERNET2 are now ignored.\nThus by default the \"internal\" method for download.file() and\nurl() uses the \"wininet\" method: to revert to the previous\ndefault use setInternet2(FALSE).\nThis means that https:// URLs can be read by default by\ndownload.file() (they have been readable by file() and url()\nsince R 3.2.0).\nThere are implications for how proxies need to be set (see\n?download.file).\nchooseCRANmirror() and chooseBioCmirror() now offer HTTPS\nmirrors in preference to HTTP mirrors. This changes the\ninterpretation of their ind arguments: see their help pages.\ncapture.output() gets optional arguments type and split to\npass to sink(), and hence can be used to capture messages.\n\n\nC-LEVEL FACILITIES\nHeader Rconfig.h now defines HAVE_ALLOCA_H if the platform has\nthe alloca.h header (it is needed to define alloca on Solaris\nand AIX, at least: see ‘Writing R Extensions’ for how to use it).\n\n\nINSTALLATION and INCLUDED SOFTWARE\nThe libtool script generated by configure has been modified to\nsupport FreeBSD >= 10 (PR#16410).\n\n\nBUG FIXES\nThe HTML help page links to demo code failed due to a change in R\n3.2.0. (PR#16432)\nIf the na.action argument was used in model.frame(), the\noriginal data could be modified. (PR#16436)\ngetGraphicsEvent() could cause a crash if a graphics window was\nclosed while it was in use. (PR#16438)\nmatrix(x, nr, nc, byrow = TRUE) failed if x was an object of\ntype \"expression\".\nstrptime() could overflow the allocated storage on the C stack\nwhen the timezone had a non-standard format much longer than the\nstandard formats. (Part of PR#16328.)\noptions(OutDec = s) now signals a warning (which will become an\nerror in the future) when s is not a string with exactly one\ncharacter, as that has been a documented requirement.\nprettyNum() gains a new option input.d.mark which together with\nother changes, e.g., the default for decimal.mark, fixes some\nformat()ting variants with non-default getOption(\"OutDec\") such\nas in PR#16411.\ndownload.packages() failed for type equal to either \"both\" or\n\"binary\". (Reported by Dan Tenenbaum.)\nThe dendrogram method of labels() is much more efficient for\nlarge dendrograms, now using rapply(). (Comment #15 of PR#15215)\nThe \"port\" algorithm of nls() could give spurious errors.\n(Reported by Radford Neal.)\nReference classes that inherited from reference classes in another\npackage could invalidate methods of the inherited class. Fixing this\nrequires adding the ability for methods to be “external”, with the\nobject supplied explicitly as the first argument, named .self. See\n\"Inter-Package Superclasses\" in the documentation.\nreadBin() could fail on the SPARC architecture due to alignment\nissues. (Reported by Radford Neal.)\nqt(*, df=Inf, ncp=.) now uses the natural qnorm() limit instead\nof returning NaN. (PR#16475)\nAuto-printing of S3 and S4 values now searches for print() in the\nbase namespace and show() in the methods namespace instead of\nsearching the global environment.\npolym() gains a coefs = NULL argument and returns class \"poly\"\njust like poly() which gets a new simple=FALSE option. They now\nlead to correct predict()ions, e.g., on subsets of the original\ndata.\nrhyper(nn, <large>) now works correctly. (PR#16489)\nttkimage() did not (and could not) work so was removed. Ditto for\ntkimage.cget() and tkimage.configure(). Added two Ttk widgets\nand missing subcommands for Tk’s image command: ttkscale(),\nttkspinbox(), tkimage.delete(), tkimage.height(),\ntkimage.inuse(), tkimage.type(), tkimage.types(),\ntkimage.width(). (PR#15372, PR#16450)\ngetClass(\"foo\") now also returns a class definition when it is\nfound in the cache more than once.\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2015-2-tvedebrink/",
    "title": "Conference Report: useR! 2015",
    "description": "The 'Conference Report: useR! 2015' article from the 2015-2 issue.",
    "author": [
      {
        "name": "Torben Tvedebrink",
        "url": {}
      }
    ],
    "date": "2015-12-01",
    "categories": [],
    "contents": "\n\nThe 11th international R user conference, useR! 2015, took place in\nAalborg, Denmark, 1–3 July 2015. The Department of Mathematical\nSciences, Aalborg University, hosted the conference, which took place in\nAalborg Congress and Culture Centre.\nWe had originally hoped for 300–400 participants and some support from\nsponsors. The meeting attracted a total of 660 participants from 42\ncountries with an almost uniform split on academia and industry.\nFurthermore, the industry’s generous support made it possible to provide\nfree meals, drinks and a well-suited venue for the conference.\n\nOur social events included welcome reception at the waterfront in the\nHouse of Music, a poster session with free bar and food, and a trip to\nDenmark’s second largest forest (Rold Forest) where we held the\nconference dinner. During the conference dinner competitive games took\nplace such as long sawing, axe hurling and archery.\nWe received more than 250 abstracts of which some 220 were accepted\neither as posters, lightning talks or oral presentations. The final\nprogramme consisted of six invited talks, 126 oral presentations, 14\nlightning talks and 77 posters were presented at the conference.\nPre-conference tutorials\nInspired by the initiative of useR! 2014 in Los Angeles we decided to\nprovide the tutorials free of charge to useR! participants. This reduced\nthe book-keeping load and allowed people to attend tutorials without\nconsidering the additional cost per tutorial. Based on the submitted\ntutorial proposal, the programme committee elected tutorials below:\nApplied Spatial Data Analysis with R (Virgilio Gómez Rubio)\nBayesian Networks and Graphical Models with R (Søren Højsgaard and\nTherese Graversen)\nData Manipulation with\ndplyr (Hadley\nWickham)\nEfficient Statistical Consulting using R Workflow for Data Analysis\nProjects (Peter Baker)\nHandling Missing Values with a Special Focus on the Use of Principal\nComponents Methods (François Husson)\nRHadoop (Andrie de Vries and Simon Field)\nRocker: Using R on Docker (Dirk Eddelbuettel)\nStatistical Analysis of Network Data (Gabor Csardi)\nAnalysis and Visualization of Large Complex Data with Tessera (Ryan\nHafen and Stephen Elston)\nApplied Machine Learning and Efficient Model Selection with\nmlr (Bernd Bischl and\nMichel Lang)\nBioconductor for High-Throughput Sequence Analysis (Martin Morgan)\nGetting to Know grid Graphics (Paul Murrell)\nIntroduction to Bayesian Data Analysis with R (Rasmus Bååth)\nspatstat: An R\nPackage for Analysing Spatial Point Patterns (Adrian Baddeley and\nEge Rubak)\nTesting R Code (Richard J. Cotton)\nUsing Pandoc’s Markdown with R (Gergely Daróczi)\nMore than 80% of the conference participants registered at Tutorial\nTuesday and most of these participated in one or two tutorials making\nthe “open source” offer of free participation a success.\nInvited talks\nWith the aim of getting the “use” of useR! in focus we invited speakers\nwith varying backgrounds to give the six plenary talks of useR! 2015.\nMost of the presented topics were also discussed in the submitted\nsessions.\nThomas Lumley: How Flexible Computing Expands What an Individual\nCan Do\nAdrian Baddeley: How R Has Changed Spatial Statistics\nSteffen Lauritzen: Linear Estimating Equations for Gaussian\nGraphical Models with Symmetry\nDi Cook: A Survey of Two Decades of Efforts to Build Interactive\nGraphics Capacity in R\nRomain François: My R Adventures\nSusan Holmes: Multitype Data Integration: Challenges from the\nHuman Microbiome\nContributed sessions\nAfter the selection of submitted abstracts we attempted to group the\ncontributed talks in sessions of similar talks. The overall headings of\nthe five parallel sessions were:\nEcology\nNetworks\nReproducibility\nInterfacing\nCase study\nClustering\nData management\nComputational\nperformance\nBusiness\nSpatial\nDatabases\nMedicine\nRegression\nCommercial offerings\nInteractive graphics\nTeaching\nStatistical methodology\nMachine learning\nVisualisation\nThese themes were also represented in the poster session and in the six\nkaleidoscope sessions. In addition to posters and presentations, there\nwere 14 Lightning Talks, a 5-minute presentation on any R-related topic\naimed particularly at those new to R. Participants seemed to appreciate\nthis fast-paced introduction to a wide range of topics.\nOrganisers\nThe selection of abstracts for presentations would not have been\npossible without the thorough review process of the programme committee.\nWe are grateful to the programme committee of useR! 2015: Peter\nDalgaard, Dirk Eddelbuettel, Poul Svante Eriksen, Julie Josse, Martin\nMaechler, Katharine Mullen, Helle Sørensen, Heather Turner, Hadley\nWickham, Achim Zeileis, and Søren Højsgaard (chair).\nThe local “green shirt” heroes making the useR! 2015 in Aalborg possible\nconsisted of several students and local statisticians: Mikkel Meyer\nAndersen, Anders Ellern Bilgrau, Claus Dethlefsen, Mateusz ‘Matt’\nDziubinski, Poul Svante Eriksen, Søren Højsgaard, Rikke Nørmark\nMortensen, Maria Rodrigo-Domingo, Ege Rubak, and Torben Tvedebrink\n(chair).\nFurther information\nThe useR! 2015 website,\nwww.R-project.org/useR-2015\nprovides a record of the conference. Where authors have made them\navailable, slides are accessible via the online conference schedule\n(Oral Sessions).\nA blog post summarising the planning and execution of useR! 2015 can be\nfound at the Revolution Analytics’\nblog.\n\n\nCRAN packages used\ndplyr, mlr, spatstat\nCRAN Task Views implied by cited packages\nDatabases, ModelDeployment, Spatial, SpatioTemporal, Survival\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2015-2-plummer/",
    "title": "The R Consortium and the R Foundation",
    "description": "The R Consortium was announced at the useR! 2015 conference in Aalborg, Denmark on 30 June. It is a non-profit organization set up to provide infrastructure for the R community. The purpose of this article is to explain some of the background to the setting up of the Consortium and how it interacts with the R Foundation.",
    "author": [
      {
        "name": "Martyn Plummer",
        "url": {}
      }
    ],
    "date": "2015-11-30",
    "categories": [],
    "contents": "\n\nOne of the most striking developments in the recent history of R is the\nextent to which it is now used in a commercial environment. This success\nhas generated new demands for the R project. In particular, there has\nbeen an ongoing conversation about how commercial organizations can make\nfinancial contributions to the R project and support infrastructure for\nthe R community. This is of particular concern to companies based in the\nUnited States, who may find it difficult to make donations to the R\nFoundation for Statistical Computing, as we are a non-profit\norganization based in Europe. It was also clear that the interested\ncompanies wanted to play an active role in supporting infrastructure for\nR. Representatives from companies based in the United States discussed\nthese issues with the R Foundation at the DSC\n2014 meeting in July 2014,\nwhere it was decided that the best way forward would be to create a\ntrade association under the name “The R Consortium”. Members of a trade\nassociation (formally, a non-profit organization under US Internal\nRevenue code 501(c)(6)) are businesses that agree to work together to\nadvance a common interest.\nOnce the idea of a trade association was approved by the R Foundation,\nrepresentatives of the founding members, including John Chambers\nrepresenting the R Foundation, worked with the Linux Foundation to\nfollow the legal steps to create the Consortium. The Linux Foundation\nhas wide experience in setting up what they call “collaborative\nprojects”. The R Consortium is one of many such projects now listed at\nhttp://collabprojects.linuxfoundation.org/. Other examples include the\nCore Infrastructure Initiative and the Open Virtualization Alliance.\nAll current members of the R Consortium, apart from the R Foundation,\nare commercial organizations, and their status within the R Consortium\n(platinum, gold, or silver) depends on their level of financial\ncontributions. The R Foundation has a special status in the bylaws of\nthe R Consortium, and has permanent membership without making any\nfinancial contributions. This membership includes a seat on the R\nConsortium Board of Directors, where our representative is currently\nJohn Chambers. In addition, the R Foundation has a representative on the\nInfrastructure Steering\nCommittee (ISC), the body that\ndecides what projects should receive funding from the R Consortium. Our\ncurrent representative on the ISC is Luke Tierney.\nIn November 2015, the R Consortium announced its first funding award to\nGábor Csárdi to develop R-hub. At\nthe time of writing the ISC also has a call for\nproposals set to end\non 10 January 2016. Grants awarded by the R Consortium could have values\nup to $20–30k. Proposals are open to everyone, not just members of the\nR Consortium.\nThe stated goals of the R Consortium emphasize that it will not\ninfluence the development of R itself (noted in the R Consortium\nFAQ); this remains entirely\nunder the control of the R Core Team and the R Foundation remains the\nsole representative of the R project at the organization level.\nIt should also be noted that the R Consortium was set up to answer the\nparticular needs of companies in the United States. The R Foundation is\nalso open to collaboration with other non-profit organizations working\nto support the development of R world-wide.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2015-1-bioconductor/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2015-1 issue.",
    "author": [
      {
        "name": "The Bioconductor Team",
        "url": {}
      }
    ],
    "date": "2015-06-01",
    "categories": [],
    "contents": "\n\nThe Bioconductor project provides tools for\nthe analysis and comprehension of high-throughput genomic data. The 1024\nsoftware packages available in Bioconductor can be viewed at\nhttp://bioconductor.org/packages/. Navigate packages using ‘biocViews’\nterms and title search. Each package has an html page with a\ndescription, links to vignettes, reference manuals, and usage\nstatistics. Start using Bioconductor version 3.1 by installing R 3.2.1\nand evaluating the commands\n  source(\"http://bioconductor.org/biocLite.R\")\n  biocLite()\nInstall additional packages and dependencies, e.g.,\nAnnotationHub,\nwith\n  source(\"http://bioconductor.org/biocLite.R\")\n  biocLite(\"AnnotationHub\")\n1 Bioconductor 3.1 release highlights\nBioconductor 3.1 was released on 17 April 2015. It is compatible with R\n3.2 and consists of 1024 software packages, 214 experiment data\npackages, and more 917 up-to-date annotation packages. There are 95 new\nsoftware packages and many updates and improvements to existing\npackages. The release\nannouncement includes\ndescriptions of new packages and updated NEWS files provided by package\nmaintainers. There are a great diversity of packages represented.\nHighlights include:\nsincell\nfor assessment of cell-state hierarchies from single-cell data; gene set\nand network analysis packages (e.g.,\nRCyjs\nmogsa,\nnethet,\npandaR,\npwOmics,\nseq2pathway);\npackages for methylation (e.g.,\nBEclear,\nconumee,\nDMRcaller,\nENmix,\nRnBeads,\nskewr),\nflow cytometry (e.g.,\nFlowRepositoryR,\nFlowSOM,\nflowVS,\nimmunoClus),\nand other domain-specific analysis (e.g.,\nLEA,\nfor landscape genomics); access to multiple-sequence alignment\nalgorithms\n(muscle,\nmsa);\nvisualization packages such as\ngtrellis\n(genome level Trellis graph visualizes),\nggtree\n(phylogenetic tree and associated annotation data),\nComplexHeatmap,\nseqPattern\n(oligonucleotide patterns and sequence motifs centred at a common\nreference point), and\nsoGGI\n(genomic interval aggregate and summary plots of signal or motif\noccurrence); and infrastructure packages such as\nRhtslib\n(wrapping a recent version of the htslib C library for processing CRAM,\nBAM, and other high-throughput sequence files) and\nGoogleGenomics\n(to interact with the Google Genomics interface).\nOur collection of microarray, transcriptome and organism-specific\nannotation packages use the ‘select’ interface (keys, columns,\nkeytypes) to access static information on gene annotations (org.*\npackages) and gene models (TxDb.* packages); these augment packages\nsuch as\nbiomaRt\nfor interactive querying of web-based resources and\nVariantAnnotation,\nVariantFiltering,\nand\nensemblVEP\nfor annotation of DNA sequences. Use of these resources are documented\nin updated annotation\nworkflows. The\nAnnotationHub complements our traditional offerings with diverse whole\ngenome annotations from Ensembl, ENCODE, dbSNP, UCSC, and elsewhere; a\nrecent addition includes Roadmap Epigenomics resources, with use\ndescribed in the AnnotationHub\nHow-To\nvignette.\n2 Other activities\nSeveral enhancements to the Bioconductor web and support sites aim to\nhelp users to identify appropriate packages while encouraging developers\nto provide high-quality software. In addition to\nbiocViews\nterms to classify packages, each ‘landing’ page (e.g.,\nhttp://bioconductor.org/packages/DESeq2) contains graphical shields\nthat highlight cross-platform availability, download percentile, support\nsite queries and responses, years in Bioconductor, and maintenance\nactivity during the last 6 months. Landing pages also contain shields\nmore useful to package maintainers, including current build status and\ntest coverage. Users posting questions on the support\nsite are encouraged to add tags\nidentifying the package the question is about; maintainers are\nsubscribed to the tag and receive email notification of the question.\nThis enables maintainers to stay informed of problems with their\npackage, without requiring daily monitoring of the support site.\nContinued availability of Bioconductor\nDocker and\nAmazon\nimages provides a very effective on-ramp for power users to rapidly\nobtain access to standardized and scalable computing environments.\nDocker images are available for release and development versions of\nBioconductor, with analysis-specific images pre-loaded with packages\nrelevant to common analysis scenarios, e.g., of sequencing, microarray,\nflow cell, or proteomic data. Both Amazon and Docker images include\nRStudio Server for easy web-browser based access.\nNew Bioconductor package contributors are encouraged to consult the\npackage\nguidelines and\nsubmission\nsections of the Bioconductor web site, and use the\nBiocCheck\npackage, in addition to R CMD check, for guidance on conforming to\nBioconductor package standards. New package submissions are\nautomatically built across Linux, Mac, and Windows platforms, providing\nan opportunity to address cross-platform issues; many new package\ncontributors take advantage of this facility to refine their package\nbefore it is subject to technical preview. Keep abreast of packages\nadded to the ‘devel’ branch and other activities by following\n@Bioconductor on Twitter.\nThe Bioconductor web site advertises training and community\nevents, including the BioC\n2015, the Bioconductor annual\nconference, to be held in Seattle, 20–22 July.\n\n\nBioconductor packages used\nAnnotationHub, sincell, RCyjs, mogsa, nethet, pandaR, pwOmics, seq2pathway, BEclear, conumee, DMRcaller, ENmix, RnBeads, skewr, FlowRepositoryR, FlowSOM, flowVS, immunoClus, LEA, muscle, msa, gtrellis, ggtree, ComplexHeatmap, seqPattern, soGGI, Rhtslib, GoogleGenomics, biomaRt, VariantAnnotation, VariantFiltering, ensemblVEP, BiocCheck\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2015-1-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2015-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2015-06-01",
    "categories": [],
    "contents": "\n\nNew packages in CRAN task views\nBayesian\n\nBayesSummaryStatLM, SamplerCompare, coalescentMCMC,\nmatchingMarkets.\n\nChemPhys\n\nCRAC, CosmoPhotoz, RobPer, UPMASK, astrodatR, astrolibR,\nsnapshot, speaq.\n\nCluster\n\nflexCWM, protoclust.\n\nDifferentialEquations\n\nodeintr.\n\nDistributions\n\nDiscreteInverseWeibull, DistributionUtils, GB2, GMD,\nNewdistns, PDQutils, ParetoPosStable, RMKdiscrete, SMR,\nald, cmvnorm, condMVNorm, hermite, ihs, mvrtn,\nsadists, sgt, sld, tolerance, tsallisqexp.\n\nEconometrics\n\nBMA, BMS, PANICr, Paneldata, Rchoice, brglm, frm,\nglmx, gmnl, ivbma, ivfixed, ivlewbel, ivpack, ivpanel,\nivprobit, lavaan, matchingMarkets, multiwayvcov, pampe,\npanelAR, pdR, pglm, psidR, semsfa, wahc, xts.\n\nFinance\n\nTAQMNGR, gets, matchingMarkets, restimizeapi.\n\nGraphics\n\nhexbin.\n\nHighPerformanceComputing\n\nRborist, gmatrix.\n\nMedicalImaging\n\nKATforDCEMRI\\(^*\\), MRIaggr, brainR, fslr, neuRosim\\(^*\\),\nneuroim\\(^*\\).\n\nMetaAnalysis\n\nCopulaREMADA, EasyStrata, MultiMeta, forestplot,\nmetaRNASeq.\n\nNumericalMathematics\n\nBrobdingnag, Deriv.\n\nOfficialStatistics\n\nsaeSim, simPop, stringdist, synthpop.\n\nOptimization\n\nCEoptim, cccp, cec2005benchmark, cec2013, localsolver,\nmatchingMarkets.\n\nPhylogenetics\n\nBioGeoBEARS, DAMOCLES, bayou, cati, convevol, ggplot2,\nips, rncl.\n\nPsychometrics\n\nSNSequate, flexmix, kcirt, kequate, medflex, missMDA,\nnlsem.\n\nSpatial\n\nvec2dtransf, wkb.\n\nTimeSeries\n\nBNPTSclust, HarmonicRegression, RGENERATE, acp,\nbayesDccGarch, cents, dygraphs, forecTheta, gtop, hts,\nhwwntest, multitaper, sae2, strucchange, trend, tscount.\n\nWebTechnologies\n\nblsAPI, chromer, gistr, urltools.\n\n(* = core package)\n1 New contributed packages\nABCanalysis\n\nComputed ABC Analysis. Authors: Michael Thrun, Jorn Lotsch, Alfred\nUltsch.\n\nADPclust\n\nFast Clustering Using Adaptive Density Peak Detection. Authors:\nYifan “Ethan” Xu, Xiao-Feng Wang.\n\nALTopt\n\nOptimal Experimental Designs for Accelerated Life Testing. Authors:\nKangwon Seo [aut, cre], Rong Pan [aut].\n\nATE\n\nInference for Average Treatment Effects using Covariate Balancing.\nAuthors: Asad Haris and Gary Chan.\n\nAke\n\nAssociated Kernel Estimations. Authors: W. E. Wansouwé, S. M. Somé\nand C. C. Kokonendji.\n\nAnglerCreelSurveySimulation\n\nSimulate a Bus Route Creel Survey of Anglers. Author: Steven Ranney.\n\nApacheLogProcessor\n\nProcess the Apache Web Server Log Combined Files. Author: Diogo\nSilveira Mendonca.\n\nArArRedux\n\nRigorous Data Reduction and Error Propagation of ‘40Ar/39Ar’ Data.\nAuthor: Pieter Vermeesch [aut, cre].\n\nArfimaMLM\n\nArfima-MLM Estimation For Repeated Cross-Sectional Data. Authors:\nPatrick Kraft [aut, cre], Christopher Weber [ctb].\n\nAsynchLong\n\nRegression Analysis of Sparse Asynchronous Longitudinal Data.\nAuthors: Hongyuan Cao, Donglin Zeng, Jason P. Fine, and Shannon T.\nHolloway.\n\nBACA\n\nBubble Chart to Compare Biological Annotations by using DAVID.\nAuthors: Vittorio Fortino and Dario Greco.\n\nBCRA\n\nBreast Cancer Risk Assessment. Author: Fanni Zhang.\n\nBNPTSclust\n\nA Bayesian Nonparametric Algorithm for Time Series Clustering.\nAuthors: Martell-Juarez, D.A. & Nieto-Barajas, L.E. In view:\nTimeSeries.\n\nBSGS\n\nBayesian Sparse Group Selection. Authors: Kuo-Jung Lee and Ray-Bin\nChen.\n\nBayesSummaryStatLM\n\nMCMC Sampling of Bayesian Linear Models via Summary Statistics.\nAuthors: Evgeny Savel’ev, Alexey Miroshnikov, Erin Conlon. In view:\nBayesian.\n\nBinOrdNonNor\n\nConcurrent Generation of Binary, Ordinal and Continuous Data.\nAuthors: Yue Wang, Hakan Demirtas.\n\nBinarize\n\nBinarization of One-Dimensional Data. Authors: Stefan Mundus,\nChristoph Müssel, Ludwig Lausser, Tamara J. Blätte, Martin\nHopfensitz, Hans A. Kestler.\n\nBinaryEPPM\n\nMean and Variance Modeling of Binary Data. Authors: David M Smith,\nMalcolm J Faddy.\n\nBivarP\n\nEstimating the Parameters of Some Bivariate Distributions. Author:\nJosef Brejcha.\n\nCAM\n\nCausal Additive Model. Authors: Jonas Peters and Jan Ernest.\n\nCARBayesdata\n\nData Sets Used in the Vignette Accompanying the CARBayes Package.\nAuthor: Duncan Lee.\n\nCARLIT\n\nEcological Quality Ratios Calculation and Plot. Authors: Danilo\nPecorino, Gina de la Fuente Mancebo, Xavier Torras.\n\nCEGO\n\nCombinatorial Efficient Global Optimization. Author: Martin\nZaefferer.\n\nCEoptim\n\nCross-Entropy R Package for Optimization. Authors: Tim Benham and\nQibin Duan and Dirk P. Kroese and Benoit Liquet. In view:\nOptimization.\n\nCFC\n\nCause-Specific Framework for Competing-Risk Analysis. Authors:\nMansour T.A. Sharabiani, Alireza S. Mahani.\n\nCMplot\n\nCircle Manhattan Plot. Author: LiLin-Yin.\n\nCOMMUNAL\n\nRobust Selection of Cluster Number K. Authors: Albert Chen [aut,\ncre], Timothy E Sweeney [aut], Olivier Gevaert [ths].\n\nCausalFX\n\nMethods for Estimating Causal Effects from Observational Data.\nAuthors: Ricardo Silva [cre, aut], Robin Evans [aut].\n\nCladdis\n\nMeasuring Morphological Diversity and Evolutionary Tempo. Author:\nGraeme T. Lloyd.\n\nClueR\n\nCLUster Evaluation. Author: Pengyi Yang & Raja Jothi.\n\nClustMMDD\n\nVariable Selection in Clustering by Mixture Models for Discrete\nData. Author: Wilson Toussile.\n\nColorPalette\n\nColor Palettes Generator. Author: Carl Ambroselli [aut, cre].\n\nConSpline\n\nPartial Linear Least-Squares Regression using Constrained Splines.\nAuthor: Mary C Meyer.\n\nConake\n\nContinuous Associated Kernel Estimation. Authors: W. E.\nWansouwé, F. G. Libengué and C. C. Kokonendji.\n\nCopula.Markov\n\nEstimation and Statistical Process Control Under Copula-Based Time\nSeries Models. Authors: Takeshi Emura and Ting-Hsuan Long.\n\nCopulaREMADA\n\nCopula Mixed Effect Models for Bivariate Meta-Analysis of Diagnostic\nTest Accuracy Studies. Author: Aristidis K. Nikoloulopoulos. In\nview:\nMetaAnalysis.\n\nCorrMixed\n\nEstimate Correlations Between Repeatedly Measured Endpoints (E.g.,\nReliability) Based on Linear Mixed-Effects Models. Authors: Wim Van\nder Elst, Geert Molenberghs, Dieter Hilgers, & Nicole Heussen.\n\nCoxnet\n\nRegularized Cox Model. Authors: Xiang Li, Donglin Zeng and Yuanjia\nWang.\n\nDAISIE\n\nDynamical Assembly of Islands by Speciation, Immigration and\nExtinction. Authors: Rampal S. Etienne, Luis M. Valente & Albert B.\nPhillimore.\n\nDEEPR\n\nDirichlet-multinomial Evolutionary Event Profile Randomization test.\nAuthor: Mark T Merilo.\n\nDIFtree\n\nItem Focused Trees for the Identification of Items in Differential\nItem Functioning. Author: Moritz Berger.\n\nDNMF\n\nDiscriminant Non-Negative Matrix Factorization. Authors: Zhilong Jia\n[aut, cre], Xiang Zhang [aut].\n\nDSviaDRM\n\nExploring Disease Similarity in Terms of Dysfunctional Regulatory\nMechanisms. Author: Jing Yang.\n\nDVHmetrics\n\nAnalyze Dose-Volume Histograms and Check Constraints. Authors:\nDaniel Wollschlaeger [aut, cre], Heiko Karle [aut], Heinz\nSchmidberger [ctb].\n\nDark\n\nThe Analysis of Dark Adaptation Data. Author: Jeremiah MF Kelly.\n\nDiagrammeR\n\nCreate Diagrams and Flowcharts Using R. Authors: Knut Sveidqvist\n[aut, cph] (mermaid.js), Mike Bostock [aut, cph] (d3.js), Chris\nPettitt [aut, cph] (d3.js), Mike Daines [aut, cph] (viz.js),\nRichard Iannone [aut, cre] (R interface).\n\nDiffCorr\n\nAnalyzing and Visualizing Differential Correlation Networks in\nBiological Data. Authors: Atsushi Fukushima, Kozo Nishida.\n\nEFDR\n\nWavelet-Based Enhanced FDR for Signal Detection in Noisy Images.\nAuthors: Andrew Zammit-Mangion [aut, cre], Hsin-Cheng Huang\n[aut].\n\nELYP\n\nEmpirical Likelihood Analysis for the Cox Model and\nYang-Prentice (2005) Model. Author: Mai Zhou.\n\nESEA\n\nDiscovering the Dysregulated Pathways based on Edge Set Enrichment\nAnalysis. Authors: Junwei Han, Xinrui Shi, Chunquan Li.\n\nEW\n\nEdgeworth Expansion. Author: H.R.Law.\n\nEcoGenetics\n\nAnalysis of Phenotypic, Genotypic and Environmental Data. Authors:\nLeandro Roser, Juan Vilardi, Beatriz Saidman and Laura Ferreyra.\n\nEcoSimR\n\nNull Model Analysis for Ecological Data. Authors: Nick Gotelli\n[aut], Edmund Hart [aut, cre], Aaron Ellison [aut].\n\nEffectLiteR\n\nAverage and Conditional Effects. Authors: Axel Mayer [aut, cre],\nLisa Dietzfelbinger [ctb].\n\nEntropyExplorer\n\nTools for Exploring Differential Shannon Entropy, Differential\nCoefficient of Variation and Differential Expression. Authors: Kai\nWang, Charles A. Phillips, Arnold M. Saxton and Michael A. Langston.\n\nFACTscorer\n\nScores the FACT and FACIT Family of Patient-Reported Outcome\nMeasures. Authors: Ray Baser [aut, cre], Ayelet Greenberg [ctb].\n\nFCMapper\n\nFuzzy Cognitive Mapping. Authors: Shaun Turney and Michael\nBachhofer.\n\nFSInteract\n\nFast Searches for Interactions. Authors: Hyun Jik Kim, Rajen D.\nShah.\n\nFactoshiny\n\nPerform Factorial Analysis from FactoMineR with a shiny\nApplication. Authors: Pauline Vaissie, Astrid Monge, Francois\nHusson.\n\nFastKNN\n\nFast k-Nearest Neighbors. Author: Gaston Besanson.\n\nFedData\n\nFunctions to Automate Downloading Geospatial Data Available from\nSeveral Federated Data Sources. Authors: R. Kyle Bocinsky and Dylan\nBeaudette.\n\nFinCovRegularization\n\nCovariance Matrix Estimation and Regularization for Finance. Author:\nYachen Yan [aut, cre].\n\nGAR\n\nAuthorize and Request Google Analytics Data. Author: Andrew Geisler.\n\nGAabbreviate\n\nAbbreviating Questionnaires (or Other Measures) Using Genetic\nAlgorithms. Authors: Luca Scrucca [aut], Baljinder K. Sahdra\n[aut, cre].\n\nGDAdata\n\nDatasets for the Book “Graphical Data Analysis with R”. Author:\nAntony Unwin.\n\nGOplot\n\nVisualization Of Functional Analysis Data. Authors: Wencke Walter,\nFatima Sanchez-Cabo.\n\nGPlab\n\nGaussian Process Laboratory. Authors: Yves Deville, David\nGinsbourger, Olivier Roustant. Contributor: Nicolas Durrande.\n\nGWLelast\n\nGeographically Weighted Logistic Elastic Net Regression. Authors:\nDaisuke Yoneoka, Eiko Saito.\n\nGaDiFPT\n\nFirst Passage Time Simulation for Gaussian Diffusion Processes.\nAuthors: A. Buonocore, M.F. Carfora.\n\nGameTheory\n\nCooperative Game Theory. Author: Sebastian Cano-Berlanga.\n\nGenForImp\n\nThe Forward Imputation: A Sequential Distance-Based Approach for\nImputing Missing Data. Authors: Nadia Solaro, Alessandro Barbiero,\nGiancarlo Manzi, Pier Alda Ferrari.\n\nGlobalFit\n\nBi-Level Optimization of Metabolic Network Models. Author: Daniel\nHartleb.\n\nGmisc\n\nDescriptive Statistics, Transition Plots, and More. Author: Max\nGordon.\n\nHarmonicRegression\n\nHarmonic Regression to One or more Time Series. Author: Paal O.\nWestermark. In view:\nTimeSeries.\n\nHelpersMG\n\nTools for Earth Meteorological Analysis. Author: Marc Girondot.\n\nHighDimOut\n\nOutlier Detection Algorithms for High-Dimensional Data. Author:\nCheng Fan.\n\nHistDAWass\n\nHistogram-Valued Data Analysis. Author: Antonio Irpino [aut, cre].\n\nHolidays\n\nHoliday and Half-Day Data, for Use with the TimeWarp Package.\nAuthors: Jeffery Horner, Lars Hansen, Tony Plate.\n\nHomoPolymer\n\nTheoretical Model to Simulate Radical Polymerization. Author:\nGianmarco Polotti.\n\nIATscores\n\nImplicit Association Test Scores Using Robust Statistics. Author:\nGiulio Costantini.\n\nIBDLabels\n\nConvert Between Different IBD-State Labelling Schemes. Author: Fiona\nGrimson.\n\nICAFF\n\nImperialist Competitive Algorithm. Authors: Farimah Houshmand and\nFarzad Eskandari.\n\nInteratrix\n\nCompute Chi-Square Measures with Corrections. Authors: Aurélie\nSiberchicot, Eléonore Hellard, Dominique Pontier, David Fouchet and\nFranck Sauvage.\n\nKMDA\n\nKernel-Based Metabolite Differential Analysis. Authors: Xiang Zhan\nand Debashis Ghosh.\n\nKOGMWU\n\nFunctional Summary and Meta-Analysis of Gene Expression Data.\nAuthor: Mikhail V. Matz.\n\nKernelheaping\n\nKernel Density Estimation for Heaped Data. Author: Marcus Gross.\n\nL1pack\n\nRoutines for L1 Estimation. Author: Felipe Osorio.\n\nLDAvis\n\nInteractive Visualization of Topic Models. Authors: Carson Sievert\n[aut, cre], Kenny Shirley [aut].\n\nLDPD\n\nProbability of Default Calibration. Author: Denis Surzhko.\n\nLLSR\n\nData Analysis of Liquid-Liquid Systems. Author: Diego F Coelho.\n\nLPTime\n\nLP Nonparametric Approach to Non-Gaussian Non-Linear Time Series\nModelling. Authors: Subhadeep Mukhopadhyay, Shinjini Nandi.\n\nLeafArea\n\nRapid Digital Image Analysis of Leaf Area. Author: Masatoshi\nKatabuchi.\n\nLocFDRPois\n\nFunctions for Performing Local FDR Estimation when Null and\nAlternative are Poisson. Author: Kris Sankaran [aut, cre].\n\nMCL\n\nMarkov Cluster Algorithm. Author: Martin L. Jäger.\n\nMCMC4Extremes\n\nPosterior Distribution of Extreme Value Models in R. Authors:\nFernando Ferraz do Nascimento [aut, cre], Wyara Vanesa Moura e\nSilva [aut, ctb].\n\nMCTM\n\nMarkov Chains Transition Matrices. Author: Alessandro Bessi.\n\nMIIVsem\n\nTwo Stage Least Squares with Model Implied Instrumental Search.\nAuthors: Zachary Fisher and Ken Bollen.\n\nMInt\n\nLearn Direct Interaction Networks. Authors: Surojit Biswas, Meredith\nMcDonald, Derek S. Lundberg, Jeffery L. Dangl, Vladimir Jojic.\n\nMLmetrics\n\nMachine Learning Evaluation Metrics. Author: Yachen Yan [aut,\ncre].\n\nMRIaggr\n\nManagement, Display, and Processing of Medical Imaging Data. Author:\nBrice Ozenne. In view:\nMedicalImaging.\n\nMaxPro\n\nMaximum Projection Designs. Authors: Shan Ba and V. Roshan Joseph.\n\nMazamaSpatialUtils\n\nMazama Science Spatial Data Download and Utility Functions. Authors:\nJonathan Callahan [aut, cre], Will Leahy [aut], Henry Nguyen\n[aut].\n\nMetNorm\n\nStatistical Methods for Normalizing Metabolomics Data. Author:\nAlysha M De Livera.\n\nMiRSEA\n\nDiscovering the Risk Pathways Based on microRNA. Authors: Junwei\nHan, Siyao Liu.\n\nMixAll\n\nClustering using Mixture Models. Author: Serge Iovleff [aut, cre].\n\nMultiMeta\n\nMeta-analysis of Multivariate Genome Wide Association Studies.\nAuthor: Dragana Vuckovic. In view:\nMetaAnalysis.\n\nMultiRR\n\nBias, Precision, and Power for Multi-Level Random Regressions.\nAuthor: Yimen G. Araya-Ajoy.\n\nNAM\n\nNested Association Mapping Analysis. Authors: Alencar Xavier,\nWilliam Muir, Katy Rainey, Tiago Pimenta, Qishan Wang, Shizhong Xu.\n\nNNTbiomarker\n\nCalculate Design Parameters for Biomarker Validation Studies.\nAuthor: Roger Day.\n\nNORRRM\n\nGeochemical Toolkit for R. Author: Renee Gonzalez Guzman.\n\nNPC\n\nNonparametric Combination of Hypothesis Tests. Author: Devin Caughey\n[aut, cre].\n\nNSUM\n\nNetwork Scale Up Method. Authors: Rachael Maltiel and Aaron J.\nBaraff.\n\nNormalLaplace\n\nThe Normal Laplace Distribution. Authors: David Scott, Jason Shicong\nFu and Simon Potter.\n\nOpenMx\n\nExtended Structural Equation Modelling. Authors: Steven M. Boker\n[aut], Michael C. Neale [aut], Hermine H. Maes [aut],\nMichael J. Wilde [ctb], Michael Spiegel [aut], Timothy R. Brick\n[aut], Ryne Estabrook [aut], Timothy C. Bates [aut], Paras\nMehta [ctb], Timo von Oertzen [ctb], Ross J. Gore [aut],\nMichael D. Hunter [aut], Daniel C. Hackett [ctb], Julian Karch\n[ctb], Andreas M. Brandmaier [ctb], Joshua N. Pritikin [aut,\ncre], Mahsa Zahery [aut], Robert M. Kirkpatrick [aut], Yang\nWang [ctb].\n\nPAFit\n\nNonparametric Estimation of Preferential Attachment and Node Fitness\nin Temporal Complex Networks. Authors: Thong Pham, Paul Sheridan,\nHidetoshi Shimodaira.\n\nPDQutils\n\nPDQ Functions via Gram Charlier, Edgeworth, and Cornish Fisher\nApproximations. Author: Steven E. Pav [aut, cre]. In view:\nDistributions.\n\nPGRdup\n\nDiscover Probable Duplicates in Plant Genetic Resources Collections.\nAuthors: J. Aravind [aut, cre], J. Radhamani [aut], Kalyani\nSrinivasan [aut], B. Ananda Subhash [aut], R. K. Tyagi [aut].\n\nPPtreeViz\n\nProjection Pursuit Classification Tree Visualization. Author:\nEun-Kyung Lee.\n\nPhyloMeasures\n\nFast and Exact Algorithms for Computing Phylogenetic Biodiversity\nMeasures. Authors: Constantinos Tsirogiannis [aut, cre], Brody\nSandel [aut].\n\nPogromcyDanych\n\nPogromcyDanych / DataCrunchers is the Masive Online Open Course that\nBrings R and Statistics to the People. Author: Przemyslaw Biecek.\n\nPoisBinNonNor\n\nData Generation with Poisson, Binary and Continuous Components.\nAuthors: Gul Inan, Hakan Demirtas.\n\nPoisBinOrd\n\nData Generation with Poisson, Binary and Ordinal Components.\nAuthors: Gul Inan, Hakan Demirtas.\n\nPoisBinOrdNonNor\n\nGeneration of up to Four Different Types of Variables. Authors:\nRachel Nordgren, Hakan Demirtas.\n\nPoisBinOrdNor\n\nData Generation with Poisson, Binary, Ordinal and Normal Components.\nAuthors: Yiran Hu, Hakan Demirtas.\n\nPoisNonNor\n\nSimultaneous Generation of Count and Continuous Data. Authors: Yaru\nShi, Hakan Demirtas.\n\nPopVar\n\nGenomic Breeding Tools: Genetic Variance Prediction and\nCross-Validation. Authors: Tyler Tiede [aut, cre], Mohsen\nMohammadi [ctb], Kevin P. Smith [ctb].\n\nPortfolioAnalytics\n\nPortfolio Analysis, Including Numerical Methods for Optimization of\nPortfolios. Authors: Brian G. Peterson [cre, aut, cph], Peter Carl\n[aut, cph], Kris Boudt [ctb, cph], Ross Bennett [ctb, cph],\nHezky Varon [ctb], Guy Yollin [ctb], R. Douglas Martin [ctb].\n\nQCAfalsePositive\n\nTests for Type I Error in Qualitative Comparative Analysis (QCA).\nAuthor: Bear Braumoeller.\n\nQCAtools\n\nHelper functions for QCA in R. Author: Jirka Lewandowski [aut,\ncre].\n\nRANN.L1\n\nFast Nearest Neighbour Search (Wraps ANN Library) Using L1 Metric.\nAuthors: Sunil Arya and David Mount (for ANN), Samuel E. Kemp,\nGregory Jefferis, Kirill Müller.\n\nRBPcurve\n\nThe Residual-based Predictiveness Curve. Authors: Giuseppe\nCasalicchio, Bernd Bischl.\n\nRDML\n\nImporting Real-Time Thermo Cycler (qPCR) Data from RDML Format\nFiles. Authors: Konstantin A. Blagodatskikh [cre, aut], Stefan\nRoediger [aut], Michal Burdukiewicz [aut].\n\nRDota\n\nData Analysis Toolbox for Dota2. Author: Xiao Lei.\n\nRESS\n\nIntegrates R and Essentia. Author: Ben Waxer.\n\nREST\n\nRcmdrPlugin Easy Script Templates. Author: De Troyer Ewoud.\n\nRFgroove\n\nImportance Measure and Selection for Groups of Variables with Random\nForests. Author: Baptiste Gregorutti.\n\nRFmarkerDetector\n\nMultivariate Analysis of Metabolomics Data using Random Forests.\nAuthors: Piergiorgio Palla, Giuliano Armano.\n\nRGENERATEPREC\n\nTools To Generate Daily-Precipitation Time Series. Author: Emanuele\nCordano.\n\nRJafroc\n\nAnalysis of Data Acquired Using the Receiver Operating\nCharacteristic Paradigm and Its Extensions. Authors: Xuetong Zhai\n[aut, cre], Dev Chakraborty [aut, ths].\n\nRLumShiny\n\nshiny Applications for the R Package Luminescence. Authors:\nChristoph Burow [aut, cre], Jan Odvarko [cph] (jscolor.js),\nAnalytixWare [cph] (ShinySky package).\n\nROCS\n\nReceiver Operating Characteristics Surface. Author: Tianwei Yu.\n\nRPEnsemble\n\nRandom Projection Ensemble Classification. Authors: Timothy I.\nCannings and Richard J. Samworth.\n\nRPPairwiseDesign\n\nResolvable partially pairwise balanced design and Space-filling\ndesign via association scheme. Authors: Mohamed Laib, Imane Rezgui\nand Zebida Gheribi-Aoulmi.\n\nRRTCS\n\nRandomized Response Techniques for Complex Surveys. Authors: Beatriz\nCobo Rodríguez, María del Mar Rueda García, Antonio Arcos Cebrián.\n\nRSPS\n\nRNA-Seq Power Simulation. Authors: Milan Bimali, Joseph Usset,\nBrooke L. Fridley.\n\nRVFam\n\nRare Variants Association Analyses with Family Data. Authors:\nMing-Huei Chen and Qiong Yang.\n\nRadTran\n\nRadon and Soil Gas Transport in 2D Porous Medium. Author: Francisco\nLopes.\n\nRandomFieldsUtils\n\nUtilities for the Simulation and Analysis of Random Fields. Authors:\nMartin Schlather [aut, cre], Reinhard Furrer [ctb].\n\nRborist\n\nExtensible, Parallelizable Implementation of the Random Forest\nAlgorithm. Author: Mark Seligman. In view:\nHighPerformanceComputing.\n\nRcellData\n\nExample Dataset for Rcell Package. Author: Alan Bush.\n\nRcppAPT\n\nRcpp Interface to the APT Package Manager. Author: Dirk\nEddelbuettel.\n\nRcppStreams\n\nRcpp Integration of the Streamulus DSEL for Stream Processing.\nAuthor: Dirk Eddelbuettel.\n\nRcppTOML\n\nRcpp Bindings to Parser for Tom’s Obvious Markup Language. Author:\nDirk Eddelbuettel.\n\nRlibeemd\n\nEnsemble Empirical Mode Decomposition (EEMD) and Its Complete\nVariant (CEEMDAN). Authors: Jouni Helske [aut, cre] (R interface),\nPerttu Luukko [aut] (Original libeemd C library).\n\nRlinkedin\n\nAccess to the LinkedIn API via R. Author: Michael Piccirilli.\n\nRmonkey\n\nA Survey Monkey R Client. Author: Thomas J. Leeper.\n\nRsampletrees\n\nSampletrees Input/Output Processing. Authors: Kelly Burkett, Brad\nMcNeney, Jinko Graham.\n\nRtts\n\nConvert Text into Speech. Author: Xiaodong Deng.\n\nRxnSim\n\nFunctions to Compute Chemical Reaction Similarity. Author: Varun\nGiri [aut, cre].\n\nSAENET\n\nA Stacked Autoencoder Implementation with Interface to neuralnet.\nAuthors: Stephen Hogg [aut, cre], Eugene Dubossarsky [aut].\n\nSAMUR\n\nStochastic Augmentation of Matched Data Using Restriction Methods.\nAuthors: Mansour T.A. Sharabiani, Alireza S. Mahani.\n\nSDDE\n\nShortcuts, Detours and Dead Ends Path Types in Genome Similarity\nNetworks. Authors: Etienne Lord, Margaux Le Cam, Eric Bapteste,\nVladimir Makarenkov and Francois-Joseph Lapointe.\n\nSETPath\n\nSpiked Eigenvalue Test for Pathway data. Author: Patrick Danaher.\n\nSID\n\nStructural Intervention Distance. Author: Jonas Peters.\n\nSLOPE\n\nSorted L1 Penalized Estimation. Authors: Malgorzata Bogdan, Ewout\nvan den Berg, Chiara Sabatti, Weijie Su, Emmanuel Candes, Evan\nPatterson.\n\nSOMbrero\n\nSOM Bound to Realize Euclidean and Relational Outputs. Authors:\nLaura Bendhaiba [aut], Julien Boelaert [aut], Madalina Olteanu\n[aut], Nathalie Villa-Vialaneix [aut, cre].\n\nSOUP\n\nStochastic Ordering Using Permutations (and Pairwise Comparisons).\nAuthor: Federico Mattiello [aut, cre].\n\nSPRT\n\nWald’s Sequential Probability Ratio Test. Author: Stephane Mikael\nBottine.\n\nSRCS\n\nStatistical Ranking Color Scheme for Multiple Pairwise Comparisons.\nAuthor: Pablo J. Villacorta.\n\nSVMMatch\n\nCausal Effect Estimation and Diagnostics with Support Vector\nMachines. Author: Marc Ratkovic.\n\nSWMPr\n\nRetrieving, Organizing, and Analyzing Estuary Monitoring Data.\nAuthor: Marcus W. Beck [aut, cre].\n\nSabermetrics\n\nSabermetrics Functions For Baseball Analytics. Author: Peter\nXenopoulos.\n\nScale\n\nLikert Type Questionnaire Item Analysis. Author: Nikolaos\nGiallousis.\n\nSegCorr\n\nDetecting Correlated Genomic Regions. Authors: Eleni Ioanna\nDelatola, Emilie Lebarbier, Tristan Mary-Huard, Francois Radvanyi,\nStephane Robin, Jennifer Wong.\n\nSensusR\n\nSensus Analytics. Author: Matthew S. Gerber.\n\nShapeSelectForest\n\nShape Selection for Landsat Time Series of Forest Dynamics. Authors:\nMary C. Meyer, Xiyue Liao, Elizabeth Freeman, Gretchen G. Moisen.\n\nSimilarityMeasures\n\nTrajectory Similarity Measures. Author: Kevin Toohey.\n\nSocialPosition\n\nSocial Position Indicators Construction Toolbox. Author: Julie\nFalcon.\n\nSpatPCA\n\nRegularized Principal Component Analysis for Spatial Data. Authors:\nWen-Ting Wang and Hsin-Cheng Huang.\n\nSpatialPosition\n\nSpatial Position Models. Authors: Timothee Giraud [cre, aut],\nHadrien Commenges [aut], Joel Boulier [ctb].\n\nSpecHelpers\n\nSpectroscopy Related Utilities. Authors: Bryan A. Hanson DePauw\nUniversity, Greencastle Indiana USA.\n\nStanHeaders\n\nC++ Header Files for Stan. Authors: Stan Development Team [aut,\ncph], Joshua N. Pritikin [cre, com].\n\nStatMeasures\n\nEasy Data Manipulation, Data Quality and Statistical Checks. Author:\nAkash Jain.\n\nSubpathwayGMir\n\nIdentify Metabolic Subpathways Mediated by MicroRNAs. Authors: Li\nFeng, Chunquan Li and Xia Li.\n\nSurvCorr\n\nCorrelation of Bivariate Survival Times. Authors: Meinhard Ploner,\nAlexandra Kaider and Georg Heinze.\n\nSurvLong\n\nAnalysis of Proportional Hazards Model with Sparse Longitudinal\nCovariates. Authors: Hongyuan Cao, Mathew M. Churpek, Donglin Zeng,\nJason P. Fine, and Shannon T. Holloway.\n\nTAQMNGR\n\nManage Tick-by-Tick Transaction Data. Authors: Francesco Calvori,\nFabrizio Cipollini, Giampiero M. Gallo and ‘gzstream’ authors. In\nview: Finance.\n\nTDAmapper\n\nAnalyze High-Dimensional Data Using Discrete Morse Theory. Authors:\nPaul Pearson [aut, cre, trl], Daniel Muellner [aut, ctb],\nGurjeet Singh [aut, ctb].\n\nTDCor\n\nGene Network Inference from Time-Series Transcriptomic Data. Author:\nJulien Lavenus.\n\nTKF\n\nPairwise Distance Estimation with TKF91 and TKF92 Model. Author: Ge\nTan.\n\nTRD\n\nTransmission Ratio Distortion. Author: Lam Opal Huang.\n\nTROM\n\nTranscriptome Overlap Measure. Authors: Jingyi Jessica Li, Wei Li.\n\nTSPred\n\nFunctions for Baseline-Based Time Series Prediction. Authors:\nRebecca Pontes Salles [aut, cre, cph], Eduardo Ogasawara [ths].\n\nTSmisc\n\nTSdbi Extensions to Wrap Miscellaneous Data Sources. Author: Paul\nGilbert.\n\nTSsdmx\n\nTSdbi Extension to Connect with ‘SDMX’. Author: Paul Gilbert.\n\nTTmoment\n\nSampling and Calculating the First and Second Moments for the Doubly\nTruncated Multivariate \\(t\\) Distribution. Authors: Hsiu J. Ho,\nTsung-I Lin, Wan-Lun Wang, Aldo M. Garay, Victor H. Lachos, and\nMauricio Castro.\n\nThermimage\n\nFunctions for Handling Thermal Images. Authors: Glenn J. Tattersall,\nPhD.\n\nThreeArmedTrials\n\nDesign and Analysis of Clinical Non-inferiority or Superiority\nTrials with Active and Placebo Control. Author: Tobias Muetze.\n\nTickExec\n\nExecution Functions for Tick Data Back Test. Author: HKUST.\n\nVCA\n\nVariance Component Analysis. Author: Andre Schuetzenmeister.\n\nVIGoR\n\nVariational Bayesian Inference for Genome-Wide Regression. Authors:\nAkio Onogi and Hiroyoshi Iwata.\n\nVarSelLCM\n\nVariable Selection for Model-Based Clustering using the Integrated\nComplete-Data Likelihood of a Latent Class Model. Authors: Matthieu\nMarbac and Mohammed Sedki.\n\nWCE\n\nWeighted Cumulative Exposure Models. Authors: Marie-Pierre\nSylvestre, Marie-Eve Beauchamp, Ryan Patrick Kyle, Michal\nAbrahamowicz.\n\nWaterML\n\nFetch and Analyze Data from WaterML or CUAHSI WaterOneFlow Web\nService. Author: Jiri Kadlec [aut, cre].\n\nWhopGenome\n\nHigh-Speed Processing of VCF, FASTA and Alignment Data. Authors:\nUlrich Wittelsbuerger [aut, cre], Heng Li [ctb], Bob Handsaker\n[ctb].\n\nWikipediaR\n\nR-Based Wikipedia Client. Authors: Avner Bar-Hen [aut, cre],\nLouise Baschet [ctb], Francois-Xavier Jollois [ctb], Jeremie\nRiou [ctb].\n\naSPU\n\nAdaptive Sum of Powered Score Test. Authors: Il-Youp Kwak and\nothers.\n\nabc.data\n\nData Only: Tools for Approximate Bayesian Computation (ABC).\nAuthors: Csillery Katalin [aut], Lemaire Louisiane [aut],\nFrancois Olivier [aut], Blum Michael [aut, cre].\n\nacc\n\nProcesses Accelerometer Data. Authors: Jaejoon Song, Matthew G. Cox.\n\nadegraphics\n\nAn S4 Lattice-Based Package for the Representation of Multivariate\nData. Authors: Stéphane Dray and Aurélie Siberchicot, with\ncontributions from Jean Thioulouse. Based on earlier work by Alice\nJulien-Laferrière.\n\nald\n\nThe Asymmetric Laplace Distribution. Authors: Christian E. Galarza\nand Victor H. Lachos. In view:\nDistributions.\n\nalphaOutlier\n\nObtain Alpha-Outlier Regions for Well-Known Probability\nDistributions. Authors: Andre Rehage, Sonja Kuhnt.\n\nanalyz\n\nModel Layer for Automatic Data Analysis via CSV File Interpretation.\nAuthor: Rodrigo Buhler.\n\nanfis\n\nAdaptive Neuro Fuzzy Inference System in R. Authors: Cristobal\nFresno, Andrea S. Llera and Elmer A. Fernandez.\n\napex\n\nPhylogenetic Methods for Multiple Gene Data. Authors: Thibaut\nJombart [aut, cre], Zhian Namir Kamvar [aut], Klaus Schliep\n[aut], Rebecca Harris [aut].\n\nasVPC\n\nAverage Shifted Visual Predictive Checks. Author: Eun-Kyung Lee.\n\nassertr\n\nAssertive Programming for R Analysis Pipelines. Author: Tony\nFischetti [aut, cre].\n\natsd\n\nSupport Querying Axibase Time-Series Database. Author: Axibase\nCorporation.\n\nbabar\n\nBayesian Bacterial Growth Curve Analysis in R. Authors: Lydia\nRickett, Matthew Hartley, Richard Morris and Nick Pullen.\n\nbayesDccGarch\n\nThe Bayesian Dynamic Conditional Correlation GARCH Model. Authors:\nJose A Fioruci, Ricardo S Ehlers, Francisco Louzada. In view:\nTimeSeries.\n\nbetas\n\nStandardized Beta Coefficients. Author: Andrea Cantieni [aut,\ncre].\n\nbigrquery\n\nAn Interface to Google’s BigQuery API. Authors: Hadley Wickham\n[aut, cre], RStudio [cph].\n\nbiogas\n\nAnalyze Biogas Data and Predict Biogas Production. Authors: Sasha D.\nHafner, Charlotte Rennuit, Jin Mi Triolo, and Ali Heidarzadeh\nVazifehkhoran.\n\nbiorxivr\n\nSearch and Download Papers from the bioRxiv Preprint Server. Author:\nEdmund Hart [aut, cre].\n\nbiosignalEMG\n\nStandard Processing Tools for Electromyogram Signals. Authors: J.A.\nGuerrero, J.E. Macias-Diaz.\n\nblatr\n\nSend Emails Using ‘Blat’ for Windows. Author: Stefan Milton Bache.\n\nblmeco\n\nData Files and Functions Accompanying the Book “Bayesian Data\nAnalysis in Ecology using R, BUGS and Stan”. Authors: Fraenzi\nKorner-Nievergelt, Tobias Roth, Stefanie von Felten, Jerome Guelat,\nBettina Almasi, Pius Korner-Nievergelt.\n\nblockmodels\n\nLatent and Stochastic Block Model Estimation by a ‘V-EM’ Algorithm.\nAuthors: INRA, Jean-Benoist Leger.\n\nbootnet\n\nBootstrap Methods for Various Network Estimation Routines. Author:\nSacha Epskamp.\n\nbootsPLS\n\nBootstrap Subsamplings of Sparse Partial Least Squares -\nDiscriminant Analysis for Classification and Signature\nIdentification. Authors: Florian Rohart [aut, cre], Kim-Anh Le Cao\n[boss], Christine Wells [boss].\n\nboottol\n\nBootstrap Tolerance Levels for Credit Scoring Validation Statistics.\nAuthor: Garrett Schiltgen.\n\nboxr\n\nInterface for the Box.com API. Author: Brendan Rocks [aut, cre].\n\nbrewdata\n\nExtracting Usable Data from the Grad Cafe Results Search. Author:\nNathan Welch.\n\nbrms\n\nBayesian Regression Models using Stan. Author: Paul-Christian\nBuerkner [aut, cre].\n\ncOde\n\nAutomated C Code Generation for Use with the deSolve and\nbvpSolve Packages. Author: Daniel Kaschek.\n\ncaretEnsemble\n\nEnsembles of Caret Models. Authors: Zachary A. Mayer [aut, cre],\nJared E. Knowles [aut].\n\ncccp\n\nCone Constrained Convex Problems. Authors: Bernhard Pfaff [aut,\ncre], Lieven Vandenberghe [cph], Martin Andersen [cph], Joachim\nDahl [cph]. In view:\nOptimization.\n\ncchs\n\nCox Model for Case-Cohort Data with Stratified Subcohort-Selection.\nAuthor: E. Jones.\n\ncds\n\nConstrained Dual Scaling for Detecting Response Styles. Author:\nPieter Schoonees [aut, cre].\n\ncellranger\n\nTranslate Spreadsheet Cell Ranges to Rows and Columns. Authors:\nJennifer Bryan [cre, aut], Hadley Wickham [ctb].\n\ncernn\n\nCovariance Estimation Regularized by Nuclear Norm Penalties. Author:\nEric C. Chi.\n\nchopthin\n\nThe Chopthin Resampler. Authors: Axel Gandy and F. Din-Houn Lau.\n\nchromer\n\nInterface to Chromosome Counts Database API. Author: Matthew Pennell\n[aut, cre]. In view:\nWebTechnologies.\n\nclifro\n\nEasily Download and Visualise Climate Data from CliFlo. Author:\nBlake Seers [aut, cre].\n\nclimwin\n\nClimate Window Analysis. Authors: Liam D. Bailey and Martijn van de\nPol.\n\nclusterSEs\n\nCalculate Cluster-Robust \\(p\\)-Values and Confidence Intervals.\nAuthor: Justin Esarey [aut, cre].\n\nclustering.sc.dp\n\nOptimal Distance-Based Clustering for Multidimensional Data with\nSequential Constraint. Authors: Tibor Szkaliczki [aut, cre], J.\nSong [ctb].\n\nclustertend\n\nCheck the Clustering Tendency. Authors: Luo YiLan, Zeng RuTong.\n\ncoloredICA\n\nImplementation of Colored Independent Component Analysis and Spatial\nColored Independent Component Analysis. Authors: Lee, S., Shen, H.,\nTruong, Y. and Zanini, P.\n\ncommonmark\n\nBindings to the ‘CommonMark’ Reference Implementation. Authors:\nJeroen Ooms [aut, cre], John MacFarlane [cph].\n\ncompareC\n\nCompare Two Correlated C Indices with Right-censored Survival\nOutcome. Authors: Le Kang, Weijie Chen.\n\ncondMVNorm\n\nConditional Multivariate Normal Distribution. Author: Ravi Varadhan\n[aut, cre]. In view:\nDistributions.\n\nconformal\n\nConformal Prediction for Regression and Classification. Author:\nIsidro Cortes.\n\ncope\n\nCoverage Probability Excursion Sets. Author: Max Sommerfeld [aut,\ncre].\n\ncovr\n\nTest Coverage for Packages. Author: Jim Hester [aut, cre].\n\ncoxsei\n\nFitting a CoxSEI Model. Author: Feng Chen.\n\ncp4p\n\nCalibration Plot for Proteomics. Authors: Quentin Giai Gianetto,\nFlorence Combes, Yohann Couté, Christophe Bruley, Thomas Burger.\n\ncquad\n\nConditional Maximum Likelihood for Quadratic Exponential Models for\nBinary Panel Data. Authors: Francesco Bartolucci, Claudia Pigini.\n\ncranlogs\n\nDownload Logs from the RStudio CRAN Mirror. Author: Gabor Csardi\n[aut, cre].\n\ncrimelinkage\n\nStatistical Methods for Crime Series Linkage. Authors: Michael\nPorter [aut, cre], Brian Reich [aut].\n\ncrunch\n\nCrunch.io Data Tools. Author: Neal Richardson [aut, cre].\n\ncsrplus\n\nMethods to Test Hypotheses on the Distribution of Spatial Point\nProcesses. Author: Sarah Smith.\n\ndaff\n\nDiff, Patch and Merge for Data.frames. Authors: Paul Fitzpatrick\n[aut], Edwin de Jonge [aut, cre].\n\ndata.tree\n\nHierarchical Data Structures. Author: Christoph Glur.\n\nddeploy\n\nWrapper for the Duke Deploy REST API. Author: Niall McGearailt.\n\ndecisionSupport\n\nQuantitative Support of Decision Making under Uncertainty. Authors:\nLutz [cre, aut], Eike Luedeling [aut].\n\ndecode\n\nDifferential Co-Expression and Differential Expression Analysis.\nAuthor: Thomas Lui [aut, cre].\n\ndenovolyzeR\n\nStatistical Analyses of De Novo Genetic Variants. Authors: James\nWare [aut, cre], Jason Homsy [ctb], Kaitlin Samocha [ctb].\n\ndga\n\nCapture-Recapture Estimation using Bayesian Model Averaging.\nAuthors: James Johndrow, Kristian Lum, and Patrick Ball.\n\ndiagonals\n\nBlock Diagonal Extraction or Replacement. Author: Bastiaan Quast\n[aut, cre].\n\ndiscSurv\n\nDiscrete Time Survival Analysis. Authors: Thomas Welchowski and\nMatthias Schmid.\n\ndisparityfilter\n\nDisparity Filter Algorithm of Weighted Network. Author: Alessandro\nBessi.\n\ndivo\n\nTools for Analysis of Diversity and Similarity in Biological\nSystems. Authors: Maciej Pietrzak, Michal Seweryn, Grzegorz Rempala.\n\ndmm\n\nDyadic Mixed Model for Pedigree Data. Author: Neville Jackson.\n\ndplRCon\n\nConcordance for Dendroclimatology. Author: Maryann Pirie.\n\ndpmr\n\nData Package Manager for R. Author: Christopher Gandrud [aut,\ncre].\n\ndrat\n\nDrat R Archive Template. Author: Dirk Eddelbuettel.\n\ndropR\n\nAnalyze Drop Out of an Experiment or Survey. Authors: Matthias\nBannert [aut, cre], Ulf-Dietrich Reips [aut].\n\ndst\n\nUsing Dempster-Shafer Theory. Author: Claude Boivin.\n\ndynRB\n\nDynamic Range Boxes. Authors: Manuela Schreyer and Wolfgang\nTrutschnig.\n\nebGenotyping\n\nGenotyping using Next Generation Sequencing Data. Authors: Na You\nand Gongyi Huang.\n\nelastic\n\nGeneral Purpose Interface to Elasticsearch. Author: Scott\nChamberlain [aut, cre].\n\nemIRT\n\nEM Algorithms for Estimating Item Response Theory Models. Authors:\nKosuke Imai, James Lo, Jonathan Olmsted.\n\nemov\n\nEye Movement Analysis Package for Fixation and Saccade Detection.\nAuthor: Simon Schwab.\n\nepisensr\n\nBasic Sensitivity Analysis of Epidemiological Results. Author: Denis\nHaine [aut, cre].\n\nesaBcv\n\nEstimate Number of Latent Factors and Factor Matrix for Factor\nAnalysis. Authors: Art B. Owen [aut], Jingshu Wang [aut, cre].\n\nestimability\n\nEstimability Tools for Linear Models. Author: Russell V. Lenth.\n\neurostat\n\nTools for Eurostat Open Data. Authors: Lahti Leo [aut, cre],\nBiecek Przemyslaw [aut], Kainu Markus [aut], Huovari Janne\n[aut].\n\nevolqg\n\nTools for Evolutionary Quantitative Genetics. Authors: Ana Paula\nAssis, Diogo Melo, Edgar Zanella, Fabio Machado, Guilherme Garcia.\n\nfastpseudo\n\nFast Pseudo Observations. Authors: Dayne Batten [aut, cre], Maja\nPohar Perme [ctb], Mette Gerster [ctb].\n\nfbroc\n\nFast Algorithms to Bootstrap Receiver Operating Characteristics\nCurves. Author: Erik Peter [aut, cre].\n\nfdrDiscreteNull\n\nFalse Discovery Rate Procedure Under Discrete Null Distributions.\nAuthors: Xiongzhi Chen and R.W. Doerge.\n\nfermicatsR\n\nFermi Large Area Telescope Catalogs. Author: Pablo Saz Parkinson\n[aut, cre].\n\nfgpt\n\nFloating Grid Permutation Technique. Author: Reinder Radersma & Ben\nSheldon.\n\nfheatmap\n\nDraw Heatmaps with Colored Dendogram. Authors: Vaishali Tumulu and\nSivasish Sindiri.\n\nfitbitScraper\n\nScrapes Data from www.fitbit.com. Author: Cory Nissen [aut, cre].\n\nflower\n\nTools for characterizing flowering traits. Author: Xie Wang.\n\nforecTheta\n\nForecasting Time Series by Theta Method. Authors: Jose Augusto\nFioruci, Francisco Louzada and Bao Yiqi. In view:\nTimeSeries.\n\nforestFloor\n\nVisualizes Random Forests with Feature Contributions. Author: Soeren\nHavelund Welling.\n\nfpCompare\n\nReliable Comparison of Floating Point Numbers. Authors: Alex M\nChubaty [aut, cre], Her Majesty the Queen in Right of Canada, as\nrepresented by the Minister of Natural Resources Canada [cph].\n\nfrmpd\n\nRegression Analysis of Panel Fractional Responses. Author: Joaquim\nJ.S. Ramalho.\n\nfsia\n\nImport and Analysis of OMR Data from FormScanner. Author: Michela\nBattauz.\n\nfuntimes\n\nFunctions for Time Series Analysis. Authors: Vyacheslav Lyubchich,\nYulia R. Gel and Xingyu Wang.\n\ngapminder\n\nGapminder Data. Author: Jennifer Bryan [aut, cre].\n\ngaselect\n\nGenetic Algorithm for Variable Selection from High-Dimensional Data.\nAuthor: David Kepplinger.\n\ngazepath\n\nGazepath Transforms Eye-Tracking Data into Fixations and Saccades.\nAuthor: Daan van Renswoude.\n\ngbm2sas\n\nConvert GBM Object Trees to SAS Code. Author: John R. Dixon.\n\ngdm\n\nFunctions for Generalized Dissimilarity Modeling. Authors: Glenn\nManion, Matthew Lisk, Simon Ferrier, Diego Nieto-Lugilde, Matthew C.\nFitzpatrick.\n\ngelnet\n\nGeneralized Elastic Nets. Author: Artem Sokolov.\n\ngenderizeR\n\nGender Prediction Based on First Names. Author: Kamil Wais [aut,\ncre].\n\ngeojsonio\n\nConvert Data from and to ‘geoJSON’ or ‘topoJSON’. Authors: Scott\nChamberlain [aut, cre], Andy Teucher [aut].\n\nggExtra\n\nAdd Marginal Histograms to ggplot2, and More ggplot2\nEnhancements. Author: Dean Attali [aut, cre].\n\nggenealogy\n\nVisualization Tools for Genealogical Data. Authors: Lindsay Rutter,\nSusan Vanderplas, Di Cook.\n\ngistr\n\nWork with GitHub Gists. Authors: Ramnath Vaidyanathan [aut],\nKarthik Ram [aut], Scott Chamberlain [aut, cre]. In view:\nWebTechnologies.\n\ngit2r\n\nProvides Access to Git Repositories.\n\nglba\n\nGeneral Linear Ballistic Accumulator Models. Author: Ingmar Visser.\n\nglmgraph\n\nGraph-Constrained Regularization for Sparse Generalized Linear\nModels. Authors: Li Chen, Jun Chen.\n\nglmm\n\nGeneralized Linear Mixed Models via Monte Carlo Likelihood\nApproximation. Author: Christina Knudson.\n\ngmnl\n\nMultinomial Logit Models with Random Parameters. Authors: Mauricio\nSarrias [aut, cre], Ricardo Daziano [aut], Yves Croissant\n[ctb]. In view:\nEconometrics.\n\ngraphicalVAR\n\nGraphical VAR for Experience Sampling Data. Author: Sacha Epskamp.\n\ngraphscan\n\nCluster Detection with Hypothesis Free Scan Statistic. Authors:\nRobin Loche, Benoit Giron, David Abrial, Lionel Cucala, Myriam\nCharras-Garrido, Jocelyn De-Goer.\n\ngreyzoneSurv\n\nFit a Grey-Zone Model with Survival Data. Authors: Pingping Qu and\nJohn Crowley.\n\ngromovlab\n\nGromov-Hausdorff Type Distances for Labeled Metric Spaces. Author:\nVolkmar Liebscher.\n\ngroupRemMap\n\nRegularized Multivariate Regression for Identifying Master\nPredictors Using the GroupRemMap Penalty. Authors: Xianlong Wang, Li\nQin, Hexin Zhang, Yuzheng Zhang, Li Hsu, Pei Wang.\n\ngsheet\n\nDownload Google Sheets Using Just the URL. Author: Max Conway [aut,\ncre].\n\ngsw\n\nGibbs Sea Water Functions. Authors: Dan Kelley [aut, cre, cph],\nClark Richards [aut, cph], WG127 SCOR/IAPSO [aut, cph].\n\ngtop\n\nGame-Theoretically OPtimal Reconciliation Method. Authors: Jairo\nCugliari, Tim van Erven. In view:\nTimeSeries.\n\ngvc\n\nGlobal Value Chains Tools. Authors: Bastiaan Quast [aut, cre],\nVictor Kummritz [aut].\n\nh5\n\nInterface to the ‘HDF5’ Library. Author: Mario Annau [aut, cre].\n\nhaplotypes\n\nHaplotype Inference and Statistical Analysis of Genetic Variation.\nAuthor: Caner Aktas.\n\nhaven\n\nImport SPSS, Stata and SAS Files. Authors: Hadley Wickham [aut,\ncre], Evan Miller [aut, cph], RStudio [cph].\n\nhbm\n\nHierarchical Block Matrix Analysis. Author: Yoli Shavit.\n\nhgm\n\nHolonomic Gradient Method and Gradient Descent. Authors: Nobuki\nTakayama, Tamio Koyama, Tomonari Sei, Hiromasa Nakayama, Kenta\nNishiyama.\n\nhierDiversity\n\nHierarchical Multiplicative Partitioning of Complex Phenotypes.\nAuthors: Zachary Marion, James Fordyce, and Benjamin Fitzpatrick.\n\nhiertest\n\nConvex Hierarchical Testing of Interactions. Authors: Jacob Bien,\nNoah Simon, and Rob Tibshirani.\n\nhisse\n\nHidden State Speciation and Extinction. Authors: Jeremy M. Beaulieu,\nBrian O’Meara.\n\nhistmdl\n\nA Most Informative Histogram-Like Model. Author: Jouke Witteveen.\n\nhornpa\n\nHorn’s (1965) Test to Determine the Number of Components/Factors.\nAuthor: Francis Huang.\n\nhsdar\n\nManage, Analyse and Simulate Hyperspectral Data in R. Authors:\nLukas W. Lehnert [cre, aut], Hanna Meyer [ctb], Joerg Bendix\n[ctb].\n\nhttk\n\nHigh-Throughput Toxicokinetics. Authors: John Wambaugh and Robert\nPearce, Schmitt method implementation by Jimena Davis, dynamic model\nadapted from code by R. Woodrow Setzer, Rabbit parameters from Nisha\nSipes.\n\nhwwntest\n\nTests of White Noise using Wavelets. Authors: Delyan Savchev\n[aut], Guy Nason [aut, cre]. In view:\nTimeSeries.\n\nicenReg\n\nRegression Models for Interval Censored Data. Author: Clifford\nAnderson-Bergman.\n\nifctools\n\nItalian Fiscal Code (‘Codice Fiscale’) Utilities. Author: Luca\nBraglia [aut, cre].\n\nig.vancouver.2014.topcolour\n\nInstagram 2014 Vancouver Top Colour Dataset. Author: Roland Tanglao\n[aut, cre].\n\nihs\n\nInverse Hyperbolic Sine Distribution. Author: Carter Davis. In view:\nDistributions.\n\nimport\n\nAn Import Mechanism for R. Author: Stefan Milton Bache.\n\ninferference\n\nMethods for Causal Inference with Interference. Author: Bradley\nSaul.\n\ninfra\n\nAn Infrastructure Proxy Function. Author: Steve Pickering.\n\ninfuser\n\nA Very Basic Templating Engine. Author: Bart Smeets.\n\ninstall.load\n\nCheck, Install and Load CRAN & USGS GRAN Packages. Author:\nmaloneypatr at Stack Overflow, Irucka Embry.\n\ninterferenceCI\n\nExact Confidence Intervals in the Presence of Interference. Author:\nJoseph Rigdon.\n\ninternetarchive\n\nAn API Client for the Internet Archive. Author: Lincoln Mullen\n[aut, cre].\n\nitsadug\n\nInterpreting Time Series and Autocorrelated Data Using GAMMs.\nAuthors: Jacolien van Rij [aut, cre], Martijn Wieling [aut], R.\nHarald Baayen [aut], Hedderik van Rijn [aut].\n\nivmodel\n\nStatistical Inference and Diagnostics for Instrumental Variables\nModel. Authors: Yang Jiang, Hyunseung Kang, and Dylan Small.\n\nivpanel\n\nInstrumental Panel Data Models. Author: Zaghdoudi Taha. In view:\nEconometrics.\n\njagsUI\n\nA Wrapper Around rjags to Streamline JAGS Analyses. Author: Ken\nKellner.\n\njames.analysis\n\nAnalysis Tools for the ‘JAMES’ Framework. Author: Herman De\nBeukelaer.\n\njiebaRD\n\nChinese Text Segmentation Data for jiebaR Package. Author: Qin\nWenfeng.\n\njmetrik\n\nTools for Interacting with ‘jMetrik’. Author: J. Patrick Meyer.\n\njoint.Cox\n\nPenalized Likelihood Estimation under the Joint Cox Models Between\nTTP and OS for Meta-Analysis. Author: Takeshi Emura.\n\njs\n\nTools for Working with JavaScript in R. Author: Jeroen Ooms.\n\nkfigr\n\nIntegrated Code Chunk Anchoring and Referencing for R Markdown\nDocuments. Author: Michael Koohafkan.\n\nkissmig\n\na Keep It Simple Species Migration Model. Authors: Michael P. Nobis\n[cre, aut], Signe Normand [ctb].\n\nkmodR\n\nK-Means with Simultaneous Outlier Detection. Author: David Charles\nHowe [aut, cre].\n\nlaketemps\n\nLake Temperatures Collected by Situ and Satellite Methods from\n1985-2009. Author: Jordan S Read.\n\nlamW\n\nLambert-W Function. Author: Avraham Adler [aut, cph, cre].\n\nlawn\n\nR Client for ‘Turfjs’ for Geospatial Analysis. Authors: Scott\nChamberlain [aut, cre], Jeff Hollister [aut].\n\nlba\n\nLatent Budget Analysis for Compositional Data. Author: Enio G.\nJelihovschi Ivan Bezerra Allaman.\n\nlbfgsb3\n\nLimited Memory BFGS Minimizer with Bounds on Parameters. Authors:\nJohn C Nash [aut, cre], Ciyou Zhu [aut], Richard Byrd [aut],\nJorge Nocedal [aut], Jose Luis Morales [aut].\n\nlearnstats\n\nAn Interactive Environment for Learning Statistics. Author: Daniel\nWalter [aut, cre].\n\nlfactors\n\nFactors with Levels. Author: Paul Bailey [aut, cre].\n\nlfl\n\nLinguistic Fuzzy Logic. Author: Michal Burda.\n\nlinbin\n\nBinning and Plotting of Linearly Referenced Data. Authors: Ethan Z.\nWelty [aut, cre], Christian E. Torgersen [ctb], Samuel J.\nBrenkman [ctb], Jeffrey J. Duda [ctb], Jonathan B. Armstrong\n[ctb].\n\nlinkR\n\n3D Lever and Linkage Mechanism Modeling. Author: Aaron Olsen.\n\nlistenv\n\nEnvironments Behaving (Almost) as Lists. Author: Henrik Bengtsson\n[aut, cre, cph].\n\nlmfor\n\nFunctions for Forest Biometrics. Author: Lauri Mehtatalo.\n\nlodGWAS\n\nGenome-Wide Association Analysis of a Biomarker Accounting for Limit\nof Detection. Authors: Ahmad Vaez, Ilja M. Nolte, Peter J. van der\nMost.\n\nloopr\n\nUses an Archive to Amend Previous Stages of a Pipe using Current\nOutput. Author: Brandon Taylor.\n\nlsbclust\n\nLeast-Squares Bilinear Clustering for Three-Way Data. Authors:\nPieter Schoonees [aut, cre], Patrick Groenen [ctb].\n\nmanifestoR\n\nAccess and Process Data and Documents of the Manifesto Project.\nAuthors: Jirka Lewandowski [aut, cre], Nicolas Merz [aut], Sven\nRegel [ctb], Pola Lehmann [ctb].\n\nmapDK\n\nMaps of Denmark. Author: Sebastian Barfort.\n\nmapfit\n\nA Tool for PH/MAP Parameter Estimation. Author: Hiroyuki Okamura.\n\nmarl\n\nMultivariate Analysis Based on Relative Likelihoods. Author: Milan\nBimali.\n\nmatchingR\n\nGale-Shapley Algorithm in R and C++. Author: Jan Tilly.\n\nmedicalrisk\n\nMedical Risk and Comorbidity Tools for ICD-9-CM Data. Authors:\nPatrick McCormick [aut, cre], Thomas Joseph [aut].\n\nmetagear\n\nComprehensive Research Synthesis Tools for Systematic Reviews and\nMeta-Analysis. Author: Marc J. Lajeunesse [aut, cre].\n\nmglmn\n\nModel Averaging for Multivariate GLM with Null Models. Authors:\nMasatoshi Katabuchi and Akihiro Nakamura.\n\nminimist\n\nParse Argument Options. Authors: Jeroen Ooms, James Halliday.\n\nmitml\n\nTools for Multiple Imputation in Multilevel Modeling. Authors: Simon\nGrund [aut, cre], Alexander Robitzsch [aut], Oliver Luedtke\n[aut].\n\nmixedMem\n\nTools for Discrete Multivariate Mixed Membership Models. Authors: Y.\nSamuel Wang [aut, cre], Elena A. Erosheva [aut].\n\nmixlm\n\nMixed Model ANOVA and Statistics for Education. Authors: Kristian\nHovde Liland [aut, cre], Solve Sæbø [ctb], R-Core [ctb].\n\nmixtNB\n\nDE Analysis of RNA-Seq Data by Mixtures of NB. Authors: Elisabetta\nBonafede, Cinzia Viroli.\n\nmldr\n\nExploratory Data Analysis and Manipulation of Multi-Label Data Sets.\nAuthors: David Charte [cre], Francisco Charte [aut].\n\nmlxR\n\nSimulation of Longitudinal Data. Authors: Marc Lavielle [aut,\ncre], Raphael Kuate [ctb], Romain Francois [ctb], Fazia Bellal\n[ctb].\n\nmma\n\nMultiple Mediation Analysis. Author: Qingzhao Yu.\n\nmmpp\n\nVarious Similarity and Distance Metrics for Marked Point Processes.\nAuthors: Hideitsu Hino, Ken Takano, Yuki Yoshikawa, and Noboru\nMurata.\n\nmodMax\n\nCommunity Structure Detection via Modularity Maximization. Authors:\nMaria Schelling, Cang Hui.\n\nmomentchi2\n\nMoment-Matching Methods for Weighted Sums of Chi-Squared Random\nVariables. Author: Dean Bodenham.\n\nmongolite\n\nFast and Simple ‘MongoDB’ Client for R. Authors: Jeroen Ooms [aut,\ncre], MongoDB, Inc [cph].\n\nmountainplot\n\nMountain Plots, Folded Empirical Cumulative Distribution Plots.\nAuthor: Kevin Wright.\n\nmousetrack\n\nMouse-Tracking Measures from Trajectory Data. Authors: Moreno I.\nCoco and Nicholas D. Duran with contributions of Rick Dale, Denis\nO’Hora and Michael J. Spivey.\n\nmuir\n\nExploring Data with Tree Data Structures. Author: Justin Alford\n[aut, cre].\n\nmultiAssetOptions\n\nFinite Difference Method for Multi-Asset Option Valuation. Authors:\nMichael Eichenberger and Carlo Rosa.\n\nmultimark\n\nCapture-Mark-Recapture Analysis using Multiple Non-Invasive Marks.\nAuthors: Brett T. McClintock [aut, cre], Acho Arnold [ctb, cph],\nBarry Brown [ctb], James Lovato [ctb], John Burkardt [ctb],\nCleve Moler [ctb].\n\nmultirich\n\nCalculate Multivariate Richness via UTC and sUTC. Author: Alexander\nKeyel.\n\nmultiway\n\nComponent Models for Multi-Way Data. Author: Nathaniel E. Helwig.\n\nmvmesh\n\nMultivariate Meshes and Histograms in Arbitrary Dimensions. Author:\nJohn P. Nolan.\n\nmvnpermute\n\nGenerate New Multivariate Normal Samples from Permutations. Author:\nMark Abney.\n\nmztwinreg\n\nRegression Models for Monozygotic Twin Data. Author: Aldo\nCordova-Palomera.\n\nnFCA\n\nNumerical Formal Concept Analysis for Systematic Clustering.\nAuthors: Junheng Ma, Jiayang Sun, and Guo-Qiang Zhang.\n\nnLTT\n\nCalculate the NLTT Statistic. Author: Thijs Janzen.\n\nncappc\n\nNCA Calculation and Population PK Model Diagnosis. Authors: Chayan\nAcharya [aut, cre], Andrew C. Hooker [aut], Siv Jonsson [aut],\nMats O. Karlsson [aut].\n\nneotoma\n\nAccess to the Neotoma Paleoecological Database Through R. Authors:\nSimon J. Goring [aut, cre], Gavin L. Simpson [aut], Jeremiah P.\nMarsicek [ctb], Karthik Ram [aut], Luke Sosalla [ctb].\n\nnestedRanksTest\n\nMann-Whitney-Wilcoxon Test for Nested Ranks. Author: Douglas G.\nScofield [aut, cre].\n\nnetassoc\n\nInference of Species Associations from Co-Occurrence Data. Authors:\nBenjamin Blonder, Naia Morueta-Holme.\n\nnetgen\n\nNetwork Generator for Combinatorial Graph Problems. Author: Jakob\nBossek [aut, cre].\n\nngramrr\n\nA Simple General Purpose N-Gram Tokenizer. Author: Chung-hong Chan.\n\nnnlasso\n\nNon-Negative Lasso and Elastic Net Penalized Generalized Linear\nModels. Authors: B N Mandal and Jun Ma.\n\nnovelist\n\nNOVEL Integration of the Sample and Thresholded Correlation and\nCovariance Estimators. Authors: Na Huang and Piotr Fryzlewicz.\n\nnpIntFactRep\n\nNonparametric Interaction Tests for Factorial Designs with Repeated\nMeasures. Author: Jos Feys.\n\nodeintr\n\nC++ ODE Solvers Compiled on-Demand. Author: Timothy H. Keitt. In\nview:\nDifferentialEquations.\n\nonls\n\nOrthogonal Nonlinear Least-Squares Regression. Author:\nAndrej-Nikolai Spiess.\n\noptifunset\n\nSet Options if Unset. Author: Nicholas Hamilton.\n\nordinalCont\n\nOrdinal Regression Analysis for Continuous Scales. Authors: Maurizio\nManuguerra [aut, cre], Gillian Heller [aut].\n\npRF\n\nPermutation Significance for Random Forests. Author: Ankur\nChakravarthy.\n\npacman\n\nPackage Management Tool. Authors: Tyler Rinker [aut, cre, ctb],\nDason Kurkiewicz [aut, ctb].\n\npairsD3\n\nD3 Scatterplot Matrices. Author: Garth Tarr [aut, cre].\n\npampe\n\nImplementation of the Panel Data Approach Method for Program\nEvaluation. Author: Ainhoa Vega-Bayo. In view:\nEconometrics.\n\nparallelSVM\n\nA Parallel-Voting Version of the Support-Vector-Machine Algorithm.\nAuthor: Wannes Rosiers.\n\npartialAR\n\nPartial Autoregression. Author: Matthew Clegg [aut, cre, cph].\n\npartools\n\nTools for the parallel Package. Author: Norm Matloff.\n\npatchSynctex\n\nCommunication Between Editor and Viewer for Literate Programs.\nAuthors: Jan Gleixner [aut], Daniel Hicks [ctb], Emmanuel\nCharpentier [aut, cre].\n\npathological\n\nPath Manipulation Utilities. Authors: Richard Cotton [aut, cre],\nJanko Thyson [ctb].\n\npcaBootPlot\n\nCreate 2D Principal Component Plots with Bootstrapping. Author:\nJoshua Starmer.\n\nperspectev\n\nPermutation of Species During Turnover Events. Authors: Kenneth B.\nHoehn [aut, cre], Glen A. Sargeant [ctb].\n\nphylocurve\n\nPhylogenetic Comparative Methods for Function-Valued and Other\nHigh-Dimensional Traits. Author: Eric W. Goolsby.\n\nphysiology\n\nCalculate Physiological Characteristics of Adults and Children.\nAuthor: Jack O. Wasey [aut, cre].\n\nphytotools\n\nPhytoplankton Production Tools. Authors: Greg M. Silsbe, Sairah Y.\nMalkin.\n\npipe.design\n\nDual-Agent Dose Escalation for Phase I Trials using the PIPE Design.\nAuthor: Michael Sweeting.\n\nplantecophys\n\nModelling and Analysis of Leaf Gas Exchange Data. Author: Remko\nDuursma.\n\nplaqr\n\nPartially Linear Additive Quantile Regression. Author: Adam Maidman\n[cre, aut].\n\npogit\n\nBayesian Variable Selection for a Poisson-Logistic Model. Authors:\nMichaela Dvorzak [aut, cre], Helga Wagner [aut].\n\npointRes\n\nAnalyzing Pointer Years and Components of Resilience. Authors:\nMarieke van der Maaten-Theunissen and Ernst van der Maaten.\n\npoisDoubleSamp\n\nConfidence Intervals with Poisson Double Sampling. Authors: David\nKahle [aut, cre], Phil Young [aut], Dean Young [aut].\n\nppiPre\n\nPredict Protein-Protein Interactions Based on Functional and\nTopological Similarities. Authors: Yue Deng, Rongjie Shao, Gang Wang\nand Yuanjun Sun.\n\nprais\n\nPrais-Winsten Estimation Procedure for AR(1) Serial Correlation.\nAuthor: Franz Mohr.\n\nprecintcon\n\nPrecipitation Intensity, Concentration and Anomaly Analysis. Author:\nLucas Venezian Povoa.\n\npresens\n\nR Interface for PreSens Fiber Optic Data. Author: Matthew A. Birk.\n\nprobFDA\n\nProbabilistic Fisher Discriminant Analysis. Author: Charles\nBouveyron & Camille Brunet.\n\nprobemod\n\nStatistical Tools for Probing Moderation Effects. Author: Jiat Chow\nTan [aut, cre].\n\nprogress\n\nTerminal Progress Bars. Author: Gabor Csardi [aut, cre].\n\nprovenance\n\nStatistical Toolbox for Sedimentary Provenance Analysis. Author:\nPieter Vermeesch [aut, cre].\n\npssm\n\nPiecewise Exponential Model for Time to Progression and Time from\nProgression to Death. Author: David A. Schoenfeld [aut, cre].\n\npullword\n\nR Interface to Pullword Service. Author: Tong He.\n\npvrank\n\nRank Correlations. Authors: Amerise I. L., Marozzi M., Tarsitano A.\n\nqclust\n\nRobust Estimation of Gaussian Mixture Models. Authors: Yichen Qin,\nCarey E. Priebe.\n\nqrLMM\n\nQuantile Regression for Linear Mixed-Effects Models. Authors:\nChristian E. Galarza and Victor H. Lachos.\n\nqrNLMM\n\nQuantile Regression for Nonlinear Mixed-Effects Models. Authors:\nChristian E. Galarza and Victor H. Lachos.\n\nqrmtools\n\nTools for Quantitative Risk Management. Authors: Marius Hofert\n[aut, cre], Kurt Hornik [aut].\n\nqrng\n\n(Randomized) Quasi-Random Number Generators. Authors: Marius Hofert\n[aut, cre], Christiane Lemieux [aut].\n\nqte\n\nQuantile Treatment Effects. Author: Brantly Callaway.\n\nquanteda\n\nQuantitative Analysis of Textual Data. Authors: Kenneth Benoit\n[aut, cre], Paul Nulty [aut], Pablo Barberá [ctb], Kohei\nWatanabe [ctb], Benjamin Lauderdale [ctb].\n\nquantification\n\nQuantification of Qualitative Survey Data. Author: Joachim\nZuckarelli.\n\nquickpsy\n\nFits Psychometric Functions for Multiple Groups. Authors: Daniel\nLinares [aut, cre], Joan López-Moliner [aut].\n\nqwraps2\n\nQuick Wraps 2. Author: Peter DeWitt [aut, cre].\n\nrLTP\n\nR interface to LTP-Cloud service. Author: Tong He.\n\nrLiDAR\n\nLiDAR Data Processing and Visualization. Authors: Carlos A. Silva,\nNicholas L. Crookston, Andrew T. Hudak, Lee A. Vierling.\n\nrNMF\n\nRobust Nonnegative Matrix Factorization. Authors: Yifan Ethan Xu,\nJiayang Sun.\n\nrTableICC\n\nRandom Generation of Contingency Tables. Author: Haydar Demirhan.\n\nrUnemploymentData\n\nData and Functions for USA State and County Unemployment Data.\nAuthor: Ari Lamstein [cre].\n\nradiant\n\nBusiness Analytics using R and shiny. Author: Vincent Nijs [aut,\ncre].\n\nradir\n\nInverse-Regression Estimation of Radioactive Doses. Authors: David\nMoriña, Manuel Higueras and Pedro Puig.\n\nramify\n\nAdditional Matrix Functionality. Author: Brandon Greenwell [aut,\ncre].\n\nrandNames\n\nProvide Access to Fake User Data. Author: Karthik Ram [aut, cre].\n\nrandomizr\n\nEasy to Use Tools for Common Forms of Random Assignment. Author:\nAlexander Coppock [aut, cre].\n\nrankdist\n\nDistance Based Ranking Models. Author: Zhaozhi Qian.\n\nrchallenge\n\nA Simple Datascience Challenge System. Authors: Adrien Todeschini\n[aut, cre], Robin Genuer [ctb].\n\nrcorpora\n\nA Collection of Small Text Corpora of Interesting Data. Authors:\nDarius Kazemi, Matthew Rothenberg, Karl Swedberg, Matthew Hokanson,\nNathan Lachenmyer, Aaron Marriner, Mark Sample, Casey Kolderup,\nNathaniel Mitchell, Daniel D. Beck, Mike Nowak, Ryan Freebern, Ross\nBarclay, Ross Binden, Justin Alford, Cole Willsea, Andrew Gorman,\nJavier Arce, Patrick Rodriguez, Liam Cooke, Will Hankinson, K. Adam\nWhite, Garrett Miller, Zac Moody, Jordan Killpack, Brian Jones, Greg\nBorenstein, Noah Swartz, Nathan Black, Russell Horton, Mark Wunsch,\nKay Belardinelli, Colin Mitchell, Michael Dewberry, Joe Mahoney.\n\nrdrop2\n\nProgrammatic Interface to the Dropbox API. Author: Karthik Ram\n[aut, cre].\n\nreGenotyper\n\nDetecting Mislabeled Samples in Genetic Data. Author: Yang Li.\n\nreadGenalex\n\nRead, Write, Manipulate and Convert GenAlEx-Format Genotype Files.\nAuthor: Douglas G. Scofield [aut, cre].\n\nreadr\n\nRead Tabular Data. Authors: Hadley Wickham [aut, cre], Romain\nFrancois [aut], R Core Team [ctb], RStudio [cph].\n\nreadstata13\n\nImport Stata 13 and 14 Data Files. Authors: Jan Marvin Garbuszus\n[aut], Sebastian Jeworutzki [aut, cre], R Core Team [cph].\n\nreadxl\n\nRead Excel Files. Authors: Hadley Wickham [aut, cre], RStudio\n[cph], Marcin Kalicinski [ctb, cph], Komarov Valery [ctb,\ncph], Christophe Leitienne [ctb, cph], Bob Colbert [ctb, cph],\nDavid Hoerl [ctb, cph].\n\nrebus\n\nBuild Regular Expressions in a Human Readable Way. Author: Richard\nCotton [aut, cre].\n\nredist\n\nMarkov Chain Monte Carlo Methods for Redistricting Simulation.\nAuthors: Ben Fifield, Alexander Tarr, Michael Higgins, and Kosuke\nImai.\n\nreplicatedpp2w\n\nTwo-Way ANOVA-Like Method to Analyze Replicated Point Patterns.\nAuthor: Marcelino de la Cruz Rot.\n\nreproducer\n\nReproduce Statistical Analyses and Meta-Analyses. Authors: Lech\nMadeyski [cre, aut], Marian Jureczko [ctb], Barbara Kitchenham\n[ctb].\n\nrerddap\n\nGeneral Purpose Client for ‘ERDDAP’ Servers. Author: Scott\nChamberlain [aut, cre].\n\nrestimizeapi\n\nFunctions for Working with the ‘www.estimize.com’ Web Services.\nAuthor: Thomas P. Fuller. In view:\nFinance.\n\nretrosheet\n\nImport Professional Baseball Data from ‘Retrosheet’. Author: Richard\nScriven [aut, cre].\n\nreval\n\nRepeated Function Evaluation for Sensitivity Analysis. Author:\nMichael C Koohafkan [aut, cre].\n\nrglobi\n\nR Interface to Global Biotic Interactions. Authors: Jorrit Poelen\n[aut, cre], Stephen Gosnell [aut], Sergey Slyusarev [aut].\n\nrgrass7\n\nInterface Between GRASS 7 Geographical Information System and R.\nAuthors: Roger Bivand [cre, aut], Rainer Krug [ctb], Markus\nNeteler [ctb].\n\nriceware\n\nA Diceware Passphrase Implementation. Authors: Francois Michonneau\n[aut, cre], Arnold G. Reinhold [cph].\n\nrivr\n\nSteady and Unsteady Open-Channel Flow Computation. Author: Michael C\nKoohafkan [aut, cre].\n\nrjade\n\nA Clean, Whitespace-Sensitive Template Language for Writing HTML.\nAuthors: Jeroen Ooms, Forbes Lindesay.\n\nrkafka\n\nUsing Apache ‘Kafka’ Messaging Queue Through R. Author: Shruti\nGupta[aut,cre].\n\nrkafkajars\n\nExternal Jars Required for Package rkafka. Authors: Shruti Gupta\n[aut, cre], Coda Hale and Yammer Inc. [ctb, cph], Sun\nMicrosystems Inc. [ctb, cph], Marc Prud’hommeaux [ctb, cph],\nPaul Holser [ctb], Junit [ctb, cph], The Apache Software\nFoundation [ctb, cph], Stefan Groschupf [ctb, cph], Taro L.Saito\n[ctb], EPFL Typesafe Inc. [ctb, cph], QOS.ch [ctb, cph].\n\nrlm\n\nRobust Fitting of Linear Model. Author: Oleg Yegorov.\n\nrotationForest\n\nFit and Deploy Rotation Forest Models. Authors: Michel Ballings and\nDirk Van den Poel.\n\nroughrf\n\nRoughened Random Forests for Binary Classification. Author: Kuangnan\nXiong.\n\nrprime\n\nFunctions for Working with ‘Eprime’ Text Files. Author: Tristan\nMahr.\n\nrr\n\nStatistical Methods for the Randomized Response Technique. Authors:\nGraeme Blair, Yang-Yang Zhou, Kosuke Imai.\n\nrsatscan\n\nTools, Classes, and Methods for Interfacing with SaTScan Stand-Alone\nSoftware. Author: Ken Kleinman [aut, cre].\n\nrscala\n\nBi-Directional Interface Between R and Scala with Callbacks.\nAuthors: David B. Dahl [aut, cre], Scala developers [ctb].\n\nrtable\n\nTabular Reporting Functions. Author: David Gohel [aut, cre].\n\nrversions\n\nQuery R Versions, Including ‘r-release’ and ‘r-oldrel’. Authors:\nGabor Csardi [aut, cre], Jeroen Ooms [ctb].\n\nsadists\n\nSome Additional Distributions. Author: Steven E. Pav [aut, cre].\nIn view:\nDistributions.\n\nsae2\n\nSmall Area Estimation: Time-series Models. Authors: Robert E. Fay,\nMamadou Diallo. In view:\nTimeSeries.\n\nsaturnin\n\nSpanning Trees Used for Network Inference. Author: Loïc Schwaller.\n\nsdwd\n\nSparse Distance Weighted Discrimination. Authors: Boxiang Wang, Hui\nZou.\n\nsearchable\n\nTools for Custom Searches / Subsets / Slices of Named R Objects.\nAuthor: DecisionPatterns [aut, cre].\n\nseismicRoll\n\nFast Rolling Functions for Seismology using Rcpp. Authors:\nJonathan Callahan [aut, cre], Rob Casey [aut], Mary Templeton\n[aut].\n\nselfea\n\nSelect Features Reliably with Cohen’s Effect Sizes. Authors: Lang Ho\nLee, Arnold Saxton, Nathan Verberkmoes.\n\nsemsfa\n\nSemiparametric Estimation of Stochastic Frontier Models. Authors:\nGiancarlo Ferrara and Francesco Vidoli. In view:\nEconometrics.\n\nseroincidence\n\nEstimating Infection Rates from Serological Data. Authors: Peter\nTeunis [aut], Daniel Lewandowski [com, ctb], Chantal Quinten\n[ctb, cre].\n\nsgPLS\n\nSparse Group Partial Least Square Methods. Authors: Benoit Liquet\nand Pierre Lafaye de Micheaux.\n\nsgd\n\nStochastic Gradient Descent for Scalable Estimation. Authors: Dustin\nTran [aut, cre], Tian Lian [aut], Panos Toulis [aut], Ye Kuang\n[ctb], Edoardo Airoldi [ctb].\n\nsgt\n\nSkewed Generalized \\(T\\) Distribution. Author: Carter Davis. In view:\nDistributions.\n\nshapeR\n\nCollection and Analysis of Otolith Shape Data. Authors: Lisa Anne\nLibungan [aut, cre], Snaebjorn Palsson [aut, ths].\n\nshinyTree\n\njsTree Bindings for shiny. Authors: Trestle Technology, LLC\n[aut], Jeff Allen [cre], Institut de Radioprotection et de\nSûreté Nucléaire [cph], Ivan Bozhanov [ctb, cph], The Dojo\nFoundation [ctb, cph], jQuery Foundation, Inc. [ctb, cph].\n\nshinybootstrap2\n\nBootstrap 2 Web Components for Use with shiny. Authors: Winston\nChang [aut, cre], RStudio [cph], Mark Otto [ctb], Jacob\nThornton [ctb], Bootstrap contributors [ctb] (Bootstrap\nlibrary), Twitter, Inc [cph], Brian Reavis [ctb, cph], Egor\nKhmelev [ctb, cph], SpryMedia Limited [ctb, cph].\n\nshinydashboard\n\nCreate Dashboards with shiny. Authors: Winston Chang [aut, cre],\nRStudio [cph], Almasaeed Studio [ctb, cph], Adobe Systems\nIncorporated [ctb, cph].\n\nshinyjs\n\nPerform Common JavaScript Operations in shiny Apps using Plain R\nCode. Author: Dean Attali [aut, cre].\n\nshinythemes\n\nThemes for shiny. Authors: Winston Chang [aut, cre], RStudio\n[cph], Thomas Park [ctb, cph], Lukasz Dziedzic [ctb, cph],\nNathan Willis [ctb, cph], Google Corporation [ctb, cph], Matt\nMcInerney [ctb, cph], Adobe Systems Incorporated [ctb, cph],\nCanonical Ltd [ctb, cph].\n\nshowtextdb\n\nFont Files for the showtex Package. Authors: Yixuan Qiu and\nauthors of the included fonts.\n\nsignmedian.test\n\nPerform Exact Sign Test and Asymptotic Sign Test in Large Samples.\nAuthors: Yeyun Yu and Ting Yang.\n\nsimcausal\n\nSimulating Longitudinal Data with Causal Inference Applications.\nAuthors: Oleg Sofrygin [aut, cre], Romain Neugebauer [aut].\n\nsimpleNeural\n\nAn Easy to Use Multilayer Perceptron. Authors: David Dernoncourt\n[aut, cre].\n\nsivipm\n\nSensitivity Indices with Dependent Inputs. Authors: A. Bouvier\n[aut], J.-P. Gauchi [aut, cre], E. Volatier [ctb].\n\nsjmisc\n\nMiscellaneous Data Management Tools. Author: Daniel Lüdecke.\n\nsmbinning\n\nOptimal Binning for Scoring Modeling. Author: Herman R. Jopia\nBonnet.\n\nsmcfcs\n\nMultiple Imputation of Covariates by Substantive Model Compatible\nFully Conditional Specification. Author: Jonathan Bartlett [aut,\ncre].\n\nsmds\n\nSymbolic Multidimensional Scaling. Authors: Yoshikazu Terada,\nPatrick J. F. Groenen.\n\nsmoof\n\nSingle and Multi-Objective Optimization Test Functions. Author:\nJakob Bossek [aut, cre].\n\nsolarius\n\nAn R Interface to SOLAR. Authors: Andrey Ziyatdinov [cre, aut],\nHelena Brunel [aut], Angel Martinez-Perez [aut], Alfonso Buil\n[aut], Alexandre Perera [cph], Jose Manuel Soria [cph].\n\nspTest\n\nNonparametric Hypothesis Tests of Isotropy and Symmetry. Author:\nZachary Weller [aut, cre].\n\nspatialEco\n\nSpatial Analysis and Modeling. Authors: Jeffrey S. Evans [aut,\ncre], Karthik Ram [ctb].\n\nspeaq\n\nTools for Nuclear Magnetic Resonance Spectrum Alignment and\nQuantitative Analysis. Authors: Trung Nghia Vu, Kris Laukens and\nDirk Valkenborg. In view:\nChemPhys.\n\nspgs\n\nStatistical Patterns in Genomic Sequences. Authors: Andrew Hart\n[aut, cre], Servet Martínez [aut], Universidad de Chile [cph],\nINRIA-Chile [cph].\n\nsprex\n\nCalculate Species Richness and Extrapolation Metrics. Author: Eric\nArcher.\n\nssfa\n\nSpatial Stochastic Frontier Analysis. Authors: Elisa Fusco,\nFrancesco Vidoli. In view:\nEconometrics.\n\nssizeRNA\n\nSample Size Calculation for RNA-Seq Experimental Design. Authors:\nRan Bi, Peng Liu.\n\nsspse\n\nEstimating Hidden Population Size using Respondent Driven Sampling\nData. Authors: Mark S. Handcock [aut, cre, cph], Krista J. Gile\n[aut, cph].\n\nstaTools\n\nStatistical Tools for Social Network Analysis. Author: Alessandro\nBessi.\n\nstackoverflow\n\nStack Overflow’s Greatest Hits. Authors: Neal Fultz and the\nStackOverflow.com community.\n\nstagePop\n\nModelling the Population Dynamics of a Stage-Structured Species in\nContinuous Time. Author: Helen Kettle.\n\nstcm\n\nTools for Inference with Set-Theoretic Comparative Methods. Author:\nChris Krogslund [aut, cre].\n\nstepR\n\nFitting Step Functions. Authors: Thomas Hotz [aut, cre], Hannes\nSieling [aut], Pein Florian [ctb].\n\nstheoreme\n\nKlimontovich’s S-Theorem Algorithm Implementation and Data\nPreparation Tools. Author: Vitaly Efremov.\n\nstmCorrViz\n\nA Tool for Structural Topic Model Visualizations. Authors: Antonio\nCoppola [aut, cre, cph], Margaret Roberts [ctb, cph], Brandon\nStewart [aut, cph], Dustin Tingley [ctb, ths, cph].\n\nstocks\n\nFast Functions for Stock Market Analysis. Author: Dane R. Van\nDomelen.\n\nsupcluster\n\nSupervised Cluster Analysis. Authors: David A. Schoenfeld, Jesse\nHsu.\n\nsurvRM2\n\nComparing Restricted Mean Survival Time. Authors: Hajime Uno, Lu\nTian, Angel Cronin, Chakib Battioui.\n\nsynRNASeqNet\n\nSynthetic RNA-Seq Network Generation and Mutual Information\nEstimates. Authors: Luciano Garofano, Stefano Maria Pagnotta,\nMichele Ceccarelli.\n\nsystemicrisk\n\nA Toolbox for Systemic Risk. Authors: Axel Gandy and Luitgard A.M.\nVeraart.\n\nsyuzhet\n\nExtracts Sentiment and Sentiment-Derived Plot Arcs from Text.\nAuthor: Matthew Jockers [aut, cre].\n\ntdr\n\nTarget Diagram. Author: Oscar Perpinan Lamigueiro [cre, aut].\n\ntexmexseq\n\nTreatment Effect eXplorer for Microbial Ecology eXperiments (using\nSequence Counts). Author: Scott Olesen.\n\nthreejs\n\nInteractive 3D Scatter Plots and Globes. Author: B. W. Lewis.\n\nthsls\n\nThree-Stage Least Squares Estimation for Systems of Simultaneous\nEquations. Author: Zaghdoudi Taha.\n\ntidyjson\n\nA Grammar for Turning JSON into Tidy Tables. Author: Jeremy Stanley.\n\ntimeSeq\n\nNonparallel Differential Expressed Genes. Authors: Fan Gao, Xiaoxiao\nSun.\n\ntimetree\n\nInterface to the TimeTree of Life Webpage. Author: Franz-Sebastian\nKrah.\n\ntoOrdinal\n\nFunction for Converting Cardinal to Ordinal Numbers by Adding a\nLanguage Specific Ordinal Indicator to the Number. Author: Damian W.\nBetebenner.\n\ntreeClust\n\nCluster Distances Through Trees. Author: Sam Buttrey.\n\ntreeperm\n\nExact and Asymptotic \\(K\\) Sample Permutation Test. Author: Qiao Kang.\n\ntrend\n\nNon-Parametric Trend Tests and Change-Point Detection. Author:\nThorsten Pohlert. In view:\nTimeSeries.\n\ntsallisqexp\n\nTsallis q-Exp Distribution. Authors: Cosma Shalizi [aut],\nChristophe Dutang [cre]. In view:\nDistributions.\n\ntscount\n\nAnalysis of Count Time Series. Authors: Tobias Liboschik [aut,\ncre], Roland Fried [aut], Konstantinos Fokianos [aut], Philipp\nProbst [aut], Jonathan Rathjens [ctb]. In view:\nTimeSeries.\n\nuniqtag\n\nAbbreviate Strings to Short, Unique Identifiers. Author: Shaun\nJackman [cre].\n\nvmsbase\n\nGUI Tools to Process, Analyze and Plot Fisheries Data. Authors:\nLorenzo D’Andrea, Tommaso Russo, Antonio Parisi, Stefano Cataudella.\n\nwaffle\n\nCreate Waffle Chart Visualizations in R. Author: Bob Rudis.\n\nwahc\n\nAutocorrelation and Heteroskedasticity Correction in Fixed Effect\nPanel Data Model. Author: Zaghdoudi Taha. In view:\nEconometrics.\n\nwebchem\n\nChemical Information from the Web. Author: Eduard Szoecs.\n\nwkb\n\nConvert Between Spatial Objects and Well-Known Binary Geometry.\nAuthor: TIBCO Software Inc. In view:\nSpatial.\n\nwmlf\n\nWavelet Leaders in Multifractal Analysis. Authors: Stephane Roux,\nFrancois Semecurbe, Cecile Tannier.\n\nx.ent\n\neXtraction of ENTity. Authors: Nicolas Turenne [aut], Tien T. Phan\n[aut, cre], John Resig [ctb, cph], Jeroen Ooms [ctb].\n\nxml2\n\nParse XML. Authors: Hadley Wickham [aut, cre], Jeroen Ooms\n[ctb], RStudio [cph], R Foundation [ctb].\n\nzooaRch\n\nAnalytical Tools for Zooarchaeological Data. Authors: Erik\nOtarola-Castillo, Jesse Wolfhagen, Max D. Price.\n\n2 Other changes\nThe following packages were moved to the Archive: AdapEnetClass,\nBAS, EMDomics, HTSDiff, MGLM, MsatAllele, NCBI2R, NRAIA,\nPRISMA, PenLNM, PoMoS, Rcell, RfmriVC, TR8, TSgetSymbol,\nTShistQuote, TSjson, TSxls, TSzip, UScensus2000blkgrp,\nVarEff, bamboo, bark, bcool, clusthaplo, convexHaz,\nepicalc, gemmR, ggHorizon, hypred, imputeYn, integrOmics,\njackknifeKME, jvmr, mfblock, miP, mobForest, muscle,\nnlrwr, npRmpi, opm, opmdata, papeR, parfm, pkgutils,\npowerr, pxweb, qp, qtlbim, rbiouml, rgrs, rsnps, rsprng,\nsaps, spectral.methods, toaster, trackObjs, visova,\nwikipediatrend, xgboost.\nThe following packages were resurrected from the Archive: ARTIVA,\nAncestryMapper, BLCOP, BOG, IFP, MortalitySmooth, RDS,\nRSocrata, Rdsdp, TAQMNGR, UBCRM, assist, bigml,\nblockTools, eco, emg, emplik2, faisalconjoint, fracprolif,\ngammSlice, glrt, hddtools, hgm, knncat, longclust,\nneuRosim, noia, orthogonalsplinebasis, pamctdp, ppiPre,\nppmlasso, protoclust, sra, ssize.fdr, survJamda,\nsurvJamda.data, tmg, treelet.\nThe following packages had to be removed: Rniftilib.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2015-1-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2015-1 issue.",
    "author": [
      {
        "name": "Bettina Grün",
        "url": {}
      }
    ],
    "date": "2015-06-01",
    "categories": [],
    "contents": "\n\nOn behalf of the editorial board, I am pleased to publish Volume 7,\nIssue 1 of the R Journal. This issue contains 16 contributed research\narticles. Each of them either presents an R package, a specific\nextension of an R package or applications using R packages available\nfrom the Comprehensive R Archive Network (CRAN,\nhttp://CRAN.R-project.org). It thus provides a small insight into the\nwide variety of functionality covered currently by the more than 6800\npackages available from CRAN.\nThe presented packages include packages for enhancing the graphics\nfunctionality of R such as package gridGraphics for converting\ngraphics drawn with the graphics package to grid graphics and\nshowtext for using system fonts in R graphics. Additional graphical\ntools are provided by package sparkTable, which allows to enhance\ntables, and by package fanplot, which allows to visualize the\nuncertainty connected with forecasts using fan charts. Further\ninfrastructure is implemented in package rstackdeque which provides\nefficient data structures for stacks and queues.\nSome of the presented packages provide specialized infrastructure which\nis valuable for certain areas of application or data situations such as\nthe Peptides package for antimicrobial peptides analysis, the\nFrames2 package for estimation in dual frame surveys, packages dpcr\nand qpcr for the analysis of data from digital and quantitative\npolymerase chain reaction experiments and package fslr which provides\na connection to the FSLR software commonly used to process and analyze\nneuroimaging data.\nSpecific statistical methods and models which might prove useful in\ndifferent areas of applications are provided by package rdrobust,\nwhich allows for robust nonparametric inference in\nregression-discontinuity designs, by package cmvnorm, which implements\na complex generalization of the mvtnorm package, by package sae,\nwhich complements other software available on CRAN for small area\nestimation, by package FactoMineR, which now also contains\nfunctionality for correspondence analysis on generalized aggregated\nlexical tables, by package cna, which performs coincidence analysis to\nidentify complex causal dependencies, and package estimability, which\nallows to determine if a certain prediction is possible in a\nrank-deficient regression. Furthermore package discreteRV provides\ninfrastructure to manipulate discrete random variables which is intended\nto help students in introductionary probability courses to understand\nthe theoretical concepts and thus adds to the other tools available in R\nfor teaching.\nIn addition the News and Notes section contains the usual updates on the\nR Foundation, the Bioconductor project, CRAN, and changes in R itself.\nI hope you enjoy the issue.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2015-1-r-changes/",
    "title": "Changes in R",
    "description": "The 'Changes in R' article from the 2015-1 issue.",
    "author": [
      {
        "name": "The R Core Team",
        "url": {}
      }
    ],
    "date": "2015-06-01",
    "categories": [],
    "contents": "\n\nCHANGES IN R 3.2.1\n\nNEW FEATURES\nutf8ToInt() now checks that its input is valid UTF-8 and returns\nNA if it is not.\ninstall.packages() now allows type = \"both\" with repos = NULL\nif it can infer the type of file.\nnchar(x, *) and nzchar(x) gain a new argument keepNA which\ngoverns how the result for NAs in x is determined. For the R\n3.2.x series, the default remains FALSE which is fully back\ncompatible. From R 3.3.0, the default will change to keepNA = NA\nand you are advised to consider this for code portability.\nnews() more flexibly extracts dates from package NEWS.Rd files.\nlengths(x) now also works (trivially) for atomic x and hence can\nbe used more generally as an efficient replacement of\nsapply(x, length) and similar.\nThe included version of PCRE has been updated to 8.37, a bug-fix\nrelease.\ndiag() no longer duplicates a matrix when extracting its diagonal.\nas.character.srcref() gains an argument to allow characters\ncorresponding to a range of source references to be extracted.\n\n\nBUG FIXES\nacf() and ccf() now guarantee values strictly in \\([-1,1]\\)\n(instead of sometimes very slightly outside).\nPR#15832.\nas.integer(\"111111111111\") now gives NA (with a warning) as it\ndoes for the corresponding numeric or negative number coercions.\nFurther, as.integer(M + 0.1) now gives M (instead of NA) when M\nis the maximal representable integer.\nOn some platforms nchar(x, \"c\") and nchar(x, \"w\") would return\nvalues (possibly NA) for inputs which were declared to be UTF-8\nbut were not, or for invalid strings without a marked encoding in a\nmulti-byte locale, rather than give an error. Additional checks have\nbeen added to mitigate this.\napply(a, M, function(u) c(X = ., Y = .)) again has dimnames\ncontaining \"X\" and \"Y\" (as in R < 3.2.0).\n(Windows only) In some cases, the –clean option to R CMD INSTALL\ncould fail.\n(PR#16178)\n(Windows only) choose.files() would occasionally include\ncharacters from the result of an earlier call in the result of a\nlater one.\n(PR#16270)\nA change in RSiteSearch() in R 3.2.0 caused it to submit invalid\nURLs.\n(PR#16329)\nRscript and command line R silently ignored incomplete\nstatements at the end of a script; now they are reported as parse\nerrors.\n(PR#16350)\nParse data for very long strings was not stored.\n(PR#16354)\nplotNode(), the workhorse of the plot method for \"dendrogram\"s\nis no longer recursive, thanks to Suharto Anggono, and hence also\nworks for deeply nested dendrograms.\n(PR#15215)\nThe parser could overflow internally when given numbers in\nscientific format with extremely large exponents.\n(PR#16358)\nIf the CRAN mirror was not set, install.packages(type = \"both\")\nand related functions could repeatedly query the user for it. (Part\nof\nPR#16362)\nThe low-level functions .rowSums() etc. did not check the length\nof their argument, so could segfault.\n(PR#16367)\nThe quietly argument of library() is now correctly propagated\nfrom .getRequiredPackages2().\nUnder some circumstances using the internal PCRE when building R\nfron source would cause external libs such as -llzma to be omitted\nfrom the main link.\nThe .Primitive default methods of the logic operators, i.e., !,\n& and |, now give correct error messages when appropriate, e.g.,\nfor ‘&‘(TRUE) or ‘!‘().\n(PR#16385)\ncummax(x) now correctly propagates NAs also when x is of type\ninteger and begins with an NA.\nsummaryRprof() could fail when the profile contained only two\nrecords.\n(PR#16395)\nHTML vignettes opened using vignette() did not support links into\nthe rest of the HTML help system. (Links worked properly when the\nvignette was opened using browseVignettes() or from within the\nhelp system.)\narima(*, xreg = .) (for \\(d \\ge 1\\)) computes estimated variances\nbased on a the number of effective observations as in R version\n3.0.1 and earlier.\n(PR#16278)\nslotNames(.) is now correct for \"signature\" objects (mostly used\ninternally in methods).\nOn some systems, the first string comparison after a locale change\nwould result in NA.\n\nCHANGES IN R 3.2.0\n\nNEW FEATURES\nanyNA() gains a recursive argument.\nWhen x is missing and names is not false (including the default\nvalue), Sys.getenv(x, names) returns an object of class \"Dlist\"\nand hence prints tidily.\n(Windows.) shell() no longer consults the environment variable\nSHELL: too many systems have been encountered where it was set\nincorrectly (usually to a path where software was compiled, not\nwhere it was installed). R_SHELL, the preferred way to select a\nnon-default shell, can be used instead.\nSome unusual arguments to embedFonts() can now be specified as\ncharacter vectors, and the defaults have been changed accordingly.\nFunctions in the Summary group duplicate less.\n(PR#15798)\n(Unix-alikes.) system(cmd, input = ) now uses\n‘shell-execution-environment’ redirection, which will be more\nnatural if cmd is not a single command (but requires a\nPOSIX-compliant shell). (Wish of\nPR#15508)\nread.fwf() and read.DIF() gain a fileEncoding argument, for\nconvenience.\nGraphics devices can add attributes to their description in\n.Device and .Devices. Several of those included with R use a\n\"filepath\" attribute.\npmatch() uses hashing in more cases and so is faster at the\nexpense of using more memory.\n(PR#15697)\npairs() gains new arguments to select sets of variables to be\nplotted against each other.\nfile.info(, extra_cols = FALSE) allows a minimal set of columns to\nbe computed on Unix-alikes: on some systems without\nproperly-configured caching this can be significantly faster with\nlarge file lists.\nNew function dir.exists() in package base to test efficiently\nwhether one or more paths exist and are directories.\ndput() and friends gain new controls hexNumeric and digits17\nwhich output double and complex quantities as, respectively, binary\nfractions (exactly, see sprintf(\"%a\")) and as decimals with up to\n17 significant digits.\nsave(), saveRDS() and serialize() now support ascii = NA\nwhich writes ASCII files using sprintf(\"%a\") for double/complex\nquantities. This is read-compatible with ascii = TRUE but avoids\nbinary->decimal->binary conversions with potential loss of\nprecision. Unfortunately the Windows C runtime’s lack of C99\ncompliance means that the format cannot be read correctly there in R\nbefore 3.1.2.\nThe default for formatC(decimal.mark =) has been changed to be\ngetOption(\"OutDec\"); this makes it more consistent with format()\nand suitable for use in print methods, e.g. those for classes\n\"density\", \"ecdf\", \"stepfun\" and \"summary.lm\".\ngetOption(\"OutDec\") is now consulted by the print method for class\n\"kmeans\", by cut(), dendrogram(), plot.ts() and quantile()\nwhen constructing labels and for the report from\nlegend(trace = TRUE).\n(In part, wish of\nPR#15819.)\nprintNum() and hence format() and formatC() give a warning if\nbig.mark and decimal.mark are set to the same value (period and\ncomma are not uncommonly used for each, and this is a check that\nconventions have not got mixed).\nmerge() can create a result which uses long vectors on 64-bit\nplatforms.\ndget() gains a new argument keep.source which defaults to\nFALSE for speed (dput() and dget() are most often used for\ndata objects where this can make dget() many times faster).\nPackages may now use a file of common macro definitions in their\nhelp files, and may import definitions from other packages.\nA number of macros have been added in the new share/Rd directory\nfor use in package overview help pages, and promptPackage() now\nmakes use of them.\ntools::parse_Rd() gains a new permissive argument which converts\nunrecognized macros into text. This is used by\nutils:::format.bibentry to allow LaTeX markup to be ignored.\noptions(OutDec =) can now specify a multi-byte character, e.g.,\noptions(OutDec = \"\\\\u00b7\") in a UTF-8 locale.\nis.recursive(x) is no longer true when x is an external pointer,\na weak reference or byte code; the first enables all.equal(x, x)\nwhen x <- getClass(.).\nls() (aka objects()) and as.list.environment() gain a new\nargument sorted.\nThe \"source\" attribute (which has not been added to functions by R\nsince before R version 2.14.0) is no longer treated as special.\nFunction returnValue() has been added to give on.exit() code\naccess to a function’s return value for debugging purposes.\ncrossprod(x, y) allows more matrix coercions when x or y are\nvectors, now equalling t(x) %*% y in these cases (also reported by\nRadford Neal). Similarly, tcrossprod(x,y) and %*% work in more\ncases with vector arguments.\nUtility function dynGet() useful for detecting cycles, aka\ninfinite recursions.\nThe byte-code compiler and interpreter include new instructions that\nallow many scalar subsetting and assignment and scalar arithmetic\noperations to be handled more efficiently. This can result in\nsignificant performance improvements in scalar numerical code.\napply(m, 2, identity) is now the same as the matrix m when it\nhas named row names.\nA new function debuggingState() has been added, allowing to\ntemporarily turn off debugging.\nexample() gets a new optional argument run.donttest and\ntools::Rd2ex() a corresponding commentDonttest, with a default\nsuch that example(..) in help examples will run \\\\donttest code\nonly if used interactively (a change in behaviour).\nrbind.data.frame() gains an optional argument make.row.names,\nfor potential speedup.\nNew function extSoftVersion() to report on the versions of\nthird-party software in use in this session. Currently reports\nversions of zlib, bzlib, the liblzma from xz, PCRE, ICU, TRE\nand the iconv implementation.\nA similar function grSoftVersion() in package grDevices reports\non third-party graphics software.\nFunction tcltk::tclVersion() reports the Tcl/Tk version.\nCalling callGeneric() without arguments now works with primitive\ngenerics to some extent.\nvapply(x, FUN, FUN.VALUE) is more efficient notably for large\nlength(FUN.VALUE); as extension of\nPR#16061.\nas.table() now allows tables with one or more dimensions of length\n0 (such as as.table(integer())).\nnames(x) <- NULL now clears the names of call and ... objects.\nlibrary() will report a warning when an insufficient dependency\nversion is masking a sufficient one later on the library search\npath.\nA new plot() method for class \"raster\" has been added.\nNew check_packages_in_dir_changes() function in package tools\nfor conveniently analyzing how changing sources impacts the check\nresults of their reverse dependencies.\nSpeed-up from Peter Haverty for ls() and\nmethods:::.requirePackage() speeding up package loading.\n(PR#16133)\nNew get0() function, combining exists() and get() in one call,\nfor efficiency.\nmatch.call() gains an envir argument for specifying the\nenvironment from which to retrieve the ... in the call, if any;\nthis environment was wrong (or at least undesirable) when the\ndefinition argument was a function.\ntopenv() has been made .Internal() for speedup, based on Peter\nHaverty’s proposal in\nPR#16140.\ngetOption() no longer calls options() in the main case.\nOptional use of libcurl (version 7.28.0 from Oct 2012 or later)\nfor Internet access:\ncapabilities(\"libcurl\") reports if this is available.\nlibcurlVersion() reports the version in use, and other details\nof the \"libcurl\" build including which URL schemes it\nsupports.\ncurlGetHeaders() retrieves the headers for http://,\nhttps://, ftp:// and ftps:// URLs: analysis of these\nheaders can provide insights into the ‘existence’ of a URL (it\nmight for example be permanently redirected) and is so used in\nR CMD check –as-cran.\ndownload.file() has a new optional method \"libcurl\" which\nwill handle more URL schemes, follow redirections, and allows\nsimultaneous downloads of multiple URLs.\nurl() has a new method \"libcurl\" which handles more URL\nschemes and follows redirections. The default method is\ncontrolled by a new option url.method, which applies also to\nthe opening of URLs via file() (which happens implicitly in\nfunctions such as read.table.)\nWhen file() or url() is invoked with a https:// or\nftps:// URL which the current method cannot handle, it\nswitches to a suitable method if one is available.\n\n(Windows.) The DLLs internet.dll and internet2.dll have been\nmerged. In this version it is safe to switch (repeatedly) between\nthe internal and Windows internet functions within an R session.\nThe Windows internet functions are still selected by flag\n–internet2 or setInternet2(). This can be overridden for an\nurl() connection via its new method argument.\ndownload.file() has new method \"wininet\", selected as the\ndefault by –internet2 or setInternet2().\nparent.env<- can no longer modify the parent of a locked namespace\nor namespace imports environment. Contributed by Karl Millar.\nNew function isNamespaceLoaded() for readability and speed.\nnames(env) now returns all the object names of an environment\nenv, equivalently to ls(env, all.names = TRUE, sorted = FALSE)\nand also to the names of the corresponding list,\nnames(as.list(env, all.names = TRUE)). Note that although\nnames() returns a character vector, the names have no particular\nordering.\nThe memory manager now grows the heap more aggressively. This\nreduces the number of garbage collections, in particular while data\nor code are loaded, at the expense of slightly increasing the memory\nfootprint.\nNew function trimws() for removing leading/trailing whitespace.\ncbind() and rbind() now consider S4 inheritance during S3\ndispatch and also obey deparse.level.\ncbind() and rbind() will delegate recursively to\nmethods::cbind2 (methods::rbind2) when at least one argument is\nan S4 object and S3 dispatch fails (due to ambiguity).\n(Windows.) download.file(quiet = FALSE) now uses text rather than\nWindows progress bars in non-interactive use.\nNew function hsearch_db() in package utils for building and\nretrieving the help search database used by help.search(), along\nwith functions for inspecting the concepts and keywords in the help\nsearch database.\nNew function .getNamespaceInfo(), a no-check version of\ngetNamespaceInfo() mostly for internal speedups.\nThe help search system now takes \\\\keyword entries in Rd files\nwhich are not standard keywords (as given in KEYWORDS in the R\ndocumentation directory) as concepts. For standard keyword entries\nthe corresponding descriptions are additionally taken as concepts.\nNew lengths() function for getting the lengths of all elements in\na list.\nNew function toTitleCase() in package tools, tailored to package\ntitles.\nThe matrix methods of cbind() and rbind() allow matrices as\ninputs which have \\(2^{31}\\) or more elements. (For cbind(), wish of\nPR#16198.)\nThe default method of image() has an explicit check for a numeric\nor logical matrix (which was always required).\nURLencode() will not by default encode further URLs which appear\nto be already encoded.\nBIC(mod) and BIC(mod, mod2) now give non-NA numbers for\narima() fitted models, as nobs(mod) now gives the number of\n“used” observations for such models. This fixes\nPR#16198,\nquite differently than proposed there.\nThe print() methods for \"htest\", \"pairwise.htest\" and\n\"power.htest\" objects now have a digits argument defaulting to\n(a function of) getOption(\"digits\"), and influencing all printed\nnumbers coherently. Unavoidably, this changes the display of such\ntest results in some cases.\nCode completion for namespaces now recognizes all loaded namespaces,\nrather than only the ones that are also attached.\nThe code completion mechanism can now be replaced by a\nuser-specified completer function, for (temporary) situations where\nthe usual code completion is inappropriate.\nunzip() will now warn if it is able to detect truncation when\nunpacking a file of 4GB or more (related to\nPR#16243).\nmethods() reports S4 in addition to S3 methods; output is\nsimplified when the class argument is used. .S3methods() and\nmethods::.S4methods() report S3 and S4 methods separately.\nHigher order functions such as the apply functions and Reduce()\nnow force arguments to the functions they apply in order to\neliminate undesirable interactions between lazy evaluation and\nvariable capture in closures. This resolves\nPR#16093.\n\n\nINSTALLATION and INCLUDED SOFTWARE\nThe \\\\donttest sections of R’s help files can be tested bymake check TEST_DONTTEST=TRUE .\nIt is possible to request the use of system valgrind headers via\nconfigure option –with-system-valgrind-headers: note the\npossible future incompatibility of such headers discussed in the ‘R\nInstallation and Administration’ manual. (Wish of\nPR#16068.)\nThe included version of liblzma has been updated to xz-utils\n5.0.7 (minor bug fixes from 5.0.5).\nconfigure options –with-system-zlib, –with-system-bzlib and\n–with-system-pcre are now the default. For the time being there is\nfallback to the versions included in the R sources if no system\nversions are found or (unlikely) if they are too old.\nLinux users should check that the -devel or -dev versions of\npackages zlib, bzip2/libbz2 and pcre as well as\nxz-devel/liblzma-dev (or similar names) are installed.\nconfigure by default looks for the texi2any script from\ntexinfo 5.1 or later, rather than the makeinfo program.\n(makeinfo is a link to the Perl script texi2any in texinfo\n5.x.)\nR CMD INSTALL gains an option –built-timestamp=STAMP allowing\n100% reproducible package building, thanks to Dirk Eddelbuettel.\n\n\nUTILITIES\nThere is support for testing the \\\\dontrun and \\\\donttest parts\nof examples in packages.\ntools::testInstalledPackage() accepts new arguments\ncommentDontrun = FALSE and commentDonttest = FALSE.\nR CMD check gains options –run-dontrun and –run-donttest.\nThe HTML generated by tools::Rd2HTML() and tools::toHTML()\nmethods is now ‘XHTML 1.0 Strict’.\nThe compiler package’s utility function setCompilerOptions() now\nreturns the old values invisibly. The initial optimization level can\nalso be set with the environment variable R_COMPILER_OPTIMIZE.\nR CMD build adds a NeedsCompilation field if one is not already\npresent in the DESCRIPTION file.\nR CMD check gains option –test-dir to specify an alternative set\nof tests to run.\nR CMD check will now by default continue with testing after many\ntypes of errors, and will output a summary count of errors at the\nend if any have occurred.\nR CMD check now checks that the Title and Description fields\nare correctly terminated.\nR CMD check –as-cran now:\nchecks a README.md file can be processed: this needs pandoc\ninstalled.\nchecks the existence and accessibility of URLs in the\nDESCRIPTION, CITATION, NEWS.Rd and README.md files and\nin the help files (provided the build has libcurl support).\nreports non-ASCII characters in R source files when there is no\npackage encoding declared in the DESCRIPTION file.\nreports (apparent) S3 methods exported but not registered.\nreports overwriting registered S3 methods from base/recommended\npackages. (Such methods are replaced in the affected package for\nthe rest of the session, even if the replacing namespace is\nunloaded.)\nreports if the Title field does not appear to be in title case\n(see ‘Writing R Extensions’: there may be false positives, but\nnote that technical words should be single-quoted and will then\nbe accepted).\nMost of these checks can also be selected by environment variables:\nsee the ‘R Internals’ manual.\n\n\nC-LEVEL FACILITIES\nNew C API utility logspace_sum(logx[], n).\nEntry points rbinom_mu, rnbinom_mu and rmultinom are remapped\n(by default) to Rf_rbinom_mu etc. This requires packages using\nthem to be re-installed.\n.C(DUP = FALSE) and .Fortran(DUP = FALSE) are now ignored, so\narguments are duplicated if DUP = TRUE would do so. As their help\nhas long said, .Call() is much preferred.\nNew entry point R_allocLD, like R_alloc but guaranteed to have\nsufficient alignment for long double pointers.\nisPairList() now returns TRUE for DOTSXP.\n\n\nWINDOWS BUILD CHANGES A number of changes to the Windows build system\nare in development. The following are currently in place.\nInstallation using external binary distributions of zlib, bzip2,\nliblzma, pcre, libpng, jpeglib and libtiff is now\nrequired, and the build instructions have been revised.\nA new make target rsync-extsoft has been added to obtain copies\nof the external libraries from CRAN.\nBuilding the manuals now requires texi2any from texinfo 5.1 or\nlater. CRAN binary builds include the manuals, but by default builds\nfrom source will not, and they will be accessed from CRAN. See the\ncomments in src/gnuwin32/MkRules.dist for how to specify the\nlocation of texi2any.\n(Windows) Changes have been made to support an experimental Windows\ntoolchain based on GCC 4.9.2. The default toolchain continues to be\nbased on GCC 4.6.3, as the new toolchain is not yet stable enough. A\nchange to a new toolchain is expected during the R 3.2.x lifetime.\n\n\nPACKAGE INSTALLATION\n(Windows) The use of macro ZLIB_LIBS in file src/Makevars.win\n(which has not been documented for a long time) now requires an\nexternal libz.a to be available (it is part of the ‘goodies’ used\nto compile Windows binary packages). It would be simpler to use\n-lz instead.\nThe default for option pkgType on platforms using binary packages\nis now \"both\", so source packages will be tried if binary versions\nare not available or not up to date.\nThere are options for what install.packages(type = \"both\")\n(possibly called via update.packages()) will do if compilation\nof a source package is desirable: see ?options (under utils).\nIf you intend not to accept updates as source packages, you should\nuse update.packages(type = \"binary\").\n\n\nDEPRECATED AND DEFUNCT\ndownload.file(method = \"lynx\") is defunct.\nBuilding R using the included versions of zlib, bzip2, xz and\nPCRE is deprecated: these are frozen (bar essential bug-fixes) and\nwill be removed for R 3.3.0.\nThe configure option –with-valgrind-instrumentation=3 has been\nwithdrawn, as it did not work with recent valgrind headers: it is\nnow treated as level 2.\nThe MethodsList class in package methods had been deprecated in\nR 2.11.0 and is defunct now. Functions using it are defunct if they\nhad been deprecated in R 2.11.0, and are deprecated now, otherwise.\n\n\nBUG FIXES\nFixed two obscure bugs in pairlist subassignment, reported by\nRadford Neal as part of pqR issue 16.\nFixes for bugs in handling empty arguments and argument matching by\nname in log().\nall.equal() gains methods for environments and refClasses.\n[<- and [[<- gain S4 data.frame methods to avoid corruption of\nS4 class information by the S3 methods.\ncallNextMethod() should now work within a .local call when ...\nis absent from formals(.local).\ndput(pairlist(x)) generates a call to the pairlist constructor\ninstead of the list constructor.\nFix missing() when arguments are propagated through ... .\n(PR#15707)\neigen(m) now defaults to symmetric = TRUE even when the dimnames\nare asymmetric if the matrix is otherwise symmetric.\n(PR#16151)\nFix issues with forwarding ... through callGeneric() and\ncallNextMethod().\n(PR#16141)\ncallGeneric() now works after a callNextMethod().\nSubclass information is kept consistent when replacing an ordinary\nS4 class with an “old class” via the S4Class argument to\nsetOldClass(). Thus, for example, a data.frame is valid for a\nlist argument in the signature, and a factor is valid for\nvector arguments.\nIn qbeta() the inversion of pbeta() is much more sophisticated.\nThis works better in corner cases some of which failed completely\npreviously\n(PR#15755),\nor were using too many iterations.\nAuto-printing no longer duplicates objects when printing is\ndispatched to a method.\nkmeans(x, k) would fail when nrow(x) >= 42949673. (Comment 6 of\nPR#15364)\n‘Abbreviated’ locale-specific day and month names could have been\ntruncated in those rare locales where there are the same as the full\nnames.\nAn irrelevant warning message from updating subclass information was\nsilenced (the namespace would not be writable in this case).\n\nCHANGES IN R 3.1.3\n\nNEW FEATURES\nThe internal method of download.file() can now handle files larger\nthan 2GB on 32-bit builds which support such files (tested on 32-bit\nR running on 64-bit Windows).\nkruskal.test() warns on more types of suspicious input.\nThe as.dendrogram() method for \"hclust\" objects gains a check\nargument protecting against memory explosion for invalid inputs.\ncapabilities() has a new item long.double which indicates if the\nbuild uses a long double type which is longer than double.\nnlm() no longer modifies the callback argument in place (a new\nvector is allocated for each invocation, which mimics the implicit\nduplication that occurred in R < 3.1.0); note that this is a change\nfrom the previously documented behavior.\n(PR#15958)\nicuSetCollate() now accepts locale = \"ASCII\" which uses the\nbasic C function strcmp and so collates strings byte-by-byte in\nnumerical order.\nsessionInfo() tries to report the OS version in use (not just that\ncompiled under, and including details of Linux distributions).\nmodel.frame() (used by lm() and many other modelling functions)\nnow warns when it drops contrasts from factors. (Wish of\nPR#16119)\ninstall.packages() and friends now accept the value\ntype = \"binary\" as a synonym for the native binary type on the\nplatform (if it has one).\nSingle source or binary files can be supplied for\ninstall.packages(type = \"both\") and the appropriate type and\nrepos = NULL will be inferred.\nNew function pcre_config() to report on some of the configuration\noptions of the version of PCRE in use. In particular, this reports\nif regular expressions using \\\\p{xx} are supported.\n(Windows.) download.file(cacheOK = FALSE) is now supported when\ninternet2.dll is used.\nbrowseURL() has been updated to work with Firefox 36.0 which has\ndropped support for the -remote interface.\n\n\nINSTALLATION and INCLUDED SOFTWARE\nThe included version of PCRE has been updated to 8.36.\nconfigure accepts MAKEINFO=texi2any as another way to ensure\ntexinfo 5.x is used when both 5.x and 4.x are installed.\n\n\nUTILITIES\nR CMD check now checks the packages used in \\\\donttest sections\nof the examples are specified in the DESCRIPTION file. (These are\nneeded to run the examples interactively.)\nR CMD check checks for the undeclared use of GNU extensions in\nMakefiles, and for Makefiles with a missing final linefeed.\nR CMD build will correct line endings in all Makefiles, not just\nthose in the src directory.\nR CMD check notes uses of library() and require() in package\ncode: see the section ‘Suggested packages’ of ‘Writing R Extensions’\nfor good practice.\n\n\nDEPRECATED AND DEFUNCT\nThe configure option –with-valgrind-instrumentation=3 is\ndeprecated and will be removed in R 3.2.0.\n\n\nBUG FIXES\n(Windows.) Rscript.exe was missing a manifest specifying the\nmodern style for common controls (e.g., the download progress bar).\nIf a package had extra documentation files but no vignette, the HTML\nhelp system produced an empty index page.\nThe parser now gives an error if a null character is included in a\nstring using Unicode escapes.\n(PR#16046)\nqr.Q() failed on complex arguments due to pre-3.0(!) typo.\n(PR#16054)\nabs() failed with named arguments when the argument was complex.\n(PR#16047)\n\"noquote\" objects may now be used as columns in dataframes.\n(PR#15997)\nSome values with extremely long names were printed incorrectly.\n(PR#15999)\nExtremely large exponents on zero expressed in scientific notation\n(e.g. 0.0e50000) could give NaN.\n(PR#15976)\ndownload.file() reported downloaded sizes as 0KB if less than 1MB,\nonly for R 3.1.2 and only on big-endian platforms.\nprompt() did not escape percent signs in the automatically\ngenerated usage section of help files.\ndrop.terms() dropped some of the attributes of the object it was\nworking with.\n(PR#16029)\n(Windows.) The command completion in Rgui.exe messed up the\nconsole.\n(PR#15791)\n(Windows.) The choose.files() command returned a blank string when\nthe user asked for a single file but cancelled the request.\n(PR#16074)\nMath2 S4 group generics failed to correctly dispatch\n\"structure\"- and \"nonStructure\"-derived classes.\nloadNamespace() imposed undocumented restrictions on the\nversionCheck parameter. (Reported by Geoff Lee.)\nRare over-runs detected by AddressSanitizer in substr() and its\nreplacement version have been avoided.\nInter alia that fix gives the documented behaviour for\nsubstr(x, 1, 2) <- \"\" (subsequently reported as\nPR#16214).\nLoading packages incorrectly defining an S4 generic followed by a\nfunction of the same name caused an erroneous cyclic namespace\ndependency error.\nDeclared vignette encodings are now always passed to the vignette\nengine.\nPort Tomas Kalibera’s fix from R-devel that restores the\nloadMethod() fast path, effectively doubling the speed of S4\ndispatch.\npower.t.test() and power.prop.test() now make use of the\nextendInt option of uniroot() and hence work in more extreme\ncases.\n(PR#15792)\nIf a package was updated and attached when its namespace was already\nloaded, it could end up with parts from one version and parts from\nthe other.\n(PR#16120)\ntools:::.Rdconv() didn’t accept –encoding= due to a typo.\n(PR#16121)\nUnix-alike builds without a suitable makeinfo were documented to\nlink the missing HTML manuals to CRAN, but did not.\nsave(*, ascii=TRUE) and load() now correctly deal with NaN’s.\n(PR#16137)\nsplit.Date() retains fractional representations while avoiding\nincomplete class propagation.\nR_ext/Lapack.h had not been updated for changes made by LAPACK to\nthe argument lists of its (largely internal) functions dlaed2 and\ndlaed3.\n(PR#16157)\nRShowDoc(\"NEWS\", \"txt\") had not been updated for the layout\nchanges of R 3.1.0.\nThe xtfrm() method for class \"Surv\" has been corrected and its\ndescription expanded.\nmode(x) <- y would incorrectly evaluate x before changing its\nmode.\n(PR#16215)\nbesselJ(1, 2^64) and besselY(..) now signal a warning, returning\nNaN instead of typically segfaulting. (Issue 3 of\nPR#15554)\nHTML conversion of \\\\href markup in .Rd files did not remove the\nbackslash from \\\\% and so gave an invalid URL. In a related\nchange, the \\\\ escape is now required in such URLs.\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2015-1-r-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2015-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2015-06-01",
    "categories": [],
    "contents": "\n1 Donations and new members\nDonations\nKevin Tappe (Germany)\nHrishikesh D. Vinod (USA)\nNew supporting institutions\nDepartment of Mathematical Sciences, Aalborg University, Denmark\nNew supporting members\nMichael Blanks (USA)\nBernhard Brabec (Germany)\nJay Emerson (USA)\nMatthias Haeni (Switzerland)\nJesse Krijthe (Netherlands)\nHans Mielke (Germany)\nHannes Mühleisen (Netherlands)\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2014-2-bioconductor/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2014-2 issue.",
    "author": [
      {
        "name": "The Bioconductor Team",
        "url": {}
      }
    ],
    "date": "2014-12-01",
    "categories": [],
    "contents": "\n\nThe Bioconductor project provides tools for the analysis and\ncomprehension of high-throughput genomic data. The 934 software packages\navailable in Bioconductor can be viewed at\nhttp://bioconductor.org/packages/release/. Navigate packages using\n‘biocViews’ terms and title search. Each package has an html page with a\ndescription, links to vignettes, reference manuals, and usage\nstatistics. Start using Bioconductor and R version 3.1 with\n  source(\"http://bioconductor.org/biocLite.R\")\n  biocLite()\nInstall additional packages and dependencies, e.g.,\nGenomicAlignments,\nwith\n  source(\"http://bioconductor.org/biocLite.R\")\n  biocLite(\"GenomicAlignments\")\nUpgrade installed packages with\n  source(\"http://bioconductor.org/biocLite.R\")\n  biocLite()\n1 Bioconductor 3.0 Release Highlights\nBioconductor 3.0 was released on 14 October 2014. It is compatible with\nR 3.1 and consists of 934 software packages, 219 experiment data\npackages, and more than 870 current annotation packages. In total, the\nrelease includes 114 new software packages and many updates and\nimprovements to existing packages. The release\nannouncement includes\ndescriptions of new packages and updated NEWS files provided by package\nmaintainers.\nThe variety of research areas represented by Bioconductor packages are\norganized (and searched) via the\nbiocViews\ninterface. Here we highlight a few topics covered by the new packages.\nMethods for differential expression analyses are offered in\nballgown\n(assembled transcriptomes),\nderfinder\n(RNA-seq data at base-pair resolution) and\ncsaw\n(differentially bound regions in ChIP-seq data). Quantitative trait loci\n(QTL) analysis for 1H NMR data are provided in\nmQTL.NMR;\nDOQTL\nanalyzes QTLs in multi-parent outbred populations. Copy number analysis\nin tumoral phenotypes and genomic focal aberrations are available in\nfacopy\nand\nfocalCall,\nrespectively. Additions to the flow cytometry family include\nflowcatchR\nwith tools for analyzing in vivo microscopy imaging data of flowing\nblood cells,\nflowCHIC\nfor analyzing flow data of microbial communities based on histogram\nimages and\nflowDensity\nwhich provides tools for automated sequential gating (analogous to\nmanual gating) based on data density. Several new packages take the\npipeline approach and facilitate steps from raw data to final analysis:\ngroHMM\n(GRO-seq data),\nFourCSeq\n(multiplexed 4C sequencing data), and\nsystemPipeR\n(NGS applications such as RNA-Seq, ChIP-Seq, VAR-Seq).\nBioconductor is built on the mature and flexible ‘Ranges’ infrastructure\ndefined in packages such as\nIRanges,\nGenomicRanges,\nGenomicAlignments,\nand\nGenomicFeatures.\nMany packages rely on the Ranges framework for interoperable, re-usable\nanalysis; (Lawrence 2013) provide an introduction and\n(Lawrence 2014) review strategies for processing, summarizing and\nvisualizing large genomic data.\nOur collection of microarray, transcriptome and organism-specific\nannotation packages use the ‘select’ interface (keys, columns,\nkeytypes) which enable programmatic access to the databases they\ncontain. The\nAnnotationHub\ncomplements our traditional offerings with diverse whole genome\nannotations from Ensembl, ENCODE, dbSNP, UCSC, and elsewhere.\n2 Other activities\nBioconductor offers an Amazon Machine\nImage\noptimized for running Bioconductor in the Amazon Elastic Compute Cloud\n(EC2). The AMI comes pre-loaded with the latest release version of R,\nand a subset of Bioconductor packages. The AMI can be customized by\ninstalling R packages with ‘biocLite()’ or system-level packages with\nthe Ubuntu package manager ‘apt-get’. Files can be transferred to the\nEC2 instance via scp or the Rstudio interface.\nA recent addition is our collection of Bioconductor Docker\nImages. These self-contained\nenvironments run on Linux, Windows and Mac as well as virtual machines.\nThe containers provide convenient access to a ‘fresh R session’ or\nspecific version of Bioconductor without the overhead of installing\npackages and dependencies. Analysis-specific images come pre-loaded with\npackages of a common topic such as flow, proteomics, microarray and\nsequencing.\nNew Bioconductor package contributors are encouraged to consult the\npackage\nguidelines and\nPackage\nSubmission\nsections of the Bioconductor web site, and use the new\nBiocCheck\npackage, in addition to R CMD check, for guidance on conforming to\nBioconductor package standards.\nThe Bioconductor web site advertises training and community\nevents; mailing\nlists connect users with\neach other, to domain experts, and to maintainers eager to ensure that\ntheir packages satisfy the needs of leading edge approaches. Keep\nabreast of packages added to the ‘devel’ branch and other activities by\nfollowing @Bioconductor on Twitter.\n\n\nBioconductor packages used\nGenomicAlignments, ballgown, derfinder, csaw, mQTL.NMR, DOQTL, facopy, focalCall, flowcatchR, flowCHIC, flowDensity, groHMM, FourCSeq, systemPipeR, IRanges, GenomicRanges, GenomicFeatures, AnnotationHub, BiocCheck\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\nM. Lawrence Michael AND Morgan. Scalable genomics with R and Bioconductor. Statistical Science, 29: 214–226, 2014. URL http://arxiv.org/abs/1409.2864.\n\n\nW. A. P. Lawrence Michael AND Huber. Software for computing and annotating genomic ranges. PLoS Comput Biol, 9(8): e1003118, 2013. URL http://dx.doi.org/10.1371\\%2Fjournal.pcbi.1003118.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2014-2-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2014-2 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2014-12-01",
    "categories": [],
    "contents": "\n\nNew packages in CRAN task views\nBayesian\n\nBayesTree.\n\nCluster\n\nfclust, funFEM, funHDDC, pgmm, tclust.\n\nDistributions\n\nFatTailsR, RTDE, STAR, predfinitepop, statmod.\n\nEconometrics\n\nLinRegInteractive, MSBVAR, nonnest2, phtt.\n\nEnvironmetrics\n\nsiplab.\n\nFinance\n\nGCPM, MSBVAR, OptionPricing, financial, fractal,\nriskSimul.\n\nHighPerformanceComputing\n\nGUIProfiler, PGICA, aprof.\n\nMachineLearning\n\nBayesTree, LogicForest, hdi, mlr, randomForestSRC,\nstabs, vcrpart.\n\nMetaAnalysis\n\nMAVIS, ecoreg, ipdmeta, metaplus.\n\nNumericalMathematics\n\nRootsExtremaInflections, Rserve, SimplicialCubature,\nfastGHQuad, optR.\n\nOfficialStatistics\n\nCoImp, RecordLinkage, rworldmap, tmap, vardpoor.\n\nOptimization\n\nRCEIM, blowtorch, globalOptTests, irace, isotone, lbfgs.\n\nPhylogenetics\n\nBAMMtools, BoSSA, DiscML, HyPhy, MPSEM, OutbreakTools,\nPBD, PCPS, PHYLOGR, RADami, RNeXML, Reol, Rphylip,\nadhoc, betapart, dendextend, expands, expoTree, jaatha,\nkdetrees, mvMORPH, outbreaker, pastis, pegas, phyloTop,\nphyloland, rdryad, rphast, strap, surface, taxize.\n\nPsychometrics\n\nIRTShiny, PP, WrightMap, mirtCAT, pairwise.\n\nReproducibleResearch\n\nNMOF.\n\nRobust\n\nTEEReg, WRS2, robeth, robustDA, robustgam,\nrobustloggamma, robustreg, ror, rorutadis.\n\nSpatial\n\nPReMiuM.\n\nSpatioTemporal\n\nBayesianAnimalTracker, TrackReconstruction, fishmove, mkde,\nwildlifeDI.\n\nSurvival\n\nDStree, ICsurv, IDPSurvival, MIICD, MST, MicSim,\nPHeval, PReMiuM, aftgee, bshazard, bujar, coxinterval,\ngamboostMSM, imputeYn, invGauss, lsmeans, multipleNCC,\npaf, penMSM, spBayesSurv, survAccuracyMeasures,\nsurvivalMPL, vitality.\n\nTimeSeries\n\nGMDH, gets, orderedLasso, yuima.\n\nWebTechnologies\n\nBerlinData, EIAdata, IBrokers, ONETr, RCryptsy,\nRDataCanvas, RGA, RGoogleAnalytics, RJSDMX, RPublica,\nRPushbullet, RSelenium, RStars, SocialMediaMineR, TR8,\nTaxonstand, W3CMarkupValidator, WikipediR, aRxiv,\nboilerpipeR, colourlovers, curl, d3Network, dataRetrieval,\ndownloader, ecoretriever, enigma, federalregister, ggvis,\ngmailr, indicoio, jSonarR, leafletR, magrittr, mailR,\nmarmap, meteoForecast, paleobioDB, polidata, pollstR,\npushoverr, pvsR, pxweb, rClinicalCodes, rFDSN, rNOMADS,\nrWBclimate, rYoutheria, rainfreq, rbitcoinchartsapi,\nrclinicaltrials, recalls, redcapAPI, reutils, rnbn,\nrnrfa, ropensecretsapi, rsdmx, rsunlight, shopifyr,\nslackr, sorvi, translateR, tumblR, ustyc, webutils,\nwhisker, wikipediatrend.\n\n1 New contributed packages\nADDT\n\nAnalysis of Accelerated Destructive Degradation Test Data. Authors:\nYili Hong, Yimeng Xie, and Caleb King.\n\nARTool\n\nAligned Rank Transform. Authors: Matthew Kay [aut, cre], Jacob O.\nWobbrock [aut].\n\nASMap\n\nLinkage map construction using the MSTmap algorithm. Authors: Julian\nTaylor, David Butler.\n\nASPBay\n\nBayesian Inference on Causal Genetic Variants using Affected\nSib-Pairs Data. Author: Claire Dandine-Roulland.\n\nBANFF\n\nBayesian Network Feature Finder. Authors: Zhou Lan, Yize Zhao, Jian\nKang, Tianwei Yu.\n\nBAT\n\nBiodiversity Assessment Tools. Authors: Pedro Cardoso, Francois\nRigal, Jose Carlos Carvalho.\n\nBBEST\n\nBayesian Estimation of Incoherent Neutron Scattering Backgrounds.\nAuthors: Anton Gagin and Igor Levin with contributions from\nCharles R. Hogg III.\n\nBEANSP\n\nBayesian Estimate of Age-specific Nest Survival Probabilities.\nAuthors: Chong He, Yiqun Yang, Jing Cao.\n\nBHMSMAfMRI\n\nBayesian hierarchical multi-subject multiscale analysis of\nfunctional MRI data. Authors: Nilotpal Sanyal [aut, cre], Marco\nA.R. Ferreira [aut].\n\nBIOM.utils\n\nUtilities for the BIOM (Biological Observation Matrix) Format.\nAuthor: Daniel T. Braithwaite [aut, cre].\n\nBNDataGenerator\n\nData Generator based on Bayesian Network Model. Author: Jae-seong\nYoo.\n\nBNSP\n\nBayesian Non- and Semi-parametric Model Fitting. Author: Georgios\nPapageorgiou.\n\nBOIN\n\nBayesian Optimal Interval Design for Phase I Clinical Trials.\nAuthors: Ying Yuan and Suyu Liu.\n\nBSGW\n\nBayesian Survival Model using Generalized Weibull Regression.\nAuthors: Alireza S. Mahani, Mansour T.A. Sharabiani.\n\nBayClone2\n\nBayesian Feature Allocation Model for Tumor Heterogeneity. Authors:\nJuhee Lee, Peter Mueller, Subhajit Sengupta, Kamalakar Gulukota,\nYuan Ji.\n\nBayesMixSurv\n\nBayesian Mixture Survival Models using Additive Mixture-of-Weibull\nHazards, with Lasso Shrinkage and Stratification. Authors:\nAlireza S. Mahani, Mansour T.A. Sharabiani.\n\nBayesianAnimalTracker\n\nBayesian Melding of GPS and DR Path for Animal Tracking. Authors:\nYang (Seagle) Liu [aut, cre], Brian C. Battaile [ctb]. In view:\nSpatioTemporal.\n\nBinNonNor\n\nData Generation with Binary and Continuous Non-normal Components.\nAuthors: Gul Inan, Hakan Demirtas.\n\nBlandAltmanLeh\n\nPlots (slightly extended) Bland-Altman plots. Author: Bernhard\nLehnert.\n\nCARBayesST\n\nPoisson Log-linear Models with Spatio-temporal Random Effects.\nAuthors: Duncan Lee and Alastair Rushworth.\n\nCEC\n\nCross-Entropy Clustering. Authors: Konrad Kamieniecki [aut, cre],\nPrzemyslaw Spurek [ctb].\n\nCINOEDV\n\nCo-Information based N-Order Epistasis Detector and Visualizer.\nAuthor: Junliang Shang.\n\nCLME\n\nConstrained Inference for Linear Mixed Effects Models. Author:\nCasey M. Jelsema.\n\nCNOGpro\n\nCopy Numbers of Genes in prokaryotes. Authors: Ola Brynildsrud,\nLars-Gustav Snipen.\n\nCOPASutils\n\nTools for processing COPAS large-particle flow cytometer data.\nAuthors: Tyler Shimko, Erik Andersen.\n\nCP\n\nConditional Power Calculations. Author: Andreas Kuehnapfel.\n\nCVTuningCov\n\nRegularized Estimators of Covariance Matrices with CV Tuning.\nAuthor: Binhuan Wang.\n\nCarletonStats\n\nFunctions For Statistics Classes At Carleton College. Author: Laura\nChihara.\n\nCateSelection\n\nCategorical Variable Selection Methods. Authors: Yi Xu and Jixiang\nWu.\n\nCerioliOutlierDetection\n\nOutlier detection using the iterated RMCD method of Cerioli (2010).\nAuthors: Christopher G. Green [aut, cre], R. Doug Martin [ths].\n\nClimClass\n\nClimate Classification According To Several Indices. Authors:\nEmanuele Eccel, Emanuele Cordano, Giambattista Toller.\n\nCombinePValue\n\nCombine a Vector of Correlated \\(p\\)-values. Author: Hongying Dai.\n\nCompGLM\n\nConway-Maxwell-Poisson GLM and distribution functions. Author:\nJeffrey Pollock.\n\nCompind\n\nComposite indicators functions. Authors: Francesco Vidoli, Elisa\nFusco.\n\nCosmoPhotoz\n\nPhotometric redshift estimation using Generalized Linear Models.\nAuthors: Rafael S. de Souza, Alberto Krone-Martins, Jonathan\nElliott, Joseph Hilbe.\n\nCpGFilter\n\nCpG Filtering Method Based on Intra-class Correlation Coefficients.\nAuthor: Jun Chen.\n\nCrossover\n\nCrossover Designs. Author: Kornelius Rohmeyer.\n\nD2C\n\nPredicting Causal Direction from Dependency Features. Authors:\nGianluca Bontempi, Catharina Olsen, Maxime Flauder.\n\nDAMOCLES\n\nDynamic Assembly Model Of Colonization, Local Extinction and\nSpeciation. Authors: Rampal S. Etienne and Alex L. Pigot.\n\nDDIwR\n\nDDI with R. Author: Adrian Dusa [aut, cre].\n\nDLMtool\n\nData-Limited Methods Toolkit. Author: Tom Carruthers.\n\nDOvalidation\n\nLocal Linear Hazard Estimation with Do-Validated and Cross-Validated\nBandwidths. Authors: M.L. Gamiz, E. Mammen, M.D. Martinez-Miranda\nand J.P. Nielsen.\n\nDStree\n\nRecursive Partitioning for Discrete-Time Survival Trees. Authors:\nPeter Mayer, Denis Larocque, Matthias Schmid. In view:\nSurvival.\n\nDepthProc\n\nAuthors: Daniel Kosiorowski, Mateusz Bocian, Anna Wegrzynkiewicz and\nZygmunt Zawadzki.\n\nDeriv\n\nSymbolic Differentiation. Author: Andrew Clausen.\n\nDetMCD\n\nDetMCD Algorithm (Robust and Deterministic Estimation of Location\nand Scatter). Authors: Vakili Kaveh [aut, cre], Mia Hubert\n[ths].\n\nDynNom\n\nA Dynamic Nomogram for Linear and Generalized Linear Models as Shiny\nApplications. Authors: Amirhossein Jalali, Alberto Alvarez-Iglesias,\nJohn Newell.\n\nEBglmnet\n\nEmpirical Bayesian Lasso and Elastic Net Methods for Generalized\nLinear Models. Author: Anhui Huang.\n\nEGRET\n\nExploration and Graphics for RivEr Trends. Authors: Robert Hirsch\n[aut], Laura DeCicco [aut, cre].\n\nEIAdata\n\nR Wrapper for the Energy Information Administration (EIA) API.\nAuthor: Matthew Brigida. In view:\nWebTechnologies.\n\nEMDomics\n\nEarth Mover’s Distance for Differential Analysis of Genomics Data.\nAuthors: Daniel Schmolze [aut, cre], Andrew Beck [aut], Sheida\nNabavi [aut].\n\nENMeval\n\nAutomated runs and evaluations of ecological niche models. Authors:\nRobert Muscarella, Peter J. Galante, Mariano Soley-Guardia,\nRobert A. Boria, Jamie M. Kass, Maria Uriarte and Robert P.\nAnderson.\n\nENiRG\n\nEcological Niche in R and GRASS. Authors: Fernando Canovas, Chiara\nMagliozzi, Jose Antonio Palazon-Ferrando, Frederico Mestre, Mercedes\nGonzalez-Wanguemert.\n\nEcoVirtual\n\nSimulation of Ecological Models. Authors: Alexandre Adalardo de\nOliveira and Paulo Inacio Prado.\n\nEffectTreat\n\nPrediction of Therapeutic Success. Authors: Wim Van der Elst, Ariel\nAlonso and Geert Molenberghs.\n\nEnsembleBase\n\nExtensible Package for Parallel, Batch Training of Base Learners for\nEnsemble Modeling. Authors: Alireza S. Mahani, Mansour T.A.\nSharabiani.\n\nEnsembleCV\n\nExtensible Package for Cross-Validation-Based Integration of Base\nLearners. Authors: Mansour T.A. Sharabiani, Alireza S. Mahani.\n\nEnsemblePCReg\n\nExtensible Package for Principal-Component-Regression-based\nIntegration of Base Learners. Authors: Mansour T.A. Sharabiani,\nAlireza S. Mahani.\n\nEnsemblePenReg\n\nExtensible Classes and Methods for Penalized-Regression-based\nIntegration of Base Learners. Authors: Mansour T.A. Sharabiani,\nAlireza S. Mahani.\n\nEpiDynamics\n\nDynamic Models in Epidemiology. Authors: Oswaldo Santos Baquero\n[aut, cre], Fernando Silveira Marques [aut].\n\nEplot\n\nPlotting longitudinal series. Author: Eran Raviv.\n\nFADA\n\nVariable selection for supervised classification in high dimension.\nAuthors: Emeline Perthame, Chloe Friguet and David Causeur.\n\nFAMILY\n\nA Convex Formulation for Modeling Interactions with Strong Heredity.\nAuthor: Asad Haris.\n\nFDGcopulas\n\nMultivariate Dependence with FDG Copulas. Authors: Gildas Mazo,\nStephane Girard.\n\nFPDclustering\n\nPD-Clustering and Factor PD-Clustering. Authors: Cristina Tortora\nand Paul D. McNicholas.\n\nFRESA.CAD\n\nFeatuRE Selection Algorithms for Computer Aided Diagnosis. Author:\nJose Gerardo Tamez-Pena.\n\nFatTailsR\n\nPower Hyperbolic Functions and Kiener Distributions. Author: Patrice\nKiener. In view:\nDistributions.\n\nFeatureHashing\n\nCreates a Model Matrix via Feature Hashing With a Formula Interface.\nAuthor: Wush Wu [aut, cre].\n\nForIT\n\nFunctions from the 2nd Italian Forest Inventory (INFC). Authors:\nNicola Puletti, Marco Mura, Cristiano Castaldi, Maurizio Marchi, Ugo\nChiavetta, Roberto Scotti.\n\nForwardSearch\n\nForward Search using asymptotic theory. Author: Bent Nielsen.\n\nFrames2\n\nEstimation in dual frame surveys. Authors: Antonio Arcos, Maria del\nMar Rueda, Maria Giovanna Ranalli and David Molina.\n\nFreeSortR\n\nFree Sorting data analysis. Author: Philippe Courcoux.\n\nFunctionalNetworks\n\nAn algorithm for gene and gene set network inference. Author:\nAlejandro Quiroz-Zarate.\n\nGCAI.bias\n\nGuided Correction Approach for Inherited bias (GCAI.bias). Author:\nGuoshuai Cai.\n\nGCPM\n\nGeneralized Credit Portfolio Model. Author: Kevin Jakob. In view:\nFinance.\n\nGENLIB\n\nGenealogical Data Analysis. Authors: Louis Houde [aut],\nJean-Francois Lefebvre [aut], Valery Roy-Lagace [aut], Sebastien\nLemieux [aut], Michael J. Fromberger [ctb], Marie-Helene\nRoy-Gagnon [cre].\n\nGLDreg\n\nFit GLD Regression Model and GLD Quantile Regression Model to\nEmpirical Data. Authors: Steve Su, with contributions from the R\nCore Team.\n\nGMDH\n\nPredicting and Forecasting Time Series via GMDH-Type Neural Network\nAlgorithms. Authors: Osman Dag, Ceylan Yozgatligil. In view:\nTimeSeries.\n\nGPC\n\nGeneralized Polynomial Chaos. Authors: Miguel Munoz Zuniga and\nJordan Ko.\n\nGPareto\n\nGaussian Processes for Pareto Front Estimation and Optimization.\nAuthors: Mickael Binois, Victor Picheny.\n\nGUILDS\n\nImplementation of sampling formulas for the unified neutral model of\nbiodiversity and biogeography, with or without guild structure.\nAuthor: Thijs Janzen.\n\nGUIProfiler\n\nProfiler Graphical User Interface. Authors: Fernando de Villar and\nAngel Rubio. In view:\nHighPerformanceComputing.\n\nGenWin\n\nSpline Based Window Boundaries for Genomic Analyses. Author:\nTimothy M. Beissinger.\n\nGeneticSubsetter\n\nIdentify Favorable Subsets of Germplasm Collections. Authors:\nRyan C. Graebner and Alfonso Cuesta-Marcos.\n\nGeoDE\n\nA geometrical Approach to Differential expression and gene-set\nenrichment. Authors: Neil R. Clark and Avi Ma’ayan.\n\nGlobalOptions\n\nGenerate Functions to Get or Set Global Options. Author: Zuguang Gu.\n\nGrammR\n\nGraphical Representation and Modeling of Metagenomic Reads. Authors:\nDeepak N. Ayyala, Shili Lin.\n\nHSSVD\n\nBiclustering with Heterogeneous Variance. Authors: Guanhua Chen\n[aut, cre], Michael Kosorok [aut], Shannon Holloway [ctb].\n\nHWxtest\n\nExact Tests for Hardy-Weinberg Proportions. Author: Bill Engels.\n\nHiDimMaxStable\n\nInference on High Dimensional Max-Stable Distributions. Authors:\nAlexis Bienvenüe [aut, cre], Christian Robert [aut].\n\nHierO\n\nA graphical user interface for calculating power and sample size for\nhierarchical data. Author: Kari Tokola.\n\nIDPSurvival\n\nImprecise Dirichlet Process for Survival Analysis. Authors:\nFrancesca Mangili, Alessio Benavoli, Cassio P. de Campos, Marco\nZaffalon. In view:\nSurvival.\n\nIRTShiny\n\nItem Response Theory via Shiny. Authors: William Kyle Hamilton,\nAtsushi Mizumoto. In view:\nPsychometrics.\n\nISOpureR\n\nDeconvolution of Tumour Profiles. Authors: Gerald Quon [aut],\nCatalina V Anghel [aut, trl], Syed Haider [aut], Francis Nguyen\n[aut], Amit G Deshwar [aut], Quaid D Morris [aut], Paul C\nBoutros [aut, cre].\n\nInvariantCausalPrediction\n\nInvariant Causal Prediction. Author: Nicolai Meinshausen.\n\nJAGUAR\n\nJoint Analysis of Genotype and Group-specific Variability Using a\nNovel Score Test Approach to Map eQTL. Authors: Chaitanya R. Acharya\nand Andrew S. Allen.\n\nJMdesign\n\nJoint Modeling of Longitudinal and Survival Data – Power\nCalculation. Authors: Emil A. Cornea, Liddy M. Chen, Bahjat F.\nQaqish, Haitao Chu, and Joseph G. Ibrahim.\n\nKODAMA\n\nKnowledge discovery by accuracy maximization. Authors: Stefano\nCacciatore, Claudio Luchinat, Leonardo Tenori.\n\nLDRTools\n\nTools for Linear Dimension Reduction. Authors: Eero Liski [aut,\ncre], Klaus Nordhausen [aut], Hannu Oja [aut], Anne Ruiz-Gazen\n[aut].\n\nLakeMetabolizer\n\nTools for the analysis of ecosystem metabolism. Authors: Luke\nWinslow, Jake Zwart, Ryan Batt, Jessica Corman, Hilary Dugan, Paul\nHanson, Gordon Holtgrieve, Aline Jaimes, Jordan Read, Richard\nWoolway.\n\nLinCal\n\nStatic Univariate Frequentist and Bayesian Linear Calibration.\nAuthors: Derick L. Rivers and Edward L. Boone.\n\nLinRegInteractive\n\nInteractive Interpretation of Linear Regression Models. Author:\nMartin Meermeyer. In view:\nEconometrics.\n\nLindenmayeR\n\nFunctions to Explore L-Systems (Lindenmayer Systems). Author: Bryan\nHanson [aut, cre].\n\nMATA\n\nModel-Averaged Tail Area Wald (MATA-Wald) Confidence Interval.\nAuthor: Daniel Turek [aut, cre].\n\nMAVIS\n\nMeta Analysis via Shiny. Authors: William Kyle Hamilton, Atsushi\nMizumoto. In view:\nMetaAnalysis.\n\nMCAvariants\n\nMultiple Correspondence Analysis Variants. Author: Rosaria Lombardo.\n\nMCS\n\nModel Confidence Set Procedure. Authors: Leopoldo Catania and Mauro\nBernardi.\n\nMGL\n\nModule Graphical Lasso. Author: Safiye Celik.\n\nMGRASTer\n\nAPI Client for the MG-RAST Server of the US DOE KBase. Author:\nDaniel T. Braithwaite [aut, cre].\n\nMGSDA\n\nMulti-Group Sparse Discriminant Analysis. Author: Irina Gaynanova.\n\nMOrder\n\nCheck Time Homogeneity and Markov Chain Order. Authors: Akshay\nChougule, Robert Canales.\n\nMPAgenomics\n\nMulti-Patient Analysis of Genomic Markers. Authors: Quentin\nGrimonprez with contributions from Guillemette Marot and Samuel\nBlanck. Some functions use code created by Sjoerd Vosse, Mark van de\nWiel, Pierre Neuvial, Henrik Bengtsson.\n\nMRH\n\nMulti-Resolution Estimation of the Hazard Rate. Authors: Yolanda\nHagar, Yuanting Chen, Vanja Dukic.\n\nMRSP\n\nMultinomial Response Models with Structured Penalties. Author:\nWolfgang Poessnecker.\n\nMSIseq\n\nAssess Tumor Microsatellite Instability with a Decision Tree\nClassifier from Exome Somatic Mutations. Author: Mini Huang.\n\nMST\n\nMultivariate Survival Trees. Authors: Xiaogang Su, Peter Calhoun,\nand Juanjuan Fan. In view:\nSurvival.\n\nMVar.pt\n\nAnalise Multivariada (Brazilian Portuguese). Authors: Paulo Cesar\nOssani and Marcelo Angelo Cirillo.\n\nMareyMap\n\nEstimation of meiotic recombination rates using marey maps. Authors:\nAurelie Siberchicot, Clement Rezvoy, Delphine Charif, Laurent\nGueguen and Gabriel Marais.\n\nMatchingFrontier\n\nComputation of the Balance Sample Size Frontier in Matching Methods\nfor Causal Inference. Authors: Gary King, Christopher Lucas, and\nRichard Nielsen.\n\nMenuCollection\n\nCollection of Configurable GTK+ Menus. Author: Gianmarco Polotti.\n\nMetFns\n\nAnalysis of Visual Meteor Data. Author: Kristina Veljkovic.\n\nMetaLandSim\n\nMetapopulation and Landscape Simulation. Authors: Frederico Mestre,\nFernando Canovas, Ricardo Pita, Antonio Mira, Pedro Beja.\n\nMfUSampler\n\nMultivariate-from-Univariate (MfU) MCMC Sampler. Authors: Alireza S.\nMahani, Mansour T.A. Sharabiani.\n\nMixGHD\n\nModel Based Clustering, Classification and Discriminant Analysis\nUsing the Mixture of Generalized Hyperbolic Distributions. Authors:\nCristina Tortora, Ryan P. Browne, Brian C. Franczak and Paul D.\nMcNicholas.\n\nMixedTS\n\nMixed Tempered Stable Distribution. Authors: Lorenzo Mercuri, Edit\nRroji.\n\nMultNonParam\n\nMultivariate Nonparametric Methods. Authors: John E. Kolassa and\nStephane Jankowski.\n\nMultiSV\n\nIdentification of structural variations in multiple populations\nbased on whole genome resequencing. Author: Khurram Maqbool.\n\nNB\n\nMaximum Likelihood method in estimating effective population size\nfrom genetic data. Author: Tin-Yu Hui.\n\nNHANES\n\nNHANES data. Authors: Randall Pruim, Daniel Kaplan, Nicholas Horton.\n\nNHMM\n\nBayesian NHMM Modeling (Multiple Time Series). Author: Tracy\nHolsclaw.\n\nNISTunits\n\nFundamental Physical Constants and Unit Conversions from NIST.\nAuthor: Jose Gama [aut, cre].\n\nNORTARA\n\nGeneration of Multivariate Data with Arbitrary Marginals. Author: Po\nSu [aut, cre].\n\nNPBayesImpute\n\nNon-parametric Bayesian Multiple Imputation for Categorical Data.\nAuthors: Quanli Wang, Daniel Manrique-Vallier, Jerome P. Reiter and\nJingchen Hu.\n\nNeuralNetTools\n\nVisualization and Analysis Tools for Neural Networks. Author:\nMarcus W. Beck [aut, cre].\n\nONETr\n\nEfficient authenticated interaction with the O*NET API. Author:\nEric Knudsen. In view:\nWebTechnologies.\n\nOptionPricing\n\nOption Pricing with Efficient Simulation Algorithms. Authors: Kemal\nDingec, Wolfgang Hormann. In view:\nFinance.\n\nOutrankingTools\n\nFunctions for Solving Multiple-criteria Decision-making Problems.\nAuthor: Michel Prombo.\n\nP2C2M\n\nPosterior Predictive Checks of Coalescent Models. Authors: Michael\nGruenstaeudl, Noah Reid.\n\nPANDA\n\nPreferential Attachment Based Common Neighbor Distribution Derived\nFunctional Associations. Authors: Hua Li and Pan Tong.\n\nPANICr\n\nPANIC Tests of Nonstationarity. Author: Steve Bronder.\n\nPASWR2\n\nProbability and Statistics with R, Second Edition. Author: Alan T.\nArnholt.\n\nPGICA\n\nParallel Group ICA Algorithm. Authors: Shaojie Chen, Lei Huang,\nHuitong Qiu, Ani Eloyan, Brian Caffo and Ciprian Crainiceanu. In\nview:\nHighPerformanceComputing.\n\nPHENIX\n\nPhenotypic Integration Index. Authors: R. Torices, A. J.\nMuñoz-Pajares.\n\nPLSbiplot1\n\nThe Partial Least Squares (PLS) Biplot. Authors: Opeoluwa F. Oyedele\n[aut, cre], Sugnet Gardner-Lubbe [aut].\n\nPLordprob\n\nMultivariate Ordered Probit Model via Pairwise Likelihood. Authors:\nEuloge Clovis Kenne Pagui [aut, cre], Antonio Canale [aut], Alan\nGenz [ctb], Adelchi Azzalini [ctb].\n\nPRROC\n\nPrecision-Recall and ROC Curves for Weighted and Unweighted Data.\nAuthors: Jan Grau and Jens Keilwagen.\n\nParallelForest\n\nRandom Forest Classification with Parallel Computing. Author:\nBertram Ieong [aut, cre, cph].\n\nPepPrep\n\nInsilico peptide mutation, digestion and homologous comparison.\nAuthor: Rafael Dellen.\n\nPerFit\n\nPerson Fit. Author: Jorge N. Tendeiro.\n\nPhyActBedRest\n\nMarks periods of sleep in Actigraph accelerometer data. Authors: J.\nDustin Tracy, Zhiyi Xu, Leena Choi, Sari Acra, Kong Y. Chen,\nMaciej S. Buchowski.\n\nPolyPatEx\n\nPaternity exclusion in autopolyploid species. Author: Alexander\nZwart.\n\nPrevMap\n\nGeostatistical Modelling of Spatially Referenced Prevalence Data.\nAuthors: Emanuele Giorgi, Peter J. Diggle.\n\nQoLR\n\nAnalysis of Health-Related Quality of Life in oncology. Author:\nAmelie Anota.\n\nQualInt\n\nTest for Qualitative Interactions. Authors: Lixi Yu, Eun-Young Suh,\nGuohua (James) Pan.\n\nQuor\n\nQuantile Ordering. Authors: Adriano Polpo, Carlos A. de B. Pereira,\nCassio P. de Campos.\n\nR6\n\nClasses with reference semantics. Author: Winston Chang [aut,\ncre].\n\nRAM\n\nR for Amplicon-based Metagenomics. Authors: Wen Chen and Joshua\nSimpson.\n\nRAMP\n\nRegularized Generalized Linear Models with Interaction Effects.\nAuthors: Yang Feng, Ning Hao and Hao Helen Zhang.\n\nRAdwords\n\nLoading Google Adwords Data Into R. Authors: Johannes Burkhardt,\nMatthias Bannert.\n\nRCMIP5\n\nTools for Manipulating and Summarizing CMIP5 Data. Authors: Ben\nBond-Lamberty [aut], Kathe Todd-Brown [aut, cre].\n\nRConics\n\nComputations on Conics. Author: Emanuel Huber.\n\nRCryptsy\n\nAccess to Cryptsy Crypto-Currency Exchange Public Information API\nvia R. Author: William Kyle Hamilton. In view:\nWebTechnologies.\n\nRDML\n\nImporting real-time thermo cycler (qPCR) data from RDML format\nfiles. Authors: Konstantin A. Blagodatskikh [cre, aut], Stefan\nRoediger [aut], Michal Burdukiewicz [aut].\n\nRDataCanvas\n\nBasic Runtime Support for Datacanvas.io. Author: Xiaolin Zhang\n[aut, cre]. In view:\nWebTechnologies.\n\nRECA\n\nRelevant Component Analysis for Supervised Distance Metric Learning.\nAuthor: Nan Xiao.\n\nREDCapR\n\nInteraction between R and REDCap. Authors: Will Beasley [aut,\ncre], David Bard [ctb], Thomas Wilson [ctb], John J Aponte\n[ctb], Rollie Parrish [ctb], Benjamin Nutter [ctb], Andrew\nPeters [ctb].\n\nRGA\n\nA Google Analytics API client for R. Authors: Artem Klevtsov [aut,\ncre], Philipp Upravitelev [ctb], Olga Shramko [ctb]. In view:\nWebTechnologies.\n\nRGoogleAnalytics\n\nR Wrapper for the Google Analytics API. Authors: Michael Pearmain.\nContributions from Nick Mihailowski, Vignesh Prajapati, Kushan Shah\nand Nicolas Remy. In view:\nWebTechnologies.\n\nRJSDMX\n\nR Interface to SDMX Web Services. Authors: Attilio Mattiocco, Diana\nNicoletti, Gianpaolo Lopez. In view:\nWebTechnologies.\n\nRMKdiscrete\n\nSundry Discrete Probability Distributions. Author: Robert M.\nKirkpatrick.\n\nRMOA\n\nConnect R with MOA for Massive Online Analysis. Authors: Jan\nWijffels [aut, cre], BNOSAC [cph].\n\nRMOAjars\n\nExternal jars required for package RMOA. Author: See file AUTHORS.\n\nRMRAINGEN\n\nR Multi-site RAINfall GENeretor: generate daily time series of\nrainfall from monthly mean values. Author: Emanuele Cordano.\n\nRNeXML\n\nImplement semantically rich I/O for the NeXML format. Authors: Carl\nBoettiger [cre, aut], Scott Chamberlain [aut], Hilmar Lapp\n[aut], Kseniia Shumelchyk [aut], Rutger Vos [aut]. In view:\nPhylogenetics.\n\nRODBCext\n\nParameterized queries extension for RODBC. Authors: Mateusz Zoltak\n[aut, cre], Brian Ripley [aut], Michael Lapsley [aut].\n\nRPANDA\n\nPhylogenetic ANalyses of DiversificAtion. Author: Hélène Morlon\n[aut, cre, cph].\n\nRRreg\n\nCorrelation and Regression Analyses for Randomized Response Data.\nAuthors: Daniel W. Heck [aut, cre], Morten Moshagen [aut].\n\nRSQLServer\n\nSQL Server R Database Interface (DBI). Authors: Imanuel Costigan\n[aut, cre], The jTDS Project [aut] (for MSSQL Server driver),\nSimon Urbanek [ctb], The Legion Of The Bouncy Castle [cph, ctb].\n\nRStars\n\nAccess to the Digital Universe Data set API. Author: William Kyle\nHamilton. In view:\nWebTechnologies.\n\nRSurveillance\n\nDesign and Analysis of Disease Surveillance Activities. Author: Evan\nSergeant.\n\nRTDE\n\nRobust Tail Dependence Estimation. Authors: Christophe Dutang [aut,\ncre], Armelle Guillou [ctb], Yuri Goegebeur [ctb]. In view:\nDistributions.\n\nRTriangle\n\nA 2D Quality Mesh Generator and Delaunay Triangulator. Authors:\nJonathan Shewchuk, David C. Sterratt.\n\nRamd\n\nTools For Managing File/function Dependencies In R. Author: Robert\nKrzyzanowski.\n\nRcmdrMisc\n\nR Commander Miscellaneous Functions. Authors: John Fox [aut, cre],\nRobert Muenchen [ctb], Dan Putler [ctb].\n\nRcmdrPlugin.EcoVirtual\n\nRcmdr EcoVirtual Plugin. Authors: Alexandre Adalardo de Oliveira\nand Paulo Inacio Prado.\n\nRcmdrPlugin.RMTCJags\n\nR MTC Jags Rcmdr Plugin. Author: Marcelo Goulart Correia.\n\nRcmdrPlugin.ROC\n\nRcmdr Receiver Operator Characteristic Plug-In package. Authors:\nDaniel-Corneliu Leucuta [aut, cre], Mihaela Hedesiu [ctb],\nAndrei Achimas [ctb], Oana Almasan [ctb].\n\nRcppAnnoy\n\nRcpp Bindings for Annoy, a Library for Approximate Nearest\nNeighbors. Author: Dirk Eddelbuettel.\n\nRcppDL\n\nDeep Learning Methods via Rcpp. Authors: Qiang Kou, Yusuke\nSugomori.\n\nRcppMLPACK\n\nRcpp Integration for MLPACK Library. Authors: Qiang Kou, Ryan\nCurtin.\n\nRcppParallel\n\nParallel programming tools for Rcpp. Authors: JJ Allaire; Romain\nFrancois; Intel, Inc.; Marcus Geelnard.\n\nRdsdp\n\nR Interface to DSDP Semidefinite Programming Library. Authors: Zhisu\nZhu, Yinyu Ye (DSDP by Steve Benson, Yinyu Ye and Xiong Zhang).\n\nRealVAMS\n\nMultivariate VAM Fitting. Authors: Andrew Karl, Jennifer Broatch,\nand Jennifer Green.\n\nRegressionFactory\n\nExpander Functions for Generating Full Gradient and Hessian from\nSingle- and Multi-Slot Base Distributions. Authors: Alireza S.\nMahani, Mansour T.A. Sharabiani.\n\nReorderCluster\n\nReordering the dendrogram according to the class labels. Authors:\nNatalia Novoselova, Frank Klawonn, Junxi Wang.\n\nRmixmodCombi\n\nCombining Mixture Components for Clustering. Authors: J.-P. Baudry\nand G. Celeux.\n\nRootsExtremaInflections\n\nFinds roots, extrema and inflection points of a curve. Author:\nDemetris T. Christopoulos. In view:\nNumericalMathematics.\n\nRoughSetKnowledgeReduction\n\nSimplification of Decision Tables using Rough Sets. Author: Alber\nSanchez.\n\nSBRect\n\nDetecting structural breaks using rectangle covering (non-parametric\nmethod). Authors: Paul Fischer [aut, cre, cph], Astrid Hilbert\n[ctb, cph].\n\nSCEPtERbinary\n\nStellar CharactEristics Pisa Estimation gRid for Binary Systems.\nAuthors: Matteo Dell’Omodarme [aut, cre], Giada Valle [aut].\n\nSEAsic\n\nScore Equity Assessment summary index computation. Authors: Anne\nCorinne Huggins-Manley [aut, cre], Douglas Whitaker [aut].\n\nSOD\n\nSOD for multidimensional scaling. Author: Martin Jakt.\n\nSOR\n\nEstimation using Sequential Offsetted Regression. Authors: Lee S.\nMcDaniel, Jonathan S. Schildcrout.\n\nSPREDA\n\nStatistical Package for Reliability Data Analysis. Authors: Yili\nHong, Yimeng Xie, and Zhibing Xu.\n\nSQDA\n\nSparse Quadratic Discriminant Analysis. Author: Jiehuan Sun.\n\nSSrat\n\nTwo-dimensional sociometric status determination with rating scales.\nAuthor: Hans Landsheer.\n\nScoreGGUM\n\nScore Persons Using the Generalized Graded Unfolding Model. Authors:\nDavid R. King and James S. Roberts.\n\nSelvarMix\n\nRegularization for variable selection in model-based clustering and\ndiscriminant analysis. Authors: Mohammed Sedki, Gilles Celeux, Cathy\nMaugis-Rabusseau.\n\nSimplicialCubature\n\nNumerical integration of functions over simplices. Authors: John P.\nNolan, with parts based on code by Alan Genz. In view:\nNumericalMathematics.\n\nSoundexBR\n\nPhonetic-Coding For Portuguese. Author: Daniel Marcelino.\n\nSphericalK\n\nSpherical K-function. Authors: Scott Robeson, Ao Li, Chunfeng Huang.\n\nStatMethRank\n\nStatistical Methods for Ranking Data. Author: Li Qinglong.\n\nStatomica\n\nStatomica utility package. Authors: Zahra Montazeri, Alaa Ali, Kyle\nLeckett, Marta Padilla and David R. Bickel.\n\nTDA\n\nStatistical Tools for Topological Data Analysis. Authors:\nBrittany T. Fasy, Jisu Kim, Fabrizio Lecci, Clement Maria.\n\nTDboost\n\nA Boosted Nonparametric Tweedie Model. Authors: Yi Yang, Wei Qian,\nHui Zou.\n\nTEEReg\n\nTrimmed Elemental Estimation for Linear Models. Authors: Wei Jiang\nand Matthew S. Mayo. In view:\nRobust.\n\nTR8\n\nA tool for downloading functional traits data for plant species.\nAuthor: Gionata Bocci. In view:\nWebTechnologies.\n\nTRSbook\n\nFunctions and Datasets to Accompany the Book “The R Software:\nFundamentals of Programming and Statistical Analysis”. Authors:\nPierre Lafaye de Micheaux, Remy Drouilhet, Benoit Liquet.\n\nTableMonster\n\nTable Monster. Author: Grant Izmirlian Jr.\n\nUPMASK\n\nUnsupervised Photometric Membership Assignment in Stellar Clusters.\nAuthors: Alberto Krone-Martins, Andre Moitinho.\n\nUSAboundaries\n\nHistorical Boundaries of the United States of America, 1629–2000.\nAuthors: Lincoln Mullen [aut, cre], Dr. William M. Scholl Center\nfor American History and Culture, The Newberry Library [cph].\n\nV8\n\nEmbedded JavaScript Engine. Author: Jeroen Ooms.\n\nW3CMarkupValidator\n\nR Interface to W3C Markup Validation Services. Author: Kurt Hornik\n[aut, cre]. In view:\nWebTechnologies.\n\nWRS2\n\nWilcox Robust Estimation and Testing. Authors: Patrick Mair [cre,\naut], Felix Schoenbrodt [aut], Rand Wilcox [aut]. In view:\nRobust.\n\nWatersheds\n\nSpatial Watershed Aggregation and Spatial Drainage Network Analysis.\nAuthor: J.A. Torres.\n\nWaveletComp\n\nComputational Wavelet Analysis. Authors: Angi Roesch and Harald\nSchmidbauer.\n\nWhiteStripe\n\nWhitestripe White Matter Normalization for Magnetic Resonance\nImages. Authors: Taki Shinohara, John Muschelli.\n\naRxiv\n\nInterface to the arXiv API. Authors: Karthik Ram [aut], Karl\nBroman [aut, cre]. In view:\nWebTechnologies.\n\nacid\n\nAnalysing Conditional Distributions of Income. Author: Alexander\nSohn.\n\nacnr\n\nAnnotated Copy-Number Regions. Authors: Morgane Pierre-Jean and\nPierre Neuvial.\n\nacp\n\nAutoregressive Conditional Poisson. Author: Siakoulis Vasileios.\n\nactivity\n\nAnimal Activity Statistics. Author: Marcus Rowcliffe.\n\nadaptDA\n\nAdaptive Mixture Discriminant Analysis. Author: Charles Bouveyron.\n\naddreg\n\nAdditive Regression for Discrete Data. Author: Mark Donoghoe.\n\nadwave\n\nWavelet Analysis of Genomic Data from Admixed Populations. Author:\nJean Sanderson.\n\nalleHap\n\nAllele simulation and Haplotype reconstruction from pedigree\ndatabases. Authors: Nathan Medina-Rodriguez and Angelo Santana.\n\nanalogueExtra\n\nAdditional functions for use with the analogue package. Author:\nGavin L. Simpson [aut, cre].\n\nanim.plots\n\nSimple Animated Plots For R. Author: David Hugh-Jones.\n\naoos\n\nAnother Object Orientation System. Author: Sebastian Warnholz.\n\napc\n\nAge-period-cohort analysis. Author: Bent Nielsen.\n\naplore3\n\nDatasets from Hosmer, Lemeshow and Sturdivant, “Applied Logistic\nRegression” (3rd ed.). Author: Luca Braglia [aut, cre].\n\naprean3\n\nDatasets from Draper and Smith “Applied Regression Analysis” (3rd\ned., 1998). Author: Luca Braglia [aut, cre].\n\narchdata\n\nExample Datasets from Archaeological Research. Author: David L.\nCarlson.\n\narchiDART\n\nPlant Root System Architecture Analysis Using DART Output Files.\nAuthors: Benjamin M Delory, Caroline Baudson, Yves Brostaux, Patrick\ndu Jardin, Loic Pages, Pierre Delaplace.\n\narchivist\n\nTools for Storing, Restoring and Searching for R Objects. Authors:\nPrzemyslaw Biecek [aut, cre], Marcin Kosinski [aut].\n\nastrodatR\n\nAstronomical Data. Author: Eric D. Feigelson.\n\nastrolibR\n\nAstronomy Users Library. Authors: Arnab Chakraborty and Eric D.\nFeigelson.\n\natmcmc\n\nAutomatically Tuned Markov Chain Monte Carlo. Author: Jinyoung Yang.\n\nattribrisk\n\nPopulation Attributable Risk. Authors: Louis Schenck, Elizabeth\nAtkinson, Cynthia Crowson, Terry Therneau.\n\nbabynames\n\nUS baby names 1880–2013. Author: Hadley Wickham [aut, cre].\n\nbamboo\n\nProtein Secondary Structure Prediction Using the Bamboo Method.\nAuthor: David B. Dahl.\n\nbayou\n\nBayesian fitting of Ornstein-Uhlenbeck models to phylogenies.\nAuthors: Josef C. Uyeda, Jon Eastman and Luke Harmon.\n\nbde\n\nBounded Density Estimation. Authors: Guzman Santafe, Borja Calvo,\nAritz Perez and Jose A. Lozano.\n\nbdscale\n\nRemove Weekends and Holidays From ggplot2 Axes. Author: Dave\nMills.\n\nbglm\n\nBayesian Estimation in Generalized Linear Models. Authors: Nicolas\nMolano-Gonzalez, Edilberto Cepeda-Cuervo.\n\nbinequality\n\nMethods for Analyzing Binned Income Data. Authors: Samuel V.\nScarpino, Paul von Hippel, and Igor Holas.\n\nbinr\n\nCut Numeric Values Into Evenly Distributed Groups. Author: Sergei\nIzrailev.\n\nbio3d\n\nBiological Structure Analysis. Authors: Barry Grant, Xin-Qiu Yao,\nLars Skjaerven, Julien Ide.\n\nbiogram\n\nN-Gram Analysis of Biological Sequences. Authors: Michal\nBurdukiewicz [cre, aut], Piotr Sobczyk [aut], Chris Lauber\n[aut].\n\nblocksdesign\n\nNested Block Designs for Unstructured Treatments. Author: R. N.\nEdmondson.\n\nblsAPI\n\nRequest Data From The U.S. Bureau of Labor Statistics API. Author:\nMichael Silva.\n\nbnormnlr\n\nBayesian Estimation for Normal Heteroscedastic Nonlinear Regression\nModels. Authors: Nicolas Molano-Gonzalez, Marta Corrales Bossio,\nMaria Fernanda Zarate, Edilberto Cepeda-Cuervo.\n\nbootSVD\n\nFast, Exact Bootstrap Principal Component Analysis for High\nDimensional Data. Author: Aaron Fisher.\n\nboral\n\nBayesian Ordination and Regression AnaLysis. Author: Francis K.C.\nHui.\n\nbreakaway\n\nSpecies richness estimation and modelling. Authors: Amy Willis and\nJohn Bunge.\n\nbroom\n\nConvert Statistical Analysis Objects Into Tidy Data Frames. Authors:\nDavid Robinson [aut, cre], Matthieu Gomez [ctb], Boris Demeshev\n[ctb], Hadley Wickham [ctb].\n\nbtf\n\nEstimates univariate function via Bayesian trend filtering. Author:\nEdward A. Roualdes.\n\nbvarsv\n\nBayesian Analysis of a Vector Autoregressive Model with Stochastic\nVolatility and Time-Varying Parameters. Author: Fabian Krueger.\n\ncausaleffect\n\nDeriving Expressions of Joint Interventional Distributions in Causal\nModels. Author: Santtu Tikka.\n\ncdcsis\n\nConditional Distance Correlation and Its Related Feature Screening\nMethod. Authors: Canhong Wen, Wenliang Pan, Mian Huang, and Xueqin\nWang.\n\ncents\n\nCensored time series. Authors: A.I. McLeod, Nagham M. Mohammad,\nJustin Veenstra and Abdel El-Shaarawi.\n\ncheckpoint\n\nInstall Packages from Snapshots on the Checkpoint Server for\nReproducibility. Author: Revolution Analytics.\n\nchildsds\n\nCalculation of standard deviation scores adduced from different\ngrowth standards. Author: Mandy Vogel [aut, cre].\n\nchoiceDes\n\nDesign Functions for Choice Studies. Author: Jack Horne [aut,\ncre].\n\nchoroplethrAdmin1\n\nContains an Administrative-Level-1 Map of the World. Author: Ari\nLamstein.\n\nchoroplethrMaps\n\nContains maps used by the choroplethr package. Author: Ari\nLamstein.\n\ncjoint\n\nAMCE Estimator for Conjoint Experiments. Authors: Anton Strezhnev,\nJens Hainmueller, Daniel Hopkins, Teppei Yamamoto.\n\nclassyfire\n\nRobust multivariate classification using highly optimised SVM\nensembles. Authors: Eleni Chatzimichali and Conrad Bessant.\n\ncmprskQR\n\nAnalysis of Competing Risks Using Quantile Regressions. Authors:\nStephan Dlugosz, based on code from Limin Peng and Ruosha Li.\n\ncmvnorm\n\nComplex multivariate Gaussian distribution. Author: Robin K. S.\nHankin.\n\ncoenocliner\n\nCoenocline simulation. Authors: Gavin L. Simpson [aut, cre],\nFrancisco Rodriguez-Sanchez [ctb].\n\ncommentr\n\nPrint Nicely Formatted Comments for use in Script Files. Author:\nErik Bulow.\n\ncompendiumdb\n\nTools for Storage and Retrieval of Gene Expession Data. Authors:\nUmesh Nandal, Perry D. Moerland.\n\ncomplmrob\n\nRobust Linear Regression with Compositional Data as Covariates.\nAuthor: David Kepplinger.\n\nconfidence\n\nConfidence Estimation of Environmental State Classifications.\nAuthors: Willem M. G. M. van Loon [aut, cph], Dennis J. J.\nWalvoort [aut, cre].\n\ncooptrees\n\nCooperative aspects of optimal trees in weighted graphs. Author:\nManuel Fontenla.\n\ncopCAR\n\nFitting the copCAR regression model for discrete areal data.\nAuthors: Emily Goren and John Hughes.\n\ncoreTDT\n\nTDT for compound heterozygous and recessive models. Authors: Yu\nJiang, Andrew S Allen.\n\ncosinor\n\nTools for estimating and predicting the cosinor model. Author:\nMichael Sachs.\n\ncouchDB\n\nConnect and work with couchDB databases. Author: Aleksander\nDietrichson.\n\ncoxinterval\n\nCox-type models for interval-censored data. Authors: Audrey Boruvka\nand Richard J. Cook. In view:\nSurvival.\n\ncqrReg\n\nQuantile, Composite Quantile Regression and Regularized Versions.\nAuthors: Jueyu Gao and Linglong Kong.\n\ncrayon\n\nColored Terminal Output. Author: Gabor Csardi [aut, cre].\n\ncrossReg\n\nConfidence intervals for crossover points of two simple regression\nlines. Author: Sunbok Lee.\n\ncurl\n\nA Connection Interface to Libcurl. Author: Jeroen Ooms. In view:\nWebTechnologies.\n\ndashboard\n\nInteractive Data Visualization with D3.js. Author: Johann Laurent.\n\ndataRetrieval\n\nRetrieval Functions for USGS and EPA Hydrologic and Water Quality\nData. Authors: Robert Hirsch [aut], Laura DeCicco [aut, cre],\nDavid Lorenz [aut]. In view:\nWebTechnologies.\n\ndb.r\n\nA Database Exploration Tool with Assisted Querying and Schema\nExploration. Author: Greg Lamp.\n\ndbarts\n\nDiscrete Bayesian Additive Regression Trees Sampler. Authors: Hugh\nChipman, Robert McCulloch, Vincent Dorie.\n\ndcGOR\n\nAnalysis of ontologies and protein domain annotations. Authors: Hai\nFang and Julian Gough.\n\ndcmr\n\nAttribute profile estimation using Diagnostic Classification Models\nand MCMC. Authors: Diane Losardo and Margi Dubal.\n\ndecompr\n\nExport Decomposition (Wang-Wei-Zhu and source). Authors: Bastiaan\nQuast [aut, cre], Fei Wang [aut], Victor Kummritz [aut].\n\ndeming\n\nDeming, Thiel-Sen and Passing-Bablock Regression. Author: Terry\nTherneau.\n\ndensityClust\n\nClustering by fast search and find of density peaks. Author: Thomas\nLin Pedersen.\n\ndescomponer\n\nSeasonal Adjustment by Frequency Analysis. Author: Francisco Parra.\n\ndfcomb\n\nPhase I/II Adaptive Dose-Finding Design for Combination Studies.\nAuthors: Marie-Karelle Riviere and Jacques-Henri Jourdan.\n\ndfmta\n\nPhase I/II Adaptive Dose-Finding Design For MTA. Authors:\nMarie-Karelle Riviere and Jacques-Henri Jourdan.\n\ndiffeR\n\nDifference Metrics for Comparing Pairs of Maps. Authors: Robert\nGilmore Pontius Jr., Alí Santacruz.\n\ndigitalPCR\n\nEstimate copy number for digital PCR. Author: Xutao Deng.\n\ndisposables\n\nCreate Disposable R Packages for Testing. Author: Gabor Csardi\n[aut, cre].\n\ndocumair\n\nAutomatic Documentation for R packages. Authors: Jean-Baptiste\nDenis, Regis Pouillot, Kien Kieu.\n\ndotenv\n\nLoad environment variables from .env. Author: Gabor Csardi [aut,\ncre].\n\ndslice\n\nDynamic slicing. Authors: Chao Ye and Bo Jiang.\n\ndummy\n\nAutomatic Creation of Dummies with Support for Predictive Modeling.\nAuthors: Michel Ballings and Dirk Van den Poel.\n\ndunn.test\n\nDunn’s Test Of Multiple Comparisons Using Rank Sums. Author: Alexis\nDinno.\n\ndygraphs\n\nInterface to Dygraphs Interactive Time Series Charting Library.\nAuthors: Dan Vanderkam [aut, cph] (dygraphs library), JJ Allaire\n[aut, cre] (R interface), RStudio [cph].\n\necipex\n\nEfficient calculation of fine structure isotope patterns via Fourier\ntransforms of simplex-based elemental models. Author: Andreas Ipsen.\n\necoretriever\n\nR Interface to the EcoData Retriever. Authors: Daniel McGlinn [aut,\ncre], Ethan White [aut]. In view:\nWebTechnologies.\n\necospat\n\nSpatial ecology miscellaneous methods. Authors: Olivier Broenniman,\nBlaise Petitpierre, Christophe Randin, Robin Engler, Frank Breiner,\nManuela D’Amen, Loic Pellissier, Julien Pottier, Dorothea Pio, Ruben\nGarcia Mateo, Valeria Di Cola, Wim Hordijk, Anne Dubuis, Daniel\nScherrer, Nicolas Salamin and Antoine Guisan.\n\necoval\n\nProcedures for Ecological Assessment of Surface Waters. Authors:\nNele Schuwirth and Peter Reichert with contributions by Simone\nLanghans.\n\nedgeRun\n\nMore Powerful Unconditional Testing of Negative Binomial Means for\nDigital Gene Expression Data. Author: Emmanuel Dimont.\n\neegkit\n\nToolkit for Electroencephalography Data. Author: Nathaniel E.\nHelwig.\n\neegkitdata\n\nData for package eegkit. Author: Nathaniel E. Helwig.\n\nega\n\nError Grid Analysis. Author: Daniel Schmolze [aut, cre].\n\nembryogrowth\n\nTools to Analyze the Thermal Reaction Norm of Embryo Growth. Author:\nMarc Girondot.\n\nemil\n\nEvaluation of Modeling without Information Leakage. Authors:\nChristofer Backlin, Mats Gustafsson.\n\nempiricalFDR.DESeq2\n\nSimulation-based False Discovery Rate in RNA-seq. Author: Mikhail V.\nMatz.\n\nenigma\n\nR Client for the Enigma API. Author: Scott Chamberlain [aut, cre].\nIn view:\nWebTechnologies.\n\nenpls\n\nEnsemble Partial Least Squares (EnPLS) Regression. Authors: Nan\nXiao, Dong-Sheng Cao, Qing-Song Xu.\n\nensurer\n\nEnsure values at runtime. Author: Stefan Holst Milton Bache.\n\nenviPick\n\nPeak picking for high resolution mass spectrometry data. Author:\nMartin Loos.\n\nepi2loc\n\nEpistatic and penetrance models for two-locus genetic interactions.\nAuthors: Raymond Walters, Charles Laurin, Gitta Lubke.\n\nepisplineDensity\n\nDensity Estimation with Soft Information by Exponential Epi-splines.\nAuthors: Sam Buttrey, Johannes Royset, and Roger Wets, based on the\nMatlab code of Royset and Wets.\n\nexCon\n\nInteractive Exploration of Contour Data. Authors: Bryan Hanson\n[aut, cre], Kristina Mulry [ctb].\n\nextlasso\n\nMaximum penalized likelihood estimation with extended lasso penalty.\nAuthors: B N Mandal and Jun Ma.\n\nfalsy\n\nDefine truthy and falsy values. Author: Gabor Csardi [aut, cre].\n\nfilenamer\n\nEasy Management of File Names. Author: David J. H. Shih.\n\nflam\n\nFits Piecewise Constant Models with Data-Adaptive Knots. Author:\nAshley Petersen.\n\nforestplot\n\nAdvanced Forest Plot Using grid Graphics. Authors: Max Gordon [aut,\ncre], Thomas Lumley [aut, ctb].\n\nfrmhet\n\nRegression Analysis of Fractional Responses Under Unobserved\nHeterogeneity. Author: Joaquim J.S. Ramalho.\n\nfueleconomy\n\nEPA fuel economy data. Author: Hadley Wickham [aut, cre].\n\nfunFEM\n\nClustering in the Discriminative Functional Subspace. Author:\nCharles Bouveyron. In view:\nCluster.\n\nfunHDDC\n\nModel-based clustering in group-specific functional subspaces.\nAuthors: C. Bouveyron and J. Jacques. In view:\nCluster.\n\nfuzzyMM\n\nMap Matching Using Fuzzy Logic. Author: Nikolai Gorte.\n\ngCat\n\nGraph-based two-sample tests for categorical data. Authors: Hao Chen\nand Nancy R. Zhang.\n\ngapmap\n\nFunctions for Drawing Gapped Cluster Heatmap with ggplot2. Author:\nRyo Sakai.\n\ngeesmv\n\nModified Variance Estimators for Generalized Estimating Equations.\nAuthor: Ming Wang.\n\ngemmR\n\nGeneral Monotone Model. Authors: Jeffrey Chrabaszcz [aut, cre],\nJoe Tidwell [aut], Michael Dougherty [aut].\n\ngender\n\nPredict Gender from Names Using Historical Data. Authors: Lincoln\nMullen [aut, cre], Cameron Blevins [ctb], Ben Schmidt [ctb].\n\ngenpathmox\n\nGeneralized PATHMOX Algorithm for PLS-PM, LS and LAD Regression.\nAuthor: Giuseppe Lamberti [aut, cre].\n\ngeoBayes\n\nAnalysis of geostatistical data using Bayes and empirical Bayes\nmethods. Authors: Evangelos Evangelou, Vivekananda Roy.\n\ngeocodeHERE\n\nWrapper for Nokia’s HERE Geocoding API. Author: Cory Nissen [aut,\ncre].\n\ngets\n\nGeneral-to-Specific (GETS) Modelling and Indicator Saturation\nMethods. Authors: Felix Pretis, James Reade, Genaro Sucarrat. In\nview: TimeSeries.\n\nggRandomForests\n\nVisually Exploring Random Forests. Author: John Ehrlinger.\n\nggswissmaps\n\nOffers Various Swiss Maps as ggplot2 Objects. Author: Sandro\nPetrillo Burri.\n\ngimme\n\nGroup Iterative Multiple Model Estimation. Author: Stephanie Lane.\n\nglmvsd\n\nVariable Selection Deviation (VSD) Measures and Instability Tests\nfor High-dimensional Generalized Linear Models. Authors: Ying Nan,\nYi Yang, Yuhong Yang.\n\ngmailr\n\nAccess the Gmail RESTful API. Author: Jim Hester. In view:\nWebTechnologies.\n\ngridGraphics\n\nRedraw Base Graphics Using grid Graphics. Author: Paul Murrell\n[cre, aut].\n\ngrowfunctions\n\nBayesian non-parametric dependent models for time-indexed functional\ndata. Author: Terrance Savitsky.\n\nhcp\n\nChange Point Estimation for Regression with Heteroscedastic Data.\nAuthors: Stephen J. Ganocy, Jiayang Sun, and Yulei Wang.\n\nheritability\n\nMarker-based Estimation of Heritability Using Individual Plant or\nPlot Data. Authors: Willem Kruijer, with a contribution from Ian\nWhite. Contains data collected by Padraic Flood and Rik Kooke.\n\nhermite\n\nGeneralized Hermite Distribution. Authors: David Moriña, Manuel\nHigueras and Pedro Puig.\n\nhglm.data\n\nData for The hglm Package. Authors: Xia Shen, Moudud Alam, Lars\nRonnegard.\n\nhighD2pop\n\nTwo-Sample Tests for Equality of Means in High Dimension. Author:\nKarl Gregory.\n\nhighTtest\n\nSimultaneous Critical Values for \\(t\\)-Tests in Very High Dimensions.\nAuthors: Hongyuan Cao [aut], Michael Kosorok [aut], Shannon\nHolloway [aut, cre].\n\nhillmakeR\n\nPerform occupancy analysis. Author: David Gilinson.\n\nhistorydata\n\nData Sets for Historians. Author: Lincoln Mullen [aut, cre].\n\nhnp\n\nHalf-Normal Plots with Simulation Envelopes. Authors: Rafael de\nAndrade Moral [aut, cre], John Hinde [aut], Clarice Garcia\nBorges Demetrio [aut].\n\nhot.deck\n\nMultiple Hot-deck Imputation. Authors: Skyler Cranmer, Jeff Gill,\nNatalie Jackson, Andreas Murr, Dave Armstrong.\n\nhpcwld\n\nHigh Performance Cluster Models Based on Kiefer-Wolfowitz Recursion.\nAuthor: Alexander Rumyantsev [aut, cre].\n\nhtmlTable\n\nAdvanced Tables for Markdown/HTML. Author: Max Gordon.\n\nhtmlwidgets\n\nHTML Widgets for R. Authors: Ramnath Vaidyanathan, Joe Cheng, JJ\nAllaire, Yihui Xie, and Kenton Russell.\n\nhydrostats\n\nHydrologic indices for daily time series data. Author: Nick Bond.\n\niBATCGH\n\nIntegrative Bayesian Analysis of Transcriptomic and CGH data.\nAuthor: Alberto Cassese.\n\niFes\n\nIncremental Feature Selection Algorithm accelerated by GPU. Authors:\nQinghan Meng, Fengfeng Zhou.\n\nibeemd\n\nIrregular-lattice based ensemble empirical mode decomposition.\nAuthor: Maogui Hu.\n\nibelief\n\nImplementing Belief Functions. Author: Kuang Zhou; Arnaud Martin.\n\nibmdbR\n\nIBM In-Database Analytics for R. Author: IBM Corporation.\n\nica\n\nIndependent Component Analysis. Author: Nathaniel E. Helwig.\n\nicamix\n\nEstimation of ICA Mixture Models. Authors: Xiaotian Zhu, David R.\nHunter.\n\niccbeta\n\nMultilevel model intraclass correlation for slope heterogeneity.\nAuthors: Steven Andrew Culpepper [aut, cph, cre], Herman Aguinis\n[aut, cph].\n\niki.dataclim\n\nConsistency, Homogeneity and Summary Statistics of Climatological\nData. Author: Boris Orlowsky.\n\nilc\n\nLee-Carter Mortality Models using Iterative Fitting Algorithms.\nAuthors: Zoltan Butt, Steven Haberman and Han Lin Shang.\n\nimputeLCMD\n\nA collection of methods for left-censored missing data imputation.\nAuthor: Cosmin Lazar.\n\ninTrees\n\nInterpret Tree Ensembles. Author: Houtao Deng.\n\nindicoio\n\nA simple R Wrapper for the indico set of APIs. Author: Alexander\nGedranovich. In view:\nWebTechnologies.\n\ninsuranceData\n\nA Collection of Insurance Datasets Useful in Risk Classification in\nNon-life Insurance. Authors: Alicja Wolny–Dominiak and Michal\nTrzesiok.\n\ninterAdapt\n\nA shiny application for designing adaptive clinical trials Authors:\nAaron Fisher, Michael Rosenblum, Harris Jaffee.\n\ninterpretR\n\nBinary Classifier Interpretation Functions. Authors: Michel Ballings\nand Dirk Van den Poel.\n\nionflows\n\nCalculate the Number of Required Flows for Semiconductor Sequencing.\nAuthors: Michael Bockmayr and Jan Budczies.\n\niosmooth\n\nFunctions for smoothing with infinite order flat-top kernels.\nAuthors: Timothy L. McMurry, Dimitris N. Politis.\n\nips\n\nInterfaces to Phylogenetic Software in R. Author: Christoph Heibl.\n\nitertools2\n\nFunctions creating iterators for efficient looping. Authors: John A.\nRamey, Kayla Schaefer.\n\nivprobit\n\nInstrumental variables probit model. Author: Zaghdoudi Taha.\n\njSonarR\n\njSonar Analytics Platform API for R. Author: jSonar Inc. In view:\nWebTechnologies.\n\njiebaR\n\nChinese Text Segmentation. Authors: Qin Wenfeng, and the authors of\nCppJieba for the included version of CppJieba.\n\njomo\n\nMultilevel Joint Modelling Multiple Imputation. Authors: Matteo\nQuartagno, James Carpenter.\n\nknockoff\n\nKnockoff Filter. Authors: Rina Foygel Barber, Emmanuel Candes, Evan\nPatterson.\n\nkofnGA\n\nA genetic algorithm for fixed-size subset selection. Author: Mark A.\nWolters.\n\nkpodclustr\n\nMethod for Clustering Partially Observed Data. Authors: Jocelyn T.\nChi [aut, cre], Eric C. Chi [ctb].\n\nkselection\n\nSelection of \\(k\\) in \\(k\\)-means clustering. Author: Daniel Rodriguez\nPerez.\n\nlakemorpho\n\nLake morphometry in R. Author: Jeffrey W. Hollister [aut, cre].\n\nlandpred\n\nLandmark Prediction of a Survival Outcome. Author: Layla Parast.\n\nlazyeval\n\nLazy (Non-Standard) Evaluation. Authors: Hadley Wickham [aut,\ncre], RStudio [cph].\n\nlbfgs\n\nLimited-memory BFGS Optimization. Authors: Antonio Coppola [aut,\ncre, cph], Brandon Stewart [aut, cph], Naoaki Okazaki [aut,\ncph], David Ardia [ctb, cph], Dirk Eddelbuettel [ctb, cph],\nKatharine Mullen [ctb, cph], Jorge Nocedal [ctb, cph]. In view:\nOptimization.\n\nleaderCluster\n\nLeader Clustering Algorithm. Author: Taylor B. Arnold.\n\nlefse\n\nPhylogenetic and Functional Analyses for Ecology. Author: Nathan G.\nSwenson.\n\nlintr\n\nStatic R Code Analysis. Author: Jim Hester [aut, cre].\n\nlm.beta\n\nAdd Standardized Regression Coefficients to lm-Objects. Author:\nStefan Behrendt [aut, cre].\n\nlmeVarComp\n\nTesting for a subset of variance components in linear mixed models.\nAuthor: Yichi Zhang.\n\nlmenssp\n\nLinear Mixed Effects Models with Non-stationary Stochastic\nProcesses. Authors: Ozgur Asar, Peter J. Diggle.\n\nlmmot\n\nMultiple Ordinal Tobit (MOT) model. Author: Marvin N. Wright.\n\nlogbin\n\nRelative Risk Regression Using the Log Binomial Model. Author: Mark\nDonoghoe.\n\nlogconPH\n\nCoxPH Model with Log Concave Baseline Distribution. Author: Clifford\nAnderson-Bergman.\n\nlogitchoice\n\nFitting \\(L_2\\)-regularized logit choice models via generalized\ngradient descent. Author: Michael Lim.\n\nlpme\n\nLocal Polynomial Estimator in Measurement Error Models. Authors:\nHaiming Zhou and Xianzheng Huang.\n\nlucid\n\nLucid Printing of Floating Point Numbers. Author: Kevin Wright.\n\nlunar\n\nLunar Phase & Distance, Seasons and Other Environmental Factors.\nAuthor: Emmanuel Lazaridis [aut, cre].\n\nlvm4net\n\nLatent Variable Models for Networks. Author: Isabella Gollini.\n\nm4fe\n\nModels for Financial Economics. Author: Nathan Esau.\n\nmaboost\n\nBinary and Multiclass Boosting Algorithms. Author: Tofigh Naghibi.\n\nmads\n\nMulti-Analysis Distance Sampling. Author: Laura Marshall.\n\nmanagelocalrepo\n\nManage a CRAN-style Local Repository. Author: Imanuel Costigan.\n\nmanipulate\n\nInteractive Plots for RStudio. Authors: JJ Allaire [aut, cre] (R\ninterface), RStudio [cph].\n\nmatR\n\nMetagenomics Analysis Tools for R. Authors: Daniel Braithwaite\n[aut, cre], Kevin Keegan [aut], University of Chicago [cph].\n\nmatchingMarkets\n\nAnalysis of stable matchings. Author: Thilo Klein.\n\nmatpow\n\nmatrix powers. Authors: Norm Matloff, Jack Norman.\n\nmcc\n\nMoment Corrected Correlation. Author: Yi-Hui Zhou.\n\nmdscore\n\nImproved Score Tests for Generalized Linear Models. Authors: Antonio\nHermes M. da Silva-Junior [aut, cre], Damiao N. da Silva [aut],\nSilvia L. P. Ferrari [ctb].\n\nmdsdt\n\nFunctions for Analysis of Data with General Recognition Theory.\nAuthors: Robert X.D. Hawkins, Joe Houpt, Noah Silbert, Leslie Blaha,\nThomas D. Wickens.\n\nmeasuRing\n\nDetection and Control of Tree-Ring Widths on Scanned Image Sections\nof Dendrochronological Samples. Authors: Wilson Lara, Carlos Sierra.\n\nmedflex\n\nFlexible Mediation Analysis using Natural Effect Models. Authors:\nJohan Steen [aut, cre], Tom Loeys [aut], Beatrijs Moerkerke\n[aut], Stijn Vansteelandt [aut], Joris Meys [ctb] (technical\nsupport), Theis Lange [ctb] (valuable suggestions).\n\nmegaptera\n\nMEGAPhylogeny Techniques in R. Author: Christoph Heibl.\n\nmetaMix\n\nBayesian Mixture Analysis for Metagenomic Community Profiling.\nAuthor: Sofia Morfopoulou.\n\nmetafolio\n\nMetapopulation simulations for conserving salmon through portfolio\noptimization. Authors: Sean C. Anderson [aut, cre], Jonathan W.\nMoore [ctb], Michelle M. McClure [ctb], Nicholas K. Dulvy\n[ctb], Andrew B. Cooper [ctb].\n\nmetaplus\n\nRobust meta-analysis and meta-regression. Author: Ken Beath. In\nview:\nMetaAnalysis.\n\nmeteoForecast\n\nNumerical Weather Predictions. Authors: Oscar Perpinan Lamigueiro\n[cre, aut], Marcelo Pinho Almeida [ctb]. In view:\nWebTechnologies.\n\nmfblock\n\nFitting and Simulation of a block multifactor model. Author: Marc\nFortier.\n\nmicropan\n\nMicrobial Pan-genome Analysis. Authors: Lars Snipen and Kristian\nHovde Liland.\n\nminiCRAN\n\nTools to create an internally consistent, mini version of CRAN with\nselected packages only. Authors: Revolution Analytics [aut],\nAndrie de Vries [aut, cre].\n\nmipfp\n\nMultidimensional Iterative Proportional Fitting. Authors: Johan\nBarthelemy [aut, cre], Thomas Suesse [aut], Mohammad Namazi-Rad\n[ctb].\n\nmirtCAT\n\nComputerized Adaptive Testing with Multidimensional Item Response\nTheory. Author: Phil Chalmers [aut, cre, cph]. In view:\nPsychometrics.\n\nmkde\n\n2D and 3D movement-based kernel density estimates (MKDEs). Authors:\nJeff A. Tracey, James Sheppard, Jun Zhu, Robert Sinkovts, Amit\nChourasia, Glenn Lockwood, and Robert N. Fisher. In view:\nSpatioTemporal.\n\nmnormpow\n\nMultivariate Normal Distributions with Power Integrand. Authors:\nAlan Genz [ctb], Adelchi Azzalini [ctb], Alexis Bienvenüe [aut,\ncre], Christian Robert [aut].\n\nmoonBook\n\nFunctions and Datasets for the Book by Keon-Woong Moon. Author:\nKeon-Woong Moon [aut, cre].\n\nmosaicData\n\nProject MOSAIC (mosaic-web.org) data sets. Authors: Randall Pruim,\nDaniel Kaplan, Nicholas Horton.\n\nmp\n\nMultidimensional Projection Techniques. Authors: Francisco M.\nFatore, Samuel G. Fadel.\n\nmpath\n\nRegularized Linear Models. Authors: Zhu Wang, with contributions\nfrom Achim Zeileis, Simon Jackman, Brian Ripley, Trevor Hastie, Rob\nTibshirani, Balasubramanian Narasimhan, Gil Chu and Patrick Breheny.\n\nmpcv\n\nMultivariate Process Capability Vector. Author: Krzysztof Ciupke.\n\nmppa\n\nStatistics for analysing multiple simultaneous point processes on\nthe real line. Authors: Patrick Rubin-Delanchy and Nicholas A Heard.\n\nmsBP\n\nMultiscale Bernstein Polynomials for Densities. Author: Antonio\nCanale.\n\nmsda\n\nMulti-class Sparse Discriminant Analysis. Authors: Qing Mai, Yi\nYang, Hui Zou.\n\nmtk\n\nMexico ToolKit library (MTK). Authors: Juhui Wang [aut, cre]\n(software and engineering), Hervé Monod [aut] (applications and\nstatistical methods), Robert Faivre [ctb] (applications and\nstatistical methods), Hervé Richard [ctb] (software and\nengineering).\n\nmultiband\n\nPeriod Estimation for Multiple Bands. Authors: Eric C. Chi, James P.\nLong.\n\nmultibiplotGUI\n\nMultibiplot Analysis in R. Authors: Ana Belen Nieto Librero, Nora\nBaccala, Purificacion Vicente Galindo, Purificacion Galindo\nVillardon.\n\nmultipleNCC\n\nWeighted Cox-regression for nested case-control data. Authors:\nNathalie C. Stoer, Sven Ove Samuelsen. In view:\nSurvival.\n\nmultispatialCCM\n\nMultispatial Convergent Cross Mapping. Author: Adam Clark.\n\nmultiwayvcov\n\nMulti-way Standard Error Clustering. Authors: Nathaniel Graham and\nMahmood Arai and\n\nmusicNMR\n\nConversion of Nuclear Magnetic Resonance spectrum in audio file.\nAuthors: Stefano Cacciatore, Edoardo Saccenti, Mario Piccioli.\n\nmvglmmRank\n\nMultivariate Generalized Linear Mixed Models for Ranking Sports\nTeams. Authors: Andrew T. Karl, Jennifer Broatch.\n\nmvprpb\n\nOrthant Probability of the Multivariate Normal Distribution. Author:\nNoboru Nomura.\n\nmvrtn\n\nMean and Variance of Truncated Normal Distribution. Author: Matthew\nMcLeod.\n\nmwaved\n\nMultichannel wavelet deconvolution with additive long memory noise.\nAuthor: Justin Rory Wishart.\n\nmyTAI\n\nA Framework to Perform Phylotranscriptomics Analyses for\nEvolutionary Developmental Biology Research. Author: Hajk-Georg\nDrost.\n\nmycor\n\nAutomatic Correlation and Regression Test in a Data Frame. Author:\nKeon-Woong Moon [aut, cre].\n\nnabor\n\nWraps libnabo, a fast \\(K\\) Nearest Neighbour library for low\ndimensions. Authors: Stephane Mangenat (for libnabo), Gregory\nJefferis.\n\nnasaweather\n\nCollection of datasets from the ASA 2006 data expo. Author: Hadley\nWickham [aut, cre].\n\nnat.nblast\n\nNeuroAnatomy Toolbox (nat) Extension for Assessing Neuron\nSimilarity and Clustering. Authors: Greg Jefferis and James Manton.\n\nnat.templatebrains\n\nNeuroAnatomy Toolbox (nat) Extension for Handling Template Brains.\nAuthors: James Manton and Greg Jefferis.\n\nnetgsa\n\nNetwork-based Gene Set Analysis. Authors: Ali Shojaie and Jing Ma.\n\nnettools\n\nA Network Comparison Framework. Authors: Michele Filosi [aut,\ncre], Roberto Visintainer [aut], Samantha Riccadonna [aut],\nGiuseppe Jurman [ctb], Cesare Furlanello [ctb].\n\nnetworkD3\n\nTools for Creating D3 JavaScript Network Graphs from R. Authors:\nChristopher Gandrud, J.J. Allaire, and B.W. Lewis.\n\nnicheROVER\n\n(Niche) (R)egion and Niche (Over)lap Metrics for Multidimensional\nEcological Niches. Authors: Martin Lysy [aut, cre], Ashley D.\nStasko [aut, ctb], Heidi K. Swanson [aut, ctb].\n\nnlWaldTest\n\nWald Test of nonlinear restrictions for regression parameters.\nAuthor: Oleh Komashko.\n\nnlsem\n\nFitting Structural Equation Mixture Models. Authors: Nora Umbach\n[aut, cre], Katharina Naumann [aut], David Hoppe [aut], Holger\nBrandt [aut], Augustin Kelava [ctb], Bernhard Schmitz [ctb].\n\nnodiv\n\nCompares the Distribution of Sister Clades Through a Phylogeny.\nAuthor: Michael Krabbe Borregaard.\n\nnonnest2\n\nTests of Non-nested Models. Authors: Edgar C. Merkle and Dongjun\nYou. In view:\nEconometrics.\n\nnontargetData\n\nQuantized simulation data of isotope pattern centroids. Authors:\nMartin Loos, Francesco Corona.\n\nnpsm\n\nNonparametric Statistical Methods using R. Authors: John Kloke,\nJoseph McKean.\n\nnscancor\n\nNon-Negative and Sparse CCA. Authors: Christian Sigg [aut, cre], R\nCore team [aut].\n\nnsgp\n\nNon-Stationary Gaussian Process Regression. Author: Markus Heinonen.\n\nnycflights13\n\nData about flights departing NYC in 2013. Author: Hadley Wickham\n[aut, cre].\n\noaxaca\n\nBlinder-Oaxaca decomposition. Author: Marek Hlavac.\n\nocc\n\nEstimates PET neuroreceptor occupancies. Author: Joaquim Radua. In\nview:\nMedicalImaging.\n\nonlinePCA\n\nOnline Principal Component Analysis. Author: David Degras.\n\nopenssl\n\nBindings to OpenSSL. Author: Jeroen Ooms.\n\nopentraj\n\nTools for Creating and Analysing Air Trajectory Data. Author:\nThalles Santos Silva.\n\noptiscale\n\nOptimal scaling. Author: William G. Jacoby.\n\noptrees\n\nOptimal Trees in Weighted Graphs. Author: Manuel Fontenla [aut,\ncre].\n\norderedLasso\n\nOrdered Lasso and Time-lag Sparse Regression. Authors: Jerome\nFriedman, Xiaotong Suo and Robert Tibshirani. In view:\nTimeSeries.\n\nordinalgmifs\n\nOrdinal Regression for High-dimensional Data. Authors: Kellie J.\nArcher, Jiayi Hou, Qing Zhou, Kyle Ferber, John G. Layne, Amanda\nGentry.\n\nore\n\nAn R Interface to the Oniguruma Regular Expression Library. Authors:\nJon Clayden, based on Onigmo by K. Kosako and K. Takata.\n\norgR\n\nAnalyse Text Files Created by Emacs’ Org mode. Author: Yi Tang.\n\npBrackets\n\nPlot Brackets. Author: Andreas Schulz.\n\npRSR\n\nTest of periodicity using response surface regression. Author: M. S.\nIslam.\n\npackrat\n\nA Dependency Management System for Projects and their R Package\nDependencies. Authors: Kevin Ushey, Jonathan McPherson, Joe Cheng,\nJJ Allaire.\n\npanelaggregation\n\nAggregate Longitudinal Survey Data. Authors: Matthias Bannert [aut,\ncre], Gabriel Bucur [aut].\n\nparsedate\n\nRecognize and Parse Dates in Various Formats, Including All ISO 8601\nFormats. Authors: Gabor Csardi, Linus Torvalds.\n\npauwels2014\n\nBayesian Experimental Design for Systems Biology. Author: Edouard\nPauwels.\n\npdR\n\nthreshold regression and unit root test in panel data. Author: Ho\nTsung-wu.\n\npedometrics\n\nPedometric Tools and Techniques. Authors: Alessandro Samuel-Rosa\n[aut, cre], Lucia Helena Cunha dos Anjos [ths], Gustavo de\nMattos Vasques [ths], Gerard B. M. Heuvelink [ths], Tony Olsen\n[ctb], Tom Kincaid [ctb], Juan Carlos Ruiz Cuetos [ctb], Maria\nEugenia Polo Garcia [ctb], Pablo Garcia Rodriguez [ctb], Edzer\nPebesma [ctb], Jon Skoien [ctb], Joshua French [ctb].\n\npenMSM\n\nEstimating regularized multistate models using \\(L_1\\) penalties.\nAuthor: Holger Reulen. In view:\nSurvival.\n\npez\n\nPhylogenetics for the Environmental Sciences. Authors: William D.\nPearse, Marc W. Cadotte, Jeannine Cavender-Bares, Caroline Tucker,\nSteve C. Walker, Matthew R. Helmus.\n\nphylin\n\nSpatial interpolation of genetic data. Authors: Pedro Tarroso,\nGuillermo Velo-Anton, Silvia Carvalho.\n\npicasso\n\nPathwise Calibrated Sparse Shooting Algorithm. Authors: Xingguo Li,\nTuo Zhao and Han Liu.\n\npingr\n\nCheck If a Remote Computer is Up. Author: Gabor Csardi [aut, cre].\n\nplotROC\n\nGenerate Useful ROC Curve Charts for Print and Interactive Use.\nAuthor: Michael C Sachs.\n\npointdensityP\n\nPoint density for geospatial data. Authors: Paul Evangelista and\nDave Beskow.\n\npolidata\n\nPolitical Data Interface in R. Authors: Eunjeong Park [aut, cre],\nJong Hee Park [aut]. In view:\nWebTechnologies.\n\npopKorn\n\nFor interval estimation of mean of selected populations. Authors:\nVik Gopal, Claudio Fuentes.\n\npoplite\n\nTools for simplifying the population and querying of SQLite\ndatabases. Author: Daniel Bottomly.\n\npowerr\n\nAnalysis of Power System. Author: Jingfan Sun [aut, cre].\n\nprc\n\nPaired Response Curve. Author: Youyi Fong.\n\npredictmeans\n\nCalculate Predicted Means for Linear Models. Authors: Dongwen Luo,\nSiva Ganesh and John Koolaard.\n\npreseqR\n\nPredicting Species Accumulation. Authors: Chao Deng, Timothy Daley\nand Andrew D. Smith.\n\nprettyunits\n\nPretty, Human Readable Formatting of Quantities. Author: Gabor\nCsardi [aut, cre].\n\npropOverlap\n\nFeature (gene) selection based on the Proportional Overlapping\nScores. Authors: Osama Mahmoud, Andrew Harrison, Aris Perperoglou,\nAsma Gul, Zardad Khan, Berthold Lausen.\n\nproteomics\n\nStatistical Analysis of High Throughput Proteomics Data. Author:\nThomas W. D.\n\npryr\n\nTools for computing on the language. Authors: Hadley Wickham [aut,\ncre], R Core Team [ctb].\n\npxweb\n\nR interface to the PX-Web/PC-Axis API. Authors: Mans Magnusson, Leo\nLahti, Love Hansson. In view:\nWebTechnologies.\n\nqdapRegex\n\nRegular Expression Removal, Extraction, and Replacement Tools.\nAuthors: Jason Gray [ctb], Tyler Rinker [aut, cre].\n\nqdm\n\nFitting a Quadrilateral Dissimilarity Model to Same-Different\nJudgments. Authors: Nora Umbach [aut, cre], Florian Wickelmaier\n[aut].\n\nqgtools\n\nTools for Quantitative Genetics Data Analyses. Authors: Jixiang Wu,\nJohnie N. Jenkins and Jack C. McCarty.\n\nqicharts\n\nQuality Improvement Charts. Authors: Jacob Anhoej [aut, cre], Timo\nRoeder [ctb].\n\nqqtest\n\nQuantile Quantile Plots Self Calibrating For Visual Testing. Author:\nWayne Oldford [aut, cre].\n\nquad\n\nExact permutation moments of quadratic form statistics. Author:\nYi-Hui Zhou.\n\nqualCI\n\nCausal Inference with Qualitative and Ordinal Information on\nOutcomes. Authors: Konstantin Kashin, Adam Glynn, Nahomi Ichino.\n\nrARPACK\n\nR wrapper of ARPACK for large scale eigenvalue/vector problems, on\nboth dense and sparse matrices. Authors: Yixuan Qiu, Jiali Mei and\nauthors of the ARPACK library. In view:\nNumericalMathematics.\n\nrDEA\n\nRobust Data Envelopment Analysis (DEA) for R. Authors: Jaak Simm\n[aut, cre], Galina Besstremyannaya [aut].\n\nrFDSN\n\nGet Seismic Data from the International Federation of Digital\nSeismograph Networks. Author: Daniel C. Bowman [aut, cre]. In\nview:\nWebTechnologies.\n\nrJPSGCS\n\nR-interface to Gene Drop Simulation from JPSGCS. Authors: Sigal Blay\n[aut], Jinko Graham [aut], Brad McNeney [aut, cre], Annick\nNembot-Simo [aut], Alun Thomas [ctb], Hin-Tak Leung [ctb].\n\nrPref\n\nRoutines to select and visualize the maxima for a given strict\npartial order. Author: Patrick Roocks.\n\nrSPACE\n\nSpatially-Explicit Power Analysis for Conservation and Ecology.\nAuthors: Martha Ellis, Jake Ivan, Jody Tucker, Mike Schwartz.\n\nrYoutheria\n\nAccess to the YouTheria mammal trait database. Author: Tom August.\nIn view:\nWebTechnologies.\n\nradar\n\nFundamental Formulas for Radar. Authors: Jose’ Gama [aut, cre],\nNick Guy [aut].\n\nrappdirs\n\nApplication directories: determine where to save data, caches and\nlogs. Authors: Hadley Wickham [trl, cre, cph], RStudio [cph],\nSridhar Ratnakumar [aut], Trent Mick [aut], ActiveState [cph],\nEddy Petrisor [ctb], Trevor Davis [trl, aut], Gabor Csardi\n[ctb], Gregory Jefferis [ctb].\n\nrareGE\n\nTesting Gene-Environment Interaction for Rare Genetic Variants.\nAuthor: Han Chen.\n\nrcbalance\n\nLarge, Sparse Optimal Matching with Refined Covariate Balance.\nAuthor: Samuel D. Pimentel.\n\nrcicr\n\nReverse correlation image classification toolbox. Author: Ron\nDotsch.\n\nrclinicaltrials\n\nDownload Aggregate Trial Information and Results from\nClinicalTrials.gov. Author: Michael C Sachs. In view:\nWebTechnologies.\n\nrcrossref\n\nR Client for Various CrossRef APIs. Authors: Carl Boettiger [aut],\nTed Hart [aut], Scott Chamberlain [aut, cre], Karthik Ram\n[aut].\n\nreconstructr\n\nSession Reconstruction and Analysis. Author: Oliver Keyes.\n\nrecosystem\n\nRecommender System using Matrix Factorization. Authors: Yixuan Qiu,\nChih-Jen Lin, Yu-Chin Juan, Yong Zhuang, Wei-Sheng Chin and other\ncontributors.\n\nredcapAPI\n\nR interface to REDCap. Authors: Benjamin Nutter. Initiated by\nJeffrey Horner and Will Gray with contributions from Jeremy\nStephens, and Will Beasley. In view:\nWebTechnologies.\n\nrefset\n\nSubsets with Reference Semantics. Author: David Hugh-Jones.\n\nrefund.wave\n\nWavelet-Domain Regression with Functional Data. Authors: Lan Huo,\nPhilip Reiss and Yihong Zhao.\n\nregexr\n\nReadable Regular Expressions. Author: Tyler Rinker [aut, cre].\n\nremote\n\nEmpirical Orthogonal Teleconnections in R. Authors: Tim Appelhans,\nFlorian Detsch, Thomas Nauss.\n\nreplicationInterval\n\nReplication Interval Functions. Author: David Stanley.\n\nrepra\n\nRenewable Energy Probability Resource Assessment Tool (REPRA).\nAuthors: Eduardo Ibanez [aut, cre], National Renewable Energy\nLaboratory [cph].\n\nretistruct\n\nRetinal Reconstruction Program. Authors: David C. Sterratt [aut,\ncre, cph], Daniel Lyngholm [aut, cph].\n\nrex\n\nFriendly Regular Expressions. Authors: Kevin Ushey [aut], Jim\nHester [cre, aut].\n\nrfUtilities\n\nRandom Forests model selection and performance evaluation. Authors:\nJeffrey S. Evans [aut, cre], Melanie A. Murphy [aut].\n\nrfoaas\n\nR Interface to FOAAS. Author: Dirk Eddelbuettel.\n\nrfordummies\n\nCode examples to accompany the book “R for Dummies”. Authors: Andrie\nde Vries [aut, cre], Joris Meys [aut].\n\nriskSimul\n\nRisk Quantification for Stock Portfolios under the \\(t\\)-Copula Model.\nAuthors: Wolfgang Hormann, Ismail Basoglu. In view:\nFinance.\n\nrivernet\n\nRead, Analyze and Plot River Networks. Author: Peter Reichert.\n\nrjstat\n\nRead and write JSON-stat data sets. Authors: Aaron Schumacher, Håkon\nMalmedal.\n\nrkvo\n\nRead Key/Value Pair Observations. Author: Vehbi Sinan Tunalioglu\n[aut, cre].\n\nrmarkdown\n\nDynamic Documents for R. Authors: JJ Allaire, Jonathan McPherson,\nYihui Xie, Hadley Wickham, Joe Cheng, Jeff Allen.\n\nrnaseqWrapper\n\nWrapper for several R packages and scripts to automate RNA-seq\nanalysis. Author: Mark Peterson.\n\nrnbn\n\nAccess NBN Data. Authors: Stuart Ball and Tom August. In view:\nWebTechnologies.\n\nrncl\n\nAn interface to the Nexus Class Library. Authors: Francois\nMichonneau [aut, cre], Ben Bolker [aut], Mark Holder [aut,\ncre], Paul Lewis [aut, cre], Brian O’Meara [aut, cre].\n\nrnrfa\n\nUK National River Flow Archive data from R. Authors: Claudia Vitolo,\nMatthew Fry. In view:\nWebTechnologies.\n\nrobustDA\n\nRobust Mixture Discriminant Analysis. Authors: Charles Bouveyron and\nStephane Girard. In view:\nRobust.\n\nrobustvarComp\n\nRobust Estimation of Variance Component Models. Authors: Claudio\nAgostinelli and Victor J. Yohai.\n\nrodd\n\nOptimal Discriminating Designs. Author: Roman Guchenko [aut, cre].\n\nropensecretsapi\n\nInterface for the OpenSecrets.org API. Author: Thomas P. Fuller. In\nview:\nWebTechnologies.\n\nrowr\n\nRow-based functions for R objects. Author: Craig Varrichio.\n\nrpg\n\nEasy interface to advanced PostgreSQL features. Author: Timothy H.\nKeitt.\n\nrplexos\n\nRead and Analyze PLEXOS Solutions from R. Authors: Eduardo Ibanez\n[aut, cre], National Renewable Energy Laboratory [cph].\n\nrqPen\n\nPenalized Quantile Regression. Author: Ben Sherwood.\n\nrsdmx\n\nTools for Reading SDMX Data and Metadata. Authors: Emmanuel Blondel\n[aut, cre], Matthieu Stigler [ctb]. In view:\nWebTechnologies.\n\nrsml\n\nPlant Root System Markup Language (RSML) File Processing. Author:\nGuillaume Lobet.\n\nrstackdeque\n\nPersistent Fast Amortized Stack and Queue Data Structures. Author:\nShawn T. O’Neil.\n\nrsubgroup\n\nSubgroup Discovery and Analytics. Author: Martin Atzmueller.\n\nrsunlight\n\nInterface to Sunlight Foundation APIs. Authors: Scott Chamberlain\n[aut, cre], Thomas J. Leeper [ctb]. In view:\nWebTechnologies.\n\nrtdists\n\nResponse time distributions. Authors: Scott Brown [aut], Matthew\nGretton [aut], Andrew Heathcote [aut], Andreas Voss [ctb],\nJochen Voss [ctb], Andrew Terry [ctb], Henrik Singmann [aut,\ncre].\n\nrtkpp\n\nSTK++ Integration To R Using Rcpp. Authors: Serge Iovleff [aut,\ncre], Vincent Kubicki [ctb], Quentin Grimonprez [ctb], Parmeet\nBhatia [ctb].\n\nrtype\n\nA strong type system for R. Author: Kun Ren.\n\nrucm\n\nImplementation of Unobserved Components Model (UCM) in R. Author:\nKaushik Roy Chowdhury.\n\nruv\n\nDetect and Remove Unwanted Variation using Negative Controls.\nAuthor: Johann Gagnon-Bartsch.\n\nrvalues\n\nComputation of r-values for ranking in high-dimensional settings.\nAuthors: Nicholas Henderson and Michael Newton.\n\nrvest\n\nEasily Harvest (Scrape) Web Pages. Authors: Hadley Wickham [aut,\ncre], RStudio [cph].\n\nsaccades\n\nDetection of Fixations in Eye-Tracking Data. Author: Titus von der\nMalsburg [aut, cph, cre].\n\nsads\n\nMaximum Likelihood Models for Species Abundance Distributions.\nAuthors: Paulo I. Prado and Murilo Dantas Miranda.\n\nsaeSim\n\nSimulation Tools for Small Area Estimation. Author: Sebastian\nWarnholz.\n\nsaery\n\nSmall Area Estimation for Rao and Yu Model. Authors: Maria Dolores\nEsteban Lefler, Domingo Morales Gonzalez, Agustin Perez Martin.\n\nsafi\n\nSensitivity Analysis for Functional Input. Authors: Jana Fruth,\nMalte Jastrow.\n\nsanitizers\n\nC/C++ source code to trigger Address and Undefined Behaviour\nSanitizers. Author: Dirk Eddelbuettel.\n\nsaps\n\nSignificance Analysis of Prognostic Signatures. Authors: Daniel\nSchmolze [aut, cre], Andrew Beck [aut], Benjamin Haibe-Kains\n[aut].\n\nscrm\n\nSimulating the Evolution of Biological Sequences. Authors: Paul\nStaab [aut, cre, cph], Zhu Sha [aut, cph], Dirk Metzler [aut,\ncph, ths], Gerton Lunter [aut, cph, ths].\n\nsdcTarget\n\nStatistical Disclosure Control Substitution Matrix Calculator.\nAuthor: Emmanuel Lazaridis [aut, cre].\n\nsecrlinear\n\nSpatially Explicit Capture-Recapture for Linear Habitats. Author:\nMurray Efford.\n\nseedy\n\nSimulation of Evolutionary and Epidemiological Dynamics. Author:\nColin Worby.\n\nsegmag\n\nDetermine Event Boundaries in Event Segmentation Experiments.\nAuthors: Frank Papenmeier [aut, cre], Konstantin Sering [ctb].\n\nselectspm\n\nSelect point patterns models based on minimum contrast and AIC.\nAuthor: Marcelino de la Cruz.\n\nselfingTree\n\nGenotype Probabilities in Intermediate Generations of Inbreeding\nThrough Selfing. Authors: Frank Technow [aut, cre].\n\nsensory\n\nSimultaneous Model-Based Clustering and Imputation via a Progressive\nExpectation-Maximization (PEM) algorithm. Authors: Brian C.\nFranczak, Ryan P. Browne and Paul D. McNicholas.\n\nsettings\n\nSoftware Option Settings Manager for R. Author: Mark van der Loo.\n\nshopifyr\n\nAn R Interface to the Shopify API. Author: Charlie Friedemann. In\nview:\nWebTechnologies.\n\nsievetest\n\nSieve test reporting functions. Author: Petr Matousu.\n\nsigloc\n\nSignal Location Estimation. Author: Sergey S. Berg.\n\nsignal.hsmm\n\nPredict Presence of Signal Peptides. Authors: Michal Burdukiewicz\n[cre, aut], Piotr Sobczyk [aut].\n\nsimPop\n\nSimulation of Synthetic Populations for Survey Data Considering\nAuxiliary Information. Authors: Bernhard Meindl, Matthias Templ,\nAndreas Alfons, Alexander Kowarik, with contributions from Mathieu\nRibatet.\n\nsimTool\n\nConduct Simulation Studies with a Minimal Amount of Source Code.\nAuthor: Marsel Scheer.\n\nsimrel\n\nLinear Model Data Simulation and Design of Computer Experiments.\nAuthor: Solve Sæbø.\n\nsisVIVE\n\nSome Invalid Some Valid Instrumental Variables Estimator. Author:\nHyunseung Kang.\n\nsla\n\nTwo-Group Straight Line ANCOVA. Authors: W. Gregory Alvord [aut,\ncre], Nick Carchedi [aut].\n\nslackr\n\nSend messages, images, R objects and files to Slack.com\nchannels/users. Authors: Bob Rudis and Jay Jacobs. In view:\nWebTechnologies.\n\nsld\n\nEstimation and Use of the Quantile-Based Skew Logistic Distribution.\nAuthors: Robert King, Paul van Staden.\n\nslp\n\nDiscrete Prolate Spheroidal (Slepian) Sequence Regression Smoothers.\nAuthors: Wesley Burr, with contributions from Karim Rahim.\n\nsmac\n\nSparse Multi-category Angle-Based Large-Margin Classifiers. Authors:\nChong Zhang, Guo Xian Yau, Yufeng Liu.\n\nsmacpod\n\nStatistical Methods for the Analysis of Case-Control Point Data.\nAuthor: Joshua French.\n\nsmnet\n\nSmoothing For Stream Network Data. Author: Alastair Rushworth.\n\nsmoother\n\nGaussian window smoothing. Author: Nicholas Hamilton.\n\nsnht\n\nStandard Normal Homogeneity Test. Author: Josh Browning.\n\nsnipEM\n\nSnipping methods for robust estimation and clustering. Authors:\nAlessio Farcomeni, Andy Leung.\n\nsnpRF\n\nRandom Forest for SNPs to Prevent X-chromosome SNP Importance Bias.\nAuthors: Fortran original by Leo Breiman and Adele Cutler, R port by\nAndy Liaw and Matthew Wiener. Modifications of randomForest v 4.6-7\nfor SNPs by Greg Jenkins based on a method developed by Stacey\nWinham, Greg Jenkins and Joanna Biernacka.\n\nsnpar\n\nSupplementary Non-parametric Statistics Methods. Author: Debin Qiu.\n\nsns\n\nStochastic Newton Sampler. Authors: Alireza S. Mahani, Asad Hasan,\nMarshall Jiang, Mansour T.A. Sharabiani.\n\nsonicLength\n\nEstimating Abundance of Clones from DNA fragmentation data. Author:\nCharles Berry.\n\nspThin\n\nFunctions for Spatial Thinning of Species Occurrence Records for Use\nin Ecological Models. Authors: Matthew E. Aiello-Lammens, Robert A.\nBoria, Aleksandar Radosavljevic, Bruno Vilela, and Robert P.\nAnderson.\n\nspanr\n\nSearch Partition Analysis. Author: Roger Marshall.\n\nspareserver\n\nClient side load balancing. Author: Gabor Csardi [aut, cre].\n\nspark\n\nSparklines in the R Terminal. Author: Gabor Csardi [aut, cre].\n\nsparseSEM\n\nSparse-aware Maximum Likelihood for Structural Equation Models.\nAuthor: Anhui Huang.\n\nspatialnbda\n\nPerforms spatial NBDA in a Bayesian context. Author: Glenna\nNightingale.\n\nspca\n\nSparse Principal Component Analysis. Author: Giovanni Maria Merola.\n\nspdynmod\n\nSpatio-dynamic wetland plant communities model. Authors: Javier\nMartinez-Lopez, Babak Naimi, Julia Martinez-Fernandez.\n\nspiders\n\nFits predator preferences model. Authors: Edward A. Roualdes and\nSimon Bonner.\n\nspnet\n\nPlotting (social) networks on maps. Authors: Emmanuel Rousseaux,\nMarion Deville.\n\nsprinter\n\nFramework for Screening Prognostic Interactions. Author: Isabell\nHoffmann.\n\nsprm\n\nSparse and Non-Sparse Partial Robust M Regression. Authors: Sven\nSerneels, BASF Corp and Irene Hoffmann.\n\nsptm\n\nSemiParametric Transformation Model Methods. Authors: Youyi Fong,\nKrisztian Sebestyen.\n\nsrd\n\nDraws Scaled Rectangle Diagrams. Author: Roger Marshall.\n\nssd\n\nSample Size Determination (SSD) for Unordered Categorical Data.\nAuthors: Junheng Ma and Jiayang Sun.\n\nssh.utils\n\nLocal and remote system commands with output and error capture.\nAuthor: Sergei Izrailev.\n\nstabs\n\nStability Selection with Error Control. Authors: Benjamin Hofner\n[aut, cre], Torsten Hothorn [aut]. In view:\nMachineLearning.\n\nstatar\n\nTools Inspired by Stata to Clean, Explore and Join Datasets. Author:\nMatthieu Gomez [aut, cre].\n\nstatcheck\n\nExtract statistics from articles and recompute \\(p\\)-values. Authors:\nSacha Epskamp and Michele B. Nuijten.\n\nstatebins\n\nAn alternative to choropleth maps for USA States. Author: Bob Rudis.\n\nstrataG\n\nSummaries and Population Structure Analyses of Haplotypic and\nGenotypic Data. Author: Eric Archer.\n\nsubgroup\n\nMethods for exploring treatment effect heterogeneity in subgroup\nanalysis of clinical trials. Author: I. Manjula Schou.\n\nsubrank\n\nComputes copula using ranks and subsampling. Author: Jerome Collet.\n\nsudokuAlt\n\nTools for Making, Displaying and Spoiling Sudoku Games. Author: Bill\nVenables.\n\nsummarytools\n\nDataframe Summaries, Frequency Tables and Numerical Summaries with\nCustomizable Output. Author: Dominic Comtois.\n\nsurvAccuracyMeasures\n\nEstimate accuracy measures for risk prediction markers from survival\ndata. Authors: Yingye Zheng, Tianxi Cai, and Marshall Brown. In\nview: Survival.\n\nsvgViewR\n\n3D Animated Interactive Visualizations using SVG. Author: Aaron\nOlsen.\n\nsweidnumbr\n\nHandling of Swedish Identity Numbers. Author: Mans Magnusson.\n\nswfscMisc\n\nMiscellaneous Functions for Southwest Fisheries Science Center.\nAuthor: Eric Archer.\n\nsynthpop\n\nGenerating synthetic versions of sensitive microdata for statistical\ndisclosure control. Authors: Beata Nowok, Gillian M Raab and Chris\nDibben.\n\ntcR\n\nData Analysis of T-cell Receptor Repertoires. Authors: Vadim\nNazarov, Mikhail Pogorelyy.\n\ntestthatsomemore\n\nA mocking, stubbing, and file testing framework extending\ntestthat. Author: Robert Krzyzanowski [aut, cre].\n\ntextreg\n\nn-gram Text Regression, aka Concise Comparative Summarization.\nAuthor: Luke Miratrix.\n\nthermocouple\n\nTemperature Measurement with Thermocouples, RTD and IC Sensors.\nAuthor: Jose Gama [aut, cre].\n\ntidyr\n\nEasily Tidy Data with spread() and gather() Functions. Authors:\nHadley Wickham [aut, cre], RStudio [cph].\n\ntimeseriesdb\n\nStore and Organize Time Series in a Database. Author: Matthias\nBannert [aut, cre].\n\ntimma\n\nTarget Inhibition Interaction using Maximization and Minimization\nAveraging. Author: Liye.\n\ntlm\n\nEffects under Linear, Logistic and Poisson Regression Models with\nTransformed Variables. Authors: Jose Barrera-Gomez and Xavier\nBasagana.\n\ntmap\n\nThematic Maps. Author: Martijn Tennekes. In view:\nOfficialStatistics.\n\ntoxtestD\n\nExperimental design for binary toxicity tests. Authors: Nadia Keddig\nand Werner Wosniok.\n\ntraj\n\nTrajectory Analysis. Authors: Marie-Pierre Sylvestre, Dan Vatnik.\n\ntrajectories\n\nClasses and methods for trajectory data. Authors: Edzer Pebesma\n[cre, aut], Benedikt Klus [aut].\n\ntranslateR\n\nBindings for the Google and Microsoft Translation APIs. Authors:\nChristopher Lucas and Dustin Tingley. In view:\nWebTechnologies.\n\ntreatSens\n\nSensitivity analysis for causal inference. Authors: Nicole Bohme\nCarnegie, Masataka Harada, Jennifer Hill.\n\ntreeclim\n\nNumerical calibration of proxy-climate relationships. Authors:\nChristian Zang [aut, cre, cph, trl], Franco Biondi [ctb, cph].\n\ntrimTrees\n\nTrimmed opinion pools of trees in a random forest. Authors: Yael\nGrushka-Cockayne, Victor Richmond R. Jose, Kenneth C. Lichtendahl\nJr. and Huanghui Zeng, based on the source code from the\nrandomForest package by Andy Liaw and Matthew Wiener and on the\noriginal Fortran code by Leo Breiman and Adele Cutler.\n\ntrotter\n\nPseudo-Vectors Containing All Permutations, Combinations and Subsets\nof Objects Taken from a Vector. Author: Richard Ambler.\n\ntsc\n\nLikelihood-ratio Tests for Two-Sample Comparisons. Authors: Yang\nZhao, Albert Vexler, Alan Hutson.\n\ntufterhandout\n\nTufte-style HTML document format for rmarkdown. Author: Michael\nSachs.\n\ntumblR\n\nTumblr API. Author: Andrea Capozio. In view:\nWebTechnologies.\n\ntuple\n\nFind every match, or orphan, duplicate, triplicate, or other\nreplicated values. Author: Emmanuel Lazaridis [aut, cre].\n\ntvd\n\nTotal Variation Denoising. Author: Mark Pinese [aut, cre, cph].\n\nuniftest\n\nTests for Uniformity. Authors: Maxim Melnik, Ruslan Pusev.\n\nunittest\n\nTAP-compliant unit testing. Authors: Jamie Lentin [aut, cre],\nAnthony Hennessey [aut].\n\nurltools\n\nVectorised Tools for URL Handling and Parsing. Author: Oliver Keyes.\n\nuskewFactors\n\nModel-based clustering via mixtures of unrestricted skew-\\(t\\) factor\nanalyzer models. Authors: Paula M. Murray, Ryan P. Browne, and\nPaul D. McNicholas.\n\nvartors\n\nTransform Definition of Variables to R Scripts. Authors: Joris\nMuller [aut, cre], Erik-André Sauleau [ctb].\n\nvcrpart\n\nTree-Based Varying Coefficient Regression for Generalized Linear and\nOrdinal Mixed Models. Authors: Reto Buergin [aut, cre, cph],\nGilbert Ritschard [ctb, ths]. In view:\nMachineLearning.\n\nvdmR\n\nVisual Data Mining Tools for R. Author: Tomokazu Fujino.\n\nvegan3d\n\nStatic and dynamic 3D plots for vegan package. Authors: Jari\nOksanen [aut, cre], Roeland Kindt [aut], Gavin L. Simpson\n[aut].\n\nvetools\n\nTools for Venezuelan Environmental Data. Authors: Andrew\nSajo-Castelli [aut, cre], Desiree Villalta [ctb], Lelys Bravo\n[ctb].\n\nvirtualspecies\n\nGeneration of Virtual Species Distributions. Authors: Boris Leroy\nwith help from C. N. Meynard, C. Bellard and F. Courchamp.\n\nvisova\n\nVisualization of Analysis of Variance. Author: Ali Vala Barbaros.\n\nvudc\n\nVisualization of Univariate Data for Comparison. Author: Csaba\nFarago.\n\nwebutils\n\nUtility Functions for Web Applications. Author: Jeroen Ooms. In\nview:\nWebTechnologies.\n\nwikipediatrend\n\nPublic Subject Attention via Wikipedia Page Access Statistics.\nAuthors: Peter Meissner [aut, cre], R Core team [ctb]. In view:\nWebTechnologies.\n\nwildlifeDI\n\nCalculate Indices of Dynamic Interaction for Wildlife Telemetry\nData. Author: Jed Long. In view:\nSpatioTemporal.\n\nwindex\n\nAnalysing convergent evolution using the Wheatsheaf index. Authors:\nKevin Arbuckle and Amanda Minter.\n\nwrassp\n\nInterface to the ASSP Library. Authors: Raphael Winkelmann [aut,\ncre], Lasse Bombien [aut], Michel Scheffers [aut].\n\nwux\n\nWegener Center Climate Uncertainty Explorer. Authors: Thomas\nMendlik, Georg Heinrich, Andreas Gobiet and Armin Leuprecht.\n\nx.ent\n\neXtraction of ENTity. Authors: Nicolas Turenne, Tien T. Phan.\n\nxgboost\n\neXtreme Gradient Boosting. Authors: Tianqi Chen, Tong He.\n\nxtal\n\nCrystallization Toolset. Authors: Qingan Sun, Xiaojun Li.\n\nztable\n\nZebra-Striped Tables in LaTeX and HTML Formats. Author: Keon-Woong\nMoon [aut, cre].\n\n2 Other changes\nThe following packages were moved to the Archive: ARAMIS, ARTIVA,\nAWS.tools, Ace, AncestryMapper, Animal, BLCOP, BMAmevt,\nBOG, BaSAR, Barnard, BayesPen, BayesQTLBIC, BiomarkeR,\nCCMnet, CFL, CONOR, CONORData, CVD, DRI, DWD, Defaults,\nDevore6, DierckxSpline, ENA, ESPRESSO, EVER, FPDC,\nFRBData, FusedLasso, GOsummaries, HIBAG, HPO.db, HPOSim,\nJJcorr, KsPlot, LargeRegression, MASSI, MCMChybridGP, MFSAS,\nMIfuns, MLEP, MLPAstats, MMST, MVPARTwrap, MVpower,\nMangrove, MiClip, MiscPsycho, MortalitySmooth, NHMMfdr,\nNMRS, Nemenyi, NetPreProc, OneHandClapping, PIN,\nPKmodelFinder, PKtools, POET, PSMix, PamGeneMixed, RAHRS,\nRBerkeley, RC, RDS, RECSO, REGENT, RHmm, RJSONLD,\nRMendeley, RMessenger, RNCBI, RNCBIAxis2Libs, RPPanalyzer,\nRSQLite.extfuns, RSocrata, RSpincalc, RcmdrPlugin.doBy,\nRearrangement, RelativeRisk, Reot, Rgbp, Rgnuplot, Rjms,\nRjmsjars, Rknots, SCEPtERextras, SDBP, SDDA, SRPM,\nSTARSEQ, SesIndexCreatoR, SigTree, SimHap, StVAR,\nStateTrace, StreamingLm, TFDEA, TRIANG, TRIANGG, TSAgg,\nUBCRM, VisuClust, WebDevelopR, aCGH.Spline, acer, anaglyph,\nanoint, ant, attfad, avgrankoverlap, biOps, biOpsGUI,\nbigRR, bigml, bilan, blockTools, bootfs, cacheSweave,\ncacher, capme, cgwtools, changeLOS, colbycol, comorbidities,\ncomplex.surv.dat.sim, confReg, conicfit, csound, cusp,\ndataone, dataonelibs, ddepn, dse1, dse2, easi, edmr,\nem2, emg, emplik2, factas, faisalconjoint, fork,\nfracprolif, gWidgetsWWW, gammSlice, gcExplorer, genomicper,\nglmperm, googlePublicData, gsmaRt, highriskzone, iScreen,\nicomp, ipw, iwtp, jmec, lancet.iraqmortality, latticist,\nldDesign, lmPerm, lmbc, logistiX, logregperm, longclust,\nmalaria.em, margie, marginalmodelplots, maticce, metrumrg,\nmixedQF, mixstock, modelcf, mrdrc, mseq, muRL, multicore,\nmunsellinterpol, mvpart, mvtBinaryEP, nacopula, neuRosim,\nnoia, nordklimdata1, nricens, oposSOM, optmatch,\northogonalsplinebasis, pacose, parspatstat, pcaPA, pcenum,\npfa, pgnorm, phyext, playitbyr, plink, postCP, ppmlasso,\nppstat, processdata, qfa, randomSurvivalForest, rcqp,\nrdyncall, review, rgexf, risaac, rknn, rmmseg4j, rocplus,\nroxygen, rrdf, rrdflibs, rwm, samplesize, scaleboot,\nseqminer, signalextraction, sigora, sltl, speedRlibTF,\nspeedRlibs, sra, ssize.fdr, standGL, sugaR, survBayes,\nsurvJamda, survJamda.data, sweSCB, tilting, transmission,\ntransnet, treelet, varcompci, vcf2geno, vimcom,\nvisualizationTools, waldwolf, wccsom, weathermetrics, wild1,\nxgrid\nThe following packages were resurrected from the Archive: BTSPAS,\nBayesTree, BcDiag, CGP, EstSimPDMP, HDPenReg, HiDimDA,\nLogicForest, MAVTgsa, OrdLogReg, PHYLOGR,\nRcmdrPlugin.FactoMineR, RcmdrPlugin.steepness, RecordLinkage,\nSparseTSCGM, SpatialPack, XLConnectJars, agsemisc, convevol,\necp, evtree, pgmm, rngSetSeed, sensitivityPStrat, sprint,\ntagcloud, tclust\nThe following packages had to be removed: GWAtoolbox, Gmisc,\nLDExplorer, Rdrools, Rdroolsjars, WhopGenome, bstats\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2014-2-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2014-2 issue.",
    "author": [
      {
        "name": "Deepayan Sarkar",
        "url": {}
      }
    ],
    "date": "2014-12-01",
    "categories": [],
    "contents": "\n\nOn behalf of the editorial board, I am pleased to publish Volume 6,\nIssue 2 of the R Journal.\nThe first article in this issue presents a case study illustrating the\nuse of R for analyzing fMRI data. The second article introduces the\ninnovative TableToLongForm package that tries to automate the\npreprocessing of commonly encountered hierarchical tables that are often\ndifficult to convert into machine-readable form. The remaining articles\ndescribe a variety of R packages that make new methods available to the\nR community: Prinsimp to study interesting structures in low\nvariability principal components, phaseR for autonomous ODE Systems,\naccelerometry and nhanesaccel for processing accelerometer data,\nspartan to analyze simulation results, ngspatial for analyzing areal\ndata, sgof for multiple testing problems, bshazard for survival\nanalysis, SMR which implements a set of distribution functions, FLIM\nfor longitudinal studies with missing data, MVN for assessing\nmultivariate normality, qmethod for studying perspectives and\nattitudes using Q methodology, and gset for exact sequential tests of\nequivalence hypotheses. In addition to the usual updates , the News and\nNotes section also contains two conference reports. I hope you enjoy the\nissue.\nWith the end of the year, it is also time for a refresh of the editorial\nboard. Hadley Wickham is leaving the board after a four-year term. As\nwith everything he turns his attention to, Hadley has considerably\nstreamlined the behind-the-scenes operations of the Journal, making life\neasier for the rest of us. We welcome Roger Bivand who is joining the\neditorial board in his place. Publishing this issue is my last act as\nEditor-in-Chief, with Bettina Grün taking over the job for the next\nyear.\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2014-2-r-changes/",
    "title": "Changes in R",
    "description": "The 'Changes in R' article from the 2014-2 issue.",
    "author": [
      {
        "name": "The R Core Team",
        "url": {}
      }
    ],
    "date": "2014-12-01",
    "categories": [],
    "contents": "\n\nCHANGES IN R 3.1.2\n\nNEW FEATURES\nembedFonts() now defaults to format = \"ps2write\" for .ps and\n.eps files. This is available in Ghostscript 9.x (since 2010)\nwhereas the previous default, format = \"pswrite\", was removed in\nGhostscript 9.10.\nFor consistency with [dpqr]norm(), [dp]lnorm(sdlog = 0) model a\npoint mass at exp(mulog) rather than return NaN (for an error).\ncapabilities() now reports if ICU is compiled in for use for\ncollation (it is only actually used if a suitable locale is set for\ncollation, and never for a C locale).\n(OS X only.) Package tcltk checks when loaded if it is linked\nagainst the CRAN X11-based Tcl/Tk and if so that the Tcl/Tk\ncomponent and the X11 libraries are installed. This allows more\ninformative error messages to be given advising the installation of\nthe missing component or of XQuartz.\nThe X11() device and X11-based versions of the data editor and\nviewer (invoked by edit() and View() for data frames and\nmatrices from command-line R) check that the X11 libraries are\ninstalled and if not advises installing XQuartz.\nicuSetCollate() allows locale = \"default\", and locale = \"none\"\nto use OS services rather than ICU for collation.\nEnvironment variable R_ICU_LOCALE can be used to set the default\nICU locale, in case the one derived from the OS locale is\ninappropriate (this is currently necessary on Windows).\nNew function icuGetCollate() to report on the ICU collation locale\nin use (if any).\nutils::URLencode() was updated to use unreserved and reserved\ncharacters from RFC 3986, http://tools.ietf.org/html/rfc3986,\ninstead of RFC 1738.\nunique(warnings()) and c(warnings()) are now supported.\nThe Bioconductor ‘version’ used by setRepositories() now defaults\nto 3.0. (It can be set at runtime via environment variable\nR_BIOC_VERSION.)\n\n\nINSTALLATION and INCLUDED SOFTWARE\nThe configure script reports on the more important\ncapabilities/options which will not be compiled in.\nMore types of external BLAS are recognized by name in that report.\nWhen building R as a shared library, the -L${R_HOME}/lib${R_ARCH}\nflag is placed earlier in the link commands used during installation\nand when packages are installed: this helps ensure that the current\nbuild has priority if an R shared library has already been installed\nby e.g. install-libR in a library mentioned in LDFLAGS (and not\nin ‘your system’s library directory’ as documented). (Wish of\nPR#15790.)\nLaTeX package upquote is no longer required for R’s use of\ninconsolata.\n(Windows only) If both 32 and 64 bit versions of R are installed,\nthe bin/R.exe and bin/Rscript.exe executables now run 64 bit R.\n(To run 32 bit R, overwrite these files with copies of\nbin/i386/Rfe.exe.)\n\n\nUTILITIES\nRunning R CMD check with _R_CHECK_DEPENDS_ONLY_ true now makes\nthe VignetteBuilder packages available even if they are listed in\nSuggests, since they are needed to recognise and process\nnon-Sweave vignettes.\nR CMD check now reports empty importFrom declarations in a\nNAMESPACE file, as these are common errors (writing\nimportFrom(``Pkg``) where import(``Pkg``) was intended).\nR CMD check now by default checks code usage directly on the\npackage namespace without loading and attaching the package and its\nsuggests and enhances. For good practice with packages in the\nSuggests field, see §1.1.3.1 of ‘Writing R Extensions’. For use of\nlazy-data objects in the package’s own code, see ?data.\n\n\nBUG FIXES\ndmultinom() did not handle non-finite probabilities correctly.\nprettyNum(x, zero.print=*) now also works when x contains NAs.\nA longstanding bug exhibited by nlminb() on Windows was traced to\na compiler bug in gcc 4.6.3; a workaround has been put in place.\n(PR#15244 and PR#15914).\nRendering of \\\\command in HTML versions of help pages has been\nimproved: this is particularly evident on the help page for\nINSTALL.\nas.hexmode(x) and as.octmode(x) now behave correctly for some\nnumeric x, e.g., c(NA, 1) or c(1, pi).\ndrop1() failed if the scope argument had no variables to drop.\n(PR#15935)\nedit() (and hence fix()) failed if an object had a non-character\nattribute named \"source\" (an attribute that had been used in R\nprior to version 2.14.0).\ncallGeneric() could fail if the generic had ... as a formal\nargument. (PR#15937).\nForking in package parallel called C entry point exit in the\nchild. This was unsafe (_exit should have been called), and could\nflush stdin of the main R process (seen most often on Solaris).\nAs good practice, stdout is now flushed before forking a child.\nR objects such as list(‘a\\\\b‘ = 1) now print correctly.\ngetAnywhere(\"C_pbinom\") now returns correctly a single object\n(rather than unlisting it).\nThe confint() method for nls() fits failed it these has\nspecified parameter limits despite using an algorithm other than\n\"port\". (PR#15960)\nSubclassing an S4 class failed if the class required arguments to\nthe generator, through its initialize() method.\nremoveSource() did not properly handle expressions containing\narguments that were supplied as missing, e.g. x[i,]. (PR#15957)\nas.environment(list()) now works, and as.list() of such an\nenvironment is now the same as list().\nSeveral tcltk functions failed when run in unusual environments.\n(PR#15970)\noptions(list()) now works (trivially). (PR#15979)\nmerge(<dendrogram>, ..) now works correctly for two ‘independent’\ndendrograms (PR#15648), and still compatibly via adjust = \"auto\"\ne.g. for two branches of an existing dendrogram.\nThe plot method for \"hclust\" objects gets an optional argument\ncheck; When that is true (the default) it checks more carefully\nfor valid input.\n(Windows only) If a user chose to install 64 bit R but not 32 bit R,\nthe bin/R and bin/Rscript executables failed to run. (PR#15981)\nVarious possible buffer overruns have been prevented, and missed\nmemory protection added. (PR#15990)\nRscript no longer passes –args to R when there are no extra\n(“user”) arguments.\nobjects like getClass(\"refClass\")@prototype now print() and\nstr() without error.\nidentical() now also looks at the S4 bit.\nhist(x, breaks) is more robust in adding a small fuzz to few\nbreaks when some are very large. (PR#15988)\nsub() and gsub() did not handle regular expressions like\n\"\\\\s{2,}\" properly if the text contained NA or non-ascii\nelements in a UTF-8 locale. Part of this was due to a bug in the TRE\nlibrary. (PR#16009)\nRShowDoc(\"NEWS\") now displays the PDF version.\nMatrices and arrays with last dimension zero did not print at all or\nincompletely. (PR#16012)\nplot.histogram() and hence hist() now respect the xaxs, yaxs\nand lab graphics parameters. (PR#16021)\nbw.SJ(x) and other bw.*() no longer segfault when x contains\nnon-finite values. (PR#16024)\nR CMD Rd2pdf unintentionally ignored its –os option.\nThe internal method of download.file() was not reporting file\nsizes and progress correctly on files larger than 2GB (inherited\nfrom libxml2). This is corrected for 64-bit builds (32-bit\nplatforms may not support such files, but where possible will be\nsupported in future versions of R).\nWork around a bug in OS X Yosemite where key environment variables\nmay be duplicated causing issues in subprocesses. The duplicates are\nnow removed on R startup (via Rprofile). (PR#16042)\nAdjust X11 auto-launch detection in DISPLAY on OS X to recognize\nlatest XQuartz.\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2014-2-r-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2014-2 issue.",
    "author": [
      {
        "name": "Martin Mächler",
        "url": {}
      },
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2014-12-01",
    "categories": [],
    "contents": "\n\n1 New R Foundation board\nSubsequent to meetings of the R Foundation in the summer of 2014, and\nafter a careful nomination and voting process, the election of a new\nboard of the R Foundation was finalized on December 1. The new board\nconsists of\nPresidents:\n\nDuncan Murdoch, Martyn Plummer\n\nSecretary General:\n\nMartin Mächler\n\nTreasurer:\n\nKurt Hornik\n\nMembers at Large:\n\nJohn Chambers, Brian Ripley, Dirk Eddelbuettel\n\nPeter Dalgaard and Roger Bivand will serve as auditors.\nOur many thanks go to the outgoing board members, who have led the R\nFoundation during the years of phenomenal growth and success since its\ncreation in April 2003: These are Robert Gentleman and Ross Ihaka, our\npast presidents, and Friedrich Leisch, the former Secretary General.\n2 New ordinary members\nThe following new ordinary members were elected, as announced on\nSeptember 15.1\nDirk Eddelbuettel, USA\nTorsten Hothorn, Switzerland\nMichael Lawrence, USA\nMartin Morgan, USA\nMarc Schwartz, USA\nHadley Wickham, USA\nAchim Zeileis, Austria\nThis brings the total number of ordinary members to 29. As always, the\ncomplete membership list, along with other details, is available at\nhttp://www.r-project.org/foundation/.\n3 Donations and new supporting members\nDonations\nShannon Callan, USA\nRees Morrison, USA\nCarlos Ortega, Spain\nNew supporting members\nJose M. Benitez, Spain\nDaniel Emaasit, USA\nJay Emerson, USA\nBastiaan Quast, Switzerland\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\nhttps://stat.ethz.ch/pipermail/r-announce/2014/000577.html\n\n↩︎\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2014-2-beresewicz-szabelska-zyprychwalczak-etal/",
    "title": "Conference Report: Polish Academic R User Meeting",
    "description": "The 'Conference Report: Polish Academic R User Meeting' article from the 2014-2 issue.",
    "author": [
      {
        "name": "Maciej Beręsewicz",
        "url": {}
      },
      {
        "name": "Alicja Szabelska",
        "url": {}
      },
      {
        "name": "Joanna Zyprych-Walczak",
        "url": {}
      },
      {
        "name": "Łukasz Wawrowski",
        "url": {}
      }
    ],
    "date": "2014-11-30",
    "categories": [],
    "contents": "\n\n1 Conference summary\nThe first national conference “Polish Academic R User Meeting” (PAZUR)\nwas held at the Poznan University of Economics from October 15–17,\n2014. The organizers of the conference were the Department of Statistics\nat the Poznan University of Economics (PUE),\nthe Department of Mathematical and Statistical Methods at the Poznan\nUniversity of Life Sciences (PULS) and SKN\nEstymator, the students scientific association that resides at the\nDepartment of Statistics at the Poznan University of Economics. The\nhonorary patronage of the conference took Professor Emil Panek, Dean of\nthe Faculty of Informatics and Electronic Economy PUE and Professor\nWiesław Koziara, Dean of the Faculty of Agronomy and Bioengineering\nPULS. In addition, patrons were the Branch in Poznan of the Polish\nStatistical Association, the Polish Biometric Society and the General\nDirector of the Statistical Office in Poznan. The sponsors of the\nconference were: Revolution Analytics\nCompany and\nAnalyx as well as foundation\nSmarterPoland.\nThe main goal of the conference was to present the possibility of using\nthe statistical software environment R in various fields of science and\nbusiness, exchange experiences and integrate the R users in Poland. The\nfirst day of the event was devoted to workshops focusing on spatial data\nanalysis, spatial data mining, processing large data sets with the\ndata.table package\n(Dowle et al. 2014), survey data analysis with the\nsurvey package\n(Lumley 2004, 2014), data visualization, as well as the\nintroduction to the analysis of data in the statistical software\nenvironment R. The workshop was attended by nearly 130 participants.\nDuring the second and third day of the conference 29 presentations\nconcerning the variety of applications of R in the fields of\nmathematics, biological sciences, economics and information technology\nas well as business applications. The participation in the conference\nwas free of charge. There were two invited talks during the conference\npresented by: dr hab. Katarzyna Kopczewska (Faculty of Economic\nSciences, University of Warsaw) entilted Spatial modelling of economic\nphenomenon in R (in Polish: Przestrzenne modelowanie zjawisk\nekonomicznych w R) and dr hab. Przemysław Biecek (Interdisciplinary\nCentre for Mathematical and Computational Modelling, University of\nWarsaw) entitled Project Beta and Bit, ULAM diagrams, data\nvisualisation in R – my analytical atelier (in Polish: Projekt Beta i\nBit, diagramy ULAM, wizualizacja z R, czyli o moim analitycznym\natelier).\nAll the presentations from the conference are available at the webpage\nwww.estymator.ue.poznan.pl/PAZUR\nand\nhere.\n2 The organizing committee\nThe members of the organizing committee were: Maciej Beręsewicz\n(chairperson, Poznan University of Economics, Poznan Statistical\nOffice), Joanna Zyprych-Walczack (Poznan University of Life Sciencies),\nAlicja Szabelska (Poznan University of Life Sciences) and Łukasz\nWawrowski (Poznan University of Economics, Poznan Statistical Office).\n3 The presentations\nBeside the two invited talks the conference participants presented the\nfollowing 27 topics (in alphabetical order):\nAdolfo Alvarez (Analyx): Mastering data frames with dplyr\nZbigniew Bartkowiak (Poznan Archaeological Museum): The impact of\ntrimming and mixing ore of Wladyslaw Jagiello’s coins on the\ndistribution of their weight\nMaciej Beręsewicz (Poznan University of Economics): Small area\nstatistics in R\nPaweł Budzianowski (Adam Mickiewicz University): A copula-based\nmultivariate analysis with R\nDamian Chmura (Academy of Humanities and Technology in\nBielsko-Biala): The use of the R package in teaching courses of\nbiocoeno in the fields of study: Environmental protection and\nenvironmental engineering\nMarcin K. Dyderski, Anna K. Gdula (Botanical Section students\nscientific foresters association in Poznan University of Life\nSciences): Analysis of vegetation using vegan and eHOF packages\nMarek Gągolewski (Systems Research Institute, Polish Academy of\nSciences): Processing string using stringi package and ICU libraries\nJarosłąw Jasiewicz (Adam Mickiewicz University): GIS-R –\nIntegrating geographic information systems and R\nPaweł Kliber (Poznan University of Economics): R in the financial\nanalysis\nPaweł Kleka (Adam Mickiewicz University): From the data to\npublication. Automatic formatting of the results using knitr package\nKrzysztof Krawiec (Poznan University of Technology): Genetic\nprogRamming\nMarcin Kosiński (Warsaw University of Technology): Archiving\nartifacts with the Archivist package\nJakub Nowosad (Adam Mickiewicz University): Visualization of spatial\ndata in R – from static to interactive map\nMichał Okoniewski (ETH Zurich, Scientific IT Services): R with\nexternal data sources in genomics – Nonsense case study\nAdrian Olszewski (KCR): GNU R in clinical trials – biostatistician\nworkspace\nNatalia Reszka (PBS): Integrating R and NetLogo agent systems\nsimulations\nKamil Rotter (SKN Estimator, Poznan University of Economics):\nInternet as a source of data on the example of the Allegro service\nArtur Schwałko (QuantUp): If / how R can replace Excel in the\ncompany?\nAgnieszka Strzałka (University of Wroclaw): Using ggplot2 to\nvisualize the growth of Streptomyces coelicolor\nAlicja Szabelska, Joanna Zyprych-Walczak (Poznan University of Life\nSciences): Using R in the analysis of RNA-seq data\nMonika Szczerba, Marek Wiewiórka (Warsaw University of Technology):\nR + big (bio)data warehouses\nŁukasz Wawrowski (Poznan University of Economics): Data analysis\nfrom social networking sites\nMarek Wiewiórka (Warsaw University of Technology): Scala(-ble) R –\nR integration and the Scala language\nMarek Wiewiórka (Warsaw University of Technology), Alicja Szabelska\n(Poznan University of Life Sciences), Michał Okoniewski (ETH Zurich,\nScientific IT Services): Disease gene signature – the use of\nparallel R and machine learning with MLInterfaces\nAdam Zagański (Wroclaw University of Technology/QuantUp): Analysis\nand forecasting of time series in R\nZygmunt Zawadzki, Daniel Kosiorowski (Cracow University of\nEconomics): Robust data mining using depthproc package\n\n\n\n\n\n\nCRAN packages used\ndata.table, survey\nCRAN Task Views implied by cited packages\nFinance, HighPerformanceComputing, OfficialStatistics, Survival, TimeSeries, WebTechnologies\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\nM. Dowle, T. Short, S. Lianoglou, A. Srinivasan and with contributions from R. Saporta and E. Antonyan. Data.table: Extension of data.frame. 2014. URL http://CRAN.R-project.org/package=data.table. R package version 1.9.4.\n\n\nT. Lumley. Analysis of complex survey samples. Journal of Statistical Software, 9(1): 1–19, 2004. URL http://www.jstatsoft.org/v09/i01.\n\n\nT. Lumley. Survey: Analysis of complex survey samples. 2014. URL http://CRAN.R-project.org/package=survey. R package version 3.30.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2014-2-gesmann-tsanakas/",
    "title": "Conference Report: R in Insurance 2014",
    "description": "The 'Conference Report: R in Insurance 2014' article from the 2014-2 issue.",
    "author": [
      {
        "name": "Markus Gesmann",
        "url": {}
      },
      {
        "name": "Andreas Tsanakas",
        "url": {}
      }
    ],
    "date": "2014-11-30",
    "categories": [],
    "contents": "\n\n1 Conference summary\nThe 2nd R in Insurance conference took place at Cass Business School\nLondon on 14 July 2014. This one-day conference focused once more on the\nwide range of applications of R in insurance, actuarial science and\nbeyond. The conference programme covered topics including reserving,\npricing, loss modelling, the use of R in a production environment and\nmuch more.\nThe audience of the conference included both practitioners (70%) and\nacademics (30%) who are active or interested in the applications of R in\nInsurance. It was a truly international event with speakers and\ndelegates from many different countries, including USA, Canada, Belgium,\nNetherlands, Switzerland, Germany, Ireland, Argentina, France, Spain and\nof course the UK. The coffee breaks and conference dinner offered great\nnetworking opportunities.\nIn the first plenary session, Montserrat\nGuillen (Riskcenter, University\nof Barcelona) and Leo Guelman (Royal Bank of Canada, RBC Insurance)\nspoke about the rise of uplift models. These predictive models are used\nfor improved targeting of policyholders by marketing campaigns, through\nthe use of experimental data. The presenters illustrated the use of\ntheir uplift package\n(available on CRAN), which they have developed for such applications.\nThereafter, the programme consisted of a combination of contributed\npresentations and lightning talks, as well as a panel discusson on R at\nthe interface of practitioner / academic interaction. The panel, drawn\nfrom academia and practice, discussed the efforts made in bridging\nthrough the use of R cultural and communication divides, as well as the\nchallenges of developing collaborative business models that respond to\nmarket needs and the incentives of academic researchers.\nIn the closing plenary, Arthur\nCharpentier (Professor of\nActuarial Science at UQAM, Canada) gave a non-Bayesian’s account of\nBayesian modelling in R. Bayesian philosophy has a long history in\nactuarial science, even if it is sometimes hidden. The presenter\ndemonstrated how some standard actuarial methods can be expressed in a\nBayesian modelling framework using R.\nAll conference presentations are available on request, contact:\ninfo@rininsurance.com.\n2 Scientific committee and sponsors\nThe members of the scientific committee were: Katrien\nAntonio\n(University of Amsterdam and KU Leuven), Christophe\nDutang (Universite du Maine,\nFrance), Jens Nielsen\n(Cass Business School), Andreas\nTsanakas (Cass Business\nSchool) and Markus\nGesmann (ChainLadder\nproject)\nFinally, we are grateful to our sponsors Mango\nSolutions, CYBAEA,\nPwC and RStudio. This\nconference would not have been possible without their generous support.\n3 R in Insurance 2015\nWe are delighted to announce next year’s event already. Following two\nyears in London at Cass Business School, the conference will travel\nacross the Channel to Amsterdam, 29 June 2015. Further details will be\npublished on www.rininsurance.com.\n\n\nCRAN packages used\nuplift\nCRAN Task Views implied by cited packages\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2014-1-bioconductor/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2014-1 issue.",
    "author": [
      {
        "name": "The Bioconductor Team",
        "url": {}
      }
    ],
    "date": "2014-06-01",
    "categories": [],
    "contents": "\n\nThe Bioconductor project provides tools for the analysis and\ncomprehension of high-throughput genomic data. The 824 software packages\navailable in Bioconductor can be viewed at\nhttp://bioconductor.org/packages/release/. Navigate packages using\n‘biocViews’ terms and title search. Each package has an html page with a\ndescription, links to vignettes, reference manuals, and usage\nstatistics. Start using Bioconductor and R version 3.1.0 with\n  source(\"http://bioconductor.org/biocLite.R\")\n  biocLite()\nInstall additional packages and dependencies, e.g.,\ndeepSNV,\nwith\n  source(\"http://bioconductor.org/biocLite.R\")\n  biocLite(\"deepSNV\")\nUpgrade installed packages with\n  source(\"http://bioconductor.org/biocLite.R\")\n  biocLite()\n1 Bioconductor 2.14 Release Highlights\nBioconductor 2.14 was released on 14 April 2014. It is compatible with R\n3.1.0 and consists of 824 software packages, 200 experiment data\npackages, and more than 860 current annotation packages. The release\nincludes 77 new software packages and many updates and improvements to\nexisting packages. The release\nannouncement includes\ndescriptions of new packages and updated NEWS files provided by current\npackage maintainers.\nNew packages continue to represent a wide variety of research areas.\nRariant\nidentifies single nucleotide variants (SNVs) based on the difference of\nbinomially distributed mismatch rates between matched samples.\nSomaticSignatures\nidentifies the mutational signatures of SNVs. Filtering of SNVs based on\ninheritance models, amino acid change consequence, and minor allele\nfrequency is offered through\nVariantFiltering.\nThe monocle package, currently in the ‘devel’ branch, preforms\ndifferential expression and time series analysis for single-cell\nexpression experiments. CRISPR/Cas is a compelling new molecular biology\ntechnique used for gene editing;\nCRIPSRseek\nhelps find potential guide RNAs for input target sequences.\nCCREPE\nassesses the significance of similarity measures in ‘compositional’ data\nsets, as found in microbial abundance studies.\nMIMOSA\nmodels count data using Dirichlet-multinomial and beta-binomial mixtures\nwith applications to single-cell assays. Machine learning methods such\nas SVM, Random Forest and CART are applied to RNASeq data in\nMLSeq;\nclustering and classification methods are used to summarize active paths\nin genome-scale metabolic and reaction networks in\nNetPathMiner.\nBioconductor hosts a number of packages relevant to chemical compound\ndiscovery. The latest additions integrate bioinformatics and\nchemoinformatics into a molecular informatics platform in\nRcpi,\nand performs alternating least squares analysis on chemical data in\nalsace.\nIn addition to these contributed packages, ‘Ranges’ infrastructure\npackages such as\nGenomicRanges,\nGenomicAlignments,\nand\nGenomicFeatures\nprovide an extensive, mature and extensible framework for interacting\nwith high throughput sequence data. One recent addition is the\nGenomeInfoDb\npackage, which contains functions that allow translation between\ndifferent chromosome sequence naming conventions (e.g., UCSC versus\nNCBI). Many packages rely on the Ranges infrastructure for\ninteroperable, re-usable analysis; (Lawrence 2013)\nprovides an introduction.\nOur large collection of microarray, transcriptome and organism-specific\nannotation packages have been updated to include current information.\nMost of these packages now provide access to the ‘select’ interface\n(keys, columns, keytypes and select) which enable programmatic access to\nthe databases they contain. The\nAnnotationHub,\nwith 10,780 entries, complements our traditional offerings with diverse\nwhole genome annotations from Ensembl, ENCODE, dbSNP, UCSC, and\nelsewhere.\n2 Other activities\nThe Bioconductor Git-SVN\nBridge allows\ndevelopers to synchronize a GitHub repository with the canonical\nBioconductor SVN package repository. Commits made in SVN are propagated\nto GitHub and vice versa. This was driven by developer requests for\naccess to social coding features, such as issue tracking and pull\nrequests. The service has been well received, with 73 bridges\nestablished as of June 2014.\nThe Bioconductor Amazon Machine Instance is now compatible with the\nStarCluster toolkit. This enhancement makes it straightforward to\nconfigure a cluster with nodes that communicate via MPI, SSH or Sun Grid\nEngine, and to control jobs via the\nBiocParallel\nand\nBatchJobs\npackages. Details are available at the AMI page\nhttp://www.bioconductor.org/help/bioconductor-cloud-ami/#using_cluster.\nNew Bioconductor package contributors are encouraged to consult the\nPackage\nGuidelines and\nPackage\nSubmission\nsections of the Bioconductor web site, and use the new\nBiocCheck\npackage, in addition to R CMD check, for guidance on conforming to\nBioconductor package standards.\nThe Bioconductor web site advertises training and community\nevents; mailing\nlists connect users with\neach other, to domain experts, and to maintainers eager to ensure that\ntheir packages satisfy the needs of leading edge approaches. Keep\nabreast of packages added to the ‘devel’ branch and other activities by\nfollowing @Bioconductor on Twitter.\n\n\nBioconductor packages used\ndeepSNV, Rariant, SomaticSignatures, VariantFiltering, CRIPSRseek, CCREPE, MIMOSA, MLSeq, NetPathMiner, Rcpi, alsace, GenomicRanges, GenomicAlignments, GenomicFeatures, GenomeInfoDb, AnnotationHub, BiocParallel, BatchJobs, BiocCheck\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\nW. A. P. Lawrence Michael AND Huber. Software for computing and annotating genomic ranges. PLoS Comput Biol, 9(8): e1003118, 2013. DOI 10.1371/journal.pcbi.1003118.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2014-1-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2014-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2014-06-01",
    "categories": [],
    "contents": "\n\nNew packages in CRAN task views\nBayesian\n\nBAYSTAR, PReMiuM, eigenmodel, rstiefel, spikeslab.\n\nChemPhys\n\nclustvarsel, investr, nlreg, resemble.\n\nClinicalTrials\n\nAGSDest, binomSamSize, metasens.\n\nCluster\n\nPReMiuM, clusterfly, clustvarsel, dendextend, mixer,\noptpart, seriation.\n\nEconometrics\n\nSemiParSampleSel, mfx, mnlogit.\n\nEnvironmetrics\n\nDistance, EnvStats, RMark, bReeze, dsm, dynatopmodel,\nmarked, mrds.\n\nFinance\n\nChainLadder, GEVStableGarch, MarkowitzR, Rbitcoin,\nTAQMNGR, bizdays, egcm, lgarch, pbo, tvm,\nycinterextra.\n\nGenetics\n\nrmetasim.\n\nHighPerformanceComputing\n\nRhpc, ffbase, toaster.\n\nMachineLearning\n\nRoughSets, penalizedLDA.\n\nMetaAnalysis\n\nGmisc, Metatron, RcmdrPlugin.EZR, extfunnel, metap,\nmetasens, mmeta, pcnetmeta, robumeta.\n\nMultivariate\n\nclustvarsel, denpro.\n\nNaturalLanguageProcessing\n\nboilerpipeR, languageR, tm.plugin.alceste,\ntm.plugin.europresse, tm.plugin.lexisnexis,\ntm.plugin.webmining.\n\nNumericalMathematics\n\nQZ, SparseM, conicfit, geigen, ktsolve, rARPACK.\n\nOfficialStatistics\n\nMicSim, foreign, prevR, questionr, seasonal, sms.\n\nOptimization\n\nDEoptimR, GA, GrassmannOptim, NMOF.\n\nPhylogenetics\n\nTreePar.\n\nPsychometrics\n\nDFIT, DIFlasso, TestScorer, pcIRT, pcaPA.\n\nReproducibleResearch\n\nbibtex, papeR, sparktex, stargazer, suRtex, table1xls,\ntexreg, tikzDevice, tth.\n\nRobust\n\nGSE, OutlierDC, OutlierDM, RECSO, RobPer, RobRSVD,\ndrgee, georob, mblm, robcor, robumeta, rsig, ssmrob.\n\nSocialSciences\n\nlmeSplines.\n\nSpatial\n\nAMOEBA, geospacom, latticeDensity, leafletR, marmap,\nseg, siplab, spaMM, spacom.\n\nSpatioTemporal\n\nrmatio.\n\nSurvival\n\nAdapEnetClass, BGPhazard, CoxRidge, LogrankA, MAMSE,\nMRsurv, NADA, NPMLEcmprsk, OutlierDC, ROCt,\nSemiCompRisks, SemiMarkov, SurvRegCensCov, YPmodel,\ncoarseDataTools, kmc, kmconfband, psbcGroup, rsig,\nsimMSM, simPH, smoothHR, spatsurv, surv2sampleComp,\nsurvMisc, survsim, wtcrsk.\n\nTimeSeries\n\nBAYSTAR, BootPR, GEVStableGarch, KFKSDS, LPStimeSeries,\nMAPA, MSwM, MTS, Sim.DiffProc, TED, TSdist, VAR.etp,\nbsts, costat, depmix, depmixS4, dlnm, earlywarnings,\nfractal, glarma, lgarch, locits, lomb, mvcwt, npst,\npdfetch, rmaf, seasonal, spectral.methods, stsm,\nstsm.class, tsintermittent, tsoutliers.\n\nWebTechnologies\n\nGhcnDaily, RForcecom, RISmed, Rbitcoin, RefManageR,\nThinknum, XML2R, acs, ecoengine, fbRanks, hoardeR,\nhttpRequest, jsonlite, okmesonet, pdfetch, plusser,\nprimerTree, psidR, pubmed.mineR, raincpc, rapport, rbhl,\nrbison, rnoaa, soilDB, spocc, sweSCB,\ntm.plugin.webmining, tseries, weatherData.\n\n(* = core package)\n1 New contributed packages\nAMOEBA\n\nA Multidirectional Optimum Ecotope-Based Algorithm. Author:\nGuillermo Valles. In view:\nSpatial.\n\nAR1seg\n\nSegmentation of an autoregressive Gaussian process of order 1.\nAuthors: S. Chakar, E. Lebarbier, C. Levy-Leduc, S. Robin.\n\nARPobservation\n\nTools for simulating different methods of observing behavior based\non alternating renewal processes. Author: James E. Pustejovsky.\n\nATmet\n\nAdvanced Tools for Metrology. Authors: S. Demeyer, A. Allard.\n\nAmpliconDuo\n\nStatistical Analysis Of Amplicon Data Of The Same Sample To Identify\nArtefacts. Authors: Anja Lange [aut, cre], Daniel Hoffmann\n[aut].\n\nAntWeb\n\nprogrammatic interface to the AntWeb. Author: Karthik Ram [aut,\ncre].\n\nAnthropometry\n\nStatistical methods for anthropometric data oriented towards the\nergonomic design of products. Authors: Guillermo Vinue, Irene\nEpifanio, Amelia Simo, M. Victoria Ibanez, Juan Domingo, Guillermo\nAyala.\n\nBAMMtools\n\nAnalysis and visualization of macroevolutionary dynamics on\nphylogenetic trees. Authors: Dan Rabosky, Mike Grundler, Pascal\nTitle, Carlos Anderson, Jeff Shi, Joseph Brown, Huateng Huang.\n\nBANOVA\n\nHierarchical Bayesian ANOVA Models. Authors: Chen Dong, Michel\nWedel.\n\nBBRecapture\n\nBayesian Behavioural Capture-Recapture Models. Authors: Luca\nTardella and Danilo Alunni Fegatelli.\n\nBEQI2\n\nBenthic Ecosystem Quality Index 2. Authors: Willem van Loon [aut,\ncph], Dennis Walvoort [aut, cre].\n\nBIPOD\n\nBayesian Inference for Partially Observed diffusions. Author: Anders\nChr. Jensen.\n\nBMhyd\n\nPCM for Hybridization. Author: Dwueng-Chwuan Jhwueng.\n\nBalancedSampling\n\nBalanced and spatially balanced sampling. Author: Anton\n\nBayesComm\n\nBayesian community ecology analysis. Author: Nick Golding.\n\nBayesGESM\n\nBayesian Analysis of Generalized Elliptical Semiparametric Models.\nAuthors: Luz Marina Rondon and Heleno Bolfarine.\n\nBayesMed\n\nDefault Bayesian hypothesis tests for correlation, partial\ncorrelation, and mediation. Authors: Michele B. Nuijten, Ruud\nWetzels, Dora Matzke, Conor V. Dolan, and Eric-Jan Wagenmakers.\n\nBayesPen\n\nBayesian Penalized Credible Regions. Authors: Ander Wilson,\nHoward D. Bondell, and Brian J. Reich.\n\nBerlinData\n\nEasy access to Berlin related data. Authors: Kate McCurdy, Dirk\nSchumacher.\n\nBiSEp\n\nToolkit to identify synthetic lethality and cell line resistance\nrelationships based on bimodality in gene expression data. Author:\nMark Wappett.\n\nBlaunet\n\nCalculate and Analyze Blau statuses for measuring social distance.\nAuthors: Michael Genkin [aut], George Berry [aut], Liyuan Chen\n[aut], Matthew Brashears [aut].\n\nBoom\n\nBayesian Object Oriented Modeling. Authors: Steven L. Scott is the\nsole author and creator of the BOOM project. Some code in the BOOM\nlibraries has been modified from other open source projects. These\ninclude Cephes (obtained from Netlib, written by Stephen L.\nMoshier), NEWUOA (M.J.D Powell, obtained from Powell’s web site),\nand a modified version of the R math libraries (R core development\nteam).\n\nBoomSpikeSlab\n\nMCMC for spike and slab regression. Author: Steven L. Scott.\n\nCAvariants\n\nCorrespondence Analysis Variants. Authors: Rosaria Lombardo and Eric\nJ Beh.\n\nCCMnet\n\nSimulate Congruence Class Model for Networks. Authors: Ravi Goyal,\nwith contributions from Mark S. Handcock, David R. Hunter, Carter T.\nButts, Steven M. Goodreau, Pavel N. Krivitsky, Martina Morris, and\nNicole Bohme Carnegie.\n\nCCpop\n\nOne and two locus GWAS of binary phenotype with\ncase-control-population design. Author: Shachar Kaufman.\n\nCHAT\n\nClonal Heterogeneity Analysis Tool. Author: Bo Li.\n\nCIDnetworks\n\nGenerative models for complex networks with conditionally\nindependent dyadic structure. Authors: Beau Dabbs, Brian Junker,\nMauricio Sadinle, Tracy Sweet, A.C. Thomas.\n\nCMF\n\nCollective matrix factorization. Authors: Arto Klami and Lauri Väre.\n\nCMPControl\n\nControl Charts for Conway-Maxwell-Poisson Distribution. Author:\nKimberly Sellers and Luis Costa.\n\nCORM\n\nThe Clustering of Regression Models Method. Authors: Li-Xuan Qin\n[aut], Jiejun Shi [cre].\n\nCRAC\n\nCosmology R Analysis Code. Author: Jiayi Liu.\n\nCRF\n\nConditional Random Fields. Author: Ling-Yun Wu [aut, cre].\n\nCVD\n\nColor Vision Deficiencies. Authors: José Gama [aut, cre, trl],\nMaria Nyberg [aut], [ths], Brian Foutch [ctb], Mark Grundland\n[ctb], Neil Dodgson [ctb].\n\nCVcalibration\n\nEstimation of the Calibration Equation with Error-in Observations.\nAuthors: He Qi and Lu Tian.\n\nChargeTransport\n\nCharge Transfer Rates and Charge Carrier Mobilities. Authors: Julien\nIdé and Guido Raos.\n\nCircE\n\nCircumplex models Estimation. Author: Michele Grassi.\n\nClickClust\n\nModel-Based Clustering of Categorical Sequences. Author: Volodymyr\nMelnykov [aut, cre].\n\nCoImp\n\nCopula based imputation method. Authors: Francesca Marta Lilja Di\nLascio, Simone Giannerini.\n\nCombinS\n\nConstructions method of rectangular PBIB and rectangular right\nangular PBIB(\\(m\\)) (\\(m = 4, 5\\) and 7) designs. Authors: Mohamed Laib,\nImane Rezgui, Zoubida Gheribi-Aoulmi and Herve Monod.\n\nCommunityCorrelogram\n\nEcological Community Correlogram. Authors: J. Malia Andrus, Timothy\nKuehlhorn, Luis F. Rodriguez, Angela D. Kent, and Julie L. Zilles.\n\nConnMatTools\n\nTools for working with connectivity matrices. Author: Marco\nAndrello.\n\nCorReg\n\nLinear regression based on linear structure between covariates.\nAuthors: Clement Thery [aut, cre], Christophe Biernacki [ctb],\nGaetan Loridant [ctb], Florian Watrin [ctb], Quentin Grimonprez\n[ctb], Vincent Kubicki [ctb].\n\nDBFTest\n\nDBF test of no difference between groups. Author: Christopher Minas.\n\nDESnowball\n\nBagging with Distance-based Regression for Differential Gene\nExpression Analyses. Author: Yaomin Xu.\n\nDEoptimR\n\nDifferential Evolution Optimization in pure R. Authors:\nEduardo L. T. Conceicao and Martin Maechler [ctb]. In view:\nOptimization.\n\nDFIT\n\nDifferential Functioning of Items and Tests (DFIT) framework\nanalyses. Author: Victor H. Cervantes. In view:\nPsychometrics.\n\nDNAprofiles\n\nDNA profiling evidence analysis. Author: Maarten Kruijver.\n\nDSsim\n\nDistance Sampling Simulations. Author: Laura Marshall.\n\nDensity.T.HoldOut\n\nDensity.T.HoldOut: Non-combinatorial T-estimation Hold-Out for\ndensity estimation. Authors: Nelo Magalhães and Yves Rozenholc.\n\nDescTools\n\nTools for descriptive statistics. Authors: Andri Signorell. Includes\nR source code and/or documentation previously published by (in\nalphabetical order): Nanina Anderegg, Tomas Aragon, Antti Arppe, Ben\nBolker, Stephane Champely, Daniel Chessel, Leanne Chhay, Michael\nDewey, Harold C. Doran, Stephane Dray, Charles Dupont, Jeff Enos,\nClaus Ekstrom, Martin Elff, John Fox, Tal Galili, Matthias Gamer,\nJuergen Gross, Gabor Grothendieck, Frank E. Harrell Jr, Michael\nHoehle, Christian W. Hoffmann, Markus Huerzeler, Rob J. Hyndman,\nPablo J. Villacorta Iglesias, David Kahle, Matthias Kohl, Mikko\nKorpela, Jim Lemon, Martin Maechler, Arni Magnusson, Daniel Malter,\nAlina Matei, David Meyer, Yongyi Min, Markus Naepflin, Derek Ogle,\nSandrine Pavoine, Roland Rapold, William Revelle, Venkatraman E.\nSeshan, Greg Snow, Michael Smithson, Werner A. Stahel, Yves Tille,\nAdrian Trapletti, Kevin Ushey, Jeremy VanDerWal, Bill Venables, John\nVerzani, Gregory R. Warnes, Stefan Wellek, Peter Wolf, Achim\nZeileis.\n\nDisake\n\nDiscrete associated kernel estimators. Authors: W. E.\nWansouwe, C. C. Kokonendji and D.T. Kolyang.\n\nDiscML\n\nEstimate evolutionary rates of discrete characters using maximum\nlikelihood. Authors: Tane Kim, Weilong Hao.\n\nDivE\n\nDiversity Estimator. Authors: Daniel Laydon, Aaron Sim, Charles\nBangham, Becca Asquith.\n\nDoubleExpSeq\n\nDifferential Exon Usage Test for RNA-Seq data via Empirical Bayes\nShrinkage of the Dispersion Parameter. Author: Sean Ruddy.\n\nEBEN\n\nEmpirical Bayesian Elastic Net. Authors: Anhui Huang, Shizhong Xu,\nXiaodong Cai.\n\nELT\n\nBuild Experience Life Tables. Authors: Julien Tomas, Frederic\nPlanchet, Wassim Youssef.\n\nEMMIXcontrasts\n\nContrasts in mixed effects for EMMIX model with random effects.\nAuthors: Angus Ng, Geoff McLachlan, Kui Wang.\n\nEMMREML\n\nFitting mixed models with known covariance structures. Authors:\nDeniz Akdemir, Okeke Uche Godfrey.\n\nEMP\n\nExpected Maximum Profit for Credit Scoring. Authors: Cristian Bravo\nand Thomas Verbraken.\n\nERP\n\nSignificance analysis of Event-Related Potentials data. Authors:\nDavid Causeur and Ching-Fan Sheu.\n\nESGtoolkit\n\nToolkit for the simulation of financial assets and interest rates\nmodels. Authors: Jean-Charles Croix, Thierry Moudiki, Frederic\nPlanchet, Wassim Youssef.\n\nEWGoF\n\nGoodness-of-fit tests for the Exponential and two-parameter Weibull\ndistributions. Author: Meryam Krit.\n\nEasyMARK\n\nUtility functions for working with mark-recapture data. Author: John\nWaller.\n\nEasyStrata\n\nEvaluation of stratified genome-wide association meta-analysis\nresults. Author: Thomas Winkler.\n\nEcfun\n\nFunctions for Ecdat. Author: Spencer Graves.\n\nEloRating\n\nAnimal Dominance Hierarchies by Elo Rating. Authors: Christof\nNeumann and Lars Kulik.\n\nElstonStewart\n\nElston-Stewart Algorithm. Author: Herve Perdry.\n\nEntropyEstimation\n\nTools for the estimation of entropy and related quantities. Authors:\nLijuan Cao and Michael Grabchak.\n\nEnviroStat\n\nStatistical analysis of environmental space-time processes. Authors:\nNhu Le, Jim Zidek, Rick White, and Davor Cubranic, with Fortran code\nfor Sampson-Guttorp estimation authored by Paul D. Sampson, Peter\nGuttorp, Wendy Meiring, and Catherine Hurley, and\nRunge-Kutta-Fehlberg method implementation by H.A. Watts and L.F.\nShampine.\n\nEpiDynamics\n\nDynamic Models in Epidemiology. Authors: Oswaldo Santos [aut,\ncre], Fernando Silveira Marques [aut].\n\nEvapotranspiration\n\nAuthors: Danlu Guo, Seth Westra.\n\nEvoRAG\n\nEvolutionary Rates Across Gradients. Author: Jason T. Weir.\n\nExtDist\n\nExtended Probability Distribution Functions. Authors: Haizhen Wu, A.\nJonathan R. Godfrey, Kondaswamy Govindaraju.\n\nExtremeBounds\n\nExtreme Bounds Analysis (EBA). Author: Marek Hlavac.\n\nFDRreg\n\nFalse discovery rate regression. Authors: James G. Scott, with\ncontributions from Rob Kass and Jesse Windle.\n\nFDboost\n\nBoosting functional regression models. Author: Sarah Brockhaus.\n\nFGSG\n\nFeature grouping and selection over an undirected graph. Authors:\nXiaotong Shen, Yiwen Sun, Julie Langou.\n\nFLIM\n\nFarewell’s Linear Increments Model. Authors: Rune Hoff with\ncontributions from Jon Michael Gran and Daniel Farewell.\n\nFLR\n\nFuzzy Logic Rule Classifier. Authors: Constantinos Mavridis and\nIoannis N. Athanasiadis.\n\nFLSSS\n\nFixed Size Subset Sum Solution. Author: Charlie Wusuo Liu.\n\nFPDC\n\nPD-clustering and factor PD-clustering. Authors: Cristina Tortora\nand Paul D. McNicholas.\n\nFastHCS\n\nCompute the FastHCS outlyingness index. Author: Kaveh Vakili [aut,\ncre].\n\nFisHiCal\n\nIterative FISH-based Calibration of Hi-C Data. Authors: Yoli Shavit,\nFiona Kathryn Hamey and Pietro Lio’.\n\nFunChisq\n\nNonparametric functional chi-square tests. Authors: Yang Zhang, Joe\nSong.\n\nFusedLasso\n\nSolves the generalized Fused Lasso. Author: Holger Hoefling.\n\nGDAtools\n\nA toolbox for the analysis of categorical data in social sciences,\nand especially Geometric Data Analysis. Author: Nicolas Robette.\n\nGEVStableGarch\n\nARMA-GARCH/APARCH models with GEV and stable distributions. Authors:\nThiago do Rego Sousa, Cira Etheowalda Guevara Otiniano and Silvia\nRegina Costa Lopes. In views:\nFinance,\nTimeSeries.\n\nGHQp\n\nGauss Hermite Quadrature with pruning. Author: Freddy Hernandez\nBarajas.\n\nGLSME\n\nGeneralized Least Squares with Measurement Error. Author: Krzysztof\nBartoszek.\n\nGMCM\n\nFast estimation of Gaussian Mixture Copula Models. Authors: Anders\nEllern Bilgrau, Martin Boegsted, Poul Svante Eriksen.\n\nGNE\n\nComputation of generalized Nash equilibria. Author: Christophe\nDutang.\n\nGPFDA\n\nApply Gaussian Process in Functional data analysis. Authors: Jian\nQing Shi, Yafeng Cheng.\n\nGPLTR\n\nGeneralized Partially Linear Tree-based Regression Model. Authors:\nCyprien Mbogning and Wilson Toussile.\n\nGSAgm\n\nGene Set Analysis using the Gamma Method. Authors: Rama Raghavan,\nAlice Wang.\n\nGWsignif\n\nGenome-wide significance for whole genome sequencing studies.\nAuthors: ChangJiang Xu and Celia M.T. Greenwood.\n\nGammareg\n\nClassic gamma regression: joint modeling of mean and shape\nparameters. Authors: Martha Corrales and Edilberto Cepeda-Cuervo,\nwith the colaboration of Maria Fernanda Zarate, Ricardo Duplat and\nCampo Elias Pardo.\n\nGenABEL.data\n\nContains data which is used by GenABEL example and test functions.\nAuthors: Maksim Struchalin and GenABEL project developers.\n\nGenBinomApps\n\nClopper-Pearson Confidence Interval and Generalized Binomial\nDistribution. Authors: Horst Lewitschnig, David Lenzi.\n\nGeneFeST\n\nBayesian calculation of gene-specific FST from genomic SNP data.\nAuthor: Bastian Pfeifer.\n\nGeoGenetix\n\nQuantification of the effect of geographic versus environmental\nisolation on genetic differentiation. Authors: Filippo Botta, Gilles\nGuillot.\n\nGmisc\n\nA few handy misc functions for plots, tables, and more. Author: Max\nGordon. In view:\nMetaAnalysis.\n\nGraphPCA\n\nGraphical tools of histogram PCA. Authors: Brahim Brahim and Sun\nMakosso-Kallyth.\n\nHBSTM\n\nHierarchical Bayesian Space-Time models for Gaussian space-time\ndata. Authors: Pilar Munyoz, Alberto Lopez Moreno.\n\nHIV.LifeTables\n\nHIV calibrated model life tables for countries with generalized HIV\nepidemics. Author: David J Sharrow.\n\nHK80\n\nConversion Tools for HK80 Geographical Coordinate System. Author:\nJinlong Zhang.\n\nHLSM\n\nHierarchical Latent Space network Model. Authors: Samrachana\nAdhikari, Brian Junker, Tracy Sweet, Andrew C. Thomas.\n\nHMMCont\n\nHidden Markov Model for Continuous Observations Processes. Author:\nMikhail A. Beketov.\n\nHMMpa\n\nAnalysing accelerometer data using hidden Markov models. Authors:\nVitali Witowski, Ronja Foraita.\n\nHSAUR3\n\nA Handbook of Statistical Analyses Using R (3rd Edition). Authors:\nBrian S. Everitt and Torsten Hothorn.\n\nHUM\n\nCompute HUM value and visualize ROC curves. Authors: Natalia\nNovoselova, Junxi Wang, Jialiang Li, Frank Pessler, Frank Klawonn.\n\nHankel\n\nUnivariate non-parametric two-sample test based on empirical Hankel\ntransforms. Author: Daniel Kolbe.\n\nHiClimR\n\nHierarchical Climate Regionalization: An Improved Hierarchical\nClustering in R for Climate Regionalization. Authors: Hamada S. Badr\n[aut, cre], Benjamin F. Zaitchik [aut], Amin K. Dezfuli [aut].\n\nHiCseg\n\nDetection of domains in HiC data. Author: Celine Levy-Leduc.\n\nHiLMM\n\nEstimation of heritability in high dimensional Linear Mixed Models.\nAuthor: Anna Bonnet.\n\nICGE\n\nEstimation of number of clusters and identification of atypical\nunits. Authors: Itziar Irigoien [aut, cre], Concepcion Arenas\n[aut].\n\nICsurv\n\nSemiparametric regression analysis of interval-censored data.\nAuthors: Christopher S. McMahan and Lianming Wang.\n\nInventorymodelPackage\n\nAuthor: Alejandro Saavedra Nieves.\n\nIsingFit\n\nFitting Ising models using the eLasso method. Authors: Claudia van\nBorkulo, Sacha Epskamp, with contributions from Alexander Robitzsch.\n\nIsingSampler\n\nSampling methods and distribution functions for the Ising model.\nAuthor: Sacha Epskamp.\n\nIsoCI\n\nConfidence intervals for current status data based on\ntransformations and bootstrap. Authors: Byeong Yeob Choi, Jason P.\nFine and M. Alan Brookhart.\n\nJBTools\n\nJB’s tools and helper functions. Author: Jannis v. Buttlar.\n\nKANT\n\nIdentify and sort genes overexpressed. Author: Noemie Robil.\n\nKATforDCEMRI\n\nKinetic analysis and visualization of DCE-MRI data. Authors:\nGregory Z. Ferl, Georges Hankov.\n\nKFKSDS\n\nKalman Filter, Smoother and Disturbance Smoother. Author: Javier\nLópez-de-Lacalle. In view:\nTimeSeries.\n\nLINselect\n\nSelection of linear estimators. Authors: Yannick Baraud, Christophe\nGiraud, Sylvie Huet.\n\nLOGICOIL\n\nMulti-state prediction of coiled-coil oligomeric state. Authors:\nThomas L. Vincent, Peter J. Green and Derek N. Woolfson.\n\nLPS\n\nLinear Predictor Score, for binary inference from multiple\ncontinuous variables. Author: Sylvain Mareschal.\n\nLPStimeSeries\n\nLearned Pattern Similarity and Representation for Time Series.\nAuthors: Learned Pattern Similarity (LPS) for time series by Mustafa\nGokce Baydogan, Ensemble of regression trees by Andy Liaw and\nMatthew Wiener. In view:\nTimeSeries.\n\nLS2Wstat\n\nA Multiscale Test of Spatial Stationarity for LS2W processes.\nAuthors: Sarah Taylor [aut], Matt Nunes [aut, cre], Idris Eckley\n[ctb, ths].\n\nLSAfun\n\nApplied Latent Semantic Analysis (LSA) functions. Author: Fritz\nGuenther [aut, cre].\n\nLogisticDx\n\nDiagnostic tests for logistic regression models. Author: Chris\nDardis.\n\nMAPA\n\nMultiple Aggregation Prediction Algorithm. Authors: Nikolaos\nKourentzes and Fotios Petropoulos. In view:\nTimeSeries.\n\nMC2toPath\n\nTranslates information from netcdf files with MC2 output into\ninter-PVT transitions. Authors: Dave Conklin and Emilie Henderson.\n\nMCMC.OTU\n\nBayesian analysis of multivariate counts data. Author: Mikhail V.\nMatz.\n\nMIICD\n\nMultiple Imputation for interval censored data regression. Author:\nMarc Delord.\n\nMILC\n\nMIcrosimulation Lung Cancer (MILC) model. Author: Stavroula A.\nChrysanthopoulou.\n\nMMMS\n\nMulti-Marker Molecular Signature for Treatment-specific Subgroup\nIdentification. Authors: Lin Li, Tobias Guennel, Scott Marshall, Leo\nWang-Kit Cheung.\n\nMTS\n\nAll-purpose toolkit for analyzing multivariate time series (MTS) and\nestimating multivariate volatility models. Author: Ruey S. Tsay. In\nview: TimeSeries.\n\nMXM\n\nDiscovering multiple, statistically-equivalent signatures. Authors:\nIoannis Tsamardinos, Vincenzo Lagani, Giorgos Athineou.\n\nManyTests\n\nMultiple testing procedures of Cox (2011) and Wang and Cox (2007).\nAuthor: Christiana Kartsonaki.\n\nMarkowitzR\n\nStatistical significance of the Markowitz portfolio. Author:\nSteven E. Pav [aut, cre]. In view:\nFinance.\n\nMetatron\n\nMeta-analysis for Classification Data and Correction to Imperfect\nReference. Author: Huiling Huang. In view:\nMetaAnalysis.\n\nMethplot\n\nVisualize the methylation patterns. Author: Xin Yang.\n\nMiST\n\nMixed effects Score Test for continuous outcomes. Authors: Jianping\nSun, Yingye Zheng, and Li Hsu.\n\nMicSim\n\nPerforming continuous-time microsimulation. Author: Sabine Zinn. In\nview:\nOfficialStatistics.\n\nMposterior\n\nRobust and Scalable Bayes via a Median of Subset Posterior Measures.\nAuthor: Sanvesh Srivastava.\n\nMultiCNVDetect\n\nMultiple Copy Number Variation Detection. Authors: Hao Lin, Qiang\nKou.\n\nNHMMfdr\n\nCompute FDR under dependence using NHMM. Author: Pei Fen Kuan.\n\nNLPutils\n\nNatural Language Processing Utilities. Author: Kurt Hornik [aut,\ncre].\n\nNPS\n\nConvenience functions and tests for working with the Net Promoter\nScore (NPS). Author: Brendan Rocks.\n\nNemenyi\n\nImplementation of the Nemenyi post-hoc test to find the groups of\ndata that differ after a statistical test of multiple comparisons.\nAuthor: Christian Guckelsberger.\n\nNetSim\n\nA Social Networks Simulation Tool in R. Author: Christoph Stadtfeld.\n\nNormPsy\n\nNormalisation of psychometric tests. Authors: Cecile Proust-Lima,\nViviane Philipps.\n\nNormalLaplace\n\nThe Normal Laplace Distribution. Authors: David Scott, Jason Shicong\nFu and Simon Potter.\n\nORCI\n\nSeveral confidence intervals for the odds ratio. Author: Libo Sun.\n\nOceanView\n\nVisualisation of Oceanographic Data and Model Output. Author:\nKarline Soetaert.\n\nOrdNor\n\nConcurrent generation of ordinal and normal data with given\ncorrelation matrix and marginal distributions. Authors: Anup Amatya\nand Hakan Demirtas.\n\nOutbreakTools\n\nBasic tools for the analysis of disease outbreaks. Authors: The\nHackout team (In alphabetic order: David Aanensen, Marc Baguelin,\nPaul Birrell, Simon Cauchemez, Anton Camacho, Caroline Colijn, Anne\nCori, Xavier Didelot, Ken Eames, Christophe Fraser, Simon Frost,\nNiel Hens, Joseph Hugues, Thibaut Jombart, Lulla Opatowski, Oliver\nRatmann, Samuel Soubeyrand, Marc Suchard, Jacco Wallinga, Rolf\nYpma).\n\nOutlierDM\n\nOutlier detection for replicated high-throughput data. Authors:\nSoo-Heang Eo [aut, cre], HyungJun Cho [aut]. In view:\nRobust.\n\nPBC\n\nProduct of Bivariate Copulas (PBC). Authors: Van Trung Pham and\nGildas Mazo, with contributions from R Core team, Nash, Zhu, Byrd,\nLu-Chen and Nocedal.\n\nPBD\n\nProtracted birth-death model of diversification. Author: Rampal S.\nEtienne.\n\nPCAmixdata\n\nMultivariate analysis for a mixture of quantitative and qualitative\ndata. Authors: Marie Chavent and Vanessa Kuentz and Amaury Labenne\nand Benoit Liquet and Jerome Saracco.\n\nPCDSpline\n\nSemiparametric regression analysis of panel count data using\nmonotone splines. Authors: Bin Yao and Lianming Wang.\n\nPCGSE\n\nPrincipal Component Gene Set Enrichment. Author: H. Robert Frost.\n\nPCPS\n\nPrincipal Coordinates of Phylogenetic Structure. Author: Vanderlei\nJulio Debastiani.\n\nPEMM\n\nA Penalized EM algorithm incorporating missing-data mechanism.\nAuthors: Lin Chen and Pei Wang.\n\nPGM2\n\nRecursive method for construction of nested resolvable designs and\nuniform designs associated. Authors: Mohamed Laib, Abla Boudraa and\nZoubida Gheribi-Aoulmi.\n\nPHeval\n\nEvaluation of the proportional hazards assumption with a\nstandardized score process. Author: Cecile Chauvel.\n\nPIGE\n\nSelf contained gene set analysis for gene- and pathway-environment\ninteraction analysis. Authors: Benoit Liquet, Therese Truong.\n\nPIGShift\n\nPolygenic Inverse Gamma rate Shifts. Author: Joshua G. Schraiber.\n\nPMCMR\n\nCalculate Pairwise Multiple Comparisons of Mean Rank Sums. Author:\nThorsten Pohlert.\n\nPSMix\n\nPopulation structure inference using mixture model. Authors: Baolin\nWu [aut, cph], Nianjun Liu [aut, cph], Hongyu Zhao [aut, cph],\nJose Gama [cre].\n\nPTE\n\nPersonalized Treatment Evaluator. Authors: Adam Kapelner, Justin\nBleich.\n\nPaneldata\n\nLinear models for panel data. Author: Zaghdoudi Taha.\n\nParetoPosStable\n\nComputing, fitting and validating the Pareto Positive Stable\ndistribution. Authors: Antonio Jose Saez-Castillo [aut, cre],\nFaustino Prieto [aut], Jose Maria Sarabia [aut].\n\nPedCNV\n\nAn implementation for association analysis with CNV data. Authors:\nMeiling Liu, Sungho Won and Weicheng Zhu.\n\nPeptides\n\nCalculate indices and theoretical physicochemical properties of\npeptides and protein sequences. Authors: Daniel Osorio, Paola\nRondon-Villarreal and Rodrigo Torres.\n\nPerMallows\n\nPermutations and Mallows distributions. Author: Ekhine Irurozki.\n\nPermAlgo\n\nPermutational algorithm to simulate survival data. Authors:\nMarie-Pierre Sylvestre, Thad Edens, Todd MacKenzie, Michal\nAbrahamowicz. In view:\nSurvival.\n\nPharmPow\n\nPharmacometric Power calculations for mixed study designs. Authors:\nFrank Kloprogge and Joel Tarning.\n\nPoisNor\n\nSimultaneous generation of multivariate data with Poisson and normal\nmarginals. Authors: Anup Amatya and Hakan Demirtas.\n\nPopED\n\nPopulation (and individual) optimal Experimental Design. Authors:\nAndrew C. Hooker [aut, cre, trl, cph], Sebastian Ueckert [aut]\n(MATLAB version), Marco Foracchia [aut] (O-Matrix version), Joakim\nNyberg [aut] (MATLAB version), Eric Stroemberg [ctb] (MATLAB\nversion).\n\nPortRisk\n\nPortfolio Risk Analysis. Authors: Tamal Kanti Panja, Sourish Das,\nRajeswaran Viswanathan.\n\nPower2Stage\n\nPower and Sample size distribution of 2-stage BE studies via\nsimulations. Authors: Detlew Labes [aut, cre], Helmut Schuetz\n[ctb].\n\nQuantifQuantile\n\nEstimation of conditional quantiles using optimal quantization.\nAuthors: Isabelle Charlier and Davy Paindaveine and Jerome Saracco.\n\nR4CDISC\n\nRead CDISC data files. Author: Ippei Akiya.\n\nR4CouchDB\n\nAn R convenience layer for CouchDB. Author: Thomas Bock.\n\nRADami\n\nPhylogenetic Analysis of RADseq Data. Author: Andrew L. Hipp.\n\nRAHRS\n\nData fusion filters for Attitude Heading Reference System (AHRS)\nwith several variants of the Kalman filter and the Mahoney and\nMadgwick filters. Authors: Jose’ Gama [aut, cre, trl], Vlad\nMaximov [aut], Sebastian O.H. Madgwick [aut], Alain Barraud\n[ctb], [ths].\n\nRAPIDR\n\nReliable Accurate Prenatal non-Invasive Diagnosis R package. Author:\nKitty Lo.\n\nRApiSerialize\n\nR API Serialization. Authors: Dirk Eddelbuettel, Junji Nakano, Ei-ji\nNakama, and R Core (original code).\n\nREdaS\n\nCompanion Package to the Book “R: Einführung durch angewandte\nStatistik”. Author: Marco Johannes Maier [cre, aut].\n\nRGENERATE\n\nA tool for generation random variable time series using the tools of\n‘vars’ or ‘RMAWGEN’. Author: Emanuele Cordano.\n\nRI2by2\n\nRandomization inference for treatment effects on a binary outcome.\nAuthor: Joseph Rigdon.\n\nRImageJROI\n\nRead ImageJ Region of Interest (ROI) files. Authors: David C\nSterratt [aut, cph, cre], Mikko Vihtakari [aut, cph].\n\nRJSONLD\n\nSemantic packaging tools for standard analytics. Author: Joseph\nDureau.\n\nROC632\n\nConstruction of diagnostic or prognostic scoring system and internal\nvalidation of its discriminative capacities based on ROC curve and\n0.633+ boostrap resampling. Author: Y. Foucher.\n\nROCt\n\nTime-dependent ROC curve estimation and adaptation to the relative\nsurvival context. Authors: Y. Foucher, K. Trebern-Launay and M.\nLorent. In view:\nSurvival.\n\nRPublica\n\nProPublica API Client. Author: Thomas J. Leeper.\n\nRPushbullet\n\nR interface to the wonderful Pushbullet service. Author: Dirk\nEddelbuettel.\n\nRSNPset\n\nAuthors: Chanhee Yi, Alexander Sibley, and Kouros Owzar.\n\nRSelenium\n\nR bindings for Selenium WebDriver. Author: John Harrison.\n\nRSpincalc\n\nConverting between attitude representations: DCM, Euler angles,\nQuaternions, and Euler vectors. Authors: Jose’ Gama [aut, cre],\nJohn Fuller [aut, cph], Paolo Leva [aut, cph], [ths].\n\nRTextureMetrics\n\nFunctions for calculation of texture metrics for Grey Level\nCo-occurrence Matrices. Author: Hans-Joachim Klemmt.\n\nRWBP\n\nDetects spatial outliers using a Random Walk on Bipartite Graph.\nAuthors: Sigal Shaked and Ben Nasi.\n\nRWebLogo\n\nplotting custom sequence logos. Author: Omar Wagih.\n\nRYoudaoTranslate\n\nFunctions to translate English words into Chinese. Author: Ke-Hao\nWu.\n\nRankResponse\n\nRanking Responses in a Single Response Question or a Multiple\nResponse Question. Authors: Hsiuying Wang, Yu-Jun Lin.\n\nRapidPolygonLookup\n\nPolygon lookup using kd trees. Authors: Markus Loecher and Madhav\nKumar.\n\nRchoice\n\nDiscrete Choice (Binary, Poisson and Ordered) Models with Random\nParameters. Author: Mauricio Sarrias.\n\nRcmdrPlugin.NMBU\n\nR Commander Plug-In for statistics at NMBU. Authors: Kristian Hovde\nLiland, Solve Sæbø.\n\nRcpp11\n\nR and C++11. Authors: Romain Francois [aut, cre], Kevin Ushey\n[aut], John Chambers [ctb].\n\nRcppRedis\n\nRcpp bindings for Redis using the hiredis library. Author: Dirk\nEddelbuettel.\n\nRefFreeEWAS\n\nEWAS using reference-Free DNA methylation mixture deconvolution.\nAuthors: E. Andres Houseman.\n\nRefManageR\n\nStraightforward BibTeX and BibLaTeX Bibliography Management. Author:\nMathew W. McLean [aut, cre]. In view:\nWebTechnologies.\n\nRegClust\n\nCluster analysis via regression coefficients. Authors: Weichao Bao,\nXin Tong, Meredith Ray, Hongmei Zhang.\n\nRelValAnalysis\n\nRelative Value Analysis. Author: Ting-Kam Leonard Wong [aut, cre].\n\nReot\n\nEmpirical Orthogonal Teleconnections in R. Authors: Tim Appelhans,\nFlorian Detsch, Thomas Nauss.\n\nReporteRs\n\nMicrosoft Word, Microsoft Powerpoint and HTML documents generation\nfrom R. Author: David Gohel.\n\nReporteRsjars\n\nExternal jars required for package ReporteRs. Author: David Gohel.\n\nRhpc\n\nHigh-Performance Computing. Authors: Junji Nakano and Ei-ji Nakama.\nIn view:\nHighPerformanceComputing.\n\nRobRSVD\n\nRobust Regularized Singular Value Decomposition. Authors: Lingsong\nZhang and Chao Pan. In view:\nRobust.\n\nRothermel\n\nRothermel fire spread model for R. Authors: Giorgio Vacchiano,\nDavide Ascoli.\n\nRoughSets\n\nData Analysis Using Rough Set and Fuzzy Rough Set Theories. Authors:\nLala Septem Riza, Andrzej Janusz, Chris Cornelis, Francisco Herrera,\nDominik Slezak, and Jose Manuel Benitez. In view:\nMachineLearning.\n\nRpdb\n\nRead, write, visualize and manipulate PDB files. Author: Julien Idé.\n\nRphylip\n\nAn R interface for PHYLIP. Authors: Liam J. Revell, Scott A.\nChamberlain.\n\nRrdrand\n\nGenerate Physical Random Numbers on Intel CPUs with the RdRand\ninstruction. Authors: Eiji Nakama, Junji Nakano.\n\nRsimMosaic\n\nR Simple IMage Mosaic creation library. Author: Alberto\nKrone-Martins.\n\nRsomoclu\n\nR package for somoclu. Authors: Peter Wittek [aut], Shichao Gao\n[cre].\n\nRtsne\n\nT-distributed Stochastic Neighbor Embedding using Barnes-Hut\nimplementation. Author: Jesse Krijthe.\n\nRttf2pt1\n\nPackage for ttf2pt1 program. Authors: Winston Chang, Andrew Weeks,\nFrank M. Siegert, Mark Heath, Thomas Henlick, Sergey Babkin, Turgut\nUyar, Rihardas Hepas, Szalay Tamas, Johan Vromans, Petr Titera, Lei\nWang, Chen Xiangyang, Zvezdan Petkovic, Rigel, I. Lee Hetherington.\n\nRuchardet\n\nDetect character encoding. Author: Heewon Jeon.\n\nRvcg\n\nManipulations of triangular meshes (smoothing, quadric edge collapse\ndecimation, im- and export of various mesh file-formats, cleaning,\netc.) based on the VCGLIB API. Author: Stefan Schlager; the authors\nof VCGLIB for the included version of the code.\n\nSCBmeanfd\n\nSimultaneous Confidence Bands for the Mean of Functional Data.\nAuthor: David Degras.\n\nSCI\n\nStandardized Climate Indices such as SPI, SRI or SPEI. Authors:\nLukas Gudmundsson and James H. Stagge.\n\nSCORER2\n\nAn algorithm for distinguishing parallel dimeric and trimeric\ncoiled-coil sequences. Authors: Craig T. Armstrong, Thomas L.\nVincent, Peter J. Green and Derek N. Woolfson.\n\nSNFtool\n\nSimilarity Network Fusion. Authors: Bo Wang, Aziz Mezlini, Feyyaz\nDemir, Marc Fiume, Zhuowen Tu, Michael Brudno, Benjamin Haibe-Kains,\nAnna Goldenberg.\n\nSPAr\n\nPerform rare variants association analysis based on summation of\npartition approaches. Author: Ruixue Fan.\n\nSTEPCAM\n\nABC-SMC inference of the STEPCAM model. Authors: Thijs Janzen and\nFons van der Plas.\n\nSTPGA\n\nSelection of Training Populations by Genetic Algorithm. Author:\nDeniz Akdemir.\n\nSample.Size\n\nSample size calculation. Authors: Wei Jiang, Jonathan Mahnken,\nMatthew Mayo.\n\nSemiCompRisks\n\nParametric and semi-parametric analyses of semi-competing risks\ndata. Authors: Kyu Ha Lee and Sebastien Haneuse. In view:\nSurvival.\n\nSeqFeatR\n\nCalculates possible epitopes and co-mutations. Author: Bettina\nBudeus.\n\nShrinkCovMat\n\nShrinkage Covariance Matrix Estimators. Author: Anestis Touloumis.\n\nSimRAD\n\nSimulations to predict the number of loci expected in RAD and GBS\napproaches. Authors: Olivier Lepais [aut, cre], Jason Weir\n[aut].\n\nSimSeq\n\nNonparametric Simulation of RNA-Seq Data. Author: Samuel Benidt.\n\nSocialMediaMineR\n\nA Social Media Search and Analytic Tool. Author: Marco Toledo\nBastos.\n\nSocialNetworks\n\nGenerates social networks based on distance. Authors: Glenna\nNightingale, Peter Nightingale.\n\nSoftClustering\n\nSoft Clustering Algorithms. Author: G. Peters.\n\nSpecsVerification\n\nForecast verification routines for the SPECS FP7 project. Author:\nStefan Siegert [aut, cre].\n\nStableEstim\n\nEstimate the 4 parameters of stable law using different methods.\nAuthors: Tarak Kharrat, Georgi N. Boshnakov.\n\nStereoMorph\n\nStereo Camera Calibration and Reconstruction. Authors: Aaron Olsen,\nAnnat Haber.\n\nStorm\n\nWrite Storm Bolts in R using the Storm Multi-Language Protocol.\nAuthor: Allen Day.\n\nSubLasso\n\nGene selection using Lasso for Microarray data with user-defined\ngenes fixed in model. Authors: Fengfeng Zhou, Youxi Luo, Qinghan\nMeng, Ruiquan Ge, Guoqin Mai, Jikui Liu.\n\nSunder\n\nQuantification of the effect of geographic versus environmental\nisolation on genetic differentiation. Authors: Filippo Botta, Casper\nEriksen, Gilles Guillot.\n\nSurrogate\n\nEvaluation of surrogate endpoints in clinical trials. Authors: Wim\nVan der Elst, Ariel Alonso and Geert Molenberghs.\n\nSurvRegCensCov\n\nWeibull Regression for a Right-Censored Endpoint with\nInterval-Censored Covariate. Authors: Stanislas Hubeaux and Kaspar\nRufibach. In view:\nSurvival.\n\nTAQMNGR\n\nManage tick-by-tick transaction data. Authors: Francesco Calvori,\nFabrizio Cipollini, Giampiero M. Gallo. In view:\nFinance.\n\nTED\n\nTurbulence time series Event Detection and classification. Authors:\nYanfei Kang, Danijel Belusic and Kate Smith-Miles. In view:\nTimeSeries.\n\nTFDEA\n\nTechnology Forecasting using Data Envelopment Analysis functions.\nAuthor: ETA Research Group at Portland State University.\n\nTFMPvalue\n\nEfficient and accurate \\(p\\)-value computation for Position Weight\nMatrices. Author: Ge Tan.\n\nTSdist\n\nDistance Measures for Time Series data. Authors: Usue Mori,\nAlexander Mendiburu, J.A. Lozano. In view:\nTimeSeries.\n\nTable1Heatmap\n\nTable 1 Heatmap. Author: Philip C Schouten.\n\nTaoTeProgramming\n\nIllustrations from Tao Te Programming. Author: Pat Burns.\n\nTcGSA\n\nTime-course Gene Set Analysis. Author: Boris P. Hejblum [aut,\ncre].\n\nTeachNet\n\nFits neural networks to learn about back propagation. Author: Georg\nSteinbuss.\n\nTopKLists\n\nInference, aggregation and visualization for top-\\(k\\) ranked lists.\nAuthors: Michael G. Schimek, Eva Budinska, Jie Ding, Karl G. Kugler,\nVendula Svendova, Shili Lin.\n\nTrackReconstruction\n\nReconstruct animal tracks from magnetometer, accelerometer, depth\nand optional speed data. Author: Brian Battaile.\n\nTreatmentSelection\n\nEvaluate Treatment Selection Biomarkers. Authors: Marshall Brown and\nHolly Janes.\n\nTurtleGraphics\n\nTurtle graphics in R. Authors: Anna Cena [aut], Marek Gagolewski\n[aut], Marcin Kosinski [aut], Natalia Potocka [aut], Barbara\nZogala-Siudem [aut, cre].\n\nUBCRM\n\nFunctions to simulate and conduct dose escalation phase I studies.\nAuthor: Benjamin Esterni with contribution from Baboukar Mane.\n\nVAR.etp\n\nVAR modelling: estimation, testing, and prediction. Author: Jae. H.\nKim. In view:\nTimeSeries.\n\nVIMGUI\n\nVisualization and Imputation of Missing Values. Authors: Daniel\nSchopfhauser, Matthias Templ, Andreas Alfons, Alexander Kowarik,\nBernd Prantner.\n\nVNM\n\nMultiple objective optimal design. Authors: Seung Won Hyun, Weng Kee\nWong, and Yarong Yang.\n\nVdgRsm\n\nVariance Dispersion and Fraction of Design Space Plots. Authors:\nPatchanok Srisuradetchai, John J. Borkowski.\n\nVideoComparison\n\nVideo comparison tool. Authors: Silvia Espinosa, Joaquin Ordieres,\nAntonio Bello, Jose Maria Perez.\n\nVoxR\n\nMetrics extraction of trees from T-LiDAR data. Authors: Bastien\nLecigne, Sylvain Delagrange and Christian Messier.\n\nWats\n\nWrap Around Time Series graphics. Authors: Will Beasley [aut,\ncre], Joe Rodgers [aut], Matthew Schuelke [ctb], Ronnie Coleman\n[ctb], Mark Joseph Lachowicz [ctb].\n\nWikipediR\n\nA MediaWiki API wrapper. Author: Oliver Keyes.\n\nWrightMap\n\nWright Map: IRT item-person map with ConQuest integration. Authors:\nDavid Torres Irribarra and Rebecca Freund.\n\nXBRL\n\nExtraction of business financial information from XBRL documents.\nAuthors: Roberto Bertolusso and Marek Kimmel.\n\nXNomial\n\nExact Goodness-Of-Fit Test For Multinomial Data With Fixed\nProbabilities. Author: Bill Engels.\n\nXmisc\n\nXiaobei’s miscellaneous classes and functions. Author: Xiaobei Zhao\n[aut, cre, cph].\n\naRpsDCA\n\nArps Decline Curve Analysis in R. Author: Derrick Turk [aut, cre,\ncph].\n\naccrual\n\nBayesian Accrual Prediction. Authors: Yu Jiang, Steve Simon,\nMatthew S. Mayo, Rama Raghavan, Byron J. Gajewski.\n\nacm4r\n\nAlign-and-Count Method comparisons of RFLP data. Authors: Andrea\nBenedetti, Sahir Rai Bhatnagar, Xiaofei Zhao.\n\nacss\n\nAlgorithmic Complexity for Short Strings. Authors: Nicolas Gauvrit\n[aut], Henrik Singmann [aut, cre], Fernando Soler Toscano\n[ctb], Hector Zenil [ctb].\n\nacss.data\n\nData Only: Algorithmic Complexity of Short Strings (Computed via\nCoding Theorem Method). Authors: Fernando Soler Toscano [aut],\nNicolas Gauvrit [aut], Hector Zenil [aut], Henrik Singmann\n[aut, cre].\n\nadditivityTests\n\nAdditivity tests in the two way ANOVA with single sub-class numbers.\nAuthors: Marie Simeckova [aut], Thomas Rusch [aut], Petr Simecek\n[cre].\n\nadhoc\n\nCalculate ad hoc distance thresholds for DNA barcoding\nidentification. Author: Gontran Sonet.\n\naemo\n\nDownload and process AEMO price and demand data. Authors: Imanuel\nCostigan [aut, cre], Australian Energy Market Operator [cph].\n\naidar\n\nTools for reading AIDA (http://aida.freehep.org/) files into R.\nAuthor: Andreas Pfeiffer.\n\nalgstat\n\nAlgebraic statistics in R. Authors: David Kahle and Luis\nGarcia-Puente.\n\nanominate\n\nalpha-NOMINATE Ideal Point Estimator. Authors: Royce Carroll,\nChristopher Hare, Jeffrey B. Lewis, James Lo, Keith T. Poole, and\nHoward Rosenthal.\n\napmsWAPP\n\nPre- and Postprocessing for AP-MS data analysis based on spectral\ncounts. Author: Martina Fischer.\n\napsimr\n\nEdit, run and evaluate APSIM simulations from R easily. Author:\nBryan Stanfill.\n\nargparser\n\nCommand-line argument parser. Author: David JH Shih.\n\narnie\n\n“Arnie” box office records 1982-2014. Author: Imanuel Costigan\n[aut, cre].\n\nassertthat\n\nEasy pre and post assertions. Author: Hadley Wickham [aut, cre].\n\nastrochron\n\nAn R Package for Astrochronology. Author: Stephen Meyers.\n\nautoencoder\n\nAn implementation of sparse autoencoder for automatic learning of\nrepresentative features from unlabeled data. Authors: Eugene\nDubossarsky (project leader, chief designer), Yuriy Tyshetskiy\n(design, implementation, testing).\n\nbabel\n\nRibosome profiling data analysis. Authors: Adam B. Olshen,\nRichard A. Olshen, Barry S. Taylor.\n\nbartMachine\n\nBayesian Additive Regression Trees. Authors: Adam Kapelner and\nJustin Bleich.\n\nbcpmeta\n\nBayesian Multiple Changepoint Detection Using Metadata. Author:\nYingbo Li.\n\nbdvis\n\nBiodiversity Data Visualizations. Authors: Vijay Barve, Javier\nOtegui.\n\nbeepr\n\nEasily Play Notification Sounds on any Platform. Author: Rasmus\nBååth.\n\nbenford.analysis\n\nBenford Analysis for data validation and forensic analytics. Author:\nCarlos Cinelli.\n\nberryFunctions\n\nfunction collection related to hydrology, zooming and shapefiles.\nAuthor: Berry Boessenkool.\n\nbezier\n\nBezier Curve and Spline Toolkit. Author: Aaron Olsen.\n\nbigalgebra\n\nBLAS routines for native R matrices and big.matrix objects. Authors:\nMichael J. Kane, Bryan Lewis, and John W. Emerson.\n\nbigpca\n\nPCA, transpose and multicore functionality for big.matrix objects.\nAuthor: Nicholas Cooper.\n\nbigsplines\n\nBig Splines (smoothing splines for large samples). Author:\nNathaniel E. Helwig.\n\nbilan\n\nBilan water balance model. Authors: T. G. Masaryk Water Research\nInstitute, p.r.i.: Ladislav Kasparek, Martin Hanel, Stanislav\nHoracek, Petr Maca, Adam Vizina.\n\nbinda\n\nMulti-Class Discriminant Analysis using Binary Predictors. Authors:\nSebastian Gibb and Korbinian Strimmer.\n\nbingat\n\nBinary Graph Analysis Tools. Authors: Terrence Brooks, Berkley\nShands, Skye Buckner-Petty, Patricio S. La Rosa, Elena Deych,\nWilliam D. Shannon.\n\nbioPN\n\nSimulation of deterministic and stochastic biochemical reaction\nnetworks using Petri Nets. Authors: Roberto Bertolusso and Marek\nKimmel.\n\nbiotools\n\nTools for Biometry and Applied Statistics in Agricultural Science.\nAuthor: Anderson Rodrigo da Silva.\n\nbiplotbootGUI\n\nBootstrap on Classical Biplots. Authors: Ana Belen Nieto Librero,\nPurificacion Galindo Villardon.\n\nbirdring\n\nMethods to analyse ring re-encounter data. Authors: Fraenzi\nKorner-Nievergelt, Rob Robinson.\n\nbirk\n\nMA Birk functions. Author: Matthew A Birk.\n\nblockmatrix\n\nTools to solve algebraic systems with partitioned matrices. Author:\nEmanuele Cordano.\n\nblowtorch\n\nConstrained optimization via stochastic gradient descent. Author:\nSteven Pollack.\n\nbmmix\n\nBayesian multinomial mixture. Author: Thibaut Jombart.\n\nbold\n\nInterface to Bold Systems API. Author: Scott Chamberlain [aut,\ncre].\n\nboolean3\n\nBoolean Binary Response Models. Author: Jason W. Morgan.\n\nboostr\n\nA modular framework to bag or boost any estimation procedure.\nAuthor: Steven Pollack.\n\nbootLR\n\nBootstrapped confidence intervals for (negative) likelihood ratio\ntests. Authors: Keith A. Marill and Ari B. Friedman.\n\nbrainR\n\nHelper functions to misc3d and rgl packages for brain imaging.\nAuthor: John Muschelli III.\n\nbreakpoint\n\nMultiple Break-Point Detection via the Cross-Entropy Method.\nAuthors: Priyadarshana W.J.R.M. and Georgy Sofronov.\n\nbshazard\n\nNonparametric Smoothing of the Hazard Function. Authors: Paola\nRebora, Agus Salim, Marie Reilly.\n\nbsts\n\nBayesian structural time series. Author: Steven L. Scott. In view:\nTimeSeries.\n\nbujar\n\nBuckley-James Regression for Survival Data with High-Dimensional\nCovariates. Authors: Zhu Wang and others (see COPYRIGHTS).\n\ncAIC4\n\nConditional Akaike information criterion for lme4. Authors: Benjamin\nSaefken and David Ruegamer, with contributions from Sonja Greven and\nThomas Kneib.\n\ncapm\n\nCompanion Animal Population Management. Authors: Oswaldo Santos\n[aut, cre], Marcos Amaku [ctb], Fernando Ferreira [ctb].\n\ncaseMatch\n\nIdentify similar cases for qualitative case studies. Author: Rich\nNielsen.\n\ncati\n\nCommunity Assembly by Traits: Individuals and beyond. Authors:\nAdrien Taudiere, Cyrille Violle with contribution of Francois Munoz.\n\nccda\n\nCombined Cluster and Discriminant Analysis. Authors: Solt Kovacs,\nJozsef Kovacs, Peter Tanos.\n\ncgam\n\nConstrained Generalized Additive Model. Authors: Mary C. Meyer and\nXiyue Liao.\n\ncheckmate\n\nFast and versatile argument checks. Authors: Michel Lang, Bernd\nBischl.\n\nchipPCR\n\nToolkit of helper functions to pre-process amplification data.\nAuthors: Stefan Roediger, Michal Burdukiewicz.\n\nchoroplethr\n\nFunctions to simplify the creation of choropleths (thematic maps)\nin R. Authors: Ari Lamstein [cre, aut], Brian P Johnson [ctb,\nfrontend animation code].\n\nchromoR\n\nAnalysis of chromosomal interactions data (correction, segmentation\nand comparison). Author: Yoli Shavit.\n\nclere\n\nCLERE methodology for simultaneous variables clustering and\nregression. Authors: Loic Yengo, Mickael Canouil.\n\nclickstream\n\nAnalyzes clickstreams based on Markov chains. Author: Michael\nScholz.\n\nclustMD\n\nModel based clustering for mixed data. Author: Damien McParland.\n\ncna\n\nCoincidence Analysis (CNA). Author: Mathias Ambuehl.\n\ncolourlovers\n\nR client for the COLOURlovers API. Author: Thomas J. Leeper.\n\ncomato\n\nAnalysis of Concept Maps. Author: Andreas Muehling.\n\nconfreq\n\nConfigural Frequencies Analysis Using Loglinear Modeling. Authors:\nJoerg-Henrik Heine, R.W. Alexandrowicz and some package testing by\nMark Stemmler.\n\nconicfit\n\nAlgorithms for fitting circles, ellipses and conics based on the\nwork by Prof. Nikolai Chernov. Authors: Jose’ Gama [aut, cre],\nNikolai Chernov [aut, cph], [ths]. In view:\nNumericalMathematics.\n\ncooccur\n\nProbabilistic Species Co-occurrence Analysis in R. Authors:\nDaniel M. Griffith, Joseph A. Veech, and Charles J. Marsh.\n\ncorclass\n\nCorrelational Class Analysis. Author: Andrei Boutyline.\n\ncorrelate\n\nMultivariate Data Generation by Permutation. Authors: Pascal van\nKooten, Gerko Vink.\n\ncosmosR\n\nAuthor: Maxime Wack.\n\ncovreg\n\nA simultaneous regression model for the mean and covariance.\nAuthors: Xiaoyue Niu and Peter Hoff.\n\ncpca\n\nMethods to perform Common Principal Component Analysis (CPCA).\nAuthors: Andrey Ziyatdinov [aut, cre], Samir Kanaan-Izquierdo\n[aut], Nickolay T. Trendafilov [aut], Alexandre Perera-Lluna\n[aut].\n\ncrackR\n\nProbabilistic damage tolerance analysis for fatigue cracking of\nmetallic aerospace structures. Author: Keith Halbert.\n\ncrossval\n\nGeneric Functions for Cross Validation. Author: Korbinian Strimmer.\n\ncsn\n\nClosed-skew normal distribution. Author: Eugene Girtcius.\n\ncstar\n\nSubstantive significance testing for regression estimates and\nmarginal effects. Author: Justin Esarey.\n\ncsvread\n\nFast Specialized CSV File Loader. Author: Sergei Izrailev.\n\ncubfits\n\nCodon Usage Bias Fits. Authors: Wei-Chen Chen [aut, cre], Russell\nZaretzki [aut], William Howell [aut], Drew Schmidt [aut],\nMichael Gilchrist [aut], Students REU13 [ctb].\n\ncutoffR\n\nCUTOFF: A Spatio-temporal Imputation Method. Authors: Lingbing Feng,\nGen Nowak, Alan. H. Welsh, Terry. J. O’Neill.\n\ncuttlefish.model\n\nPerforms LPUE standardization and stock assessment of the English\nChannel cuttlefish stock using a two-stage biomass model. Authors:\nMichael Gras and Jean-Paul Robin.\n\ndagbag\n\nLearning directed acyclic graphs (DAGs) through bootstrap\naggregating. Authors: Ru Wang, Jie Peng.\n\ndams\n\nDams in the United States from the National Inventory of Dams (NID).\nAuthor: Gopi Goteti.\n\ndatalist\n\nConvert data sets for import into JAGS, WinBUGS and OpenBUGS and to\ngenerate data.frames for predicting the effects of particular\nvariables. Author: Joe Thorley [aut, cre].\n\ndawai\n\nDiscriminant analysis with additional information. Authors: David\nConde, Miguel A. Fernandez, Bonifacio Salvador.\n\ndeepnet\n\nDeep learning toolkit in R. Author: Xiao Rong.\n\ndendextend\n\nExtending R’s dendrogram functionality. Authors: Tal Galili [aut,\ncre, cph], Gavin Simpson [ctb], jefferis [ctb] (imported code\nfrom his dendroextras package), Marco Gallotta [ctb], plannapus\n[ctb], Gregory [ctb], R core team [ctb] (Other than the\nInfastructure, some code came from their examples), Kurt Hornik\n[ctb], Uwe Ligges [ctb], Yoav Benjamini [ths]. In view:\nCluster.\n\ndendextendRcpp\n\nFaster dendrogram manipulation using Rcpp. Authors: Tal Galili\n[aut, cre, cph], Romain Francois [ctb], Dirk Eddelbuettel\n[ctb], Kevin Ushey [ctb], Yoav Benjamini [ths].\n\ndendsort\n\nSorting and reordering dendrogram nodes. Author: Ryo Sakai.\n\ndfexplore\n\nExplore data.frames by plotting NA and classes of each variable.\nAuthor: Joris Muller.\n\ndiskmemoiser\n\nDisk Memoisation For R. Author: Farzad Noorian.\n\ndissUtils\n\nUtilities for making pairwise comparisons of multivariate data.\nAuthor: Benjamin N. Taft.\n\ndnet\n\nOmics data integrative analysis in terms of network, evolution and\nontology. Authors: Hai Fang and Julian Gough.\n\ndocopt\n\nCommandline interface specification language. Author: Edwin de\nJonge.\n\ndomino\n\nDomino Data Lab R console bindings. Author: Jacek Glodek.\n\ndplyr\n\nA grammar of data manipulation. Authors: Hadley Wickham, Romain\nFrancois.\n\ndrgee\n\nDoubly Robust Generalized Estimating Equations. Authors: Johan\nZetterqvist, Arvid with contributions from Alexander Ploner. In\nview: Robust.\n\ndrsmooth\n\nDose-Response Modeling with Smoothing Splines. Authors: Greg Hixon\n[aut, cph], Anne Bichteler [aut, cre], Chad Thompson [ctb],\nLiz Abraham [ctb].\n\ndualScale\n\nDual Scaling Analysis of Multiple Choice Data. Authors: Jose G.\nClavel, Shizuiko Nishisato and Antonio Pita.\n\ndynatopmodel\n\nImplementation of the Dynamic TOPMODEL hydrological model. Authors:\nPeter Metcalfe, based on Fortran code by Keith Beven and Jim Freer.\nIn view:\nEnvironmetrics.\n\ndynia\n\nFit Dynamic Intervention Model. Authors: Jinkun Xiao and A.I.\nMcLeod.\n\neasingr\n\nFetch the Cleveland Federal Reserve Bank easing policy tool data.\nAuthor: Matt Barry.\n\neasynls\n\nEasy nonlinear model. Author: Emmanuel Arnhold.\n\nebSNP\n\nGenotyping and SNP calling using single-sample next generation\nsequencing data. Author: Na You.\n\necoengine\n\nProgrammatic interface to the API serving UC Berkeley’s Natural\nHistory Data. Author: Karthik Ram [aut, cre]. In view:\nWebTechnologies.\n\nedeR\n\nEmail Data Extraction Using R. Author: Jaynal Abedin.\n\nedmr\n\nEmpirical differentially methylated regions calculation. Authors:\nSheng Li [aut, cre, cph], Francine Garrett-Bakelman [ctb],\nAltuna Akalin [ctb], Paul Zumbo [ctb], Ari Melnick [ctb],\nChris Mason [ctb, ths].\n\neegAnalysis\n\nTools for analysis and classification of electroencephalography\n(EEG) data. Authors: Murilo Coutinho Silva, George Freitas von\nBorries.\n\negcm\n\nEngle-Granger cointegration models. Author: Matthew Clegg. In view:\nFinance.\n\neiwild\n\nEcological Inference with individual and aggregate data. Author:\nThomas Schlesinger.\n\nerpR\n\nEvent-related potentials (ERP) analysis, graphics and utility\nfunctions. Authors: Giorgio Arcara, Anna Petrova.\n\netasFLP\n\nEstimation of an ETAS model. Mixed FLP (Forward Likelihood\nPredictive) and ML estimation of non-parametric and parametric\ncomponents of the ETAS model for earthquake description. Authors:\nMarcello Chiodi [aut, cre], Giada Adelfio [aut].\n\neulerian\n\nFind eulerian paths from graphs. Authors: Ashis Saha, with\ncontribution from Jaewoo Kang.\n\nevolvability\n\nCalculation of evolvability parameters. Author: Geir H. Bolstad.\n\nexpp\n\nSpatial analysis of extra-pair paternity. Authors: Mihai Valcu,\nLotte Schlicht.\n\nextWeibQuant\n\nEstimate the lower extreme quantile with the censored Weibull MLE\nand censored Weibull Mixture. Author: Yang (Seagle) Liu.\n\nfSRM\n\nSocial Relations Analyses with roles (“Family SRM”). Authors: Felix\nLara Stas, Tom Loeys.\n\nfactorplot\n\nAuthors: Dave Armstrong.\n\nfalcon\n\nFinding Allele-specific Copy Number in Next-Generation Sequencing\nData. Authors: Hao Chen and Nancy R. Zhang.\n\nfastHICA\n\nHierarchical Independent Component Analysis: a multi-scale sparse\nnon-orthogonal data-driven basis. Authors: Piercesare Secchi, Simone\nVantini, and Paolo Zanini.\n\nfastM\n\nFast Computation of Multivariate M-estimators. Authors: Lutz\nDuembgen, Klaus Nordhausen, Heike Schuhmacher.\n\nfat2Lpoly\n\nTwo-locus Family-based Association Test with Polytomic Outcome.\nAuthors: Alexandre Bureau and Jordie Croteau.\n\nfcd\n\nFused Community Detection. Authors: Yang Feng, Richard J. Samworth\nand Yi Yu.\n\nfederalregister\n\nClient package for the U.S. Federal Register API. Author: Thomas J.\nLeeper.\n\nfifer\n\nA collection of miscellaneous functions. Author: Dustin Fife.\n\nfindpython\n\nPython tools to find an acceptable python binary. Authors: Trevor L\nDavis and Paul Gilbert.\n\nfiniteruinprob\n\nComputation of the probability of ruin within a finite time horizon.\nAuthors: Benjamin Baumgartner [aut, cre], Riccardo Gatto [ctb,\nths].\n\nflowfield\n\nForecasts future values of a univariate time series. Author: Kyle A.\nCaudle.\n\nfrair\n\nFunctional response analysis in R. Author: Daniel Pritchard.\n\nfreestats\n\nStatistical algorithms used in common data mining course. Author:\nXiaoyao Yang.\n\nfreqparcoord\n\nNovel Methods for Parallel Coordinates. Authors: Norm Matloff and\nYingkang Xie.\n\nfreqweights\n\nWorking with frequency tables. Author: Emilio Torres-Manzanera.\n\nfrm\n\nRegression analysis of fractional responses. Author: Joaquim J.S.\nRamalho.\n\nfslr\n\nWrapper functions for FSL (FMRIB Software Library) from Functional\nMRI. of the Brain (FMRIB). Author: John Muschelli.\n\nfunreg\n\nFunctional Regression for Irregularly Timed Data. Authors: John\nDziak [aut, cre], Mariya Shiyko [aut].\n\ngRapfa\n\nAcyclic Probabilistic Finite Automata. Authors: Smitha Ankinakatte\nand David Edwards.\n\ngSeg\n\nGraph-Based Change-Point Detection (g-Segmentation). Authors: Hao\nChen and Nancy R. Zhang.\n\ngamboostMSM\n\nEstimating multistate models using gamboost(). Author: Holger\nReulen.\n\ngamlss.spatial\n\nFit spatial data in gamlss. Authors: Fernanda De Bastiani, Mikis\nStasinopoulos.\n\ngconcord\n\nConcord method for Graphical Model Selection. Author: Sang-Yun Oh\nKshitij Khare Bala Rajaratnam.\n\ngdalUtils\n\nWrappers for the Geospatial Data Abstraction Library (GDAL)\nUtilities. Authors: Jonathan Asher Greenberg and Matteo Mattiuzzi.\n\ngenasis\n\nGlobal ENvironmental ASsessment Information System (GENASIS)\ncomputational tools. Authors: Jiri Kalina, Jana Klanova, Ladislav\nDusek, Tom Harner, Jana Boruvkova, Jiri Jarkovsky.\n\ngendata\n\nGenerate and modify synthetic datasets. Author: Francis Huang.\n\ngeoCount\n\nAnalysis and Modeling for Geostatistical Count Data. Author: Liang\nJing.\n\ngfcanalysis\n\nTools for working with Hansen et al. 2013 Global Forest Change\ndataset. Author: Alex Zvoleff [aut, cre].\n\nggtern\n\nAn extension to ggplot2, for the creation of ternary diagrams.\nAuthor: Nicholas Hamilton.\n\nggvis\n\nInteractive grammar of graphics. Authors: RStudio, Inc.\n\nglarma\n\nGeneralized Linear Autoregressive Moving Average Models. Authors:\nWilliam T.M. Dunsmuir, Cenanning Li, and David J. Scott. In view:\nTimeSeries.\n\nglcm\n\nCalculate textures from grey-level co-occurrence matrices (GLCMs)\nin R. Author: Alex Zvoleff [aut, cre].\n\nglmx\n\nGeneralized Linear Models Extended. Authors: Achim Zeileis [aut,\ncre], Roger Koenker [aut], Philipp Doebler [aut].\n\ngoft\n\nTests of fit for some probability distributions. Authors: Elizabeth\nGonzalez-Estrada, Jose A. Villasenor-Alva.\n\ngoftest\n\nClassical Goodness-of-Fit Tests for Univariate Distributions.\nAuthors: Julian Faraway [aut], George Marsaglia [aut], John\nMarsaglia [aut], Adrian Baddeley [aut, cre].\n\ngramEvol\n\nGrammatical Evolution For R. Authors: Farzad Noorian, Anthony\nMihirana de Silva.\n\ngreport\n\nGraphical Reporting for Clinical Trials. Author: Frank E Harrell Jr.\n\ngroc\n\nGeneralized Regression on Orthogonal Components. Authors: M.\nBilodeau and P. Lafaye de Micheaux.\n\ngrppenalty\n\nConcave 1-norm and 2-norm group penalty in linear and logistic\nregression. Author: Dingfeng Jiang.\n\ngset\n\nGroup Sequential Design in Equivalence Studies. Author: Fang Liu.\n\ngsscopu\n\nCopula Density and 2-D Hazard Estimation using Smoothing Splines.\nAuthor: Chong Gu.\n\nh2o\n\nH2O R Interface. Authors: Anqi Fu, Tom Kraljevic and Petr Maj, with\ncontributions from the 0xdata team.\n\nhamlet\n\nHierarchical Optimal Matching and Machine Learning Toolbox. Author:\nTeemu Daniel Laajala.\n\nhasseDiagram\n\nDrawing Hasse diagram. Author: Krzysztof Ciomek.\n\nhawkes\n\nHawkes process simulation and calibration toolkit. Author: Riadh\nZaatour.\n\nhazus\n\nDamage functions from FEMA’s HAZUS software for use in modeling\nfinancial losses from natural disasters. Author: Gopi Goteti.\n\nhcci\n\nInterval estimation for the parameters of linear models with\nheteroskedasticity (Wild Bootstrap). Authors: Pedro Rafael Diniz\nMarinho [aut, cre], Francisco Cribari Neto [aut, ctb].\n\nhdi\n\nHigh-Dimensional Inference. Authors: Lukas Meier, Nicolai\nMeinshausen.\n\nheatmap3\n\nA improved heatmap package. Authors: Shilin Zhao, Yan Guo, Quanhu\nSheng, Yu Shyr.\n\nhelsinki\n\nHelsinki open data R tools. Authors: Juuso Parkkinen, Leo Lahti,\nJoona Lehtomaki.\n\nhflights\n\nFlights that departed Houston in 2011. Author: Hadley Wickham.\n\nhglasso\n\nLearning graphical models with hubs. Author: Kean Ming Tan.\n\nhiddenf\n\nThe hidden F-test for nonadditivity. Authors: Jason A. Osborne and\nChristopher T. Franck.\n\nhoardeR\n\nAuthor: Daniel Fischer. In view:\nWebTechnologies.\n\nhpoPlot\n\nFunctions to plot graphviz style graphs of sets of HPO terms.\nAuthor: Daniel Greene.\n\nhqmisc\n\nMiscellaneous convenience functions and datasets. Author: Hugo Quené\n[aut, cre].\n\nhrr\n\nHorizontal rule for the R language. Author: Leonardo Di Donato.\n\nhtmltools\n\nTools for HTML. Authors: RStudio, Inc.\n\nhybridEnsemble\n\nBuild, deploy and evaluate a Hybrid Ensemble. Authors: Michel\nBallings, Dauwe Vercamer, and Dirk Van den Poel.\n\nhypergea\n\nHypergeometric tests. Author: Markus Boenn.\n\niC10\n\nA copy number and expression-based classifier for breast tumours.\nAuthor: Oscar M Rueda.\n\niC10TrainingData\n\nTraining datasets for iC10 package. Author: Oscar M Rueda.\n\niDynoR\n\nAnalysis of iDynoMiCS Simulation Results. Authors: Kieran Alden,\nJan-Ulrich Kreft.\n\niRepro\n\nReproducibility for Interval-Censored Data. Author: Jelena Kovacic.\n\niScreen\n\nimage-based High-Throughput RNAi Screening Analysis Tool. Author:\nRui Zhong.\n\nicapca\n\nMixed ICA/PCA. Author: Roger Woods.\n\nicd9\n\ntools for working with ICD-9 codes, and finding comorbidities.\nAuthor: Jack O. Wasey [aut, cre].\n\nimputeR\n\nA General Imputation Framework in R. Authors: Lingbing Feng, Gen\nNowak, Alan. H. Welsh, Terry. J. O’Neill.\n\nin2extRemes\n\nInto the extRemes Package. Author: Eric Gilleland.\n\ninterventionalDBN\n\nInterventional Inference for Dynamic Bayesian Networks. Author:\nSimon Spencer.\n\ninvGauss\n\nThreshold regression that fits the (randomized drift) inverse\nGaussian distribution to survival data. Author: Hakon K. Gjessing.\n\nio\n\nA unified framework for input-output operations in R. Author: David\nJH Shih.\n\nipdw\n\nInterpolation by Inverse Path Distance Weighting. Author: Joseph\nStachelek.\n\nisingLenzMC\n\nMonte Carlo for classical Ising Model. Author: Mehmet Suzen.\n\nisotonic.pen\n\nPenalized Isotonic Regression in one and two dimensions. Authors:\nMary C Meyer, Jiwen Wu, and Jean D. Opsomer.\n\niterpc\n\nEfficient iterator for permutations and combinations. Authors: Randy\nLai [aut, cre], Martin Broadhurst [aut].\n\nivfixed\n\nInstrumental fixed effect panel data model. Author: Zaghdoudi Taha.\n\nivlewbel\n\nUses heteroscedasticity to estimate mismeasured and endogenous\nregressor models. Author: Alan Fernihough.\n\nivpack\n\nInstrumental Variable Estimation. Author: Dylan Small.\n\njackstraw\n\nNon-parametric Jackstraw for Principal Component Analysis. Author:\nNeo Christopher Chung.\n\njointPm\n\nRisk estimation using the joint probability method. Authors: Feifei\nZheng, Michael Leonard, Seth Westra.\n\njsonlite\n\nA smarter JSON encoder/decoder for R. Authors: Jeroen Ooms, Duncan\nTemple Lang, Jonathan Wallace. In view:\nWebTechnologies.\n\nkimisc\n\nKirill’s miscellaneous functions. Author: Kirill Mueller.\n\nkintone\n\nkintone REST client package for R. Author: Ryu Yamashita.\n\nkmc\n\nKaplan–Meier estimator with constraints for right censored data –\na recursive computational algorithm. Authors: Yifan Yang, Mai Zhou.\nIn view: Survival.\n\nknnIndep\n\nIndependence tests and benchmarks. Author: Sebastian Dümcke.\n\nkyotil\n\nUtility Functions by Youyi & Krisz. Authors: Youyi Fong, Krisztian\nSebestyen.\n\nlambda.tools\n\nTools for modeling data with functional programming. Author: Brian\nLee Yung Rowe.\n\nlar\n\nHistory of labour relations. Authors: Richard Zijdeman [aut, cre],\nJosemiguel Lana-Berasain [ctb].\n\nlassoscore\n\nhigh-dimensional inference with the penalized score test. Author:\nArend Voorman.\n\nlctools\n\nLocal Correlation, Spatial Inequalities and other tools. Author:\nStamatis Kalogirou.\n\nleafletR\n\nInteractive web-maps based on the Leaflet JavaScript library.\nAuthor: Christian Graul. In view:\nSpatial.\n\nletsR\n\nTools for data handling and analysis in macroecology. Authors: Bruno\nVilela and Fabricio Villalobos.\n\nlgarch\n\nSimulation and estimation of log-GARCH models. Author: Genaro\nSucarrat. In views:\nFinance,\nTimeSeries.\n\nlinkim\n\nLinkage information based genotype imputation method. Authors: Yi Xu\nand Jixiang Wu.\n\nlllcrc\n\nLocal Log-linear Models for Capture-Recapture. Author: Zach Kurtz.\n\nlmms\n\nLinear mixed effect model splines for modelling and analysis of time\ncourse data. Authors: Jasmin Straube, Kim-Anh Le Cao and Emma Huang\nwith contributions of Dominique Gorse.\n\nloa\n\nVarious plots, options and add-ins for use with lattice. Author:\nKarl Ropkins.\n\nlocalsolver\n\nR API to LocalSolver. Authors: Walerian Sokolowski [aut, cre,\ncph], Wit Jakuczun [aut, cph], Natalia Okinczyc [aut], Bogumil\nKaminski [aut].\n\nloe\n\nLocal Ordinal Embedding. Authors: Yoshikazu Terada, Ulrike von\nLuxburg.\n\nlpmodeler\n\nModeler for linear programs (LP) and mixed integer linear programs\n(MILP). Author: Cyrille Szymanski [aut].\n\nlsgl\n\nLinear sparse group lasso. Author: Martin Vincent.\n\nltbayes\n\nSimulation-Based Bayesian Inference for Latent Traits of Item\nResponse Models. Author: Timothy R. Johnson.\n\nmGSZ\n\nGene set analysis based on GSZ-scoring function and asymptotic\n\\(p\\)-value. Authors: Pashupati Mishra, Petri Toronen.\n\nmaSAE\n\nMandallaz’ model-assisted small area estimators. Authors: Andreas\nDominik Cullmann [aut, cre], Daniel Mandallaz [ctb], Alexander\nFrancis Massey [ctb].\n\nmagrittr\n\nA forward-pipe operator for R. Authors: Stefan Milton Bache and\nHadley Wickham.\n\nmailR\n\nA utility to send emails from R. Author: Rahul Premraj.\n\nmapStats\n\nGeographic display of survey data statistics. Author: Samuel\nAckerman.\n\nmaptpx\n\nMAP estimation of topic models. Author: Matt Taddy.\n\nmbest\n\nMoment-Based Estimation for Hierarchical Models. Author: Patrick O.\nPerry.\n\nmcheatmaps\n\nMultiple matrices heatmap visualization. Authors: Thierry Chenard\n[aut], Rafael Najmanovich [aut, cre].\n\nmdatools\n\nMultivariate data analysis for chemometrics. Author: Sergey\nKucheryavskiy.\n\nmemgene\n\nSpatial pattern detection in genetic distance data using Moran’s\nEigenvector Maps. Authors: Pedro Peres-Neto, Paul Galpern.\n\nmetaRNASeq\n\nMeta-analysis of RNA-seq data. Authors: Guillemette Marot, Florence\nJaffrezic, Andrea Rau.\n\nmetap\n\nMeta-analysis of significance values. Author: Michael Dewey. In\nview:\nMetaAnalysis.\n\nmetasens\n\nAdvanced statistical methods to model and adjust for bias in\nmeta-analysis. Authors: Guido Schwarzer [aut, cre], James\nCarpenter [aut], Gerta Rücker [aut]. In views:\nClinicalTrials,\nMetaAnalysis.\n\nmewAvg\n\nA Fixed Memeory Moving Expanding Window Average. Authors: Adam L.\nPintar and Zachary H. Levine.\n\nmfx\n\nMarginal Effects, Odds Ratios and Incidence Rate Ratios for GLMs.\nAuthor: Alan Fernihough. In view:\nEconometrics.\n\nmiceadds\n\nSome additional multiple imputation functions, especially for\nmice. Author: Alexander Robitzsch [aut, cre].\n\nmime\n\nMap filenames to MIME types. Author: Yihui Xie.\n\nminque\n\nLinear Mixed Model Analyses. Author: Jixiang Wu.\n\nmiscset\n\nMiscellaneous Tools Set. Author: Sven E. Templer.\n\nmixlm\n\nMixed model ANOVA and statistics for education. Authors: Kristian\nHovde Liland, Solve Sæbø.\n\nmme\n\nMultinomial Mixed Effects Models. Authors: E. Lopez-Vizcaino, M.J.\nLombardia and D. Morales.\n\nmnlogit\n\nMultinomial Logit Model. Authors: Wang Zhiyu, Asad Hasan. In view:\nEconometrics.\n\nmonitoR\n\nAcoustic template detection in R. Authors: Sasha D. Hafner and Jon\nKatz, with code for the Fourier transform from the seewave package\n(by Jerome Sueur, Thierry Aubin, and Caroline Simonis), and code for\nthe readMP3 function from the tuneR package (by Uwe Ligges).\n\nmorgenstemning\n\nColor schemes compatible with red-green color perception\ndifficulties. Authors: Matthias Geissbuehler, James Manton.\n\nmorse\n\nMOdelling tools for Reproduction and Survival data in Ecotoxicology.\nAuthors: Marie Laure Delignette-Muller [aut, cre], Philippe Ruiz\n[aut, cre], Sandrine Charles [aut], Wandrille Duchemin [ctb],\nChristelle Lopes [ctb], Philippe Veber [ctb].\n\nmph\n\nMultiscale persistent homology. Author: Samuel Gerber.\n\nmsos\n\nDatasets and Functions used in Multivariate Statistics: Old School\nby John Marden. Authors: John Marden [aut, cph] and James Balamuta\n[cre, ctb, com].\n\nmulticon\n\nMultivariate Constructs. Author: Ryne A. Sherman.\n\nmultigroup\n\nMethods for multigroup data analysis. Authors: Aida Eslami, El\nMostafa Qannari, Stephanie Bougeard, Gaston Sanchez.\n\nmultinbmod\n\nRegression analysis of overdispersed correlated count data. Author:\nIvonne Solis-Trapala.\n\nmunsellinterpol\n\nInterpolation of Munsell renotation data to convert any hue and\nchroma values to CIE xyY, CIE XYZ, sRGB, CIE Lab or CIE Luv.\nAuthors: Jose Gama [aut, cre, trl], Paul Centore [aut, cph],\n[ths].\n\nmvctm\n\nMultivariate Variance Components Tests for Multilevel Data. Author:\nDenis Larocque.\n\nmvnfast\n\nFast multivariate normal methods. Authors: Matteo Fasiolo, using the\nC++ parallel RNG of Thijs van den Berg and Ziggurat algorithm of\nJens Maurer and Steven Watanabe (boost).\n\nmwa\n\nCausal inference in spatiotemporal event data. Authors: Sebastian\nSchutte and Karsten Donnay.\n\nmycobacrvR\n\nIntegrative immunoinformatics for Mycobacterial diseases in R\nplatform. Authors: Deepika Kulshreshtha, Rupanjali Chaudhuri, S.\nRamachandran.\n\nnat\n\nNeuroAnatomy Toolbox for Analysis of 3D Image Data. Authors: Greg\nJefferis and James Manton.\n\nnat.utils\n\nFile System Utility Functions for NeuroAnatomy Toolbox. Author:\nGregory Jefferis.\n\nncdf.tools\n\nEasier ncdf file handling. Author: Jannis v. Buttlar.\n\nncdf4.helpers\n\nHelper functions for use with the ncdf4 package. Author: David\nBronaugh for the Pacific Climate Impacts Consortium (PCIC).\n\nnetworkDynamicData\n\nDynamic network datasets. Author: Skye Bender-deMoll [cre, aut].\n\nnetworkreporting\n\nTools for using network reporting estimators. Authors: Dennis\nFeehan, Matthew Salganik.\n\nneuroim\n\nReading, writing and representing brain imaging data. Author:\nBradley R. Buchsbaum.\n\nngram\n\nAn \\(n\\)-gram Babbler. Authors: Drew Schmidt [aut, cre], Christian\nHeckendorf [aut].\n\nnlsMicrobio\n\nNonlinear regression in predictive microbiology. Authors: Florent\nBaty and Marie-Laure Delignette-Muller.\n\nnmcdr\n\nNon-parametric Multiple Change-points Detection. Authors: Changliang\nZou, Lancezhange.\n\nnoncensus\n\nU.S. Census Regional and Demographic Data. Author: John A. Ramey.\n\nnormtest\n\nTests for Normality. Authors: Ilya Gavrilov, Ruslan Pusev.\n\nnpbr\n\nNonparametric boundary regression. Authors: Abdelaati Daouia,\nThibault Laurent, Hohsuk Noh.\n\nnpcp\n\nSome nonparametric tests for change-point detection in\n(multivariate) observations. Author: Ivan Kojadinovic.\n\nnplr\n\nN-Parameter Logistic Regression. Authors: Frederic Commo [aut,\ncre], Brian M. Bot [aut].\n\nnumOSL\n\nNumeric routines for optically stimulated luminescence dating.\nAuthor: Peng Jun.\n\nobs.agree\n\nAssess agreement between observers. Authors: Teresa Henriques, Luis\nAntunes and Cristina Costa-Santos.\n\nocedata\n\nOceanographic datasets for Oce. Author: Dan Kelley.\n\nopenxlsx\n\n.xlsx reading, writing and editing. Authors: Alexander Walker\n[aut, cre], Luca Braglia [ctb].\n\noptR\n\nOptimization Toolbox for solving linear systems. Author: Prakash\n(PKS Prakash).\n\noptiRum\n\nMiscellaneous functions for finance / credit risk analysts. Author:\nStephanie Locke [aut, cre].\n\norca\n\nCounting graphlet orbits in sparse graphs. Authors: Tomaz Hocevar,\nJanez Demsar.\n\npSI\n\nSpecificity Index Statistic. Authors: Xiaoxiao Xu, Alan B. Wells,\nDavid OBrien, Arye Nehorai, Joseph D. Dougherty.\n\npaf\n\nAttributable Fraction Function for Censored Survival Data. Author:\nLi Chen.\n\npaleobioDB\n\nDownloading, visualizing and processing data from Paleobiology\nDatabase. Authors: Sara Varela [aut, cre], Javier González\nHernández [aut], Luciano Fabris Sgarbi [aut].\n\npaleofire\n\nAnalysis of sedimentary charcoal records from the Global Charcoal\nDatabase to reconstruct past biomass burning. Author: Global\nPaleofire Working Group.\n\npalinsol\n\nInsolation for palaeoclimate studies. Author: Michel Crucifix.\n\npanelAR\n\nEstimation of Linear AR(1) Panel Data Models with Cross-Sectional\nHeteroskedasticity and/or Correlation. Author: Konstantin Kashin.\n\nparallelMCMCcombine\n\nMethods for combining independent subset Markov chain Monte\nCarlo (MCMC) posterior samples to estimate a posterior density given\nthe full data set. Authors: Alexey Miroshnikov, Erin Conlon.\n\npbo\n\nProbability of Backtest Overfitting. Author: Matt Barry. In view:\nFinance.\n\npcIRT\n\nIRT models for polytomous and continuous item responses. Author:\nChristine Hohensinn. In view:\nPsychometrics.\n\npcg\n\nPreconditioned Conjugate Gradient Algorithm for solving \\(Ax=b\\).\nAuthors: B N Mandal and Jun Ma.\n\npcnetmeta\n\nMethods for patient-centered network meta-analysis. Authors: Lifeng\nLin, Jing Zhang, and Haitao Chu. In view:\nMetaAnalysis.\n\npdfetch\n\nFetch economic and financial time series data from public sources.\nAuthor: Abiel Reinhart. In views:\nTimeSeries,\nWebTechnologies.\n\npdmod\n\nProximal/distal modeling framework for Pavlovian conditioning\nphenomena. Author: Chloe Bracis.\n\npeacots\n\nPeriodogram Peaks in Correlated Time Series. Author: Stilianos\nLouca.\n\nperformanceEstimation\n\nAn infra-structure for performance estimation of predictive models.\nAuthor: Luis Torgo.\n\nphenability\n\nNonparametric Stability Analysis. Author: Leonardo Castelo Branco.\n\nphreeqc\n\nR interface to the phreeqc geochemical modeling program. Authors:\nS.R. Charlton, D.L. Parkhurst, and C.A.J. Appelo, with contributions\nfrom D. Gillespie for Chipmunk BASIC and S.D. Cohen, A.C.\nHindmarsh, R. Serban, D. Shumaker, and A.G. Taylor for\nCVODE/SUNDIALS.\n\nphyloland\n\nModelling Competitive Exclusion and Limited Dispersal in a\nStatistical Phylogeographic Framework. Authors: Louis Ranjard, Marie\nPaturel.\n\nphyreg\n\nImplements the Phylogenetic Regression of Grafen (1989). Author:\nAlan Grafen.\n\npipeR\n\nSpecialized, high-performance pipeline operators. Author: Kun Ren.\n\npkgKitten\n\nCreate simple packages which do not upset R CMD check. Author: Dirk\nEddelbuettel.\n\nplot2groups\n\nPlot scatter points for two groups of values. Author: Fuquan Zhang\n[aut, cre].\n\nplot3D\n\nPlotting multi-dimensional data. Author: Karline Soetaert.\n\nplot3Drgl\n\nPlotting multi-dimensional data using rgl. Author: Karline\nSoetaert.\n\nplotMCMC\n\nMCMC Diagnostic Plots. Authors: Arni Magnusson [aut, cre], Ian\nStewart [aut].\n\nplusser\n\nA Google+ Interface for R. Author: Christoph Waldhauser [aut,\ncre]. In view:\nWebTechnologies.\n\npmcgd\n\nAuthors: Antonio Punzo and Paul D. McNicholas.\n\npollstR\n\nR client for the Huffpost Pollster API. Authors: Jeffrey B. Arnold\n[aut, cre], Thomas J. Leeper [aut].\n\npopRange\n\nA spatially and temporally explicit forward genetic simulator.\nAuthor: Kimberly F. McManus.\n\npqantimalarials\n\nWeb tool for estimating under-five deaths caused by poor-quality\nantimalarials in sub-Saharan Africa. Author: J. Patrick Renschler.\n\npraktikum\n\nKvantitatiivsete meetodite praktikumi asjad / Functions used in the\ncourse “Quantitative methods in behavioural sciences” (SHPH.00.004),\nUniversity of Tartu. Author: Kenn Konstabel.\n\npredfinitepop\n\nPredictive Inference on Totals and Averages of Finite Populations\nSegmented in Planned and Unplanned Domains. Authors: Juan Carlos\nMartinez-Ovando, Sergio I. Olivares-Guzman, Adriana\nRoldan-Rodriguez.\n\npsData\n\nDownload regularly maintained political science data sets and make\ncommonly used, but infrequently updated variables based on this\ndata. Author: Christopher Gandrud.\n\npt\n\nComputational models for prospect theory and other theories of risky\ndecision making. Author: Gary Au.\n\npubmed.mineR\n\nText mining of PubMed Abstracts. Authors: Jyoti Sharma, S.\nRamachandran, Ab Rauf Shah. In view:\nWebTechnologies.\n\npushoverr\n\nSend push notifications using Pushover. Author: Brian Connelly\n[aut, cre].\n\nqVarSel\n\nVariable Selection for Clustering and Classification. Author:\nStefano Benati.\n\nqcr\n\nQuality control and reliability. Authors: Miguel Flores, Salvador\nNaya, Ruben Fernandez.\n\nqdapDictionaries\n\nDictionaries and word lists for the qdap package. Author: Tyler\nRinker.\n\nqdapTools\n\nTools for the qdap package. Authors: Bryan Goodrich [ctb], Dason\nKurkiewicz [ctb], Kirill Muller [ctb], Tyler Rinker [aut,\ncre].\n\nqlcMatrix\n\nUtility sparse matrix functions for Quantitative Language\nComparison. Author: Michael Cysouw.\n\nqmethod\n\nAnalysis of subjective perspectives using Q methodology. Author:\nAiora Zabala [aut, cre].\n\nqqman\n\nQ-Q and manhattan plots for GWAS data. Author: Stephen Turner.\n\nquipu\n\nSummary charts of micro satellite profiles for a set of biological\nsamples. Authors: Reinhard Simon, Pablo Carhuapoma, Vilma Hualla,\nStef de Haan, Marc Ghislain, Jorge Nunez, Rene Gomez, Felipe de\nMendiburu, William Roca, Merideth Bonierbale.\n\nr2d2\n\nBivariate (Two-Dimensional) Confidence Region and Frequency\nDistribution. Authors: Arni Magnusson [aut], Julian Burgos [aut,\ncre], Gregory R. Warnes [ctb].\n\nrARPACK\n\nR wrapper of ARPACK for large scale eigenvalue/vector problems, on\nboth dense and sparse matrices. Authors: Yixuan Qiu and authors of\nthe ARPACK library. In view:\nNumericalMathematics.\n\nrAvis\n\nInterface to the bird-watching datasets at proyectoavis.com.\nAuthors: Javier González Hernández, Sara Varela González.\n\nrClinicalCodes\n\nR tools for integrating with the www.clinicalcodes.org repository.\nAuthor: David Springate.\n\nrDVR\n\nStart, stop and save a video server from within R. Author: John\nHarrison [aut, cre].\n\nrHealthDataGov\n\nRetrieve data sets from the HealthData.gov data API. Author: Erin\nLeDell.\n\nrSCA\n\nStepwise Cluster Analysis. Author: Xiuquan Wang.\n\nrTensor\n\nTools for tensor analysis and decomposition. Authors: James Li and\nJacob Bien and Martin Wells.\n\nrWBclimate\n\nAccess World Bank climate data. Author: Edmund Hart [aut, cre].\n\nrags2ridges\n\nRidge Estimation of Precision Matrices from High-Dimensional Data.\nAuthors: Carel F.W. Peeters, Wessel N. van Wieringen.\n\nrainfreq\n\nRainfall Frequency (Design Storm) Estimates from the US National\nWeather Service. Author: Gopi Goteti.\n\nrandomUniformForest\n\nRandom Uniform Forests for Classification and Regression. Author:\nSaip Ciss.\n\nrandtests\n\nTesting randomness in R. Authors: Frederico Caeiro and Ayana Mateus.\n\nrapportools\n\nMiscellaneous (stats) helper functions with sane defaults for\nreporting. Authors: Aleksandar Blagotić and Gergely Daróczi.\n\nrareNMtests\n\nEcological and biogeographical null model tests for comparing\nrarefaction curves. Authors: Luis Cayuela and Nicholas J. Gotelli.\n\nraters\n\nAn index of inter-rater agreement among a set of raters. Authors:\nDaniele Giardiello, Piero Quatto and Stefano Vigliani.\n\nrbhl\n\nR interface to the Biodiversity Heritage Library. Authors: Scott\nChamberlain [aut, cre], Karthik Ram [aut]. In view:\nWebTechnologies.\n\nrbison\n\nR interface to the USGS BISON API. Author: Scott Chamberlain [aut,\ncre]. In view:\nWebTechnologies.\n\nrbitcoinchartsapi\n\nR Package for the BitCoinCharts.com API. Author: Thomas P. Fuller.\n\nrdrobust\n\nRobust data-driven statistical inference in Regression-Discontinuity\ndesigns. Authors: Sebastian Calonico, Matias D. Cattaneo, Rocio\nTitiunik.\n\nreadODS\n\nRead ODS files and puts them into data frames. Author: Gerrit-Jan\nSchutten.\n\nrecalls\n\nAccess U.S. Federal Government Recall Data. Author: Thomas J.\nLeeper.\n\nregRSM\n\nRandom Subspace Method (RSM) for linear regression. Authors: Pawel\nTeisseyre, Robert A. Klopotek.\n\nrepfdr\n\nReplicability Analysis for Multiple Studies of High Dimension.\nAuthors: Ruth Heller, Shachar Kaufman, Shay Yaacoby, Daniel\nYekutieli.\n\nreportRx\n\nTools for automatically generating reproducible clinical report.\nAuthors: Ryan Del Bel, Wei Xu.\n\nresample\n\nResampling functions. Author: Tim Hesterberg.\n\nresemble\n\nRegression and similarity evaluation for memory-based learning in\nspectral chemometrics. Authors: Leonardo Ramirez-Lopez and Antoine\nStevens. In view:\nChemPhys.\n\nrevealedPrefs\n\nRevealed preferences and microeconomic rationality. Author: Julien\nBoelaert.\n\nrgabriel\n\nGabriel Multiple Comparison Test and Plot the Confidence Interval on\nBarplot. Authors: Yihui Xie, Miao Yu.\n\nrgpui\n\nUI for the RGP genetic programming framework. Author: Oliver Flasch.\n\nrinat\n\nAccess iNaturalist data through APIs. Authors: Vijay Barve, Edmund\nHart.\n\nriverplot\n\nSankey or ribbon plots. Author: January Weiner.\n\nrivervis\n\nRiver Visualisation Tool. Authors: Feng Mao, Yichuan Shi, and Keith\nRichards.\n\nrlist\n\nA toolset for working with lists. Author: Kun Ren.\n\nrmaf\n\nRefined Moving Average Filter. Author: Debin Qiu. In view:\nTimeSeries.\n\nrmatio\n\nRead and write matlab files. Authors: Stefan Widgren [aut, cre]\n(Author of the R interface to the C-library matio), Christopher\nHulbert [aut] (Author of the C-library matio,\nhttp://sourceforge.net/projects/matio/). In view:\nSpatioTemporal.\n\nrmngb\n\nrmngb Miscellaneous. Author: Antoine Filipovic Pierucci.\n\nrnoaa\n\nNOAA climate data from R. Authors: Hart Edmund [aut, cre], Scott\nChamberlain [aut], Karthik Ram [aut]. In view:\nWebTechnologies.\n\nrobcor\n\nRobust Correlations. Author: Paul Smirnov. In view:\nRobust.\n\nrobumeta\n\nRobust variance meta-regression. Authors: Zachary Fisher and\nElizabeth Tipton. In views:\nMetaAnalysis,\nRobust.\n\nrorutadis\n\nRobust Ordinal Regression UTADIS. Author: Krzysztof Ciomek.\n\nrpart.utils\n\nTools for parsing and manipulating rpart objects, including\ngenerating machine readable rules. Author: Craig Varrichio.\n\nrpartitions\n\nCode for integer partitioning. Authors: Ken Locey, Daniel McGlinn.\n\nrprintf\n\nAdaptive builder for formatted strings. Author: Kun Ren.\n\nrstudioapi\n\nSafely access the RStudio API. Author: RStudio.\n\nrvTDT\n\nPopulation control weighted rare-variants TDT. Authors: Yu Jiang,\nAndrew S. Allen.\n\nryouready\n\nCompanion to the “R your ready?” book. Author: Mark Heckmann.\n\ns2dverification\n\nSet of common tools for model diagnostics. Authors: Nicolau Manubens\nGil, Virginie Guemas, Isabel Andreu-Burillo, Fabian Lienert, Javier\nGarcia-Serrano, Ludovic Auger.\n\nsamplesize4surveys\n\nSample size calculations for complex surveys. Author: Hugo Andres\nGutierrez Rojas.\n\nsand\n\nStatistical Analysis of Network Data with R. Authors: Eric D\nKolaczyk, Gabor Csardi.\n\nsbioPN\n\nSimulation of deterministic and stochastic spatial biochemical\nreaction networks using Petri Nets. Authors: Roberto Bertolusso and\nMarek Kimmel.\n\nscalreg\n\nScaled sparse linear regression. Author: Tingni Sun.\n\nscrypt\n\nScrypt key derivation functions for R. Authors: RStudio, Inc.; Colin\nPercival.\n\nsdmvspecies\n\nCreate virtual species for species distribution modelling. Authors:\nXiaoquan Kong, Renyan Duan, Minyi Huang.\n\nseasonal\n\nR interface to X-13ARIMA-SEATS. Author: Christoph Sax. In views:\nOfficialStatistics,\nTimeSeries.\n\nseawaveQ\n\nU.S. Geological Survey seawaveQ model. Authors: Karen R. Ryberg and\nAldo V. Vecchia.\n\nsecrdesign\n\nSampling Design for Spatially Explicit Capture–Recapture. Author:\nMurray Efford.\n\nsemiArtificial\n\nGenerator of semi-artificial data. Author: Marko Robnik-Sikonja.\n\nsensitivitymw\n\nSensitivity analysis using weighted M-statistics. Author: Paul R.\nRosenbaum.\n\nseqDesign\n\nSimulation and group sequential monitoring of randomized multi-arm\ntwo-stage Phase IIb/III treatment efficacy trials with time-to-event\nendpoints. Authors: Michal Juraska and Doug Grove, with\ncontributions from Xuesong Yu and Peter B. Gilbert.\n\nsequenza\n\nAnalysis and visualization of tumor genome sequencing data. Authors:\nFrancesco Favero, Andrea M. Marquard, Tejal Joshi, Aron C. Eklund.\n\nsesem\n\nSpatially explicit structural equation modeling. Authors: Eric Lamb\n[aut, cre], Kerrie Mengersen [aut], Katherine Stewart [aut],\nUdayanga Attanayake [aut], Steven Siciliano [aut].\n\nsglOptim\n\nSparse group lasso generic optimizer. Author: Martin Vincent.\n\nsglasso\n\nLasso method for RCON(V,E) models. Author: Luigi Augugliaro.\n\nsglr\n\nPower and boundary calculations in pre-licensure vaccine trials\nusing a sequential generalized likelihood ratio test. Authors:\nBalasubramanian Narasimhan [aut, cre], Mei-Chiung Shih [aut].\n\nsharpshootR\n\nA collection of functions to support soil survey. Author: USDA-NRCS\nSoil Survey Staff.\n\nshinyBS\n\nTwitter Bootstrap Components for Shiny. Author: Eric Bailey.\n\nshinyFiles\n\nA server-side file system viewer for shiny. Author: Thomas Lin\nPedersen.\n\nshowtext\n\nEnable (any) R Graphics Device to Show Text Using System Fonts.\nAuthors: Yixuan Qiu and authors/contributors of the included\nsoftware.\n\nshp2graph\n\nConvert a SpatialLinesDataFrame object to an “igraph-class” object.\nAuthor: Binbin Lu.\n\nshuffle\n\nThe shuffle estimator for explainable variance. Author: Yuval\nBenjamini.\n\nsiRSM\n\nSingle-Index Response Surface Models. Authors: Huan Cheng, Mu Zhu.\n\nsimplexreg\n\nRegression Analysis of Proportional Data Using Simplex Distribution.\nAuthors: Peng Zhang, Zhengguo Qiu and Chengchun Shi.\n\nsiplab\n\nSpatial individual-plant modelling. Author: Oscar Garcia. In view:\nSpatial.\n\nsitar\n\nSITAR growth curve analysis. Author: Tim Cole.\n\nskda\n\nSparse (Multicategory) Kernel Discriminant Analysis. Authors: Len\nStefanski, Yichao Wu, and Kyle White.\n\nslfm\n\nTools for fitting sparse latent factor model. Authors: Joao Duarte\nand Vinicius Mayrink.\n\nsoc.ca\n\nSpecific correspondence analysis for the social sciences. Authors:\nAnton Grau Larsen, with contributions from Christoph Ellersgaard and\nStefan Andrade.\n\nsoilphysics\n\nSoil Physical Analysis. Authors: Anderson Rodrigo da Silva, Renato\nPaiva de Lima.\n\nsolr\n\nGeneral purpose R interface to Solr. Author: Scott Chamberlain\n[aut, cre].\n\nsortinghat\n\nAuthor: John A. Ramey.\n\nsotkanet\n\nSotkanet R Tools. Authors: Leo Lahti, Einari Happonen, Juuso\nParkkinen, Joona Lehtomaki.\n\nsp23design\n\nDesign and Simulation of seamless Phase II-III Clinical Trials.\nAuthors: Balasubramanian Narasimhan [aut, cre], Mei-Chiung Shih\n[aut], Pei He [aut].\n\nspBayesSurv\n\nSpatial Copula Modelling to Bayesian Survival Analysis. Authors:\nHaiming Zhou and Tim Hanson.\n\nspaMM\n\nMixed models, particularly spatial GLMMs. Authors: François Rousset\n[aut, cre, cph], Jean-Baptiste Ferdy [aut, cph]. In view:\nSpatial.\n\nspatial.gev.bma\n\nHierarchical spatial generalized extreme value (GEV) modeling with\nBayesian Model Averaging (BMA). Author: Alex Lenkoski.\n\nspatialTailDep\n\nEstimation of spatial tail dependence models. Authors: Anna\nKiriliouk, Johan Segers.\n\nspatsurv\n\nBayesian spatial survival analysis with parametric proportional\nhazards models. Authors: Benjamin M. Taylor and Barry S. Rowlingson.\nIn view: Survival.\n\nspcr\n\nSparse principal component regression. Author: Shuichi Kawano.\n\nspdynmod\n\nSpatio-dynamic wetland plant communities model. Authors: Javier\nMartinez-Lopez, Babak Naimi, Julia Martinez-Fernandez.\n\nspectral.methods\n\nSingular Spectrum Analysis (SSA) tools for time series analysis.\nAuthor: Jannis v. Buttlar. In view:\nTimeSeries.\n\nspfrontier\n\nSpatial Stochastic Frontier models estimation. Author: Dmitry\nPavlyuk.\n\nspocc\n\nR interface to many species occurrence data sources. Authors: Scott\nChamberlain [aut, cre], Karthik Ram [aut], Ted Hart [aut]. In\nview:\nWebTechnologies.\n\nsqliter\n\nConnection wrapper to SQLite databases. Author: Wilson Freitas.\n\nss3sim\n\nFisheries stock assessment simulation testing with Stock Synthesis.\nAuthors: Sean Anderson [aut, cre], Cole Monnahan [aut], Kelli\nJohnson [aut], Kotaro Ono [aut], Juan Valero [aut], Curry\nCunningham [aut], Felipe Hurtado-Ferro [aut], Roberto Licandeo\n[aut], Carey McGilliard [aut], Melissa Muradian [ctb], Cody\nSzuwalski [aut], Katyana Vert-pre [aut], Athol Whitten [aut].\n\nsse\n\nSample size estimation. Author: Thomas Fabbro.\n\nssym\n\nFitting Semiparametric Symmetric Regression Models. Authors: Luis\nHernando Vanegas and Gilberto A. Paula.\n\nstatfi\n\nstatfi R tools. Authors: Leo Lahti, Juuso Parkkinen, Joona\nLehtomaki.\n\nstilt\n\nSeparable Gaussian Process Interpolation (Emulation). Authors: Roman\nOlson, Won Chang, Klaus Keller, and Murali Haran.\n\nstm\n\nEstimation of the Structural Topic Model. Authors: Margaret E.\nRoberts, Brandon M. Stewart and Dustin Tingley.\n\nstochprofML\n\nStochastic Profiling using Maximum Likelihood Estimation. Author:\nChristiane Fuchs.\n\nstosim\n\nStochastic Simulator for Reliability Modeling of Repairable Systems.\nAuthor: Jacob T. Ormerod.\n\nstrap\n\nStratigraphic Tree Analysis for Palaeontology. Author: Mark A. Bell\nGraeme T. Lloyd.\n\nstreamMOA\n\nstream Interface to MOA Algorithms. Authors: Michael Hahsler\n[aut, cre, cph], Matthew Bolanos [aut, cph], John Forrest [aut,\ncph].\n\nstressr\n\nFetch and plot financial stress index and component data. Author:\nMatt Barry.\n\nstringi\n\nCharacter string processing facilities. Authors: Marek Gagolewski\nand Bartek Tartanus (stringi source code); IBM and other\ncontributors (ICU4C 52.1 source code); Unicode, Inc. (Unicode\nCharacter Database).\n\nstsm\n\nStructural Time Series Models. Author: Javier López-de-Lacalle. In\nview: TimeSeries.\n\nstsm.class\n\nClass and Methods for Structural Time Series Models. Author: Javier\nLópez-de-Lacalle. In view:\nTimeSeries.\n\nsubsemble\n\nAn Ensemble Method for Combining Subset-Specific Algorithm Fits.\nAuthors: Erin LeDell, Stephanie Sapp, Mark van der Laan.\n\nsurvivalMPL\n\nPenalised Maximum Likelihood for Survival Analysis Models. Authors:\nDominique-Laurent Couturier, Jun Ma, Stephane Heritier.\n\nsweSCB\n\nAn R interface to the web API of Statistics Sweden. Authors: Love\nHansson, Thomas Reinholdsson, Mans Magnusson. In view:\nWebTechnologies.\n\nswirl\n\nStatistics with Interactive R Learning. Authors: Nick Carchedi\n[aut, cre], Bill Bauer [aut], Gina Grdina [aut], Sean Kross\n[aut].\n\nsybilccFBA\n\nCost Constrained FLux Balance Analysis: MetabOlic Modeling with\nENzyme kineTics (MOMENT). Author: Abdelmoneim Amer Desouki [aut,\ncre].\n\nsybilcycleFreeFlux\n\ncycle-Free Flux balance analysis: Efficient removal of\nthermodynamically infeasible cycles from metabolic flux\ndistributions. Author: Abdelmoneim Amer Desouki [aut, cre].\n\nsynchrony\n\nMethods for computing spatial, temporal, and spatiotemporal\nstatistics. Author: Tarik C. Gouhier.\n\nsynlik\n\nSynthetic Likelihood methods for intractable likelihoods. Authors:\nMatteo Fasiolo and Simon Wood.\n\nsysfonts\n\nLoading system fonts into R. Authors: Yixuan Qiu and\nauthors/contributors of the included fonts.\n\ntab\n\nFunctions for creating summary tables for statistical reports.\nAuthor: Dane R. Van Domelen.\n\ntableone\n\nCreate “Table 1” to describe baseline characteristics. Authors:\nKazuki Yoshida, Justin Bohn.\n\nthreeboost\n\nThresholded variable selection and prediction based on estimating\nequations. Authors: Julian Wolfson and Christopher Miller.\n\ntictoc\n\nFunctions for timing R scripts, as well as implementations of Stack\nand List structures. Author: Sergei Izrailev.\n\ntigerstats\n\nR for Elementary Statistics. Authors: Rebekah Robinson and Homer\nWhite.\n\ntm.plugin.alceste\n\nImport texts from files in the Alceste format using the tm text\nmining framework. Author: Milan Bouchet-Valat [aut, cre]. In view:\nNaturalLanguageProcessing.\n\ntm.plugin.europresse\n\nImport articles from Europresse using the tm text mining\nframework. Author: Milan Bouchet-Valat [aut, cre]. In view:\nNaturalLanguageProcessing.\n\ntm.plugin.lexisnexis\n\nImport articles from LexisNexis using the tm text mining\nframework. Author: Milan Bouchet-Valat [aut, cre]. In view:\nNaturalLanguageProcessing.\n\ntmle.npvi\n\nTargeted Minimum Loss Estimation (TMLE) of a NP variable importance\nof a continuous exposure. Authors: Antoine Chambaz, Pierre Neuvial.\n\ntoaster\n\nanalytics and visualization with Aster Database. Author: Gregory\nKanevsky. In view:\nHighPerformanceComputing.\n\ntosls\n\nInstrumental Variables Two Stage Least Squares estimation. Author:\nZaghdoudi Taha.\n\ntransnet\n\nConducts transmission modeling on a bayesian network. Authors: Alun\nThomas [aut, cph], Andrew Redd [com, cre, ctb].\n\ntransport\n\nOptimal transport in various forms. Authors: Dominic Schuhmacher\nwith substantial contributions of code by Bjoern Baehre and Carsten\nGottschlich.\n\ntsintermittent\n\nIntermittent Time Series Forecasting. Authors: Nikolaos Kourentzes\nand Fotios Petropoulos. In view:\nTimeSeries.\n\ntsoutliers\n\nAutomatic Detection of Outliers in Time Series. Author: Javier\nLópez-de-Lacalle. In view:\nTimeSeries.\n\nturfR\n\nTURF Analysis for R. Author: Jack Horne [aut, cre].\n\ntvm\n\nTime Value of Money Functions. Author: Juan Manuel Truppia. In view:\nFinance.\n\nucbthesis\n\nUC Berkeley graduate division thesis template. Author: Steven\nPollack.\n\nunbalanced\n\nImplementation of different data-driven method for unbalanced\ndatasets. Authors: Andrea Dal Pozzolo, Olivier Caelen and Gianluca\nBontempi.\n\nuniReg\n\nUnimodal penalized spline regression using B-splines. Author:\nClaudia Koellmann.\n\nuplift\n\nUplift Modeling. Author: Leo Guelman.\n\nuserfriendlyscience\n\nQuantitative analysis made accessible. Author: Gjalt-Jorn Peters.\n\nustyc\n\nFetch US Treasury yield curve data. Author: Matt Barry.\n\nvardpoor\n\nVariance estimation for sample surveys by the ultimate cluster\nmethod. Authors: Juris Breidaks [aut, cre], Martins Liberts\n[aut].\n\nvbsr\n\nVariational Bayes Spike Regression Regularized Linear Models.\nAuthor: Benjamin Logsdon.\n\nvdg\n\nVariance Dispersion Graphs and Fraction of Design Space Plots.\nAuthor: Pieter Schoonees [aut, cre, cph].\n\nvecsets\n\nlike base::sets tools but keeps duplicate elements. Author: Carl\nWitthoft.\n\nwbs\n\nWild Binary Segmentation for multiple change-point detection.\nAuthors: Rafal Baranowski and Piotr Fryzlewicz.\n\nweatherData\n\nGet Weather Data from the Web. Author: Ram Narasimhan. In view:\nWebTechnologies.\n\nwesanderson\n\nA Wes Anderson Palette Generator. Authors: Karthik Ram [aut, cre],\nRichards Clark [ctb].\n\nwrspathrow\n\nFunctions for working with Worldwide Reference System (WRS). Author:\nAlex Zvoleff [aut, cre].\n\nwrspathrowData\n\nData used by the wrspathrow package. Author: Alex Zvoleff [aut,\ncre].\n\nwskm\n\nWeighted \\(k\\)-means Clustering. Authors: Graham Williams [aut],\nJoshua Z Huang [aut], Xiaojun Chen [aut], Qiang Wang [aut],\nLongfei Xiao [aut], He Zhao [cre].\n\nwsrf\n\nWeighted Subspace Random Forest. Authors: Qinghan Meng [aut], He\nZhao [aut, cre], Graham Williams [aut], Junchao Lv [ctb].\n\nwtcrsk\n\nCompeting risks regression models with covariate-adjusted censoring\nweight. Author: Peng He. In view:\nSurvival.\n\nxergm\n\nExtensions for Exponential Random Graph Models (ERGM). Authors:\nPhilip Leifeld [aut, cre], Skyler J. Cranmer [aut], Bruce A.\nDesmarais [aut].\n\nxhmmScripts\n\nXHMM R scripts. Author: Menachem Fromer.\n\nycinterextra\n\nYield curve or zero-coupon prices interpolation and extrapolation.\nAuthor: Thierry Moudiki. In view:\nFinance.\n\nykmeans\n\nK-means using a target variable. Author: Yohei sato.\n\nyuima\n\nThe YUIMA Project package for SDEs. Author: YUIMA Project Team.\n\nzCompositions\n\nReplacement of zeros and nondetects in compositional data sets.\nAuthors: Javier Palarea-Albaladejo and Josep Antoni\nMartin-Fernandez.\n\nzoib\n\nBayesian Inference for Zero/One Inflated Beta Regression. Author:\nFang Liu with contributions YunChuan Kong.\n\n2 Other changes\nThe following packages were moved to the Archive: ANN, BINCO,\nBayesTree, CAscaling, CGP, CalciOMatic,\nChangeAnomalyDetection, ClinicalRobustPriors, CvM2SL1Test,\nCvM2SL2Test, DPM.GGM, DataFrameConstr, DesignPatterns,\nEasyUpliftTree, EstSimPDMP, ExactSampling, FunNet, GGIR,\nGGally, GOFSN, GUTS, GridR, HGLMMM, HIBAG, HMMmix,\nHiDimDA, JGR, JMLSD, LearnEDA, MAVTgsa, MCUSUM, MEWMA,\nMLDA, MTSKNN, MetaPath, MultiChIPmixHMM, PL.popN, POT,\nPeak2Trough, QLSpline, QT, RLastFM, RSearchYJ, RSofia,\nRTDAmeritrade, RTisean, RWebMA, RadialPlotter, RcppZiggurat,\nRecordLinkage, RiDMC, Rvelslant, SDisc, SNPRelate, SRMA,\nSigWinR, SlimPLS, Snowball, SparseTSCGM, SpatialPack,\nStochaTR, StructR, TAHMMAnnot, TGUICore, TGUITeaching, TPAM,\nTSPC, TWIX, TinnR, ToxLim, VisCov, VizCompX, WMTregions,\nWeightedCluster, XiMpLe, YjdnJlp, adk, ageprior, aggrisk,\nbinarySimCLF, birch, bscr, caGUI, cems, charlson,\ncladoRpp, cldr, colcor, compositionsGUI, convevol, copas,\ncorrperm, cpm, dynpred, easystab, eco, ecp, eigendog,\nel.convex, epibase, evtree, flubase, gamesNws, gazetools,\ngdsfmt, gearman, glmmAK, glrt, gmvalid, govdat, gppois,\ngregmisc, h5r, hints, hof, iSubpathwayMiner, iWebPlots,\nimputation, indicspecies, int64, kernelPop, knorm, koRpus,\nleiv, ljr, lossDev, magnets, mchof, mixfdr, mtcreator,\nmugnet, mutatr, ndvits, nga, nloptwrap, numConversion,\nodprism, opencpu.encode, orth, pa, pamctdp, parboost,\npcrsim, pcurve, pgmm, postgwas, ppMeasures, probemapper,\nprotoclust, pycno, rHadoopClient, rbamtools, readMETEO,\nrlandscape, rmac, rngSetSeed, rolasized, ropensnp,\nscapeMCMC, sensitivityPStrat, seq2R, sessionTools, shapes,\nsheldusr, sifds, simPopulation, sinartra, skewtools, snort,\nspclust, sprint, sspir, stochmod, stratasphere, survivalBIV,\ntagcloud, tclust, tmg, tonymisc, ttime, validator, vmv,\nwaveclock, websockets, wethepeople, xpose4classic, xpose4data,\nxpose4generic, xpose4specific\nThe following packages were resurrected from the Archive: BootPR,\nCatDyn, LSC, RFreak, RHive, RcmdrPlugin.pointG,\nRcmdrPlugin.sos, Sim.DiffProc, anchors, binhf, binomSamSize,\nbujar, cem, cladoRcpp, clues, clusterfly, cond, cplm,\ncsampling, dtt, elrm, epinet, extfunnel, fbati, financial,\nfitDRC, fractal, geospacom, hydrogeo, languageR, ltsk,\nmarg, mblm, mmeta, nlreg, npst, pcaPA, polytomous, ripa,\nrsdepth, simone, spacom, tikzDevice\nThe following package had to be removed: CDS.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2014-1-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2014-1 issue.",
    "author": [
      {
        "name": "Deepayan Sarkar",
        "url": {}
      }
    ],
    "date": "2014-06-01",
    "categories": [],
    "contents": "\n\nOn behalf of the editorial board, I am pleased to publish Volume 6,\nIssue 1 of the R Journal.\nAs usual, the bulk of the articles in this issue describe a variety of R\npackages, whose diversity reflects the ever increasing reach of R. Many\nof these packages make new data analysis methods available to the R\ncommunity: LS2Wstat implements a test of spatial stationarity for\ntextured images, straweib implements stratified Weibull regression\nmodels for interval-censored survival data, rotations provides various\ntools to work with rotation data, ROSE implements methods to deal with\nbinary classification problems with high class imbalance, investr\nprovides tools to solve inverse estimation problems for both linear and\nnonlinear regression models, Rankcluster enables model-based\nclustering of multivariate as well as partial rankings, MRCV allows\nanalysis of data with multiple-response categorical variables, and\noligoMask enables the removal of systematic effects of genetic\nvariants when preprocessing microarray data. Several others fall into\nthe category of more general purpose tools: stringdist implements\nvarious string distance functions and approximate string matching based\non them, RStorm provides an environment to prototype and test\nstreaming algorithms, RWiener implements distribution functions for\nthe Wiener diffusion model that is useful for reaction time modeling,\nand sgr allows simulation of fake ordinal data to systematically study\nthe effect of faked responses on inference. Two articles discuss\npackages that provide interfaces to other systems: PivotalR to various\ndatabases and the MADlib library for in-database machine learning, and\ndvn to The Dataverse Network to allow archival and sharing of\nreproducible research. Finally, we have three visualization packages\nthat have quite different focus but share the common thread of\ninteractive browser-based displays: pitchRx (along with XML2R) can\nbe used to obtain and visualize basketball pitch data, brainR creates\ninteractive displays of neuroimaging data, and gridSVG allows the\nexporting of grid graphics in the SVG format with several additional\nfeatures.\nThe News and Notes section contains the usual updates on the R\nFoundation, the Bioconductor project, CRAN, and changes in R itself. In\naddition, we have a brief overview of the Web Technologies Task View\navailable on CRAN. We also have a short addendum to an article published\nin the last issue of the R Journal, “Statistical Software from a Blind\nPerson’s Perspective”, that provides a solution to a problem identified\nin the original article.\nI hope you enjoy the issue.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2014-1-r-changes/",
    "title": "Changes in R",
    "description": "The 'Changes in R' article from the 2014-1 issue.",
    "author": [
      {
        "name": "The R Core Team",
        "url": {}
      }
    ],
    "date": "2014-06-01",
    "categories": [],
    "contents": "\n\nCHANGES IN R 3.1.1\n\nNEW FEATURES\nWhen attach() reports conflicts, it does so compatibly with\nlibrary() by using message().\nR CMD Sweave no longer cleans any files by default, compatibly\nwith versions of R prior to 3.1.0. There are new options –clean,\n–clean=default and –clean=keepOuts.\ntools::buildVignette() and tools::buildVignettes() with\nclean = FALSE no longer remove any created files.\nbuildvignette() gains a keep argument for more cleaning\ncustomization.\nThe Bioconductor ‘version’ used by setRepositories() can now be\nset by environment variable R_BIOC_VERSION at runtime, not just\nwhen R is installed. (It has been stated that Bioconductor will\nswitch from ‘version’ 2.14 to ‘version’ 3.0 during the lifetime of\nthe R 3.1 series.)\nError messages from bugs in embedded Sexpr code in Sweave\ndocuments now report the source location.\ntype.convert(), read.table() and similar read.*() functions\nget a new numerals argument, specifying how numeric input is\nconverted when its conversion to double precision loses accuracy.\nThe default value, \"allow.loss\" allows accuracy loss, as in R\nversions before 3.1.0.\nFor some compilers, integer addition could overflow without a\nwarning. R’s internal code for both integer addition and subtraction\nis more robust now. (PR#15774)\nThe function determining the default number of knots for\nsmooth.spline() is now exported, as .nknots.smspl().\ndbeta(, a,b), pbeta(), qbeta() and rbeta() are now defined\nalso for \\(a = 0\\), \\(b = 0\\), or infinite \\(a\\) and \\(b\\) (where they\ntypically returned NaN before).\nMany package authors report that the RStudio graphics device does\nnot work correctly with their package’s use of dev.new(). The new\noption dev.new(noRStudioGD = TRUE) replaces the RStudio override\nby the default device as selected by R itself, still respecting\nenvironment variables R_INTERACTIVE_DEVICE and R_DEFAULT_DEVICE.\nreadRDS() now returns visibly.\nModifying internal logical scalar constants now results in an error\ninstead of a warning.\ninstall.packages(repos = NULL) now accepts http:// or ftp://\nURLs of package archives as well as file paths, and will download as\nrequired. In most cases repos = NULL can be deduced from the\nextension of the URL.\nThe warning when using partial matching with the $ operator on\ndata frames is now only given when\noptions(\"warnPartialMatchDollar\") is TRUE.\nPackage help requests like package?foo now try the package foo\nwhether loaded or not.\nGeneral help requests now default to trying all loaded packages, not\njust those on the search path.\nAdded a new function promptImport(), to generate a help page for a\nfunction that was imported from another package (and presumably\nre-exported, or help would not be needed).\n\n\nINSTALLATION and INCLUDED SOFTWARE\nconfigure option –with-internal-tzcode can now be used with\nvariable rsharedir.\nThe included version of PCRE has been updated to 8.35.\nThere is a new target make uninstall-libR to remove an installed\nshared/static libR.\nmake install-libR now works if a sub-architecture is used,\nalthough the user will need to specify libdir differently for\ndifferent sub-architectures.\nThere is more extensive advice on which LaTeX packages are required\nto install R or to make package manuals (as done by R CMD check)\nin the ‘Writing R Extensions’ manual.\nCompilers/linkers were handling the visibility control in\nsrc/extra/xz inconsistently (and apparently in some cases\nincorrectly), so it has been simplified. (PR#15327)\n(Windows) There is updated support for the use of ICU for collation:\nsee the ‘R Installation and Administration Manual’.\n\n\nBUG FIXES\ndbinom(x, n), pbinom(), dpois(), etc, are slightly less\nrestrictive in checking if n is integer-valued. (Wish of\nPR#15734.)\npchisq(x, df, ncp, log.p = TRUE) is more accurate and no longer\nunderflows for small x and ncp < 80, e.g, for\npchisq(1e-5, df = 100, ncp = 1, log = TRUE). (Based on PR#15635\nand a suggestion by Roby Joehanes.)\nThe s (“step into”) command in the debugger would cause R to step\ninto expressions evaluated there, not just into functions being\ndebugged. (PR#15770)\nThe C code used by strptime() rejected time-zone offsets of more\nthan +1200 (+1245, +1300 and +1400 can occur). (PR#15768)\n(Windows only.) png(type = \"cairo\", antialias = \"gray\") was not\naccepted. (PR#15760)\nUse of save(..., envir=) with named objects could fail. (PR#15758)\nSweave() mis-parsed Sexpr expressions that contained\nbackslashes. (PR#15779)\nThe return value from options(foo = NULL) was not the previous\nvalue of the option. (PR#15781)\nenc2utf8() and enc2native() did not always mark the encoding of\nthe return values when it was known.\ndnbinom(x, size = <large>, mu, log = TRUE) no longer underflows to\n-Inf for large mu, thanks to a suggestion from Alessandro Mammana\n(MPI MolGen, Berlin).\npbeta(x, a, b, log = TRUE) no longer behaves discontinuously (in a\nsmall x-region) because of denormalized numbers. Also,\npbeta(1-1e-12, 1e30, 1.001, log=TRUE) now terminates “in real\ntime”.\nThe \"CRAN\" filter (see available.packages()) no longer removes\nduplicates other than of packages on CRAN, and does not fail if\nthere is no CRAN repository in getOption(\"repos\").\nThe device listing from dev2bitmap() and bitmap() was truncated\nto 1000 characters: modern versions of GhostScript on most platforms\nhave many more devices.\n(Windows.) Commands such as Sys.which() and pipe() which needed\nto find the full path to a command could segfault if the ‘long’ path\nname was much longer than the ‘short’ path name (which Sys.which()\nreturns), as the behaviour of the Windows API call had changed.\nR CMD build will fail with an error if one of the packages\nspecified in the VignetteBuilder field is not installed. (Without\nloading those packages it cannot be ascertained which files are\nintended to be vignettes. This means that the VignetteBuilder\npackages have to be installed for package checking too.) (Wish of\nPR#15775.)\nMisguided attempts to use chull() with non-finite points now give\nan error (related to PR#15777).\nFor a formula with exactly 32 variables the 32nd variable was\naliased to the intercept in some C-level computations of terms, so\nthat for example attempting to remove it would remove the intercept\ninstead (and leave a corrupt internal structure). (PR#15735)\nanyDuplicated() silently returned wrong values when the first\nduplicate was at an index which was too large to be stored in an\ninteger vector (although a lot of RAM and patience would have been\nneeded to encounter this).\ntools::Rd2ex(commentDontrun = FALSE) failed if the block had only\none line.\nHexadecimal constants such as 0x110p-5L which were incorrectly\nqualified by L were parsed incorrectly since R 3.0.0, with a\nslightly garbled warning. (PR#15753)\nsystem() returned success on some platforms even if the system was\nunable to launch a process. (PR#15796)\n(Windows Rgui console.) Unbuffered output was sometimes not output\nimmediately if the prompt was not on the last line of the console.\nThe built-in help server did not declare the encoding for the\nDESCRIPTION or other text files to be the package encoding, so\nnon-ASCII characters could be displayed incorrectly.\nR is now trying harder to not cleanup child processes that were not\nspawned by mcparallel() on platforms that provide information\nabout the source process of the SIGCHLD signal. This allows 3rd\nparty libraries to manage the exit status of children that they\nspawn without R interfering.\nmcmapply() was only parallelizing if the number of jobs was bigger\nthan the number of cores. It now parallelizes if the number of jobs\nis more than one.\nAuto-printing would re-evaluate its argument when trying to dispatch\nto a print method. This is now avoided when possible.\nUnserializing (including load() and readRDS()) could silently\nreturn incorrect numeric values from ASCII saves if there was a read\nerror.\ngetParseData() could return incorrect values for the parents of\nsome elements. (Reported by Andrew Redd.)\nAttempting to use data frames of 2^31 or more rows with merge()\nor to create a merged data frame of that size now gives a clearer\nerror message.\nparse() did not check its file argument was a connection if it\nwas not a character string, so e.g. parse(FALSE) attempted to read\nfrom stdin.\nNor did dump() and dput().\nThe \"help.try.all.packages\" option was ignored when the shortcut\nsyntax for help was used, e.g. ?foo.\nA potential segfault in string allocation has been fixed. (Found by\nRadford Neal.)\nPotential memory protection errors in sort() and D() have been\nfixed. (Found by Radford Neal.)\nFixed a lack of error checking in graphics event functions. (Found\nby Radford Neal; a different patch used here than the one in pqR.)\nnumericDeriv() sometimes miscalculated the gradient. (PR#15849,\nreported originally by Radford Neal)\n\nCHANGES IN R 3.1.0\n\nNEW FEATURES\ntype.convert() (and hence by default read.table()) returns a\ncharacter vector or factor when representing a numeric input as a\ndouble would lose accuracy. Similarly for complex inputs.\nIf a file contains numeric data with unrepresentable numbers of\ndecimal places that are intended to be read as numeric, specify\ncolClasses in read.table() to be \"numeric\".\ntools::Rdiff(useDiff = FALSE) is closer to the POSIX definition of\ndiff -b (as distinct from the description in the man pages of\nmost systems).\nNew function anyNA(), a version of any(is.na(.)) which is fast\nfor atomic vectors, based on a proposal by Tim Hesterberg. (Wish of\nPR#15239.)\narrayInd(*, useNames = TRUE) and, analogously,\nwhich(*, arr.ind = TRUE) now make use of names(.dimnames) when\navailable.\nis.unsorted() now also works for raw vectors.\nThe \"table\" method for as.data.frame() (also useful as\nas.data.frame.table()) now passes sep and base arguments to\nprovideDimnames().\nuniroot() gets new optional arguments, notably extendInt,\nallowing to auto-extend the search interval when needed. The return\nvalue has an extra component, init.it.\nswitch(f, ...) now warns when f is a factor, as this typically\nhappens accidentally where the useR meant to pass a character\nstring, but f is treated as integer (as always documented).\nThe parser has been modified to use less memory.\nThe way the unary operators (+ - !) handle attributes is now more\nconsistent. If there is no coercion, all attributes (including\nclass) are copied from the input to the result: otherwise only\nnames, dims and dimnames are.\ncolorRamp() and colorRampPalette() now allow non-opaque colours\nand a ramp in opacity via the new argument alpha = TRUE.\n(Suggested by Alberto Krone-Martins, but optionally as there are\nexisting uses which expect only RGB values.)\ngrid.show.layout() and grid.show.viewport() get an optional\nvp.ex argument.\nThere is a new function find_gs_cmd() in the tools package to\nlocate a GhostScript executable. (This is an enhanced version of a\npreviously internal function there.)\nobject.size() gains a format() method.\nThere is a new family, \"ArialMT\", for the pdf() and\npostscript() devices. This will only be rendered correctly on\nviewers which have access to Monotype TrueType fonts (which are\nsometimes requested by journals).\nThe text and PDF news files, including NEWS and NEWS.2, have\nbeen moved to the doc directory.\ncombn(x, simplify = TRUE) now gives a factor result for factor\ninput x (previously user error). (Related to PR#15442.)\nAdded utils::fileSnapshot() and utils::changedFiles() functions\nto allow snapshots and comparison of directories of files.\nmake.names(names, unique=TRUE) now tries to preserve existing\nnames. (Suggestion of PR#15452.)\nNew functions cospi(x), sinpi(x), and tanpi(x), for more\naccurate computation of cos(pi*x), etc, both in R and the C API.\nUsing these gains accuracy in some cases, e.g., inside lgamma() or\nbesselI(). (Suggested by Morten Welinder in PR#15529.)\nprint.table(x, zero.print = \".\") now also has an effect when x\nis not integer-valued.\nThere is more support to explore the system’s idea of time-zone\nnames. Sys.timezone() tries to give the current system setting by\nname (and succeeds at least on Linux, OS X, Solaris and Windows),\nand OlsonNames() lists the names in the system’s Olson database.\nSys.timezone(location = FALSE) gives the previous behaviour.\nPlatforms with a 64-bit time_t type are allowed to handle\nconversions between the \"POSIXct\" and \"POSIXlt\" classes for\ndate-times outside the 32-bit range (before 1902 or after 2037): the\nexisting workarounds are used on other platforms. (Note that\ntime-zone information for post-2037 is speculative at best, and the\nOS services are tested for known errors and so not used on OS X.)\nCurrently time_t is usually long and hence 64-bit on Unix-alike\n64-bit platforms: however in several cases the time-zone database is\n32-bit. For R for Windows it is 64-bit (for both architectures as\nfrom this version).\nThe \"save.defaults\" option can include a value for\ncompression_level. (Wish of PR#15579.)\ncolSums() and friends now have support for arrays and data-frame\ncolumns with \\(2^{31}\\) or more elements.\nas.factor() is faster when f is an unclassed integer vector (for\nexample, when called from tapply()).\nfft() now works with longer inputs, from the 12 million previously\nsupported up to 2 billion. (PR#15593)\nComplex svd() now uses LAPACK subroutine ZGESDD, the complex\nanalogue of the routine used for the real case.\nSweave now outputs .tex files in UTF-8 if the input encoding is\ndeclared to be UTF-8, regardless of the local encoding. The UTF-8\nencoding may now be declared using a LaTeX comment containing the\nstring %\\\\SweaveUTF8 on a line by itself.\nfile.copy() gains a copy.date argument.\nPrinting of date-times will make use of the time-zone abbreviation\nin use at the time, if known. For example, for Paris pre-1940 this\ncould be LMT, PMT, WET or WEST. To enable this, the\n\"POSIXlt\" class has an optional component \"zone\" recording the\nabbreviation for each element.\nFor platforms which support it, there is also a component \"gmtoff\"\nrecording the offset from GMT where known.\n(On Windows, by default on OS X and optionally elsewhere.) The\nsystem C function strftime has been replaced by a more\ncomprehensive version with closer conformance to the POSIX 2008\nstandard.\ndnorm(x, log = FALSE) is more accurate (but somewhat slower) for\n|x| > 5; as suggested in PR#15620.\nSome versions of the tiff() device have further compression\noptions.\nread.table(), readLines() and scan() have a new argument to\ninfluence the treatment of embedded nuls.\nAvoid duplicating the right hand side values in complex assignments\nwhen possible. This reduces copying of replacement values in\nexpressions such as Z$a <- a0 and ans[[i]] <- tmp: some package\ncode has relied on there being copies.\nAlso, a number of other changes to reduce copying of objects; all\ncontributed by or based on suggestions by Michael Lawrence.\nThe fast argument of KalmanLike(), KalmanRun() and\nKalmanForecast() has been replaced by update, which instead of\nupdating mod in place, optionally returns the updated model in an\nattribute \"mod\" of the return value.\narima() and makeARIMA() get a new optional argument SSinit,\nallowing the choice of a different state space\ninitialization which has been observed to be more reliable close to\nnon-stationarity: see PR#14682.\nwarning() has a new argument noBreaks., to simplify\npost-processing of output with options(warn = 1).\npushBack() gains an argument encoding, to support reading of\nUTF-8 characters using scan(), read.table() and related\nfunctions in a non-UTF-8 locale.\nall.equal.list() gets a new argument use.names which by default\nlabels differing components by names (if they match) rather than by\ninteger index. Saved R output in packages may need to be updated.\nThe methods for all.equal() and attr.all.equal() now have\nargument check.attributes after ... so it cannot be partially\nnor positionally matched (as it has been, unintentionally).\nA side effect is that some previously undetected errors of passing\nempty arguments (no object between commas) to all.equal() are\ndetected and reported.\nThere are explicit checks that check.attributes is logical,\ntolerance is numeric and scale is NULL or numeric. This\ncatches some unintended positional matching.\nThe message for all.equal.numeric() reports a\n\"scaled difference\" only for scale != 1.\nall.equal() now has a \"POSIXt\" method replacing the \"POSIXct\"\nmethod.\nThe \"Date\" and \"POSIXt\" methods of seq() allows\nby = \"quarter\" for completeness (by = \"3 months\" always worked).\nfile.path() removes any trailing separator on Windows, where they\nare invalid (although sometimes accepted). This is intended to\nenhance the portability of code written by those using POSIX file\nsystems (where a trailing / can be used to confine path matching\nto directories).\nNew function agrepl() which like grepl() returns a logical\nvector.\nfifo() is now supported on Windows. (PR#15600)\nsort.list(method = \"radix\") now allows negative integers (wish of\nPR#15644).\nSome functionality of print.ts() is now available in\n.preformat.ts() for more modularity.\nmcparallel() gains an option detach = TRUE which allows\nexecution of code independently of the current session. It is based\non a new estranged = TRUE argument to mcfork() which forks child\nprocesses such that they become independent of the parent process.\nThe pdf() device omits circles and text at extremely small sizes,\nsince some viewers were failing on such files.\nThe rightmost break for the \"months\", \"quarters\" and \"years\"\ncases of hist.POSIXlt() has been increased by a day. (Inter alia,\nfixes PR#15717.)\nThe handling of DF[i,] <- a where i is of length 0 is improved.\n(Inter alia, fixes PR#15718.)\nhclust() gains a new method \"ward.D2\" which implements Ward’s\nmethod correctly. The previous \"ward\" method is \"ward.D\" now,\nwith the old name still working. Thanks to research and proposals by\nPierre Legendre.\nThe sunspot.month dataset has been amended and updated from the\nofficial source, whereas the sunspots and sunspot.year datasets\nwill remain immutable. The documentation and source links have been\nupdated correspondingly.\nThe summary() method for \"lm\" fits warns if the fit is\nessentially perfect, as most of the summary may be computed\ninaccurately (and with platform-dependent values).\nProgrammers who use summary() in order to extract just a component\nwhich will be reliable (e.g. $cov.unscaled) should wrap their\ncalls in suppressWarnings().\n\n\nINSTALLATION and INCLUDED SOFTWARE\nThe included version of LAPACK has been updated to 3.5.0.\nThere is some support for parallel testing of an installation, by\nsetting TEST_MC_CORES to an integer greater than one to indicate\nthe maximum number of cores to be used in parallel. (It is worth\nspecifying at least 8 cores if available.) Most of these require a\nmake program (such as GNU make and dmake) which supports the\n$MAKE -j nproc syntax.\nExcept on Windows: the tests of standard package examples in\nmake check are done in parallel. This also applies to running\ntools::testInstalledPackages().\nThe more time-consuming regression tests are done in parallel.\nThe package checks in make check-devel and\nmake check-recommended are done in parallel.\nMore of make check will work if recommended packages are not\ninstalled: but recommended packages remain needed for thorough\nchecking of an R build.\nThe version of tzcode included in src/extra/tzone has been\nupdated. (Formerly used only on Windows.)\nThe included (64-bit) time-zone conversion code and Olson time-zone\ndatabase can be used instead of the system version: use configure\noption –with-internal-tzcode. This is the default on Windows and\nOS X. (Note that this does not currently work if a non-default\nrsharedir configure variable is used.)\n(It might be necessary to set environment variable TZ on OSes\nwhere this is not already set, although the system timezone is\ndeduced correctly on at least Linux, OS X and Windows.)\nThis option also switches to the version of strftime included in\ndirectory src/extra/tzone.\nconfigure now tests for a C++11-compliant compiler by testing some\nbasic features. This by default tries flags for the compiler\nspecified by CXX, but an alternative compiler, options and\nstandard can be specified by variables CXX1X, CXX1XFLAGS and\nCXX1XSTD (e.g. -std=gnu++11).\nR can now optionally be compiled to use reference counting instead\nof the NAMED mechanism by defining SWITCH_TO_REFCNT in\nRinternals.h. This may become the default in the future.\nThere is a new option –use-system-tre to use a suitable system\ntre library: at present this means a version from their git\nrepository, after corrections. (Wish of PR#15660.)\n\n\nPACKAGE INSTALLATION\nThe CRANextra repository is no longer a default repository on\nWindows: all the binary versions of packages from CRAN are now on\nCRAN, although CRANextra contains packages from Omegahat and\nelsewhere used by CRAN packages.\nOnly vignettes sources in directory vignettes are considered to be\nvignettes and hence indexed as such.\nIn the DESCRIPTION file,\nX11\nis no longer recognized as valid. Use MIT or BSD_2_clause\ninstead, both of which need + file LICENSE.\nFor consistency, entries in .Rinstignore are now matched\ncase-insensitively on all platforms.\nHelp for S4 methods with very long signatures now tries harder to\nsplit the description in the Usage field to no more than 80\ncharacters per line (some packages had over 120 characters).\nR CMD INSTALL –build (not Windows) now defaults to the internal\ntar() unless R_INSTALL_TAR is set.\nThere is support for compiling C++11 code in packages on suitable\nplatforms: see ‘Writing R Extensions’.\nFake installs now install the contents of directory inst: some\npackages use this to install e.g. C++ headers for use by other\npackages that are independent of the package itself. Option\n–no-inst can be used to get the previous behaviour.\n\n\nDEBUGGING\nThe behaviour of the code browser has been made more consistent, in\npart following the suggestions in PR#14985.\nCalls to browser() are now consistent with calls to the browser\ntriggered by debug(), in that will default to n rather than c.\nA new browser command s has been added, to “step into” function\ncalls.\nA new browser command f has been added, to “finish” the current\nloop or function.\nWithin the browser, the command help will display a short list of\navailable commands.\n\n\nUTILITIES\nOnly vignettes sources in directory vignettes are considered to be\nvignettes by R CMD check. That has been the preferred location\nsince R 2.14.0 and is now obligatory.\nFor consistency, R CMD build now matches entries in\n.Rbuildignore and vignettes/.install_extras case-insensitively\non all platforms (not just on Windows).\ncheckFF() (called by R CMD check by default) can optionally\ncheck foreign function calls for consistency with the registered\ntype and argument count. This is the default for\nR CMD check –as-cran or can be enabled by setting environment\nvariable _R_CHECK_FF_CALLS_ to registration (but is in any case\nsuppressed by –install=no). Because this checks calls in which\n.NAME is an R object and not just a literal character string, some\nother problems are detected for such calls.\nFunctions suppressForeignCheck() and dontCheck() have been added\nto allow package authors to suppress false positive reports.\nR CMD check –as-cran warns about a false value of the\nDESCRIPTION field BuildVignettes for Open Source packages, and\nignores it. (An Open Source package needs to have complete sources\nfor its vignettes which should be usable on a suitably well-equipped\nsystem).\nR CMD check –no-rebuild-vignettes is defunct:R CMD check –no-build-vignettes has been preferred since R 3.0.0.\nR CMD build –no-vignettes is defunct:R CMD build –no-build-vignettes has been preferred since R 3.0.0.\nR CMD Sweave and R CMD Stangle now process both Sweave and\nnon-Sweave vignettes. The tools::buildVignette() function has been\nadded to do the same tasks from within R.\nThe flags returned by R CMD config –ldflags and (where installed)\npkg-config –libs libR are now those needed to link a front-end\nagainst the (shared or static) R library.\nSweave.sty has a new option [inconsolata].\nR CMD check customizations such as _R_CHECK_DEPENDS_ONLY_ make\navailable packages only in LinkingTo only for installation, and\nnot for loading/runtime tests.\ntools::checkFF() reports on .C and .Fortran calls with\nDUP = FALSE if argument check_DUP is true. This is selected by\nR CMD check by default.\nR CMD check –use-gct can be tuned to garbage-collect less\nfrequently using gctorture2() via the setting of environment\nvariable _R_CHECK_GCT_N_.\nWhere supported, tools::texi2dvi() limits the number of passes\ntried to 20.\n\n\nC-LEVEL FACILITIES\n(Windows only) A function R_WaitEvent() has been added (with\ndeclaration in headerR.h) to block execution until the next event\nis received by R.\nRemapping in the Rmath.h header can be suppressed by defining\nR_NO_REMAP_RMATH.\nThe remapping of rround() in header Rmath.h has been removed:\nuse fround() instead.\nftrunc() in header Rmath.h is now a wrapper for the C99 function\ntrunc(), which might as well be used in C code: ftrunc() is\nstill needed for portable C++ code.\nThe never-documented remapping of prec() to fprec() in header\nRmath.h has been removed.\nThe included LAPACK subset now contains ZGESDD and ZGELSD.\nThe function LENGTH() now checks that it is only applied to vector\narguments. However, in packages length() should be used. (In R\nitself LENGTH() is a macro without the function overhead of\nlength().)\nCalls to SET_VECTOR_ELT() and SET_STRING_ELT() are now checked\nfor indices which are in-range: several packages were writing one\nelement beyond the allocated length.\nallocVector3 has been added which allows custom allocators to be\nused for individual vector allocations.\n\n\nDEPRECATED AND DEFUNCT\nchol(pivot = TRUE, LINPACK = TRUE) is defunct.\nArguments EISPACK for eigen() and LINPACK for chol(),\nchol2inv(), solve() and svd() are ignored: LAPACK is always\nused.\n.find.package() and .path.package() are defunct: only the\nversions without the initial dot introduced in R 2.13.0 have ever\nbeen in the API.\nPartial matching when using the $ operator on data frames now\nthrows a warning and may become defunct in the future. If partial\nmatching is intended, replace foo$bar by\nfoo[[\"bar\", exact = FALSE]].\nThe long-deprecated use of \\\\synopsis in the Usage section of\n.Rd files has been removed: such sections are now ignored (with a\nwarning).\npackage.skeleton()’s deprecated argument namespace has been\nremoved.\nMany methods are no longer exported by package stats. They are all\nregistered on their generic, which should be called rather than\ncalling a method directly.\nFunctions readNEWS() and checkNEWS() in package tools are\ndefunct.\ndownload.file(method = \"lynx\") is deprecated.\n.C(DUP = FALSE) and .Fortran(DUP = FALSE) are now deprecated,\nand may be disabled in future versions of R. As their help has long\nsaid, .Call() is much preferred.\nR CMD check notes such usages (by default).\nThe workaround of setting R_OSX_VALGRIND has been removed: it is\nnot needed in current valgrind.\n\n\nBUG FIXES\nCalling lm.wfit() with no non-zero weights gave an array-overrun\nin the Fortran code and a not very sensible answer. It is now\nspecial-cased with a simpler answer (no qr component).\nError messages involving non-syntactic names (e.g. as produced by\n‘\\\\r‘ when that object does not exist) now encode the control\ncharacters. (Reported by Hadley Wickham.)\ngetGraphicsEvent() caused 100% usage of one CPU in Windows.\n(PR#15500)\nnls() with no start argument may now work inside another\nfunction (scoping issue).\npbeta() and similar work better for very large (billions) ncp.\nWhere time zones have changed abbreviations over the years, the\nsoftware tries to more consistently use the abbreviation appropriate\nto the time or if that is unknown, the current abbreviation. On some\nplatforms where the C function localtime changed the tzname\nvariables the reported abbreviation could have been that of the last\ntime converted.\nall.equal(list(1), identity) now works.\nBug fix for pushing viewports in grid (reported by JJ Allaire and\nKevin Ushey).\nNOTE for anyone poking around within the graphics engine display\nlist (despite the warnings not to) that this changes what is\nrecorded by grid on the graphics engine display list.\nExtra checks have been added for unit resolution and conversion in\ngrid, to catch instances of division-by-zero. This may introduce\nerror messages in existing code and/or produce a different result in\nexisting code (but only where a non-finite location or dimension may\nnow become zero).\nSome bugs in TRE have been corrected by updating from the git\nrepository. This allows R to be installed on some platforms for\nwhich this was a blocker (PR#15087 suggests Linux on ARM and HP-UX).\n? applied to a call to an S4 generic failed in several cases.\n(PR#15680)\nThe implicit S4 generics for primitives with ... in their argument\nlist were incorrect. (PR#15690)\nBug fixes to methods::callGeneric(). (PR#15691)\nThe bug fix to aggregrate() in PR#15004 introduced a new bug in\nthe case of no grouping variables. (PR#15699)\nIn rare cases printing deeply nested lists overran a buffer by one\nbyte and on a few platforms segfaulted. (PR#15679)\nThe dendrogram method of as.dendrogram() was hidden accidentally,\n(PR#15703), and order.dendrogram(d) gave too much for a leaf d.\n(PR#15702)\nR would try to kill processes on exit that have pids ever used by a\nchild process spawned by mcparallel even though the current\nprocess with that pid was not actually its child.\ncophenetic() applied to a \"dendrogram\" object sometimes\nincorrectly returned a \"Labels\" attribute with dimensions.\n(PR#15706)\nprintCoefmat() called from quite a few print() methods now obeys\nsmall getOption(\"width\") settings, line wrapping the\n\"signif. codes\" legend appropriately. (PR#15708)\nmodel.matrix() assumed that the stored dimnames for a matrix was\nNULL or length 2, but length 1 occurred.\nThe clipping region for a device was sometimes used in base graphics\nbefore it was set.\n\nCHANGES IN R 3.0.3\n\nNEW FEATURES\nOn Windows there is support for making .texi manuals using\ntexinfo 5.0 or later: the setting is in file\nsrc/gnuwin32/MkRules.dist.\nA packaging of the Perl script and modules for texinfo 5.2 has\nbeen made available at http://www.stats.ox.ac.uk/pub/Rtools/.\nwrite.table() now handles matrices of \\(2^{31}\\) or more elements,\nfor those with large amounts of patience and disc space.\nThere is a new function, La_version(), to report the version of\nLAPACK in use.\nThe HTML version of ‘An Introduction to R’ now has links to PNG\nversions of the figures.\nThere is some support to produce manuals in ebook formats. (See\ndoc/manual/Makefile. Suggested by Mauro Cavalcanti.)\nOn a Unix-alike Sys.timezone() returns NA if the environment\nvariable TZ is unset, to distinguish it from an empty string which\non some OSes means the UTC time zone.\nThe backtick may now be escaped in strings, to allow names\ncontaining them to be constructed, e.g. ‘\\\\“. (PR#15621)\nread.table(), readLines() and scan() now warn when an embedded\nnul is found in the input. (Related to PR#15625 which was puzzled by\nthe behaviour in this unsupported case.)\n(Windows only.) file.symlink() works around the undocumented\nrestriction of the Windows system call to backslashes. (Wish of\nPR#15631.)\nKalmanForecast(fast = FALSE) is now the default, and the help\ncontains an example of how fast = TRUE can be used in this\nversion. (The usage will change in 3.1.0.)\nstrptime() now checks the locale only when locale-specific formats\nare used and caches the locale in use: this can halve the time taken\non OSes with slow system functions (e.g. OS X).\nstrptime() and the format() methods for classes \"POSIXct\",\n\"POSIXlt\" and \"Date\" recognize strings with marked encodings:\nthis allows, for example, UTF-8 French month names to be read on\n(French) Windows.\niconv(to = \"utf8\") is now accepted on all platforms (some\nimplementations did already, but GNU libiconv did not: however\nconverted strings were not marked as being in UTF-8). The official\nname, \"UTF-8\" is still preferred.\navailable.packages() is better protected against corrupt metadata\nfiles. (A recurring problem with Debian package shogun-r:\nPR#14713.)\nFinalizers are marked to be run at garbage collection, but run only\nat a somewhat safer later time (when interrupts are checked). This\ncircumvents some problems with finalizers running arbitrary code\nduring garbage collection (the known instances being running\noptions() and (C-level) path.expand() re-entrantly).\n\n\nINSTALLATION and INCLUDED SOFTWARE\nThe included version of PCRE has been updated to 8.34. This fixes\nbugs and makes the behaviour closer to Perl 5.18. In particular, the\nconcept of ‘space’ includes VT and hence agrees with POSIX’s.\n\n\nPACKAGE INSTALLATION\nThe new field SysDataCompression in the DESCRIPTION file allows\nuser control over the compression used for sysdata.rda objects in\nthe lazy-load database.\ninstall.packages(dependencies = value) for value = NA (the\ndefault) or value = TRUE omits packages only in LinkingTo for\nbinary package installs.\n\n\nC-LEVEL FACILITIES\nThe long undocumented remapping of rround() to Rf_fround() in\nheader Rmath.h is now formally deprecated: use fround()\ndirectly.\nRemapping of prec() and trunc() in the Rmath.h header has been\ndisabled in C++ code (it has caused breakage with libc++ headers).\n\n\nBUG FIXES\ngetParseData() truncated the imaginary part of complex number\nconstants. (Reported by Yihui Xie.)\ndbeta(x, a, b) with a or b within a factor of 2 of the largest\nrepresentable number could infinite-loop. (Reported by Ioannis\nKosmidis.)\nprovideDimnames() failed for arrays with a 0 dimension. (PR#15465)\nrbind() and cbind() did not handle list objects correctly.\n(PR#15468)\nreplayPlot() now checks if it is replaying a plot from the same\nsession.\nrasterImage() and grid.raster() now give error on an empty\n(zero-length) raster. (Reported by Ben North.)\nplot.lm() would sometimes scramble the labels in plot type 5.\n(PR#15458 and PR#14837)\nmin() did not handle NA_character_ values properly. (Reported by\nMagnus Thor Torfason.)\n(Windows only.) readRegistry() would duplicate default values for\nkeys. (PR#15455)\nstr(..., strict.width = \"cut\") did not handle it properly when\nmore than one line needed to be cut. (Reported by Gerrit Eichner.)\nRemoving subclass back-references when S4 classes were removed or\ntheir namespace unloaded had several bugs (e.g., PR#15481).\naggregate() could fail when there were too many levels present in\nthe by argument. (PR#15004)\nnamespaceImportFrom() needed to detect primitive functions when\nchecking for duplicated imports (reported by Karl Forner).\ngetGraphicsEvent() did not exit when a user closed the graphics\nwindow. (PR#15208)\nErrors in vignettes were not always captured and displayed properly.\n(PR#15495)\ncontour() could fail when dealing with extremely small z values.\n(PR#15454)\nSeveral functions did not handle zero-length vectors properly,\nincluding browseEnv(), format(), gl(), relist() and\nsummary.data.frame(). (E.g., PR#15499)\nSweave() did not restore the R output to the console if it was\ninterrupted by a user in the middle of evaluating a code chunk.\n(Reported by Michael Sumner.)\nFake installs of packages with vignettes work again.\nIllegal characters in the input caused parse() (and thus\nsource()) to segfault. (PR#15518)\nThe nonsensical use of nmax = 1 in duplicated() or unique() is\nnow silently ignored.\nqcauchy(p, *) is now fully accurate even when p is very close\nto 1. (PR#15521)\nThe validmu() and valideta() functions in the standard glm()\nfamilies now also report non-finite values, rather than failing.\nSaved vignette results (in a .Rout.save file) were not being\ncompared to the new ones during R CMD check.\nDouble-clicking outside of the list box (e.g. on the scrollbar) of a\nTk listbox widget generated by tk_select.list() no longer causes\nthe window to close. (PR#15407)\nImproved handling of edge cases in parallel::splitindices().\n(PR#15552)\nHTML display of results from help.search() and ?? sometimes\ncontained badly constructed links.\nc() and related functions such as unlist() converted raw vectors\nto invalid logical vectors. (PR#15535)\n(Windows only) When a call to system2() specified one of stdin,\nstdout or stderr to be a file, but the command was not found\n(e.g. it contained its arguments, or the program was not on the\nPATH), it left the file open and unusable until R terminated.\n(Reported by Mathew McLean.)\nThe bmp() device was not recording res = NA correctly: it is now\nrecorded as 72 ppi.\nSeveral potential problems with compiler-specific behaviour have\nbeen identified using the ‘Undefined Behaviour Sanitizer’ in\nconjunction with the clang compiler.\nhcl() now honours NA inputs (previously they were mapped to\nblack).\nSome translations in base packages were being looked up in the main\ncatalog rather than that for the package.\nAs a result of the 3.0.2 change about ‘the last second before the\nepoch’, most conversions which should have given NA returned that\ntime. (The platforms affected include Linux and OS X, but not\nWindows nor Solaris.)\nrowsum() has more support for matrices and dataframes with\n\\(2^{31}\\) or more elements. (PR#15587)\npredict(<lm object>, interval = \"confidence\", scale = <something>)\nnow works. (PR#15564)\nThe bug fix in 3.0.2 for PR#15411 was too aggressive, and sometimes\nremoved spaces that should not have been removed. (PR#15583)\nRunning R code in a tcltk callback failed to set the busy flag,\nwhich will be needed to tell OS X not to ‘App Nap’.\nThe code for date-times before 1902 assumed that the offset from GMT\nin 1902 was a whole number of minutes: that was not true of Paris\n(as recorded on some platforms).\nUsing Sys.setlocale to set LC_NUMERIC to \"C\" (to restore the\nsane behavior) no longer gives a warning.\ndeparse() now deparses complex vectors in a way that re-parses to\nthe original values. (PR#15534, patch based on code submitted by\nAlex Bertram.)\nIn some extreme cases (more than \\(10^{15}\\)) integer inputs to\ndpqrxxx() functions might have been rounded up by one (with a\nwarning about being non-integer). (PR#15624)\nPlotting symbol pch = 14 had the triangle upside down on some\ndevices (typically screen devices). The triangle is supposed to be\npoint up. (Reported by Bill Venables.)\ngetSrcref() did not work on method definitions if\nrematchDefinition() had been used.\nKalmanForecast(fast = FALSE) reported a (harmless) stack\nimbalance.\nThe count of observations used by KalmanRun() did not take missing\nvalues into account.\nIn locales where the abbreviated name of one month is a partial\nmatch for the full name of a later one, the %B format in\nstrptime() could fail. An example was French on OS X, where juin\nis abbreviated to jui and partially matches juillet. Similarly\nfor weekday names.\npbeta(x, a, b, log.p = TRUE) sometimes underflowed to zero for\nvery small and very differently sized a, b. (PR#15641)\napprox() and approxfun() now handle infinite values with the\n\"constant\" method. (PR#15655)\nstripchart() again respects reversed limits in xlim and ylim.\n(PR#15664)\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2014-1-r-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2014-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2014-06-01",
    "categories": [],
    "contents": "\n1 Donations and new members\nDonations\nGrupo Usuarios R — Madrid, Spain\nKorean R Users Group, Korea\nQuan Development LLC, USA\nRavinderpal Vaid, USA\nSBW Consulting, USA\nNew benefactors\nHMS Analytical Software, Germany\nNew supporting institutions\nSriSatish Ambati, USA\nSyncfusion Inc, USA\nNew supporting members\nAna Maria Dobre, Romania\nHans-Michael Kaltenbach, Germany\nJoris Muller, France\nJong-Hwa Shin, Korea\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2013-2-bioconductor/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2013-2 issue.",
    "author": [
      {
        "name": "Bioconductor Team",
        "url": {}
      }
    ],
    "date": "2013-12-01",
    "categories": [],
    "contents": "\n\nBioconductor 2.13 was released on 15 October 2013. It is compatible with\nR 3.0.2, and consists of 749 software packages, 179 experiment data\npackages, and more than 690 up-to-date annotation packages. The release\nincludes 84 new software packages, and enhancements to many others.\nDescriptions of new packages and updated NEWS files provided by current\npackage maintainers are at\nhttp://bioconductor.org/news/bioc_2_13_release/.\nStart using Bioconductor and R version 3.0.2 with\n> source(\"http://bioconductor.org/biocLite.R\")\n> biocLite()\nInstall additional packages, e.g.,\nVariantTools,\nwith\n> source(\"http://bioconductor.org/biocLite.R\")\n> biocLite(\"VariantTools\")\nUpgrade installed packages with\n> source(\"http://bioconductor.org/biocLite.R\")\n> biocLite()\nExplore available Bioconductor packages at\nhttp://bioconductor.org/packages/release/. All packages are grouped by\n‘BiocViews’ to identify coherent groups of packages. Each package has an\nhtml page with the descriptions and links to vignettes, reference\nmanuals, and use statistics.\nA Bioconductor Amazon Machine Instance is available and updated; seehttp://bioconductor.org/help/bioconductor-cloud-ami.\n1 Core Bioconductor packages\nGenomicRanges\nand related packages continue to provide an extensive, mature and\nextensible framework for interacting with high throughput sequence data.\nMany contributed packages rely on this infrastructure for interoperable,\nre-usable analysis; (Lawrence 2013) provide an\nintroduction.\nOur large collection of microarray, transcriptome and organism-specific\nannotation packages have also been updated to include current\ninformation. Most of these packages now provide access to the ‘select’\ninterface (keys, columns, keytypes and select) which enable programmatic\naccess to the databases they contain. This uniform interface simplifies\nthe user experience; one illustration of this is in packages such as\nHomo.sapiens, which coordinate access to model organism gene,\ntranscript, and pathway data bases. The\nAnnotationHub,\nnow with more than 10,000 entries, complements our traditional offerings\nwith diverse whole genome annotations from Ensembl, ENCODE, dbSNP, UCSC,\nand elsewhere.\nThis release includes the\nPSICQUIC\npackage, an R interface to a powerful and standardized query language\nfrom the HUPO Proteomics Standard Initiative. More than two dozen\nwell-known interaction databases are include, of which BioGrid, BIND,\nReactome, STRING, IntAct, UniProt, DIP, and ChEMBL may be the best\nknown. The query language uses a controlled vocabulary honed over\nseveral years by an active community, which returns documented and\nannotated interactions. One can now curate a detailed and up-to-date\nnetwork illuminating functional relationships between genes and proteins\nof interest.\n2 Other activities\nIn a change from the routine, our next Annual Meeting is in Boston, 30\nJuly–1 August 2014, making it easier for east coast and European\nattendees. The 2013 Annual Meeting was in Seattle, 17–19 July, with our\nEuropean developer community meeting in Cambridge, UK, 9–10 December.\nOur very active training and community events are advertised at\nhttp://bioconductor.org/help/events/. The Bioconductor mailing lists\n(http://bioconductor.org/help/mailing-list/) connect users with each\nother, to domain experts, and to maintainers eager to ensure that their\npackages satisfy the needs of leading edge approaches. Keep abreast of\npackages added to the ‘devel’ branch and other activities by following\n@Bioconductor on Twitter.\nThe past year marked our first participation in the Google Summer of\nCode project. We had many excellent applicants, and sponsored two\nprojects to completion. GSoC participant Shawn Balcome, under Marc\nCarlson’s mentoring, produced the\ninteractiveDisplay\npackage for Bioconductor /\nshiny integration. Michel\nLang, mentored by Michael Lawrence, added very useful batch job and\nerror recovery functionality to the\nBiocParallel\npackage. This was a very successful experience!\n\n\nCRAN packages used\nshiny\nCRAN Task Views implied by cited packages\nWebTechnologies\nBioconductor packages used\nVariantTools, GenomicRanges, AnnotationHub, PSICQUIC, interactiveDisplay, BiocParallel\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\nM. A. H. Lawrence. Software for computing and annotating genomic ranges. PLoS Computational Biology, 9: e1003118, 2013. DOI 10.1371/journal.pcbi.1003118.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2013-2-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2013-2 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2013-12-01",
    "categories": [],
    "contents": "\n\nNew CRAN task views\nNumericalMathematics\n\nTopic: Numerical Mathematics. Maintainer: Hans W. Borchers.\nPackages: BB, Bessel, MASS, Matrix\\(^*\\), MonoPoly,\nPolynomF, R.matlab, R2Cuba, Rcpp, RcppArmadillo,\nRcppEigen, RcppOctave, Rmpfr, Ryacas, SparseGrid,\nSphericalCubature, akima, appell, combinat, contfrac,\ncubature, eigeninv, elliptic, expm, features, gaussquad,\ngmp, gsl\\(^*\\), hypergeo, irlba, magic, matlab, mpoly,\nmultipol, nleqslv, numDeriv\\(^*\\), numbers, onion,\northopolynom, partitions, pcenum, polyCub, polynom\\(^*\\),\npracma, rPython, rSymPy, signal, ssvd, statmod,\nstinepack, svd.\n\nWebTechnologies\n\nTopic: Web Technologies and Services. Maintainer: Scott Chamberlain,\nKarthik Ram, Christopher Gandrud, Patrick Mair. Packages:\nAWS.tools, CHCN, FAOSTAT, GuardianR, MTurkR, NCBI2R,\nOAIHarvester, Quandl, RCurl\\(^*\\), RJSONIO\\(^*\\), RLastFM,\nRMendeley, RNCBI, RNCEP, ROAuth, RSiteCatalyst,\nRSocrata, RTDAmeritrade, RWeather, Rcolombos, Reol,\nRfacebook, RgoogleMaps, Rook, SynergizeR, TFX, WDI,\nXML\\(^*\\), alm, anametrix, bigml, cgdsr, cimis, crn,\ndatamart, dataone, decctools, dismo, dvn, fImport,\nfactualR, flora, ggmap, gooJSON, googlePublicData,\ngoogleVis, govStatJPN, govdat, httpuv, httr\\(^*\\), imguR,\nngramr, nhlscrapr, opencpu, osmar, pitchRx,\nplotGoogleMaps, plotKML, quantmod, rAltmetric, rPlant,\nrdatamarket, rebird, rentrez, repmis, rfigshare,\nrfishbase, rfisheries, rgauges, rgbif, rjson\\(^*\\), rplos,\nrpubchem, rsnps, rvertnet, scholar, scrapeR, selectr,\nseq2R, seqinr, servr, shiny\\(^*\\), sos4R, streamR,\ntaxize, translate, treebase, twitteR, waterData,\nwethepeople, yhatr, zendeskR.\n\n(* = core package)\nNew packages in CRAN task views\nBayesian\n\nBSquare, FME, prevalence.\n\nChemPhys\n\nBioMark, SCEPtER, SCEPtERextras, celestial, prospectr.\n\nCluster\n\nFunclustering, bayesMCClust, mixture.\n\nDifferentialEquations\n\nadaptivetau.\n\nDistributions\n\nCompLognormal, HistogramTools, NormalGamma, flexsurv,\nmbbefd, msm, sparseMVN.\n\nEconometrics\n\ncrch, midasr, pwt8.\n\nEnvironmetrics\n\nquantregGrowth, rtop.\n\nFinance\n\nBenfordTests, LSMonteCarlo, OptHedging, RND,\nSmithWilsonYieldCurve, markovchain.\n\nHighPerformanceComputing\n\nHistogramTools, MonetDB.R, RProtoBuf, RhpcBLASctl,\npbdPROF, pls.\n\nMachineLearning\n\nRXshrink, bigRR, bmrm.\n\nMedicalImaging\n\ngdimap\\(^*\\).\n\nMetaAnalysis\n\nCAMAN, MetaSKAT, PubBias, dosresmeta, exactmeta,\nnetmeta, seqMeta.\n\nNaturalLanguageProcessing\n\nlda, movMF, skmeans.\n\nOfficialStatistics\n\nSAScii.\n\nPhylogenetics\n\nDDD, convevol, corHMM, evobiR, metafor, phylolm.\n\nPsychometrics\n\nExPosition, ICC, MCMCglmm, TAM\\(^*\\), cocor, cocron,\nequateIRT, irtProb, mediation, multiplex, nlme, ordinal,\nsemPlot, sirt.\n\nReproducibleResearch\n\ninstallr.\n\nRobust\n\nRSKC.\n\nSpatial\n\nCARBayes, GWmodel, Grid2Polygons, McSpatial, SSN,\nSpatialEpi, SpatialTools, dbmss, georob, gstudio, gwrr,\nngspatial, plotGoogleMaps, rlandscape, rtop, rworldxtra,\nspTimer, spatial.tools, splm, taRifx.\n\nSpatioTemporal\n\nBBMM, animalTrack, bcpa, crawl, move, smam.\n\nTimeSeries\n\nArDec, FeedbackTS, SDD, SparseTSCGM, StVAR, TSclust,\nTides, midasr, nlts, nonlinearTseries, portes, psd,\nrmgarch, rugarch, sltl, spTimer, sspir, timesboot,\ntsModel.\n\n(* = core package)\n1 New contributed packages\nABCoptim\n\nImplementation of Artificial Bee Colony (ABC) Optimization. Authors:\nGeorge Vega Yon [aut], Enyelbert Muñoz [ctb].\n\nACTCD\n\nAsymptotic Classification Theory for Cognitive Diagnosis. Authors:\nChia-Yi Chiu and Wenchao Ma.\n\nAFLPsim\n\nHybrid simulation and genome scan for dominant markers. Authors:\nFrancisco Balao [aut, cre], Juan Luis García-Castaño [aut].\n\nALSCPC\n\nAccelerated line search algorithm for simultaneous orthogonal\ntransformation of several positive definite symmetric matrices to\nnearly diagonal form. Author: Dariush Najarzadeh.\n\nAMGET\n\nPost-processing tool for ADAPT 5. Author: Benjamin Guiastrennec.\n\nARTP\n\nGene and Pathway p-values computed using the Adaptive Rank Truncated\nProduct. Authors: Kai Yu, Qizhai Li and William Wheeler.\n\nAUC\n\nThreshold independent performance measures for probabilistic\nclassifiers. Authors: Michel Ballings and Dirk Van den Poel.\n\nAdapEnetClass\n\nA class of adaptive elastic net methods for censored data. Authors:\nHasinur Rahaman Khan and Ewart Shaw.\n\nAdaptiveSparsity\n\nAdaptive Sparsity Models. Authors: Kristen Zygmunt, Eleanor Wong,\nTom Fletcher.\n\nAnDE\n\nAn extended Bayesian Learning Technique developed by Dr. Geoff Webb.\nAuthor: Sai Teja Ranuva and Nayyar Zaidi.\n\nAppliedPredictiveModeling\n\nFunctions and Data Sets for “Applied Predictive Modeling”. Authors:\nMax Kuhn, Kjell Johnson.\n\nBASIX\n\nAn efficient C/C++ toolset for R. Author: Bastian Pfeifer.\n\nBCDating\n\nBusiness Cycle Dating and Plotting Tools. Author: Majid Einian.\n\nBCEs0\n\nBayesian models for cost-effectiveness analysis in the presence of\nstructural zero costs. Author: Gianluca Baio.\n\nBEDASSLE\n\nDisentangles the effects of geographic and ecological isolation on\ngenetic differentiation. Author: Gideon Bradburd.\n\nBEST\n\nBayesian Estimation Supersedes the t-Test. Authors: John K. Kruschke\nand Mike Meredith.\n\nBGLR\n\nBayesian Generalized Linear Regression. Authors: Gustavo de los\nCampos, Paulino Perez Rodriguez.\n\nBGPhazard\n\nMarkov beta and gamma processes for modeling hazard rates.\nAuthors: J. A. Garcia-Bueno and L. E. Nieto-Barajas.\n\nBMAmevt\n\nMultivariate Extremes: Bayesian estimation of the spectral measure.\nAuthor: Anne Sabourin.\n\nBSSasymp\n\nAsymptotic covariance matrices of some BSS mixing and unmixing\nmatrix estimates. Authors: Jari Miettinen, Klaus Nordhausen, Hannu\nOja, Sara Taskinen.\n\nBayesCR\n\nBayesian analysis of censored linear regression models with scale\nmixtures of normal (SMN) distributions. Authors: Aldo M. Garay,\nVictor H. Lachos.\n\nBayesSAE\n\nBayesian Analysis of Small Area Estimation. Authors: Chengchun Shi,\nwith contributions from Peng Zhang.\n\nBayesianbetareg\n\nBayesian Beta regression: joint mean and precision modeling.\nAuthors: Margarita Marin and Javier Rojas and Daniel Jaimes, under\nthe direction of Edilberto Cepeda-Cuervo and with collaboration of\nMartha Corrales, Maria Fernanda Zarate, Ricardo Duplat and Luis F\nVillarraga.\n\nBioGeoBEARS\n\nBioGeography with Bayesian (and Likelihood) Evolutionary Analysis in\nR Scripts. Author: Nicholas J. Matzke [aut, cre, cph].\n\nCALIBERrfimpute\n\nMultiple imputation using MICE and Random Forest. Author: Anoop\nShah.\n\nCARrampsOcl\n\nReparameterized and marginalized posterior sampling for conditional\nautoregressive models, OpenCL implementation. Authors: Kate Cowles\nand Michael Seedorff and Alex Sawyer.\n\nCCTpack\n\nCultural Consensus Theory applications to data. Author: Royce\nAnders.\n\nCIFsmry\n\nWeighted summary of cumulative incidence functions. Author: Jianing\nLi.\n\nCINID\n\nCurculionidae INstar IDentification. Authors: Aurelie Siberchicot,\nAdrien Merville, Marie-Claude Bel-Venner and Samuel Venner.\n\nCNVassocData\n\nExample data sets for association analysis of CNV data. Authors:\nJuan R González, Isaac Subirana.\n\nCNprep\n\nPre-process DNA copy number (CN) data for detection of CN events.\nAuthors: Alex Krasnitz, Guoli Sun.\n\nCORE\n\nCores of Recurrent Events. Authors: Alex Krasnitz, Guoli Sun.\n\nCSS\n\nExtract information from an HTML document with CSS selectors.\nAuthor: Francois Guillem.\n\nCausata\n\nAnalysis utilities for binary classification and Causata users.\nAuthors: Justin Hemann, David Barker, Suzanne Weller, Jason McFall.\n\nClustVarLV\n\nClustering of variables around Latent Variables. Authors: Evelyne\nVigneau, Mingkun Chen.\n\nCorrelplot\n\nA collection of functions for graphing correlation matrices. Author:\nJan Graffelman.\n\nCovSel\n\nModel-Free Covariate Selection. Authors: Jenny Emma Persson.\n\nCoxRidge\n\nCox models with dynamic ridge penalties. Author: Aris Perperoglou.\n\nDCL\n\nClaims Reserving under the Double Chain Ladder Model. Authors: Maria\nDolores Martinez-Miranda, Jens Perch Nielsen and Richard Verrall.\n\nDIFlasso\n\nA penalty approach to Differential Item Functioning in Rasch Models.\nAuthor: Gunther Schauberger.\n\nDSBayes\n\nBayesian subgroup analysis in clinical trials. Authors: Ravi\nVaradhan and Wenliang Yao.\n\nDTMCPack\n\nSuite of functions related to discrete-time discrete-state Markov\nChains. Author: William Nicholson.\n\nDTR\n\nEstimation and comparison of dynamic treatment regimes. Authors:\nXinyu Tang and Maria Melguizo.\n\nDiscreteWeibull\n\nDiscrete Weibull distribution. Author: Alessandro Barbiero.\n\nDistatisR\n\nDiSTATIS Three Way Metric Multidimensional Scaling. Authors: Derek\nBeaton [aut, com, ctb], Cherise Chin Fatt [ctb], Herve Abdi\n[aut, cre].\n\nDoubleCone\n\nTest against parametric regression function. Authors: Mary C Meyer,\nBodhisattva Sen.\n\nDunnettTests\n\nSoftware implementation of step-down and step-up Dunnett test\nprocedures. Author: Fan Xia.\n\nDynamicDistribution\n\nDynamically visualized probability distributions and their moments.\nAuthors: Lei Zhang, Hao Jiang and Chen Xue.\n\nEILA\n\nEfficient Inference of Local Ancestry. Authors: James J. Yang, Jia\nLi, Anne Buu, and L. Keoki Williams.\n\nEMMAgeo\n\nEnd-member modelling algorithm and supporting functions for\ngrain-size analysis. Authors: Michael Dietze, Elisabeth Dietze.\n\nEMMIXskew\n\nThe EM Algorithm and Skew Mixture Distribution. Authors: Kui Wang,\nAngus Ng and Geoff McLachlan.\n\nEMMIXuskew\n\nFitting Unrestricted Multivariate Skew \\(t\\) Mixture Models.\nAuthors: S. X. Lee and G. J. McLachlan.\n\nEMVC\n\nEntropy Minimization over Variable Clusters. Authors: H. Robert\nFrost and Jason H. Moore.\n\nES\n\nEdge Selection. Authors: Meng Hwee Victor Ong, Sanjay Chaudhuri.\n\nEffectsRelBaseline\n\nTest changes of a grouped response relative to baseline. Author:\nPeter N. Steinmetz.\n\nEnvNicheR\n\nEnvironmental niche. Author: Cástor Guisande González.\n\nEnvStats\n\nPackage for Environmental Statistics, including US EPA Guidance.\nAuthor: Steven P. Millard.\n\nEvCombR\n\nEvidence Combination in R. Author: Alexander Karlsson.\n\nFField\n\nForce field simulation for a set of points. Author: Grigori\nKapoustin.\n\nFGalgorithm\n\nFlury and Gautschi algorithms. Author: Dariush Najarzadeh.\n\nFREQ\n\nEstimate population size from capture frequencies. Authors: Annegret\nGrimm and Klaus Henle.\n\nFastRCS\n\nCompute the FastRCS Algorithm. Authors: Kaveh Vakili [aut, cre].\n\nFeedbackTS\n\nAnalysis of Feedback in Time Series. Authors: Samuel Soubeyrand,\nCindy E. Morris, E. Keith Bigg. In view:\nTimeSeries.\n\nFinCal\n\nTime Value of Money, time series analysis and Computational Finance.\nAuthor: Felix Yanhui Fan.\n\nFindMinIC\n\nFind Models with Minimum IC. Authors: Nicholas Lange, Tom Fletcher,\nKristen Zygmunt.\n\nFusedPCA\n\nCommunity Detection via Fused Principal Component Analysis. Authors:\nYang Feng, Richard J. Samworth and Yi Yu.\n\nGABi\n\nFramework for Generalized Subspace Pattern Mining. Author: Ed Curry.\n\nGCD\n\nGlobal Charcoal Database. Author: Global Paleofire Working Group.\n\nGDELTtools\n\nDownload, slice, and normalize GDELT data. Authors: Stephen R.\nHaptonstahl, Thomas Scherer, Timo Thoms, and John Beieler.\n\nGGIR\n\nAuthor: Vincent T van Hees.\n\nGIGrvg\n\nRandom variate generator for the GIG distribution. Authors: Josef\nLeydold and Wolfgang Hormann.\n\nGPCSIV\n\nGeneralized Principal Component of Symbolic Interval variables.\nAuthors: Brahim Brahim and Sun Makosso-Kallyth.\n\nGRTo\n\nTools for the analysis of Gutenberg-Richter distributions of\nearthquake magnitudes. Authors: Daniel Amorese, Paul A. Rydelek and\nJean-Robert Grasso.\n\nGSE\n\nRobust Estimation of Multivariate Location and Scatter in the\nPresence of Missing Data. Authors: Mike Danilov, Andy Leung, Victor\nYohai, Ruben Zamar.\n\nGWmodel\n\nGeographically weighted models. Authors: Binbin Lu, Paul Harris,\nIsabella Gollini, Martin Charlton, Chris Brunsdon. In view:\nSpatial.\n\nGetNenshuJP\n\nGet data about Japanese company. Author: Hayakawa Atsushi.\n\nGetoptLong\n\nParse command-line arguments. Author: Zuguang Gu.\n\nGlobalDeviance\n\nGlobal Deviance Permutation Tests. Author: Frederike Fuhlbrueck.\n\nGxM\n\nMaximum Likelihood Estimation for Gene-by-Measured Environment\nInteraction Models. Authors: Hao Zheng and Paul Rathouz.\n\nHDtweedie\n\nThe Lasso for the Tweedie’s Compound Poisson Model Using an IRLS-BMD\nAlgorithm. Authors: Wei Qian, Yi Yang, Hui Zou.\n\nHEAT\n\nHealth Effects of Air Pollution and Temperature. Authors: Youn-Hee\nLim, Il-Sang Ohn, and Ho Kim.\n\nHHG\n\nHeller-Heller-Gorfine Tests of Independence. Authors: Shachar\nKaufman, based in part on an earlier implementation by Ruth Heller\nand Yair Heller.\n\nHTSDiff\n\nDifferential analysis of RNA-seq data with Poisson mixture models.\nAuthors: Andrea Rau, Marie-Laure Martin-Magniette, Cathy\nMaugis-Rabusseau.\n\nHistogramTools\n\nUtility Functions for R Histograms. Author: Murray Stokely. In\nviews:\nDistributions,\nHighPerformanceComputing.\n\nHotDeckImputation\n\nHot Deck Imputation Methods for Missing Data. Author: Dieter William\nJoenssen.\n\nIASD\n\nModel selection for index of asymmetry distribution. Author: Satoshi\nTakahashi.\n\nIAT\n\nFunctions to use with data from the Implicit Association Test.\nAuthor: Dan Martin.\n\nICEbox\n\nIndividual Conditional Expectation Plot Toolbox. Authors: Alex\nGoldstein, Adam Kapelner, Justin Bleich.\n\nINLABMA\n\nBayesian Model Averaging with INLA. Authors: Virgilio Gomez Rubio,\nRoger Bivand.\n\nISLR\n\nData for “An Introduction to Statistical Learning with Applications\nin R”. Authors: Gareth James, Daniela Witten, Trevor Hastie and Rob\nTibshirani.\n\nIUPS\n\nIncorporating Uncertainties in Propensity Scores. Authors: Weihua\nAn, Huizi Xu, and Zhida Zheng.\n\nInPosition\n\nInference Tests for ExPosition. Authors: Derek Beaton, Joseph\nDunlop, Herve Abdi.\n\nIntLik\n\nNumerical Integration for Integrated Likelihood. Author: Zhenyu\nZhao.\n\nInterVA4\n\nReplicate and analyse InterVA4. Authors: Zehang LI, Tyler McCormick,\nSam Clark.\n\nJointRegBC\n\nJoint Modelling of Mixed Correlated Binary and Continuous Responses:\nA Latent Variable Approach. Authors: Ehsan Bahrami Samani and Zhale\nTahmasebinejad.\n\nLCA\n\nLocalised Co-Dependency Analysis. Author: Ed Curry.\n\nLICurvature\n\nSensitivity Analysis for Case Weight in Normal Linear Regression.\nAuthors: Ehsan Bahrami Samani and Parisa ParsaMaram.\n\nLPmerge\n\nMerging linkage maps by linear programming. Author: Jeffrey\nEndelman.\n\nLSMonteCarlo\n\nAmerican options pricing with Least Squares Monte Carlo method.\nAuthor: Mikhail A. Beketov. In view:\nFinance.\n\nLVMMCOR\n\nA Latent Variable Model for Mixed Continuous and Ordinal Responses.\nAuthors: Ehsan Bahrami Samani and Nourallah Tazikeh Miyandarreh.\n\nLogrankA\n\nLogrank Test for Aggregated Survival Data. Authors: Jonas\nRichter-Dumke and Roland Rau.\n\nMASSI\n\nMicroArray Sample Sex Identifier. Author: Sam Buckberry.\n\nMCDA\n\nAuthors: Patrick Meyer, Sébastien Bigaret.\n\nMCMC.qpcr\n\nBayesian analysis of qRT-PCR data. Author: Mikhail V. Matz.\n\nMConjoint\n\nConjoint Analysis through Averaging of Multiple Analyses. Author:\nWilliam Hughes.\n\nMF\n\nMitigated Fraction. Author: David Siev.\n\nMFHD\n\nMultivariate Functional Halfspace Depth. Authors: M. Hubert, K.\nVakili.\n\nMGLM\n\nMultivariate Response Generalized Linear Models. Authors: Yiwen\nZhang and Hua Zhou.\n\nMLRMPA\n\nMultilinear Regression Model Population Analysis. Authors: Meihong\nXie and Xiaoyun Zhang.\n\nMODISTools\n\nMODIS Subsetting Tools. Authors: Sean Tuck, Helen Phillips.\n\nMPINet\n\nImplements the network-based metabolite pathway identification of\npathways. Authors: Yanjun Xu, Chunquan Li and Xia Li.\n\nMPSEM\n\nModeling Phylogenetic Signals using Eigenvector Maps. Authors:\nGuillaume Guenard, with contribution from Pierre Legendre.\n\nMRCV\n\nMethods for Analyzing Multiple Response Categorical Variables.\nAuthors: Natalie Koziol and Chris Bilder.\n\nMRMR\n\nMultivariate Regression Models for Reserving. Author: Brian A.\nFannin.\n\nMRsurv\n\nA multiplicative-regression model for relative survival. Authors: Y.\nFoucher, K. Trebern-Launay.\n\nMRwarping\n\nMultiresolution time warping for functional data. Authors: L.\nSlaets, G. Claeskens, B. W. Silverman.\n\nMap2NCBI\n\nMapping Markers to the Nearest Genomic Feature. Authors: Lauren L.\nHulsman Hanna and David G. Riley.\n\nMetSizeR\n\nGUI tool for estimating sample sizes for metabolomic experiments.\nAuthors: Gift Nyamundanda, Isobel Claire Gormley, Yue Fan, William M\nGallagher, Lorraine Brennan.\n\nMetStaT\n\nStatistical metabolomics tools. Author: Tim Dorscheidt.\n\nMicroDatosEs\n\nUtilities for Official Spanish Microdata. Authors: Carlos J. Gil\nBellosta [aut, cre], José Luis Cañadas Reche [ctb].\n\nMissMech\n\nTesting Homoscedasticity, Multivariate Normality, and Missing\nCompletely at Random. Authors: Mortaza Jamshidian, Siavash Jalal,\nand Camden Jansen.\n\nMyrrix\n\nInterface to Myrrix, a complete, real-time, scalable clustering and\nrecommender system, evolved from Apache Mahout. Authors: Jan\nWijffels [aut, cre].\n\nMyrrixjars\n\nExternal jars required for package Myrrix. Authors: Jan Wijffels\n[aut, cre].\n\nNAPPA\n\nPerforms the processing and normalisation of Nanostring miRNA and\nmRNA data. Author: Mark Wappett.\n\nNCmisc\n\nMiscellaneous general purpose functions. Author: Nicholas Cooper.\n\nNEff\n\nCalculating effective sizes based on known demographic parameters of\na population. Authors: Annegret Grimm, Bernd Gruber and Klaus Henle.\n\nNLP\n\nNatural Language Processing Infrastructure. Author: Kurt Hornik\n[aut, cre].\n\nNPMLEcmprsk\n\nNon-parametric Maximum-Likelihood Estimation for Competing-Risks\nData. Authors: Chung-Hsing Chen, I-Shou Chang and Chao A. Hsiung.\n\nNPMVCP\n\nNonparametric Multivariate Change Point Model. Author: Mark D.\nHolland.\n\nNSM3\n\nAccompanies Hollander, Wolfe, and Chicken “Nonparametric Statistical\nMethods, Third Edition”. Authors: Grant Schneider, Eric Chicken,\nRachel Becvarik.\n\nNetSim\n\nA Social Networks Simulation Tool in R. Author: Christoph Stadtfeld.\n\nNewdistns\n\nComputes pdf, cdf, quantile and random numbers for 19 general\nfamilies of distributions. Author: Saralees Nadarajah.\n\nNominalLogisticBiplot\n\nBiplot representations of categorical data. Authors: Julio Cesar\nHernandez Sanchez, Jose Luis Vicente-Villardon.\n\nODMconverter\n\ntools to convert ODM files. Author: Martin Dugas.\n\nOpasnetUtils\n\nUtility functions for dealing with data in Opasnet\n(www.opasnet.org) environment.\nAuthors: Teemu Rintala, Einari Happonen, Jouni Tuomisto.\n\nOptHedging\n\nEstimation of value and hedging strategy of call and put options.\nAuthor: Bruno Remillard. In view:\nFinance.\n\nOrdinalLogisticBiplot\n\nBiplot representations of ordinal variables. Authors: Julio Cesar\nHernandez Sanchez, Jose Luis Vicente-Villardon.\n\nPAGI\n\nIdentify the dysregulated KEGG pathways based on global influence\nfrom the internal effect of pathways and crosstalk between pathways.\nAuthors: Junwei Han, Yanjun Xu, Haixiu Yang, Chunquan Li and Xia Li.\n\nPAGWAS\n\nPathway analysis methods for genomewide association data. Author:\nMarina Evangelou.\n\nPLRModels\n\nStatistical inference in partial linear regression models. Authors:\nGerman Aneiros Perez and Ana Lopez Cheda.\n\nPROFANCY\n\nPrioritize candidate disease metabolites based on global functional\nrelationships between metabolites in the context of metabolic\npathways. Authors: Qianlan Yao, Desi Shang, Chunquan Li.\n\nPSAboot\n\nBootstrapping for Propensity Score Analysis. Author: Jason Bryer.\n\nParDNAcopy\n\nParallel implementation of the segment function of package\nDNAcopy. Authors: Alex Krasnitz, Guoli Sun.\n\nParentOffspring\n\nConduct the Parent-Offspring Test Using Monomorphic SNP Markers.\nAuthors: Pengsheng Ji, Hussein Abdel-Haleem, H. Roger Boerma and\nZenglu Li.\n\nPatternClass\n\nClass-focused pattern metric comparisons using simulation. Authors:\nTarmo K. Remmel, (Marie-Josee Fortin, Ferenc Csillag, Sandor Kabos).\n\nPedCNV\n\nAn implementation for association analysis with CNV data. Authors:\nMeiling Liu, Sungho Won and Weicheng Zhu.\n\nPivotalR\n\nR front-end to PostgreSQL and Pivotal (Greenplum) database, wrapper\nfor MADlib. Authors: Predictive Analytics Team at Pivotal Inc., with\ncontributions from Data Scientist Team at Pivotal Inc.\n\nPoweR\n\nComputation of power and level tables for hypothesis tests. Authors:\nPierre Lafaye de Micheaux, Viet Anh Tran.\n\nPsumtSim\n\nSimulations of grouped responses relative to baseline. Author:\nPeter N. Steinmetz.\n\nPubBias\n\nPerforms simulation study to look for publication bias, using a\ntechnique described by Ioannidis and Trikalinos; Clin Trials,\n2007;4(3):245–53. Author: Simon Thornley. In view:\nMetaAnalysis.\n\nPubMedWordcloud\n\nPubMed Word Clouds. Author: Felix Yanhui Fan.\n\nQCGWAS\n\nQuality Control of Genome Wide Association Study results. Authors:\nPeter J. van der Most and Ilja M. Nolte.\n\nQZ\n\nGeneralized Eigenvalues and QZ Decomposition. Authors: Wei-Chen\nChen, partly adapted and using routines from LAPACK.\n\nRANN\n\nFast Nearest Neighbour Search (wraps Arya and Mount’s ANN library).\nAuthors: Sunil Arya and David Mount (for ANN), Samuel E. Kemp,\nGregory Jefferis.\n\nRCEIM\n\nR Cross Entropy Inspired Method for Optimization. Author: Alberto\nKrone-Martins.\n\nRCPmod\n\nRegions of common profiles modelling with mixtures-of-experts.\nAuthor: Scott D. Foster.\n\nRECSO\n\nRobust and Efficient Analysis using Control function approach, of a\nSecondary Outcome. Author: Tamar Sofer.\n\nRGenetics\n\nGenetics research. Author: Felix Yanhui Fan.\n\nRIGHT\n\nR Interactive Graphics via HTml. Authors: ChungHa Sung, TaeJoon\nSong, Jae W. Lee, and Junghoon Lee.\n\nRImpala\n\nAuthors: Austin Chungath Vincent, Sachin Sudarshana, Vikas\nRaguttahalli.\n\nRInSp\n\nR Individual Specialization. Authors: Nicola Zaccarelli, Giorgio\nMancinelli, and Dan Bolnick.\n\nRND\n\nRisk Neutral Density. Author: Kam Hamidieh. In view:\nFinance.\n\nRObsDat\n\nStore your observations: R-Interface to the Observations Data Model\nfrom QUASHI. Author: Dominik Reusser.\n\nRSADBE\n\nData related to the book “R Statistical Application Development by\nExample”. Author: Prabhanjan Tattar.\n\nRSDA\n\nR to Symbolic Data Analysis. Author: Oldemar Rodriguez R., with\ncontributions from Johnny Villalobos M.\n\nRSocrata\n\nDownload Socrata datasets as R data frames. Author: Hugh J. Devlin.\nIn view:\nWebTechnologies.\n\nRStorm\n\nSimulate and Develop Streaming Processing in [R]. Author: Maurits\nKaptein.\n\nRTConnect\n\nTools for analyzing sales report files of iTunes Connect. Author:\nYusuke Miyazaki.\n\nRVsharing\n\nAuthors: Alexandre Bureau, Ingo Ruczinski, Samuel G. Younkin.\n\nRWiener\n\nWiener process distribution functions. Author: Dominik Wabersich.\n\nRadOnc\n\nAnalytical Tools for Radiation Oncology. Author: Reid F. Thompson.\n\nRambo\n\nThe Random Subgraph Model. Authors: Charles Bouveyron, Yacine\nJernite, Pierre Latouche, Laetitia Nouedoui.\n\nRankcluster\n\nModel-based clustering for multivariate partial ranking data.\nAuthor: Quentin Grimonprez.\n\nRbitcoin\n\nRbitcoin integration. Author: Jan Gorecki.\n\nRcmdrPlugin.sampling\n\nTools for sampling in Official Statistical Surveys. Authors: Susie\nJentoft and Johan Heldal.\n\nRcolombos\n\nInterface to Colombos Compendia using the exposed REST API. Author:\nPaolo Sonego. In view:\nWebTechnologies.\n\nRcppZiggurat\n\nRcpp integration of different Ziggurat Normal RNG implementations.\nAuthor: Dirk Eddelbuettel.\n\nRfacebook\n\nAccess to Facebook API via R. Author: Pablo Barbera. In view:\nWebTechnologies.\n\nRhpcBLASctl\n\nControl the number of threads on BLAS for R. Authors: Junji Nakano\nand Ei-ji Nakama. In view:\nHighPerformanceComputing.\n\nRidgeFusion\n\nRidge Fusion in Statistical Learning. Author: Bradley S. Price.\n\nRjpstatdb\n\nR interface of the Gateway to Advanced and User-friendly Statistics\nService. Author: Kiwamu Ishikura.\n\nRobPer\n\nPeriodogram methods for irregularly sampled time series (especially\nlight curves occurring in astroparticle physics) and periodicity\ndetection methods. Authors: Anita M. Thieler, Jonathan Rathjens and\nRoland Fried, with contributions from Brenton R. Clarke, Uwe Ligges,\nMatias Salibian-Barrera, Gert Willems and Victor Yohai.\n\nRockFab\n\nRock fabric and strain analysis tools. Author: Jeffrey R. Webber.\n\nRpoppler\n\nPDF tools based on Poppler. Author: Kurt Hornik.\n\nRuchardet\n\nAuthor: Heewon Jeon.\n\nSCEPtER\n\nStellar CharactEristics Pisa Estimation gRid. Authors: Matteo\nDell’Omodarme [aut, cre], Giada Valle [aut]. In view:\nChemPhys.\n\nSCEPtERextras\n\nAdditional grids for SCEPtER. Authors: Matteo Dell’Omodarme [aut,\ncre], Giada Valle [aut]. In view:\nChemPhys.\n\nSCGLR\n\nSupervised Component Generalized Linear Regression. Authors: Mortier\nF., Trottier C., Cornu G., Bry X.\n\nSEchart\n\nAuthors: Rutger M. van den Bor and Willem M. van der Wal.\n\nSIMMS\n\nSubnetwork Integration for Multi-Modal Signatures. Authors: Syed\nHaider, Michal Grzadkowski, Paul C. Boutros.\n\nSINGLE\n\nEstimate sparse dynamic graphs using the Smooth Incremental\nGraphical Lasso Estimation (SINGLE) algorithm. Authors: Ricardo Pio\nMonti, Christoforos Anagnostopoulos and Giovanni Montana.\n\nSML\n\nStatistical Machine Learning. Author: Tuo Zhao.\n\nSOLOMON\n\nParentage analysis. Author: Mark Christie.\n\nSPMS\n\nSub-Pathway Mining Software. Author: Xiaomeng Ni.\n\nSPODT\n\nSpatial Oblique Decision Tree. Authors: Jean Gaudart, Nathalie\nGraffeo, Guillaume Barbet, Bernard Fichet, Roch Giorgi.\n\nSPmlficmcm\n\nSemiparametric Maximum likelihood Method for interactions\ngene-environment in case-mother control-mother designs. Authors:\nMoliere Nguile Makao and Alexandre Bureau.\n\nSRRS\n\nThe Stepwise Response Refinement Screener (SRRS). Authors: Frederick\nKin Hing Phoa and Shu-Ching Lin.\n\nSciencesPo\n\nTools for analyzing political behaviour data. Author: Daniel\nMarcelino.\n\nScrabbleScore\n\nCalculates Scrabble score for strings. Author: Will Kurt.\n\nSesIndexCreatoR\n\nComputation and visualization of socioeconomic indices and\ncategories distributions. Author: Benoit Lalloue.\n\nSigTree\n\nFunctions to determine significantly responsive branches of\nphylogenetic trees and produce colored plots both in FigTree (via\nexported file) and R. Authors: John R. Stevens and Todd R. Jones.\n\nSimuChemPC\n\nSimulation process of 4 selection methods in predicting chemical\npotent compounds. Author: Mohsen Ahmadi.\n\nSmithWilsonYieldCurve\n\nSmith-Wilson Yield Curve Construction. Author: Phil Joubert. In\nview: Finance.\n\nStAMPP\n\nStatistical Analysis of Mixed Ploidy Populations. Author: L. W.\nPembleton.\n\nStatRank\n\nStatistical Rank Aggregation: Inference, Evaluation, and\nVisualization. Authors: Hossein Azari Soufiani, William Chen.\n\nStrainRanking\n\nRanking of pathogen strains. Authors: S. Soubeyrand, C.\nTollenaere, E. Haon-Lasportes and A.-L. Laine.\n\nStratSel\n\nStrategic Selection Estimator. Author: Lucas Leemann.\n\nSubCultCon\n\nMaximum-Likelihood Cultural Consensus Analysis with Sub-Cultures.\nAuthors: Mary C Meyer, Jeffrey G Snodgrass, Michael Lacy.\n\nSynchWave\n\nSynchrosqueezed Wavelet Transform. Authors: Matlab original by\nEugene Brevdo; R port by Dongik Jang, Hee-Seok Oh and Donghoh Kim.\n\nTAM\n\nTest Analysis Modules. Authors: Thomas Kiefer [aut], Alexander\nRobitzsch [aut, cre], Margaret Wu [aut]. In view:\nPsychometrics.\n\nTBEST\n\nTree Branches Evaluated Statistically for Tightness. Authors: Guoli\nSun, Alex Krasnitz.\n\nTH.data\n\nTH’s Data Archive. Author: Torsten Hothorn [aut, cre].\n\nTInPosition\n\nInference tests for TExPosition. Authors: Derek Beaton, Jenny Rieck,\nHerve Abdi.\n\nTSclust\n\nTime series clustering utilities. Authors: Pablo Montero Manso, José\nAntonio Vilar. In view:\nTimeSeries.\n\nTSjson\n\nTSdbi extension for importing time series from web sources via\nJSON. Author: Paul Gilbert.\n\nTSsql\n\nGeneric SQL helper functions for TSdbi SQL plugins. Author: Paul\nGilbert.\n\nTableToLongForm\n\nAuthor: Jimmy Oh [aut, cre].\n\nTapeR\n\nFlexible tree taper curves based on Semiparametric Mixed Models.\nAuthor: Edgar Kublin.\n\nThinknum\n\nThinknum Data Connection. Author: Gregory Ugwi.\n\nTiddlyWikiR\n\nCreate dynamic reports using a TiddlyWiki template. Author: David\nMontaner.\n\nTides\n\nAuthor: Tom Cox. In view:\nTimeSeries.\n\nToxLim\n\nIncorporating Ecological Data and Associated Uncertainty in\nBioaccumulation Modeling. Authors: Frederik De Laender and Karline\nSoetaert.\n\nTriMatch\n\nPropensity Score Matching of Non-Binary Treatments. Author: Jason\nBryer.\n\nUScancer\n\nCreate US cancer datasets from SEER, IARC, and US Census data.\nAuthor: Jonathan Lee.\n\nVIMGUI\n\nVisualization and Imputation of Missing Values. Authors: Daniel\nSchopfhauser, Matthias Templ, Andreas Alfons, Alexander Kowarik,\nBernd Prantner.\n\nVLF\n\nFrequency Matrix Approach for Assessing Very Low Frequency Variants\nin Sequence Records. Authors: Taryn B. T. Athey and Paul D.\nMcNicholas.\n\nVSURF\n\nVariable Selection Using Random Forests. Authors: Robin Genuer,\nJean-Michel Poggi and Christine Tuleau-Malot.\n\nVaRES\n\nComputes value at risk and expected shortfall for over 100\nparametric distributions. Authors: Saralees Nadarajah, Stephen Chan\nand Emmanuel Afuecheta.\n\nVizOR\n\nGraphical visualization tools for complex observational data with\nfocus on health sciences. Authors: Drew Griffin Levy [aut],\nDavid C. Norris [aut, cre].\n\nWhopGenome\n\nHigh-speed processing of whole-genome VCF-format variation data,\nFASTA-format sequence data and several alignments formats. Author:\nUlrich Wittelsbuerger.\n\nXML2R\n\nEasieR XML data collection. Author: Carson Sievert.\n\nYPmodel\n\nThe Short-term and Long-term Hazard Ratio Model for Survival Data.\nAuthors: Junlong Sun and Song Yang.\n\nZIM\n\nStatistical Models for Count Time Series with Excess Zeros. Authors:\nMing Yang, Gideon K. D. Zamba, and Joseph E. Cavanaugh.\n\naLFQ\n\nEstimation of absolute protein quantities from label-free LC-MS/MS\nproteomics data. Authors: George Rosenberger, Hannes Roest,\nChristina Ludwig, Barry Grant.\n\nabf2\n\nLoad Axon ABF2 files (currently only in gap-free recording mode).\nAuthor: Matthew Caldwell.\n\nabundant\n\nAbundant regression and high-dimensional principal fitted\ncomponents. Author: Adam J. Rothman.\n\naccelerometry\n\nFunctions for processing uniaxial minute-to-minute accelerometer\ndata. Author: Dane R. Van Domelen.\n\naccrued\n\nVisualization tools for partially accruing data. Authors: Julie\nEaton and Ian Painter.\n\nacopula\n\nModelling dependence with multivariate Archimax (or any user-defined\ncontinuous) copulas. Author: Tomas Bacigal.\n\nagop\n\nAggregation Operators and Preordered Sets. Authors: Marek Gagolewski\n[aut, cre], Anna Cena [ctb].\n\nalm\n\nR wrapper to the almetrics API platform developed by PLoS. Authors:\nScott Chamberlain [aut, cre], Carl Boettiger [aut], Karthik Ram\n[aut], Fenner Martin [aut]. In view:\nWebTechnologies.\n\naml\n\nAdaptive Mixed LASSO. Author: Dong Wang.\n\nanimalTrack\n\nAnimal track reconstruction for high frequency 2-dimensional (2D) or\n3-dimensional (3D) movement data. Authors: Ed Farrell and Lee\nFuiman. In view:\nSpatioTemporal.\n\naoristic\n\naoristic analysis with spatial output (kml). Author: George Kikuchi.\n\naprof\n\nAmdahl’s profiler, directed optimization made easy. Author: Marco D.\nVisser.\n\navgrankoverlap\n\nAverage Rank Overlap. Author: Fatih Sunor [aut, cre].\n\nb6e6rl\n\nAdaptive differential evolution, b6e6rl variant. Author: Marek\nSpruzina.\n\nbbefkr\n\nBayesian bandwidth estimation for the functional kernel regression\nwith unknown error density. Author: Han Lin Shang.\n\nbcpa\n\nBehavioral change point analysis of animal movement. Author: Eliezer\nGurarie. In view:\nSpatioTemporal.\n\nbdynsys\n\nBayesian Dynamical System Model. Authors: Shyam Ranganathan,\nViktoria Spaiser, Richard P. Mann, David J. T. Sumpter.\n\nbigGP\n\nDistributed Gaussian process calculations. Authors: Christopher\nPaciorek [aut, cre], Benjamin Lipshitz [aut], Prabhat [ctb],\nCari Kaufman [ctb], Tina Zhuo [ctb], Rollin Thomas [ctb].\n\nbizdays\n\nFunctions to handle business days calculations. Author: Wilson\nFreitas.\n\nblkergm\n\nFitting block ERGM given the block structure on social networks.\nAuthors: Xiaolin Yang, Stephen Fienberg, Alessandro Rinaldo, Han\nLiu, Michael Rosenblum.\n\nboxplotdbl\n\nDouble Box Plot for Two-Axes Correlation. Author: Shinichiro\nTomizono.\n\nbranchLars\n\nCost-efficient Variable Selection. Author: Li Hua Yue.\n\ncSFM\n\nCovariate-adjusted Skewed Functional Model (cSFM). Authors: Meng Li,\nAna-Maria Staicu, and Howard D. Bondell.\n\ncabootcrs\n\nBootstrap Confidence Regions for Correspondence Analysis.\nAuthor: T. J. Ringrose.\n\ncamel\n\nCalibrated Machine Learning. Authors: Xingguo Li, Tuo Zhao, and Han\nLiu.\n\ncensNID\n\nCensored NID samples. Authors: A. I. McLeod and N. M. Mohammad.\n\ncgwtools\n\nMy collection of useful tools. Author: Carl Witthoft.\n\nchemosensors\n\nA tool for the design of synthetic experiments in machine olfaction.\nAuthors: Alexandre Perera-Lluna and Andrey Ziyatdinov.\n\nchngpt\n\nChange Point Logistic Regression. Author: Youyi Fong.\n\ncirclize\n\nCircular layout in R. Author: Zuguang Gu.\n\nclogitL1\n\nFitting exact conditional logistic regression with lasso and elastic\nnet penalties. Authors: Stephen Reid and Robert Tibshirani.\n\ncluster.datasets\n\nCluster Analysis Data Sets. Author: Frederick Novomestky.\n\nclusterGenomics\n\nIdentifying clusters in genomics data by recursive partitioning.\nAuthors: Gro Nilsen and Ole Christian Lingjaerde.\n\nclustrd\n\nMethods for joint dimension reduction and clustering. Authors:\nAngelos Markos [aut, cre], Alfonso Iodice D’ Enza [aut], Michel\nVan de Velden [aut].\n\ncodadiags\n\nMarkov chain Monte Carlo burn-in based on “bridge” statistics.\nAuthors: Yann Richet, Xavier Bay, Olivier Jacquet, Alexis Jinaphanh.\n\ncold\n\nCount Longitudinal Data. Authors: M. Helena Gonçalves and M. Salomé\nCabral, apart from a set of Fortran-77 subroutines written by R.\nPiessens and E. de Doncker, belonging to the suite “Quadpack”.\n\ncomclim\n\nCommunity climate statistics. Author: Benjamin Blonder.\n\ncompactr\n\nCreates empty plots with compact axis notation. Author: Carlisle\nRainey.\n\nconeproj\n\nPrimal or Dual Cone Projections with Routines for Shape-restricted\nRegression. Authors: Mary C. Meyer and Xiyue Liao.\n\nconvevol\n\nQuantify and assess the significance of convergent evolution.\nAuthors: C. Tristan Stayton [aut, cre]. In view:\nPhylogenetics.\n\ncorTools\n\nTools for processing data after a Genome Wide Association Study.\nAuthor: Angela Fan.\n\ncovLCA\n\nLatent Class Models with Covariate Effects on Underlying and\nMeasured Variables. Authors: Aurelie Bertrand and Christian M.\nHafner.\n\ncpa\n\nConfirmatory Path Analysis through the d-sep tests. Authors:\nAlessandro Bellino and Daniela Baldantoni.\n\ncpk\n\nClinical Pharmacokinetics. Authors: Oscar A. Linares [aut, cre],\nDavid T. Daly [aut].\n\ncrch\n\nCensored Regression with Conditional Heteroscedasticity. Authors:\nJakob Messner [aut, cre], Achim Zeileis [aut]. In view:\nEconometrics.\n\ncrqa\n\nCross-Recurrence Quantification Analysis for Categorical and\nContinuous Time-Series. Authors: Moreno I. Coco and Rick Dale.\n\ncycloids\n\nAuthor: Peter Biber.\n\nd3Network\n\nTools for creating D3 JavaScript network and tree graphs from R.\nAuthor: Christopher Gandrud.\n\ndataQualityR\n\nPerforms variable level data quality checks and generates summary\nstatistics. Authors: Madhav Kumar and Shreyes Upadhyay.\n\ndecctools\n\nGet energy data from the UK Dept of Energy and Climate Change.\nAuthor: James Keirstead. In view:\nWebTechnologies.\n\ndemoKde\n\nKernel Density Estimation for Demonstration Purposes. Author: Bill\nVenables.\n\ndiaplt\n\nBeads Summary Plot of Ranges. Author: Shinichiro Tomizono.\n\ndiffEq\n\nFunctions from the book “Solving Differential Equations in R”.\nAuthor: Karline Soetaert.\n\ndiffIRT\n\nDiffusion-based IRT models for Response and Response Time Data.\nAuthor: Dylan Molenaar.\n\ndils\n\nData-Informed Link Strength. Combine multiple-relationship networks\ninto a single weighted network. Impute (fill-in) missing network\nlinks. Author: Stephen R. Haptonstahl.\n\ndirectPA\n\nDirection Pathway Analysis. Authors: Pengyi Yang and Ellis Patrick.\n\ndistillery\n\nMethod Functions for Confidence Intervals and to Distill Information\nfrom an Object. Author: Eric Gilleland.\n\ndistrom\n\nDistributed Multinomial Regression. Author: Matt Taddy.\n\ndosresmeta\n\nPerforming dose-response meta-analysis. Author: Alessio Crippa. In\nview:\nMetaAnalysis.\n\ndpcR\n\nDigital PCR Analysis. Authors: Michal Burdukiewicz, Stefan Roediger.\n\ndrmdel\n\nDual empirical likelihood inference under density ratio models for\nmultiple samples. Author: Song Cai.\n\ndupiR\n\nBayesian inference from count data using discrete uniform priors.\nAuthors: Federico Comoglio and Maurizio Rinaldi.\n\ndynBiplotGUI\n\nFull Interactive GUI for Dynamic Biplot in R. Author: Jaime Egido.\n\ndynsim\n\nAn R implementation of dynamic simulations of autoregressive\nrelationships. Authors: Laron K Williams, Guy D Whitten, and\nChristopher Gandrud.\n\neffsize\n\nFunctions for computing effect sizes. Author: Marco Torchiano.\n\neggCounts\n\nHierarchical modelling of faecal egg counts. Author: Michaela Paul.\n\neigenprcomp\n\nComputes confidence intervals for principal components. Author:\nFrancisco Juretig.\n\nelliplot\n\nEllipse Summary Plot of Quantiles. Author: Shinichiro Tomizono.\n\nem2\n\nCompute reading time measures for psycholinguistics. Authors: Pavel\nLogacev, Shravan Vasishth.\n\nemdatr\n\nGlobal disaster losses from the EM-DAT database. Author: Gopi\nGoteti.\n\nenRich\n\nAnalysis of multiple ChIP-seq data. Authors: Yanchun Bao and\nVeronica Vinciotti.\n\nentropart\n\nEntropy partitioning to measure diversity. Authors: Eric Marcon,\nBruno Herault.\n\nenviPat\n\nIsotope pattern, profile and centroid calculation for mass\nspectrometry. Authors: Martin Loos, Christian Gerber.\n\nepibase\n\nbasic tools for the analysis of disease outbreaks. Authors: The\nHackout team (In alphabetic order: David Aanensen, Marc Baguelin,\nPaul Birrell, Simon Cauchemez, Anton Camacho, Caroline Colijn, Anne\nCori, Xavier Didelot, Ken Eames, Christophe Fraser, Simon Frost,\nNiel Hens, Joseph Hugues, Thibaut Jombart, Lulla Opatowski, Oliver\nRatmann, Samuel Soubeyrand, Marc Suchard, Jacco Wallinga, Rolf\nYpma).\n\neqs2lavaan\n\nEQS Output Conversion to lavaan Functions. Author: Craig M.\nKrebsbach.\n\nequateIRT\n\nDirect, chain and average equating coefficients with standard errors\nusing IRT methods. Author: Michela Battauz. In view:\nPsychometrics.\n\nerboost\n\nNonparametric Multiple Expectile Regression via ER-Boost. Authors:\nYi Yang, Hui Zou.\n\nergm.graphlets\n\nERG Modeling Based on Graphlet Properties. Authors: Omer Nebil\nYaveroglu [aut, cre], Sean M. Fitzhugh [aut], Maciej Kurant\n[aut], Athina Markopoulou [aut], Natasa Przulj [aut],\nCarter T. Butts [aut].\n\neventInterval\n\nSequential event interval analysis. Author: Jim Lemon.\n\nevmix\n\nExtreme Value Mixture Modelling, Threshold Estimation and Boundary\nCorrected Kernel Density Estimation. Authors: Yang Hu and Carl\nScarrott, University of Canterbury.\n\nevobiR\n\nEvolutionary biology in R. Author: Heath Blackmon. In view:\nPhylogenetics.\n\nevt0\n\nMean of order p (MOP) and peaks over random threshold (PORT) Hill\nestimates for the extreme value index (EVI). Author: B G Manjunath.\n\nexactmeta\n\nExact fixed effect meta analysis. Authors: Yilei Yu and Lu Tian. In\nview:\nMetaAnalysis.\n\nexcursions\n\nFunctions that compute probabilistic excursion sets and contour\ncredibility regions for latent Gaussian random processes and fields.\nAuthors: David Bolin and Finn Lindgren.\n\nexpands\n\nAuthor: Noemi Andor.\n\nfExpressCertificates\n\nStructured Products Valuation for ExpressCertificates/Autocallables.\nAuthor: Stefan Wilhelm.\n\nfICA\n\nClassic, reloaded and adaptive FastICA algorithms. Authors: Jari\nMiettinen, Klaus Nordhausen, Hannu Oja, Sara Taskinen.\n\nfactas\n\nData Mining Methods. Author: Romain Bar.\n\nfclust\n\nFuzzy clustering. Authors: Paolo Giordani, Maria Brigida Ferraro.\n\nfcros\n\nFCROS for detecting differentially expressed genes. Author: Doulaye\nDembele.\n\nfdakma\n\nClustering and alignment of a functional dataset. Authors: Mirco\nPatriarca, Laura Sangalli, Piercesare Secchi, Simone Vantini,\nValeria Vitelli.\n\nfdatest\n\nInterval Testing Procedure for functional data. Authors: Alessia\nPini, Simone Vantini.\n\nfishMod\n\nFits Poisson-sum-of-Gammas GLMs, Tweedie GLMs, and delta log-normal\nmdoels. Author: Scott D. Foster.\n\nfitTetra\n\nAssigning tetraploid genotype scores. Authors: Roeland Voorrips and\nGerrit Gort.\n\nflexCWM\n\nFlexible Cluster-Weighted Modeling. Authors: A. Mazza, A. Punzo, S.\nIngrassia.\n\nflora\n\nTaxonomical information on flowering species that occur in Brazil.\nAuthor: Gustavo Carvalho. In view:\nWebTechnologies.\n\nfscaret\n\nAutomated caret feature selection. Authors: Jakub Szlek,\nacknowledgments to Aleksander Mendyk, contributions from\nstackoverflow and r-help@r-project.org mailing list community.\n\ngPCA\n\nBatch Effect Detection via Guided Principal Components Analysis.\nAuthor: Sarah Reese.\n\ngWidgets2\n\nRewrite of gWidgets API for simplified GUI construction. Author:\nJohn Verzani.\n\ngWidgets2RGtk2\n\nImplementation of gWidgets2 for RGtk2 package. Author: John\nVerzani.\n\ngWidgets2tcltk\n\nToolkit implementation of gWidgets2 for tcltk package. Author:\nJohn Verzani.\n\ngambin\n\nFit the GamBin model to species abundance distributions. Authors:\nMichael Krabbe Borregaard, Thomas Matthews and Karl Ugland.\n\ngenMOSSplus\n\nApplication of MOSS algorithm to genome-wide association study\n(GWAS). Authors: Olga Vesselova, Matthew Friedlander, Laurent\nBriollais, Adrian Dobra, Helene Massam.\n\ngeorob\n\nRobust Geostatistical Analysis of Spatial Data. Authors: Andreas\nPapritz [cre, aut], Cornelia Schwierz [ctb]. In view:\nSpatial.\n\ngeostatsp\n\nGeostatistics using SpatialPoints and rasters. Authors: Patrick\nBrown [aut, cre], Robert Hijmans [ctb].\n\ngettingtothebottom\n\nGetting to the Bottom, a package for Learning Optimization Methods.\nAuthor: Jocelyn T. Chi.\n\nggHorizon\n\nAn implementation of Horizon Graph. Author: Thomas Kern.\n\nggROC\n\nROC curve plot with ggplot2. Author: Honglong Wu.\n\ngitter\n\nRobust and accurate quantification of pinned colony sizes in\nmicroorganisms. Authors: Omar Wagih, Leopold Parts.\n\nglinternet\n\nLearning interactions via hierarchical group-lasso regularization.\nAuthors: Michael Lim, Trevor Hastie.\n\nglmlep\n\nFit GLM with LEP-based penalized maximum likelihood. Authors:\nCanhong Wen, Hao Lin.\n\nglobalGSA\n\nGlobal Gene-Set Analysis for Association Studies. Authors: Natalia\nVilor, M.Luz Calle.\n\nglobalOptTests\n\nObjective functions for benchmarking the performance of global\noptimization algorithms. Author: Katharine Mullen.\n\ngmatrix\n\nHarnessing GPU Power. Author: Nathan Morris.\n\ngovStatJPN\n\nfunctions to get public survey data in Japan. Author: Yuichiro\nOtani. In view:\nWebTechnologies.\n\ngpk\n\n100 Data Sets for Statistics Education. Author: Prabhanjan Tattar.\n\ngpmap\n\nAnalysing and plotting genotype-phenotype maps. Authors: Arne B.\nGjuvsland and Yunpeng Wang.\n\ngpr\n\nA Minimalistic package to apply Gaussian Process in R. Author:\nAfshin Sadeghi.\n\ngrowthmodels\n\nNonlinear Growth Models. Author: Daniel Rodriguez Perez.\n\ngsalib\n\nUtility functions for GATK. Author: Kiran Garimella.\n\ngskat\n\nGEE_KM. Author: Xuefeng Wang.\n\nhighr\n\nSyntax highlighting for R. Authors: Yihui Xie and Yixuan Qiu.\n\nhsphase\n\nPhasing and imputation of half-sib families using SNP data. Authors:\nMohammad Ferdosi, Cedric Gondro.\n\nhumanFormat\n\nHuman-friendly formatting functions. Author: Dustin Sallings.\n\nhydroApps\n\nTools and models for hydrological applications. Author: Daniele\nGanora.\n\nhypervolume\n\nHigh-dimensional kernel density estimation and geometry operations.\nAuthor: Benjamin Blonder.\n\nhysteresis\n\nTools for Modeling Rate-Dependent Hysteretic Processes and Ellipses.\nAuthors: Spencer Maynes, Fan Yang, and Anne Parkhurst.\n\ninarmix\n\nMixture models for longitudinal count data. Authors: Nicholas\nHenderson and Paul Rathouz.\n\nincReg\n\nIncremental Multivariate Regression. Author: Alexander Entzian\n[cre, aut, cph].\n\ninfluence.SEM\n\nCase Influence in Structural Equation Models. Authors: Massimiliano\nPastore and Gianmarco Altoe’.\n\ninvestr\n\nCalibration/Inverse Estimation with Linear and Nonlinear Regression\nModels in R. Author: Brandon M. Greenwell.\n\nipfp\n\nFast implementation of the iterative proportional fitting procedure\nin C. Author: Alexander W Blocker.\n\niqLearn\n\nInteractive Q-learning. Authors: Kristin A. Linn, Eric B. Laber,\nLeonard A. Stefanski.\n\nitree\n\nTools for classification and regression trees, with an emphasis on\ninterpretability. Authors: Alex Goldstein (itree modifications),\nTerry Therneau, Beth Atkinson, Brian Ripley (rpart).\n\njtrans\n\nJohnson transformation for normality. Author: Wang Yuchen.\n\njvmr\n\nIntegration of R, Java, and Scala. Author: David B. Dahl.\n\nkcirt\n\nk-Cube Thurstonian IRT Models. Authors: Dave Zes, Jimmy Lewis, Dana\nLandis.\n\nkedd\n\nKernel Estimator and Bandwidth Selection for Density and its\nDerivatives. Author: Arsalane Chouaib Guidoum.\n\nkmconfband\n\nKaplan-Meier Simultaneous Confidence Band for the Survivor Function.\nAuthor: David E. Matthews.\n\nkmlcov\n\nClustering longitudinal data using the likelihood as a metric of\ndistance. Authors: Mamoun O. Benghezal [aut, cre], Christophe\nGenolini [ctb].\n\nknitrBootstrap\n\nKnitr Bootstrap framework. Author: Jim Hester.\n\nkrm\n\nKernel-based Regression Models. Authors: Youyi Fong, Saheli Datta,\nKrisztian Sebestyen.\n\nktsolve\n\nConfigurable function for solving families of nonlinear equations.\nAuthor: Carl Witthoft.\n\nl2boost\n\nFriedman’s boosting algorithm for regularized linear regression.\nAuthors: John Ehrlinger [aut, cre], Hemant Ishwaran [aut].\n\nlaGP\n\nLocal Approximate Gaussian Process Regression. Author: Robert B.\nGramacy.\n\nlabel.switching\n\nRelabelling MCMC outputs of mixture models. Author: Panagiotis\nPapastamoulis.\n\nlearningr\n\nData and functions to accompany the book “Learning R”. Author:\nRichie Cotton.\n\nlikeLTD\n\nTools to determine DNA profile evidence. Authors: David Balding,\nAdrian Timpson, Christopher Steele, Mayeul d’Avezac, James\nHetherington.\n\nlikert\n\nFunctions to analyze and visualize likert type items. Authors: Jason\nBryer, Kimberly Speerschneider.\n\nlm.br\n\nLinear Model with Breakpoint. Authors: Marc Adams [aut, cre],\nauthors of R function ‘lm’ [ctb] (general interface), authors of\n‘lm.gls’ [ctb] (interface and R code for matrix weights), U.S.\nNIST [ctb] (C++ code for TNT::Vector template).\n\nlocits\n\nTest of stationarity and localized autocovariance. Authors: Guy\nNason [aut, cre].\n\nlogcondens.mode\n\nCompute MLE of Log-Concave Density on R with Fixed Mode, and Perform\nInference for the Mode. Author: Charles Doss.\n\nlomb\n\nLomb-Scargle Periodogram. Authors: Thomas Ruf, partially based on C\noriginal by Press et al. (Numerical Recipes).\n\nlrmest\n\nDifferent types of estimators to deal with multicollinearity.\nAuthors: Ajith Dissanayake [aut, cre], P. Wijekoon [aut], R-core\n[cph].\n\nlsdv\n\nFixed effect panel data regression. Author: Zaghdoudi Taha.\n\nlshorth\n\nThe Length of the Shorth. Author: G. Sawitzki.\n\nltsbase\n\nRidge and Liu Estimates based on LTS (Least Trimmed Squares) Method.\nAuthors: Betul Kan Kilinc [aut, cre], Ozlem Alpu [aut, cre].\n\nlymphclon\n\nAccurate Estimation of Clonal Coincidences and Abundances from\nBiological Replicates. Authors: Yi Liu [aut, cre], Richard A.\nOlshen [aut], Andrew Z. Fire [aut], Scott D. Boyd [aut].\n\nmQTL\n\nMetabolomic Quantitative Trait Locus Mapping. Authors: Lyamine\nHedjazi and Jean-Baptiste Cazier.\n\nmallet\n\nA wrapper around the Java machine learning tool MALLET. Author:\nDavid Mimno.\n\nmapmisc\n\nUtilities for producing maps. Author: Patrick Brown.\n\nmarkovchain\n\nHandle and analyze discrete Markov chains. Author: Giorgio Alfredo\nSpedicato. In view:\nFinance.\n\nmatrixpls\n\nMatrix-based Partial Least Squares estimation. Author: Mikko\n\nmbbefd\n\nMBBEFD distribution and exposure curve. Author: Giorgio Spedicato.\nIn view:\nDistributions.\n\nmcGlobaloptim\n\nGlobal optimization using Monte Carlo and Quasi Monte Carlo\nsimulation. Author: Thierry Moudiki.\n\nmemuse\n\nEstimate the memory usage of dense, in-core, numeric objects.\nAuthor: Drew Schmidt.\n\nmicromapST\n\nLinked Micromap Plots for U. S. States. Authors: Dan Carr and Jim\nPearson, with contributions from Linda Pickle.\n\nmidasr\n\nMixed Data Sampling Regression. Authors: Virmantas Kvedaras,\nVaidotas Zemlys. In views:\nEconometrics,\nTimeSeries.\n\nmigration.indices\n\nMigration indices. Authors: Lajos Bálint and Gergely Daróczi.\n\nmistat\n\nData sets, functions and examples from the book: “Modern Industrial\nStatistics” by Kenett, Zacks and Amberti. Author: Daniele Amberti.\n\nmizer\n\nMulti-species sIZE spectrum modelling in R. Authors: Finlay Scott\nand Julia Blanchard and Ken Andersen.\n\nmlDNA\n\nMachine Learning-based Differential Network Analysis of\nTranscriptome Data. Authors: Chuang Ma and Xiangfeng Wang.\n\nmlr\n\nMachine Learning in R. Author: Bernd Bischl.\n\nmopsocd\n\nMulti-objective Particle Swarm Optimization with Crowding Distance.\nAuthor: Pros Naval.\n\nmpmi\n\nMixed-pair mutual information estimators. Author: Chris Pardy.\n\nmreg\n\nFits regression models when the outcome is partially missing.\nAuthor: Simon Bond.\n\nmultiDimBio\n\nMultivariate Analysis and Visualization for Biological Data. Author:\nSamuel V. Scarpino.\n\nmultiplex\n\nAnalysis of Multiple Social Networks with Algebra. Author: J.\nAntonio Rivero Ostoic. In view:\nPsychometrics.\n\nmvMORPH\n\nMultivariate Comparative Tools for Fitting Evolutionary Models to\nMorphometric Data. Authors: Julien Clavel, with contributions from\nAaron King, and Emmanuel Paradis.\n\nmvSLOUCH\n\nMultiVariate Stochastic Linear Ornstein-Uhlenbeck models for\nphylogenetic Comparative hypotHeses. Author: Krzysztof Bartoszek.\n\nmvcwt\n\nWavelet analysis of multiple time series. Author: Timothy H. Keitt.\n\nnaturalsort\n\nNatural Ordering. Author: Kosei Abe.\n\nndtv\n\nNetwork Dynamic Temporal Visualizations. Authors: Skye Bender-deMoll\n[cre, aut], Martina Morris [ctb].\n\nneedy\n\nAuthor: Ryan Grannell.\n\nnetClass\n\nNetwork-Based Biomarker Discovery. Author: Yupeng Cun.\n\nnetmeta\n\nNetwork meta-analysis with R. Authors: Gerta Ruecker, Guido\nSchwarzer. In view:\nMetaAnalysis.\n\nnetweavers\n\nNetWeAvers: Weighted Averages for Networks. Author: Elizabeth\nMcClellan.\n\nneuroblastoma\n\nNeuroblastoma copy number profiles. Author: Toby Dylan Hocking.\n\nngramr\n\nRetrieve and plot Google n-gram data. Author: Sean Carmody. In view:\nWebTechnologies.\n\nnhlscrapr\n\nCompiling the NHL Real Time Scoring System Database for easy use\nin R. Authors: A.C. Thomas, Samuel L. Ventura. In view:\nWebTechnologies.\n\nnlmeU\n\nDatasets and utility functions enhancing functionality of nlme\npackage. Authors: Andrzej Galecki, Tomasz Burzykowski.\n\nnonlinearTseries\n\nNonlinear time series analysis. Author: Constantino A. Garcia. In\nview: TimeSeries.\n\nnpsp\n\nNonparametric spatial (geo)statistics. Author: Ruben\nFernandez-Casal.\n\nnsga2R\n\nElitist Non-dominated Sorting Genetic Algorithm based on R. Author:\nChing-Shih (Vince) Tsou.\n\nocean\n\nBiophysical Oceanography Tools. Author: Benjamin Jones [aut, cre].\n\nopenNLPdata\n\nApache OpenNLP Jars and Basic English Language Models. Authors: Kurt\nHornik [aut, cre], The Apache Software Foundation [ctb, cph]\n(Apache OpenNLP Java libraries), JWNL development team [ctb, cph]\n(JWNL Java WordNet Library).\n\nopencpu\n\nOpenCPU framework for embedded statistical computation and\nreproducible research. Author: Jeroen Ooms. In view:\nWebTechnologies.\n\noptextras\n\nA set of tools to support optimization methods (function\nminimization with at most bounds and masks). Author: John C. Nash\n[aut, cre].\n\nora\n\nConvenient Tools for Working with Oracle Databases. Author: Arni\nMagnusson.\n\nordBTL\n\nModelling comparison data with ordinal response. Author: Giuseppe\nCasalicchio.\n\npapeR\n\nA toolbox for writing Sweave or other LaTeX-based papers and\nreports. Author: Benjamin Hofner.\n\nparallelMap\n\nUnified interface to some popular parallelization back-ends for\ninteractive usage and package development. Authors: Bernd Bischl,\nMichel Lang.\n\nparboost\n\nDistributed Model-Based Boosting. Author: Ronert Obst.\n\npastis\n\nPhylogenetic Assembly with Soft Taxonomic Inferences. Authors: Klaas\nHartmann, Gavin Thomas, Arne Mooers, Jeffrey Joy, Walter Jetz.\n\npathdiagram\n\nBasic functions for drawing path diagrams. Author: Gaston Sanchez.\n\npawacc\n\nPhysical activity with accelerometers. Author: Marco Geraci.\n\npbdPROF\n\nProgramming with Big Data — MPI Profiling Tools. Authors: Wei-Chen\nChen [aut, cre], Drew Schmidt [aut], Gaurav Sehrawat [aut],\nPragneshkumar Patel [aut], George Ostrouchov [aut]. In view:\nHighPerformanceComputing.\n\npbs\n\nPeriodic B Splines. Author: Shuangcai Wang.\n\npedgene\n\nGene-level statistics for Pedigree Data. Authors: Dan Schaid and\nJason Sinnwell.\n\npeptider\n\nEvaluation of diversity in nucleotide libraries. Authors: Heike\nHofmann, Eric Hare, ggobi Foundation.\n\nphalen\n\nPhalen Algorithms and Functions. Author: Robert P. Bronaugh.\n\nphaseR\n\nPhase Plane Analysis of One and Two Dimensional ODE Systems. Author:\nMichael J. Grayling.\n\nphenmod\n\nAuxiliary functions for phenological data processing, modelling and\nresult handling. Author: Maximilian Lange.\n\nphyloTop\n\nPhylogenetic Tree Topological Properties Evaluator. Author: Michael\nBoyd.\n\nplot3D\n\nPlotting multi-dimensional data. Author: Karline Soetaert.\n\npolyaAeppli\n\nImplementation of the Polya-Aeppli distribution. Author: Conrad\nBurden.\n\npolyclip\n\nPolygon Clipping. Authors: Angus Johnson. Ported to R by Adrian\nBaddeley and Brian Ripley.\n\npopsom\n\nSelf-Organizing Maps With Population Based Convergence Criterion.\nAuthors: Lutz Hamel [aut, cre], Benjamin Ott [aut], Gregory\nBreard [aut].\n\npoweRlaw\n\nFitting heavy tailed distributions. Author: Colin Gillespie.\n\npowerAnalysis\n\nPower analysis in experimental design. Author: Felix Yanhui Fan.\n\nppmlasso\n\nPoint Process Models with LASSO penalties. Author: Ian Renner.\n\nprevalence\n\nAuthors: Brecht Devleesschauwer [aut, cre], Paul Torgerson\n[aut], Johannes Charlier [aut], Bruno Levecke [aut], Nicolas\nPraet [aut], Pierre Dorny [aut], Dirk Berkvens [aut], Niko\nSpeybroeck [aut]. In view:\nBayesian.\n\nprimerTree\n\nAuthor: Jim Hester.\n\nprinsimp\n\nFinding and plotting simple basis vectors for multivariate data.\nAuthors: Davor Cubranic, Jonathan Zhang, Nancy Heckman, Travis\nGaydos, and J.S. Marron.\n\nprofileR\n\nProfile Analysis and Its Applications. Authors: Okan Bulut,\nChristopher David Desjardins. In view:\nPsychometrics.\n\nprognosticROC\n\nPrognostic ROC curves for evaluating the predictive capacity of a\nbinary test. Authors: Y. Foucher and C. Combescure.\n\npropagate\n\nPropagation of Uncertainty. Author: Andrej-Nikolai Spiess.\n\nprospectr\n\nMiscellaneous functions for processing and sample selection of\nvis-NIR diffuse reflectance data. Authors: Antoine Stevens and\nLeonardo Ramirez-Lopez. In view:\nChemPhys.\n\nprotoclass\n\nInterpretable classification with prototypes. Authors: Jacob Bien\nand Robert Tibshirani.\n\npse\n\nParameter space exploration with Latin Hypercubes. Authors: Andre\nChalom, Paulo Inacio Knegt Lopez de Prado.\n\npsidR\n\nBuild panel data sets from PSID raw data. Author: Florian Oswald.\n\npumilioR\n\nPumilio in R. Author: Luis J. Villanueva-Rivera.\n\npvsR\n\nInteract with the Project Vote Smart API for scientific research.\nAuthor: Ulrich Matter.\n\npwt8\n\nPenn World Table (Version 8.0). Author: Achim Zeileis [aut, cre].\nIn view:\nEconometrics.\n\nqfa\n\nTools for modelling the growth dynamics of arrays of large numbers\nof colonies and performing quantitative fitness analysis (QFA).\nAuthors: Conor Lawless, with contributions from Alexander Young and\nDarren Wilkinson.\n\nqiimer\n\nWork with QIIME Output Files in R. Author: Kyle Bittinger.\n\nquint\n\nQualitative Interaction Trees. Authors: Elise Dusseldorp [aut, cre,\ncph], Lisa Doove [aut], Cor Ninaber [ctb] (supported with the\nplot function), Iven Van Mechelen [aut, cph].\n\nrLakeAnalyzer\n\nAnalysis of lake physics. Authors: Luke Winslow, Jordan Read,\nRichard Woolway, Jennifer Brentrup, Jake Zwart.\n\nrLindo\n\nR Interface to LINDO API. Author: Zhe Liu.\n\nrNOMADS\n\nAn interface to the NOAA Operational Model Archive and Distribution\nSystem. Author: Daniel C. Bowman [aut, cre].\n\nraincpc\n\nObtain and Analyze Rainfall data from the Climate Prediction Center\n(CPC). Author: Gopi Goteti.\n\nrandomizationInference\n\nFlexible Randomization-Based Inference. Authors: Joseph J. Lee and\nTirthankar Dasgupta.\n\nrbiouml\n\nFunctions to interact with BioUML server. Authors: Ivan Yevshin and\nTagir Valeev.\n\nrbmn\n\nHandling Linear Gaussian Bayesian Networks. Author: Jean-Baptiste\nDenis.\n\nreader\n\nA suite of functions to flexibly read data from files. Author:\nNicholas Cooper.\n\nreferenceIntervals\n\nReference Intervals. Author: Daniel Finnegan.\n\nregpro\n\nNonparametric Regression. Author: Jussi Klemela.\n\nrentrez\n\nEntrez in R. Author: David Winter. In view:\nWebTechnologies.\n\nreutils\n\nTalk to the NCBI EUtils. Author: Gerhard Schoefl.\n\nrfisheries\n\nR interface for fisheries data. Authors: Karthik Ram [aut, cre],\nCarl Boettiger [aut], Andrew Dyck [aut]. In view:\nWebTechnologies.\n\nrgauges\n\nR wrapper to Gaug.es API. Authors: Scott Chamberlain [aut, cre],\nKarthik Ram [aut]. In view:\nWebTechnologies.\n\nrio\n\nA Swiss-army knife for data file I/O. Authors: Chung-hong Chan,\nGeoffrey CH Chan.\n\nrite\n\nThe Right Editor to Write R. Author: Thomas J. Leeper.\n\nrotations\n\nTools for Working with Rotation Data. Authors: Bryan Stanfill, Heike\nHofmann, Ulrike Genschel.\n\nrsig\n\nRobust Signature Selection for Survival Outcomes. Authors: Sangkyun\nLee, Michel Lang.\n\nrsnps\n\nGet SNP (Single-Nucleotide Polymorphism) data on the web. Authors:\nScott Chamberlain [aut, cre], Kevin Ushey [aut]. In view:\nWebTechnologies.\n\nrtematres\n\nThe rtematres API package. Author: Claas-Thido Pfaff.\n\nrvHPDT\n\nCalling haplotype-based and variant-based pedigree disequilibrium\ntest for rare variants in pedigrees. Author: Wei Guo.\n\nsGPCA\n\nSparse Generalized Principal Component Analysis. Author: Frederick\nCampbell.\n\nsamplingEstimates\n\nSampling Estimates. Author: Emilio Lopez Escobar.\n\nscar\n\nShape-Constrained Additive Regression: a Maximum Likelihood\nApproach. Authors: Yining Chen and Richard Samworth.\n\nscholar\n\nAnalyse citation data from Google Scholar. Author: James Keirstead.\nIn view:\nWebTechnologies.\n\nscoring\n\nProper scoring rules. Author: Ed Merkle.\n\nsealasso\n\nStandard Error Adjusted Adaptive Lasso. Author: Wei Qian.\n\nsensitivitymv\n\nSensitivity Analysis in Observational Studies. Author: Paul R.\nRosenbaum.\n\nseqMeta\n\nMeta-analyzing region-based tests of rare DNA variants. Authors:\nArend Voorman, Jennifer Brody, Han Chen, Thomas Lumley. In view:\nMetaAnalysis.\n\nservr\n\nA simple HTTP server in R. Author: Yihui Xie. In view:\nWebTechnologies.\n\nsheldusr\n\nNatural disaster losses for the USA from the SHELDUS database.\nAuthor: Gopi Goteti.\n\nshinyAce\n\nAce editor bindings for Shiny. Author: Trestle Technology, LLC.\n\nshinyRGL\n\nShiny Wrappers for RGL. Author: Trestle Technology, LLC.\n\nsimMSM\n\nSimulation of event histories based on nonlinear hazard rate\nfunctions and potentially nonlinear covariate effects. Author:\nHolger Reulen.\n\nsimPH\n\nTools for simulating and plotting quantities of interest estimated\nfrom Cox Proportional Hazards models. Author: Christopher Gandrud.\n\nsimsalapar\n\nTools for Simulation Studies in Parallel with R. Authors: Marius\nHofert and Martin Maechler.\n\nsirt\n\nSupplementary Item Response Theory Models. Author: Alexander\nRobitzsch. In view:\nPsychometrics.\n\nsjPlot\n\nData visualization for statistics in social science. Author: Daniel\nLüdecke.\n\nsjdbc\n\nJDBC Driver Interface. Author: TIBCO Software Inc.\n\nsmaa\n\nStochastic Multi-criteria Acceptability Analysis. Author: Gert van\nValkenhoef.\n\nsmam\n\nStatistical Modeling of Animal Movements. Authors: Jun Yan and\nVladimir Pozdnyakov. In view:\nSpatioTemporal.\n\nsmoothie\n\nTwo-dimensional Field Smoothing. Author: Eric Gilleland.\n\nsmss\n\nDatasets for Agresti and Finlay’s “Statistical Methods for the\nSocial Sciences”. Authors: Jeffrey B. Arnold [aut, cre], Alan\nAgresti [cph], Barbara Finlay [cph].\n\nsnapshot\n\nGadget N-body cosmological simulation code snapshot I/O utilities.\nAuthor: Aaron Robotham.\n\nsnplist\n\nTools to create Gene Sets. Authors: Chanhee Yi, Alexander Sibley,\nand Kouros Owzar.\n\nsoilprofile\n\nConsistently represent soil properties along a soil profile. Author:\nGianluca Filippa.\n\nsomebm\n\nSome Brownian motions simulation functions. Author: Junwen Huang.\n\nsorvi\n\nFinnish Open Government Data Toolkit. Authors: Leo Lahti, Juuso\nParkkinen, Joona Lehtomaki, Juuso Haapanen, Jussi Paananen, Einari\nHapponen.\n\nsoundecology\n\nSoundscape ecology. Authors: Luis J. Villanueva-Rivera and Bryan C.\nPijanowski.\n\nspaMM\n\nMixed models, particularly spatial GLMMs. Authors: François Rousset\n[aut, cre, cph], Jean-Baptiste Ferdy [aut, cph].\n\nsparc\n\nSemiparametric Generalized Linear Models. Authors: Tuo Zhao and Han\nLiu.\n\nsparktex\n\nGenerate LaTeX sparklines in R. Authors: Thomas Leeper [aut, cre],\nAndy Barbour [ctb].\n\nsparseBC\n\nSparse biclustering of transposable data. Author: Kean Ming Tan.\n\nsparseMVN\n\nMultivariate normal functions for sparse covariate and precision\nmatrices. Author: Michael Braun. In view:\nDistributions.\n\nspeccalt\n\nAlternative spectral clustering, with automatic estimation of \\(k\\).\nAuthor: Pierrick Bruneau.\n\nsplitstackshape\n\nFunctions to split concatenated data, conveniently stack columns of\ndata.frames, and conveniently reshape data.frames. Author: Ananda\nMahto.\n\nsplusTimeDate\n\nTimes and Dates from S-PLUS. Author: TIBCO Software Inc.\n\nsplusTimeSeries\n\nTime Series from S-PLUS. Author: TIBCO Software Inc.\n\nssfit\n\nFitting of parametric models using summary statistics. Author:\nChristiana Kartsonaki.\n\nssmrob\n\nRobust estimation and inference in sample selection models. Authors:\nMikhail Zhelonkin, Marc G. Genton, Elvezio Ronchetti.\n\nssvd\n\nSparse SVD. Author: Dan Yang. In view:\nNumericalMathematics.\n\nstima\n\nSimultaneous Threshold Interaction Modeling Algorithm. Authors:\nElise Dusseldorp [aut, cre, cph], Claudio Conversano [aut, cph],\nCor Ninaber [ctb], Kristof Meers [ctb], Peter Neufeglise\n[trl].\n\nstraweib\n\nStratified Weibull Regression Model. Authors: Xiangdong Gu and Raji\nBalasubramanian.\n\nstrum\n\nSTRUctural Modeling of Latent Variables for General Pedigree.\nAuthors: Nathan Morris [aut, cre], Yeunjoo Song [aut], Stephen\nCahn [ctb].\n\nstylo\n\nFunctions for a variety of stylometric analyses. Authors: Maciej\nEder, Jan Rybicki, Mike Kestemont.\n\nsuRtex\n\nLaTeX descriptive statistic reporting for survey data. Author:\nDustin Landers.\n\nsurv2sampleComp\n\nInference for model-free between-group parameters for censored\nsurvival data. Authors: Lu Tian, Hajime Uno.\n\nsurvsim\n\nSimulation of simple and complex survival data. Authors: David\nMoriña, Centre Tecnològic de Nutrició i Salut and Albert Navarro.\n\nsvdvisual\n\nSVD visualization tools. Author: Lingsong Zhang.\n\nsvyPVpack\n\nComplex surveys including plausible values. Authors: Manuel Reif,\nJakob Peterbauer.\n\nswitchnpreg\n\nSwitching nonparametric regression models for a single curve and\nfunctional data. Authors: Camila de Souza and Davor Cubranic.\n\nsybilEFBA\n\nUsing gene expression data to improve flux balance analysis\npredictions. Author: Abdelmoneim Amer Desouki [aut, cre].\n\nsymbolicDA\n\nAnalysis of symbolic data. Authors: Andrzej Dudek, Marcin Pelka,\nJustyna Wilk.\n\ntable1xls\n\nProduces summary tables in the format most often encountered in\nscientific articles, and exports them to spreadsheet format (.xls\nor .xlsx). Author: Assaf P. Oron.\n\ntbart\n\nTeitz and Bart p-median algorithm. Author: Chris Brunsdon.\n\ntbdiag\n\nFunctions for tuberculosis diagnostics research. Author: Matt\nParker.\n\ntester\n\nTests and checks characteristics of R objects. Author: Gaston\nSanchez.\n\ntestit\n\nA simple package for testing R packages. Author: Yihui Xie.\n\ntextometry\n\nTextual Data Analysis Package used by the TXM Software. Authors:\nSylvain Loiseau, Vaudor Lise, Matthieu Decorde.\n\ntibbrConnector\n\nR interface to tibbr. Author: TIBCO Software Inc.\n\ntimesboot\n\nBootstrap computations for time series objects. Author: Francisco\nJuretig. In view:\nTimeSeries.\n\ntopsis\n\nTOPSIS method for multiple-criteria decision making (MCDM). Author:\nMahmoud Mosalman Yazdi.\n\ntsbridge\n\nCalculate normalising constants for Bayesian time series models.\nAuthors: Guy J. Abel and Jackie S. T. Wong.\n\nttScreening\n\nGenome-wide DNA methylation sites screening by use of training and\ntesting samples. Authors: Meredith Ray, Xin Tong, Hongmei Zhang.\n\nttwa\n\nTravel To Work Area. Authors: Francois Semecurbe, Joachim Timoteo.\n\nturner\n\nTurn vectors and lists of vectors into indexed structures. Author:\nGaston Sanchez.\n\nuuid\n\nTools for generating and handling of UUIDs. Authors: Simon Urbanek\n(R package), Theodore Ts’o (libuuid).\n\nvarComp\n\nVariance component models. Author: Long Qu.\n\nvbdm\n\nVariational Bayes Discrete Mixture Model. Author: Benjamin Logsdon.\n\nvectoptim\n\nVectorized optimization methods. Authors: Qiang Kou, Yann Richet.\n\nvimcom\n\nIntermediate the communication between Vim and R. Author: Jakson\nAquino.\n\nvscc\n\nVariable selection for clustering and classification. Authors:\nJeffrey L. Andrews, Paul D. McNicholas.\n\nwaldwolf\n\nWald-Wolfowitz trend test. Authors: Jodavid Ferreira, Claudio Souza.\n\nwidenet\n\nPenalized Regression with Polynomial Basis Expansions. Authors:\nStephan Ritter, Alan Hubbard.\n\nwordmatch\n\nMatches words in one file with words in another file. Author: Amit\nSingh Rathore.\n\nwpp2012\n\nWorld Population Prospects 2012. Authors: Hana Sevcikova, Patrick\nGerland, Kirill Andreev, Nan Li, Danan Gu, Thomas Spoorenberg.\n\nwppExplorer\n\nExplorer of World Population Prospects. Author: Hana Sevcikova.\n\nzoom\n\nA spatial data visualization tool. Authors: Corentin M Barbu [aut,\ncre], Sebastian Gibb [ctb].\n\n2 Other changes\nThe following packages were moved to the Archive: BTSPAS, BcDiag,\nBerkeleyEarth, BiGGR, CatDyn, EDanalysis, EquiNorm,\nExactNumCI, ExomeCNV, GOSim, GRRGI, HumMeth27QCReport,\nISIPTA, JointModeling, LSC, LaplacesDemon, LogicForest,\nMFDF, MeDiChI, Metadata, NetworkAnalysis, OrdLogReg,\nPairTrading, RAFM, RHive, RcmdrPlugin.qcc, Read.isi,\nResearchMethods, RghcnV3, SVGmapping, SteinerNet, TCC,\nTextRegression, USPS, WaveletCo, aBioMarVsuit, afmtools,\nbinhf, boolfun, bsml, bwsurvival, cem, climatol,\nclusterCons, coenoflex, cplm, ctarma, curvclust, dclong.spt,\ndriftsel, edesign, elrm, fastVAR, fitDRC, geoPlot,\ngeospacom, igraph0, interactivity, languageR, lcmr, lemma,\nlongRPart, makeR, mapReduce, marginTree, melody, mfr,\nmultmod, nonrandom, ocomposition, openNLPmodels.en,\nopenNLPmodels.es, opencpu.demo, polyphemus, polytomous, popPK,\nproductplots, profanal, rImpactStory, roxyPackage, rriskBayes,\nsabreR, spacom, trex, trio, ttrTests\nThe following packages were resurrected from the Archive: AGSDest,\nBAYSTAR, DDHFm, DescribeDisplay, KappaV, MAMSE, MMS,\nMcSpatial, MethComp, NADA, R4dfp, RMediation, Rclusterpp,\nSimile, TreePar, YourCast, cems, clustvarsel, codep,\ndenpro, gearman, gllm, kernelPop, laser, lazy, lmeSplines,\nmht, mixer, nlts, pamctdp, pcurve, rmetasim, rv,\nsoil.spec, somplot, sspline, tsModel\nThe following package had to be removed: RTriangle\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2013-2-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2013-2 issue.",
    "author": [
      {
        "name": "Hadley Wickham",
        "url": {}
      }
    ],
    "date": "2013-12-01",
    "categories": [],
    "contents": "\n\nWelcome to volume 5, issue 2 of The R Journal. I’m very pleased to\ninclude 21 articles about R for your enjoyment.\nThe end of the year also brings changes to the editorial board. Martyn\nPlummer is leaving the board after four years. Martyn was responsible\nfor writing up the standard operating procedures for the journal, an act\nwhich has made my life as a new editor considerably easier! We welcome\nMichael Lawrence, who will join the editorial board in 2014. I am\nstepping down as Editor-in-Chief and will be leaving this task in the\ncapable hands of Deepayan Sarkar.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2013-2-r-changes/",
    "title": "Changes in R",
    "description": "The 'Changes in R' article from the 2013-2 issue.",
    "author": [
      {
        "name": "The R Core Team",
        "url": {}
      }
    ],
    "date": "2013-12-01",
    "categories": [],
    "contents": "\n\nCHANGES IN R 3.0.2\n\nNEW FEATURES\nThe NEWS files have been re-organized.\nThis file contains news for R >= 3.0.0: news for the 0.x.y, 1.x.y\nand 2.x.y releases is in files NEWS.0, NEWS.1 and NEWS.2. The\nlatter files are now installed when R is installed. An HTML version\nof news from 2.10.0 to 2.15.3 is available as\ndoc/html/NEWS.2.html.\nsum() for integer arguments now uses an integer accumulator of at\nleast 64 bits and so will be more accurate in the very rare case\nthat a cumulative sum exceeds \\(2^{53}\\) (necessarily summing more\nthan 4 million elements).\nThe example() and tools::Rd2ex() functions now have parameters\nto allow them to ignore \\\\dontrun markup in examples. (Suggested\nby Peter Solymos.)\nstr(x) is considerably faster for very large lists, or factors\nwith 100,000 levels, the latter as in PR#15337.\ncol2rgb() now converts factors to character strings not integer\ncodes (suggested by Bryan Hanson).\ntail(warnings()) now works, via the new ‘[‘ method.\nThere is now support for the LaTeX style file zi4.sty which has in\nsome distributions replaced inconsolata.sty.\nunlist(x) now typically returns all non-list xs unchanged, not\njust the “vector” ones. Consequently, format(lst) now also works\nwhen the list lst has non-vector elements.\nThe tools::getVignetteInfo() function has been added to give\ninformation about installed vignettes.\nNew assertCondition(), etc. utilities in tools, useful for\ntesting.\nProfiling now records non-inlined calls from byte-compiled code to\nBUILTIN functions.\nVarious functions in stats and elsewhere that use non-standard\nevaluation are now more careful to follow the namespace scoping\nrules. E.g. stats::lm() can now find stats::model.frame() even\nif stats is not on the search path or if some package defines a\nfunction of that name.\nIf an invalid/corrupt .Random.seed object is encountered in the\nworkspace it is ignored with a warning rather than giving an error.\n(This allows R itself to rely on a working RNG, e.g. to choose a\nrandom port.)\nseq() and seq.int() give more explicit error messages if called\nwith invalid (e.g. NaN) inputs.\nWhen parse() finds a syntax error, it now makes partial parse\ninformation available up to the location of the error. (Request of\nReijo Sund.)\nMethods invoked by NextMethod() had a different dynamic parent to\nthe generic. This was causing trouble where S3 methods invoked via\nlazy evaluation could lose track of their generic. (PR#15267)\nCode for the negative binomial distribution now treats the case\nsize == 0 as a one-point distribution at zero.\nabbreviate() handles without warning non-ASCII input strings which\nrequire no abbreviation.\nread.dcf() no longer has a limit of 8191 bytes per line. (Wish of\nPR#15250.)\nformatC(x) no longer copies the class of x to the result, to\navoid misuse creating invalid objects as in PR#15303. A warning is\ngiven if a class is discarded.\nDataset npk has been copied from\nMASS to allow more tests\nto be run without recommended packages being installed.\nThe initialization of the regression coefficients for non-degenerate\ndifferenced models in arima() has been changed and in some\nexamples avoids a local maximum. (PR#15396)\ntermplot() now has an argument transform.x to control the\ndisplay of individual terms in the plot. (PR#15329)\nformat() now supports digits = 0, to display nsmall decimal\nplaces.\nThere is a new read-only par() parameter called \"page\", which\nreturns a logical value indicating whether the next plot.new()\ncall will start a new page.\nProcessing Sweave and Rd documents to PDF now renders backticks and\nsingle quotes better in several instances, including in \\\\code and\n\\\\samp expressions.\nutils::modifyList() gets a new argument keep.null allowing\nNULL components in the replacement to be retained, instead of\ncausing corresponding components to be deleted.\ntools::pkgVignettes() gains argument check; if set to TRUE, it\nwill warn when it appears a vignette requests a non-existent\nvignette engine.\n\n\nUTILITIES\nR CMD check –as-cran checks the line widths in usage and examples\nsections of the package Rd files.\nR CMD check –as-cran now implies –timings.\nR CMD check looks for command gfile if a suitable file is not\nfound. (Although file is not from GNU, OpenCSW on Solaris installs\nit as gfile.)\nR CMD build (with the internal tar) checks the permissions of\nconfigure and cleanup files and adds execute permission to the\nrecorded permissions for these files if needed, with a warning. This\nis useful on OSes and file systems which do not support execute\npermissions (notably, on Windows).\nR CMD build now weaves and tangles all vignettes, so suggested\npackages are not required during package installation if the source\ntarball was prepared with current R CMD build.\ncheckFF() (used by R CMD check) does a better job of detecting\ncalls from other packages, including not reporting those where a\nfunction has been copied from another namespace (e.g. as a default\nmethod). It now reports calls where .NAME is a symbol registered\nin another package.\nOn Unix-alike systems, R CMD INSTALL now installs packages group\nwritably whenever the library (lib.loc) is group writable. Hence,\nupdate.packages() works for other group members (suggested\noriginally and from a patch by Dirk Eddelbuettel).\nR CMD javareconf now supports the use of symbolic links for\nJAVA_HOME on platforms which have realpath. So it is now\npossible to use\nR CMD javareconf JAVA_HOME=/usr/lib/jvm/java-1.7.0\non a Linux system and record that value rather than the\nfrequently-changing full path such as\n/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.25.x86_64.\n(Windows only.) Rscript -e requires a non-empty argument for\nconsistency with Unix versions of R. (Also Rterm -e and R -e.)\nR CMD check does more thorough checking of declared packages and\nnamespaces. It reports\npackages declared in more than one of the Depends, Imports,\nSuggests and Enhances fields of the DESCRIPTION file.\nnamespaces declared in Imports but not imported from, neither\nin the NAMESPACE file nor using the :: nor ::: operators.\npackages which are used in library() or requires() calls in\nthe R code but were already put on the search path via\nDepends.\npackages declared in Depends not imported via the\nNAMESPACE file (except the standard packages). Objects used\nfrom Depends packages should be imported to avoid conflicts\nand to allow correct operation when the namespace is loaded but\nnot attached.\nobjects imported via ::: calls where :: would do.\nobjects imported by :: which are not exported.\nobjects imported by ::: calls which do not exist.\nSee ‘Writing R Extensions’ for good practice.\nR CMD check optionally checks for non-standard top-level files and\ndirectories (which are often mistakes): this is enabled for\n–as-cran.\nLaTeX style file upquote.sty is no longer included (the version\nwas several years old): it is no longer used in R. A much later\nversion is commonly included in LaTeX distributions but does not\nplay well with the ae fonts which are the default for Sweave\nvignettes.\nR CMD build makes more use of the build sub-directory of package\nsources, for example to record information about the vignettes.\nR CMD check analyses ::: calls.\n\n\nINSTALLATION and INCLUDED SOFTWARE\nThe macros used for the texinfo manuals have been changed to work\nbetter with the incompatible changes made in texinfo 5.x.\nThe minimum version for a system xz library is now 5.0.3 (was\n4.999). This is in part to avoid 5.0.2, which can compress in ways\nother versions cannot decompress.\nThe included version of PCRE has been updated to 8.33.\nThe included version of zlib has been updated to 1.2.8, a bug-fix\nrelease.\nThe included version of xz utils’s liblzma has been updated to\n5.0.5.\nSince javareconf (see above) is used when R is installed, a stable\nlink for JAVA_HOME can be supplied then.\nConfiguring with –disable-byte-compilation will override the\nDESCRIPTION files of recommended packages, which typically require\nbyte-compilation.\nMore of the installation and checking process will work even when\nTMPDIR is set to a path containing spaces, but this is not\nrecommended and external software (such as texi2dvi) may fail.\n\n\nPACKAGE INSTALLATION\nInstallation is aborted immediately if a LinkingTo package is not\ninstalled.\nR CMD INSTALL has a new option –no-byte-compile which will\noverride a ByteCompile field in the package’s DESCRIPTION file.\nLicense BSD is deprecated: use BSD_3_clause or BSD_2_clause\ninstead.\nLicense X11 is deprecated: use MIT or BSD_2_clause instead.\nVersion requirements for LinkingTo packages are now recognized:\nthey are checked at installation. (Fields with version requirements\nwere previously silently ignored.)\nThe limit of 500 S3method entries in a NAMESPACE file has been\nremoved.\nThe default ‘version’ of Bioconductor for its packages has been\nchanged to the upcoming 2.13, but this can be set by the\nenvironment variable R_BIOC_VERSION, e.g. in file Renviron.site.\n\n\nC-LEVEL FACILITIES\nRdefines.h has been tweaked so it can be included in C++ code\nafter R_ext/Boolean.h (which is included by R.h).\nNote that Rdefines.h is not kept up-to-date, and Rinternals.h is\npreferred for new code.\neval and applyClosure are now protected against package code\nsupplying an invalid rho.\n\n\nDEPRECATED AND DEFUNCT\nThe unused namespace argument to package.skeleton() is now\nformally deprecated and will be removed in R 3.1.0.\nplclust() is deprecated: use the plot() method for class\n\"hclust\" instead.\nFunctions readNEWS() and checkNEWS() in package tools are\ndeprecated (and they have not worked with current NEWS files for a\nlong time).\n\n\nDOCUMENTATION\n‘An Introduction to R’ has a new chapter on using R as a scripting\nlanguage including interacting with the OS.\n\n\nBUG FIXES\nhelp.request() could not determine the current version of R on\nCRAN. (PR#15241)\nOn Windows, file.info() failed on root directories unless the path\nwas terminated with an explicit \".\". (PR#15302)\nThe regmatches<-() replacement function mishandled results coming\nfrom regexpr(). (PR#15311)\nThe help for setClass() and representation() still suggested the\ndeprecated argument representation=. (PR#15312)\nR CMD config failed in an installed build of R 3.0.1 (only) when a\nsub-architecture was used. (Reported by Berwin Turlach.)\nOn Windows, the installer modified the etc/Rconsole and\netc/Rprofile.site files even when default options were chosen, so\nthe MD5 sums did not refer to the installed versions. (Reported by\nTal Galili.)\nplot(hclust(), cex =) respects cex again (and possibly others\nsimilarly). (Reported by Peter Langfelder.)\nIf multiple packages were checked by R CMD check, and one was\nwritten for a different OS, it would set –no-install for all\nfollowing packages as well as itself.\nqr.coef() and related functions did not properly coerce real\nvectors to complex when necessary. (PR#15332)\nftable(a) now fixes up empty dimnames such that the result is\nprintable.\npackage.skeleton() was not starting its search for function\nobjects in the correct place if environment was supplied.\n(Reported by Karl Forner.)\nParsing code was changing the length field of vectors and confusing\nthe memory manager. (PR#15345)\nThe Fortran routine ZHER2K in the reference BLAS had a comment-out\nbug in two places. This caused trouble with eigen() for Hermitian\nmatrices. (PR#15345 and report from Robin Hankin)\nvignette() and browseVignettes() did not display non-Sweave\nvignettes properly.\nTwo warning/error messages have been corrected: the (optional)\nwarning produced by a partial name match with a pairlist, the error\nmessage from a zero-length argument to the : operator. (Found by\nRadford Neal; PR#15358, PR#15356)\nsvd() returned NULL rather than omitting components as\ndocumented. (Found by Radford Neal; PR#15360)\nmclapply() and mcparallel() with silent = TRUE could break a\nprocess that uses stdout output unguarded against broken pipes\n(e.g., zip will fail silently). To work around such issues, they\nnow replace stdout with a descriptor pointed to /dev/null\ninstead. For this purpose, internal closeStdout and closeStderr\nfunctions have gained the to.null flag.\nlog(), signif() and round() now raise an error if a single\nnamed argument is not named x. (PR#15361)\ndeparse() now deparses raw vectors in a form that is syntactically\ncorrect. (PR#15369)\nThe jpeg driver in Sweave created a JPEG file, but gave it a\n.png extension. (PR#15370)\nDeparsing of infix operators with named arguments is improved.\n(PR#15350)\nmget(), seq.int() and numericDeriv() did not duplicate\narguments properly. (PR#15352, PR#15353, PR#15354)\nkmeans(algorithm = \"Hartigan-Wong\") now always stops iterating in\nthe QTran stage. (PR#15364).\nread.dcf() re-allocated incorrectly and so could segfault when\ncalled on a file with lines of more than 100 bytes.\nOn systems where mktime() does not set errno, the last second\nbefore the epoch could not be converted from POSIXlt to POSIXct.\n(Reported by Bill Dunlap.)\nadd1.glm() miscalculated F-statistics when df > 1. (Bill Dunlap,\nPR#15386).\nstem() now discards infinite inputs rather than hanging.\n(PR#15376)\nThe parser now enforces C99 syntax for floating point hexadecimal\nconstants (e.g. 0x1.1p0), rather than returning unintended values\nfor malformed constants. (PR#15234)\nmodel.matrix() now works with very long LHS names (more than 500\nbytes). (PR#15377)\nintegrate() reverts to the pre-2.12.0 behaviour: from 2.12.0 to\n3.0.1 it sometimes failed to achieve the requested tolerance and\nreported error estimates that were exceeded. (PR#15219)\nstrptime() now handles %W fields with value 0. (PR#15915)\nR is now better protected against people trying to interact with the\nconsole in startup code. (PR#15325)\nSubsetting 1D arrays often lost dimnames (PR#15301).\nUnary + on a logical vector did not coerce to integer, although\nunary - did.\nna.omit() and na.exclude() added a row to a zero-row data frame.\n(PR#15399)\nAll the (where necessary cut-down) vignettes are installed if R was\nconfigured with –without-recommended-packages.\nsource() did not display filenames when reporting syntax errors.\nSyntax error reports misplaced the caret pointing out the bad token.\n(Windows only) Starting R with R (instead of Rterm or Rgui)\nwould lose any zero-length strings from the command line arguments.\n(PR#15406)\nErrors in the encoding specified on the command line via\n–encoding=foo were not handled properly. (PR#15405)\nIf x is a symbol, is.vector(x, \"name\") now returns TRUE, since\n\"name\" and \"symbol\" should be synonyms. (Reported by Hervé\nPagès.)\nR CMD rtags works on platforms (such as OS X) with a\nXSI-conformant shell command echo. (PR#15231)\nis.unsorted(NA) returns false as documented (rather than NA).\nR CMD LINK did not know about sub-architectures.\nsystem() and system2() are better protected against users who\nmisguidedly have spaces in the temporary directory path.\nfile.show() and edit() are now more likely to work on file paths\ncontaining spaces. (Where external utilities are used, not the norm\non Windows nor in R.app which should previously have worked.)\nPackages using the methods package are more likely to work when\nthey import it but it is not attached. (Several parts of its C code\nwere looking for its R functions on the search path rather than in\nits namespace.)\nlgamma(-x) is no longer NaN for very small x.\n(Windows) system2() now respects specifying stdout and stderr\nas files if called from Rgui. (PR#15393)\nClosing an x11() device whilst locator() or identify() is in\nprogress no longer hangs R. (PR#15253)\nlist.dirs(full.names = FALSE) was not implemented. (PR#15170)\nformat() sometimes added unnecessary spaces. (PR#15411)\nall.equal(check.names = FALSE) would ignore the request to ignore\nthe names and would check them as attributes.\nThe symbol set by tools::Rd2txt_options(itemBullet=) was not\nrespected in some locales. (PR#15435)\nmcMap() was not exported by package parallel. (PR#15439)\nplot() for TukeyHSD objects did not balance dev.hold() and\ndev.flush() calls on multi-page plots. (PR#15449)\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2013-2-r-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2013-2 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2013-12-01",
    "categories": [],
    "contents": "\n1 Donations and new members\nDonations\nFaculty of Psychology, University of Barcelona, Spain\nJoanne M Potts, The Analytical Edge, Australia\nNassim Haddad, Belgium\nTransmitting Science, Spain\nNew supporting institutions\nUniversität für Bodenkultur, Austria\nNew supporting members\nRobin Crocket, UK\nTarundeep Dhot, Canada\nJan Marvin Garbuszus, Germany\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2013-2-siberchicot-dray/",
    "title": "Conference Report: Deuxièmes Rencontres R",
    "description": "The 'Conference Report: Deuxièmes Rencontres R' article from the 2013-2 issue.",
    "author": [
      {
        "name": "Aurélie Siberchicot",
        "url": {}
      },
      {
        "name": "Stéphane Dray",
        "url": {}
      }
    ],
    "date": "2013-10-04",
    "categories": [],
    "contents": "\n\nFollowing the success of the first \"Rencontres R\" (Bordeaux, 2-3 July\n2012, http://r2012.bordeaux.inria.fr/), the second meeting was held in\nLyon on 27-28 June 2013. This French-speaking conference was a great\nsuccess with 216 participants (110 were present at the first\nconference). The aim of the meeting was to provide a national forum for\nthe exchange and sharing of ideas on the use of R in different\ndisciplines. The number of participants and the list of sponsors\n(http://r2013-lyon.sciencesconf.org/resource/sponsors) demonstrate the\nincreasing impact of R in both industry and academia in France. The\nprogram, detailed below, consisted of plenary sessions, oral\npresentations, lightning talks and poster sessions.\n1 Invited speakers\nPlenary sessions consisted of five talks (45 minutes) given by\ninternational experts:\nHadley Wickham: Visualising big data in R\nKarim Chine: R and the cloud\nJérôme Sueur: R as a sound system\nYvonnick Noël: A model comparison approach with\nR2STATS for teaching\nstatistics in the social sciences\nGilbert Ritschard:\nTraMineR: a\ntoolbox for exploring and rendering sequence data\n2 User-contributed sessions\nThirty-two users and developers presented original and attractive\ncontributions covering nine fields:\ngraphics & visualization\nhigh performance computing\napplied statistics\ndata analysis & classification\npackages specific to a field of application\nteaching & pedagogy\nmixed models & longitudinal data\ndynamic documents & graphical interface\ngenomic data analysis\nAdditionally, fourteen lightning talks (6 minutes with an automatic\nslide advancement) allowed participants to quickly present their work on\nR. Eight posters were presented during the poster session and the\ncontribution of Ewen Gallic (University Rennes 1) entitled Visualizing\nspatial processes using Ripley’s correction won the best poster prize\n(two R books).\n3 Pre-conference tutorials\nTwo tutorial sessions were organized on Wednesday 26 June afternoon\n(around 30 participants per tutorial). The first session on Parallel\ncomputing with R was taught by Vincent Miele (University Lyon 1).\nDuring the second session, Anne-Béatrice Dufour (University Lyon 1) and\nSylvain Mousset (University Lyon 1) showed How to write a report with\nSweave and then Christophe Genolini (University Paris Ouest - Nanterre)\nintroduced How to create an R package.\n4 Conclusions\nThe organizing committee consisted of Julien Barnier (ENS Lyon),\nStéphane Dray (Chairman, University Lyon 1), Kenneth Knoblauch (Inserm\nLyon), Martyn Plummer (IARC) and Aurélie Siberchicot (University Lyon\n1).\nThe program was designed by the scientific committee composed of Simon\nBarthelmé (University of Geneva), Marie-Laure Delignette-Muller (VetAgro\nSup), Christophe Genolini, Robin Genuer (Chairman, University Bordeaux\n2), Julie Josse (Agrocampus Rennes) and Jérôme Saracco (Bordeaux\nInstitute of Technology).\nThe list of sponsors, participants, program, abstracts and slides are\nfreely available on the conference web site at\nhttp://r2013-lyon.sciencesconf.org/. We would like to thank the\nmembers of the steering committee that initiated this conference: Marie\nChavent (University Bordeaux 2), Robin Genuer, François Husson\n(Agrocampus Rennes), Julie Josse, Benoit Liquet (University Bordeaux 2)\nand Jérôme Saracco.\nDuring the meeting, several discussions took place about the structuring\nof the French-speaking R-users community. After the conference, we\nlaunched an R-user group based at Lyon (see\nhttp://listes.univ-lyon1.fr/sympa/info/rlyon) and we will try to share\nsome resources (common web site, etc.) with the existing semin-R group\nbased at Paris (http://rug.mnhn.fr/semin-r). During the conference, it\nwas also decided that the third edition of the \"Rencontres R\" will be\norganized in Montpellier in 2014.\n\n\n\n\nCRAN packages used\nR2STATS, TraMineR\nCRAN Task Views implied by cited packages\nSurvival\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2013-1-bioconductor/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2013-1 issue.",
    "author": [
      {
        "name": "Bioconductor Team",
        "url": {}
      }
    ],
    "date": "2013-06-01",
    "categories": [],
    "contents": "\n\nBioconductor 2.12 was released on 3 October 2012. It is compatible with\nR 3.0.1, and consists of 671 software packages and more than 675\nup-to-date annotation packages. The release includes 65 new software\npackages, and enhancements to many others. Descriptions of new packages\nand updated NEWS files provided by current package maintainers are at\nhttp://bioconductor.org/news/bioc_2_12_release/.\nStart using Bioconductor and R version 3.0.1 with\n> source(\"http://bioconductor.org/biocLite.R\")\n> biocLite()\nInstall additional packages, e.g., VariantTools, with\n> source(\"http://bioconductor.org/biocLite.R\")\n> biocLite(\"VariantTools\")\nUpgrade installed packages with\n> source(\"http://bioconductor.org/biocLite.R\")\n> biocLite()\nNew this release is biocValid(), a companion function to detect R /\nBioconductor version mis-matches.\nExplore available Bioconductor packages at\nhttp://bioconductor.org/packages/release/. All packages are grouped by\n‘BiocViews’ to identify coherent groups of packages. Each package has an\nhtml page with the descriptions and links to vignettes, reference\nmanuals, and use statistics.\nA Bioconductor Amazon Machine Instance is available and updated; see\nhttp://bioconductor.org/help/bioconductor-cloud-ami.\n1 Core annotation and software packages\nThis release includes AnnotationHub, a resource that enables ready\naccess to large genome-scale resources (e.g., GTF or FASTA files from\nEnsembl; ENCODE tracks from UCSC) in formats (e.g., GRanges or VCF\ninstances) that allow smooth integration with R work flows. The\nAnnotationHub resource can be queried through simple tab completion,\nor via metadata about resource provenance. Additional new annotation\nresources include ensemblVEP to query the Ensembl Variant Effect\nPredictor, and KEGGREST and UniProt.ws packages for on-line\nintegration of data from corresponding resources. Our large collection\nof microarray- and organism-specific annotation packages have been\nupdated to include current information.\nGenomicRanges and related packages, e.g., VariantAnnotation,\nIRanges, Biostrings, Rsamtools, GenomicFeatures provide an\nextensive, mature and extensible framework for interacting with high\nthroughput sequence data, either as a user or package developer. Many\ncontributed packages rely on this infrastructure for interoperable,\nre-usable analysis.\n2 Other activities\nBioconductor’s Annual Meeting is in Seattle, 17-19 July 2013, see\nhttp://bioconductor.org/bioc2013; our European developer community\nmeets in December, with final arrangements pending. Additional training\nand community activities advertised at\nhttp://bioconductor.org/help/events/. The active Bioconductor mailing\nlists (http://bioconductor.org/help/mailing-list/) connect users with\neach other, to domain experts, and to maintainers eager to ensure that\ntheir packages satisfy the needs of leading edge approaches. Keep\nabreast of packages added to the ‘devel’ branch and other activities by\nfollowing Bioconductor on Twitter.\nPackage developers will be interested in ongoing efforts planned for our\nnext release. Activities include better integration of parallel\nevaluation, graphical interfaces to Bioconductor objects (e.g., via\nshiny, elaboration of\nAnnotationHub to support user-contributed and locally curated data, a\nrepository for workflow and other packages that change infrequently but\nrequire significant computational resources to build, and efforts to\nease integrate with github and other social coding resources. Our Google\nSummer of Code participants are enabling progress on some of these\ntopics.\n\n\nCRAN packages used\nshiny\nCRAN Task Views implied by cited packages\nWebTechnologies\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2013-1-chinese-r-conf/",
    "title": "Conference Review: The 6th Chinese R Conference",
    "description": "The 'Conference Review: The 6th Chinese R Conference' article from the 2013-1 issue.",
    "author": [
      {
        "name": "Jing Leng",
        "url": {}
      },
      {
        "name": "Jingjing Guan",
        "url": {}
      }
    ],
    "date": "2013-06-01",
    "categories": [],
    "contents": "\n\nThe 6th Chinese R Conference (Beijing session) was held in the Sinology\nPavilion of Renmin University of China (RUC), Beijing, from May 18th to\n19th, 2013. The conference was organized by the “Capital of Statistics”\n(COS, http://cos.name), an online statistical community in China. It\nwas sponsored and co-organized by the Center for Applied Statistics of\nRUC, the School of Statistics of RUC, and the Business Intelligence\nResearch Center of Peking University.\nSince the 1st Chinese R Conference in 2008, this conference has become a\nregular and popular event for Chinese R users, where they share cutting\nedge techniques and applications with R. This is a bi-annual conference\nwith a Beijing session in the summer and a Shanghai session in the\nwinter each year.\nThis year, more than 400 attendees from China and overseas attended the\nBeijing conference. In particular, for the first time had two foreign\nspeakers at the Beijing conference1: John Maindonald (Australian\nNational University) and Graham Williams (Australian Taxation Office).\nYihui Xie, the founder of COS and the Chinese R Conference, also came\nback from the United States and presented at the conference.\nThe conference program included nineteen talks on a variety of topics,\nincluding visualizations in epidemiology, customer behaviors of\ne-commerce websites, and text mining of online social networks. It also\nprovided two lightning talk sessions as opportunities for people from\ndifferent industries to promote their business and hire R users.\nDiscussions among the audience and speakers showed increasing impact and\npopularity of R language in both the industry and academia in China.\nBelow is the list of talks:\nOpening\n\nChen Yu, the Vice Chair of the conference, provided a brief\nintroduction of the 6th Chinese R Conference; Prof Xizhi Wu, the\nfirst person to introduce R to the School of Statistics of RUC, gave\nan inspiring talk encouraging the younger generation to work hard\n(he mentioned Prof Bin Yu as an outstanding example); Prof Yanyun\nZhao, the Dean of the School of Statistics of RUC, delivered a\nwelcome speech;\n\nSoftware Development\n\n“Sharing my lessons in R package development” by Yihui Xie; “A\ncloud-based decision making system based on R” by Ben-Chang Shia and\nSizhe Liu;\n\nData Mining\n\n“Data mining with Rattle and R” by Graham Williams; “Detection of\nonline public opinions: text mining and visualization in R” by He\nWang;\n\nVisualization\n\n“displayHTS: an R package for displaying data and results from\nhigh-throughput screening experiments” by Xiaohua Zhang; “An\nintroduction to MSToolkit, Rweibo and html5vis: analysis of\nH7N9 in R” by Jian Li and Yang Zhou;\n\nBusiness Applications\n\n“Application of R in eBay big data analysis” by Zhong Li and Jiaming\nPan; “Data scientists and engineering applications of R” by Guozhu\nWen; “Applications of machine learning in online advertisements” by\nBaotong Zhuang; “Quality assessment and intelligent sorting of\nuser-generated content” by Hao Wang; “Online behavior in the mobile\napplications: an attempt in R” by Tingrui Zhou;\n\nStatistical Methodologies\n\n“Bayesian hierarchical models in R and WinBUGS” by Xinhai Li; “Data\ncloning: easy maximum likelihood estimation for complex models: an\napplication to zero-inflated responses of Internet ads” by Jingjing\nGuan; “On the ultrahigh dimensional linear discriminant analysis\nproblem with a diverging number of classes” by Hansheng Wang;\n\nKaleidoscope\n\n“Rethinking data analysis and data analysis tools” by John\nMaindonald; “Web scraping with R” by Nan Xiao; “An introduction to\nthe Julia language” by Changyou Zhang.\n\nIn addition, a series of 5-minute talks for promotion purposes and\nR-related jobs were given by Merck China, 360buy, China Citic Bank,\nCareerfocus, Springer, SupStat, Alipay, Amazon, eBay, Baidu, and Douban,\netc. Many companies have received a large number of job applications.\nAfter the lightning talks, the conference chair opened a clean R\nsession, ran sample(id, 20) and gave away 20 books in R and statistics\n(sponsored by publishers) to the lucky attendees.\nFigure 1: Learning R without thinking it makes one confused; thinking\nR without learning it makes one shallow — Chenshun Lin, the chair of\nthe lightning talk sessions, added R to a famous quote by Confucious and\nturned it to a hilarious pun.The two-day event was a great success and we got many positive feedback\nmessages from participants after the conference. We will further devote\nour future effort on:\norganizing more R meetings to meet the growing demand of R users in\nChina;\npromoting statistics and data analysis in the industry;\ninteracting with different fields, such as e-commerce, through more\nand advanced applications of R.\nThe conference summary and slides are freely available at\nhttp://cos.name/chinar/chinar-2013/ (in Chinese). We would like to\nthank the School of Statistics and the Center for Applied Statistics of\nRUC for their consistent support for the Chinese R Conference. We are\nalso grateful to Prof Hansheng Wang for his encouragement and generous\nhelp. We appreciate the tremendous help of all student volunteers from\nRUC and COS. We look forward to the next R conference in China and\nwarmly welcome more people to attend it. Inquiries and suggestions can\nbe sent to chinar-committee@cos.name.\nThe conference committee consists of Tao Gao (Chair), Yu Chen (Vice\nChair), Taiyun Wei, Sen Chen, Jianchong Su, Yanping Chen, Sizhe Liu,\nYihui Xie, Manqi Xie, Zhanhang Xiao, Yishuo Deng, Yixuan Qiu, Yan Chen,\nJing Leng.\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\nThomas W. Yee, author of VGAM, was the first foreign speaker,\nand attended the Shanghai conference in 2011.\n\n↩︎\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2013-1-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2013-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2013-06-01",
    "categories": [],
    "contents": "\n\nNew CRAN task views\nMetaAnalysis\n\nTopic: Meta-Analysis. Maintainer: Michael Dewey. Packages:\nCRTSize, HSROC, MADAM, MAMA, MAc, MAd, MetABEL,\nMetaDE, MetaPCA, MetaPath, MetaQC, RcmdrPlugin.MA,\nSAMURAI, SCMA, bamdit, bspmma, compute.es, copas,\nepiR, gap, gemtc, mada, meta\\(^*\\), metaLik, metaMA,\nmetacor, metafor\\(^*\\), metagen, metamisc, metatest,\nmvmeta, mvtmeta, psychometric, rmeta, selectMeta,\nskatMeta.\n\nSpatioTemporal\n\nTopic: Handling and Analyzing Spatio-Temporal Data. Maintainer:\nEdzer Pebesma. Packages: GeoLight, M3, RNetCDF,\nRandomFields\\(^*\\), RghcnV3, SpatioTemporal, Stem,\nadehabitatLT\\(^*\\), argosfilter, cshapes, diveMove,\ngoogleVis, gstat\\(^*\\), lgcp, lme4, mvtsplot, ncdf,\nncdf4, nlme, openair, pastecs, pbdNCDF4, plm, plotKML,\nraster\\(^*\\), rasterVis, rgl, solaR, sp\\(^*\\), spBayes,\nspTimer, spacetime\\(^*\\), spate, spatstat, sphet, splancs,\nsplm, stam, stpp\\(^*\\), stppResid, surveillance\\(^*\\),\ntrip\\(^*\\), tripEstimation, xts\\(^*\\).\n\n(* = core package)\nNew packages in CRAN task views\nBayesian\n\nPAWL, RSGHB, bspec, eco, stochvol.\n\nChemPhys\n\nastro, simecol, stepPlr.\n\nClinicalTrials\n\nCRM, epibasix.\n\nCluster\n\nEMCluster, FisherEM, GLDEX, MFDA, Rmpi, latentnet,\noptpart.\n\nDifferentialEquations\n\nPBSmodelling, primer.\n\nDistributions\n\nActuDistns\\(^*\\), CDVine, Delaporte, GLDEX, PhaseType,\nVineCopula, copBasic, lmom, retimes, rlecuyer.\n\nEconometrics\n\nLARF, RSGHB, partsm, survival.\n\nEnvironmetrics\n\nearth, flexmix, fso, ipred, maptree, mda, metacom,\nprimer, pvclust, quantreg, rioja, seas, surveillance,\nunmarked, untb.\n\nExperimentalDesign\n\nBatchExperiments, crossdes, displayHTS, gsbDesign, planor.\n\nFinance\n\nBurStMisc, ESG, FinTS, GUIDE, PIN, SharpeR,\nhighfrequency, nlme, parma, rmgarch, stochvol.\n\nGenetics\n\nhierfstat, qtlbim.\n\nGraphics\n\nRGtk2, ash, biclust, cba, diagram, igraph, onion,\nplaywith, scagnostics, seriation.\n\nHighPerformanceComputing\n\nbayesm, bigrf, doRNG, latentnet, mapReduce, mchof,\npbdDEMO, pbdNCDF4, permGPU, rredis, sprint, xgrid.\n\nMachineLearning\n\nRmalschains, bigrf, frbs, maptree.\n\nMedicalImaging\n\nbayesm, brainwaver, waveslim.\n\nMultivariate\n\nFAiR, MFDA, cwhmisc, fso.\n\nNaturalLanguageProcessing\n\nRcmdrPlugin.temis, SnowballC, qdap, tm.plugin.factiva.\n\nOfficialStatistics\n\nJoSAE, MatchIt, SamplingStrata, hbsae, lavaan,\nlavaan.survey, lpSolve, odfWeave, rsae, samplingVarEst,\ntabplot, treemap, x12GUI.\n\nOptimization\n\nadagio.\n\nPharmacokinetics\n\nPKPDmodels, deSolve, nlme.\n\nPhylogenetics\n\niteRates.\n\nPsychometrics\n\nFAiR\\(^*\\), MultiLCIRT, classify, fastICA, kst,\nlavaan.survey, mcIRT, pks.\n\nReproducibleResearch\n\ncacher, markdown, pander, rapport.\n\nRobust\n\nRobLoxBioC, coxrobust, lqmm, robustX, robustlmm,\nrrcovHD, rrcovNA.\n\nSocialSciences\n\nBMA, GPArotation, acepack, latentnet, lattice, lme4,\nmeta, mvnmle, perturb, rgl, vcd.\n\nSpatial\n\nDCluster\\(^*\\), micromap.\n\nSurvival\n\nBiograph, SmoothHazard, SvyNom, aBioMarVsuit, bscr,\nbwsurvival, currentSurvival, gems, ipdmeta, jackknifeKME,\nlbiassurv, plsRcox, randomForestSRC, survexp.fr, timeROC.\n\nTimeSeries\n\nFGN, MAR1, PVAClone, Quandl, TSTutorial, TimeProjection,\narfima, brainwaver, bspec, events, fpp, nets, partsm,\nperARMA, rdatamarket, rts, seas, stochvol, surveillance,\ntframe, tsbugs.\n\ngR\n\nBRugs, GeneNet, dclone, gRapHD, gRim, network, parcor.\n\n(* = core package)\n1 New contributed packages\nA3\n\nAccurate, Adaptable, and Accessible Error Metrics for Predictive\nModels. Author: Scott Fortmann-Roe.\n\nABCExtremes\n\nABC Extremes. Author: Rob Erhardt.\n\nABCp2\n\nApproximate Bayesian Computational model for estimating P2.\nAuthors: M. Catherine Duryea, Andrew D. Kern, Robert M. Cox, and\nRyan Calsbeek.\n\nALDqr\n\nAlgorithm Laplace density quantile regression. Authors: Luis Benites\nSanchez, Victor Lachos.\n\nALKr\n\nGenerate Age-Length Keys for fish populations. Authors: Jose\nFrancisco Loff, Alberto Murta, Laurence Kell.\n\nARAMIS\n\nA R Adaptive Multiple Importance Sampling. Authors: Luca Pozzi,\nAntonietta Mira.\n\nAnthropMMD\n\nA GUI for Mean Measures of Divergence. Author: Frederic Santos.\n\nArrayBin\n\nMy First Collection of Functions. Author: Ed Curry.\n\nBACprior\n\nSensitivity of the Bayesian Adjustment for Confounding (BAC)\nalgorithm to the choice of hyperparameter omega. Authors: Denis jf\nTalbot, Geneviève Lefebvre, Juli Atherton.\n\nBH\n\nThe Boost C++ Libraries. Authors: John W. Emerson, Michael J. Kane,\nDirk Eddelbuettel, JJ Allaire, and Romain Francois.\n\nBOG\n\nBacterium and virus analysis of Orthologous Groups (BOG) is a\npackage for identifying differentially regulated genes in the light\nof gene functions. Authors: Jincheol Park, Cenny Taslim, Shili Lin.\n\nBSquare\n\nBayesian Simultaneous Quantile Regression. Author: Luke Smith &\nBrian Reich.\n\nBaySIC\n\nBayesian Analysis of Significantly Mutated Genes in Cancer. Author:\nNicholas B. Larson.\n\nBayesBridge\n\nBridge Regression. Authors: Nicholas G. Polson, James G. Scott, and\nJesse Windle.\n\nBayesComm\n\nBayesian community ecology analysis. Author: Nick Golding.\n\nBayesVarSel\n\nBayesian Variable selection in Linear Models. Authors: Gonzalo\nGarcia-Donato and Anabel Forte.\n\nBcDiag\n\nDiagnostics plots for Bicluster Data. Authors: Aregay Mengsteab,\nMartin Otava, Tatsiana Khamiakova.\n\nBenfordTests\n\nStatistical Tests for Evaluating Conformity to Benford’s Law.\nAuthors: Dieter William Joenssen, with contributions from Thomas\nMuellerleile.\n\nBiDimRegression\n\nCalculates the bidimensional regression between two 2D\nconfigurations. Author: Claus-Christian Carbon.\n\nBlockMessage\n\nCreates strings that show a text message in 8 by 8 block letters.\nAuthors: Elliot Noma, Aliona Manvae.\n\nBurStMisc\n\nBurns Statistics miscellaneous. Author: Burns Statistics. In view:\nFinance.\n\nCAMAN\n\nFinite Mixture Models and meta-analysis tools — based on C.A.MAN.\nAuthors: Peter Schlattmann, Johannes Hoehne.\n\nCCAGFA\n\nBayesian canonical correlation analysis and group factor analysis.\nAuthors: Seppo Virtanen and Arto Klami.\n\nCDLasso\n\nCoordinate Descent Algorithms for Lasso Penalized L1, L2, and\nLogistic Regression. Authors: Edward Grant, Kenneth Lange, Tong Tong\nWu.\n\nCLAG\n\nAn unsupervised non hierarchical clustering algorithm handling\nbiological data. Authors: Linda Dib, Raphael Champeimont, Alessandra\nCarbone.\n\nCOBRA\n\nNonlinear Aggregation of Predictors. Author: Benjamin Guedj.\n\nCUMP\n\nAnalyze Multivariate Phenotypes by Combining Univariate results.\nAuthors: Xuan Liu and Qiong Yang.\n\nCaDENCE\n\nConditional Density Estimation Network Construction and Evaluation.\nAuthor: Alex J. Cannon.\n\nCfEstimateQuantiles\n\nEstimate quantiles using any order Cornish-Fisher expansion. Author:\nMaxim Yurchuk.\n\nCheckDigit\n\nCalculate and verify check digits. Author: Justin Brantley.\n\nCoinMinD\n\nSimultaneous Confidence Interval for Multinomial Proportion.\nAuthor: M. Subbiah.\n\nComp2ROC\n\nCompare two ROC curves that intersect. Authors: Ana C. Braga, with\ncontributions from Hugo Frade.\n\nConConPiWiFun\n\nAn implementation of continuous convex piecewise (linear) functions.\nAuthor: Robin Girard.\n\nCondReg\n\nCondition Number Regularized Covariance Estimation. Authors:\nSang-Yun Oh, Bala Rajaratnam, Joong-Ho Won.\n\nCountsEPPM\n\nMean and variance modeling of count data. Authors: David M Smith,\nMalcolm J Faddy.\n\nDMR\n\nDelete or Merge Regressors for linear model selection. Authors:\nAleksandra Maj, Agnieszka Prochenka, Piotr Pokarowski.\n\nDPw\n\nSemiparametric Bayesian procedure for selecting a subset containing\nthe weakest species with an acceptably high probability. Author:\nYumi Kondo.\n\nDTComPair\n\nComparison of Binary Diagnostic Tests in a Paired Study Design.\nAuthors: Christian Stock, Thomas Hielscher.\n\nDataCombine\n\nR tools for making it easier to combine and clean data sets. Author:\nChristopher Gandrud.\n\nDataFrameConstr\n\nConstrained data frames and homogenous list classes. Author: Jeffrey\nArnold.\n\nDelaporte\n\nStatistical functions for the Delaporte distribution. Author:\nAvraham Adler. In view:\nDistributions.\n\nDemerelate\n\nFunctions to calculate relatedness on diploid genetic data. Authors:\nPhilipp Kraemer and Gabriele Gerlach.\n\nDendSer\n\nDendrogram seriation: ordering for visualisation. Authors:\nCatherine B. Hurley and Denise Earle.\n\nDigiroo2\n\nAn application programming interface for generating null models of\nsocial contacts based on individuals’ space use. Authors: Ross\nDwyer, Emily Best and Anne Goldizen.\n\nDominance\n\nADI (average dominance index) and social network graphs with dual\ndirections. Authors: Knut Krueger, with contributions from Konstanze\nKrueger.\n\nEMCluster\n\nEM Algorithm for Model-Based Clustering of Finite Mixture Gaussian\nDistribution. Authors: Wei-Chen Chen [aut, cre], Ranjan Maitra\n[aut], Volodymyr Melnykov [aut]. In view:\nCluster.\n\nESG\n\nAsset projection. Authors: Jean-Charles Croix, Thierry Moudiki,\nFrédéric Planchet, Wassim Youssef. In view:\nFinance.\n\nEasyHTMLReport\n\nEasy to send HTML reports. Author: Yohei Sato.\n\nEasyUpliftTree\n\nEasy Uplift Tree Model. Authors: Yohei Sato, Issei Kurahashi.\n\nEpiModel\n\nMathematical Modeling of Infectious Disease. Author: Samuel Jenness\n[cre, aut].\n\nExactCIdiff\n\nInductive Confidence Intervals for the difference between two\nproportions. Authors: Guogen Shan, Weizhen Wang.\n\nExactNumCI\n\nExact Confidence Interval for binomial proportions. Authors: Deqiang\nSun, Hyun Jung Park.\n\nExactPath\n\nExact solution paths for regularized LASSO regressions with \\(L_1\\)\npenalty. Author: Kai Wang.\n\nExactSampling\n\nExactSampling: risk evaluation using exact resampling methods for\nthe k Nearest Neighbor algorithm. Author: Kai Li.\n\nExceedanceTools\n\nConfidence Regions for Exceedance Sets. Author: Joshua French.\n\nExpDes.pt\n\nPacote Experimental Designs (Portuguese). Authors: Eric Batista\nFerreira, Pórtya Piscitelli Cavalcanti, Denismar Alves Nogueira.\n\nFAOSTAT\n\nA complementary package to the FAOSTAT database and the Statistical\nYearbook of the Food and Agricultural Organization of the United\nNations. Author: Michael C. J. Kao.\n\nFBFsearch\n\nAlgorithm for searching the space of Gaussian directed acyclic\ngraphical models through moment fractional Bayes factors. Authors:\nDavide Altomare, Guido Consonni and Luca La Rocca.\n\nFI\n\nProvide functions for forest inventory calculations. Author:\nDavid V. Dias [aut, cre].\n\nFRAPO\n\nFinancial Risk Modelling and Portfolio Optimisation with R. Authors:\nBernhard Pfaff [aut, cre], Miguel Sousa Lobo [ctb] (SOCP),\nLieven Vandenberge [ctb] (SOCP), Stephen Boyd [ctb] (SOCP),\nHerve Lebret [ctb] (SOCP).\n\nFastPCS\n\nCompute the FastPCS outlyingness index. Author: Kaveh Vakili.\n\nFindIt\n\nFind Heterogeneous Treatment Effects. Authors: Marc Ratkovic, Kosuke\nImai.\n\nFluOMatic\n\nEstimation of background-subtracted fluorescence data. Authors:\nSebastien Joucla, Christophe Pouzat.\n\nFuzzyNumbers\n\nTools to deal with fuzzy numbers in R. Author: Marek Gagolewski.\n\nFuzzyStatProb\n\nFuzzy stationary probabilities from a sequence of observations of an\nunknown Markov chain. Author: Pablo J. Villacorta.\n\nFuzzyToolkitUoN\n\nType 1 Fuzzy Logic Toolkit. Authors: Craig Knott, Luke Hovell,\nNathan Karimian with supervision from Jon Garibaldi.\n\nGAIPE\n\nGraphical Extension with Accuracy in Parameter Estimation (GAIPE).\nAuthor: Tzu-Yao Lin.\n\nGESTr\n\nGene Expression State Transformation. Author: Ed Curry.\n\nGOsummaries\n\nWord cloud summaries of GO enrichment analysis. Author: Raivo Kolde.\n\nGRaF\n\nSpecies distribution modelling using latent Gaussian random fields.\nAuthor: Nick Golding.\n\nGSIF\n\nGlobal Soil Information Facilities. Authors: Tomislav Hengl [cre,\naut], Bas Kempen [aut], Gerard Heuvelink [aut], Brendan Malone\n[ctb], Hannes Reuter [ctb].\n\nGUIDE\n\nGUI for DErivatives in R. Author: S Subramanian. In view:\nFinance.\n\nGWG\n\nCalculation of probabilities for inadequate and excessive\ngestational weight gain. Author: Christina Riedel.\n\nGeneticTools\n\nCollection of Genetic Data Analysis Tools. Author: Daniel Fischer.\n\nGetR\n\nGetR: Calculate Guttman error trees in R. Authors: Johannes Beller,\nSoeren Kliem.\n\nGibbsACOV\n\nGibbs Sampler for One-Way Mixed-Effects ANOVA and ANCOVA Models.\nAuthors: Emily Goren and Quan Zhang.\n\nGoFKernel\n\nGoFKernel: Testing Goodness-of-fit with the Kernel Density\nEstimator. Author: Jose M. Pavia.\n\nGriegSmith\n\nUses Grieg-Smith method on 2 dimentional spatial data. Author: Brian\nMcGuire. In view:\nSpatial.\n\nGuardianR\n\nGuardian API Wrapper. Author: Marco Toledo Bastos & Cornelius\nPuschmann.\n\nHAP.ROR\n\nRecursive Organizer (ROR). Authors: Lue Ping Zhao and Xin Huang.\n\nHPOSim\n\nAnalysis similarities between HPO terms and phenotypic similarity\nbetween genes and between diseases. Authors: Yue Deng, Gang Wang,\nXiaocheng Huang and Tingting Ma.\n\nIBDhaploRtools\n\nFunctions for the Analysis of IBD Haplo output. Author: Marshall\nBrown.\n\nIBHM\n\nApproximation using the IBHM method. Author: Pawel Zawistowski.\n\nIM\n\nOrthogonal Moment Analysis. Authors: Bartek Rajwa, Murat Dundar,\nAllison Irvine, Tan Dang.\n\nIboot\n\nIboot: iterated bootstrap tests and confidence sets. Author: Nicola\nLunardon.\n\nInferenceSMR\n\nInference about the standardized mortality ratio when evaluating the\neffect of a screening program on survival. Authors: Denis Talbot,\nThierry Duchesne, Jacques Brisson, Nathalie Vandal.\n\nInteractiveIGraph\n\nInteractive network analysis and visualization. Author: Vygantas\nButkus.\n\nKappaGUI\n\nGUI for Cohen’s and Fleiss’ Kappa. Author: Frederic Santos.\n\nKmisc\n\nMiscellaneous functions intended to improve the R coding experience.\nAuthor: Kevin Ushey.\n\nLARF\n\nLocal Average Response Functions for Estimating Treatment Effects.\nAuthors: Weihua An and Xuefu Wang. In view:\nEconometrics.\n\nLDExplorer\n\nEfficient Whole-Genome LD Based Haplotpe Block Recognition. Authors:\nDaniel Taliun, Johann Gamper, Cristian Pattaro.\n\nLDOD\n\nFinding Locally D-optimal optimal designs for some nonlinear and\ngeneralized linear models. Authors: Ehsan Masoudi, Majid Sarmad and\nHooshang Talebi.\n\nLock5Data\n\nDatasets for “Statistics: UnLocking the Power of Data”. Author:\nRobin Lock.\n\nMALDIquantForeign\n\nImport/Export routines for MALDIquant. Author: Sebastian Gibb\n[aut, cre].\n\nMAR1\n\nMultivariate Autoregressive Modeling for Analysis of Community\nTime-Series Data. Author: Lindsay P. Scheef. In view:\nTimeSeries.\n\nMASSTIMATE\n\nBody Mass Estimation Equations for Vertebrates. Author: Nicolas E.\nCampione.\n\nMCPerm\n\nA Monte Carlo permutation method for multiple test correlation in\ncase/control association study. Authors: Lanying Zhang and Yongshuai\nJiang.\n\nMDPtoolbox\n\nMarkov Decision Processes toolbox. Authors: Iadine Chades, Guillaume\nChapron, Marie-Josee Cros, Frederick Garcia, Regis Sabbadin.\n\nMEET\n\nMotif Elements Estimation Toolkit. Authors: Joan Maynou and Erola\nPairo.\n\nMOJOV\n\nMojo Variants: Rare Variants analysis. Author: Ke-Hao Wu.\n\nMSwM\n\nFitting Markov Switching Models. Authors: Josep A.\nSanchez-Espigares, Alberto Lopez-Moreno.\n\nMVN\n\nMultivariate Normality Tests. Author: Selcuk Korkmaz.\n\nMapGAM\n\nMapping Smoothed Odds Ratios from Individual-Level Data. Authors:\nVeronica Vieira, Scott Bartell, and Robin Bliss.\n\nMedOr\n\nMedian Ordering Statistical R package. Authors: Adriano Polpo,\nCarlos Alberto de Braganca Pereira.\n\nMetaSKAT\n\nMeta analysis for SNP-set (Sequence) Kernel Association Test.\nAuthor: Seunggeun Lee.\n\nMiClip\n\nA Model-based Approach to Identify Binding Sites in CLIP-Seq Data.\nAuthor: Tao Wang.\n\nMiST\n\nMixed effects Score Test for continuous outcomes. Authors: Jianping\nSun, Yingye Zheng, and Li Hsu.\n\nMicroStrategyR\n\nAuthor: Rick Pechter.\n\nMixMAP\n\nImplements the MixMAP algorithm. Author: Gregory J. Matthews.\n\nMixtureInf\n\nInference for Finite Mixture Models. Authors: Jiahua Chen and\nPengfei Li.\n\nMonetDB.R\n\nConnect MonetDB to R. Authors: Hannes Muehleisen [aut, cre],\nThomas Lumley [ctb], Anthony Damico [ctb].\n\nMonoPoly\n\nFunctions to fit monotone polynomials. Authors: Berwin A. Turlach\n[aut, cre], Kevin Murray [ctb].\n\nMorpho\n\nCalculations and visualizations related to Geometric Morphometrics.\nAuthor: Stefan Schlager.\n\nMuFiCokriging\n\nMulti-Fidelity Cokriging models. Author: Loic Le Gratiet.\n\nMultinomialCI\n\nSimultaneous confidence intervals for multinomial proportions\naccording to the method by Sison and Glaz. Author: Pablo J.\nVillacorta.\n\nNHEMOtree\n\nNon-hierarchical evolutionary multi-objective tree learner to\nperform cost-sensitive classification. Author: Swaantje Casjens.\n\nNPCD\n\nNonparametric Methods for Cognitive Diagnosis. Authors: Yi Zheng and\nChia-Yi Chiu, with contributions from Jeffrey A. Douglas.\n\nNPCirc\n\nNonparametric Circular Methods. Authors: María Oliveira, Rosa M.\nCrujeiras and Alberto Rodríguez-Casal.\n\nNozzle.R1\n\nNozzle Reports. Author: Nils Gehlenborg.\n\nOPDOE\n\nOPtimal Design Of Experiments. Authors: Petr Simecek, Juergen Pilz\nMingui Wang, Albrecht Gebhardt.\n\nOmicKriging\n\nOmicKriging for Phenotypic Prediction. Authors: Hae Kyung Im,\nHeather E. Wheeler.\n\nOneTwoSamples\n\nDeal with one and two (normal) samples. Author: Ying-Ying Zhang\n(Robert).\n\nOpenMPController\n\nControl number of OpenMP threads dynamically. Author: Simon Guest.\n\nOptInterim\n\nOptimal Two and Three Stage Designs for Single-Arm and Two-Arm\nRandomized Controlled Trials with a Long-Term Binary Endpoint.\nAuthors: Bo Huang and Neal Thomas.\n\nOrdLogReg\n\nOrdinal Logic Regression. Author: Bethany Wolf.\n\nOutlierDC\n\nOutlier Detection using Quantile Regression for Censored Data.\nAuthors: Soo-Heang Eo and HyungJun Cho.\n\nPAGI\n\nIdentify the dysregulated KEGG pathways based on global influence\nfrom the internal effect of pathways and crosstalk between pathways.\nAuthors: Junwei Han, Yanjun Xu, Haixiu Yang, Chunquan Li and Xia Li.\n\nPBSmapping\n\nMapping Fisheries Data and Spatial Analysis Tools. Authors: Jon T.\nSchnute, Nicholas Boers, Rowan Haigh, Chris Grandin, Angus Johnson,\nPaul Wessel, Franklin Antonio. In view:\nSpatial.\n\nPCovR\n\nPrincipal Covariates Regression. Authors: Marlies Vervloet [aut,\ncre], Henk Kiers [aut], Eva Ceulemans [ctb].\n\nPIN\n\nEstimates the parameters of a trading-tree model for the computation\nof the probability of informed trading. Author: P. Zagaglia. In\nview: Finance.\n\nPROTOLIDAR\n\nPRocess TOol LIdar DAta in R. Author: Monica Fernanda Rinaldi.\n\nPReMiuM\n\nDirichlet Process Bayesian Clustering, Profile Regression. Authors:\nDavid I. Hastie, Silvia Liverani and Sylvia Richardson, with a\ncontribution by Lamiae Azizi.\n\nPResiduals\n\nProbability scale residuals and residual correlations. Authors:\nCharles Dupont, Chun Li, Bryan Shepherd.\n\nPST\n\nProbabilistic Suffix Trees. Author: Alexis Gabadinho.\n\nPamGeneMixed\n\nPreprocessing and Modeling Kinase Activity Profiles in PamChip Data.\nAuthors: Pushpike Thalikarathne, Ziv Shkedy, Dan Lin, Lieven\nClement, and Geert Verbeke.\n\nPlotRegionHighlighter\n\nCreates an envelope that surrounds a set of points plotted in a two\ndimensional space. Author: Elliot Noma.\n\nPracTools\n\nTools for Designing and Weighting Survey Samples. Authors: Richard\nValliant, Jill A. Dever, Frauke Kreuter.\n\nPropClust\n\nPropensity Clustering and Decomposition. Authors: John Michael O\nRanola, Kenneth Lange, Steve Horvath, Peter Langfelder.\n\nPropScrRand\n\nPropensity score methods for assigning treatment in randomized\ntrials. Author: Travis M. Loux.\n\nPurBayes\n\nBayesian Estimation of Tumor Purity and Clonality. Author:\nNicholas B. Larson.\n\nQuandl\n\nQuandl Data Connection. Authors: Raymond McTaggart, Gergely Daroczi.\nIn view: TimeSeries.\n\nRAFM\n\nAdmixture F-model. Author: Markku Karhunen.\n\nRAP\n\nReversal Association Pattern. Authors: U. Sangeetha, M. Subbiah with\nconsiderable contribution from M.R. Srinivasan.\n\nRCA\n\nRelational Class Analysis. Authors: Amir Goldberg, Gabor Csardi,\nJinjian Zhai.\n\nRCircos\n\nCircos 2D Track Plot. Author: Hongen Zhang.\n\nRClimMAWGEN\n\nR Climate Index Multi-site Auto-regressive Weather GENeretor: a\npackage to generate time series of climate indices from RMAWGEN\ngenerations. Authors: Emanuele Cordano, Annalisa Di Piazza.\n\nRDIDQ\n\nPerform Quality check on data. Author: Rahul Mehta.\n\nRDSTK\n\nAn R wrapper for the Data Science Toolkit API. Authors: Ryan Elmore\nand Andrew Heiss.\n\nREBayes\n\nEmpirical Bayes Estimation and Inference in R. Author: Roger\nKoenker.\n\nRFGLS\n\na family GWAS data-analysis tool that uses a generalized least\nsquares method to perform single-marker association analysis.\nAuthors: Xiang Li, Robert M. Kirkpatrick, and Saonli Basu.\n\nRMessenger\n\nIM Client for R. Authors: Wush Wu, Jack Moffitt and Patrick Powell.\n\nROSE\n\nROSE: Random Over-Sampling Examples. Authors: Nicola Lunardon,\nGiovanna Menardi, Nicola Torelli.\n\nRSA\n\nResponse surface analyses. Author: Felix\n\nRSAP\n\nSAP Netweaver RFC connector for R. Author: Piers Harding.\n\nRSGHB\n\nFunctions for Hierarchical Bayesian Estimation: A Flexible Approach.\nAuthors: Jeff Dumont, Jeff Keller, Chase Carpenter. In views:\nBayesian,\nEconometrics.\n\nRSiteCatalyst\n\nAdobe (Omniture) Reporting API. Author: Randy Zwitch & Jowanza\nJoseph.\n\nRadialPlotter\n\nStatistical age models analysis in optically stimulated luminescence\ndating. Author: Peng Jun.\n\nRbioRXN\n\nProcess Rhea and MetaCyc (BioCyc, EcoCyc) biochemical reaction data.\nAuthors: Byoungnam Min, Kyoung Heon Kim and In-Geol Choi.\n\nRcmdrPlugin.EZR\n\nR Commander Plug-in for the EZR (Easy R) Package. Author: Yoshinobu\nKanda.\n\nRcmdrPlugin.MA\n\nGraphical User Interface for Conducting Meta-Analyses in R. Author:\nAC Del Re. In view:\nMetaAnalysis.\n\nRcmdrPlugin.SM\n\nRcmdr Sport Management Plug-In. Author: Stéphane Champely.\n\nRcmdrPlugin.lfstat\n\nRcmdr Plug-In for low flow analysis. Authors: Daniel Koffler and\nGregor Laaha.\n\nRcmdrPlugin.plotByGroup\n\nRcmdr plots by group using lattice. Author: Poul Svante Eriksen with\ncontributions by Ege Rubak.\n\nRcmdrPlugin.seeg\n\nRcmdr Plugin for seeg. Author: Miguel F. Acevedo.\n\nRcmdrPlugin.temis\n\nGraphical user interface providing an integrated text mining\nsolution. Authors: Milan Bouchet-Valat [aut, cre], Gilles Bastin\n[aut]. In view:\nNaturalLanguageProcessing.\n\nRcppClassicExamples\n\nExamples using RcppClassic to interface R and C++. Authors: Dirk\nEddelbuettel and Romain Francois, based on code written during 2005\nand 2006 by Dominick Samperi.\n\nRcppProgress\n\nAn interruptible progress bar with OpenMP support for C++ in R\npackages. Author: Karl Forner.\n\nRcppRoll\n\nFast rolling functions through Rcpp and RcppArmadillo. Author: Kevin\nUshey.\n\nRcppXts\n\nInterface the xts API via Rcpp. Author: Dirk Eddelbuettel.\n\nReol\n\nR interface to the Encyclopedia of Life. Authors: Barb Banbury,\nBrian O’Meara.\n\nRgbp\n\nBayesian Hierarchical Modeling and Frequentist Method Check.\nAuthors: Joseph Kelly, Carl Morris, and Hyungsuk Tak.\n\nRgnuplot\n\nR interface for gnuplot. Authors: [ths], Nicolas Devillard\n[aut], Mauricio Galo [ctb], Patrick J. Bartlein [ctb], Oscar\nPerpiñán Lamigueiro [ctb], José Gama [aut, cre].\n\nRitc\n\nIsothermal Titration Calorimetry (ITC) Data Analysis. Author:\nYingyun Liu.\n\nSAMURAI\n\nSensitivity Analysis of a Meta-analysis with Unpublished but\nRegistered Analytical Investigations. Authors: Noory Y. Kim.\nAdvisors: Shrikant I. Bangdiwala, Gerald Gartlehner. In view:\nMetaAnalysis.\n\nSAVE\n\nImplementation of the SAVE approach for Computer Models. Authors:\nRui Paulo, Gonzalo Garcia-Donato, and Jesus Palomo, with\ncontributions from J. Berger, S. Bayarri and J. Sacks.\n\nSDBP\n\nCalculate the third-order accurate Unbiased P-values via Speedy\ndouble bootstrap method. Author: Aizhen Ren.\n\nSDD\n\nSerial Dependence Diagrams. Authors: Luca Bagnato, Lucio De\nCapitani, Angelo Mazza and Antonio Punzo.\n\nSEMID\n\nIdentifiability of linear structural equation models. Authors: Rina\nFoygel, Mathias Drton.\n\nSLHD\n\nMaximin-Distance (Sliced) Latin Hypercube Designs. Author: Shan Ba.\n\nSMCRM\n\nData Sets for Statistical Methods in Customer Relationship\nManagement by Kumar and Petersen (2012). Authors: Tobias Verbeke,\nbased on datasets provided on the book’s website.\n\nSMFI5\n\nR functions and data from Chapter 5 of “Statistical Methods for\nFinancial Engineering”. Author: Bruno Remillard.\n\nSMNCensReg\n\nFitting univariate censored regression model under the scale mixture\nof normal distributions. Authors: Aldo M. Garay, Victor Lachos and\nMonique Bettio Massuia.\n\nSNPMClust\n\nA bivariate Gaussian genotype clustering and calling algorithm for\nIllumina microarrays. Authors: Stephen W. Erickson, with\ncontributions from Joshua Callaway.\n\nSNPtools\n\nAccessing, subsetting and plotting mouse SNPs. Author: Daniel Gatti.\n\nSODC\n\nOptimal Discriminant Clustering (ODC) and Sparse Optimal\nDiscriminant Clustering (SODC). Author: Yanhong Wang.\n\nSOLOMON\n\nParentage analysis. Author: Mark Christie.\n\nSSDforR\n\nSSD for R to analyze single system data. Authors: Charles Auerbach,\nWendy Zeitlin Schudrich.\n\nSSN\n\nSpatial Modeling on Stream Networks. Authors: Jay Ver Hoef and Erin\nPeterson.\n\nSUE\n\nSubsampling method. Author: Jim Yi.\n\nSemiMarkov\n\nMulti-States Semi-Markov Models. Authors: Agnieszka Listwon,\nPhilippe Saint-Pierre.\n\nSequential\n\nExact Sequential Analysis for Poisson Data. Authors: Ivair Ramos\nSilva and Martin Kulldorff.\n\nSetMethods\n\nSetMethods: A Package Companion to “Set-Theoretic Methods for the\nSocial Sciences\"” Author: Mario Quaranta.\n\nSharpeR\n\nStatistical significance of Sharpe ratio. Author: Steven E. Pav. In\nview: Finance.\n\nSkillings.Mack\n\nThe Skillings-Mack test Statistic for block designs with missing\nobservations. Authors: Patchanok Srisuradetchai, John J. Borkowski.\n\nSmoothHazard\n\nFitting illness-death model for interval-censored data. Authors:\nCelia Touraine, Pierre Joly, Thomas A. Gerds. In view:\nSurvival.\n\nSnowballC\n\nSnowball stemmers based on the C libstemmer UTF-8 library. Author:\nMilan Bouchet-Valat [aut, cre]. In view:\nNaturalLanguageProcessing.\n\nSparseTSCGM\n\nSparse time series chain graphical models. Authors: Fentaw Abegaz\nand Ernst Wit.\n\nSphericalCubature\n\nNumerical integration over spheres and balls in n-dimensions;\nmultivariate polar coordinates. Authors: John P. Nolan.\n\nStVAR\n\nStudent’s t Vector Autoregression (StVAR). Author: Niraj Poudyal.\n\nStack\n\nStylized concatenation of data.frames or ffdfs. Author: Mike\nMalecki.\n\nStandardizeText\n\nStandardize Text. Author: David Nepomechie.\n\nStat2Data\n\nDatasets for Stat2. Author: Robin Lock.\n\nSvyNom\n\nNomograms for Right-Censored Outcomes from Survey Designs. Authors:\nMithat Gonen, Marinela Capanu. In view:\nSurvival.\n\nTDD\n\nTime-Domain Deconvolution of Seismometer Response. Author: Jake\nAnderson.\n\nTestScorer\n\nScores tests, shows and saves the results. Author: Manel Salamero.\n\nTimeMachine\n\nTime Machine. Authors: Gianluca Campanella [aut, cre], Marc\nChadeau-Hyam [aut], Maria De Iorio [ctb], Ajay Jasra [ctb].\n\nTimeProjection\n\nTime Projections. Author: Jeffrey Wong. In view:\nTimeSeries.\n\nTraMineRextras\n\nExtras for use with the TraMineR package. Authors: Gilbert\nRitschard, Reto Bürgin and Matthias Studer, with contributions from\nAlexis Gabadinho, Nicolas Müller and Patrick Rousset.\n\nTreeSimGM\n\nSimulating Phylogenetic Trees under a General Model. Authors: Oskar\nHagen, Tanja Stadler.\n\nUWHAM\n\nUnbinned weighted histogram analysis method (UWHAM). Authors:\nZhiqiang Tan and Emilio Gallicchio.\n\nVGAMdata\n\nData supporting the VGAM package. Author: Thomas W. Yee.\n\nVisuClust\n\nAuthors: Michael Sieger and Georg Ohmayer.\n\nWARN\n\nWeaning Age Reconstruction with Nitrogen isotope analysis. Author:\nTakumi Tsutaya.\n\nWebDevelopR\n\nWebsite development package for R. Authors: Evan Ray, Peter Krafft,\nJohn Staudenmayer.\n\nWeightedCluster\n\nClustering of Weighted Data. Author: Matthias Studer.\n\nWordPools\n\nClassical word pools used in studies of learning and memory. Author:\nMichael Friendly.\n\nXiMpLe\n\nA simple XML tree parser and generator. Author: m.eik michalke.\n\nYplantQMC\n\nPlant architectural analysis with Yplant and QuasiMC. Authors: Remko\nDuursma. QuasiMC by Mik Cieslak. Uses code by Robert Pearcy (Yplant)\nand Belinda Medlyn (MAESTRA).\n\nYuGene\n\nYuGene for comparing gene expression across platforms. Authors: Leo\nMcHugh, Kim-Anh Le Cao.\n\nZeBook\n\nZeBook Working with dynamic models for agriculture and environment.\nAuthors: Francois Brun, David Makowski, Daniel Wallach, James W.\nJones.\n\naBioMarVsuit\n\nA Biomarker Validation Suit for predicting Survival using gene\nsignature. Authors: Pushpike Thalikarathne and Ziv Shkedy. In view:\nSurvival.\n\naCRM\n\nConvenience functions for analytical Customer Relationship\nManagement. Authors: Dirk Van den Poel, Michel Ballings, Andrey\nVolkov, Jeroen D’haen, Michiel Vanherwegen.\n\nabctools\n\nTools for ABC analyses. Authors: Matt Nunes and Dennis Prangle.\n\nagrmt\n\nCalculate agreement. Author: Didier Ruedin.\n\nakmeans\n\nAdaptive Kmeans algorithm based on threshold. Author: Jungsuk Kwac.\n\nalr4\n\nData to accompany “Applied Linear Regression” 4rd edition. Author:\nSanford Weisberg.\n\naods3\n\nAnalysis of Overdispersed Data using S3 methods. Authors: Matthieu\nLesnoff and Renaud Lancelot.\n\narfima\n\nFractional ARIMA Time Series Modeling. Authors: Justin Q. Veenstra,\nA.I. McLeod. In view:\nTimeSeries.\n\nargparse\n\nCommand line optional and positional argument parser. Author: Trevor\nL Davis. Ports examples from the argparse Python module by the\nPython Software Foundation. Ports examples from the getopt package\nby Allen Day.\n\nastro\n\nAstronomy Functions, Tools and Routines. Author: Lee Kelvin. In\nview: ChemPhys.\n\naudiolyzR\n\nGive your data a listen. Authors: Eric Stone, Jesse Garrison.\n\nbPeaks\n\nA simple and intuitive approach for detection of basic peaks\n(bPeaks) from ChIP-seq data. Authors: Jawad MERHEJ and Gaelle\nLELANDAIS.\n\nbagRboostR\n\nEnsemble bagging and boosting classifiers. Author: Shannon Rush.\n\nbayess\n\nBayesian Essentials with R. Authors: Christian P. Robert, Universite\nParis Dauphine, and Jean-Michel Marin, Universite Montpellier 2.\n\nbbo\n\nBiogeography-Based Optimization. Authors: Sarvesh Nikumbh (BBO\noriginally invented by Prof. Dan Simon, Cleveland State University,\nOhio).\n\nbgeva\n\nBinary Generalized Extreme Value Additive Models. Authors: Raffaella\nCalabrese, Giampiero Marra and Silvia Anlgela Osmetti.\n\nbigRR\n\nGeneralized Ridge Regression (with special advantage for \\(p \\gg n\\)\ncases). Authors: Xia Shen, Moudud Alam and Lars Ronnegard.\n\nbigrf\n\nBig Random Forests: Classification and Regression Forests for Large\nData Sets. Authors: Aloysius Lim, Leo Breiman, Adele Cutler. In\nviews:\nHighPerformanceComputing,\nMachineLearning.\n\nbiom\n\nInterface (beta) for the BIOM file format. Authors: Paul J. McMurdie\nand the biom-format team.\n\nbmrm\n\nBundle Methods for Regularized Risk Minimization Package. Author:\nJulien Prados.\n\nbnpmr\n\nBayesian monotonic nonparametric regression. Author: Bjoern\nBornkamp.\n\nboilerpipeR\n\nInterface to the boilerpipe Java library by Christian Kohlschutter\n(http://code.google.com/p/boilerpipe/). Author: Mario Annau [aut,\ncre].\n\nbride\n\nBrier score decomposition of probabilistic forecasts for binary\nevents. Author: Stefan Siegert.\n\nbrnn\n\nBayesian regularization for feed-forward neural networks. Authors:\nPaulino Perez Rodriguez, Daniel Gianola.\n\nbscr\n\nBayesian parametric and semi-parametric analyses for semi-competing\nrisks data. Authors: Kyu Ha Lee, Sebastien Haneuse, Deborah Schrag,\nand Francesca Dominici. In view:\nSurvival.\n\nc060\n\nAdditional variable selection, model validation and parameter tuning\nfunctions for glmnet models. Authors: Martin Sill, Thomas Hielscher,\nManuela Zucknick, Natalia Becker.\n\ncape\n\nCombined analysis of pleiotropy and epistasis. Authors: Anna L.\nTyler, Wei Lu, Justin J. Hendrick, Vivek M. Philip, and Greg W.\nCarter.\n\ncatenary\n\nFits a catenary to given points. Authors: Jonathan Tuke, Matthew\nRoughan.\n\ncausalsens\n\nSelection Bias Approach to Sensitivity Analysis for Causal Effects.\nAuthor: Matthew Blackwell.\n\ncdb\n\nReading and Writing Constant DataBases. Author: Emilio Torres\nManzanera [aut, cre].\n\ncec2013\n\nBenchmark functions for the Special Session and Competition on\nReal-Parameter Single Objective Optimization at CEC-2013. Authors:\nMauricio Zambrano-Bigiarini [aut, cre], Yasser Gonzalez Fernandez\n[aut].\n\ncelestial\n\nCollection of common astronomical conversion routines. Author: Aaron\nRobotham.\n\ncgAUC\n\nCalculate AUC-type measure when gold standard is continuous and the\ncorresponding optimal linear combination of variables with respect\nto it. Authors: Yuan-chin I. Chang, Yu-chia Chang, and Ling-wan\nChen.\n\nchebpol\n\nMultivariate Chebyshev interpolation. Author: Simen Gaure.\n\nchillR\n\nStatistical methods for phenology analysis in temperate fruit trees.\nAuthor: Eike Luedeling.\n\ncitccmst\n\nCIT Colon Cancer Molecular SubTypes Prediction. Author: Laetitia\nMarisa.\n\ncladoRcpp\n\nC++ implementations of phylogenetic calculations. Author:\nNicholas J. Matzke [aut, cre, cph].\n\ncldr\n\nLanguage Identifier based on CLD library. Authors: The Chromium\nAuthors, Mike McCandless, Matt Sanford, Aykut Firat.\n\nclinUtiDNA\n\nClinical Utility of DNA Testing. Author: Thuy Trang Nguyen.\n\ncocor\n\nComparing correlations. Author: Birk Diedenhofen.\n\ncoefficientalpha\n\nRobust Cronbach’s alpha with missing and non-normal data. Authors:\nZhiyong Zhang and Ke-Hai Yuan.\n\ncolorfulVennPlot\n\nPlot and add custom coloring to Venn diagrams for 2-dimensional,\n3-dimensional and 4-dimensional data. Authors: Elliot Noma, Aliona\nManvae.\n\ncompositionsGUI\n\nGraphical User Environment for Compositional Data Analysis. Authors:\nJiri Eichler, Karel Hron, Raimon Tolosana-Delgado, Gerald van den\nBoogaart, Matthias Templ, Peter Filzmoser.\n\nconting\n\nBayesian analysis of contingency tables. Author: Antony M.\nOverstall.\n\ncorHMM\n\nAnalysis of binary character evolution. Authors: Jeremy M. Beaulieu,\nJeffrey C. Oliver, Brian O’Meara.\n\ncovTest\n\nComputes covariance test for adaptive linear modelling. Authors:\nRichard Lockhart, Jon Taylor, Ryan Tibshirani, Rob Tibshirani.\n\ncurrentSurvival\n\nEstimation of CCI and CLFS Functions. Authors: Eva Janousova, Tomas\nPavlik, Jiri Mayer, Ladislav Dusek. In view:\nSurvival.\n\ncvAUC\n\nCross-Validated Area Under the ROC Curve Confidence Intervals.\nAuthors: Erin LeDell, Maya Petersen, Mark van der Laan.\n\ncvxclustr\n\nSplitting methods for convex clustering. Author: Eric C. Chi.\n\ncwm\n\nCluster Weighted Models by EM algorithm. Authors: Giorgio A.\nSpedicato, Simona C. Minotti.\n\ndatacheck\n\nTools for checking data consistency. Author: Reinhard Simon.\n\ndataone\n\nDataONE R Client. Authors: Matthew Jones, Rob Nahf.\n\ndataonelibs\n\nDataONE R Client Libraries. Authors: Matthew Jones, Rob Nahf.\n\ndatautils\n\nSupport functions for packages VBmix, semisupKernelPCA, and\npatchPlot. Author: Pierrick Bruneau.\n\ndave\n\nFunctions for “Data Analysis in Vegetation Ecology”. Author: Otto\nWildi.\n\ndbEmpLikeNorm\n\nTest for joint assessment of normality. Authors: Lori A. Shepherd,\nWan-Min Tsai, Albert Vexler, Jeffrey C. Miecznikowski.\n\ndclong.spt\n\nSequential Permutation Test. Author: Chuanlong (Ben) Du.\n\nddalpha\n\nDDalpha-Classifier. Authors: Oleksii Pokotylo, Pavlo Mozharovskyi.\n\ndemi\n\nDifferential Expression from Multiple Indicators. Authors: Sten\nIlmjarv and Hendrik Luuk.\n\ndendroextras\n\nExtra functions to cut, label and colour dendrogram clusters.\nAuthor: Gregory Jefferis.\n\ndesignGG\n\nComputational tool for designing genetical genomics experiments.\nAuthors: Yang Li, Morris Swertz, Gonzalo Vera, Rainer Breitling,\nRitsert Jansen.\n\ndf2json\n\nConvert a dataframe to JSON. Author: Nacho Caballero.\n\ndiffdepprop\n\nCalculates Confidence Intervals for two Dependent Proportions.\nAuthors: Daniela Wenzel, Antonia Zapf.\n\ndiscreteRV\n\nAuthor: Andreas Buja.\n\ndiscrimARTs\n\nDiscrimination of Alternative Reproductive Tactics (ARTs).\nAuthors: J. Mark Rowland, Clifford Qualls, and Christian Gunning.\n\ndisplayHTS\n\nAuthor: Xiaohua Douglas Zhang & Zhaozhi Zhang. In view:\nExperimentalDesign.\n\ndistory\n\nDistance Between Phylogenetic Histories. Authors: John Chakerian and\nSusan Holmes. In view:\nPhylogenetics.\n\ndistrRmetrics\n\nPackage distr classes for distributions from Rmetrics. Authors:\nNataliya Horbenko, Matthias Kohl, Daria Pupashenko, Myhailo\nPupashenko, Peter Ruckdeschel.\n\ndriftsel\n\nDistinguishing drift and natural selection as causes of phenotypic\ndifferentiation. Author: Markku Karhunen & Otso Ovaskainen.\n\ndvn\n\nAccess to The Dataverse Network API. Author: Thomas J. Leeper.\n\neHOF\n\nExtended and enhanced Hierarchical Logistic Regression models (so\ncalled Huisman-Olff-Fresco models). Authors: Florian Jansen, Jari\nOksanen.\n\nearlywarnings\n\nEarly Warning Signals Toolbox for Detecting Critical Transitions in\nTimeseries. Authors: Vasilis Dakos, with contributions from S.R.\nCarpenter, T. Cline, L. Lahti.\n\neasystab\n\nClustering Perturbation Stability Analysis. Authors: Hoyt Koepke,\nZongjun Hu, Bertrand Clarke.\n\necosim\n\nToolbox for Aquatic Ecosystem Modeling. Author: Peter Reichert.\n\necp\n\nNonparametric Multiple Change Point Analysis of Multivariate Data.\nAuthors: Nicholas A. James and David S. Matteson.\n\neive\n\nAn algorithm for reducing errors-in-variable bias in simple linear\nregression. Authors: Mehmet Hakan Satman, Erkin Diyarbakirlioglu.\n\nensembleMOS\n\nEnsemble Model Output Statistics. Authors: RA Yuen, Tilmann\nGneiting, Thordis Thorarinsdottir, Chris Fraley.\n\nepibase\n\nbasic tools for the analysis of disease outbreaks. Authors: The\nHackout team (In alphabetic order: David Aanensen, Marc Baguelin,\nPaul Birrell, Simon Cauchemez, Anton Camacho, Caroline Colijn, Anne\nCori, Xavier Didelot, Ken Eames, Christophe Fraser, Simon Frost,\nNiel Hens, Joseph Hugues, Thibaut Jombart, Lulla Opatowski, Oliver\nRatmann, Samuel Soubeyrand, Marc Suchard, Jacco Wallinga, Rolf\nYpma).\n\nergm.count\n\nFit, Simulate and Diagnose Exponential-Family Models for Networks\nwith Count Edges. Authors: Pavel N. Krivitsky [aut, cre], Mark S.\nHandcock [ctb], David R. Hunter [ctb].\n\nergmharris\n\nLocal Health Department network data set. Author: Jenine K. Harris.\n\neventstudies\n\nEvent study and extreme event analysis. Authors: Ajay Shah, Vimal\nBalasubramaniam, Vikram Bahure.\n\nexpoTree\n\nCalculate density dependent likelihood of a phylogenetic tree.\nAuthors: Gabriel E Leventhal, partly adapted from MATLAB code by\nAwad H. Al-Mohy and using the routines DLNAC1 and DLARPC by Sheung\nHun Cheng, and DLAPST from ScaLAPACK.\n\nexsic\n\nConvenience functions for botanist to create exsiccatae indices.\nAuthors: Reinhard Simon, David M. Spooner.\n\nfail\n\nFile Abstraction Interface Layer (FAIL) mimicking a key-value store.\nAuthor: Michel Lang.\n\nfarsi\n\nTranslate integers into persian. Author: Sadegh Rasoulinejad.\n\nfastclime\n\nA fast solver for constrained l1 minimization approach to sparse\nprecision matrix estimation. Authors: Haotian Pang, Han Liu and\nRobert Vanderbei.\n\nfbRanks\n\nAssociation Football (Soccer) Ranking via Poisson Regression.\nAuthor: Eli Holmes.\n\nfftwtools\n\nAuthor: Karim Rahim.\n\nfit.models\n\nAuthor: Kjell Konis.\n\ngIPFrm\n\nGeneralized Iterative Proportional Fitting for Relational Models.\nAuthors: Anna Klimova, Tamas Rudas.\n\ngains\n\nGains Table Package. Author: Craig A. Rolling.\n\ngamlr\n\nGamma Lasso Regression. Author: Matt Taddy.\n\ngaoptim\n\nGenetic Algorithm optimization for real-based and permutation-based\nproblems. Author: Fernando Tenorio.\n\ngazetools\n\nGaze Tools. Author: Ryan M. Hope.\n\ngcookbook\n\nData for “R Graphics Cookbook”. Author: Winston Chang.\n\ngeigen\n\nCalculate generalized eigenvalues of a matrix pair. Author: Berend\nHasselman.\n\ngems\n\nGeneralized multistate simulation model. Authors: Luisa Salazar\nVizcaya, Nello Blaser, Thomas Gsponer. In view:\nSurvival.\n\ngenMOSS\n\nAn implementation of the MOSS algorithm for the analysis of GWAS\ndata. Authors: Matthew Friedlander and Laurent Briollais.\n\ngensemble\n\nGeneralized ensemble methods. Authors: Peter Werner, Eugene\nDubossarsky.\n\ngeoscale\n\nGeological timescale plot. Author: Mark A. Bell.\n\ngeospacom\n\nHelper package to facilitate the generation of distance matrices\nused in the package spacom. Authors: Davide Morselli [aut],\nMathieu Cossuta [aut, cre], Till Junge [aut], Sandra Penic\n[aut], Guy Elcheroth [ctb], Stephanie Glaeser [ctb].\n\nggdendro\n\nTools for extracting dendrogram and tree diagram plot data for use\nwith ggplot. Authors: Andrie de Vries, Brian Ripley.\n\nggthemes\n\nExtra themes, scales and geoms for ggplot. Author: Jeffrey B.\nArnold.\n\nglassomix\n\nHigh dimensional Sparse Gaussian Graphical Mixture Model. Authors:\nAnani Lotsi and Ernst Wit.\n\ngplm\n\nGeneralized partial linear models (GPLM). Author: Marlene Mueller.\n\ngrnn\n\nGeneral regression neural network. Author: Pierre-Olivier Chasset.\n\ngsg\n\nCalculation of selection coefficients. Authors: Michael Morrissey,\nKrzysztof Sakrejda.\n\ngte\n\nGeneralized Turnbull’s estimator. Authors: Mohammad Hossein Dehghan,\nThierry Duchesne and Sophie Baillargeon.\n\nhSDM\n\nHierarchical Bayesian species distribution models. Authors: Ghislain\nVieilledent, Andrew M. Latimer, Alan E. Gelfand, Cory Merow, Adam M.\nWilson, Frederic Mortier and John A. Silander Jr.\n\nhashFunction\n\nA collection of non-cryptographic hash functions. Author: Xiaowei\nZhan.\n\nhcc\n\nHidden correlation check. Authors: Yun Shi and A. I. McLeod.\n\nheatex\n\nHeat exchange calculations during physical activity. Author: Kerry\nAtkins.\n\nhet.test\n\nWhite’s Test for Heteroskedasticity. Author: Sebastian Andersson.\n\nhht\n\nThe Hilbert-Huang Transform: Tools and Methods. Author: Daniel\nBowman [aut, cre].\n\nhighfrequency\n\nAuthors: Jonathan Cornelissen, Kris Boudt, Scott Payseur. In view:\nFinance.\n\nhighriskzone\n\nDetermining and evaluating high-risk zones. Authors: Heidi Seibold,\nMonia Mahling.\n\nhint\n\nTools for hypothesis testing based on Hypergeometric Intersection\ndistributions. Author: Alex T. Kalinka.\n\nhsicCCA\n\nCanonical Correlation Analysis based on Kernel Independence\nMeasures. Author: Billy Chang.\n\nhttpuv\n\nHTTP and WebSocket server library. Authors: RStudio, Inc.\n\niWeigReg\n\nImproved methods for causal inference and missing data problems.\nAuthors: Zhiqiang Tan and Heng Shu.\n\nibd\n\nIncomplete Block Designs. Author: Baidya Nath Mandal.\n\ninflection\n\nFinds the inflection point of a curve. Author: Demetris T.\nChristopoulos.\n\ninstallr\n\nFunctions for updating and installing a new version of R and other\nsoftware from R. Author: Tal Galili.\n\njaatha\n\nA Fast Parameter Estimation Method for Evolutionary Biology.\nAuthors: Lisha Mathew, Paul R. Staab and Dirk Metzler.\n\njackknifeKME\n\nJackknife estimates of Kaplan-Meier estimators or integrals.\nAuthors: Hasinur Rahaman Khan and Ewart Shaw. In view:\nSurvival.\n\nkdetrees\n\nNonparametric method for identifying discordant trees. Authors:\nGrady Weyenberg and Peter Huggins.\n\nkernelFactory\n\nKernel Factory: An ensemble of kernel Machines. Authors: Michel\nBallings, Dirk Van den Poel.\n\nkolmim\n\nAn improved evaluation of Kolmogorov’s distribution. Author: Luis\nCarvalho.\n\nlazyData\n\nA LazyData Facility. Author: Bill Venables.\n\nlbiassurv\n\nLength-biased correction to survival curve estimation. Authors:\nPierre-Jerome Bergeron and Vahid Partovi Nia. In view:\nSurvival.\n\nlfstat\n\nCalculates Low Flow Statistics for daily stream flow data. Author:\nDaniel Koffler.\n\nlisrelToR\n\nImport output from LISREL into R. Author: Sacha Epskamp.\n\nllama\n\nLeveraging Learning to Automatically Manage Algorithms. Authors:\nLars Kotthoff, contributions by Barry Hurley.\n\nlmeNB\n\nFit negative binomial mixed-effect regression model. Authors:\nZhao, Y. and Kondo, Y.\n\nlmeNBBayes\n\nSample from the posterior of the negative binomial mixed-effect\nregression model. The random effect is modeled with DP mixture of\nbeta distributions. Author: Yumi Kondo.\n\nlmerTest\n\nTests for random and fixed effects for linear mixed effect models\n(lmer objects of lme4 package). Authors: Alexandra Kuznetsova, Per\nBruun Brockhoff, Rune Haubo Bojesen Christensen.\n\nlocalgauss\n\nEstimating local Gaussian parameters. Author: Tore Selland Kleppe.\n\nlogistiX\n\nExact logistic regression including Firth correction. Authors: Georg\nHeinze and Tobias Ladner.\n\nlongCatEDA\n\nPlotting Categorical Longitudinal and Time-Series Data. Author:\nStephen Tueller.\n\nltmle\n\nLongitudinal Targeted Maximum Likelihood Estimation. Authors: Joshua\nSchwab, Maya Petersen, and Mark van der Laan, with contributions\nfrom Susan Gruber.\n\nmadsim\n\nA Flexible Microarray Data Simulation Model. Author: Doulaye\nDembele.\n\nmargie\n\nLog Marginal Likelihood of Gaussian Mixture. Authors: Elisa Loza\n[aut, cre], David Phillips [aut, com].\n\nmarked\n\nR Code for mark-recapture analysis. Authors: Jeff Laake, Devin\nJohnson, Paul Conn.\n\nmarmap\n\nImport, plot and analyze bathymetric and topographic data. Authors:\nEric Pante and Benoit Simon-Bouhet.\n\nmatie\n\nMeasuring Association and Testing Independence Efficiently. Authors:\nBen Murrell, Dan Murrell & Hugh Murrell.\n\nmcIRT\n\nIRT models for multiple choice items (mcIRT). Author: Manuel Reif.\nIn view:\nPsychometrics.\n\nmchof\n\nmulticore higher-order functions. Author: Ryan Grannell. In view:\nHighPerformanceComputing.\n\nmedSTC\n\nA max-margin supervised Sparse Topical Coding Model. Authors: Jun\nZhu, Aykut FIRAT.\n\nmelody\n\nStatistical Methods for the Quantitative Analysis of Song\nSpectrograms. Author: Dave Schruth.\n\nmetabolomics\n\nA collection of functions for analysing metabolomics data. Authors:\nAlysha M De Livera and Jairus B Bowne.\n\nmetacom\n\nAnalysis of the ‘elements of metacommunity structure’. Author: Tad\nDallas. In view:\nEnvironmetrics.\n\nmetagen\n\nGeneralised Inference in the Random Effects Meta Regression Model.\nAuthor: Thomas Friedrich. In view:\nMetaAnalysis.\n\nmeteogRam\n\nTools for plotting meteograms. Author: Bogdan Bochenek.\n\nmicromap\n\nLinked Micromap Plots. Authors: Quinn Payton and Tony Olsen with\ncontributions from Marc Weber, Michael McManus, and Tom Kincaid. In\nview: Spatial.\n\nmiscF\n\nMiscellaneous Functions. Author: Dai Feng.\n\nmistral\n\nMethods in Structural Reliability. Authors: Vincent Moutoussamy,\nNicolas Bousquet and Bertrand Iooss.\n\nmixture\n\nMixture Models for Clustering and Classification. Authors: Ryan P.\nBrowne and Paul D. McNicholas.\n\nmlearning\n\nMachine learning algorithms with unified interface and confusion\nmatrices. Author: Ph. Grosjean & K. Denis.\n\nmodiscloud\n\nR tools for processing Level 2 Cloud Mask products from MODIS.\nAuthors: Nicholas J. Matzke, Dept. of Integrative Biology, U.C.\nBerkeley.\n\nmove\n\nVisualizing and analyzing animal track data. Authors: Bart\nKranstauber, Marco Smolla.\n\nmsarc\n\nDraws diagrams (mis)representing the results of mass spec\nexperiments. Authors: Gord Brown, Hisham Mohammed.\n\nmsgl\n\nHigh dimensional multiclass classification using sparse group lasso.\nAuthors: Martin Vincent (Sparse group lasso), Conrad Sanderson\n(Armadillo), Jaakko Jarvi (Boost Tuple) and Jens Maurer (Boost\nRandom).\n\nmsgpackR\n\nA library to serialize or unserialize data in MessagePack format.\nAuthor: Mikiya Tanizawa.\n\nmsme\n\nFunctions and Datasets for “Methods of Statistical Model\nEstimation”. Authors: Joseph Hilbe and Andrew Robinson.\n\nmultilevelPSA\n\nMultilevel Propensity Score Analysis. Author: Jason Bryer.\n\nmvinfluence\n\nInfluence Measures and Diagnostic Plots for Multivariate Linear\nModels. Author: Michael Friendly.\n\nnCDunnett\n\nNoncentral Dunnett’s test distribution. Authors: Siomara Cristina\nBroch, Daniel Furtado Ferreira.\n\nnCal\n\nNonlinear Calibration. Authors: Youyi Fong, Krisztian Sebestyen.\n\nncbit\n\nRetrieve and build NBCI taxonomic data. Author: Jon Eastman.\n\nnephro\n\nBiostatistics utilities for nephrology. Author: Cristian Pattaro.\n\nnets\n\nNetwork Estimation for Time Series. Author: Christian Brownlees. In\nview: TimeSeries.\n\nnetworkTomography\n\nTools for network tomography. Authors: Alexander W Blocker, Paul\nKoullick, Edoardo Airoldi.\n\nneuroblastoma\n\nAuthor: Toby Dylan Hocking.\n\nnloptwrap\n\nWrapper for Package nloptr. Author: Hans W Borchers.\n\nnordklimdata1\n\nDataset for climate analysis with data from the Nordic region.\nAuthors: Heikki Tuomenvirta [aut], Achim Drebs [aut], Eirik\nForland [aut], Ole Einar Tveito [aut], Hans Alexandersson\n[aut], Ellen Vaarby Laursen [aut], Trausti Jonsson [aut],\nJose’ Gama [cre].\n\nnose\n\nAuthor: originally written by Subbiah M, packaged by Sumathi R with\nconsiderable contributions by Srinivasan M R.\n\nnoweb\n\nNoweb system for R. Author: Terry Therneau.\n\nnsprcomp\n\nNon-Negative Sparse PCA. Authors: Sigg Christian [aut, cre], R\nCore team [aut].\n\nnutshell.audioscrobbler\n\nAudioscrobbler data for “R in a Nutshell”. Author: Joseph Adler.\n\nnutshell.bbdb\n\nBaseball Database for “R in a Nutshell”. Author: Joseph Adler.\n\noptAUC\n\nOptimal Combinations of Diagnostic Tests Based on AUC. Authors: Xin\nHuang, Gengsheng Qin, Yixin Fang.\n\noutbreaker\n\nBayesian inference of outbreak dynamics based on epidemiological and\ngenetic information. Authors: Thibaut Jombart, Anne Cori, Xavier\nDidelot, Simon Cauchemez, Christophe Fraser, Neil Ferguson.\n\noverlap\n\nEstimates of coefficient of overlapping for animal activity\npatterns. Authors: Mike Meredith and Martin Ridout.\n\npackHV\n\nA few useful functions for statisticians. Author: Hugo Varet.\n\npairwise\n\nRasch Model Parameters by Pairwise Algorithm. Author: Joerg-Henrik\nHeine.\n\nparallelize.dynamic\n\nAutomate parallelization of function calls by means of dynamic code\nanalysis. Author: Stefan Boehringer.\n\nparma\n\nPortfolio Allocation and Risk Management Applications. Author:\nAlexios Ghalanos. In view:\nFinance.\n\npartDSA\n\nPartitioning using deletion, substitution, and addition moves.\nAuthors: Annette Molinaro, Karen Lostritto, Gregory Ryslik, Steve\nWeston. In view:\nHighPerformanceComputing.\n\npartialOR\n\nPartial Odds Ratio. Authors: Vaclav Fidler and Nico Nagelkerke.\n\npass\n\nPrediction and Stability Selection of Tuning Parameters. Authors:\nYixin Fang, Wei Sun, Junhui Wang.\n\npatchDVI\n\nPatch .dvi files. Author: Duncan Murdoch.\n\npatchPlot\n\nScatterplots of image patches. Author: Pierrick Bruneau.\n\npavo\n\nPerceptual analysis, visualization and organization of spectral\ncolor data in R. Authors: Rafael Maia [aut, cre], Chad Eliason\n[aut], Pierre-Paul Bitton [aut].\n\npbdDEMO\n\nProgramming with Big Data – Demonstrations of pbd Packages.\nAuthors: Drew Schmidt [aut, cre], Wei-Chen Chen [aut], George\nOstrouchov [aut], Pragneshkumar Patel [aut]. In view:\nHighPerformanceComputing.\n\npbdNCDF4\n\nProgramming with Big Data – Interface to Parallel Unidata NetCDF4\nFormat Data Files. Authors: Pragneshkumar Patel [aut, cre], George\nOstrouchov [aut], Wei-Chen Chen [aut], Drew Schmidt [aut],\nDavid Pierce [aut]. In views:\nHighPerformanceComputing,\nSpatioTemporal.\n\npca3d\n\nThree dimensional PCA plots. Author: January Weiner.\n\npcrsim\n\nSimulation of the forensic DNA process. Author: Oskar Hansson.\n\npearson7\n\nMaximum Likelihood Inference for the Pearson VII Distribution with\nShape Parameter 3/2. Author: John Hughes.\n\nperARMA\n\nPeriodic Time Series Analysis. Authors: Anna Dudek, Harry Hurd and\nWioletta Wojtowicz. In view:\nTimeSeries.\n\npermGPU\n\nUsing GPUs in Statistical Genomics. Authors: Ivo D. Shterev, Sin-Ho\nJung, Stephen L. George and Kouros Owzar. In view:\nHighPerformanceComputing.\n\npersiandictionary\n\nEnglish to Persian dictionary. Authors: Sadegh Rasoulinejad (R\npackage and database version of the dictionary) Manouchehr Aryanpour\n(for the original dictionary).\n\npfa\n\nEstimates False Discovery Proportion Under Arbitrary Covariance\nDependence. Authors: Jianqing Fan, Tracy Ke, Sydney Li and Lucy Xia.\n\nphenex\n\nAuxiliary functions for phenological data analysis. Authors: Lange,\nMaximilian and Doktor, Daniel.\n\nphtt\n\nPanel Data Analysis with Heterogeneous Time Trends. Authors: Oualid\nBada, Dominik Liebl.\n\nphylolm\n\nPhylogenetic Linear Regression. Authors: Lam Si Tung Ho, Cecile Ane.\n\npitchRx\n\nTools for Collecting and Visualizing Major League Baseball PITCHf/x\nData. Author: Carson Sievert.\n\nplfm\n\nProbabilistic latent feature analysis of two-way two-mode frequency\ndata. Author: Michel Meulders.\n\npmmlTransformations\n\nTransform input data from a PMML perspective. Author: Tridivesh\nJena.\n\npnn\n\nProbabilistic neural networks. Author: Pierre-Olivier Chasset.\n\npocrm\n\nDose-finding in drug combination Phase I trials using the partial\norder continual reassessment method (PO-CRM). Author: Nolan A.\nWages.\n\npolyCub\n\nCubature over Polygonal Domains. Authors: Sebastian Meyer [aut,\ncre, trl], Michael Hoehle [ths].\n\npom\n\nPatch Occupancy Models. Authors: Fawn Hornsby, Ryan Nielson, and\nTrent McDonald (www.west-inc.com).\n\npopgraph\n\nConstruct and manipulate population graphs. Author: Rodney J. Dyer.\n\npoppr\n\nGenetic analysis of populations with mixed reproduction. Authors:\nZhian N. Kamvar, Javier F. Tabima, Niklaus J. Grunwald.\n\nprobsvm\n\nClass probability estimation for Support Vector Machines. Authors:\nChong Zhang, Seung Jun Shin, Junhui Wang, Yichao Wu, Hao Helen\nZhang, and Yufeng Liu.\n\nproteomicdesign\n\nOptimization of a multi-stage proteomic study. Author: Irene SL\nZeng.\n\npsbcGroup\n\nPenalized semi-parametric Bayesian Cox (PSBC) models with shrinkage\nand grouping priors. Authors: Kyu Ha Lee, Sounak Chakraborty, (Tony)\nJianguo Sun.\n\npsd\n\nAdaptive, sine-multitaper power spectral density estimation.\nAuthors: Robert L. Parker and Andrew J. Barbour.\n\nqdap\n\nBridging the gap between qualitative data and quantitative analysis.\nAuthor: Tyler Rinker. In view:\nNaturalLanguageProcessing.\n\nquantregGrowth\n\nGrowth charts via regression quantiles. Author: Vito M. R. Muggeo.\n\nquestionr\n\nFunctions to make surveys processing easier. Authors: Julien\nBarnier, François Briatte.\n\nrCMA\n\nCMA-ES R-to-Java interface. Author: Wolfgang Konen.\n\nrCarto\n\nBuild maps with a full cartographic layout. Author: Timothee Giraud.\n\nrGammaGamma\n\nGamma convolutions for methylation array background correction.\nAuthor: Tim Triche, Jr.\n\nrHadoopClient\n\nhadoop client interface for R. Author: Yohei Sato.\n\nrPython\n\nAllows R to call Python. Author: Carlos J. Gil Bellosta.\n\nrandomGLM\n\nRandom General Linear Model Prediction. Authors: Lin Song, Peter\nLangfelder.\n\nrattle\n\nGraphical user interface for data mining in R. Authors: Graham\nWilliams [aut, cph, cre], Mark Vere Culp [cph], Ed Cox [ctb],\nAnthony Nolan [ctb], Denis White [cph], Daniele Medri [ctb],\nAkbar Waljee [ctb] (OOB AUC for Random Forest). In view:\nMachineLearning.\n\nrawFasta\n\nMemory efficient handling of FASTA sequence files, a pure R\nimplementation. Author: Sylvain Mareschal.\n\nrbefdata\n\nBEFdata R package. Authors: Claas-Thido Pfaff, Karin Nadrowski.\n\nreadMETEO\n\nWeather Data Download from www.meteogalicia.com. Author: Dominic\nRoye.\n\nrecluster\n\nSolving biasing produced by tied values in cluster analysis.\nAuthors: Leonardo Dapporto, Matteo Ramazzotti, Simone Fattorini,\nRoger Vila, Gerard Talavera, Roger H.L. Dennis.\n\nrefGenome\n\nManaging data from reference genomes (UCSC, ensembl). Author:\nWolfgang Kaisers.\n\nrelaxnet\n\nRelaxation of glmnet models (as in relaxed lasso, Meinshausen 2007).\nAuthors: Stephan Ritter, Alan Hubbard.\n\nrepmis\n\nA collection of miscellaneous tools for reproducible research\nwith R. Author: Christopher Gandrud.\n\nreports\n\nAssist in the workflow of writing academic articles and other\nreports. Author: Tyler Rinker.\n\nrestorepoint\n\nDebugging with restore points. Author: Sebastian Kranz.\n\nrexpokit\n\nR wrappers for EXPOKIT; other matrix functions. Authors: Nicholas J.\nMatzke [aut, cre, cph], Roger B. Sidje [aut, cph].\n\nrforensicbatwing\n\nBATWING for calculating forensic trace-suspect match probabilities.\nAuthors: Mikkel Meyer Andersen and Ian J. Wilson.\n\nringbuffer\n\nRing buffer (circular buffer) data structure. Author: Allen Day.\n\nrlme\n\nRandom Effects Nested Models. Authors: Yusuf Bilgic and Herb\nSusmann.\n\nrmgarch\n\nMultivariate GARCH models. Author: Alexios Ghalanos. In view:\nFinance.\n\nrmp\n\nRounded Mixture Package. Performs probability mass function\nestimation with Dirichlet process mixtures of rounded kernels.\nAuthors: C code by A. Canale and N. Lunardon, port and R code by A.\nCanale.\n\nrms.gof\n\nRoot-mean-square goodness-of-fit test for simple null hypothesis.\nAuthor: Shubhodeep Mukherji.\n\nrobustlmm\n\nRobust Linear Mixed Effects Models. Author: Manuel Koller. In view:\nRobust.\n\nroxyPackage\n\nUtilities to automate package builds. Author: m.eik michalke.\n\nroyston\n\nRoyston’s H Test: Multivariate Normality Test. Author: Selcuk\nKorkmaz.\n\nrspear\n\nCalculate SPEARpesticide in R\n(http://www.systemecology.eu/SPEAR/index.php). Author: Eduard\nSzoecs.\n\nrtop\n\nInterpolation of data with variable spatial support. Author: Jon\nOlav Skoien.\n\nsae\n\nSmall Area Estimation. Authors: Isabel Molina, Yolanda Marhuenda.\n\nsanon\n\nStratified Analysis with Nonparametric covariable adjustment.\nAuthor: Atsushi Kawaguchi.\n\nschoRsch\n\nTools for analyzing factorial experiments. Authors: Roland Pfister,\nMarkus Janczyk.\n\nscidb\n\nAn R interface to SciDB. Authors: Paradigm4, B. W. Lewis.\n\nseeg\n\nStatistics for Environmental Sciences, Engineering, and Geography.\nAuthor: Miguel F. Acevedo.\n\nsemPlot\n\nPath diagrams and visual analysis of various SEM packages’ output.\nAuthor: Sacha Epskamp.\n\nsemisupKernelPCA\n\nKernel PCA projection, and semi-supervised variant. Author: Pierrick\nBruneau.\n\nseqPERM\n\nGenerates a permutation matrix based upon a sequence. Author: Eric\nGolinko.\n\nseqminer\n\nEfficiently Read Sequencing Data (VCF format, METAL format) into R.\nAuthors: Xiaowei Zhan and Dajiang Liu, with contributions of\nJean-loup Gailly and Mark Adler (zlib), Julian Seward (bzip2) and\nHeng Li (tabix).\n\nsequences\n\nGeneric and biological sequences. Authors: Laurent Gatto and Robert\nStojnic.\n\nseverity\n\nMayo’s Post-data Severity Evaluation. Author: Nicole Mee-Hyaang\nJinn.\n\nsgof\n\nMultiple hypotheses testing. Authors: Irene Castro Conde and Jacobo\nde Una Alvarez.\n\nsgr\n\nSample Generation by Replacement. Author: Massimiliano Pastore &\nLuigi Lombardi.\n\nshiny\n\nWeb Application Framework for R. Authors: RStudio, Inc.\n\nshrink\n\nGlobal, Parameterwise, and Joint Shrinkage of Regression\nCoefficients. Authors: Daniela Dunkler, Georg Heinze.\n\nsidier\n\nSubstitution and Indel Distances to Infer Evolutionary\nRelationships. Author: A.J. Munoz-Pajares.\n\nskatMeta\n\nEfficient meta analysis for the SKAT test. Authors: Arend Voorman,\nJennifer Brody, Thomas Lumley. In view:\nMetaAnalysis.\n\nsltl\n\nTime Series Decomposition using Loess and Harmonic Regression.\nAuthors: Hyukjun Gweon and A.I. McLeod.\n\nsmdata\n\nData to accompany Smithson & Merkle, 2014. Authors: Ed Merkle and\nMichael Smithson.\n\nsmdc\n\nDocument Similarity. Author: Masaaki Takada.\n\nsmoothHR\n\nSmooth Hazard Ratio Curves taking a Reference Value. Authors: Artur\nAgostinho Araujo and Luis Meira-Machado.\n\nsnpEnrichment\n\nSNPs enrichment analysis. Authors: Mickael Canouil [aut, cre],\nLoic Yengo [ctb].\n\nsnpStatsWriter\n\nFlexible writing of snpStats objects to flat files. Author: Chris\nWallace.\n\nsoftImpute\n\nMatrix completion via iterative soft-thresholded SVD. Authors:\nTrevor Hastie and Rahul Mazumder.\n\nsource.gist\n\nRead R code from a GitHub Gist. Author: Mason Simon.\n\nspacejam\n\nSparse conditional graph estimation with joint additive models.\nAuthor: Arend Voorman.\n\nsparsediscrim\n\nSparse Discriminant Analysis. Author: John A. Ramey.\n\nspate\n\nSpatio-temporal modeling of large data using a spectral SPDE\napproach. Authors: Fabio Sigrist, Hans R. Kuensch, Werner A. Stahel.\nIn view:\nSpatioTemporal.\n\nspatial.tools\n\nR functions for working with spatial data. Author: Jonathan Asher\nGreenberg.\n\nspecificity\n\nSpecificity of personality trait-outcome associations. Authors: Kenn\nKonstabel, Rene Mottus.\n\nspeedRlibTF\n\nspeedR’s table filter library. Author: Ilhami Visne.\n\nsprsmdl\n\nSparse modeling toolkit. Author: Hiroshi Saito.\n\nsqlshare\n\nAPI for access to SQLShare database. Author: Andrew White.\n\nsqlutils\n\nUtilities for working with SQL files. Author: Jason Bryer.\n\nstacomirtools\n\nstacomi ODBC connection class. Author: Cedric Briand.\n\nstatnet.common\n\nCommon R Scripts and Utilities Used by the Statnet Project Software.\nAuthor: Pavel N. Krivitsky [aut, cre].\n\nstochvol\n\nEfficient Bayesian Inference for Stochastic Volatility (SV) Models.\nAuthor: Gregor Kastner. In views:\nBayesian,\nFinance,\nTimeSeries.\n\nstream\n\nInfrastructure for Data Stream Mining. Authors: Matthew Bolanos,\nJohn Forrest, Michael Hahsler.\n\nstreamR\n\nAccess to Twitter Streaming API via R. Author: Pablo Barbera.\n\nstringdist\n\nString distance functions for R. Author: Mark van der Loo.\n\nstructSSI\n\nMultiple Testing for Hypotheses with Hierarchical or Group\nStructure. Author: Kris Sankaran.\n\nstrvalidator\n\nInternal validation of forensic STR kits made easy with\nstrvalidator. Author: Oskar Hansson.\n\nsubtype\n\nCluster analysis to find molecular subtypes and their assessment.\nAuthors: Andrey Alexeyenko, Woojoo Lee and Yudi Pawitan.\n\nsuperbiclust\n\nGenerating Robust Biclusters from a Bicluster Set (Ensemble\nBiclustering). Author: Tatsiana Khamiakova.\n\nsupport.BWS\n\nBasic functions for supporting an implementation of best-worst\nscaling. Author: Hideo Aizaki.\n\nsurface\n\nFitting Hansen Models to Investigate Convergent Evolution. Author:\nTravis Ingram.\n\nsurvMisc\n\nMiscellaneous functions for survival data. Author: Chris Dardis.\n\nsurvexp.fr\n\nRelative survival, AER and SMR based on French death rates. Authors:\nJean-Philippe Jais and Hugo Varet. In view:\nSurvival.\n\nsurveydata\n\nTools to manipulate survey data. Author: Andrie de Vries.\n\nsvDialogstcltk\n\nSciViews GUI API — Dialog boxes using Tcl/Tk. Author: Philippe\nGrosjean.\n\ntagcloud\n\nTag Clouds. Author: January Weiner.\n\ntaxize\n\nTaxonomic information from around the web. Authors: Scott\nChamberlain [aut, cre], Eduard Szoecs [aut], Carl Boettiger\n[aut], Ignasi Bartomeus [aut].\n\ntergm\n\nFit, Simulate and Diagnose Models for Network Evoluation based on\nExponential-Family Random Graph Models. Authors: Pavel N. Krivitsky\n[aut, cre], Mark S. Handcock [aut, ths], David R. Hunter\n[ctb], Steven M. Goodreau [ctb, ths], Martina Morris [ctb,\nths], Nicole Bohme Carnegie [ctb], Carter T. Butts [ctb], Ayn\nLeslie-Cook [ctb].\n\nthreg\n\nThreshold Regression. Author: Tao Xiao.\n\ntimeit\n\nEasy profiling of R functions. Author: Kevin Ushey.\n\ntimeline\n\nTimelines for a Grammar of Graphics. Author: Jason Bryer.\n\ntipom\n\nAutomated measure-based classification for lithic tools. Authors:\nStefano Costa [aut, cre], Luca Bianconi [aut], Elisabetta\nStarnini [ctb].\n\ntm.plugin.webmining\n\nRetrieve structured, textual data from various web sources. Author:\nMario Annau [aut, cre].\n\ntrioGxE\n\nA data smoothing approach to explore and test gene-environment\ninteraction in case-parent trio data. Authors: Ji-Hyung Shin, Brad\nMcNeney, Jinko Graham.\n\ntrueskill\n\nImplementation the TrueSkill algorithm in R. Author: Brendan Houng.\n\ntsbugs\n\nCreate time series BUGS models. Author: Guy J. Abel. In view:\nTimeSeries.\n\ntspmeta\n\nInstance feature calculation and evolutionary instance generation\nfor the traveling salesman problem. Authors: Bernd Bischl, Jakob\nBossek, Olaf Mersmann.\n\ntth\n\nTeX to HTML/MathML Translators tth/ttm. Authors: Ian H. Hutchinson\n[aut] (author of tth/ttm C sources), Friedrich Leisch [aut, cre]\n(author of R wrappers to tth/ttm), Achim Zeileis [aut] (author of\nR wrappers to tth/ttm).\n\ntwostageTE\n\nTwo-Stage Threshold Estimation. Authors: Shawn Mankad, George\nMichailidis, Moulinath Banerjee.\n\nusl\n\nAnalyze system scalability with the Universal Scalability Law.\nAuthors: Neil J. Gunther [aut], Stefan Moeding [aut, cre].\n\nvisualize\n\nGraph Probability Distributions with User Supplied Parameters and\nStats. Author: James Balamuta.\n\nvitality\n\nvitality: Fitting routines for the Vitality family of mortality\nmodels. Authors: Gregor Passolt, James J. Anderson, Ting Li,\nDavid H. Salinger.\n\nwethepeople\n\nAn R client for interacting with the White House’s “We The People”\npetition API. Author: Yoni Ben-Meshulam.\n\nwitness\n\nFits eyewitness data using Clark’s (2003) WITNESS model. Author:\nDustin Fife.\n\nwpp2008\n\nWorld Population Prospects 2008. Authors: Hana Sevcikova, Patrick\nGerland.\n\nwpp2010\n\nWorld Population Prospects 2010. Authors: Hana Sevcikova, Patrick\nGerland.\n\nxkcd\n\nPlotting ggplot2 graphics in a XKCD style. Author: Emilio Torres\nManzanera.\n\nyhatr\n\nR binder for the Yhat API. Author: Greg Lamp.\n\nzooimage\n\nAnalysis of numerical zooplankton images. Authors: Ph. Grosjean, K.\nDenis & R. Francois.\n\n2 Other changes\nThe following packages were moved to the Archive: AGSDest, AMA,\nBADER, BAMD, BAYSTAR, BPHO, BootPR, CADStat, CAVIAR,\nCarbonEL, CompModSA, ExPD2D, GAMens, GDD, ImageMetrics,\nLDdiag, LN3GV, MAMSE, MISA, MMS, MSToolkit, McSpatial,\nMetabonomic, MethComp, MixMod, NADA, NMMAPSlite, NeMo,\nPHYLOGR, PSCN, PrecipStat, QTLNetworkR, R4dfp, RDF,\nRMediation, RTAQ, RandForestGUI, Rchemcpp, Rclusterpp,\nRcmdrPlugin.Export, RcmdrPlugin.FactoMineR, RcmdrPlugin.MAc,\nRcmdrPlugin.MAd, RcmdrPlugin.PT, RcmdrPlugin.TextMining,\nRcmdrPlugin.depthTools, RcmdrPlugin.pointG, RcmdrPlugin.sos,\nRcmdrPlugin.steepness, ReadImages, Rigroup, Rlof, RpgSQL,\nRsge, Sim.DiffProc, Sim.DiffProcGUI, Simile, SpectralGEM,\nStatFingerprints, TSpadi, TreePar, VBMA4hmm,\nWMBrukerParser, XLConnectJars, YourCast, anchors, aratio,\nares, assist, bayespack, betfairly, bise, biseVec,\nboolean, bujar, cMonkey, calibFit, canvas, caspar,\nccems, cems, clim.pact, cloudRmpi, cloudRmpiJars,\ncmprskContin, cond, csampling, cyclones, dataframe,\ndelftfews, delt, denpro, diff, digeR, dynGraph,\ndynamo, emu, emudata, epsi, esd4all, fairselect, fdim,\nfilterviewR, finebalance, fractal, gcolor, gearman,\ngenomatic, graphComp, hdf5, helpr, highlight, iDEMO,\niGenomicViewer, iid.test, integrativeME, kBestShortestPaths,\nlaser, lazy, lmeSplines, marg, maxLinear, mcpd,\nmedAdherence, mht, mixer, mmeta, mnspc, motmot, mpc,\nmprobit, mspath, nFDR, nlreg, nltm, nlts, npst,\nodesolve, paloma, pamctdp, parser, pcurve, pfda,\nphitest, phull, pmc, polydect, predbayescor, proptest,\nqqplotter, rPorta, rconifers, realized, replicationDemos,\nritis, rpartOrdinal, rqmcmb2, rreval, rv, rvmbinary,\ns3x, sampfling, sculpt3d, sentiment, simone, sound,\nspeedR, speedRlibTF, splinesurv, sspline, steepness,\nsudokuplus, surv2sample, tabplotGTK, taskPR, tsModel,\ntwo.stage.boot, unknownR, xlsReadWrite\nThe following packages were resurrected from the Archive: ArDec,\nBhat, Biograph, CONOR, DCluster, EMT, ForImp,\nGWAtoolbox, MFDA, NMF, PairedData, SpatialEpi, bdoc,\nbrainwaver, bspec, bwsurvival, covRobust, crawl,\ncrossdes, cwhmisc, cyphid, formula.tools, fptdApprox,\nfso, hsmm, iteRates, labeltodendro, maticce, networksis,\nnricens, onemap, operator.tools, optpart, orderbook,\npartitionMap, pass, seas, snowfall, support.BWS,\nsurveillance, tipom, trueskill, truncgof\nThe following packages had to be removed: RExcelInstaller,\nRthroughExcelWorkbooksInstaller, SWordInstaller, auteur,\nrcom, wvioplot\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2013-1-editorial/",
    "title": "Editorial",
    "description": "The \"Editorial\" article from the 2013-1 issue.",
    "author": [
      {
        "name": "Hadley Wickham",
        "url": {}
      }
    ],
    "date": "2013-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2013-1-r-changes/",
    "title": "Changes in R",
    "description": "The 'Changes in R' article from the 2013-1 issue.",
    "author": [
      {
        "name": "The R Core Team",
        "url": {}
      }
    ],
    "date": "2013-06-01",
    "categories": [],
    "contents": "\n\nCHANGES IN R 3.0.1\n\nNEW FEATURES\nchooseCRANmirror() and chooseBioCmirror() gain an ind argument\n(like setRepositories()).\nmcparallel has a new argument mc.interactive which can modify\nthe interactive flag in the child process. The new default is\nFALSE which makes child processes non-interactive by default (this\nprevents lock-ups due to children waiting for interactive input).\nscan() now warns when end-of-file occurs within a quoted string.\ncount.fields() is now consistent with scan() in its handling of\nnewlines in quoted strings. Instead of triggering an error, this\nresults in the current line receiving NA as the field count, with\nthe next line getting the total count of the two lines.\nThe default method of image() will plot axes of the class of\nxlim and ylim (and hence of x and y if there is a suitable\nrange() method). Based on a suggestion of Michael Sumner.\nload() now has a verbose argument for debugging support, to\nprint the names of objects just before loading them.\nWhen loading a serialized object encounters a reference to a\nnamespace which cannot be loaded, this is replaced by a reference to\nthe global environment, with a warning.\npairs() gains a line.main option for title placement.\nThe remaining instances in which serialization to a raw vector was\nlimited to 2GB have been unlimited on a 64-bit platform, and in most\ncases serialization to a vector of more than 1GB will be\nsubstantially faster.\n\n\nUTILITIES\nR CMD config now make use of personal Makevars files under\n~/.R and a site file Makevars.site, in the same way as\nR CMD SHLIB and R CMD INSTALL. This makes the utility more\nuseful in package configure scripts.\nOn Windows finding the personal files may require the environment\nvariable HOME set.\nThe old behaviour can be obtained with the new options\n–no-user-files and –no-site-files.\n\n\nPACKAGE INSTALLATION\nAlternatives to the site and user customization files\nMakevars.site and ~/.R/Makevars can be specified via the\nenvironment variables R_MAKEVARS_SITE and R_MAKEVARS_USER\nrespectively. These can be used to suppress the use of the default\nfiles by setting an empty value (where possible) or a non-existent\npath.\n\n\nBUG FIXES\nsys.source() did not report error locations when\nkeep.source = TRUE.\nas.POSIXct.numeric was coercing origin using the tz argument\nand not \"GMT\" as documented (PR#14973).\nstr(d) no longer gives an error when names(d) contain illegal\nmultibyte strings (PR#15247).\nProfiling of built-in functions with line.profiling= TRUE did not\nrecord the line from which they were called.\ncitation(pkg) dropped the header and footer specified in the\nCITATION file (PR#15257).\nQuotes were handled differently when reading the first line and\nreading the rest, so read.table() misread some files that\ncontained quote characters (PR#15245).\ncat() with sep a character vector of length greater than one and\nmore than one argument was using separators inconsistently\n(PR#15261).\nOn Windows in R 3.0.0, savePlot() failed because of an incorrect\ncheck on the argument count.\nunzip(list = TRUE) returned Names as a factor and not a\ncharacter vector (as documented) for the internal method. (Noticed\nby Sean O’Riordain.)\ncontourLines() now checks more comprehensively for conformance of\nits x, y and z arguments (it was used incorrectly in package\nR2G2).\nSaved graphics display lists are R version-specific. Attempting to\nload workspaces containing them (or some other version-specific\nobjects) aborted the load in R 3.0.0 and earlier; now it does a\npartial load and generates a warning instead.\nIn R 3.0.0, identify() and locator() did not record information\ncorrectly, so replaying a graph (e.g. by copying it to another\ndevice) would fail. (PR#15271)\nCalling file.copy() or dirname() with the invalid input \"\"\n(which was being used in packages, despite not being a file path)\ncould have caused a segfault.\ndirname(\"\") is now \"\" rather than \".\" (unless it segfaulted).\nsupsmu() could read/write outside its input vectors for very short\ninputs (seen in package\nrms for n = 4).\nas.dendrogram()’s hclust method uses less memory and hence gets\nconsiderably faster for large (n ~ 1000) clusterings, thanks to\nDaniel Müllner. (PR#15174)\nThe return value when all workers failed from\nparallel::mclapply(mc.preschedule = TRUE) was a list of strings\nand not of error objects. (Spotted by Karl Forner and Bernd Bischl.)\nIn R 3.0.0, when help() found multiple pages with the same alias,\nthe HTML display of all the selections was not produced. (PR#15282)\nsplinefun(method=\"monoH.FC\") now produces a function with first\nargument named x and allows deriv=3, as documented. (PR#15273)\nsummaryRprof() would only read the first chunksize lines of an\nRprof file produced with line.profiling=TRUE. By default, this\nis the first 100 seconds. (PR#15288)\nlsfit() produced an incorrect error message when argument x had\nmore columns than rows or x had a different number of rows than\ny. (Spotted by Renaud Gaujoux.)\nBinary operations on equal length vectors copied the class name from\nthe second operand when the first had no class name, but did not set\nthe object bit. (PR#15299)\nwrite.table() did not check that factors were constructed\ncorrectly, and so caused a segment fault when writing bad ones.\n(PR#15300)\nThe internal HTTP server no longer chokes on POST requests without\nbody. It will also pass-through other request types for custom\nhandlers (with the method stored in Request-Method header) instead\nof failing.\n\nCHANGES IN R 3.0.0\n\nSIGNIFICANT USER-VISIBLE CHANGES\nPackages need to be (re-)installed under this version (3.0.0) of R.\nThere is a subtle change in behaviour for numeric index values\n\\(2^{31}\\) and larger. These never used to be legitimate and so were\ntreated as NA, sometimes with a warning. They are now legal for\nlong vectors so there is no longer a warning, and x[2^31] <- y\nwill now extend the vector on a 64-bit platform and give an error on\na 32-bit one.\nIt is now possible for 64-bit builds to allocate amounts of memory\nlimited only by the OS. It may be wise to use OS facilities (e.g.\nulimit in a bash shell, limit in csh), to set limits on\noverall memory consumption of an R process, particularly in a\nmulti-user environment. A number of packages need a limit of at\nleast 4GB of virtual memory to load.\n64-bit Windows builds of R are by default limited in memory usage to\nthe amount of RAM installed: this limit can be changed by\ncommand-line option –max-mem-size or setting environment variable\nR_MAX_MEM_SIZE.\nNegative numbers for colours are consistently an error: previously\nthey were sometimes taken as transparent, sometimes mapped into the\ncurrent palette and sometimes an error.\n\n\nNEW FEATURES\nidentical() has a new argument, ignore.environment, used when\ncomparing functions (with default FALSE as before).\nThere is a new option, options(CBoundsCheck=), which controls how\n.C() and .Fortran() pass arguments to compiled code. If true\n(which can be enabled by setting the environment variable\nR_C_BOUNDS_CHECK to yes), raw, integer, double and complex\narguments are always copied, and checked for writing off either end\nof the array on return from the compiled code (when a second copy is\nmade). This also checks individual elements of character vectors\npassed to .C().\nThis is not intended for routine use, but can be very helpful in\nfinding segfaults in package code.\nIn layout(), the limits on the grid size have been raised (again).\nNew simple provideDimnames() utility function.\nWhere methods for length() return a double value which is\nrepresentable as an integer (as often happens for package\nMatrix), this is\nconverted to an integer.\nMatrix indexing of dataframes by two-column numeric indices is now\nsupported for replacement as well as extraction.\nsetNames() now has a default for its object argument, useful for\na character result.\nStructTS() has a revised additive constant in the loglik\ncomponent of the result: the previous definition is returned as the\nloglik0 component. However, the help page has always warned of a\nlack of comparability of log-likelihoods for non-stationary models.\n(Suggested by Jouni Helske.)\nThe logic in aggregate.formula() has been revised. It is now\npossible to use a formula stored in a variable; previously, it had\nto be given explicitly in the function call.\ninstall.packages() has a new argument quiet to reduce the amount\nof output shown.\nSetting an element of the graphics argument lwd to a negative or\ninfinite value is now an error. Lines corresponding to elements with\nvalues NA or NaN are silently omitted.\nPreviously the behaviour was device-dependent.\nSetting graphical parameters cex, col, lty, lwd and pch in\npar() now requires a length-one argument. Previously some silently\ntook the first element of a longer vector, but not always when\ndocumented to do so.\nSys.which() when used with inputs which would be unsafe in a shell\n(e.g. absolute paths containing spaces) now uses appropriate\nquoting.\nas.tclObj() has been extended to handle raw vectors. Previously,\nit only worked in the other direction. (Contributed by Charlie\nFriedemann, PR#14939.)\nNew functions cite() and citeNatbib() have been added, to allow\ngeneration of in-text citations from \"bibentry\" objects. A\ncite() function may be added to bibstyle() environments.\nA sort() method has been added for \"bibentry\" objects.\nThe bibstyle() function now defaults to setting the default\nbibliography style. The getBibstyle() function has been added to\nreport the name of the current default style.\nscatter.smooth() now has an argument lpars to pass arguments to\nlines().\npairs() has a new log argument, to allow some or all variables\nto be plotted on logarithmic scale. (In part, wish of PR#14919.)\nsplit() gains a sep argument.\ntermplot() does a better job when given a model with interactions\n(and no longer attempts to plot interaction terms).\nThe parser now incorporates code from Romain Francois’\nparser package, to\nsupport more detailed computation on the code, such as syntax\nhighlighting, comment-based documentation, etc. Functions\ngetParseData() and getParseText() access the data.\nThere is a new function rep_len() analogous to rep.int() for\nwhen speed is required (and names are not).\nThe undocumented use rep(NULL, length.out = n) for n > 0 (which\nreturns NULL) now gives a warning.\ndemo() gains an encoding argument for those packages with\nnon-ASCII demos: it defaults to the package encoding where there is\none.\nstrwrap() converts inputs with a marked encoding to the current\nlocale: previously it made some attempt to pass through as bytes\ninputs invalid in the current locale.\nSpecifying both rate and scale to [dpqr]gamma is a warning (if\nthey are essentially the same value) or an error.\nmerge() works in more cases where the data frames include\nmatrices. (Wish of PR#14974.)\noptimize() and uniroot() no longer use a shared parameter object\nacross calls. (nlm(), nlminb() and optim() with numerical\nderivatives still do, as documented.)\nThe all.equal() method for date-times is now documented: times are\nregarded as equal (by default) if they differ by up to 1 msec.\nduplicated() and unique() gain a nmax argument which can be\nused to make them much more efficient when it is known that there\nare only a small number of unique entries. This is done\nautomatically for factors.\nFunctions rbinom(), rgeom(), rhyper(), rpois(), rnbinom(),\nrsignrank() and rwilcox() now return integer (not double)\nvectors. This halves the storage requirements for large simulations.\nsort(), sort.int() and sort.list() now use radix sorting for\nfactors of less than 100,000 levels when method is not supplied.\nSo does order() if called with a single factor, unless\nna.last = NA.\ndiag() as used to generate a diagonal matrix has been re-written\nin C for speed and less memory usage. It now forces the result to be\nnumeric in the case diag(x) since it is said to have ‘zero\noff-diagonal entries’.\nbacksolve() (and forwardsolve()) are now internal functions, for\nspeed and support for large matrices.\nMore matrix algebra functions (e.g. chol() and solve()) accept\nlogical matrices (and coerce to numeric).\nsample.int() has some support for \\(n \\ge  2^{31}\\): see its help for the limitations.\nA different algorithm is used for\n(n, size, replace = FALSE, prob = NULL) for n > 1e7 and\nsize <= n/2. This is much faster and uses less memory, but does\ngive different results.\napproxfun() and splinefun() now return a wrapper to an internal\nfunction in the stats namespace rather than a .C() or .Call()\ncall. This is more likely to work if the function is saved and used\nin a different session.\nThe functions .C(), .Call(), .External() and .Fortran() now\ngive an error (rather than a warning) if called with a named first\nargument.\nSweave() by default now reports the locations in the source\nfile(s) of each chunk.\nclearPushBack() is now a documented interface to a long-existing\ninternal call.\naspell() gains filters for R code, Debian Control Format and\nmessage catalog files, and support for R level dictionaries. In\naddition, package utils now provides functions\naspell_package_R_files() and aspell_package_C_files() for spell\nchecking R and C level message strings in packages.\nbibentry() gains some support for “incomplete” entries with a\ncrossref field.\ngray() and gray.colors() finally allow alpha to be specified.\nmonthplot() gains parameters to control the look of the reference\nlines. (Suggestion of Ian McLeod.)\nAdded support for new %~% relation (“is distributed as”) in\nplotmath.\ndomain = NA is accepted by gettext() and ngettext(),\nanalogously to stop() etc.\ntermplot() gains a new argument plot = FALSE which returns\ninformation to allow the plots to be modified for use as part of\nother plots, but does not plot them. (Contributed by Terry Therneau,\nPR#15076.)\nquartz.save(), formerly an undocumented part of R.app, is now\navailable to copy a device to a quartz() device. dev.copy2pdf()\noptionally does this for PDF output: quartz.save() defaults to\nPNG.\nThe default method of pairs() now allows text.panel = NULL and\nthe use of <foo>.panel = NULL is now documented.\nsetRefClass() and getRefClass() now return class generator\nfunctions, similar to setClass(), but still with the reference\nfields and methods as before (suggestion of Romain Francois).\nNew functions bitwNot(), bitwAnd(), bitwOr() and bitwXor(),\nusing the internal interfaces previously used for classes\n\"octmode\" and \"hexmode\".\nAlso bitwShiftL() and bitwShiftR() for shifting bits in elements\nof integer vectors.\nNew option \"deparse.cutoff\" to control the deparsing of language\nobjects such as calls and formulae when printing. (Suggested by a\ncomment of Sarah Goslee.)\ncolors() gains an argument distinct.\nNew demo(colors) and demo(hclColors), with utility functions.\nlist.files() (aka dir()) gains a new optional argument no..\nwhich allows to exclude \".\" and \"..\" from listings.\nMultiple time series are also of class \"matrix\"; consequently,\nhead(), e.g., is more useful.\nencodeString() preserves UTF-8 marked encodings. Thus if factor\nlevels are marked as UTF-8 an attempt is made to print them in UTF-8\nin RGui on Windows.\nreadLines() and scan() (and hence read.table()) in a UTF-8\nlocale now discard a UTF-8 byte-order-mark (BOM). Such BOMs are\nallowed but not recommended by the Unicode Standard: however\nMicrosoft applications can produce them and so they are sometimes\nfound on websites.\nThe encoding name \"UTF-8-BOM\" for a connection will ensure that a\nUTF-8 BOM is discarded.\nmapply(FUN, a1, ..) now also works when a1 (or a further such\nargument) needs a length() method (which the documented arguments\nnever do). (Requested by Hervé Pagès; with a patch.)\n.onDetach() is supported as an alternative to .Last.lib. Unlike\n.Last.lib, this does not need to be exported from the package’s\nnamespace.\nThe srcfile argument to parse() may now be a character string,\nto be used in error messages.\nThe format() method for ftable objects gains a method\nargument, propagated to write.ftable() and print(), allowing\nmore compact output, notably for LaTeX formatting, thanks to Marius\nHofert.\nThe utils::process.events() function has been added to trigger\nimmediate event handling.\nSys.which() now returns NA (not \"\") for NA inputs (related\nto PR#15147).\nThe print() method for class \"htest\" gives fewer trailing spaces\n(wish of PR#15124).\nAlso print output from HoltWinters(), nls() and others.\nloadNamespace() allows a version specification to be given, and\nthis is used to check version specifications given in the Imports\nfield when a namespace is loaded.\nsetClass() has a new argument, slots, clearer and less ambiguous\nthan representation. It is recommended for future code, but should\nbe back-compatible. At the same time, the allowed slot specification\nis slightly more general. See the documentation for details.\nmget() now has a default for envir (the frame from which it is\ncalled), for consistency with get() and assign().\nclose() now returns an integer status where available, invisibly.\n(Wish of PR#15088.)\nThe internal method of tar() can now store paths too long for the\nustar format, using the (widely supported) GNU extension. It can\nalso store long link names, but these are much less widely\nsupported. There is support for larger files, up to the ustar\nlimit of 8GB.\nLocal reference classes have been added to package methods. These\nare a technique for avoiding unneeded copying of large components of\nobjects while retaining standard R functional behavior. See\n?LocalReferenceClasses.\nuntar() has a new argument restore_times which if false (not the\ndefault) discards the times in the tarball. This is useful if they\nare incorrect (some tarballs submitted to CRAN have times in a local\ntimezone or many years in the past even though the standard required\nthem to be in UTC).\nreplayplot() cannot (and will not attempt to) replay plots\nrecorded under R < 3.0.0. It may crash the R session if an attempt\nis made to replay plots created in a different build of R >= 3.0.0.\nPalette changes get recorded on the display list, so replaying plots\n(including when resizing screen devices and using dev.copy()) will\nwork better when the palette is changed during a plot.\nchol(pivot = TRUE) now defaults to LAPACK, not LINPACK.\nThe parse() function has a new parameter keep.source, which\ndefaults to options(\"keep.source\").\nProfiling via Rprof() now optionally records information at the\nstatement level, not just the function level.\nThe Rprof() function now quotes function names in in its output\nfile on Windows, to be consistent with the quoting in Unix.\nProfiling via Rprof() now optionally records information about\ntime spent in GC.\nThe HTML help page for a package now displays non-vignette\ndocumentation files in a more accessible format.\nTo support options(stringsAsFactors = FALSE), model.frame(),\nmodel.matrix() and replications() now automatically convert\ncharacter vectors to factors without a warning.\nThe print method for objects of class \"table\" now detects tables\nwith 0-extents and prints the results as, e.g.,\n< table of extent 0 x 1 x 2 >. (Wish of PR#15198.)\nDeparsing involving calls to anonymous functions has been made\ncloser to reversible by the addition of extra parentheses.\nThe function utils::packageName() has been added as a lightweight\nversion of methods::getPackageName().\nfind.package(lib.loc = NULL) now treats loaded namespaces\npreferentially in the same way as attached packages have been for a\nlong time.\nIn Windows, the Change Directory dialog now defaults to the current\nworking directory, rather than to the last directory chosen in that\ndialog.\navailable.packages() gains a \"license/restricts_use\" filter\nwhich retains only packages for which installation can proceed\nsolely based on packages which are guaranteed not to restrict use.\nNew check_packages_in_dir() function in package tools for\nconveniently checking source packages along with their reverse\ndependencies.\nR’s completion mechanism has been improved to handle help requests\n(starting with a question mark). In particular, help prefixes are\nnow supported, as well as quoted help topics. To support this,\ncompletion inside quotes are now handled by R by default on all\nplatforms.\nThe memory manager now allows the strategy used to balance garbage\ncollection and memory growth to be controlled by setting the\nenvironment variable R_GC_MEM_GROW. See ?Memory for more\ndetails.\n(‘For experts only’, as the introductory manual says.) The use of\nenvironment variables R_NSIZE and R_VSIZE to control the initial\n(= minimum) garbage collection trigger for number of cons cels and\nsize of heap has been restored: they can be overridden by the\ncommand-line options –min-nsize and –min-vsize; see ?Memory.\nOn Windows, the device name for bitmap devices as reported by\n.Device and .Devices no longer includes the file name. This is\nfor consistency with other platforms and was requested by the\nlattice maintainer.\nwin.metafile() still uses the file name: the exact form is used by\npackage tkrplot.\nset.seed(NULL) re-initializes .Random.seed as done at the\nbeginning of the session if not already set. (Suggestion of Bill\nDunlap.)\nThe breaks argument in hist.default() can now be a function that\nreturns the breakpoints to be used (previously it could only return\nthe suggested number of breakpoints).\nFile share/licenses/licenses.db has some clarifications,\nespecially as to which variants of ‘BSD’ and ‘MIT’ is intended and\nhow to apply them to packages. The problematic licence\n‘Artistic-1.0’ has been removed.\n\n\nLONG VECTORS This section applies only to 64-bit platforms.\nThere is support for vectors longer than \\(2^{31}-1\\) elements. This\napplies to raw, logical, integer, double, complex and character\nvectors, as well as lists. (Elements of character vectors remain\nlimited to \\(2^{31}-1\\) bytes.)\nMost operations which can sensibly be done with long vectors work:\nothers may return the error ‘long vectors not supported yet’. Most\nof these are because they explicitly work with integer indices (e.g.\nanyDuplicated() and match()) or because other limits (e.g. of\ncharacter strings or matrix dimensions) would be exceeded or the\noperations would be extremely slow.\nlength() returns a double for long vectors, and lengths can be set\nto \\(2^{31}\\) or more by the replacement function with a double value.\nMost aspects of indexing are available. Generally double-valued\nindices can be used to access elements beyond \\(2^{31}-1\\).\nThere is some support for matrices and arrays with each dimension\nless than \\(2^{31}\\) but total number of elements more than that. Only\nsome aspects of matrix algebra work for such matrices, often taking\na very long time. In other cases the underlying Fortran code has an\nunstated restriction (as was found for complex svd()).\ndist() can produce dissimilarity objects for more than 65536 rows\n(but for example hclust() cannot process such objects).\nserialize() to a raw vector is unlimited in size (except by\nresources).\nThe C-level function R_alloc can now allocate \\(2^{35}\\) or more\nbytes.\nagrep() and grep() will return double vectors of indices for\nlong vector inputs.\nMany calls to .C() have been replaced by .Call() to allow long\nvectors to be supported (now or in the future). Regrettably several\npackages had copied the non-API .C() calls and so failed.\n.C() and .Fortran() do not accept long vector inputs. This is a\nprecaution as it is very unlikely that existing code will have been\nwritten to handle long vectors (and the R wrappers often assume that\nlength(x) is an integer).\nMost of the methods for sort() work for long vectors.\nrank(), sort.list() and order() support long vectors (slowly\nexcept for radix sorting).\nsample() can do uniform sampling from a long vector.\n\n\nPERFORMANCE IMPROVEMENTS\nMore use has been made of R objects representing registered entry\npoints, which is more efficient as the address is provided by the\nloader once only when the package is loaded.\nThis has been done for packages base, methods, splines and\ntcltk: it was already in place for the other standard packages.\nSince these entry points are always accessed by the R entry points\nthey do not need to be in the load table which can be substantially\nsmaller and hence searched faster. This does mean that .C /\n.Fortran / .Call calls copied from earlier versions of R may no\nlonger work – but they were never part of the API.\nMany .Call() calls in package base have been migrated to\n.Internal() calls.\nsolve() makes fewer copies, especially when b is a vector rather\nthan a matrix.\neigen() makes fewer copies if the input has dimnames.\nMost of the linear algebra functions make fewer copies when the\ninput(s) are not double (e.g. integer or logical).\nA foreign function call (.C() etc) in a package without a\nPACKAGE argument will only look in the first DLL specified in the\nNAMESPACE file of the package rather than searching all loaded\nDLLs. A few packages needed PACKAGE arguments added.\nThe @<- operator is now implemented as a primitive, which should\nreduce some copying of objects when used. Note that the operator\nobject must now be in package base: do not try to import it\nexplicitly from package methods.\n\n\nPACKAGE INSTALLATION\nThe transitional support for installing packages without namespaces\n(required since R 2.14.0) has been removed. R CMD build will still\nadd a namespace, but a .First.lib() function will need to be\nconverted.\nR CMD INSTALL no longer adds a namespace (so installation will\nfail), and a .First.lib() function in a package will be ignored\n(with an installation warning for now).\nAs an exception, packages without a R directory and no NAMESPACE\nfile can still be installed.\nPackages can specify in their DESCRIPTION file a line like\nyes\nto be installed on Windows with –force-biarch.\nPackage vignettes can now be processed by other engines besides\nSweave; see ‘Writing R Extensions’ and the tools::vignetteEngine\nhelp topic for details.\nThe *.R tangled source code for vignettes is now included in\ntarballs when R CMD build is used to produce them. In R 3.0.0,\n*.R files not in the sources will be produced at install time, but\neventually this will be dropped.\nThe package type \"mac.binary\" now looks in a path in the\nrepository without any Mac subtype (which used to be universal or\nleopard): it looks in bin/macosx/contrib/3.0 rather than\nbin/macosx/leopard/contrib/2.15). This is the type used for the\nCRAN binary distribution for OS X as from R 3.0.0.\nFile etc/Makeconf makes more use of the macros $(CC), $(CXX),\n$(F77) and $(FC), so the compiler in use can be changed by\nsetting just these (and if necessary the corresponding flags and\nFLIBS) in file ~/.R/Makevars.\nThis is convenient for those working with binary distributions of R,\ne.g. on OS X.\n\n\nUTILITIES\nR CMD check now gives a warning rather than a note if it finds\ncalls to abort, assert or exit in compiled code, and has been\nable to find the .o file in which the calls occur.\nSuch calls can terminate the R process which loads the package.\nThe location of the build and check environment files can now be\nspecified by the environment variables R_BUILD_ENVIRON and\nR_CHECK_ENVIRON, respectively.\nR CMD Sweave gains a –compact option to control possibly\nreducing the size of the PDF file it creates when –pdf is given.\nR CMD build now omits Eclipse’s .metadata directories, and\nR CMD check warns if it finds them.\nR CMD check now does some checks on functions defined within\nreference classes, including of .Call() etc calls.\nR CMD check –as-cran notes assignments to the global environment,\ncalls to data() which load into the global environment, and calls\nto attach().\nR CMD build by default uses the internal method of tar() to\nprepare the tarball. This is more likely to produce a tarball\ncompatible with R CMD INSTALL and R CMD check: an external tar\nprogram, including options, can be specified via the environment\nvariable R_BUILD_TAR.\ntools::massageExamples() is better protected against packages\nwhich re-define base functions such as cat() and get() and so\ncan cause R CMD check to fail when checking examples.\nR CMD javareconf has been enhanced to be more similar to the code\nused by configure.\nThere is now a test that a JNI program can be compiled (like\nconfigure did) and only working settings are used.\nIt makes use of custom settings from configuration recorded in\netc/javaconf.\nThe –no-vignettes argument of R CMD build has been renamed to\nthe more accurate –no-build-vignettes: its action has always been\nto (re)build vignettes and never omitted them.\nR CMD check accepts –no-build-vignettes as a preferred synonym\nfor –no-rebuild-vignettes.\n\n\nDEPRECATED AND DEFUNCT\nThe ENCODING argument to .C() is defunct. Use iconv() instead.\nThe .Internal(eval.with.vis) non-API function has been removed.\nSupport for the converters for use with .C() has been removed,\nincluding the oft misused non-API header R_ext/RConverters.h.\nThe previously deprecated uses of array() with a 0-length dim\nargument and tapply() with a 0-length INDEX list are now errors.\nTranslation packages are defunct.\nCalling rep() or rep.int() on a pairlist or other non-vector\nobject is now an error.\nSeveral non-API entry points have been transferred to packages (e.g.\nR_zeroin2) or replaced by different non-API entry points (e.g.\nR_tabulate).\nThe ‘internal’ graphics device invoked by\n.Call(\"R_GD_nullDevice\", package = \"grDevices\") has been removed:\nuse pdf(file = NULL) instead.\nThe .Fortran() entry point \"dqrls\" which has not been used by R\nsince version 2.15.1 is no longer available.\nFunctions traceOn() and traceOff() in package methods are now\ndefunct.\nFunction CRAN.packages() is finally defunct.\nUse of col2rgb(0) is defunct: use par(\"bg\") or NA instead.\nThe long-defunct functions Rd_parse(), anovalist.lm(),\ncategpry(), clearNames(), gammaCody(), glm.fit.null(),\nlm.fit.null(), lm.wfit.null(), manglePackageNames(),\nmauchley.test(), package.contents(), print.coefmat(),\nreshapeLong(), reshapeWide(), tkclose(), tkcmd(),\ntkfile.dir(), tkfile.tail(), tkopen(), tkputs(), tkread(),\ntrySilent() and zip.file.extract() have been removed entirely\n(but are still documented in the help system).\nThe unused dataPath argument to attachNamespace() has been\nremoved.\ngrid.prompt() has been removed: use devAskNewPage() instead.\nThe long-deprecated intensities component is no longer returned by\nhist().\nmean() for data frames and sd() for data frames and matrices are\ndefunct.\nchol(pivot = FALSE, LINPACK = TRUE), ch2inv(LINPACK = TRUE),\neigen(EISPACK = TRUE), solve(LINPACK = TRUE) and\nsvd(LINPACK = TRUE) are defunct: LAPACK will be used, with a\nwarning.\nThe keep.source argument to library() and require() is\ndefunct. This option needs to be set at install time.\nDocumentation for real(), as.real() and is.real() has been\nmoved to ‘defunct’ and the functions removed.\nThe maxRasters argument of pdf() (unused since R 2.14.0) has\nbeen removed.\nThe unused fontsmooth argument has been removed from the\nquartz() device.\nAll the (non-API) EISPACK entry points in R have been removed.\nchol(pivot = TRUE, LINPACK = TRUE) is deprecated.\nThe long-deprecated use of \\\\synopsis in the Usage section of\n.Rd files will be removed in R 3.1.0.\n.find.package() and .path.package() are deprecated: only the\npublic versions without the dot have ever been in the API.\nIn a package’s DESCRIPTION file,\nX11\nis deprecated, since it includes ‘Copyright (C) 1996 X Consortium’\nwhich cannot be appropriate for a current R package. Use ‘MIT’ or\n‘BSD_2_clause’ instead.\n\n\nCODE MIGRATION\nThe C code underlying base graphics has been migrated to the\ngraphics package (and hence no longer uses .Internal() calls).\nMost of the .Internal() calls used in the stats package have\nbeen migrated to C code in that package.\nThis means that a number of .Internal() calls which have been used\nby packages no longer exist, including .Internal(cor)\n.Internal(cov), .Internal(optimhess) and\n.Internal(update.formula).\nSome .External() calls to the base package (really to the R\nexecutable or shared library) have been moved to more appropriate\npackages. Packages should not have been using such calls, but some\ndid (mainly those used by integrate()).\n\n\nPACKAGE parallel\nThere is a new function mcaffinity() which allows getting or\nsetting the CPU affinity mask for the current R process on systems\nthat supports this (currently only Linux has been tested\nsuccessfully). It has no effect on systems which do not support\nprocess affinity. Users are not expected to use this function\ndirectly (with the exception of fixing libraries that break affinity\nsettings like OpenBLAS) – the function is rather intended to\nsupport affinity control in high-level parallel functions. In the\nfuture, R may supplement lack of affinity control in the OS by its\nown bookkeeping via mcaffinity() related to processes and threads\nit spawns.\nmcparallel() has a new argument mc.affinity which attempts to\nset the affinity of the child process according to the specification\ncontained therein.\nThe port used by socket clusters is chosen randomly: this should\nhelp to avoid clashes observed when two users of a multi-user\nmachine try to create a cluster at the same time. To reproduce the\nprevious behaviour set environment variable R_PARALLEL_PORT to\n10187.\n\n\nC-LEVEL FACILITIES\nThere has been some minor re-organization of the non-API header\nfiles. In particular, Rinternals.h no longer includes the non-API\nheader R_exts/PrtUtil.h, and that no longer includes\nR_exts/Print.h.\nPassing NULL to .C() is now an error.\n.C() and .Fortran() now warn if \"single\" arguments are used\nwith DUP = FALSE, as changes to such arguments are not returned to\nthe caller.\nC entry points R_qsort and R_qsort_I now have start and end\nas size_t to allow them to work with longer vectors on 64-bit\nplatforms. Code using them should be recompiled.\nA few recently added C entry points were missing the remapping to\nRf_, notably [dpq]nbinom_mu.\nSome of the interface pointers formerly available only to R.app\nare now available to front-ends on all Unix-alikes: one has been\nadded for the interface to View().\nPACKAGE = \"\" is now an error in .C() etc calls: it was always\ncontrary to the documentation.\nEntry point rcont2 has been migrated to package stats and so is\nno longer available.\nR_SVN_REVISION in Rversion.h is now an integer (rather than a\nstring) and hence usable as e.g. #if R_SVN_REVISION < 70000.\nThe entry points rgb2hsv and hsv2rgb have been migrated to\npackage grDevices and so are no longer available.\nR_GE_version has been increased to 10 and name2col removed\n(use R_GE_str2col instead). R internal colour codes are now\ndefined using the typedef rcolor.\nThe REPROTECT macro now checks that the protect index is valid.\nSeveral non-API entry points no longer used by R have been removed,\nincluding the Fortran entry points chol, chol2inv, cg, ch\nand rg, and the C entry points Brent_fmin, fft_factor and\nfft_work.\nIf a .External call is registered with a number of arguments\n(other than -1), the number of arguments passed is checked for\neach call (as for other foreign function calls).\nIt is now possible to write custom connection implementations\noutside core R using R_ext/Connections.h. Please note that the\nimplementation of connections is still considered internal and may\nchange in the future (see the above file for details).\n\n\nINTERNATIONALIZATION\nThe management of translations has been converted to R code: see\n?tools::update_pkg_po.\nThe translations for the R interpreter and RGui.exe are now part\nof the base package (rather than having sources in directory po\nand being installed to share/locale). Thus the base package\nsupports three translation domains, R-base, R and RGui.\nThe compiled translations which ship with R are all installed to the\nnew package translations for easier updating. The first package of\nthat name found on .libPaths() at the start of the R session will\nbe used. (It is possible messages will be used before .libPaths()\nis set up in which case the default translations will be used: set\nenvironment variable R_TRANSLATIONS to point to the location of\nthe intended translations package to use this right from the\nstart.)\nThe translations form a separate group in the Windows installer, so\ncan be omitted if desired.\nThe markup for many messages has been changed to make them easier to\ntranslate, incorporating suggestions from Łukasz Daniel.\n\n\nINSTALLATION\nThere is again support for building without using the C ‘long\ndouble’ type. This is required by C99, but system implementations\ncan be slow or flawed. Use configure option\n–disable-long-double.\nmake pdf and make install-pdf now make and install the full\nreference index (including all base and recommended packages).\nThe ‘reference manual’ on the Windows GUI menu and included in the\ninstaller is now the full reference index, including all base and\nrecommended packages.\nR help pages and manuals have no ISBNs because ISBN rules no longer\nallow constantly changing content to be assigned an ISBN.\nThe Windows installer no longer installs a Start Menu link to the\nstatic help pages; as most pages are generated dynamically, this led\nto a lot of broken links.\nAny custom settings for Java configuration are recorded in file\netc/javaconf for subsequent use by R CMD javareconf.\nThere is now support for makeinfo version 5.0 (which requires a\nslightly different .texi syntax).\nThe minimum versions for –use-system-zlib and –use-system-pcre\nare now tested as 1.2.5 and 8.10 respectively.\nOn Windows, the stack size is reduced to 16MB on 32-bit systems:\nmisguided users were launching many threads without controlling the\nstack size.\nconfigure no longer looks for file ~/.Rconfig: ~/.R/config has\nlong been preferred.\n\n\nBUG FIXES\nWhen R CMD build is run in an encoding other than the one\nspecified in the package’s DESCRIPTION file it tries harder to\nexpand the authors@R field in the specified encoding. (PR#14958)\nIf R CMD INSTALL is required to expand the authors@R field of\nthe DESCRIPTION file, it tries harder to do so in the encoding\nspecified for the package (rather than using ASCII escapes).\nFix in package grid for pushing a viewport into a layout cell,\nwhere the layout is within a viewport that has zero physical width\nOR where the layout has zero total relative width (likewise for\nheight). The layout column widths (or row heights) in this case were\nbeing calculated with non-finite values. (Reported by Winston\nChang.)\nsolve(A, b) for a vector b gave the answer names from\ncolnames(A) for LINPACK = TRUE but not in the default case.\nLa.svd() accepts logical matrices (as documented, and as svd()\ndid).\nlegend() now accepts negative pch values, in the same way\npoints() long has.\nParse errors when installing files now correctly display the name of\nthe file containing the bad code.\nIn Windows, tcltk windows were not always properly constructed.\n(PR#15150)\nThe internal functions implementing parse(), tools::parseLatex()\nand tools::parse_Rd() were not reentrant, leading to errors in\nrare circumstances such as a garbage collection triggering a\nrecursive call.\nField assignments in reference class objects via $<- were not\nbeing checked because the magic incantation to turn methods on for\nthat primitive operator had been inadvertently omitted.\nsetHook(hookname, value, action=\"replace\") set the hook to be the\nvalue, rather than a list containing the value as documented.\n(PR#15167)\nIf a package used a NEWS.Rd file, the main HTML package index page\ndid not link to it. (Reported by Dirk Eddelbuettel.)\nThe primitive implementation of @<- was not checking the class of\nthe replacement. It now does a check, quicker but less general than\nslot<-. See the help.\nsplit(x, f) now recycles classed objects x in the same way as\nvectors. (Reported by Martin Morgan.)\npbeta(.28, 1/2, 2200, lower.tail=FALSE, log.p=TRUE) is no longer\n-Inf; ditto for corresponding pt() and pf() calls, such as\npt(45, df=5000, lower.tail=FALSE, log.p=TRUE). (PR#15162)\nThe Windows graphics device would crash R if a user attempted to\nload the graphics history from a variable that was not a saved\nhistory. (PR#15230)\nThe workspace size for the predict() method for loess() could\nexceed the maximum integer size. (Reported by Hiroyuki Kawakatsu.)\nftable(x, row.vars, col.vars) now also works when the *.vars\narguments are (integer or character vectors) of length zero.\nCalling cat() on a malformed UTF-8 string could cause the Windows\nGUI to lock up. (PR#15227)\nremoveClass(cc) gave \"node stack overflow\" for some class\ndefinitions containing \"array\" or \"matrix\".\n\nCHANGES IN R VERSION 2.15.3\n\nNEW FEATURES\nlgamma(x) for very small x (in the denormalized range) is no\nlonger Inf with a warning.\nimage() now sorts an unsorted breaks vector, with a warning.\nThe internal methods for tar() and untar() do a slightly more\ngeneral job for ‘ustar’-style handling of paths of more than 100\nbytes.\nPackages compiler and parallel have been added to the reference\nindex (refman.pdf).\nuntar(tar = \"internal\") has some support for pax headers as\nproduced by e.g. gnutar –posix (which seems prevalent on OpenSUSE\n12.2) or bsdtar –format pax, including long path and link names.\nsQuote() and dQuote() now handle 0-length inputs. (Suggestion of\nBen Bolker.)\nsummaryRprof() returns zero-row data frames rather than throw an\nerror if no events are recorded, for consistency.\nThe included version of PCRE has been updated to 8.32.\nThe tcltk namespace can now be re-loaded after unloading.\nThe Tcl/Tk event loop is inhibited in a forked child from package\nparallel (as in e.g. mclapply()).\nparallel::makeCluster() recognizes the value random for the\nenvironment variable R_PARALLEL_PORT: this chooses a random value\nfor the port and reduces the chance of conflicts when multiple users\nstart a cluster at the same time.\n\n\nUTILITIES\nThe default for TAR on Windows for R CMD build has been changed\nto be internal if no tar command is on the path.\nThis enables most packages to be built ‘out of the box’ without\nRtools: the main exceptions are those which need to be installed\nto re-build vignettes and need Rtools for installation (usually\nbecause they contain compiled code).\n\n\nC-LEVEL FACILITIES\nOn a 64-bit Windows platform with enough RAM, R_alloc can now\nallocate up to just under 32GB like other 64-bit platforms.\n\n\nDEPRECATED AND DEFUNCT\nUse of col2rgb(0) is deprecated (see the help page for its\nlimitations).\nThe deprecated intensities component returned by hist() is no\nlonger recognized by the plot() method and will be removed in R\n3.0.0.\nreal(), as.real() and is.real() are now formally deprecated\nand give a warning.\nThis is formal notice that the non-API EISPACK entry points in R\nwill be removed shortly.\n\n\nINSTALLATION\nThe configure tests for Objective C and Objective C++ now work on\nMac OS 10.8 with Xcode 4.5.2 (PR#15107).\nThe cairo-based versions of X11() now work with current versions\nof cairographics (e.g. 1.12.10). (PR#15168)\nA workaround for earlier versions of R is to use\nX11.options(type = \"nbcairo\").\nConfiguration and R CMD javareconf now come up with a smaller set\nof library paths for Java on Oracle-format JDK (including OpenJDK).\nThis helps avoid conflicts between libraries (such as libjpeg)\nsupplied in the JDK and system libraries. This can always be\noverridden if needed: see the ‘R Installation and Administration’\nmanual.\n\n\nBUG FIXES\nbeta(a, b) could overflow to infinity in its calculations when one\nof a and b was less than one. (PR#15075)\nlbeta(a, b) no longer gives NaN if a or b is very small (in\nthe denormalized range).\nbquote() is now able to substitute default arguments in\nsingle-argument functions. (PR#15077)\nbrowseEnv(html = FALSE) would segfault if called from R (not\nR.app) on a CRAN-style Mac OS X build of R.\n[[<- for lists (generic vectors) needed to increment NAMED count\nwhen RHS is used more than once. (PR#15098)\nOn Windows, warnings about opening a file or pipe with a non-ASCII\ndescription were sometimes output in UTF-8 rather than in the\ncurrent locale’s character set.\nThe call() function did not duplicate its arguments. (PR#15115)\nTukeyHSD() could give NA results with some na.action methods\nsuch as na.exclude(). (Hinted at on R-help by John Fox.)\nThe deprecated svd(X, LINPACK = TRUE) could alter X in R\n2.15.[12]. (Reported by Bill Dunlap.)\nUnder Windows, file.link() and file.symlink() used the link name\ntwice, so would always fail. (Reported by Rui Barradas/Oliver\nSoong).\nsummaryRprof(memory = \"both\") mixed up the units of Vcells and\nNcells: it now works in bytes. (PR#15138)\ntools::Rd2HTML() would sometimes delete text. (PR#15134)\nplot() failed for \"table\" objects containing just one entry.\n(PR#15118)\nembedFonts() needed to quote some filepaths. (PR#15149)\nparallel::mccollect() handled NULL returns incorrectly (removing\nthe element rather than setting it to NULL).\nThe full reference index (fullrefman.pdf) was missing packages\ncompiler and parallel.\nThe report for\noptim(method = \"L-BFGS-B\", control = list(trace = 1)) reported the\nlast completed and not the current iteration, unlike other methods\nand trace levels. (PR#15103)\nqt(1e-12, 1.2) no longer gives NaN.\ndt(1e160, 1.2, log=TRUE) no longer gives -Inf.\nOn Windows the untar() function now quotes the directory name when\nusing an external tar utility, so R CMD check will handle\npathnames containing spaces.\nThe version for Windows 8 and Windows Server 2012 is now displayed\nby win.version(). (Reported by Gabor Grothendieck.)\nThe custom Windows installer target myR in the installer\nMakefile did not work in 2.15.2. (Reported by Erich Neuwirth.)\naperm(matrix(1:6, 2, dimnames=list(A={}, B={})), \"A\") no longer\nsegfaults.\nExpressions involving user defined operators were not always\ndeparsed faithfully. (PR#15179)\nThe enc2utf8() function converted NA_character_ to \"NA\" in\nnon-UTF-8 locales. (PR#15201)\nThe exclude argument to xtabs() was ignored for \"factor\"\narguments.\nOn Windows, work around an event-timing problem when the RGui\nconsole was closed from the ‘X’ control and the closure cancelled.\n(This would on some 64-bit systems crash R, typically those with a\nslow GPU relative to the CPU.)\nOn unix Rscript will pass the r_arch setting it was compiled\nwith on to the R process so that the architecture of Rscript and\nthat of R will match unless overridden.\nOn Windows, basename(), dirname() and file.choose() have more\nsupport for long non-ASCII file names with 260 or more bytes when\nexpressed in UTF-8.\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2013-1-r-finance/",
    "title": "Conference Report: R/Finance 2013",
    "description": "The 'Conference Report: R/Finance 2013' article from the 2013-1 issue.",
    "author": [
      {
        "name": "Joshua Ulrich",
        "url": {}
      }
    ],
    "date": "2013-06-01",
    "categories": [],
    "contents": "\n\nThe fifth annual R/Finance conference for applied finance using R was\nheld in Chicago, IL, USA on Friday May 17 and Saturday May 18, 2013.\nThe conference provided a venue to discuss how R can be used for\nportfolio management, time series analysis, advanced risk analysis,\nhigh-performance computing, market microstructure, and econometrics. As\nin prior years, the conference had 300 attendees from several countries\n(including several European countries, South Africa, Australia, and\nRussia). The program included seminars, keynotes, full-length talks, and\nlightning talks. The conference also provided exceptional networking\nopportunities.\n1 Presentations\nFive one-hour, single-track seminars were held on Friday morning:\nWhit Armstrong, Bryan Lewis: An Introduction to Distributed\nComputing in R\nMatthew Dowle: Advanced Tutorial on\ndata.table\nJan Humme, Brian Peterson: Using quantstrat to evaluate intraday\ntrading strategies\nDirk Eddelbuettel: Example-driven Introduction to\nRcpp\nJeffrey Ryan: R Programming for Financial Data\nThe first presentation was by keynote Ryan Sheftel, who talked about how\nhe uses R on his bond trading desk. David Ardia showed how expected\nreturns can be estimated via the covariance matrix. Ronald Hochreiter\ngave an overview of modeling optimization via his modopt package.\nBernhard Pfaff used Bayesian utility optimization to allocate large\nportfolios.\nMaria Belianina showed how R can interface with OneTick’s high\nperformance time series database. Yang Lu described Brinson-style\nportfolio attribution using\npa. Michael Kapler used\nfactor clusters to construct Risk Parity portfolios and evaluate risk\ncontributions. Tammer Kamel gave a live demo of the\nQuandl package and said,\n\"Quandl hopes to do to Bloomberg what Wikipedia did to Britannica.\"\nDoug Martin talked about robust covariance estimation. Giles Heywood\ndiscussed several ways of estimating and forecasting covariance, and\nproposed an \"open source equity risk and backtest system\" as a means\nof matching talent with capital.\nRuey Tsay was the next keynote, and spoke about using principal\nvolatility components to simplify multivariate volatility modeling.\nAlexios Ghalanos spoke about modeling multivariate time-varying skewness\nand kurtosis.\nKris Boudt examined changes in portfolio properties across volatility\nregimes. David Matteson described a new technique for detecting change\npoints in any statistical property of univariate and multivariate time\nseries. Celine Sun proposed a methodology to construct a full-rank\ncovariance matrix using cross-sectional volatilities. Winston Chang gave\na live demo of shiny.\nSaturday started with Christian Silva, who evaluated statistical\nproperties of moving-average-based strategies to determine when they do\nand don’t work. He provided code at http://rpubs.com/silvaac/6165.\nVyacheslav Arbuzov used a cluster of servers to analyze financial\nbubbles and crashes using an agent-based model. Stephen Rush examined\nthe relationship between bond coupon and liquidity in different market\nregimes.\nSamantha Azzarello discussed her work with Blu Putnam, which used a\ndynamic linear model to evaluate the Fed’s performance vis-a-vis the\nTaylor Rule. Grant Cavanaugh examined the success of new ETF product\nlistings. Jiahan Li used constrained least squares on 4 economic\nfundamentals to forecast foreign exchange rates. Thomas Harte talked\nabout regulatory requirements of foreign exchange pricing; basically\ndocumentation is important, Sweave to the rescue!\nSanjiv Das gave a keynote on 4 applications: 1) network analysis on SEC\nand FDIC filings to determine banks that pose systematic risk, 2)\ndetermining which home mortgage modification is optimal, 3) portfolio\noptimization with mental accounting, 4) venture capital communities.\nDirk Eddelbuettel showed how it’s easy to write fast linear algebra code\nwith\nRcppArmadillo.\nKlaus Spanderen showed how to use QuantLib from R, and even how to to\ncall C++ from R from C++. Bryan Lewis talked about SciDB and the\nscidb package (SciDB\ncontains fast linear algebra routines that operate on the database!).\nMatthew Dowle gave an introduction to\ndata.table. Chris\nBlakely showed a Java interface to R and a C implementation of the HEAVY\nrealized volatility model. Mathieu Lestel described his 2012 Google\nSummer of Code project that added functionality to\nPerformanceAnalytics.\nAttilio Meucci gave his keynote on visualizing advanced risk management\nand portfolio optimization. Immediately following, Brian Peterson gave a\nlightning on implementing Meucci’s work in R (Attilio works in Matlab),\nwhich was part of a Google Summer of Code project last year.\nThomas Hanson presented his work with Don Chance (and others) on\ncomputational issues in estimating the volatility smile. Kam Hamidieh\nused options prices to recover the underlying asset’s probability\ndistribution estimate. Jeffrey Ryan showed how to manipulate options\ndata in R with the greeks package.\n2 Prizes\nThe conference wrapped up by giving away three books, generously donated\nby Springer, to three random people who submitted feedback surveys. The\ncommittee also presented the awards for best papers. The winners were:\nRegime switches in volatility and correlation of financial\ninstitutions, Boudt et. al.\nA Bayesian interpretation of the Federal Reserve’s dual mandate and\nthe Taylor Rule, Putnam & Azzarello\nNonparametric Estimation of Stationarity and Change Points in\nFinance, Matteson et. al.\nEstimating High Dimensional Covariance Matrix Using a Factor Model,\nSun (best student paper)\n3 Networking\nThe two-hour conference reception at UIC on Friday was a great time to\ntalk with speakers, and mingle with other attendees. Next was the\n(optional) dinner at The Terrace at Trump. Unfortunately, it was cold\nand windy, so we only spent 15-20 minutes on the terrace before moving\ninside. The food was fantastic, but the conversations were even better.\nAfter the final presentation on Saturday, many attendees continued\nconversations over food and drink at Jaks Tap.\n4 Sponsors and organizers\nThe conference could not be successful without the support of our\nfantastic sponsors: International Center for Futures and Derivatives at\nUIC (our host), Revolution Analytics, MS-Computational Finance at\nUniversity of Washington, Google, lemnica, OpenGamma, OneMarketData, and\nRStudio.\nThanks to the committee: Gib Bassett, Peter Carl, Dirk Eddelbuettel,\nBrian Peterson, Dale Rosenthal, Jeffrey Ryan, Joshua Ulrich; and also to\nthe event coordinators: Holly Griffin and Alexandrina Almazan.\n5 Further information\nThe R/Finance website, http://www.RinFinance.com, contains information\nfor past and future conferences. Slides (if made available by the\nauthors) can be downloaded via the agenda page. We hope to see you in\nMay 2014!\n\nOn Behalf of the Conference Committee,\nJoshua Ulrich\n\n\n\nCRAN packages used\ndata.table, Rcpp, pa, Quandl, shiny, RcppArmadillo, scidb, PerformanceAnalytics\nCRAN Task Views implied by cited packages\nFinance, HighPerformanceComputing, NumericalMathematics, TimeSeries, WebTechnologies\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2013-1-r-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2013-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2013-06-01",
    "categories": [],
    "contents": "\n1 Donations and new members\nNew benefactors\nQuartz Bio, Switzerland\nNew supporting institutions\nInstitute for Geoinformatics, Westfälische Wilhelms-Universität\nMünster, Germany\nNew supporting members\nNicoleta Caragea, Romania\nAlexandru Antoniade Ciprian, Romania\nMartin Elff, Germany\nHubert Eser, Austria\nSarah “Mason” Garrison, USA\nChristian A. Oberst, Germany\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2013-1-user2013/",
    "title": "The R User Conference 2013",
    "description": "The 'The R User Conference 2013' article from the 2013-1 issue.",
    "author": [
      {
        "name": "UseR 2013 Organising Committee",
        "url": {}
      }
    ],
    "date": "2013-06-01",
    "categories": [],
    "contents": "\n\nThe ninth R user conference will take place at the University of\nCastilla-La Mancha, Albacete, Spain from Wednesday 10 July 2013 to\nFriday 12 July 2013. Following previous useR! conferences, this\nmeeting of the R user community will\nfocus on R as the ‘lingua franca’ of data analysis and statistical\ncomputing;\nprovide a platform for R users to discuss and exchange ideas on how\nR can be used for statistical computation, data analysis,\nvisualization and exciting applications in various fields;\ngive an overview of the new features of the ever evolving R project.\nAs with the predecessor conferences, the program consists of two parts:\ninvited talks discussing new R developments and exciting\napplications of R\nuser-contributed presentation reflecting the wide range of fields in\nwhich R is used to analyze data.\nA major goal of the useR! conference is to bring users from various\nfields together and provide a platform for discussion and exchange of\nideas: both in the formal framework of presentations as well as in the\ninformal times surrounding the conference sessions.\n1 Invited speakers\nThe invited talks represent the spectrum of interest from important\ntechnical developments to exciting applications of R, presented by\nexperts in the field:\nMaría Jesús Bayarri: New challenges and Bayes: The world of\ncomputer models.\nJosé Manuel Benítez-Sánchez: Computational Intelligence in R.\nDuncan Murdoch: What’s new in R3.0.X.\nHavard Rue: Bayesian computing with INLA and the R-INLA package.\nSteve Scott: Bayesian computation in C++ with R as an interface.\nHadley Wickham: BigR data\n2 User-contributed sessions\nIn the contributed sessions, presenters will share innovative and\ninteresting uses of R, covering topics such as:\nBayesian statistics\nBioinformatics\nChemometrics and computational physics\nData mining\nEconometrics & finance\nEnvironmetrics & ecological modeling\nHigh performance computing\nImaging\nInterfaces with other languages/software\nMachine learning\nMultivariate statistics\nNonparametric statistics\nPharmaceutical statistics\nPsychometrics\nSpatial statistics\nStatistics in the social and political sciences\nTeaching\nVisualization & graphics\nThe poster session will be a major social event on the evening of the\nfirst day of the conference. Contributed talks will be organised in the\nfollowing types of session:\nuseR! Kaleidoscope: These sessions give a broad overview of the\nmany different applications of R and should appeal to a wide\naudience.\nuseR! Focus Session: These sessions cover topics of special\ninterest and may be more technical.\nIn both cases presentations will be allowed 17 minutes, followed by 3\nminutes discussion. In addition to the regular contributed talks, all\nparticipants are invited to present a Lightning Talk, for which no\nabstract is required. These talks provide a 5-minute platform to speak\non any R-related topic and should particularly appeal to R newbies.\nParticipants wishing to give such a talk must provide an informative\ntitle.\n3 Pre-conference tutorials\nBefore the start of the official program, the following half-day\ntutorials will be offered on Tuesday, July 9th:\nEsteban Alfaro, Matías Gámez and Noelia García: Classification\nwith Individual and Ensemble Trees\nJason Bryer and Robert Pruzek: Introduction to Propensity Score\nMethods with R\nRomain François and Hadley Wickham: C++ and Rcpp for beginners\nMarkus Gesmann and Diego de Castillo: Interactive web graphics\nwith R and googleVis\nGarrett Grolemund: Data visualization with ggplot2\nStephanie A. Kovalchik: Performing Meta-Analysis with R\nMark van der Loo and Edwin de Jonge: An introduction to data\ncleaning with R\nMartin Morgan: R/Bioconductor for Analysis and Comprehension of\nHigh-throughput Genomic Data\nGeorge Ostrouchov and Drew Schmidt: Programming with Big Data in R\nXavier de Pedro: Web 2.0 interfaces for R with Tiki\nHavard Rue: Bayesian computing with INLA: An introduction item\nRoger Bivand: Using Spatial Data\nKarim Chine: R and Cloud Computing for Higher Education and\nResearch\nAndrea Dessi, Enrico Branca, Federico Figus: Applied Financial\nAnalysis and Human Capital Risk Management\nMarco Scutari: Learning Bayesian Networks in R: an Example in\nSystems Biology\nMax Kuhn: Predictive Modeling with R and the caret Package\nRui Paulo and Jesús Palomo: Statistical Analysis of Computer\nModels using R\nJosh Paulson and Joe Cheng: Developing web applications with R and\nshiny\nPete Philipson: Joint Modelling of Repeated Measurements and\nTime-to-Event Data\nAndy South: Making beautiful world maps with country-referenced\ndata using rworldmap and other R packages\nTobias Verbeke and Stephan Wahlbrink: Eclipse/StatET and Architect\nfor Professional R Development\nAlex Zolotovitski: How to work with large R projects\n4 Data analysis contest\nWe are pleased to announce the Data Analysis Contest for useR! 2013\nattendants: http://www.edii.uclm.es/~useR-2013/#contest. Check the\nrules, download the data and send your proposal to win the prize!\n5 Location & surrounding area\nThe University of Castilla-La Mancha is the only university in the\nregion and it is divided into several campuses. The conference will take\nplace at the campus in Albacete. Information and useful links on the\nnumerous and famous attractions in the area surrounding the University\nof Castilla-La Mancha in Albacete can be found at the Castilla-La Mancha\nTourism website http://www.visitclm.com/.\n6 Further information\nA web page offering more information on useR! 2013, including details\nregarding registration, is available at\nhttp://www.r-project.org/useR-2013/\nWe hope to meet you in Albacete!\nEsteban Alfaro-Cortés, José Luis Alfaro-Navarro, María Teresa\nAlonso-Martínez, Emilio L. Cano, Gonzalo García-Donato, Matías\nGámez-Martínez, Noelia García-Rubio, Virgilio Gómez-Rubio and Francisco\nParreño-Torres.\nThe organizing committee,\nuseR-2013@R-project.org\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2012-2-bioconductor/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2012-2 issue.",
    "author": [
      {
        "name": "Bioconductor Team",
        "url": {}
      }
    ],
    "date": "2012-12-01",
    "categories": [],
    "contents": "\n\nBioconductor 2.11 was released on 3 October 2012. It is compatible with\nR 2.15.2, and consists of 610 software packages and more than 650\nup-to-date annotation packages. The release includes 58 new software\npackages, and enhancements to many others. Descriptions of new packages\nand updated NEWS files provided by current package maintainers are at\nhttp://bioconductor.org/news/bioc_2_11_release/. Start using\nBioconductor and R version 2.15.2 with\n> source(\"http://bioconductor.org/biocLite.R\")\n> biocLite()\nUpgrade all packages to the current release with\n> source(\"http://bioconductor.org/biocLite.R\")\n> biocLite(\"BiocUpgrade\")\nInstall additional packages, e.g., VariantTools, with\n> source(\"http://bioconductor.org/biocLite.R\")\n> biocLite(\"VariantTools\")\nExplore Bioconductor at http://bioconductor.org. All packages are\ngrouped by ‘BiocViews’ to identify coherent groups of packages. Each\npackage has an html page with the descriptions and links to vignettes,\nreference manuals, and use statistics.\nA Bioconductor Amazon Machine Instance is available; see\nhttp://bioconductor.org/help/bioconductor-cloud-ami.\n1 Core Annotation and Software Packages\nOur large collection of microarray- and organism-specific annotation\npackages have been updated to include current information. This release\nalso includes the OrganismDbi package to integrate separate annotation\nresources. For example, the Homo.sapiens package greatly simplifies\naccess to transcript, gene, and GO (gene ontology) annotations.\nGenomicRanges and related packages, e.g., VariantAnnotation,\nIRanges, Biostrings, Rsamtools, GenomicFeatures provide an\nextensive, mature and extensible framework for interacting with high\nthroughput sequence data, either as a user or package developer. Many\ncontributed packages rely on this infrastructure for interoperable,\nre-usable analysis.\nMotifDb, part of a new emphasis on gene regulation, offers a\ncomprehensive annotated collection of DNA-binding motifs from popular\npublic sources.\n2 Other activities\nBioconductor’s Annual Meeting was in Seattle, 23-25 July 2012; our\nEuropean developer community meets 13-14 December in Zurich. We look\nforward to our next Annual Meeting on 17-19 July 2013, and to additional\ntraining and community activities advertised at\nhttp://bioconductor.org/help/events/. The active Bioconductor mailing\nlists (http://bioconductor.org/help/mailing-list/) connect users with\neach other, to domain experts, and to maintainers eager to ensure that\ntheir packages satisfy the needs of leading edge approaches. Keep\nabreast of packages added to the ‘devel’ branch and other activities by\nfollowing Bioconductor on Twitter.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2012-2-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2012-2 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2012-12-01",
    "categories": [],
    "contents": "\n\nNew packages in CRAN task views\nBayesian\n\nBVS, Bayesthresh, MISA, bspmma, ggmcmc, growcurves,\nhbsae, pacbpred, rcppbugs, spTimer.\n\nChemPhys\n\nastroFns, cosmoFns, represent.\n\nClinicalTrials\n\nTrialSize\\(^*\\), metaLik.\n\nCluster\n\nBayesLCA, HMMmix, Rmixmod\\(^*\\), longclust, pgmm, teigen.\n\nEconometrics\n\nAutoSEARCH.\n\nFinance\n\nAutoSEARCH, TFX, pa.\n\nHighPerformanceComputing\n\nHiPLARM, pbdBASE, pbdDMAT, pbdMPI, pbdSLAP.\n\nMachineLearning\n\nC50, grpreg.\n\nMedicalImaging\n\nmmand\\(^*\\).\n\nOfficialStatistics\n\nIC2.\n\nOptimization\n\nCLSOCP, DWD, trustOptim.\n\nPhylogenetics\n\nGUniFrac, HMPTrees, PVR, TESS, geomorph, phylotools,\nspider.\n\nPsychometrics\n\nCopyDetect, lava, lava.tobit, rpf, semTools, simsem.\n\nSocialSciences\n\nBradleyTerry2.\n\nSpatial\n\nGriegSmith, OpenStreetMap, ggmap, osmar, plotKML,\nrasterVis, spacetime\\(^*\\), spatialprobit.\n\nSurvival\n\nCR, FHtest, JMLSD, JMbayes, JPSurv, NPHMC, SGL,\nTBSSurvival, TPmsm, TestSurvRec, bpcp,\ncomplex.surv.dat.sim, compound.Cox, crrstep, fastcox,\ngenSurv, jmec, joineR, lava.tobit, mets, survIDINRI,\nsurvSNP.\n\nTimeSeries\n\nCommonTrend, ForeCA, Peak2Trough, TSA, WeightedPortTest,\nastsa, bfast, biwavelet, dlmodeler, x12, x12GUI.\n\ngR\n\nQUIC, R2OpenBUGS, lcd, rjags.\n\n(* = core package)\n1 New contributed packages\nACCLMA\n\nACC & LMA Graph Plotting. Authors: Tal Carmi, Liat Gaziel.\n\nACD\n\nCategorical data analisys with complete or missing responses.\nAuthors: Frederico Zanqueta Poleto, Julio da Mota Singer, Daniel\nCarlos Paulino, Fabio Mathias Correa and Enio Galinkin Jelihovschi.\n\nAID\n\nEstimate Box-Cox Power Transformation Parameter. Authors: Osman Dag,\nOzgur Asar, Ozlem Ilk.\n\nAMAP.Seq\n\nCompare Gene Expressions from 2-Treatment RNA-Seq Experiments.\nAuthor: Yaqing Si.\n\nAOfamilies\n\nAranda-Ordaz (AO) transformation families. Authors: Hakim-Moulay\nDehbi (with contributions from Mario Cortina-Borja and Marco\nGeraci).\n\nAPSIMBatch\n\nAnalysis the output of Apsim software. Author: Bangyou Zheng.\n\nActigraphy\n\nActigraphy Data Analysis. Authors: William Shannon, Tao Li, Hong\nXian, Jia Wang, Elena Deych, Carlos Gonzalez.\n\nActuDistns\n\nFunctions for actuarial scientists. Author: Saralees Nadarajah.\n\nAdequacyModel\n\nAdequacy of models. Authors: Pedro Rafael Diniz Marinho, Cicero\nRafael Barros Dias.\n\nAgreement\n\nStatistical Tools for Measuring Agreement. Author: Yue Yu and\nLawrence Lin.\n\nAlleleRetain\n\nAllele Retention, Inbreeding, and Demography. Author: Emily Weiser.\n\nAncestryMapper\n\nAncestry Mapper. Authors: Tiago Magalhaes, Darren J. Fitzpatrick.\n\nAssetPricing\n\nOptimal pricing of assets with fixed expiry date. Author: Rolf\nTurner.\n\nAtmRay\n\nAcoustic Traveltime Calculations for 1-D Atmospheric Models. Author:\nJake Anderson.\n\nBACprior\n\nSensitivity of the Bayesian Adjustment for Confounding (BAC)\nalgorithm to the choice of hyperparameter omega. Author: Denis jf\nTalbot.\n\nBADER\n\nBayesian Analysis of Differential Expression in RNA Sequencing Data.\nAuthors: Andreas Neudecker, Matthias Katzfuss.\n\nBAEssd\n\nBayesian Average Error approach to Sample Size Determination.\nAuthors: Eric M. Reyes and Sujit K. Ghosh.\n\nBDgraph\n\nGaussian Graphical Model determination based on birth-death MCMC\nmethodology. Authors: Abdolreza Mohammadi and Ernst Wit.\n\nBGSIMD\n\nBlock Gibbs Sampler with Incomplete Multinomial Distribution.\nAuthors: Kwang Woo Ahn, Kung-Sik Chan.\n\nBTYD\n\nImplementing Buy ’Til You Die Models. Authors: Lukasz Dziurzynski\n[aut], Edward Wadsworth [aut], Peter Fader [ctb], Elea\nMcDonnell Feit [cre, ctb], Bruce Hardie [ctb], Arun\nGopalakrishnan [ctb], Eric Schwartz [ctb], Yao Zhang [ctb].\n\nBayesFactor\n\nComputation of Bayes factors for simple designs. Authors: Richard D.\nMorey, Jeffrey N. Rouder.\n\nBayesNI\n\nBayesian Testing Procedure for Noninferiority with Binary Endpoints.\nAuthors: Sujit K Ghosh, Muhtarjan Osman.\n\nBayesthresh\n\nBayesian thresholds mixed-effects models for categorical data.\nAuthors: Fabio Mathias Correa and Julio Silvio de Souza Bueno Filho.\nIn view: Bayesian.\n\nBaylorEdPsych\n\nBaylor University Educational Psychology Quantitative Courses.\nAuthor: A. Alexander Beaujean.\n\nBclim\n\nBayesian Palaeoclimate Reconstruction from Pollen. Authors: Andrew\nParnell, Thinh Doan and James Sweeney.\n\nBiGGR\n\nCreates an interface to BiGG database, provides a framework for\nsimulation and produces flux graphs. Author: Anand K. Gavai.\n\nBigTSP\n\nTop Scoring Pair based methods for classification. Authors: Xiaolin\nYang,Han Liu.\n\nBrq\n\nBayesian analysis of quantile regression models. Author: Rahim\nAlhamzawi.\n\nC50\n\nC5.0 Decision Trees and Rule-Based Models. Authors: Max Kuhn, Steve\nWeston, Nathan Coulter. C code for C5.0 by R. Quinlan. In view:\nMachineLearning.\n\nCARramps\n\nReparameterized and marginalized posterior sampling for conditional\nautoregressive models. Authors: Kate Cowles and Stephen Bonett; with\nthanks to Juan Cervantes, Dong Liang, Alex Sawyer, and Michael\nSeedorff.\n\nCBPS\n\nCovariate Balancing Propensity Score. Authors: Marc Ratkovic, Kosuke\nImai, Christian Fong.\n\nCCM\n\nCorrelation Classification Method. Authors: Garrett M. Dancik and\nYuanbin Ru.\n\nCFL\n\nCompensatory Fuzzy Logic. Authors: Pablo Michel Marin Ortega,\nKornelius Rohmeyer.\n\nCGP\n\nComposite Gaussian Process models. Authors: Shan Ba and V. Roshan\nJoseph.\n\nCHsharp\n\nChoi and Hall Clustering in 3d. Author: Douglas G. Woolford. In\nview: Cluster.\n\nCMC\n\nCronbach-Mesbah Curve. Authors: Michela Cameletti and Valeria\nCaviezel. In view:\nPsychometrics.\n\nCR\n\nPower Calculation for Weighted Log-Rank Tests in Cure Rate Models.\nAuthors: Emil A. Cornea, Bahjat F. Qaqish, and Joseph G. Ibrahim. In\nview: Survival.\n\nCVST\n\nFast Cross-Validation via Sequential Testing. Authors: Tammo\nKrueger, Mikio Braun.\n\nCarbonEL\n\nCarbon Event Loop. Author: Simon Urbanek.\n\nCensRegMod\n\nFitting Normal and Student-t censored regression model. Authors:\nMonique Bettio Massuia, Larissa Avila Matos and Victor Lachos.\n\nChangeAnomalyDetection\n\nChange Anomaly Detection. Author: Yohei Sato.\n\nCombMSC\n\nCombined Model Selection Criteria. Author: Andrew K. Smith.\n\nCompLognormal\n\nFunctions for actuarial scientists. Author: Saralees Nadarajah.\n\nCompareTests\n\nEstimate diagnostic accuracy (sensitivity, specificity, etc) and\nagreement statistics when one test is conducted on only a subsample\nof specimens. Authors: Hormuzd A. Katki and David W. Edelstein.\n\nCopulaRegression\n\nBivariate Copula Based Regression Models. Authors: Nicole Kraemer,\nDaniel Silvestrini.\n\nCopyDetect\n\nComputing Statistical Indices to Detect Answer Copying on\nMultiple-Choice Tests. Author: Cengiz Zopluoglu. In view:\nPsychometrics.\n\nCorrBin\n\nNonparametrics with clustered binary data. Author: Aniko Szabo.\n\nDBKGrad\n\nDiscrete Beta Kernel Graduation of mortality data. Authors: Angelo\nMazza and Antonio Punzo.\n\nDIME\n\nDifferential Identification using Mixture Ensemble. Authors: Cenny\nTaslim, with contributions from Dustin Potter, Abbasali Khalili and\nShili Lin.\n\nDeducer\n\nAuthor: Ian Fellows with contributions from others (see\ndocumentation).\n\nDeducerSurvival\n\nAdd Survival Dialogue to Deducer. Authors: Matthew Ockendon, Paul\nCool.\n\nDeducerText\n\nDeducer GUI for Text Data. Authors: Alex Rickett and Ian Fellows,\nwith contributions from Neal Fultz.\n\nDiscreteInverseWeibull\n\nDiscrete inverse Weibull distribution. Authors: Alessandro Barbiero,\nRiccardo Inchingolo.\n\nDiscriMiner\n\nTools of the Trade for Discriminant Analysis. Author: Gaston\nSanchez.\n\nDivMelt\n\nHRM Diversity Assay Analysis Tool. Authors: David Swan with\ncontributions from Craig A Magaret and Matthew M Cousins.\n\nDnE\n\nDistribution and Equation. Authors: Junyao Chen, Cuiyi He, Yuanrui\nWu, Mengqing Sun.\n\nDynClust\n\nNon-parametric denoising and clustering method of noisy images both\nindexed by time and space. Authors: Tiffany Lieury, Christophe\nPouzat, Yves Rozenholc.\n\nEBMAforecast\n\nEnsemble BMA Forecasting. Authors: Jacob M. Montgomery, Florian\nHollenbach, and Michael D. Ward.\n\nEBS\n\nExact Bayesian Segmentation. Author: Alice Cleynen.\n\nEDISON\n\nSoftware for network reconstruction and changepoint detection.\nAuthors: Frank Dondelinger, Sophie Lebre.\n\nEDanalysis\n\nGene Enrichment Disequilibrium Analysis. Author: Yongshuai Jiang.\n\nENA\n\nEnsemble Network Aggregation. Author: Jeffrey D. Allen.\n\nETAS\n\nModeling earthquake data using Epidemic Type Aftershock Sequence\nmodel. Authors: Abdollah Jalilian, based on Fortran code by Jiancang\nZhuang.\n\nEasyABC\n\nEasyABC: performing efficient approximate Bayesian computation\nsampling schemes. Authors: Franck Jabot, Thierry Faure, Nicolas\nDumoullin.\n\nEpiContactTrace\n\nEpidemiological tool for contact tracing. Author: Stefan Widgren,\nMaria Noremark.\n\nExPD2D\n\nExact Computation of Bivariate Projection Depth Based on Fortran\nCode. Authors: Yijun Zuo, Xiangyang Ye.\n\nExPosition\n\nExploratory analysis with the singular value decomposition. Authors:\nDerek Beaton, Cherise R. Chin Fatt, Herve Abdi.\n\nFHtest\n\nTests for right and interval-censored survival data based on the\nFleming-Harrington class. Authors: Ramon Oller, Klaus Langohr. In\nview: Survival.\n\nFMStable\n\nFinite Moment Stable Distributions. Author: Geoff Robinson.\n\nFRACTION\n\nNumeric number into fraction. Author: OuYang Ming.\n\nFRCC\n\nFast Regularized Canonical Correlation Analysis. Author: Raul\nCruz-Cano.\n\nFWDselect\n\nSelecting variables in regression models. Authors: Marta Sestelo,\nNora M. Villanueva, Javier Roca-Pardinas.\n\nFactMixtAnalysis\n\nFactor Mixture Analysis with covariates. Author: Cinzia Viroli.\n\nFinancialInstrument\n\nFinancial Instrument Model Infrastructure for R. Authors: Peter\nCarl, Dirk Eddelbuettel, Jeffrey Ryan, Joshua Ulrich, Brian G.\nPeterson, Garrett See.\n\nFindAllRoots\n\nFind all root(s) of the equation and Find root(s) of the equation by\ndichotomy. Author: Bingpei Wu, Jiajun He, Sijie Chen, Yangyang Liu.\n\nFormalSeries\n\nElementary arithemtic in formal series rings. Author: Tomasz\nZmorzynski.\n\nFourScores\n\nA game for two players. Author: Matthias Speidel.\n\nGA\n\nGenetic Algorithms. Author: Luca Scrucca.\n\nGA4Stratification\n\nA genetic algorithm approach to determine stratum boundaries and\nsample sizes of each stratum in stratified sampling. Authors: Sebnem\nEr, Timur Keskinturk, Charlie Daly.\n\nGANPAdata\n\nThe GANPA Datasets Package. Authors: Zhaoyuan Fang, Weidong Tian and\nHongbin Ji.\n\nGENEAread\n\nReading Binary files. Author: Zhou Fang.\n\nGISTools\n\nSome further GIS capabilities for R. Authors: Chris Brunsdon and\nHongyan Chen.\n\nGLDEX\n\nFitting Single and Mixture of Generalised Lambda Distributions (RS\nand FMKL) using Various Methods. Authors: Steve Su, with\ncontributions from: Diethelm Wuertz, Martin Maechler and Rmetrics\ncore team members for low discrepancy algorithm, Juha Karvanen for L\nmoments codes, Robert King for gld C codes and starship codes,\nBenjamin Dean for corrections and input in ks.gof code and R core\nteam for histsu function.\n\nGOFSN\n\nGoodness-of-fit tests for the family of skew-normal models. Author:\nVeronica Paton Romero.\n\nGPfit\n\nGaussian Process Modeling. Authors: Blake MacDoanld, Hugh Chipman,\nPritam Ranjan.\n\nGWASExactHW\n\nExact Hardy-Weinburg testing for Genome Wide Association Studies.\nAuthor: Ian Painter.\n\nGeneF\n\nGeneralized F-statistics. Author: Yinglei Lai.\n\nGiza\n\nConstructing panels of population pyramid plots based on lattice.\nAuthor: Erich Striessnig.\n\nHGNChelper\n\nHandy functions for working with HGNC gene symbols and Affymetrix\nprobeset identifiers. Authors: Levi Waldron and Markus Riester.\n\nHIBAG\n\nHLA Genotype Imputation with Attribute Bagging. Author: Xiuwen\nZheng.\n\nHMMmix\n\nHMM with mixture of gaussians as emission distribution. Authors:\nStevenn Volant and Caroline Berard. In view:\nCluster.\n\nHPO.db\n\nA set of annotation maps describing the Human Phenotype Ontology.\nAuthor: Yue Deng.\n\nHPbayes\n\nHeligman Pollard mortality model parameter estimation using Bayesian\nMelding with Incremental Mixture Importance Sampling. Author: David\nJ Sharrow.\n\nHW.pval\n\nTesting Hardy-Weinberg Equilibrium for Multiallelic Genes. Author:\nShubhodeep Mukherji.\n\nHandTill2001\n\nMultiple Class Area under ROC Curve. Authors: Andreas Dominik\nCullmann [aut, cre], Edgar Kublin [ctb].\n\nHiPLARM\n\nHigh Performance Linear Algebra in R. Authors: Peter Nash and Vendel\nSzeremi. In view:\nHighPerformanceComputing.\n\nHotelling\n\nHotelling’s T-squared test and variants. Author: James Curran.\n\nHyPhy\n\nMacroevolutionary phylogentic analysis of species trees and gene\ntrees. Author: Nathaniel Malachi Hallinan.\n\nHydroMe\n\nEstimation of Soil Hydraulic Parameters from Experimental Data.\nAuthor: Christian Thine Omuto. In view:\nEnvironmetrics.\n\nISDA.R\n\ninterval symbolic data analysis for R. Authors: Ricardo Jorge de\nAlmeida Queiroz Filho, Roberta Andrade de Araujo Fagundes.\n\nImpactIV\n\nIdentifying Causal Effect for Multi-Component Intervention Using\nInstrumental Variable Method. Author: Peng Ding.\n\nIndependenceTests\n\nNonparametric tests of independence between random vectors. Authors:\nP Lafaye de Micheaux, M Bilodeau.\n\nInfDim\n\nInfine-dimensional model (IDM) to analyse phenotypic variation in\ngrowth trajectories. Authors: Anna Kuparinen, Mats Bjorklund.\n\nInteract\n\nTests for marginal interactions in a 2 class response model.\nAuthors: Noah Simon and Robert Tibshirani.\n\nJASPAR\n\nR modules for JASPAR databases: a collection of transcription factor\nDNA-binding preferences, modeled as matrices. Author: Xiaobei Zhao.\n\nJGL\n\nPerforms the Joint Graphical Lasso for sparse inverse covariance\nestimation on multiple classes. Author: Patrick Danaher.\n\nJMbayes\n\nJoint Modeling of Longitudinal and Time-to-Event Data under a\nBayesian Approach. Author: Dimitris Rizopoulos. In view:\nSurvival.\n\nJulia\n\nFractal Image Data Generator. Author: Mehmet Suzen.\n\nKpart\n\nSpline Fitting. Author: Eric Golinko.\n\nLDdiag\n\nLink Function and Distribution Diagnostic Test for Social Science\nResearchers. Author: Yongmei Ni.\n\nLICORS\n\nLight Cone Reconstruction of States — Predictive State Estimation\nFrom Spatio-Temporal Data. Author: Georg M. Goerg.\n\nLIStest\n\nLongest Increasing Subsequence Independence Test. Authors: Jesus\nGarcia and Veronica Andrea Gonzalez Lopez.\n\nLMest\n\nFit Latent Markov models in basic versions. Author: Francesco\nBartolucci.\n\nLN3GV\n\nAuthor: Steve Lund.\n\nLSC\n\nLocal Statistical Complexity — Automatic Pattern Discovery in\nSpatio-Temporal Data. Author: Georg M. Goerg.\n\nLTR\n\nPerform LTR analysis on microarray data. Author: Paul C. Boutros.\n\nLaterality\n\nAuthors: Borel A., Pouydebat E., Reghem E.\n\nLifeTables\n\nImplement HMD model life table system. Authors: David J. Sharrow,\nGUI by Hana Sevcikova.\n\nMATTOOLS\n\nModern Calibration Functions for the Modern Analog Technique (MAT).\nAuthor: M. Sawada.\n\nMBCluster.Seq\n\nModel-Based Clustering for RNA-seq Data. Author: Yaqing Si.\n\nMBI\n\n(M)ultiple-site (B)iodiversity (I)ndices Calculator. Author: Youhua\nChen.\n\nMBmca\n\nNucleic Acid Melting Curve Analysis on Microbead Surfaces with R.\nAuthor: Stefan Roediger.\n\nMCUSUM\n\nMultivariate Cumulative Sum (MCUSUM) Control Chart. Author: Edgar\nSantos Fernandez.\n\nMDSGUI\n\nA GUI for interactive MDS in R. Authors: Andrew Timm and Sugnet\nGardner-Lubbe.\n\nMESS\n\nMiscellaneous esoteric statistical scripts. Author: Claus Ekstrom.\n\nMEWMA\n\nMultivariate Exponentially Weighted Moving Average (MEWMA) Control\nChart. Author: Edgar Santos Fernandez.\n\nMExPosition\n\nMulti-table ExPosition. Authors: Cherise R. Chin Fatt, Derek Beaton,\nHerve Abdi.\n\nMMS\n\nFixed effects Selection in Linear Mixed Models. Author: F. Rohart.\n\nMPDiR\n\nData sets and scripts for Modeling Psychophysical Data in R.\nAuthors: Kenneth Knoblauch and Laurence T. Maloney.\n\nMSQC\n\nMultivariate Statistical Quality Control. Author: Edgar\nSantos-Fernandez.\n\nMTurkR\n\nAccess to Amazon Mechanical Turk Requester API via R. Author:\nThomas J. Leeper.\n\nMVB\n\nMutivariate Bernoulli log-linear model. Author: Bin Dai.\n\nMeDiChI\n\nMeDiChI ChIP-chip deconvolution library. Author: David J Reiss.\n\nMetrics\n\nEvaluation metrics for machine learning. Author: Ben Hamner.\n\nMindOnStats\n\nData sets included in Utts and Heckard’s Mind on Statistics. Author:\nJonathan Godfrey.\n\nMiney\n\nImplementation of the Well-Known Game to Clear Bombs from a Given\nField (Matrix). Author: Roland Rau.\n\nMitISEM\n\nMixture of Student t Distributions using Importance Sampling and\nExpectation Maximization. Authors: N. Basturk, L.F. Hoogerheide, A.\nOpschoor, H.K. van Dijk.\n\nMultiChIPmixHMM\n\nAuthor: Caroline Berard.\n\nMultiLCIRT\n\nMultidimensional latent class Item Response Theory models. Authors:\nFrancesco Bartolucci, Silvia Bacci, Michela Gnaldi.\n\nNLRoot\n\nSearching for the root of equation. Authors: Zheng Sengui, Lu Xufen,\nHou Qiongchen, Zheng Jianhui.\n\nNMRS\n\nNMR Spectroscopy. Author: Jose L. Izquierdo. In view:\nChemPhys.\n\nNPHMC\n\nSample Size Calculation for the Proportional Hazards Cure Model.\nAuthors: Chao Cai, Songfeng Wang, Wenbin Lu, Jiajia Zhang. In view:\nSurvival.\n\nNPMPM\n\nTertiary probabilistic model in predictive microbiology for use in\nfood manufacture. Author: Nadine Schoene.\n\nNScluster\n\nSimulation and Estimation of the Neyman-Scott Type Spatial Cluster\nModels. Authors: The Institute of Statistical Mathematics, based on\nthe program by Ushio Tanaka.\n\nNonpModelCheck\n\nModel Checking and Variable Selection in Nonparametric Regression.\nAuthor: Adriano Zanin Zambom.\n\nOPE\n\nOuter-product emulator. Author: Jonathan Rougier.\n\nOPI\n\nOpen Perimetry Interface. Author: Andrew Turpin.\n\nORDER2PARENT\n\nEstimate parent distributions with data of several order statistics.\nAuthor: Cheng Chou.\n\nPAS\n\nPolygenic Analysis System (PAS). Author: Zhiqiu Hu; Shizhong Xu;\nZhiquan Wang; Rongcai Yang.\n\nPCS\n\nCalculate the probability of correct selection (PCS). Author: Jason\nWilson.\n\nPDSCE\n\nPositive definite sparse covariance estimators. Author: Adam J.\nRothman.\n\nPF\n\nFunctions related to prevented fraction. Author: Dave Siev.\n\nPKI\n\nPublic Key Infrastucture for R based on the X.509 standard. Author:\nSimon Urbanek.\n\nPKmodelFinder\n\nSoftware for Pharmacokinetic model. Authors: Eun-Kyung Lee, Gyujeong\nNoh, Hyeong-Seok Lim.\n\nPLIS\n\nMultiplicity control using Pooled LIS statistic. Author: Zhi Wei,\nWenguang Sun.\n\nPOET\n\nPrincipal Orthogonal ComplEment Thresholding (POET) method. Authors:\nJianqing Fan, Yuan Liao, Martina Mincheva.\n\nPPtree\n\nProjection pursuit classification tree. Authors: Eun-Kyung Lee,\nYoondong Lee.\n\nPRISMA\n\nProtocol Inspection and State Machine Analysis. Authors: Tammo\nKrueger, Nicole Kraemer.\n\nPSCN\n\nParent Specific DNA Copy Number Estimation. Authors: Hao Chen,\nHaipeng Xing, and Nancy R. Zhang.\n\nPVAClone\n\nPopulation Viability Analysis with Data Cloning. Authors: Khurram\nNadeem, Peter Solymos.\n\nPVR\n\nComputes Phylogenetic eigenVectors Regression and Phylogentic\nSignal-Representation curve (with null and Brownian expectancies).\nAuthors: Thiago Santos, Jose Alexandre Diniz-Filho, Thiago Rangel\nand Luis Mauricio Bini. In view:\nPhylogenetics.\n\nPeaks\n\nAuthor: Miroslav Morhac. In view:\nChemPhys.\n\nPenLNM\n\nGroup l1 penalized logistic normal multinomial (LNM) regression\nmodel. Author: Fan Xia.\n\nPermAlgo\n\nPermutational algorithm to simulate survival data. Authors:\nMarie-Pierre Sylvestre, Thad Edens, Todd MacKenzie, Michal\nAbrahamowicz. In view:\nSurvival.\n\nPlayerRatings\n\nDynamic Updating Methods For Player Ratings Estimation. Authors:\nAlec Stephenson and Jeff Sonas.\n\nPopGenKit\n\nUseful functions for (batch) file conversion and data resampling in\nmicrosatellite datasets. Author: Sebastien Rioux Paquette.\n\nPopGenReport\n\nPopGen: A simple way to analyse and visualize population genetic\ndata. Author: Aaron Adamack, Bernd Gruber.\n\nProgGUIinR\n\nSupport package for “Programming Graphical User Interfaces in R”.\nAuthors: Michael Lawrence and John Verzani.\n\nQLSpline\n\nAuthor: Steve Lund.\n\nR0\n\nEstimation of R0 and real-time reproduction number from epidemics.\nAuthors: Pierre-Yves Boelle, Thomas Obadia.\n\nR1magic\n\nCompressive Sampling: Sparse signal recovery utilities. Author:\nMehmet Suzen.\n\nR2MLwiN\n\nRunning MLwiN from within R. Authors: Zhengzheng Zhang, Chris\nCharlton, Richard Parker, George Leckie, William Browne.\n\nRAMpath\n\nAuthors: Zhiyong Zhang, Jack McArdle, Aki Hamagami, & Kevin Grimm.\n\nRAppArmor\n\nAuthor: Jeroen Ooms.\n\nRAtmosphere\n\nStandard Atmosperic profiles. Author: Gionata Biavati.\n\nRDF\n\nRDF reading and writing. Author: Willem Robert van Hage.\n\nREPPlab\n\nR interface to EPP-lab, a Java program for exploratory projection\npursuit. Authors: Daniel Fischer, Alain Berro, Klaus Nordhausen,\nAnne Ruiz-Gazen.\n\nRGCCA\n\nRegularized Generalized Canonical Correlation Analysis. Author:\nArthur Tenenhaus.\n\nRHT\n\nRegularized Hotelling’s T-square Test for Pathway (Gene Set)\nAnalysis. Authors: Lin S. Chen and Pei Wang.\n\nROCwoGS\n\nNon-parametric estimation of ROC curves without Gold Standard Test.\nAuthor: Chong Wang.\n\nRPCLR\n\nRPCLR (Random-Penalized Conditional Logistic Regression). Author:\nRaji Balasubramanian.\n\nRSclient\n\nClient for Rserve. Author: Simon Urbanek.\n\nRTriangle\n\nA 2D Quality Mesh Generator and Delaunay Triangulator. Authors:\nJonathan Shewchuk, David C. Sterratt.\n\nRVideoPoker\n\nPlay Video Poker with R. Authors: Roland Rau; cards were created by\nByron Knoll.\n\nRVtests\n\nRare Variant Tests Using Multiple Regression Methods. Authors: C.\nXu, C. M. Greenwood.\n\nRandForestGUI\n\nAuthors: Rory Michelland, Genevieve Grundmann.\n\nRarity\n\nCalculation of rarity indices for species and assemblages of\nspecies. Author: Boris Leroy.\n\nRchemcpp\n\nR interface for the ChemCpp library. Authors: Michael Mahr, Guenter\nKlambauer.\n\nRcmdrPlugin.EACSPIR\n\nPlugin de R-Commander para el manual EACSPIR. Authors: Maribel Peró,\nDavid Leiva, Joan Guàrdia, Antonio Solanas.\n\nRcmdrPlugin.MPAStats\n\nR Commander Plug-in for MPA Statistics. Author: Andrew Heiss.\n\nRcmdrPlugin.PT\n\nSome discrete exponential dispersion models: Poisson-Tweedie.\nAuthors: David Pechel Cactcha, Laure Pauline Fotso and Celestin C\nKokonendji.\n\nRcmdrPlugin.SLC\n\nSLC Rcmdr Plug-in. Authors: Antonio Solanas, Rumen Manolov.\n\nRcmdrPlugin.StatisticalURV\n\nStatistical URV Rcmdr Plug-In. Author: Daniela Vicente.\n\nRcmdrPlugin.TextMining\n\nR commander plugin for tm package. Author: Dzemil Lusija. In view:\nNaturalLanguageProcessing.\n\nRcmdrPlugin.coin\n\nRcmdr coin Plug-In. Author: Daniel-Corneliu Leucuta.\n\nRcmdrPlugin.depthTools\n\nR commander Depth Tools Plug-In. Authors: Sara Lopez-Pintado and\nAurora Torrente.\n\nRcppCNPy\n\nRcpp bindings for NumPy files. Author: Dirk Eddelbuettel.\n\nRcppOctave\n\nSeamless Interface to Octave and Matlab. Author: Renaud Gaujoux.\n\nRdpack\n\nUpdate and manipulate Rd documentation objects. Author: Georgi N.\nBoshnakov.\n\nRearrangement\n\nMonotonize point and interval functional estimates by rearrangement.\nAuthors: Wesley Graybill, Mingli Chen, Victor Chernozhukov, Ivan\nFernandez-Val, Alfred Galichon.\n\nRecords\n\nRecord Values and Record Times. Author: Magdalena Chrapek.\n\nReliabilityTheory\n\nTools for structural reliability analysis. Author: Louis Aslett.\n\nRidit\n\nRidit Analysis (An extension of the Kruskal-Wallis Test.). Author:\nSeyedMahmood TaghaviShahri.\n\nRivivc\n\nIn vitro in vivo correlation linear level A. Authors: Aleksander\nMendyk, Sebastian Polak.\n\nRsundials\n\nSuite of Nonlinear Differential Algebraic Equations Solvers in R.\nAuthor: Selwyn-Lloyd McPherson.\n\nRttf2pt1\n\nPackage for ttf2pt1 program. Authors: Winston Chang, Andrew Weeks,\nFrank M. Siegert, Mark Heath, Thomas Henlick, Sergey Babkin, Turgut\nUyar, Rihardas Hepas, Szalay Tamas, Johan Vromans, Petr Titera, Lei\nWang, Chen Xiangyang, Zvezdan Petkovic, Rigel, I. Lee Hetherington.\n\nRvelslant\n\nDownhole Seismic Analysis in R. Authors: Original method by Dave\nBoore, R port and some additions by Eric M. Thompson.\n\nSAM\n\nSparse Additive Machine. Authors: Tuo Zhao, Xingguo Li, Han Liu, Lie\nWang, Kathryn Roeder.\n\nSECP\n\nStatistical Estimation of Cluster Parameters (SECP). Author:\nPavel V. Moskalev.\n\nSEERaBomb\n\nSEER Setup and Use with A-Bomb Data. Author: Tomas Radivoyevitch.\n\nSMR\n\nStudentized Midrange Distribution. Authors: Ben Deivide de Oliveira\nBatista, Daniel Furtado Ferreira.\n\nSTARSEQ\n\nSecondary Trait Association analysis for Rare variants via SEQuence\ndata. Author: Dajiang Liu.\n\nSWATmodel\n\nA multi-OS implementation of the TAMU SWAT model. Authors: Fuka, DR,\nWalter, MT, and Easton, ZM.\n\nScreenClean\n\nScreen and clean variable selection procedures. Authors: Pengsheng\nJi, Jiashun Jin, Qi Zhang.\n\nSegmentor3IsBack\n\nA Fast Segmentation Algorithm. Authors: Alice Cleynen, Guillem\nRigaill, Michel Koskas.\n\nSejong\n\nKoNLP static dictionaries and Sejong project resources. Author:\nHeewon Jeon.\n\nSensitivityCaseControl\n\nSensitivity Analysis for Case-Control Studies. Author: Dylan Small.\n\nSeqGrapheR\n\nSimple GUI for graph based visualization of cluster of DNA sequence\nreads. Author: Petr Novak.\n\nSimCorMultRes\n\nSimulates Correlated Multinomial Responses. Author: Anestis\nTouloumis.\n\nSimpsons\n\nDetecting Simpson’s Paradox. Author: Rogier Kievit, Sacha Epskamp.\n\nSimultAnR\n\nCorrespondence and Simultaneous Analysis. Authors: Amaya Zarraga,\nBeatriz Goitisolo.\n\nSleuth3\n\nData sets from Ramsey and Schafer’s “Statistical Sleuth (3rd ed)”.\nAuthors: Original by F.L. Ramsey and D.W. Schafer, modifications by\nDaniel W. Schafer, Jeannie Sifneos and Berwin A. Turlach.\n\nSmarterPoland\n\nA set of tools developed by the Foundation SmarterPoland.pl. Author:\nPrzemyslaw Biecek.\n\nSpatialPack\n\nAnalysis of spatial data. Authors: Felipe Osorio, Ronny Vallejos,\nand Francisco Cuevas.\n\nStem\n\nSpatio-temporal models in R. Author: Michela Cameletti. In view:\nSpatial.\n\nStressStrength\n\nComputation and estimation of reliability of stress-strength models.\nAuthors: Alessandro Barbiero, Riccardo Inchingolo.\n\nTAHMMAnnot\n\nMixture model approach to compare two samples of Tiling Array data.\nAuthor: Caroline Berard.\n\nTANOVA\n\nTime Course Analysis of Variance for Microarray. Authors: Baiyu Zhou\nand Weihong Xu.\n\nTBSSurvival\n\nTBS Model R package. Authors: Adriano Polpo, Cassio de Campos, D.\nSinha, Stuart Lipsitz, Jianchang Lin. In view:\nSurvival.\n\nTERAplusB\n\nTest for A+B Traditional Escalation Rule. Author: Eun-Kyung Lee.\n\nTESS\n\nFast simulation of reconstructed phylogenetic trees under\ntime-dependent birth-death processes. Author: Sebastian Hoehna. In\nview:\nPhylogenetics.\n\nTExPosition\n\nTwo-table ExPosition. Authors: Derek Beaton, Jenny Rieck, Cherise R.\nChin Fatt, Herve Abdi.\n\nTFX\n\nR API to TrueFX(tm). Author: Garrett See. In view:\nFinance.\n\nTPmsm\n\nEstimation of transitions probabilities in multistate models.\nAuthors: Artur Agostinho Araujo, Javier Roca-Pardinas and Luis\nMeira-Machado. In view:\nSurvival.\n\nTRIANGG\n\nGeneral discrete triangular distribution. Authors: Tristan Senga\nKiessé, Francial G. Libengué, Silvio S. Zocchi, Célestin C.\nKokonendji.\n\nTSEN\n\nTwo-dimensional peak sentinel tool for GC x GC-HRTOFMS. Author:\nYasuyuki Zushi.\n\nTSPC\n\nPrediction using time-course gene expression. Author: Yuping Zhang.\n\nTScompare\n\nTSdbi Comparison. Author: Paul Gilbert.\n\nTSdata\n\nTSdbi Illustration. Author: Paul Gilbert.\n\nThreeWay\n\nThree-way component analysis. Authors: Maria Antonietta Del Ferraro,\nHenk A.L. Kiers, Paolo Giordani.\n\nTrialSize\n\nAuthor: Ed Zhang. In view:\nClinicalTrials.\n\nTsphere\n\nTransposable Sphering for Large-Scale Inference with Correlated\nData. Author: Genevera I. Allen.\n\nTukeyC\n\nConventional Tukey Test. Authors: Jose Claudio Faria, Enio\nJelihovschi and Ivan Bezerra Allaman.\n\nTwoCop\n\nNonparametric test of equality between two copulas. Authors: Bruno\nRemillard and Jean-Francois Plante.\n\nUScensus2000blkgrp\n\nUS Census 2000 Block Group Shapefiles and Additional Demographic\nData. Author: Zack W. Almquist. In view:\nSpatial.\n\nVBMA4hmm\n\nVariational Bayesian Markov Model for hidden markov model. Author:\nStevenn Volant.\n\nVDA\n\nAuthors: Edward Grant, Xia Li, Kenneth Lange, Tong Tong Wu.\n\nVIM\n\nVisualization and Imputation of Missing Values. Authors: Matthias\nTempl, Andreas Alfons, Alexander Kowarik, Bernd Prantner. In views:\nMultivariate,\nOfficialStatistics.\n\nVineCopula\n\nStatistical inference of vine copulas. Authors: Ulf Schepsmeier,\nJakob Stoeber, Eike Christian Brechmann.\n\nVizCompX\n\nVisualisation of Computer Models. Author: Neil Diamond.\n\nW2CWM2C\n\nA set of functions to produce new graphical tools for wavelet\ncorrelation (bivariate and multivariate cases) using some routines\nfrom the waveslim and wavemulcor packages. Author: Josue Moises\nPolanco-Martinez.\n\nWCQ\n\nDetection of QTL effects in a small mapping population. Author: Jan\nMichael Yap.\n\nWMDB\n\nDiscriminant Analysis Methods by Weight Mahalanobis Distance and\nbayes. Author: Bingpei Wu.\n\nWaveCD\n\nWavelet change point detection for array CGH data. Author: M.\nShahidul Islam.\n\nWaveletCo\n\nWavelet Coherence Analysis. Author: Huidong Tian; Bernard Cazelles.\n\nZeligChoice\n\nZelig Choice Models. Authors: Matt Owen, Kosuke Imai, Olivia Lau\nand Gary King.\n\nZeligGAM\n\nGenereal Additive Models for Zelig. Authors: Matthew Owen, Skyler\nCranmer, Olivia Lau, Kosuke Imai and Gary King.\n\nZeligMultilevel\n\nMultilevel Regressions for Zelig. Authors: Matthew Owen, Ferdinand\nAlimadhi, Delia Bailey.\n\nadaptsmoFMRI\n\nAdaptive Smoothing of FMRI Data. Author: Max Hughes.\n\nafex\n\nAnalysis of Factorial Experiments. Author: Henrik Singmann.\n\naftgee\n\nAccelerated Failure Time Model with Generalized Estimating\nEquations. Authors: Sy Han (Steven) Chiou, Sangwook Kang, Jun Yan.\n\nagRee\n\nVarious Methods for Measuring Agreement. Author: Dai Feng.\n\nageprior\n\nPrior distributions for molecular dating. Author: Michael\nMatschiner.\n\naggrisk\n\nEstimate individual level risk using individual case data and\nspatially aggregated control data. Authors: Michelle Stanton,\nYongtao Guan.\n\nallanvar\n\nAllan Variance Analysis. Author: Javier Hidalgo Carrio.\n\namen\n\nAdditive and multiplicative effects modeling of networks and\nrelational data. Authors: Peter Hoff, Bailey Fosdick, Alex\nVolfovsky, Kate Stovel.\n\nanaglyph\n\n3D Anaglyph Plots. Author: Jonathan Lee.\n\nandrews\n\nAndrews curves. Author: Jaroslav Myslivec.\n\nantitrust\n\nAuthors: Michael Sandfort and Charles Taragin.\n\naqr\n\nInterface methods to access use an ActiveQuant Master Server.\nAuthor: Ulrich Staudinger.\n\nasd\n\nSimulations for adaptive seamless designs. Author: Nick parsons. In\nviews:\nClinicalTrials,\nExperimentalDesign.\n\nastroFns\n\nMiscellaneous astronomy functions, utilities, and data. Author:\nAndrew Harris. In view:\nChemPhys.\n\nastsa\n\nApplied Statistical Time Series Analysis. Author: David Stoffer. In\nview: TimeSeries.\n\nattfad\n\nEvaluation and comparison of expression data and GRNs. Author:\nRobert Maier.\n\naudit\n\nBounds for Accounting Populations. Author: Glen Meeden.\n\nautopls\n\npls regression with backward selection of predictors. Authors:\nSebastian Schmidtlein, with contributions from Carsten Oldenburg and\nHannes Feilhauer.\n\nbReeze\n\nFunctions for wind resource assessment. Authors: Christian Graul and\nCarsten Poppinga.\n\nbase64enc\n\nTools for base64 encoding. Author: Simon Urbanek.\n\nbatade\n\nHTML reports and so on. Author: Ichikawa Daisuke.\n\nbatchmeans\n\nConsistent Batch Means Estimation of Monte Carlo Standard Errors.\nAuthors: Murali Haran and John Hughes.\n\nbayesGDS\n\nFunctions to implement Generalized Direct Sampling. Author: Michael\nBraun.\n\nbayespref\n\nHierarchical Bayesian analysis of ecological count data. Authors:\nZachariah Gompert and James A. Fordyce.\n\nbc3net\n\nAuthors: Ricardo de Matos Simoes and Frank Emmert-Streib.\n\nbdpv\n\nInference and design for predictive values in binary diagnostic\ntests. Author: Frank Schaarschmidt.\n\nbeadarrayFilter\n\nBead filtering for Illumina bead arrays. Authors: Anyiawung Chiara\nForcheh, Geert Verbeke, Adetayo Kasim, Dan Lin, Ziv Shkedy, Willem\nTalloen, Hinrich WH Gohlmann, Lieven Clement.\n\nbetafam\n\nDetecting rare variants for quantitative traits using nuclear\nfamilies. Author: Wei Guo.\n\nbiasbetareg\n\nBias correction of the parameter estimates of the beta regression\nmodel. Author: Luana Cecilia Meireles.\n\nbigmemory.sri\n\nA shared resource interface for Bigmemory Project packages. Author:\nMichael J. Kane.\n\nbimetallic\n\nPower for SNP analyses using silver standard cases. Author: Andrew\nMcDavid.\n\nbinhf\n\nHaar-Fisz functions for binomial data. Author: Matt Nunes.\n\nbinomialcftp\n\nGenerates binomial random numbers via the coupling from the past\nalgorithm. Author: Francisco Juretig.\n\nbinseqtest\n\nExact Binary Sequential Designs and Analysis. Authors: Jenn Kirk,\nMike Fay.\n\nbiomod2\n\nEnsemble platform for species distribution modeling. Authors:\nWilfried Thuiller, Damien Georges and Robin Engler.\n\nbise\n\nAuxiliary functions for phenological data analysis. Author: Daniel\nDoktor.\n\nbiseVec\n\nAuxiliary functions for phenological data analysis. Author:\nMaximilian Lange.\n\nbisoreg\n\nBayesian Isotonic Regression with Bernstein Polynomials. Author: S.\nMcKay Curtis. In view:\nBayesian.\n\nbivarRIpower\n\nSample size calculations for bivariate longitudinal data.\nAuthors: W. Scott Comulada and Robert E. Weiss.\n\nbiwt\n\nFunctions to compute the biweight mean vector and covariance &\ncorrelation matrices. Author: Jo Hardin.\n\nblockcluster\n\nCo-Clustering for Binary, Contingency and Continuous data-sets.\nAuthors: Parmeet Bhatia, Serge Iovleff and Gerard Goavert, with\ncontributions from Christophe Biernacki and Gilles Celeux.\n\nbmk\n\nMCMC diagnostics. Authors: Matthew Krachey and Edward L. Boone.\n\nboostSeq\n\nOptimized GWAS cohort subset selection for resequencing studies.\nAuthor: Milan Hiersche.\n\nbootES\n\nBootstrap Effect Sizes. Authors: Daniel Gerlanc and Kris Kirby.\n\nbootfs\n\nUse multiple feature selection algorithms to derive robust feature\nsets for two class classification problems. Author: Christian\nBender.\n\nbpcp\n\nBeta Product Confidence Procedure for Right Censored Data. Author:\nMichael Fay. In view:\nSurvival.\n\nbreakage\n\nSICM pipette tip geometry estimation. Author: Matthew Caldwell.\n\nbroman\n\nKarl Broman’s R code. Author: Karl W Broman.\n\nbspmma\n\nBayesian Semiparametric Models for Meta-Analysis. Author: Deborah\nBurr. In view:\nBayesian.\n\nbursts\n\nMarkov model for bursty behavior in streams. Author: Jeff Binder.\n\nbvenn\n\nA Simple alternative to proportional Venn diagrams. Author: Raivo\nKolde.\n\ncancerTiming\n\nEstimation of temporal ordering of cancer abnormalities. Author:\nElizabeth Purdom.\n\ncapme\n\nCovariate Adjusted Precision Matrix Estimation. Authors: T. Tony\nCai, Hongzhe Li, Weidong Liu and Jichun Xie.\n\ncapwire\n\nEstimates population size from non-invasive sampling. Authors:\nMatthew W. Pennell and Craig R. Miller.\n\ncarcass\n\nEstimation of the number of fatalities from carcass searches.\nAuthors: Fraenzi Korner-Nievergelt, Ivo Niermann, Oliver Behr,\nRobert Brinkmann, Pius Korner, Barbara Hellriegel, Manuela Huso.\n\ncaspar\n\nClustered and sparse regression (CaSpaR). Author: Daniel Percival.\n\ncatIrt\n\nSimulating IRT-Based Computerized Adaptive Tests. Author: Steven W.\nNydick.\n\nccChooser\n\nDeveloping core collections. Authors: Marcin Studnicki and Konrad\nDebski.\n\nccaPP\n\n(Robust) canonical correlation analysis via projection pursuit.\nAuthors: Andreas Alfons [aut, cre], David Simcha [ctb].\n\ncggd\n\nContinuous Generalized Gradient Descent. Authors: Cun-Hui Zhang and\nOfer Melnik.\n\ncharlson\n\nConverts listwise icd9 data into comorbidity count and Charlson\nIndex. Author: Vanessa Cox.\n\ncheb\n\nDiscrete Linear Chebyshev Approximation. Author: Jan de Leeuw.\n\ncheddar\n\nAnalysis and visualisation of ecological communities. Authors:\nLawrence Hudson with contributions from Dan Reuman and Rob Emerson.\n\nchords\n\nEstimation in respondent driven samples. Author: Jonathan\nRosenblatt.\n\nclassify\n\nClassification Accuracy and Consistency under IRT models. Authors:\nDr Chris Wheadon and Dr Ian Stockford.\n\nclusterCrit\n\nClustering Indices. Author: Bernard Desgraupes.\n\nclustergas\n\nA hierarchical clustering method based on genetic algorithms.\nAuthors: Jose A. Castellanos-Garzon, Fernando Diaz.\n\nclusteval\n\nEvaluation of Clustering Algorithms. Author: John A. Ramey.\n\nclusthaplo\n\nAuthors: Damien Leroux, Brigitte Mangin, Sylvain Jasson, Abdelaziz\nRahmani.\n\ncoalescentMCMC\n\nMCMC Algorithms for the Coalescent. Author: Emmanuel Paradis.\n\ncocron\n\nStatistical comparisons of two or more alpha coefficients. Author:\nBirk Diedenhofen.\n\ncoenoflex\n\nGradient-Based Coenospace Vegetation Simulator. Author: David W.\nRoberts.\n\ncoexist\n\nSpecies coexistence modeling and analysis. Author: Youhua Chen.\n\ncolcor\n\nTests for column correlation in the presence of row correlation.\nAuthor: Omkar Muralidharan.\n\ncolortools\n\nTools for colors in an HSV color model. Author: Gaston Sanchez.\n\ncommandr\n\nCommand pattern in R. Author: Michael Lawrence.\n\ncomorbidities\n\nCategorizes ICD-9-CM codes based on published comorbidity indices.\nAuthor: Paul Gerrard.\n\ncompareODM\n\nComparison of medical forms in CDISC ODM format. Author: Martin\nDugas.\n\ncompoisson\n\nConway-Maxwell-Poisson Distribution. Author: Jeffrey Dunn. In view:\nDistributions.\n\nconics\n\nPlot Conics. Author: Bernard Desgraupes.\n\ncosmoFns\n\nFunctions for cosmological distances, times, luminosities, etc.\nAuthor: Andrew Harris. In view:\nChemPhys.\n\ncotrend\n\nConsistant Cotrend Rank Selection. Author: A. Christian Silva.\n\ncsSAM\n\nCell-specific Significance Analysis of Microarrays. Authors: Shai\nShen-Orr, Rob Tibshirani, Narasimhan Balasubramanian, David Wang.\n\ncudia\n\nCUDIA Cross-level Imputation. Authors: Yubin Park and Joydeep Ghosh.\n\ncvq2\n\nCalculate the predictive squared correlation coefficient. Author:\nTorsten Thalheim.\n\ncxxfunplus\n\nextend cxxfunction by saving the dynamic shared objects. Author:\nJiqiang Guo.\n\ndaewr\n\nDesign and Analysis of Experiments with R. Author: John Lawson.\n\ndatamart\n\nUnified access to various data sources. Author: Karsten Weinert.\n\ndatamerge\n\nMerging of overlapping and inconsistent data. Author: Christofer\nBacklin.\n\ndbConnect\n\nProvides a graphical user interface to connect with databases that\nuse MySQL. Authors: Dason Kurkiewicz, Heike Hofmann, Ulrike\nGenschel.\n\ndbmss\n\nDistance-based measures of spatial structures. Authors: Eric Marcon,\nGabriel Lang, Stephane Traissac, Florence Puech.\n\ndeamer\n\nDeconvolution density estimation with adaptive methods for a\nvariable prone to measurement error. Authors: Julien Stirnemann,\nAdeline Samson, Fabienne Comte. Contribution from Claire Lacour.\n\ndegenes\n\nDetection of differentially expressed genes. Author: Klaus Jung.\n\ndepthTools\n\nDepth Tools. Authors: Sara Lopez-Pintado and Aurora Torrente.\n\ndglars\n\nDifferential Geometric LARS (dgLARS) method. Author: Luigi\nAugugliaro.\n\ndgof\n\nDiscrete Goodness-of-Fit Tests. Authors: Taylor B. Arnold, John W.\nEmerson, R Core Team and contributors worldwide.\n\ndinamic\n\nDiNAMIC A Method To Analyze Recurrent DNA Copy Number Aberrations in\nTumors. Authors: Vonn Walter, Andrew B. Nobel, and Fred A. Wright.\n\ndistfree.cr\n\nDistribution-free confidence region (distfree.cr). Authors: Zhiqiu\nHu, Rong-cai Yang.\n\ndivagis\n\nProvides tools for quality checks of georeferenced plant species\naccessions. Author: Reinhard Simon.\n\ndiveRsity\n\nGenetic diversity partition statistics and Informative locus\nselection using Fst, Gst, Dest(Jost Chao) G’st and In. Author: Kevin\nKeenan.\n\ndna\n\nDifferential Network Analysis. Authors: Ryan Gill, Somnath Datta,\nSusmita Datta.\n\ndownloader\n\nDownloading files over https. Author: Winston Chang.\n\ndpa\n\nDynamic Path Approach. Author: Emile Chappin.\n\ndpglasso\n\nPrimal Graphical Lasso. Authors: Rahul Mazumder and Trevor Hastie.\n\ndrawExpression\n\nVisualising R syntax through graphics. Author: Sylvain Loiseau.\n\nds\n\nDescriptive Statistics. Author: Emmanuel Arnhold.\n\ndsample\n\nDiscretization-based Direct Random Sample Generation. Authors: Liqun\nWang and Chel Hee Lee.\n\ndsm\n\nDensity surface modelling (dsm) of distance sampling data. Authors:\nDavid L. Miller, Eric Rexstad, Louise Burt, Mark V. Bravington,\nSharon Hedley.\n\ndynCorr\n\nDynamic Correlation. Authors: Joel Dubin, Dandi Qiao, Hans-Georg\nMueller.\n\neasi\n\nEASI Demand System Estimation. Authors: Stephane Hoareau, Guy\nLacroix, Mirella Hoareau, Luca Tiberti.\n\neasyanova\n\nAnalysis of variance and other important complementary analyzes.\nAuthor: Emmanuel Arnhold.\n\nedesign\n\nMaximum entropy sampling. Author: Claudia Gebhardt.\n\neeptools\n\nConvenience functions for education data. Author: Jared E. Knowles.\n\neigeninv\n\nGenerates (dense) matrices that have a given set of eigenvalues.\nAuthors: Ravi Varadhan, Johns Hopkins University.\n\nel.convex\n\nEmpirical likelihood ratio tests for means. Authors: Dan Yang, Dylan\nSmall.\n\nelmNN\n\nImplementation of ELM (Extreme Learning Machine) algorithm for SLFN\n(Single Hidden Layer Feedforward Neural Networks). Author: Alberto\nGosso.\n\nemudata\n\nDatasets for the emu package. Authors: Jonathan Harrington, Tina\nJohn (package build) and others.\n\nenaR\n\nTools ecological network analysis (ena). Authors: M.K. Lau, S.R.\nBorrett, D.E. Hines.\n\nepr\n\nEasy polynomial regression. Author: Emmanuel Arnhold.\n\nevora\n\nEpigenetic Variable Outliers for Risk prediction Analysis. Author:\nAndrew E Teschendorff.\n\nexpoRkit\n\nExpokit in R. Authors: Roger B. Sidje, Niels Richard Hansen.\n\nextraTrees\n\nExtraTrees method. Author: Jaak Simm.\n\nextrafont\n\nTools for using fonts. Author: Winston Chang.\n\nextrafontdb\n\nDatabase for the extrafont package. Author: Winston Chang.\n\nezglm\n\nSelects significant non-additive interaction between two variables\nusing fast GLM implementation. Author: Yi Yang.\n\nfanplot\n\nVisualisations of sequential probability distributions. Author:\nGuy J. Abel.\n\nfastSOM\n\nFast Calculation of Spillover Measures. Authors: Stefan Kloessner,\nSven Wagner.\n\nfdasrvf\n\nElastic Functional Data Analysis. Author: J. Derek Tucker.\n\nfdrci\n\nPermutation-based FDR Point and Confidence Interval Estimation.\nAuthor: Joshua Millstein.\n\nfinebalance\n\nApproximate fine balance when exact fine balance is not achievable.\nAuthor: Dan Yang.\n\nfitDRC\n\nFitting Density Ratio Classes. Authors: Simon L. Rinderknecht and\nPeter Reichert.\n\nflare\n\nFamily of Lasso Regression. Authors: Xingguo Li, Tuo Zhao, Lie Wang,\nXiaoming Yuan and Han Liu.\n\nflubase\n\nBaseline of mortality free of influenza epidemics. Authors: Nunes B,\nNatario I and Carvalho L.\n\nfma\n\nData sets from “Forecasting: methods and applications” by\nMakridakis, Wheelwright & Hyndman (1998). Author: Rob J Hyndman. In\nviews:\nEconometrics,\nTimeSeries.\n\nfmt\n\nVariance estimation of FMT method (Fully Moderated t-statistic).\nAuthors: Lianbo Yu, The Ohio State University.\n\nfontcm\n\nComputer Modern font for use with extrafont package. Authors:\nWinston Chang, Alexej Kryukov, Paul Murrell.\n\nforensic\n\nStatistical Methods in Forensic Genetics. Author: Miriam\nMarusiakova.\n\nfpow\n\nComputing the noncentrality parameter of the noncentral \\(F\\)\ndistribution. Author: Ali Baharev.\n\nfrbs\n\nFuzzy rule-based systems. Authors: Lala Septem Riza, Christoph\nBergmeir, Francisco Herrera Triguero, and Jose Manuel Benitez.\n\nfreeknotsplines\n\nFree-Knot Splines. Authors: Steven Spiriti, Philip Smith, Pierre\nLecuyer.\n\nfrontiles\n\nPartial frontier efficiency analysis. Authors: Abdelaati Daouia,\nThibault Laurent.\n\nfrt\n\nFull Randomization Test. Authors: Giangiacomo Bravo, Lucia\nTamburino.\n\nfugeR\n\nFUzzy GEnetic, a machine learning algorithm to construct prediction\nmodel based on fuzzy logic. Author: Alexandre Bujard.\n\nfwi.fbp\n\nFire Weather Index System and Fire Behaviour Prediction System\nCalculations. Authors: Xianli Wang, Alan Cantin, Marc-Andre\nParisien, Mike Wotton, Kerry Anderson, and Mike Flannigan.\n\ngMWT\n\nGeneralized Mann-Whitney Type Tests. Authors: Daniel Fischer, Hannu\nOja.\n\ngProfileR\n\ng:ProfileR. Authors: Juri Reimand, Raivo Kolde, Tambet Arak.\n\ngamclass\n\nFunctions and data for a course on modern regression and\nclassification. Author: John Maindonald.\n\ngamlss\n\nGeneralized Additive Models for Location Scale and Shape. Authors:\nMikis Stasinopoulos, Bob Rigby with contributions from Calliope\nAkantziliotou and Vlasis Voudouris. In view:\nEconometrics.\n\ngbs\n\nGeneralized Birnbaum-Saunders Distributions. Authors: Michelli\nBarros, Victor Leiva and Gilberto A. Paula. In view:\nDistributions.\n\ngdimap\n\nGeneralized Diffusion Magnetic Resonance Imaging. Author: Adelino\nFerreira da Silva.\n\ngearman\n\nR interface to the Gearman Job Server. Author: Jeffrey Horner.\n\ngeeM\n\nFit Generalized Estimating Equations. Authors: Lee McDaniel and Nick\nHenderson.\n\ngemtc\n\nGeMTC network meta-analysis. Authors: Gert van Valkenhoef, Joel\nKuiper.\n\ngemtc.jar\n\nGeMTC Java binary. Authors: Gert van Valkenhoef, Joel Kuiper.\n\ngenSurv\n\nGenerating multi-state survival data. Authors: Artur Agostinho\nAraújo, Luís Meira-Machado and Susana Faria. In view:\nSurvival.\n\ngeneListPie\n\nProfiling a gene list into GOslim or KEGG function pie. Author:\nXutao Deng.\n\ngeneSignatureFinder\n\nA Gene-signatures finder tools. Authors: Stefano M. Pagnotta,\nMichele Ceccarelli.\n\ngenlasso\n\nPath algorithm for generalized lasso problems. Authors: Ryan J.\nTibshirani, Taylor B. Arnold.\n\ngenomatic\n\nManages microsatellite projects. Creates 96-well maps, genotyping\nsubmission forms, rerun management, and import into statistical\nsoftware. Author: Brian J. Knaus.\n\ngeomorph\n\nGeometric morphometric analysis of 2d/3d landmark data. Authors:\nDean Adams, Erik Otarola-Castillo. In view:\nPhylogenetics.\n\ngeotopbricks\n\nAnalyzes raster maps as input/output files from the Hydrological\nDistributed Model GEOtop. Authors: Emanuele Cordano, Daniele\nAndreis, Fabio Zottele.\n\nggmcmc\n\nGraphical tools for analyzing Markov Chain Monte Carlo simulations\nfrom Bayesian inference. Author: Xavier Fernández i Marín. In view:\nBayesian.\n\nggparallel\n\nVariations of Parallel Coordinate Plots for Categorical Data.\nAuthors: Heike Hofmann, Marie Vendettuoli.\n\nggsubplot\n\nExplore complex data by embedding subplots within plots. Authors:\nGarrett Grolemund, Hadley Wickham.\n\nglobalboosttest\n\nTesting the additional predictive value of high-dimensional data.\nAuthors: Anne-Laure Boulesteix, Torsten Hothorn. In view:\nSurvival.\n\ngnmf\n\nGeneralized Non-negative Matrix Factorization. Authors: Jose M.\nMaisog, Guoli Wang, Karthik Devarajan.\n\ngppois\n\nGaussian Processes for Poisson-noised Data. Author: Charles R. Hogg\nIII.\n\ngtable\n\nArrange grobs in tables. Author: Hadley Wickham.\n\ngwerAM\n\nControlling the genome-wide type I error rate in association mapping\nexperiments. Authors: Benjamin Stich, Bettina Mueller, Hans-Peter\nPiepho.\n\nhbsae\n\nHierarchical Bayesian Small Area Estimation. Author: Harm Jan\nBoonstra. In view:\nBayesian.\n\nheatmapFit\n\nHeatmap Fit Statistic For Binary Dependent Variable Models. Authors:\nJustin Esarey and Andrew Pierce.\n\nhierNet\n\nA Lasso for Hierarchical Interactions. Authors: Jacob Bien and Rob\nTibshirani.\n\nhierarchicalDS\n\nFunctions for performing hierarchical analysis of distance sampling\ndata. Author: P.B. Conn.\n\nhmeasure\n\nThe H-measure and other scalar classification performance metrics.\nAuthors: Christoforos Anagnostopoulos and David J. Hand.\n\nhmmm\n\nHierarchical multinomial marginal models. Authors: Roberto Colombi,\nSabrina Giordano, Manuela Cazzaro.\n\nholdem\n\nTexas Holdem simulator. Author: Frederic Paik Schoenberg.\n\nhomeR\n\nFunctions useful for building physics. Author: Neurobat AG.\n\nhwriterPlus\n\nExtending the hwriter Package. Author: David Scott.\n\nhypothesestest\n\nConfidence Intervals and Tests of Statistical Hypotheses. Authors:\nChengfeng Liu, Huiqing Liu, Yingyan Liang, Ruibin Feng.\n\nhzar\n\nHybrid Zone Analysis using R. Author: Graham Derryberry.\n\niBUGS\n\nAn Interface to R2WinBUGS/R2jags by gWidgets. Authors: Yihui Xie and\nJiebiao Wang.\n\nicensmis\n\nStudy Design and Data Analysis in the presence of error-prone\ndiagnostic tests and self-reported outcomes. Authors: Xiangdong Gu\nand Raji Balasubramanian.\n\nicomp\n\nICOMP criterion. Author: Jake Ferguson.\n\nigraphtosonia\n\nConvert iGraph graps to SoNIA .son files. Author: Sean J Westwood.\n\ninfutil\n\nInformation Utility. Author: Kristian E. Markon.\n\ninsol\n\nSolar Radiation. Author: Javier G. Corripio.\n\nintsvy\n\nData Manager of International Assessment Studies of Student\nPerformance. Author: Daniel Caro.\n\nisopat\n\nCalculation of isotopic pattern for a given molecular formula.\nAuthor: Martin Loos.\n\nkSamples\n\nK-Sample Rank Tests and their Combinations. Authors: Fritz Scholz\nand Angie Zhu.\n\nkelvin\n\nCalculate solutions to Kelvin differential equation using Kelvin\nfunctions. Author: Andrew J Barbour.\n\nkitagawa\n\nModel the spectral response of a closed water-well to harmonic\nstrains at seismic frequencies. Author: Andrew J Barbour.\n\nklin\n\nLinear equations with Kronecker structure. Author: Tamas K Papp.\n\nknitcitations\n\nCitations for knitr markdown files. Author: Carl Boettiger.\n\nkobe\n\nTools for providing advice for the Tuna Regional Fisheries\nManagement Organisations. Author: Laurence Kell.\n\nlabeling\n\nAxis Labeling. Author: Justin Talbot.\n\nlambda.r\n\nFunctional programming in R. Author: Brian Lee Yung Rowe.\n\nlavaan\n\nLatent Variable Analysis. Authors: Yves Rosseel [aut, cre], Daniel\nOberski [ctb], Jarrett Byrnes [ctb], Leonard Vanbrabant [ctb],\nVictoria Savalei [ctb], Ed Merkle [ctb], Michael Hallquist\n[ctb], Mijke Rhemtulla [ctb], Myrsini Katsikatsou [ctb]. In\nview:\nPsychometrics.\n\nlavaan.survey\n\nComplex survey structural equation modeling (SEM). Author: Daniel\nOberski.\n\nldlasso\n\nLD LASSO Regression for SNP Association Study. Author: Samuel G.\nYounkin.\n\nldr\n\nMethods for likelihood-based dimension reduction in regression.\nAuthors: Kofi Placid Adragni, Andrew Raim.\n\nlinLIR\n\nlinear Likelihood-based Imprecise Regression. Author: Andrea\nWiencierz.\n\nlineup\n\nLining up two sets of measurements. Author: Karl W Broman.\n\nlint\n\nTools to check R code style. Author: Andrew Redd.\n\nlmec\n\nLinear Mixed-Effects Models with Censored Responses. Authors: Florin\nVaida and Lin Liu. In view:\nSurvival.\n\nlogmult\n\nLog-multiplicative models, including association models. Author:\nMilan Bouchet-Valat.\n\nlogregperm\n\nInference in Logistic Regression. Author: Douglas M. Potter.\n\nloop\n\nloop decomposition of weighted directed graphs for life cycle\nanalysis, providing flexbile network plotting methods, and analyzing\nfood chain properties in ecology. Author: Youhua Chen.\n\nlpint\n\nLocal polynomial esitmators of intensity function or its\nderivatives. Author: Feng Chen.\n\nlsmeans\n\nLeast-squares means. Author: Russell V. Lenth.\n\nmRMRe\n\nParallelized mRMR ensemble feature selection. Authors: Nicolas De\nJay, Simon Papillon-Cavanagh, Benjamin Haibe-Kains.\n\nmaRketSim\n\nMarket simulator for R. Author: Ari Friedman. In view:\nFinance.\n\nmagicaxis\n\nPretty scientific plotting with minor-tick and log minor-tick\nsupport. Author: Aaron Robotham.\n\nmapplots\n\nData visualisation on maps. Author: Hans Gerritsen.\n\nmaxLinear\n\nConditional Samplings for Max-Linear Models. Author: Yizao Wang.\n\nmcclust\n\nProcess an MCMC Sample of Clusterings. Author: Arno Fritsch. In\nview: Cluster.\n\nmcll\n\nMonte Carlo Local Likelihood Estimation. Authors: Minjeong Jeon,\nCari Kaufman, and Sophia Rabe-Hesketh.\n\nmcpd\n\nTools to analyse and use passport data for biological collections.\nAuthor: Reinhard Simon.\n\nmcr\n\nMethod Comparison Regression. Authors: Ekaterina Manuilova, Andre\nSchuetzenmeister, Fabian Model.\n\nmded\n\nMeasuring the difference between two empirical distributions.\nAuthor: Hideo Aizaki.\n\nmederrRank\n\nBayesian Methods for Identifying the Most Harmful Medication Errors.\nAuthors: Sergio Venturini, Jessica Myers.\n\nmetRology\n\nSupport for metrological applications. Author: Stephen L R Ellison.\n\nmetamisc\n\nDiagnostic and prognostic meta analysis (metamisc). Author: Thomas\nDebray.\n\nmiRada\n\nMicroRNA Microarray Data Analysis. Author: Bin Wang.\n\nmigest\n\nUseful R code for the Estimation of Migration. Author: Guy J. Abel.\n\nminerva\n\nMaximal Information-Based Nonparametric Exploration R package for\nVariable Analysis. Authors: Michele Filosi [aut, cre], Roberto\nVisintainer [aut], Davide Albanese [aut], Samantha Riccadonna\n[ctb], Giuseppe Jurman [ctb], Cesare Furlanello [ctb].\n\nminxent\n\nEntropy Optimization Distributions. Author: Senay Asma.\n\nmixfdr\n\nComputes false discovery rates and effect sizes using normal\nmixtures. Authors: Omkar Muralidharan, with many suggestions from\nBradley Efron.\n\nmlPhaser\n\nMulti-Locus Haplotype Phasing. Author: Dave T. Gerrard.\n\nmlica2\n\nIndependent Component Analysis using Maximum Likelihood. Author:\nAndrew Teschendorff.\n\nmmeln\n\nEstimation of multinormal mixture distribution. Author:\nCharles-Edouard Giguere.\n\nmmeta\n\nMultivariate Meta-Analysis Using Sarmanov Beta Prior Distributions.\nAuthors: Sheng Luo, Yong Chen, Haitao Chu, Xiao Su.\n\nmmm\n\nMultivariate Marginal Models. Authors: Ozgur Asar, Ozlem Ilk.\n\nmotmot\n\nModels of Trait Macroevolution on Trees. Authors: Gavin Thomas, Rob\nFreckleton. In view:\nPhylogenetics.\n\nmpa\n\nCoWords Method. Author: Daniel Hernando Rodriguez and Campo Elias\nPardo.\n\nmsap\n\nStatistical analysis for Methylation-sensitive Amplification\nPolymorphism data. Author: Andres Perez-Figueroa.\n\nmtcreator\n\nCreating MAGE-TAB files using mtcreator. Author: Fabian Grandke.\n\nmtsdi\n\nMultivariate time series data imputation. Authors: Washington Junger\nand Antonio Ponce de Leon.\n\nmultgee\n\nGEE Solver for Correlated Nominal or Ordinal Multinomial Responses.\nAuthor: Anestis Touloumis.\n\nmultibiplotGUI\n\nMultibiplot Analysis in R. Authors: Ana Belen Nieto Librero, Nora\nBaccala, Purificacion Vicente Galindo, Purificacion Galindo\nVillardon.\n\nmultisensi\n\nMultivariate Sensitivity Analysis. Authors: Matieyendou Lamboni,\nHerve Monod.\n\nmuscle\n\nMultiple Sequence Alignment. Author: Algorithm by Robert C. Edgar. R\nport by Alex T. Kalinka.\n\nmvShapiroTest\n\nGeneralized Shapiro-Wilk test for multivariate normality. Authors:\nElizabeth Gonzalez Estrada, Jose A. Villasenor Alva.\n\nmvc\n\nMulti-View Clustering. Author: Andreas Maunz.\n\nmvsf\n\nShapiro-Francia Multivariate Normality Test. Author: David Delmail.\n\nmvtmeta\n\nMultivariate meta-analysis. Author: Han Chen.\n\nnamespace\n\nProvide namespace managment functions not (yet) present in base R.\nAuthors: Winston Chang, Daniel Adler, Hadley Wickham, Gregory R.\nWarnes, R Core Team.\n\nncg\n\nComputes the noncentral gamma function. Authors: Daniel Furtado\nFerreira, Izabela Regina Cardoso de Oliveira and Fernando Henrique\nToledo.\n\nngspatial\n\nClasses for Spatial Data. Author: John Hughes.\n\nnlADG\n\nRegression in the Normal Linear ADG Model. Authors: Gruber, Lutz F.\n\nnlmrt\n\nFunctions for nonlinear least squares solutions. Author: John C.\nNash.\n\nnlts\n\n(non)linear time series analysis. Author: Ottar N. Bjornstad.\n\nnontarget\n\nDetecting, combining and filtering isotope, adduct and homologue\nseries relations in high-resolution mass spectrometry (HRMS) data.\nAuthor: Martin Loos.\n\nnopp\n\nNash Optimal Party Positions. Authors: Luigi Curini, Stefano M.\nIacus.\n\nnormwhn.test\n\nNormality and White Noise Testing. Author: Peter Wickham.\n\nnotifyR\n\nSend push notifications to your smartphone via pushover.net. Author:\nTorben Engelmeyer.\n\nnpmv\n\nNonparametric Comparison of Multivariate Samples. Author: Woodrow\nBurchett.\n\nnumbers\n\nNumber-theoretic Functions. Author: Hans W Borchers.\n\nobliclus\n\nCluster-based factor rotation. Author: Michio Yamamoto.\n\nocomposition\n\nGibbs sampler for ordered compositional data. Authors: Arturas\nRozenas, Duke University.\n\noem\n\nOrthogonalizing Expectation maximization. Author: Bin Dai.\n\nomd\n\nFilter the molecular descriptors for QSAR. Author: Bin Ma.\n\noncomodel\n\nMaximum likelihood tree models for oncogenesis. Authors: Anja von\nHeydebreck, contributions from Christiane Heiss.\n\nopefimor\n\nOption Pricing and Estimation of Financial Models in R. Author:\nStefano Maria Iacus. In view:\nFinance.\n\nopmdata\n\nExample data for analysing OmniLog(R) Phenotype Microarray data.\nAuthors: Markus Goeker, with contributions by Lea A.I. Vaas and\nJohannes Sikorski.\n\norcutt\n\nEstimate procedure in case of first order autocorrelation. Authors:\nStefano Spada, Matteo Quartagno, Marco Tamburini.\n\noro.pet\n\nRigorous — Positron Emission Tomography. Author: Brandon Whitcher.\n\np2distance\n\nWelfare’s Synthetic Indicator. Authors: A.J. Perez-Luque; R.\nMoreno; R. Perez-Perez and F.J. Bonet.\n\npGLS\n\nGeneralized Least Square in comparative Phylogenetics. Authors:\nXianyun Mao and Timothy Ryan.\n\npa\n\nPerformance Attribution for Equity Portfolios. Authors: Yang Lu and\nDavid Kane. In view:\nFinance.\n\npacbpred\n\nPAC-Bayesian Estimation and Prediction in Sparse Additive Models.\nAuthor: Benjamin Guedj. In view:\nBayesian.\n\npander\n\nAn R pandoc writer. Author: Gergely Daróczi.\n\nparspatstat\n\nParallel spatial statistics. Author: Jonathan Lee.\n\npartitionMetric\n\nCompute a distance metric between two partitions of a set. Authors:\nDavid Weisman, Dan Simovici.\n\nparviol\n\nAuthor: Jaroslav Myslivec.\n\npbdBASE\n\nProgramming with Big Data — Core pbd Classes and Methods. Authors:\nDrew Schmidt, Wei-Chen Chen, George Ostrouchov, Pragneshkumar Patel.\nIn view:\nHighPerformanceComputing.\n\npbdDMAT\n\nProgramming with Big Data — Distributed Matrix Computation.\nAuthors: Drew Schmidt, Wei-Chen Chen, George Ostrouchov,\nPragneshkumar Patel. In view:\nHighPerformanceComputing.\n\npbdMPI\n\nProgramming with Big Data — Interface to MPI. Authors: Wei-Chen\nChen, George Ostrouchov, Drew Schmidt, Pragneshkumar Patel, Hao Yu.\nIn view:\nHighPerformanceComputing.\n\npbdSLAP\n\nProgramming with Big Data — Scalable Linear Algebra Packages.\nAuthors: Wei-Chen Chen [aut, cre], Drew Schmidt [aut], George\nOstrouchov [aut], Pragneshkumar Patel [aut], ScaLAPACK [ctb].\nIn view:\nHighPerformanceComputing.\n\npbivnorm\n\nVectorized Bivariate Normal CDF. Authors: Fortran code by Alan Genz.\nR code by Brenton Kenkel, based on Adelchi Azzalini’s mnormt\npackage.\n\npcenum\n\nPermutations and Combinations Enumeration. Author: Benjamin Auder.\n\npenDvine\n\nFlexible Pair-Copula Estimation in D-vines with Penalized Splines.\nAuthor: Christian Schellhase.\n\npeplib\n\nPeptide Library Analysis Methods. Author: Andrew White.\n\nperry\n\nResampling-based prediction error estimation for regression models.\nAuthor: Andreas Alfons.\n\npesticides\n\nAnalysis of single serving and composite pesticide residue\nmeasurements. Author: David M Diez.\n\npheno2geno\n\nGenerating genetic markers and maps from molecular phenotypes.\nAuthors: Konrad Zych and Danny Arends.\n\nphonR\n\nR tools for phoneticians and phonologists. Author: Daniel R. McCloy.\n\nphonTools\n\nFunctions for phonetics in R. Author: Santiago Barreda.\n\npkgutils\n\nUtilities for creating R packages. Author: Markus Goeker.\n\nplanor\n\nGeneration of regular factorial designs. Authors: Hervé Monod, Annie\nBouvier, André Kobilinsky.\n\nplmm\n\nPartially Linear Mixed Effects Model. Author: Ohinata Ren.\n\npln\n\nPolytomous logit-normit (graded logistic) model estimation. Authors:\nCarl F. Falk and Harry Joe.\n\nplotKML\n\nVisualization of spatial and spatio-temporal objects in Google\nEarth. Authors: Tomislav Hengl, Contributions by: Pierre Roudier,\nDylan Beaudette, Daniel Nuest. In view:\nSpatial.\n\nplotSEMM\n\nGraphing nonlinear latent variable interactions in SEMM. Authors:\nBethany E. Kok, Jolynn Pek, Sonya Sterba and Dan Bauer.\n\nplsdepot\n\nPartial Least Squares (PLS) Data Analysis Methods. Author: Gaston\nSanchez.\n\npnmtrem\n\nProbit-Normal Marginalized Transition Random Effects Models.\nAuthors: Ozgur Asar, Ozlem Ilk.\n\npoibin\n\nThe Poisson Binomial Distribution. Author: Yili Hong. In view:\nDistributions.\n\npoisson.glm.mix\n\nFit high dimensional mixtures of Poisson GLM’s. Authors: Panagiotis\nPapastamoulis, Marie-Laure Martin-Magniette, Cathy Maugis-Rabusseau.\n\npoistweedie\n\nPoisson-Tweedie exponential family models. Authors: David Pechel\nCactcha, Laure Pauline Fotso and Celestin C Kokonendji. In view:\nDistributions.\n\npopReconstruct\n\nReconstruct population counts, fertility, mortality and migration\nrates of human populations of the recent past. Author: Mark C.\nWheldon.\n\npostgwas\n\nGWAS Post-Processing Utilities. Author: Milan Hiersche.\n\npowerGWASinteraction\n\nPower Calculations for Interactions for GWAS. Author: Charles\nKooperberg.\n\nppMeasures\n\nPoint pattern distances and prototypes. Authors: David M Diez,\nKatherine E Tranbarger Freier, and Frederic P Schoenberg.\n\nppcor\n\nPartial and Semi-partial (Part) correlation. Author: Seongho Kim.\n\npragma\n\nProvides a pragma / directive / keyword syntax for R. Author:\nChristopher Brown.\n\nprettyGraphs\n\nPublication-quality graphics. Author: Derek Beaton.\n\nprevR\n\nEstimating regional trends of a prevalence from a DHS. Authors:\nJoseph Larmarange — CEPED (Universite Paris Descartes Ined IRD)\nIRD, with fundings from ANRS and IRD, and technical support from\nLYSIS (info@lysis-consultants.fr).\n\nprofanal\n\nImplements profile analysis described in Davison & Davenport (2002).\nAuthor: Christopher David Desjardins.\n\nprotViz\n\nVisualizing and Analyzing Mass Spectrometry Related Data in\nProteomics. Authors: Christian Panse, Jonas Grossmann.\n\nprotiq\n\nProtein (identification and) quantification based on peptide\nevidence. Authors: Sarah Gerster and Peter Buehlmann.\n\nprotr\n\nProtein Sequence Feature Extraction with R. Authors: Xiao Nan,\nDongsheng Cao, Qingsong Xu, Yizeng Liang.\n\npsytabs\n\nProduce well-formatted tables for psychological research. Authors:\nJohannes Beller, Soeren Kliem.\n\npvar\n\np-variation. Author: Vygantas Butkus.\n\nquadrupen\n\nSparsity by Worst-Case Quadratic Penalties. Author: Julien Chiquet.\n\nr2stl\n\nVisualizing data using a 3D printer. Authors: Ian Walker and José\nGama.\n\nrAltmetric\n\nRetrieves altmerics data for any published paper from\naltmetrics.com. Author: Karthik Ram.\n\nrHpcc\n\nInterface between HPCC and R. Author: Dinesh Shetye.\n\nrImpactStory\n\nRetrieves altmetrics from ImpactStory. See http://impactstory.org\nfor more about the metrics. Authors: Karthik Ram, Scott Chamberlain.\n\nrJython\n\nR interface to Python via Jython. Authors: G. Grothendieck and\nCarlos J. Gil Bellosta (authors of Jython itself are Jim Hugunin,\nBarry Warsaw, Samuele Pedroni, Brian Zimmer, Frank Wierzbicki and\nothers; Bob Ippolito is the author of the simplejson Python module).\n\nrPlant\n\nR interface to the iPlant Discovery Environment. Authors: Barb\nBanbury, Kurt Michels, Jeremy M. Beaulieu, Brian O’Meara.\n\nrandomForestSRC\n\nRandom Forests for Survival, Regression, and Classification\n(RF-SRC). Authors: Hemant Ishwaran, Udaya B. Kogalur.\n\nrandomizeBE\n\nFunction to create a random list for crossover studies. Author: D.\nLabes.\n\nrbundler\n\nManage an application’s dependencies systematically and repeatedly.\nAuthor: Yoni Ben-Meshulam.\n\nrcqp\n\nInterface to the Corpus Query Protocol. Authors: Bernard Desgraupes,\nSylvain Loiseau.\n\nrdd\n\nRegression Discontinuity Estimation. Author: Drew Dimmery.\n\nrdetools\n\nRelevant Dimension Estimation (RDE) in Feature Spaces. Author: Jan\nSaputra Mueller. In view:\nMachineLearning.\n\nrdyncall\n\nImproved Foreign Function Interface (FFI) and Dynamic Bindings to C\nLibraries (e.g. OpenGL). Author: Daniel Adler.\n\nreams\n\nResampling-Based Adaptive Model Selection. Authors: Philip Reiss and\nLei Huang.\n\nrebird\n\nInterface to eBird. Authors: Rafael Maia, Scott Chamberlain.\n\nreccsim\n\nSimulation of Rare Events Case-Control Studies. Author: Christian\nWestphal.\n\nregsubseq\n\nDetect and Test Regular Sequences and Subsequences. Author: Yanming\nDi.\n\nrentrez\n\nEntrez in R. Author: David Winter.\n\nrepolr\n\nRepeated measures proportional odds logistic regression. Author:\nNick Parsons.\n\nrestlos\n\nRobust estimation of location and scatter. Authors: Steffen\nLiebscher and Thomas Kirschstein.\n\nretimes\n\nReaction Time Analysis. Author: Davide Massidda.\n\nreview\n\nManage Review Logs. Author: Tim Bergsma.\n\nrfigshare\n\nAn R interface to figshare.com. Authors: Carl Boettiger, Scott\nChamberlain, Karthik Ram, Edmund Hart.\n\nrgexf\n\nBuild GEXF network files. Authors: George Vega Yon, Jorge Fabrega\nLacoa.\n\nridge\n\nRidge Regression with automatic selection of the penalty parameter.\nAuthor: Erika Cule.\n\nritis\n\nTaxonomic search of ITIS data. Author: Scott Chamberlain.\n\nrkt\n\nMann-Kendall test, Seasonal and Regional Kendall Tests. Author: Aldo\nMarchetto.\n\nrlandscape\n\nGenerates random landscapes with specifiable spatial\ncharacteristics. Authors: Gregor Passolt, Miranda J. Fix, Sandor F.\nToth.\n\nrmmseg4j\n\nR interface to the Java Chinese word segmentation system of mmseg4j.\nAuthor: Huang Ronggui.\n\nrngtools\n\nUtility functions for working with Random Number Generators. Author:\nRenaud Gaujoux.\n\nrobustgam\n\nRobust Estimation for Generalized Additive Models. Author:\nRaymond K. W. Wong.\n\nrobustloggamma\n\nRobust estimation of the generalized log gamma model. Authors:\nClaudio Agostinelli, Alfio Marazzi, V.J. Victor and Alex\nRandriamiharisoa.\n\nrobustreg\n\nRobust Regression Functions. Author: Ian M. Johnson.\n\nropensnp\n\nInterface to OpenSNP API methods. Author: Scott Chamberlain.\n\nrpf\n\nResponse Probability Functions. Authors: Joshua Pritikin [cre,\naut], Jonathan Weeks [ctb]. In view:\nPsychometrics.\n\nrrcovHD\n\nRobust multivariate Methods for High Dimensional Data. Author:\nValentin Todorov.\n\nrriskBayes\n\nPredefined Bayes models fitted with Markov chain Monte Carlo (MCMC)\n(related to the ‘rrisk’ project). Authors: Natalia Belgorodski,\nMatthias Greiner, Alexander Engelhardt.\n\nrseedcalc\n\nEstimating the proportion of genetically modified stacked seeds in\nseedlots via multinomial group testing. Authors: Kevin Wright,\nJean-Louis Laffont.\n\nrspa\n\nAdapt numerical records to fit (in)equality restrictions with the\nSuccessive Projection Algorithm. Author: Mark van der Loo.\n\nrts\n\nRaster time series analysis. Author: Babak Naimi.\n\nrvertnet\n\nSearch VertNet database from R. Authors: Scott Chamberlain, Vijay\nBarve.\n\nrworldxtra\n\nCountry boundaries at high resolution. Author: Andy South.\n\nsExtinct\n\nCalculates the historic date of extinction given a series of\nsighting events. Author: Christopher Clements.\n\nsamplingVarEst\n\nSampling Variance Estimation. Authors: Emilio Lopez Escobar, Ernesto\nBarrios Zamudio.\n\nsddpack\n\nSemidiscrete Decomposition. Authors: Tamara G. Kolda, Dianne P.\nO’Leary.\n\nsdnet\n\nSoft Discretization-based Bayesian Network Inference. Author:\nNikolay Balov.\n\nseem\n\nSimulation of Ecological and Environmental Models. Author: Miguel F.\nAcevedo.\n\nselectr\n\nTranslate CSS Selectors to XPath Expressions. Authors: Simon Potter,\nSimon Sapin, Ian Bicking.\n\nseparationplot\n\nSeparation Plots. Authors: Brian D. Greenhill, Michael D. Ward and\nAudrey Sacks.\n\nseq2R\n\nSimple method to detect compositional changes in genomic sequences.\nAuthors: Nora M. Villanueva, Marta Sestelo and Javier Roca-Pardinas.\n\nsig\n\nPrint function signatures. Author: Richard Cotton.\n\nsigclust\n\nStatistical Significance of Clustering. Authors: Hanwen Huang,\nYufeng Liu and J. S. Marron. In view:\nCluster.\n\nsigora\n\nSIGnature OverRepresentation Analysis. Authors: Amir B.K.\nForoushani, Fiona S.L. Brinkman, David J. Lynn.\n\nsirad\n\nFunctions for calculating daily solar radiation and\nevapotranspiration. Author: Jedrzej S. Bojanowski.\n\nsisus\n\nStable Isotope Sourcing using Sampling. Author: Erik Barry Erhardt.\n\nskewt\n\nThe Skewed Student-t Distribution. Authors: Robert King, with\ncontributions from Emily Anderson. In view:\nDistributions.\n\nsmart\n\nSparse Multivariate Analysis via Rank Transformation. Authors: Fang\nHan, Han Liu.\n\nsmco\n\nA simple Monte Carlo optimizer using adaptive coordinate sampling.\nAuthor: Juan David Velasquez.\n\nsme\n\nSmoothing-splines Mixed-effects Models. Author: Maurice Berk.\n\nsmirnov\n\nProvides two taxonomic coefficients from E. S. Smirnov “Taxonomic\nanalysis” (1969) book. Author: Alexey Shipunov (with help of Eugenij\nAltshuler).\n\nsms\n\nSpatial Microsimulation. Author: Dimitris Kavroudakis.\n\nsnort\n\nSocial Network-Analysis On Relational Tables. Authors: Eugene\nDubossarsky and Mark Norrie.\n\nsoilwater\n\nImplements parametric formulas for soil water retention or\nconductivity curve. Author: Emanuele Cordano.\n\nspTimer\n\nSpatio-Temporal Bayesian Modelling Using R. Authors: K. Shuvo Bakar\nand Sujit K. Sahu. In view:\nBayesian.\n\nspa\n\nImplements The Sequential Predictions Algorithm. Author: Mark Culp.\n\nsparseHessianFD\n\nInterface to ACM TOMS Algorithm 636, for computing sparse Hessians.\nAuthors: R interface code by Michael Braun; original Fortran code by\nThomas F. Coleman, Burton S. Garbow and Jorge J. More.\n\nsperrorest\n\nSpatial Error Estimation and Variable Importance. Author: Alexander\nBrenning.\n\nsphereplot\n\nSpherical plotting. Author: Aaron Robotham.\n\nspsmooth\n\nAn Extension Package for mgcv. Authors: Wesley Burr, with\ncontributions from Karim Rahim.\n\nsquash\n\nColor-based plots for multivariate visualization. Author: Aron\nEklund.\n\nsra\n\nSelection Response Analysis. Author: Arnaud Le Rouzic.\n\nstargazer\n\nLaTeX code for well-formatted regression and summary statistics\ntables. Author: Marek Hlavac.\n\nstepp\n\nSubpopulation Treatment Effect Pattern Plot (STEPP). Authors: Wai-ki\nYip, with contributions from Ann Lazar, David Zahrieh, Chip Cole,\nAnn Lazar, Marco Bonetti, and Richard Gelber.\n\nstocc\n\nFit a spatial occupancy model via Gibbs sampling. Author: Devin S.\nJohnson.\n\nstppResid\n\nPerform residual analysis on space-time point process models.\nAuthor: Robert Clements.\n\nsudokuplus\n\nSudoku Puzzle (\\(9*9\\), \\(12*12\\), \\(16*16\\)) Generator and Solver.\nAuthors: Zhengmairuo Gan, Yuzhen Hua, Maosheng Zhang, Caiyan Lai.\n\nsurvIDINRI\n\nIDI and NRI for comparing competing risk prediction models with\ncensored survival data. Authors: Hajime Uno, Tianxi Cai. In view:\nSurvival.\n\nsurvivalROC\n\nTime-dependent ROC curve estimation from censored survival data.\nAuthors: Patrick J. Heagerty, packaging by Paramita Saha. In view:\nSurvival.\n\nsvapls\n\nSurrogate variable analysis using partial least squares in a gene\nexpression study. Authors: Sutirtha Chakraborty, Somnath Datta and\nSusmita Datta.\n\nsybilSBML\n\nSBML Integration in Package sybil. Author: Gabriel\nGelius-Dietrich.\n\nsymbols\n\nSymbol plots. Author: Jaroslav Myslivec.\n\ntaRifx.geo\n\nCollection of various spatial functions. Author: Ari B. Friedman.\n\ntabplotd3\n\nInteractive inspection of large data. Authors: Edwin de Jonge and\nMartijn Tennekes.\n\nteigen\n\nModel-based clustering and classification with the multivariate\nt-distribution. Authors: Jeffrey L. Andrews, Paul D. McNicholas. In\nview: Cluster.\n\ntexreg\n\nConversion of R regression output to LaTeX tables. Author: Philip\nLeifeld.\n\ntiff\n\nRead and write TIFF images. Author: Simon Urbanek.\n\ntightClust\n\nTight Clustering. Authors: George C. Tseng, Wing H. Wong.\n\ntilting\n\nVariable selection via Tilted Correlation Screening algorithm.\nAuthor: Haeran Cho.\n\ntimeROC\n\nTime-dependent ROC curve and AUC for censored survival data. Author:\nPaul Blanche.\n\ntmg\n\nTruncated Multivariate Gaussian Sampling. Author: Ari Pakman.\n\ntmle\n\nTargeted Maximum Likelihood Estimation. Authors: Susan Gruber, in\ncollaboration with Mark van der Laan.\n\ntransmission\n\nContinuous time infectious disease models on individual data.\nAuthors: Alun Thomas, Andrew Redd.\n\ntransnet\n\nConducts transmission modeling on a bayesian network. Author: Alun\nThomas.\n\ntrex\n\nTruncated exact test for two-stage case-control design for studying\nrare genetic variants. Authors: Schaid DJ, Sinnwell JP.\n\ntrifield\n\nSome basic facilities for ternary fields and plots. Author: Tim\nKeitt.\n\ntrustOptim\n\nTrust region nonlinear optimization, efficient for sparse Hessians.\nAuthor: Michael Braun. In view:\nOptimization.\n\ntslars\n\nLeast angle regression for time series analysis. Author: Sarah\nGelper. In view:\nTimeSeries.\n\ntwo.stage.boot\n\nTwo-stage cluster sample bootstrap algorithm. Author: Patrick\nZimmerman.\n\ntwoStageGwasPower\n\nCompute thresholds and power for two-stage gwas. Author: Dirk F\nMoore.\n\nupclass\n\nUpdated Classification Methods using Unlabelled Data. Authors: Niamh\nRussell, Laura Cribbin, Thomas Brendan Murphy.\n\nusdm\n\nUncertainty analysis for species distribution models. Author: Babak\nNaimi.\n\nutility\n\nConstruct, Evaluate and Plot Value and Utility Functions. Author:\nPeter Reichert with contributions by Nele Schuwirth.\n\nvalidator\n\nExternal and Internal Validation Indices. Author: Marcus Scherl.\n\nvcf2geno\n\nEfficiently Read Variant Call Format (VCF) into R. Authors: Xiaowei\nZhan and Dajiang Liu, with contributions of Jean-loup Gailly, Mark\nAdler, Julian Seward and Heng Li.\n\nvegclust\n\nFuzzy clustering of vegetation data. Author: Miquel De Caceres.\n\nviolinmplot\n\nCombination of violin plot with mean and standard deviation. Author:\nRaphael W. Majeed.\n\nvmv\n\nVisualization of Missing Values. Author: Waqas Ahmed Malik.\n\nvows\n\nVoxelwise semiparametrics. Authors: Philip Reiss, Yin-Hsiu Chen, Lei\nHuang, and Lan Huo.\n\nvwr\n\nUseful functions for visual word recognition research. Author:\nEmmanuel Keuleers.\n\nwSVM\n\nWeighted SVM with boosting algorithm for improving accuracy.\nAuthors: SungHwan Kim and Soo-Heang Eo.\n\nwaterData\n\nRetrieval, Analysis, and Anomaly Calculation of Daily Hydrologic\nTime Series Data. Authors: Karen R. Ryberg and Aldo V. Vecchia.\n\nwavemulcor\n\nWavelet routine for multiple correlation. Author: Javier\nFernandez-Macho.\n\nweathermetrics\n\nFunctions to convert between weather metrics. Authors: Brooke\nAnderson and Roger Peng.\n\nwgsea\n\nWilcoxon based gene set enrichment analysis. Author: Chris Wallace.\n\nwidals\n\nWeighting by Inverse Distance with Adaptive Least Squares for\nMassive Space-Time Data. Author: Dave Zes.\n\nx12GUI\n\nX12 — Graphical User Interface. Authors: Daniel Schopfhauser,\nAlexander Kowarik, Angelika Meraner. In view:\nTimeSeries.\n\nxoi\n\nTools for analyzing crossover interference. Authors: Karl W Broman,\nIl youp Kwak.\n\nzendeskR\n\nZendesk API Wrapper. Author: Tanya Cashorali.\n\nzyp\n\nZhang + Yue-Pilon trends. Authors: David Bronaugh, Arelia Werner for\nthe Pacific Climate Impacts Consortium.\n\n2 Other changes\nThe following packages were moved to the Archive: AIGIS,\nBiograph, BradleyTerry, CCMtools, CGene, CONOR, COZIGAM,\nCompetingRiskFrailty, Covpath, DCluster, DDHFm, DOSim,\nDeducerMMR, Depela, DescribeDisplay, Devore5, EMT,\nElectroGraph, EuclideanMaps, FourierDescriptors, GWAtoolbox,\nGeneclust, HFWutils, IFP, IQMNMR, MCE, MCLIME, MFDA,\nNMF, OptionsPdf, PairedData, RFA, RLadyBug, RScaLAPACK,\nRSiteSearch, Rassoc, Ratings, RcmdrPlugin.EHESsampling,\nRcmdrPlugin.SensoMineR, RcmdrPlugin.SurvivalT, Rfun, Rpad,\nSNPMaP, SNPMaP.cdm, SQLiteMap, SSSR, SV, SeqKnn,\nSpatialEpi, ThreeGroups, TwoWaySurvival, UScensus2000,\nUScensus2000add, VhayuR, accuracy, afc, agilp, amba,\namer, anm, backfitRichards, belief, biGraph, brainwaver,\nbspec, bwsurvival, chplot, clac, clustTool, clusterfly,\nclustvarsel, codep, colorout, compOverlapCorr, concord,\ncopulaedas, covRobust, crossdes, crosshybDetector,\ncthresh, cwhmisc, cyphid, dcens, diamonds, digitize,\ndtt, dyad, edci, envelope, epinet, exactmaxsel,\nextfunnel, favir, ffmanova, financial, fptdApprox, frbf,\nfuzzyOP, gRC, gafit, gbev, gcmrec, geneARMA, hot,\nipptoolbox, iteRates, iv, jit, knn, knncat,\nlabeltodendro, latticedl, lda.cv, lodplot, mapLD,\nmaptree, margLikArrogance, mblm, mecdf, mimR, moc,\nmosaicManip, mrp, mrpdata, mrt, msBreast, msDilution,\nmsProcess, msProstate, mtsc, networksis, nfda,\nnonbinROC, nutshellDE, onemap, paltran, panel, papply,\npartitionMap, pcaPA, permax, pgfSweave, phpSerialize,\nphybase, qAnalyst, quaternions, rTOFsPRO, rWMBAT, rake,\nrichards, rrp, rrv, rsdepth, rtv, satin, scaleCoef,\nsdtalt, seas, simco, similarityRichards, skellam,\nskills, soil.spec, somplot, spssDDI, stream.net,\nsurveillance, swst, tikzDevice, triads, truncgof, twslm,\nuncompress, voronoi, xterm256\nThe following packages were resurrected from the Archive: MAMA,\nNBPSeq, Peak2Trough, RPPanalyzer, SAPP, Sim.DiffProcGUI,\nSimHap, TSTutorial, copuladaes, dummies, geoPlot,\ngmvalid, latentnet, lcd, mapReduce, miniGUI, muStat,\nnonrandom, pheno, statnet, treelet, ttime.\nThe following packages had to be removed: Deducer, PBSmapping,\nfEcofin, ggdendro.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2012-2-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2012-2 issue.",
    "author": [
      {
        "name": "Martyn Plummer",
        "url": {}
      }
    ],
    "date": "2012-12-01",
    "categories": [],
    "contents": "\n\nWelcome to volume 4, issue 2 of The R Journal.\n1 Changes to the journal\nThomson Reuters has informed us that The R Journal has been accepted for\nlisting in the Science Citation Index-Expanded (SCIE), including the Web\nof Science, and the ISI Alerting Service, starting with volume 1, issue\n1 (May 2009). This complements the current listings by EBSCO and the\nDirectory of Open Access Journals (DOAJ), and completes a process\nstarted by Peter Dalgaard in 2010.\nSince The R Journal publishes two issues per year, the delay between\nacceptance and publication can sometimes be long. In July, we started\nputting accepted articles online, so that they are immediately\naccessible. If you want to see a preview of some of the articles in the\nnext issue, go to the “Accepted Articles” page on the R Journal Web\nsite.\nA minor formatting change in this issue is the inclusion of back-links\nin the bibliography. Citations in The R Journal are hyper-links that\nwill take you to the corresponding entry in the bibliography. The\nback-links now enable you to go back to the referring page.\n2 In this issue\nThe Contributed Research Articles section of this issue opens with a\ntrio of papers by Paul Murrell, explaining advanced graphics features of\nR. We then have two papers on multilevel models: Il Do Ha, Maengseok\nNoh, and Youngjo Lee present the\nfrailtyHL package for\nfitting survival models, and Rense Nieuwenhuis, Manfred te Grotenhuis,\nand Ben Pelzer present the\ninfluence.ME\npackage for diagnostics in multilevel models. We also have two papers on\nflexible and robust regression: Zhenghua Nie and Jeffrey Racine discuss\nnonparametric regression splines with the\ncrs package, while John\nKloke and Joseph McKean discuss rank-based regression for linear models\nwith Rfit. Finally, Kayvan\nSadeghi and Giovanni Marchetti show how the\nggm package can be used to\nexamine the statistical properties of mixed graphical models.\n3 Changes to the editorial board\nThe end of the year also brings changes to the editorial board. Heather\nTurner is leaving the board after four years. Heather has been on the\nboard since the first issue of R News and, in addition to being an\nindefatigable editor, is responsible for much of the computational\ninfrastructure of the journal. Another departure is Bill Venables, who\nhas been editor of Programmer’s Niche since the very first issue of R\nNews – the predecessor of The R Journal – in 2001. The last paper\nhandled by Bill is a survey of naming conventions in R by Rasmus Bååth.\nWe welcome Bettina Grün, who will join the editorial board in 2013. I\nshall be stepping down as Editor-in-Chief and will be leaving this task\nin the capable hands of Hadley Wickham.\n\n\nCRAN packages used\nfrailtyHL, influence.ME, crs, Rfit, ggm\nCRAN Task Views implied by cited packages\nGraphicalModels, MixedModels, Optimization, Survival\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2012-2-r-changes/",
    "title": "Changes in R",
    "description": "The 'Changes in R' article from the 2012-2 issue.",
    "author": [
      {
        "name": "The R Core Team",
        "url": {}
      }
    ],
    "date": "2012-12-01",
    "categories": [],
    "contents": "\n\nCHANGES IN R VERSION 2.15.2\n\nNEW FEATURES\nThe X11() window gains an icon: the latter may be especially\nuseful on Ubuntu’s ‘Unity’ interface.\nThe WM_CLASS should be set in circumstances where the Window\nManager failed to make use of X11 resource settings.\n(Contributed by Philip Johnson.)\nThe \"Date\" and \"POSIXt\" methods for cut() will accept an\nunsorted breaks argument (as the default method does, although\nthis was undocumented). (Wish of PR#14961.)\nReference class methods (in the methods package) that use other\nmethods in an indirect way (e.g. by sapply()) must tell the code\nanalysis to include that method. They can now do so by invoking\n$usingMethods().\nMore Polish translations are available: for the RGui menus and for\nseveral recommended packages.\nMultistratum MANOVA works. In fact, it seems to have done so for\nyears in spite of the help page claiming it did not.\nqqline() has new optional arguments distribution, probs and\nqtype, following the example of lattice’s panel.qqmathline().\nThe handling of single quotes in the en@quot pseudo-language has\nbeen slightly improved. Double quotes are no longer converted.\nNew functions checkPoFiles() and checkPoFile() have been added\nto the tools package to check for consistency of format strings in\ntranslation files.\nmodel.matrix(~1, ...) now also contains the same rownames that\nless trivial formulae produce. (Wish of PR#14992, changes the output\nof several packages.)\nMisuse of rep() on undocumented types of objects (e.g. calls) is\nnow reported as an error.\nThe included LAPACK has been updated to 3.4.1, with some patches\nfrom the current SVN sources. (Inter alia, this resolves\nPR#14692.)\nfile.copy(recursive = TRUE) has some additional checks on user\nerror leading to attempted infinite recursion (and on some platforms\nto crashing R).\nPCRE has been updated to version 8.31, a bug-fix release.\nThe included version of liblzma has been updated to version 5.0.4,\na minor bug-fix release.\nNew function .bincode(), a ‘bare-bones’ version of\ncut.default(labels = FALSE) for use in packages with image()\nmethods.\nThe HTML manuals now use directional single quotes.\nmaintainer() now converts embedded new lines to spaces. It no\nlonger gives a non-obvious error for non-installed packages.\nThe X11() device has some protection against being used with\nforked processes via package parallel.\nSetting the environment variable R_OSX_VALGRIND (to any value)\nallows R to be run under valgrind on Mac OS 10.6 and 10.7\n(valgrind currently has very limited support for 10.8), provided\nsystem() is not used (directly or indirectly). This should not be\nneeded for valgrind >= 3.8.1.\nThe \"model.frame\" method for lm() uses xlevels: this is safer\nif data was supplied or model = FALSE was used and the levels of\nfactors used in the fit had been re-ordered since fitting.\nSimilarly, model.frame(fm, data=<data>) copies across the\nvariables used for safe prediction from the fit.\nFunctions such as parLapply() in package parallel can make use\nof a default cluster if one is set. (Reported by Martin Morgan.)\nchol(pivot = TRUE, LINPACK = FALSE) is now available using LAPACK\n3.2 subroutine DPSTRF.\nThe functions .C(), .Call(), .External() and .Fortran() now\ncheck that they are called with an unnamed first argument: the\nformal arguments were changed from name= to .NAME= in R 2.13.0,\nbut some packages were still using the old name. This is currently a\nwarning, but will be an error in future.\nstep() no longer tries to improve a model with AIC of -Inf (a\nperfect fit).\nspline() and splinefun() gain a new method \"hyman\", an\nimplementation of Hyman’s method of constructing monotonic\ninterpolation splines. (Based on contributions of Simon Wood and Rob\nHyndman.)\nOn Windows, the C stack size has been increased to 64MB (it has been\n10MB since the days of 32MB RAM systems).\n\n\nPERFORMANCE IMPROVEMENTS\narray() is now implemented in C code (for speed) when data is\natomic or an unclassed list (so it is known that as.vector(data)\nwill have no class to be used by rep()).\nrep() is faster and uses less memory, substantially so in some\ncommon cases (e.g. if times is of length one or length.out is\ngiven, and each = 1).\nfindInterval(), tabulate(), cut(), hist() and\nimage.default() all use .Call() and are more efficient.\nduplicated(), unique() and similar now support vectors of\nlengths above \\(2^{29}\\) on 64-bit platforms.\nOmitting PACKAGE in .C() etc calls was supposed to make use of\nthe DLL from the namespace within which the enclosing function was\ndefined. It was less successful in doing so than it might be, and\ngave no indication it had failed.\nA new search strategy is very successful and gives a warning when it\nfails. In most cases this is because the entry point is not actually\nprovided by that package (and so PACKAGE should be used to\nindicate which package is intended) but in some the namespace does\nnot have a DLL specified by a useDynLib() directive so PACKAGE\nis required.\n\n\nUTILITIES\nR CMD check now checks if a package can be loaded by\nlibrary(pkgname, lib.loc = \"somewhere\") without being on the\nlibrary search path (unless it is already installed in .Library,\nwhen it always will be).\nR CMD check –as-cran notes ‘hidden’ files and directories (with\nnames starting with a dot) that are not needed for the operation of\nR CMD INSTALL or R CMD build: such files should be excluded from\nthe published tarball.\nR CMD check (if checking subdirectories) checks that the R code in\nany demos is ASCII and can be parsed, and warns if not.\nWhen R CMD Rd2pdf is used with inputenx.sty, it allows further\ncharacters (mainly for Eastern European languages) by including\nix-utf8enc.dfu (if available). (Wish of PR#14989.)\nR CMD build now omits several types of hidden files/directories,\nincluding inst/doc/.Rinstignore, vignettes/.Rinstignore,\n(.Rinstignore should be at top level), .deps under src,\n.Renviron, .Rprofile, .Rproj.user, .backups, .cvsignore,\n.cproject, .directory, .dropbox, .exrc, .gdb.history,\n.gitattributes, .gitignore, .gitmodules, .hgignore,\n.hgtags, .htaccess, .latex2html-init, .project, .seed,\n.settings, .tm_properties and various leftovers.\nR CMD check now checks for .C(), .Call(), .External() and\n.Fortran() calls in other packages, and gives a warning on those\nfound from R itself (which are not part of the API and change\nwithout notice: many will be changed for R 2.16.0).\n\n\nC-LEVEL FACILITIES\nThe limit for R_alloc on 64-bit platforms has been raised to just\nunder 32GB (from just under 16GB).\nThe misuse of .C(\"name\", ..., PACKAGE = foo) where foo is an\narbitrary R object is now an error.\nThe misuse .C(\"name\",..., PACKAGE = \"\") is now warned about in\nR CMD check, and will be an error in future.\n\n\nDEPRECATED AND DEFUNCT\nUse of array() with a 0-length dim argument is deprecated with a\nwarning (and was contrary to the documentation).\nUse of tapply() with a 0-length INDEX list is deprecated with a\nwarning.\nTranslation packages are deprecated.\nCalling rep() or rep.int() on a pairlist is deprecated and will\ngive a warning. In any case, rep() converted a pairlist to a list\nso you may as well do that explicitly.\nEntry point rcont2 is no longer part of the API, and will move to\npackage stats in R 2.16.0.\nThe ‘internal’ graphics device invoked by\n.Call(\"R_GD_nullDevice\", package = \"grDevices\") is about to be\nremoved: use pdf(file = NULL) instead.\neigen(EISPACK = TRUE), chol(pivot = FALSE, LINPACK = TRUE),\nchol2inv(LINPACK = TRUE), solve(LINPACK = TRUE) and\nsvd(LINPACK = TRUE) are deprecated and give a warning.\nThey were provided for compatibility with R 1.7.0 (Mar 2003)!\nThe ‘internal function’ kappa.tri() has been renamed to\n.kappa_tri() so it is not inadvertently called as a method for\nclass \"tri\".\nFunctions sessionData() and browseAll() in package methods are\non a help page describing them as ‘deprecated’ and are now formally\ndeprecated.\n\n\nPACKAGE INSTALLATION\nFor a Windows or Mac OS X binary package install,\ninstall.packages() will check if a source package is available on\nthe same repositories, and report if it is a later version or there\nis a source package but no binary package available.\nThis check can be suppressed: see the help page.\ninstall.packages(type = \"both\") has been enhanced. In interactive\nuse it will ask whether to choose the source version of a package if\nthe binary version is older and contains compiled code, and also\nasks if source packages with no binary version should be installed).\n\n\nINSTALLATION\nThere is a new configure option –with-libtiff (mainly in case\nthe system installation needs to be avoided).\nLAPACK 3.4.1 does use some Fortran 90 features, so g77 no longer\nsuffices.\nIf an external LAPACK is used, it must be version 3.2 or later.\n\n\nBUG FIXES\nOn Windows, starting Rterm via R.exe caused Ctrl-C to misbehave.\n(PR#14948)\nThe tools::latexToUtf8() function missed conversions that were\ncontained within braces.\nLong timezone specifications (such as a file name preceded by :)\ncould crash as.POSIXlt. (PR#14945)\nR CMD build –resave-data could fail if there was no data\ndirectory but there was an R/sysdata.rda file. (PR#14947)\nis.na() misbehaved on a 0-column data frame. (PR#14959)\nanova.lmlist() failed if test was supplied. (PR#14960)\nIt was unable to compute Cp tests for object of class \"lm\" (it\nassumed class \"glm\").\nThe formula method for sunflowerplot() now allows xlab and\nylab to be set. (Reported by Gerrit Eichner.)\nThe \"POSIXt\" and \"Date\" methods for hist() could fail on\nWindows where adjustments to the right-hand boundary crossed a DST\ntransition time.\nOn Windows, the code in as.POSIXct() to handle incorrectly\nspecified isdst fields might have resulted in NA being returned.\naov() and manova() gave spurious warnings about a singular error\nmodel in the multiresponse case.\nIn ns() and bs(), specifying knots = NULL is now equivalent to\nomitting it, also when df is specified. (PR#14970)\nsprintf() did not accept numbered arguments ending in zero.\n(PR#14975)\nrWishart() could overflow the C stack and maybe crash the R\nprocess for dimensions of several hundreds or more. (Reported by\nMichael Braun on R-sig-mac.)\nBase package vignettes (e.g. vignette(\"Sweave\")) were not fully\ninstalled in builds of R from the tarball.\nlchoose() and choose() could overflow the C stack and crash R.\nWhen given a 0-byte file and asked to keep source references,\nparse() read input from stdin() instead.\npdf(compress = TRUE) did not delete temporary files it created\nuntil the end of the R session. (PR#14991)\nlogLik() did not detect the error of applying it to a\nmultiple-response linear model. (PR#15000)\nfile.copy(recursive = TRUE) did not always report FALSE for a\nfailure two or more directories deep.\nqgeom() could return -1 for extremely small q. (PR#14967.)\nsmooth.spline() used DUP = FALSE which allowed its compiled C\ncode to change the function: this was masked by the default\nbyte-compilation. (PR#14965.)\nIn Windows, the GUI preferences for foreground color were not always\nrespected. (Reported by Benjamin Wells.)\nOn OS X, the Quartz versions of the bitmap devices did not respect\nantialias = \"none\". (PR#15006.)\nunique() and similar would infinite-loop if called on a vector of\nlength > \\(2^{29}\\) (but reported that the vector was too long for\n\\(2^{30}\\) or more).\nparallel::stopCluster() now works with MPI clusters without\nsnow being on the search\npath.\nterms.formula() could exhaust the stack, and the stack check did\nnot always catch this before the segfault. (PR#15013)\nsort.list(method = \"radix\") could give incorrect results on\ncertain compilers (seen with clang on Mac OS 10.7 and\nXcode 4.4.1).\nbacksolve(T, b) gave incorrect results when nrows(b) > ncols(T)\nand b had more than one column.\nIt could segfault or give nonsense if k was specified as more than\nncols(T).\nsmooth.spline() did not check that a specified numeric spar was\nof length 1, and gave corrupt results if it was of length 0.\nProtection added to do_system. (PR#15025)\nPrinting of vectors with names > 1000 characters now works\ncorrectly rather than truncating. (PR#15028)\nqr() for a complex matrix did not pivot the column names.\n–with-blas=’-framework vecLib’ now also works on OS X 10.8.\nR CMD check no longer fails with an error if a DESCRIPTION file\nincorrectly contains a blank line. (Reported by Bill Dunlap.)\ninstall.packages(type = \"both\") could call chooseCRANmirror()\ntwice.\nlm.wfit() could segfault in R 2.15.1 if all the weights were zero.\n(PR#15044)\nA malformed package name could cause R CMD INSTALL to write\noutside the target library.\nSome of the quality control functions (e.g. tools::checkFF()) were\nwrongly identifying the source of S4 methods in a package and so not\nchecking them.\nThe default type of display by browseEnv() when using R.app on\nMac OS X has been incorrect for a long time.\nThe implementation of importMethodsFrom in a NAMESPACE file\ncould be confused and fail to find generics when importing from\nmultiple packages (reported and fixed by Michael Lawrence).\nThe detection of the C stack direction is better protected against\ncompiler optimization. (PR#15011.)\nLong custom line types would sometimes segfault on the\ncairographics-based devices. (PR#15055.)\ntools::checkPoFile() unprotected too early in its C code and so\nsegfaulted from time to time.\nThe Fortran code underlying nlminb() could infinite-loop if any of\nthe input functions returned NA or NaN. This is now an error for\nthe gradient or Hessian, and a warning for the function (with the\nvalue replaced by Inf). (In part, PR#15052.)\nThe code for creating coerce() methods could generate false notes\nabout ambiguous selection; the notes have been suppressed for this\nfunction.\narima.sim() could give too long an output in some corner cases (in\npart, PR#15068).\nanova.glm() with test = \"Rao\" didn’t work when models included\nan offset. (Reported by Søren Feodor Nielsen.)\nas.data.frame.matrix() could return invalid data frame with no\nrow.names attribute for 0-row matrix. (Reported by Hervé Pagès.)\nCompilation with the vecLib or Accelerate frameworks on OS X\nwithout using that also for LAPACK is more likely to be successful.\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2012-2-r-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2012-2 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2012-12-01",
    "categories": [],
    "contents": "\n1 Donations and new members\nDonations\nJonathan M. Lees, USA\nNew benefactors\nDsquare, Germany\nCybaea Limited, U.K.\nNew supporting members\nPavel Motuzenko, Czech Republic\nLudwig Hothorn, Germany\nGergely Darocz, Hungary\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2012-1-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2012-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2012-06-01",
    "categories": [],
    "contents": "\n\nNew CRAN task views\nDifferentialEquations\n\nTopic: Differential Equations. Maintainer: Karline Soetaert and\nThomas Petzoldt. Packages: CollocInfer, FME, GillespieSSA,\nPBSddesolve, PKfit, PKtools, PSM, ReacTran,\nbvpSolve\\(^*\\), deSolve\\(^*\\), deTestSet, ecolMod, mkin,\nnlmeODE, pomp, pracma, rootSolve\\(^*\\), scaRabee, sde\\(^*\\),\nsimecol.\n\n(* = core package)\nNew packages in CRAN task views\nBayesian\n\nAtelieR, Runuran, iterLap.\n\nChemPhys\n\nFITSio, cda, dielectric, planar, ringscale, stellaR.\n\nClinicalTrials\n\nAGSDest, CRTSize\\(^*\\), FrF2, MSToolkit\\(^*\\), PIPS\\(^*\\),\nPowerTOST\\(^*\\), TEQR\\(^*\\), ThreeGroups, adaptTest\\(^*\\),\nasd\\(^*\\), bcrm\\(^*\\), clinsig, conf.design, crossdes\\(^*\\),\ndfcrm\\(^*\\), longpower, medAdherence, nppbib, pwr\\(^*\\),\nqtlDesign\\(^*\\), samplesize\\(^*\\), tdm.\n\nCluster\n\nCoClust, bgmm, pmclust, psychomix.\n\nDistributions\n\nLambertW, TSA, agricolae, e1071, emdbook, modeest,\nmoments, npde, s20x.\n\nEconometrics\n\ngeepack, intReg, lfe, mhurdle, pcse, spdep, sphet.\n\nEnvironmetrics\n\nInterpol.T, RMAWGEN, anm, boussinesq, fast, hydroPSO,\nnsRFA, qualV, rconifers, sensitivity, tiger.\n\nExperimentalDesign\n\ndynaTree, mixexp, plgp, tgp.\n\nFinance\n\nAmericanCallOpt, BurStFin, FinAsym, VarSwapPrice,\ncrp.CSFP, frmqa.\n\nHighPerformanceComputing\n\nBatchExperiments, BatchJobs, WideLM, cloudRmpi,\ncloudRmpiJars, harvestr, pmclust, rreval.\n\nMachineLearning\n\nGMMBoost, RPMM, bst, evtree, gamboostLSS, gbev,\nlongRPart, oblique.tree, obliqueRF, partykit, rattle,\nrpartOrdinal.\n\nMedicalImaging\n\nDATforDCEMRI\\(^*\\), arf3DS4\\(^*\\), neuRosim\\(^*\\), occ\\(^*\\).\n\nNaturalLanguageProcessing\n\nKoNLP, RcmdrPlugin.TextMining, TextRegression, koRpus,\nmaxent, tau, textcat, textir, tm.plugin.dc,\ntm.plugin.mail, topicmodels, wordcloud.\n\nOfficialStatistics\n\nFFD, pxR.\n\nOptimization\n\nGenSA, Rmalschains, clpAPI, cplexAPI, crs, dfoptim,\nglpkAPI, hydroPSO, mcga, nloptr, powell.\n\nPhylogenetics\n\nSYNCSA, auteur, paleotree, pmc.\n\nPsychometrics\n\nCDM, MPTinR, MplusAutomation, betareg, irtrees, pathmox,\nplspm.\n\nReproducibleResearch\n\nRExcelInstaller, SWordInstaller, knitr, rtf, tables.\n\nSpatial\n\nMcSpatial, geospt, rangeMapper, vec2dtrans.\n\nSurvival\n\nBaSTA, CPE, CPHshape, OIsurv, RobustAFT, Survgini,\nahaz, asbio, bwsurvival, dcens, dynpred, dynsurv,\nflexsurv, kaps, logconcens, parfm, riskRegression, rtv,\nsurvC1, tlmec.\n\nTimeSeries\n\nInterpol.T, RMAWGEN, deseasonalize, quantspec, tempdisagg.\n\ngR\n\nabn, gRim.\n\n(* = core package)\n1 New contributed packages\nAGD\n\nAnalysis of Growth Data. Author: Stef van Buuren.\n\nARTIVA\n\nTime-varying DBN inference with the ARTIVA (Auto Regressive TIme\nVArying) model. Authors: S. Lebre and G. Lelandais.\n\nAce\n\nAssay-based Cross-sectional Estimation of incidence rates. Authors:\nBrian Claggett, Weiliang Qiu, Rui Wang.\n\nAdaptFitOS\n\nAdaptive Semiparametric Regression with Simultaneous Confidence\nBands. Authors: Manuel Wiesenfarth and Tatyana Krivobokova.\n\nAmericanCallOpt\n\nThis package includes pricing function for selected American call\noptions with underlying assets that generate payouts. Author: Paolo\nZagaglia. In view:\nFinance.\n\nAssotesteR\n\nStatistical Tests for Genetic Association Studies. Author: Gaston\nSanchez.\n\nBBmisc\n\nMiscellaneous helper functions for B. Bischl. Authors: Bernd Bischl,\nMichel Lang, Olaf Mersmann.\n\nBCEA\n\nBayesian Cost Effectiveness Analysis. Author: Gianluca Baio.\n\nBINCO\n\nBootstrap Inference for Network COstruction. Authors: Shuang Li, Li\nHsu, Jie Peng, Pei Wang.\n\nBVS\n\nBayesian Variant Selection: Bayesian Model Uncertainty Techniques\nfor Genetic Association Studies. Author: Melanie Quintana.\n\nBaSAR\n\nBayesian Spectrum Analysis in R. Authors: Emma Granqvist, Matthew\nHartley and Richard J Morris.\n\nBatchExperiments\n\nStatistical experiments on batch computing clusters. Authors: Bernd\nBischl, Michel Lang, Olaf Mersmann. In view:\nHighPerformanceComputing.\n\nBatchJobs\n\nBatch computing with R. Authors: Bernd Bischl, Michel Lang, Olaf\nMersmann. In view:\nHighPerformanceComputing.\n\nBayesLCA\n\nBayesian Latent Class Analysis. Authors: Arthur White and Brendan\nMurphy.\n\nBayesLogit\n\nLogistic Regression. Authors: Nicolas Polson, James G. Scott, and\nJesse Windle.\n\nBayesSingleSub\n\nComputation of Bayes factors for interrupted time-series designs.\nAuthors: Richard D. Morey, Rivka de Vries.\n\nBayesXsrc\n\nR Package Distribution of the BayesX C++ Sources. Authors: Daniel\nAdler [aut, cre], Thomas Kneib [aut], Stefan Lang [aut],\nNikolaus Umlauf [aut], Achim Zeileis [aut].\n\nBerkeleyEarth\n\nData Input for Berkeley Earth Surface Temperature. Author: Steven\nMosher.\n\nBrailleR\n\nImproved access for blind useRs. Author: Jonathan Godfrey.\n\nBurStFin\n\nBurns Statistics Financial. Author: Burns Statistics. In view:\nFinance.\n\nCALINE3\n\nR interface to Fortran 77 implementation of CALINE3. Author: David\nHolstius.\n\nCARBayes\n\nSpatial areal unit modelling. Author: Duncan Lee.\n\nCARE1\n\nStatistical package for population size estimation in\ncapture-recapture models. Author: T.C. Hsieh.\n\nCARramps\n\nReparameterized and marginalized posterior sampling for conditional\nautoregressive models. Authors: Kate Cowles and Stephen Bonett; with\nthanks to Juan Cervantes, Dong Liang, Alex Sawyer, and Michael\nSeedorff.\n\nCAscaling\n\nCA scaling in R. Author: J. H. Straat.\n\nCPHshape\n\nFind the maximum likelihood estimator of the shape constrained\nhazard baseline and the effect parameters in the Cox proportional\nhazards model. Authors: Rihong Hui and Hanna Jankowski. In view:\nSurvival.\n\nCPMCGLM\n\nCorrection of the pvalue after multiple coding. Authors: Jeremie\nRiou, Amadou Diakite, and Benoit Liquet.\n\nCUMP\n\nAnalyze Multivariate Phenotypes by Combining Univariate results.\nAuthors: Xuan Liu and Qiong Yang.\n\nCePa\n\nCentrality-based pathway enrichment. Author: Zuguang Gu.\n\nChoiceModelR\n\nChoice Modeling in R. Authors: Ryan Sermas, assisted by John V.\nColias.\n\nCoClust\n\nCopula based cluster analysis. Authors: Francesca Marta Lilja Di\nLascio, Simone Giannerini. In view:\nCluster.\n\nCompounding\n\nComputing Continuous Distributions. Authors: Bozidar V. Popovic,\nSaralees Nadarajah, Miroslav M. Ristic.\n\nConjointChecks\n\nA package to check the cancellation axioms of conjoint measurement.\nAuthor: Ben Domingue.\n\nCpGassoc\n\nAssociation between Methylation and a phenotype of interest.\nAuthors: Barfield, R., Conneely, K., Kilaru,V.\n\nCrypticIBDcheck\n\nIdentifying cryptic relatedness in genetic association studies.\nAuthors: Annick Joelle Nembot-Simo, Jinko Graham and Brad McNeney.\n\nDDD\n\nDiversity-dependent diversification. Author: Rampal S. Etienne &\nBart Haegeman.\n\nDIRECT\n\nBayesian Clustering of Multivariate Data Under the Dirichlet-Process\nPrior. Authors: Audrey Qiuyan Fu, Steven Russell, Sarah J. Bray and\nSimon Tavare.\n\nDSL\n\nDistributed Storage and List. Authors: Ingo Feinerer [aut], Stefan\nTheussl [aut, cre], Christian Buchta [ctb].\n\nDandEFA\n\nDandelion Plot for R-mode Exploratory Factor Analysis. Authors:\nArtur Manukyan, Ahmet Sedef, Erhan Cene, Ibrahim Demir (Advisor).\n\nDeducerSpatial\n\nDeducer for spatial data analysis. Authors: Ian Fellows and Alex\nRickett with contributions from Neal Fultz.\n\nDetSel\n\nA computer program to detect markers responding to selection.\nAuthor: Renaud Vitalis.\n\nDiscreteLaplace\n\nDiscrete Laplace distribution. Authors: Alessandro Barbiero,\nRiccardo Inchingolo.\n\nDistance\n\nA simple way to fit detection functions to distance sampling data\nand calculate abundance/density for biological populations. Author:\nDavid L. Miller.\n\nETLUtils\n\nUtility functions to execute standard ETL operations (using package\nff) on large data. Author: Jan Wijffels.\n\nEcoTroph\n\nEcoTroph modelling support. Authors: J. Guitton and M. Colleter, D.\nGascuel.\n\nEffectStars\n\nVisualization of Categorical Response Models. Author: Gunther\nSchauberger.\n\nEpiEstim\n\nEpiEstim: a package to estimate time varying reproduction numbers\nfrom epidemic curves. Author: Anne Cori.\n\nEstSimPDMP\n\nEstimation of the jump rate and simulation for\npiecewise-deterministic Markov processes. Author: Romain Azais.\n\nExact\n\nExact Unconditional Tests for 2x2 Tables. Author: Peter Calhoun.\n\nExomeDepth\n\nCalls CNV from exome sequence data. Author: Vincent Plagnol.\n\nExpDes\n\nExperimental Designs package. Authors: Eric Batista Ferreira, Portya\nPiscitelli Cavalcanti, Denismar Alves Nogueira.\n\nFacPad\n\nBayesian Sparse Factor Analysis model for the inference of pathways\nresponsive to drug treatment. Author: Haisu Ma.\n\nFactMixtAnalysis\n\nFactor Mixture Analysis with covariates. Author: Cinzia Viroli.\n\nFamilias\n\nProbabilities for Pedigrees given DNA data. Authors: Petter Mostad\nand Thore Egeland.\n\nFastImputation\n\nLearn from training data then quickly fill in missing data. Author:\nStephen R. Haptonstahl.\n\nFinAsym\n\nClassifies implicit trading activity from market quotes and computes\nthe probability of informed trading. Author: Paolo Zagaglia. In\nview: Finance.\n\nForeCA\n\nForeCA — Forecastable Component Analysis. Author: Georg M. Goerg.\n\nG2Sd\n\nGrain-size Statistics and Description of Sediment. Authors: Regis K.\nGallon, Jerome Fournier.\n\nGOGANPA\n\nGO-Functional-Network-based Gene-Set-Analysis. Author: Billy Chang.\n\nGPvam\n\nMaximum Likelihood Estimation of the Generalized Persistence\nValue-Added Model. Authors: Andrew Karl, Yan Yang, and Sharon Lohr.\n\nGUniFrac\n\nGeneralized UniFrac distances. Author: Jun Chen.\n\nGenOrd\n\nSimulation of ordinal and discrete variables with given correlation\nmatrix and marginal distributions. Authors: Alessandro Barbiero,\nPier Alda Ferrari.\n\nGeoLight\n\nAnalysis of light based geolocator data. Authors: Simeon Lisovski,\nSilke Bauer, Tamara Emmenegger.\n\nGrid2Polygons\n\nConvert Spatial Grids to Polygons. Author: Jason C. Fisher.\n\nHIest\n\nHybrid index estimation. Author: Ben Fitzpatrick.\n\nHMMmix\n\nThe HMMmix (HMM with mixture of gaussians as emission distribution)\npackage. Authors: Stevenn Volant and Caroline Berard.\n\nHolidays\n\nHoliday and halfday data, for use with the TimeWarp package. Author:\nLars Hansen.\n\nIC2\n\nInequality and Concentration Indices and Curves. Author: Didier\nPlat.\n\nIPMpack\n\nBuilds and analyses Integral Projection Models (IPMs). Authors: CJE\nMetcalf, SM McMahon, R Salguero-Gomez, E Jongejans.\n\nISBF\n\nIterative Selection of Blocks of Features — ISBF. Author: Pierre\nAlquier.\n\nIgorR\n\nRead binary files saved by Igor Pro (including Neuromatic data).\nAuthor: Greg Jefferis.\n\nInterpol.T\n\nHourly interpolation of multiple temperature daily series. Author:\nEmanuele Eccel & Emanuele Cordano. In views:\nEnvironmetrics,\nTimeSeries.\n\nJMLSD\n\nJoint Modeling of Longitudinal and Survival Data — Power\nCalculation. Authors: Emil A. Cornea, Liddy M. Chen, Bahjat F.\nQaqish, Haitao Chu, and Joseph G. Ibrahim.\n\nJPSurv\n\nMethods for population-based cancer survival analysis. Author:\nYongwu Shao.\n\nJmisc\n\nJulian Miscellaneous Function. Author: TszKin Julian Chan.\n\nJohnsonDistribution\n\nJohnson Distribution. Authors: A.I. McLeod and Leanna King.\n\nLCFdata\n\nData sets for package LMERConvenienceFunctions. Authors: Antoine\nTremblay.\n\nLIHNPSD\n\nPoisson Subordinated Distribution. Author: Stephen Horng-Twu Lihn.\n\nLOST\n\nMissing morphometric data simulation and estimation. Authors: J.\nArbour and C. Brown.\n\nLTR\n\nPerform LTR analysis on microarray data. Author: Paul C. Boutros.\n\nLambda4\n\nEstimation techniques for the reliability estimate: Maximized\nLambda4. Author: Tyler Hunt.\n\nLeafAngle\n\nFits, plots, and summarizes leaf angle distributions. Author: Remko\nDuursma.\n\nLinearizedSVR\n\nLinearized Support Vector Regression. Authors: Sriharsha\nVeeramachaneni and Ken Williams.\n\nLuminescence\n\nPackage for Luminescence Dating data analysis. Authors: Sebastian\nKreutzer [aut, cre], Christoph Schmidt [aut, ctb], Margret C.\nFuchs [aut, ctb], Michael Dietze [aut, ctb], Manfred Fischer\n[aut, ctb], Markus Fuchs [ths].\n\nMAMS\n\nDesigning Multi-Arm Multi-Stage Studies. Authors: Thomas Jaki and\nDominic Magirr.\n\nMAVTgsa\n\nOrdinary least square test and Multivariate Analysis Of Variance\ntest with n contrasts. Authors: Chih-Yi Chien, Chen-An Tsai,\nChing-Wei Chang, and James J. Chen.\n\nMImix\n\nMixture summary method for multiple imputation. Authors: Russell\nSteele, Naisyin Wang, and Adrian Raftery. In view:\nOfficialStatistics.\n\nMLEP\n\nMaximum likelihood estimate of penetrance parameters. Author: Yuki\nSugaya.\n\nMM\n\nThe multiplicative multinomial distribution. Authors: Robin K. S.\nHankin and P. M. E. Altham.\n\nMRCE\n\nAuthor: Adam J. Rothman.\n\nMcSpatial\n\nNonparametric spatial data analysis. Author: Daniel McMillen. In\nview: Spatial.\n\nMetaDE\n\nMeta analysis of multiple microarray data. Authors: Jia Li and\nXingbin Wang.\n\nMetaPath\n\nPerform the Meta-Analysis for Pathway Enrichment analysis (MAPE).\nAuthors: Kui Shen and Geroge Tseng.\n\nMixMod\n\nAnalysis of Mixed Models. Authors: Alexandra Kuznetsova, Per Bruun\nBrockhoff.\n\nMobilize\n\nMobilize plots and functions. Author: Jeroen Ooms.\n\nMomocs\n\nShape Analysis of Outlines. Authors: Vincent Bonhomme, Sandrine\nPicq, Julien Claude.\n\nMorseGen\n\nSimple raw data generator based on user-specified summary\nstatistics. Author: Brendan Morse.\n\nMultiOrd\n\nGeneration of multivariate ordinal variates. Authors: Anup Amatya\nand Hakan Demirtas.\n\nNHPoisson\n\nModelling and validation of non homogeneous Poisson processes.\nAuthor: Ana C. Cebrian.\n\nNPMPM\n\ntertiary probabilistic model in predictive microbiology for use in\nfood manufacture. Author: Nadine Schoene.\n\nNbClust\n\nAn examination of indices for determining the number of clusters.\nAuthors: Malika Charrad and Nadia Ghazzali and Veronique Boiteau and\nAzam Niknafs.\n\nNetComp\n\nNetwork Generation and Comparison. Authors: Shannon M. Bell, Lyle D.\nBurgoon.\n\nNetPreProc\n\nNetPreProc: Network Pre-Processing and normalization. Authors:\nGiorgio Valentini.\n\nNlsyLinks\n\nUtilities and kinship information for Behavior Genetics and\nDevelopmental research using the NLSY. Authors: Will Beasley, Joe\nRodgers, David Bard, and Kelly Meredith.\n\nNormalGamma\n\nNormal-gamma convolution model. Authors: S. Plancade and Y.\nRozenholc.\n\nOIdata\n\nData sets and supplements (OpenIntro). Authors: Andrew P Bray and\nDavid M Diez.\n\nOIsurv\n\nSurvival analysis supplement to OpenIntro guide. Author: David M\nDiez. In view:\nSurvival.\n\nOLScurve\n\nOLS growth curve trajectories. Authors: Phil Chalmers and Carrie\nSmith and Matthew Sigal.\n\nOOmisc\n\nOzgur-Ozlem Miscellaneous. Authors: Ozgur Asar, Ozlem Ilk.\n\nOhmage\n\nR Client for Mobilize/Andwellness server. Author: Jeroen Ooms.\n\nOneHandClapping\n\nPrediction of condition-specific transcription factor interactions.\nAuthor: Sebastian Dümcke.\n\nOpenStreetMap\n\nAccess to open street map raster images. Authors: Ian Fellows, using\nthe JMapViewer library by Jan Peter Stotz.\n\nOptimalCutpoints\n\nComputing optimal cutpoints in diagnostic tests. Authors: Monica\nLopez-Raton, Maria Xose Rodriguez-Alvarez.\n\nOptionsPdf\n\nThis package estimates a mix of lognormal distributions from\ninterest-rate option data. Author: Paolo Zagaglia.\n\nPEIP\n\nFunctions for Aster Book on Inverse Theory. Author: Jonathan M.\nLees.\n\nPIPS\n\nPredicted Interval Plots. Authors: Daniel G. Muenz, Ray Griner,\nHuichao Chen, Lijuan Deng, Sachiko Miyahara, and Scott R. Evans,\nwith contributions from Lingling Li, Hajime Uno, and Laura M.\nSmeaton. In view:\nClinicalTrials.\n\nPKPDmodels\n\nPharmacokinetic/pharmacodynamic models. Authors: Anne Dubois, Julie\nBertand, France Mentre and Douglas Bates.\n\nPairedData\n\nPaired Data Analysis. Author: Stephane Champely.\n\nParamHelpers\n\nHelpers for parameters in black-optimization, tuning and maching\nlearning. Authors: Bernd Bischl, Patrick Koch.\n\nPopGenome\n\nPopulation genetic analysis. Author: Bastian Pfeifer.\n\nPrivateLR\n\nDifferentially private regularized logistic regression. Author:\nStaal A. Vinterbo.\n\nQRM\n\nProvides R-language code to examine Quantitative Risk Management\nconcepts. Author: Bernhard Pfaff.\n\nQUIC\n\nRegularized sparse inverse covariance matrix estimation. Authors:\nCho-Jui Hsieh [aut], Matyas A. Sustik [aut, cre], Inderjit S.\nDhillon [aut], Pradeep Ravikumar [aut].\n\nQuasiSeq\n\nAuthor: Steve Lund.\n\nR.devices\n\nEnhanced methods for handling graphical devices. Author: Henrik\nBengtsson.\n\nR2BayesX\n\nEstimate Structured Additive Regression Models with BayesX. Authors:\nNikolaus Umlauf [aut, cre], Thomas Kneib [aut], Stefan Lang\n[aut], Achim Zeileis [aut].\n\nR2G2\n\nConverting R CRAN outputs into Google Earth. Author: Nils Arrigo.\n\nR2OpenBUGS\n\nRunning OpenBUGS from R. Authors: originally written as R2WinBUGS by\nAndrew Gelman; changes and packaged by Sibylle Sturtz and Uwe\nLigges. With considerable contributions by Gregor Gorjanc and Jouni\nKerman. Adapted to R2OpenBUGS from R2WinBUGS by Neal Thomas.\n\nR2admb\n\nADMB to R interface functions. Authors: Ben Bolker, Hans Skaug.\n\nR330\n\nAn R package for Stats 330. Authors: Alan Lee, Blair Robertson.\n\nRAFM\n\nAdmixture F-model. Authors: Markku Karhunen, Uni. Helsinki.\n\nRCALI\n\nCalculation of the Integrated Flow of Particles between Polygons.\nAuthors: Annie Bouvier, Kien Kieu, Kasia Adamczyk, and Herve Monod.\n\nRCassandra\n\nR/Cassandra interface. Author: Simon Urbanek.\n\nRForcecom\n\nRForcecom provides the connection to Force.com (Salesforce.com)\nfrom R. Author: Takekatsu Hiramura.\n\nRGIFT\n\nCreate quizzes in GIFT Format. Authors: María José Haro-Delicado,\nVirgilio Gómez-Rubio and Francisco Parreño-Torres.\n\nRIFS\n\nRandom Iterated Function System (RIFS). Authors: Pavel V. Moskalev,\nAlexey G. Bukhovets and Tatyana Ya. Biruchinskay.\n\nRMallow\n\nFit Multi-Modal Mallows’ Models to ranking data. Author: Erik\nGregory.\n\nRMendeley\n\nInterface to Mendeley API methods. Authors: Carl Boettiger, Duncan\nTemple Lang.\n\nRSeed\n\nborenstein analysis. Author: Claus Jonathan Fritzemeier.\n\nRTDAmeritrade\n\nAuthor: Theodore Van Rooy.\n\nRcmdrPlugin.EBM\n\nRcmdr Evidence Based Medicine Plug-In package. Author:\nDaniel-Corneliu Leucuta.\n\nRcmdrPlugin.KMggplot2\n\nRcmdr Plug-In for Kaplan-Meier Plot and Other Plots by Using the\nggplot2 Package. Authors: Triad sou. and Kengo NAGASHIMA.\n\nRcmdrPlugin.SCDA\n\nRcmdr plugin for designing and analyzing single-case experiments.\nAuthors: Isis Bulte and Patrick Onghena.\n\nRcmdrPlugin.UCA\n\nUCA Rcmdr Plug-in. Author: and Manuel Munoz-Marquez.\n\nRcmdrPlugin.doBy\n\nRcmdr doBy Plug-In. Author: Jonathan Lee.\n\nRcmdrPlugin.pointG\n\nRcmdr Graphical POINT of view for questionnaire data Plug-In.\nAuthor: Stephane Champely.\n\nRcppSMC\n\nRcpp bindings for Sequential Monte Carlo. Authors: Dirk Eddelbuettel\nand Adam M. Johansen.\n\nRdistance\n\nDistance sampling analyses. Author: Trent McDonald.\n\nReCiPa\n\nRedundancy Control in Pathways databases. Author: Juan C. Vivar.\n\nRenextGUI\n\nGUI for Renext. Authors: Yves Deville and IRSN.\n\nRfmriVC\n\nVarying stimulus coefficient fMRI models in R. Authors: Ludwig\nBothmann, Stefanie Kalus.\n\nRmalschains\n\nContinuous Optimization using Memetic Algorithms with Local Search\nChains (MA-LS-Chains) in R. Authors: Christoph Bergmeir, Daniel\nMolina, José M. Benítez. In view:\nOptimization.\n\nRmisc\n\nRmisc: Ryan Miscellaneous. Author: Ryan M. Hope.\n\nRmixmod\n\nAn interface of MIXMOD. Authors: Remi Lebret and Serge Iovleff and\nFlorent Langrognet, with contributions from C. Biernacki and G.\nCeleux and G. Govaert.\n\nRquake\n\nSeismic Hypocenter Determination. Author: Jonathan M. Lees.\n\nRxCEcolInf\n\nR x C Ecological Inference With Optional Incorporation of Survey\nInformation. Authors: D. James Greiner, Paul Baines, and Kevin M.\nQuinn. In view:\nBayesian.\n\nSAScii\n\nImport ASCII files directly into R using only a SAS input script.\nAuthor: Anthony Joseph Damico.\n\nSCMA\n\nSingle-Case Meta-Analysis. Authors: Isis Bulte and Patrick Onghena.\n\nSCRT\n\nSingle-Case Randomization Tests. Authors: Isis Bulte and Patrick\nOnghena.\n\nSCVA\n\nSingle-Case Visual Analysis. Authors: Isis Bulte and Patrick\nOnghena.\n\nSCperf\n\nSupply Chain Perform. Author: Marlene Silva Marchena.\n\nSEER2R\n\nreading and writing SEER*STAT data files. Author: Jun Luo.\n\nSGL\n\nFit a GLM (or cox model) with a combination of lasso and group lasso\nregularization. Authors: Noah Simon, Jerome Friedman, Trevor Hastie,\nand Rob Tibshirani.\n\nSGPdata\n\nExemplar data sets for SGP analyses. Authors: Damian W. Betebenner,\nAdam Van Iwaarden and Ben Domingue.\n\nSKAT\n\nSNP-set (Sequence) Kernel Association Test. Authors: Seunggeun Lee,\nLarisa Miropolsky and Micheal Wu.\n\nSNSequate\n\nStandard and Nonstandard Statistical Models and Methods for Test\nEquating. Author: Jorge Gonzalez Burgos.\n\nSPA3G\n\nSPA3G: R package for the method of Li and Cui (2012). Authors:\nShaoyu Li and Yuehua Cui.\n\nSPIn\n\nOptimal Shortest Probability Intervals. Author: Ying Liu.\n\nSPSL\n\nSite Percolation on Square Lattice (SPSL). Author: Pavel V.\nMoskalev.\n\nSRMA\n\nSRMA Analysis of Array-based Sequencing Data. Authors: Wenyi Wang,\nNianxiang Zhang, Yan Xu.\n\nSemiParSampleSel\n\nSemiparametric Sample Selection Modelling with Continuous Response.\nAuthors: Giampiero Marra and Rosalba Radice.\n\nSightabilityModel\n\nWildlife Sightability Modeling. Author: John Fieberg.\n\nSimile\n\nInteract with Simile models. Author: Simulistics Ltd.\n\nSoilR\n\nModels of Soil Organic Matter Decomposition. Authors: Carlos A.\nSierra, Markus Mueller.\n\nSparseGrid\n\nSparse grid integration in R. Author: Jelmer Ypma.\n\nSpatialTools\n\nAuthor: Joshua French.\n\nSteinerNet\n\nSteiner approach for Biological Pathway Graph Analysis. Authors:\nAfshin Sadeghi, Holger Froehlich.\n\nStressStrength\n\nComputation and estimation of reliability of stress-strength models.\nAuthors: Alessandro Barbiero, Riccardo Inchingolo.\n\nStructR\n\nStructural geology tools. Author: Jeffrey R. Webber.\n\nSunterSampling\n\nSunter’s sampling design. Authors: Alessandro Barbiero, Giancarlo\nManzi.\n\nTCC\n\nTCC: tag count comparison package. Authors: Koji Kadota, Tomoaki\nNishiyama, Kentaro Shimizu.\n\nTPAM\n\nAuthor: Yuping Zhang.\n\nTTAinterfaceTrendAnalysis\n\nTemporal Trend Analysis Graphical Interface. Authors: David Devreker\n[aut], Alain Lefebvre [aut, cre].\n\nTUWmodel\n\nLumped hydrological model developed at the Vienna University of\nTechnology for education purposes. Authors: Juraj Parajka, Alberto\nViglione.\n\nTaxonstand\n\nTaxonomic standardization of plant species names. Author: Luis\nCayuela.\n\nTestSurvRec\n\nStatistical tests to compare two survival curves with recurrent\nevents. Author: Dr. Carlos Martinez.\n\nThresholdROC\n\nOptimum threshold estimation based on cost function in a two and\nthree state setting. Author: Konstantina Skaltsa.\n\nTimeWarp\n\nDate calculations and manipulation. Authors: Tony Plate, Jeffrey\nHorner, Lars Hansen.\n\nVarEff\n\nVariation of effective population size. Authors: Natacha Nikolic and\nClaude Chevalet.\n\nVarSwapPrice\n\nPricing a variance swap on an equity index. Author: Paolo Zagaglia.\nIn view: Finance.\n\nVariABEL\n\nTesting of genotypic variance heterogeneity to detect potentially\ninteracting SNP. Author: Maksim Struchalin.\n\nVoss\n\nGeneric Voss algorithm (random sequential additions). Author:\nPavel V. Moskalev.\n\nWeightedPortTest\n\nWeighted Portmanteau Tests for Time Series Goodness-of-fit. Authors:\nThomas J. Fisher and Colin M. Gallagher.\n\nWideLM\n\nFitting many skinny linear models to a single data set. Authors:\nMark Seligman, with contributions from Chris Fraley. In view:\nHighPerformanceComputing.\n\nacer\n\nThe ACER Method for Extreme Value Estimation. Author: Even Haug.\n\nacs\n\nDownload and manipulate data from the US Census American Community\nSurvey. Author: Ezra Haber Glenn.\n\nadagio\n\nDiscrete and Global Optimization Routines. Author: Hans W Borchers.\n\nadaptMCMC\n\nImplementation of a generic adaptive Monte Carlo Markov Chain\nsampler. Authors: Andreas Scheidegger,.\n\nageprior\n\nPrior distributions for molecular dating. Author: Michael\nMatschiner.\n\nanametrix\n\nConnects to Anametrix. Author: Roman Jugai.\n\nanoint\n\nAnalysis of interactions. Authors: Ravi Varadhan and Stephanie\nKovalchik.\n\nappell\n\nCompute Appell’s F1 hypergeometric function. Authors: Daniel Sabanes\nBove with contributions by F. D. Colavecchia, R. C. Forrey, G.\nGasaneo, N. L. J. Michel, L. F. Shampine, M. V. Stoitsov and H. A.\nWatts.\n\napple\n\nApproximate Path for Penalized Likelihood Estimators. Authors: Yi\nYu, Yang Feng.\n\nassertive\n\nReadable check functions to ensure code integrity. Authors: Richard\nCotton [aut, cre].\n\nawsMethods\n\nClass and Methods definitions for packages aws, adimpro, fmri,\ndwi. Author: Joerg Polzehl.\n\nbams\n\nBreakpoint annotation model smoothing. Author: Toby Dylan Hocking.\n\nbandit\n\nFunctions for simple A/B split test and multi-armed bandit analysis.\nAuthor: Thomas Lotze.\n\nbase64\n\nBase 64 encoder/decoder. Authors: Romain Francois, based on code by\nBob Trower available at http://base64.sourceforge.net/.\n\nbayesMCClust\n\nMixtures-of-Experts Markov Chain Clustering and Dirichlet\nMultinomial Clustering. Author: Christoph Pamminger.\n\nbayesPop\n\nProbabilistic Population Projection. Authors: Hana Sevcikova, Adrian\nRaftery.\n\nbcrm\n\nBayesian continuous reassessment method (CRM) designs for Phase I\ndose-finding trials. Author: Michael Sweeting. In view:\nClinicalTrials.\n\nbda\n\nAlgorithms for Birth Data Analysis. Author: Bin Wang.\n\nbetafam\n\nDetecting rare variants for quantitative traits using nuclear\nfamilies. Author: Wei Guo.\n\nbetapart\n\nPartitioning beta diversity into turnover and nestedness components.\nAuthors: Andres Baselga and David Orme.\n\nbigdata\n\nBig Data Analytics. Authors: Han Liu, Tuo Zhao.\n\nbigml\n\nR bindings for the BigML API. Authors: Justin Donaldson [aut,\ncre].\n\nbinomlogit\n\nEfficient MCMC for Binomial Logit Models. Author: Agnes Fussl.\n\nbionetdata\n\nBiological and chemical data networks. Authors: Matteo Re.\n\nbisectr\n\nTools to find bad commits with git bisect. Author: Winston Chang.\n\nbit64\n\nA S3 class for vectors of 64bit integers. Author: Jens Oehlschlägel.\n\nbiwavelet\n\nConduct univariate and bivariate wavelet analyses. Authors: Tarik C.\nGouhier, Aslak Grinsted.\n\nbmp\n\nRead Windows Bitmap (BMP) images. Author: Gregory Jefferis.\n\nboss\n\nBoosted One-Step Statistics: Fast and accurate approximations for\nGLM, GEE and Mixed models for use in GWAS. Author: Arend Voorman.\n\nboussinesq\n\nAnalytic Solutions for (ground-water) Boussinesq Equation. Author:\nEmanuele Cordano. In view:\nEnvironmetrics.\n\nbpkde\n\nBack Projected Kernel Density Estimation. Authors: Kjell Konis,\nVictor Panaretos.\n\ncatdata\n\nCategorical Data. Authors: Gerhard Tutz, Gunther Schauberger.\n\ncec2005benchmark\n\nBenchmark for the CEC 2005 Special Session on Real-Parameter\nOptimization. Authors: Yasser González-Fernández and Marta Soto.\n\ncepp\n\nContext Driven Exploratory Projection Pursuit. Author: Mohit Dayal.\n\ncin\n\nCausal Inference for Neuroscience. Authors: Xi (Rossi) LUO with\ncontributions from Dylan Small, Chiang-shan Li, and Paul Rosenbaum.\n\nclhs\n\nConditioned Latin Hypercube Sampling. Author: Pierre Roudier.\n\ncloudRmpi\n\nCloud-based MPI Parallel Processing for R (cloudRmpi). Author:\nBarnet Wagman. In view:\nHighPerformanceComputing.\n\ncloudRmpiJars\n\nThird-party jars for cloudRmpi. Author: Barnet Wagman. In view:\nHighPerformanceComputing.\n\ncloudUtil\n\nCloud Util Plots. Authors: Christian Panse, Ermir Qeli.\n\ncoloc\n\nColocalisation tests of two genetic traits. Author: Chris Wallace.\n\ncomparison\n\nMultivariate likelihood ratio calculation and evaluation. Author:\nDavid Lucy.\n\ncomplex.surv.dat.sim\n\nSimulation of recurrent event survival data. Authors: David Moriña,\nCentre Tecnològic de Nutrició i Salut and Albert Navarro.\n\ncompound.Cox\n\nRegression estimation based on the compound covariate methed under\nthe Cox proportional hazard model. Author: Takeshi Emura & Yi-Hau\nChen.\n\ncondmixt\n\nConditional Density Estimation with Neural Network Conditional\nMixtures. Author: Julie Carreau.\n\ncpm\n\nSequential Parametric and Nonparametric Change Detection. Authors:\nGordon J. Ross, incorporating code from the GNU Scientific Library.\n\ncrblocks\n\nCategorical Randomized Block Data Analysis. Authors: David\nAllingham, D.J. Best.\n\ncrp.CSFP\n\nCreditRisk+ portfolio model. Authors: Dr. Matthias Fischer, Kevin\nJakob & Stefan Kolb. In view:\nFinance.\n\ncrrstep\n\nStepwise covariate selection for the Fine & Gray competing risks\nregression model. Author: Ravi Varadhan & Deborah Kuk.\n\ncsound\n\nAccessing Csound functionality through R. Author: Ethan Brown.\n\ncumplyr\n\nExtends ddply to allow calculation of cumulative quantities. Author:\nJohn Myles White.\n\ncurvclust\n\nCurve clustering. Authors: Madison Giacofci, Sophie Lambert-Lacroix,\nGuillemette Marot, Franck Picard.\n\ndataframe\n\nFast data frames. Author: Tim Hesterberg.\n\ndeTestSet\n\nTestset for differential equations. Authors: Karline Soetaert, Jeff\nCash, Francesca Mazzia. In view:\nDifferentialEquations.\n\ndeltaPlotR\n\nIdentification of dichotomous differential item functioning (DIF)\nusing Angoff’s Delta Plot method. Authors: David Magis, Bruno Facon.\n\ndepend.truncation\n\nInference for parametric and semiparametric models based on\ndependent truncation data. Authors: Takeshi Emura.\n\ndeseasonalize\n\nOptimal deseasonalization for geophysical time series using AR\nfitting. Author: A. I. McLeod. In view:\nTimeSeries.\n\ndgmb\n\ndgmb Simulating data for PLS structural models. Authors: Alba\nMartinez-Ruiz and Claudia Martinez-Araneda.\n\ndiffEq\n\nFunctions from the book Solving Differential Equations in R. Author:\nKarline Soetaert.\n\ndisclap\n\nDiscrete Laplace Family. Authors: Mikkel Meyer Andersen and Poul\nSvante Eriksen.\n\ndisclapmix\n\nDiscrete Laplace mixture inference using the EM algorithm. Authors:\nMikkel Meyer Andersen and Poul Svante Eriksen.\n\ndiscreteMTP\n\nMultiple testing procedures for discrete test statistics. Authors:\nRuth Heller [aut], Hadas Gur [aut], Shay Yaacoby [aut, cre].\n\ndisp2D\n\n2D Hausdorff and Simplex Dispersion Orderings. Author: Guillermo\nAyala.\n\ndistory\n\nDistance Between Phylogenetic Histories. Authors: John Chakerian and\nSusan Holmes. In view:\nPhylogenetics.\n\ndkDNA\n\nDiffusion kernels on a set of genotypes. Authors: Gota Morota and\nMasanori Koyama.\n\ndma\n\nDynamic model averaging. Authors: Tyler H. McCormick, Adrian\nRaftery, David Madigan.\n\ndoParallel\n\nForeach parallel adaptor for the parallel package. Author:\nRevolution Analytics.\n\ndostats\n\nCompute statistics helper functions. Author: Andrew Redd.\n\neigendog\n\nEigenDog. Author: The EigenDog Team.\n\nendorse\n\nR Package for Analyzing Endorsement Experiments. Authors: Yuki\nShiraito, Kosuke Imai.\n\nevents\n\nStore and manipulate event data. Author: Will Lowe.\n\nevora\n\nEpigenetic Variable Outliers for Risk prediction Analysis. Author:\nAndrew E Teschendorff.\n\nexptest\n\nTests for Exponentiality. Authors: Ruslan Pusev and Maxim Yakovlev.\n\nextraBinomial\n\nExtra-binomial approach for pooled sequencing data. Author: Xin\nYang.\n\nfaisalconjoint\n\nFaisal Conjoint Model: A New Approach to Conjoint Analysis. Authors:\nFaisal Afzal Siddiqui, Ghulam Hussain, and Mudassiruddin.\n\nfanc\n\nPenalized likelihood factor analysis via nonconvex penalty. Authors:\nKei Hirose, Michio Yamamoto.\n\nfanovaGraph\n\nBuilding Kriging models from FANOVA graphs. Authors: Jana Fruth,\nThomas Muehlenstaedt, Olivier Roustant.\n\nfaoutlier\n\nInfluential case detection methods for factor analysis and SEM.\nAuthor: Phil Chalmers.\n\nfastGHQuad\n\nFast Rcpp implementation of Gauss-Hermite quadrature. Author:\nAlexander W Blocker.\n\nfastcox\n\nLasso and elastic-net penalized Cox’s regression in high dimensions\nmodels using the cocktail algorithm. Authors: Yi Yang, Hui Zou.\n\nfgof\n\nFast Goodness-of-fit Test. Authors: Ivan Kojadinovic and Jun Yan.\n\nfilterviewR\n\nGet started easily with FilterView from R. Author: Nelson Ray.\n\nfishmove\n\nPrediction of Fish Movement Parameters. Author: Johannes Radinger.\n\nfoodweb\n\nvisualisation and analysis of food web networks. Author: Giselle\nPerdomo.\n\nfracprolif\n\nFraction Proliferation via a quiescent growth model. Authors: Shawn\nGarbett, Darren Tyson.\n\nfrmqa\n\nFinancial Risk Management and Quantitative Analysis. Author:\nThanh T. Tran. In view:\nFinance.\n\nfrt\n\nFull Randomization Test. Authors: Giangiacomo Bravo, Lucia\nTamburino.\n\nfume\n\nFUME package. Author: Santander Meteorology Group.\n\nfwsim\n\nFisher-Wright Population Simulation. Authors: Mikkel Meyer Andersen\nand Poul Svante Eriksen.\n\ngammSlice\n\nGeneralized additive mixed model analysis via slice sampling.\nAuthors: Tung Pham and Matt Wand.\n\ngcdnet\n\nA generalized coordinate descent (GCD) algorithm for computing the\nsolution path of the hybrid Huberized support vector machine (HHSVM)\nand its generalization. Authors: Yi Yang, Hui Zou.\n\ngenomicper\n\nCircular Genomic Permutation using GWAS p-values of association.\nAuthors: Claudia P. Cabrera-Cardenas, Pau Navarro, Chris S. Haley.\n\ngeospt\n\nSpatial geostatistics; some geostatistical and radial basis\nfunctions, prediction and cross validation; design of optimal\nspatial sampling networks based on geostatistical modelling.\nAuthors: Carlos Melo, Alí Santacruz, Oscar Melo and others. In view:\nSpatial.\n\ngeotools\n\nGeo tools. Author: Antoine Lucas.\n\ngglasso\n\nGroup Lasso Penalized Learning Using A Unified BMD Algorithm.\nAuthors: Yi Yang, Hui Zou.\n\ngldist\n\nAn Asymmetry-Steepness Parameterization of the Generalized Lambda\nDistribution. Authors: Yohan Chalabi and Diethelm Wuertz.\n\nglmmGS\n\nGauss-Seidel Generalized Linear Mixed Model solver. Authors: Michele\nMorara, Louise Ryan, Subharup Guha, Christopher Paciorek.\n\ngooglePublicData\n\nAn R library to build Google’s Public Data Explorer DSPL Metadata\nfiles. Author: George Vega Yon.\n\ngovdat\n\nInterface to API methods for government data. Author: Scott\nChamberlain.\n\ngraphComp\n\nVisual graph comparison. Authors: Khadija El Amrani, Ulrich\nMansmann.\n\ngridDebug\n\nDebugging Grid Graphics. Authors: Paul Murrell and Velvet Ly.\n\ngridGraphviz\n\nDrawing Graphs with Grid. Author: Paul Murrell.\n\ngrowcurves\n\nBayesian semiparametric growth curve models that additionally\ninclude multiple membership random effects. Author: Terrance\nSavitsky.\n\ngsbDesign\n\nGroup Sequential Bayes Design. Authors: Florian Gerber, Thomas\nGsponer.\n\ngsmaRt\n\nGene Set Microarray Testing. Authors: Stephan Artmann, Mathias\nFuchs.\n\ngvcm.cat\n\nRegularized Categorial Effects/Categorial Effect Modifiers in GLMs.\nAuthor: Margret-Ruth Oelker.\n\nharvestr\n\nA Parallel Simulation Framework. Author: Andrew Redd. In view:\nHighPerformanceComputing.\n\nhiPOD\n\nhierarchical Pooled Optimal Design. Author: Wei E. Liang.\n\nhitandrun\n\n“Hit and Run” method for sampling uniformly form convex shapes.\nAuthor: Gert van Valkenhoef.\n\nhof\n\nMore higher order functions for R. Author: Hadley Wickham.\n\nhttr\n\nTools for working with URLs and HTTP. Author: Hadley Wickham.\n\nhydroPSO\n\nModel-Independent Particle Swarm Optimisation for Environmental\nModels. Authors: Mauricio Zambrano-Bigiarini [aut, cre] and\nRodrigo Rojas [ctb]. In views:\nEnvironmetrics,\nOptimization.\n\niDEMO\n\nintegrated degradation models. Authors: Ya-Shan Cheng, Chien-Yu\nPeng.\n\niGasso\n\nGenetic association tests. Author: Dr. Kai Wang.\n\niSubpathwayMiner\n\nThe package can implement the graph-based reconstruction, analyses,\nand visualization of the KEGG pathways. Author: Chunquan Li.\n\nidbg\n\nR debugger. Author: Ronen Kimchi.\n\nigraph0\n\nNetwork analysis and visualization. Author: Gabor Csardi.\n\nigraphdata\n\nA collection of network data sets for the igraph package. Author:\nGabor Csardi.\n\nimputeYn\n\nImputing the last largest censored datum under weighted least\nsquares. Authors: Hasinur Rahaman Khan and Ewart Shaw.\n\nintReg\n\nInterval Regression. Author: Ott Toomet. In view:\nEconometrics.\n\nintpoint\n\nlinear programming solver by the interior point method and\ngraphically (two dimensions). Author: Alejandro Quintela del Rio.\n\nirace\n\nIterated Racing Procedures. Authors: Manuel López-Ibáñez, Jérémie\nDubois-Lacoste, Thomas Stützle, Mauro Birattari, Eric Yuan and\nPrasanna Balaprakash.\n\nirtrees\n\nEstimation of Tree-Based Item Response Models. Authors: Ivailo\nPartchev and Paul De Boeck. In view:\nPsychometrics.\n\nivbma\n\nBayesian Instrumental Variable Estimation and Model Determination\nvia Conditional Bayes Factors. Authors: Alex Lenkoski, Anna Karl,\nAndreas Neudecker.\n\niwtp\n\nNumerical evaluation willingness to pay based on interval data.\nAuthors: Yuri Belyaev, Wenchao Zhou.\n\njmec\n\nFit joint model for event and censoring with cluster-level\nfrailties. Author: Willem M. van der Wal.\n\njoineR\n\nJoint modelling of repeated measurements and time-to-event data.\nAuthors: Pete Philipson, Ines Sousa, Peter Diggle, Paula Williamson,\nRuwanthi Kolamunnage-Dona, Robin Henderson.\n\nkappaSize\n\nSample Size Estimation Functions for Studies of Interobserver\nAgreement. Author: Michael A Rotondi.\n\nkaps\n\nK Adaptive Partitioning for Survival data. Authors: Soo-Heang Eo and\nHyungJun Cho. In view:\nSurvival.\n\nkequate\n\nThe kernel method of test equating. Authors: Bjorn Andersson, Kenny\nBranberg and Marie Wiberg.\n\nknitr\n\nA general-purpose package for dynamic report generation in R.\nAuthor: Yihui Xie. In view:\nReproducibleResearch.\n\nknnGarden\n\nMulti-distance based k-Nearest Neighbors. Author: Boxian Wei & Fan\nYang & Xinmiao Wang & Yanni Ge.\n\nkoRpus\n\nAn R Package for Text Analysis. Authors: m.eik michalke, with\ncontributions from Earl Brown, Alberto Mirisola, and Laura Hauser.\nIn view:\nNaturalLanguageProcessing.\n\nkriging\n\nOrdinary Kriging. Author: Omar E. Olmedo.\n\nktspair\n\nk-Top Scoring Pairs for Microarray Classification. Author: Julien\nDamond.\n\nlabeledLoop\n\nLabeled Loop. Author: Kohske Takahashi.\n\nlava\n\nLinear Latent Variable Models. Author: Klaus K. Holst.\n\nlava.tobit\n\nLVM with censored and binary outcomes. Author: Klaus K. Holst.\n\nleapp\n\nlatent effect adjustment after primary projection. Authors: Yunting\nSun, Nancy R.Zhang, Art B. Owen.\n\nleiv\n\nBivariate linear errors-in-variables estimation. Author: David\nLeonard.\n\nlestat\n\nA package for LEarning STATistics. Author: Petter Mostad.\n\nlikelihood\n\nMethods for maximum likelihood estimation. Author: Lora Murphy.\n\nlisp\n\nList-processing à la SRFI-1. Author: Peter Danenberg.\n\nlle\n\nLocally linear embedding. Authors: Holger Diedrich, Dr. Markus Abel\n(Department of Physics, University Potsdam).\n\nlmbc\n\nLinear Model Bias Correction for RNA-Seq Data. Author: David\nDalpiaz.\n\nlmf\n\nFunctions for estimation and inference of selection in\nage-structured populations. Author: Thomas Kvalnes.\n\nlogitnorm\n\nFunctions for the logitnormal distribution. Author: Thomas Wutzler.\n\nlongclust\n\nModel-Based Clustering and Classification for Longitudinal Data.\nAuthors: P. D. McNicholas, K. Raju Jampani and Sanjeena Subedi.\n\nlqmm\n\nLinear Quantile Mixed Models. Author: Marco Geraci.\n\nlsr\n\nCompanion to \"Learning Statistics with R\". Author: Daniel Navarro.\n\nlxb\n\nFast LXB file reader. Author: Winckler.\n\nmada\n\nMeta-Analysis of Diagnostic Accuracy (mada). Author: Philipp\nDoebler.\n\nmakeProject\n\nCreates an empty package framework for the LCFD format. Author: Noah\nSilverman.\n\nmakeR\n\nPackage for managing projects with multiple versions derived from a\nsingle source repository. Author: Jason Bryer.\n\nmalaria.em\n\nEM Estimation of Malaria Haplotype Probabilities from Multiply\nInfected Human Blood Samples. Author: Xiaohong Li.\n\nmarkdown\n\nMarkdown rendering for R. Authors: JJ Allaire, Jeffrey Horner,\nVicent Marti, and Natacha Porte.\n\nmarqLevAlg\n\nAn algorithm for least-squares curve fitting. Authors: D.\nCommenges, M. Prague and Amadou Diakite.\n\nmaxlike\n\nModel species distributions by estimating the probability of\noccurrence using presence-only data. Authors: Richard Chandler and\nAndy Royle.\n\nmcbiopi\n\nMatrix Computation Based Identification Of Prime Implicants. Author:\nHolger Schwender.\n\nmcmcse\n\nMonte Carlo standard errors for MCMC. Author: James M. Flegal.\n\nmets\n\nAnalysis of Multivariate Event Times. Authors: Klaus K. Holst and\nThomas Scheike.\n\nmgraph\n\nGraphing map attributes and non-map variables in R. Author: George\nOwusu.\n\nmiscFuncs\n\nMiscellaneous Useful Functions. Author: Benjamin M. Taylor.\n\nmlgt\n\nMulti-Locus Geno-Typing. Author: Dave T. Gerrard.\n\nmmand\n\nMathematical Morphology in Any Number of Dimensions. Author: Jon\nClayden.\n\nmmds\n\nMixture Model Distance Sampling (mmds). Author: David Lawrence\nMiller.\n\nmmm2\n\nMultivariate marginal models with shared regression parameters.\nAuthors: Ozgur Asar, Ozlem Ilk.\n\nmmod\n\nModern measures of population differentiation. Author: David Winter.\n\nmobForest\n\nModel based Random Forest analysis. Authors: Nikhil Garge and Barry\nEggleston.\n\nmosaicManip\n\nProject MOSAIC (mosaic-web.org) manipulate\nexamples. Authors: Andrew Rich, Daniel Kaplan, Randall Pruim.\n\nmpMap\n\nMulti-parent RIL genetic analysis. Author: Emma Huang.\n\nmpc\n\nMPC — Multiple Precision Complex Library. Author: Murray Stokely.\n\nmpoly\n\nSymbolic computation and more with multivariate polynomials. Author:\nDavid Kahle.\n\nmrds\n\nMark-Recapture Distance Sampling (mrds). Authors: Jeff Laake, David\nBorchers, Len Thomas, David Miller and Jon Bishop.\n\nmrp\n\nMultilevel Regression and Poststratification. Authors: Andrew\nGelman, Michael Malecki, Daniel Lee, Yu-Sung Su.\n\nmrpdata\n\nData for Multilevel Regression and Poststratification. Authors:\nAndrew Gelman, Michael Malecki, Daniel Lee, Yu-Sung Su, Jiqiang Guo.\n\nmseapca\n\nMetabolite set enrichment analysis for factor loading in principal\ncomponent analysis. Author: Hiroyuki Yamamoto.\n\nmsgps\n\nDegrees of freedom of elastic net, adaptive lasso and generalized\nelastic net. Author: Kei Hirose.\n\nmultivator\n\nA multivariate emulator. Author: Robin K. S. Hankin.\n\nmuma\n\nMetabolomic Univariate and Multivariate Analysis. Authors: Edoardo\nGaude, Francesca Chignola, Dimitrios Spiliotopoulos, Silvia Mari,\nAndrea Spitaleri and Michela Ghitti.\n\nmyepisodes\n\nMyEpisodes RSS/API functions. Author: Matt Malin.\n\nnadiv\n\nFunctions to construct non-additive genetic relatedness matrices.\nAuthor: Matthew Wolak.\n\nnetworkDynamic\n\nDynamic Extensions for Network Objects. Authors: Ayn Leslie-Cook,\nZack Almquist, Pavel N. Krivitsky, Skye Bender-deMoll, David R.\nHunter, Martina Morris, Carter T. Butts.\n\nneuroblastoma\n\nNeuroblastoma. Author: Toby Dylan Hocking.\n\nnlsmsn\n\nFitting nonlinear models with scale mixture of skew-normal\ndistributions. Authors: Aldo Garay, Marcos Prates and Victor Lachos.\n\noblique.tree\n\nOblique Trees for Classification Data. Author: Alfred Truong. In\nview:\nMachineLearning.\n\nocc\n\nEstimates PET neuroreceptor occupancies. Author: Joaquim Radua. In\nview:\nMedicalImaging.\n\nokmesonet\n\nRetrieve Oklahoma Mesonet climatological data. Authors: Brady\nAllred, Torre Hovick, Samuel Fuhlendorf.\n\nopencpu.demo\n\nOpenCPU Demo apps. Authors: Jeroen Ooms and others as specified in\nthe manual page.\n\nopm\n\nTools for analysing OmniLog(R) Phenotype Microarray data. Authors:\nMarkus Goeker, with contributions by Lea A.I. Vaas, Johannes\nSikorski, Nora Buddruhs and Anne Fiebig.\n\nops\n\nOptimal Power Space Transformation. Author: Micha Sammeth.\n\np2distance\n\nWelfare’s Synthetic Indicator. Authors: A.J. Perez-Luque; R.\nMoreno; R. Perez-Perez and F.J. Bonet.\n\npacose\n\niPACOSE, PACOSE and other methods for covariance selection. Authors:\nVincent Guillemot, Andreas Bender.\n\npairedCI\n\nConfidence intervals for the ratio of locations and for the ratio of\nscales of two paired samples. Authors: Cornelia Froemke, Ludwig\nHothorn and Michael Schneider.\n\npairheatmap\n\nA tool for comparing heatmaps. Author: Xiaoyong Sun.\n\npaleotree\n\nPaleontological and Phylogenetic Analyses of Evolution. Author:\nDavid Bapst. In view:\nPhylogenetics.\n\nparfm\n\nParametric Frailty Models. Authors: Federico Rotolo and Marco Munda.\nIn view: Survival.\n\npcaL1\n\nThree L1-Norm PCA Methods. Authors: Sapan Jot and Paul Brooks.\n\npcaPA\n\nParallel Analysis for ordinal and numeric data using polychoric and\nPearson correlations with S3 classes. Authors: Carlos A. Arias and\nVíctor H. Cervantes.\n\npcenum\n\nPermutations and Combinations Enumeration. Author: Benjamin Auder.\n\npdc\n\nPermutation Distribution Clustering. Author: Andreas M. Brandmaier.\n\npgmm\n\nParsimonious Gaussian mixture models. Authors: Paul McNicholas, Raju\nJampani, Aaron McDaid, Brendan Murphy, Larry Banks.\n\npgnorm\n\nThe p-generalized normal distribution. Author: Steve Kalke.\n\nphcfM\n\nphcfM R package. Author: Ghislain Vieilledent.\n\nphenology\n\nTools to manage a parametric function that describes phenology.\nAuthor: Marc Girondot.\n\nphia\n\nPost-Hoc Interaction Analysis. Author: Helios De Rosario-Martinez.\n\nphom\n\nPersistent Homology in R. Author: Andrew Tausz.\n\npkgmaker\n\nPackage development utilities. Author: Renaud Gaujoux.\n\nplmDE\n\nAdditive partially linear models for differential gene expression\nanalysis. Author: Jonas Mueller.\n\npmc\n\nPhylogenetic Monte Carlo. Author: Carl Boettiger. In view:\nPhylogenetics.\n\npmclust\n\nParallel Model-Based Clustering. Authors: Wei-Chen Chen, George\nOstrouchov. In views:\nCluster,\nHighPerformanceComputing.\n\npolywog\n\nBootstrapped Basis Regression with Oracle Model Selection. Authors:\nBrenton Kenkel and Curtis S. Signorino.\n\npopdemo\n\nProvides Tools For Demographic Modelling Using Projection Matrices.\nAuthors: Iain Stott, Dave Hodgson, Stuart Townley.\n\npostCP\n\nA package to estimate posterior probabilities in change-point models\nusing constrained HMM. Authors: Gregory Nuel and The Minh Luong.\n\nqLearn\n\nEstimation and inference for Q-learning. Authors: Jingyi Xin, Bibhas\nChakraborty, and Eric B. Laber.\n\nqmap\n\nQuantile-mapping for post-processing climate model output. Author:\nLukas Gudmundsson.\n\nqtbase\n\nInterface between R and Qt. Authors: Michael Lawrence, Deepayan\nSarkar.\n\nqtlhot\n\nInference for QTL Hotspots. Authors: Elias Chaibub Neto and Brian S\nYandell.\n\nqtlnet\n\nCausal Inference of QTL Networks. Authors: Elias Chaibub Neto and\nBrian S. Yandell.\n\nqtpaint\n\nQt-based painting infrastructure. Authors: Michael Lawrence,\nDeepayan Sarkar.\n\nqtutils\n\nMiscellaneous Qt-based utilities. Author: Deepayan Sarkar.\n\nquantspec\n\nQuantile-based Spectral Analysis of Time Series. Author: Tobias\nKley. In view:\nTimeSeries.\n\nrBeta2009\n\nThe Beta Random Number and Dirichlet Random Vector Generating\nFunctions. Authors: Ching-Wei Cheng, Ying-Chao Hung, Narayanaswamy\nBalakrishnan.\n\nrFerns\n\nRandom ferns classifier. Author: Miron B. Kursa.\n\nrSFA\n\nSlow Feature Analysis in R. Authors: Wolfgang Konen, Martin\nZaefferer, Patrick Koch; Bug hunting and testing by Ayodele Fasika,\nAshwin Kumar, Prawyn Jebakumar.\n\nrapport\n\nA report templating system. Authors: Aleksandar Blagotić and Gergely\nDaróczi.\n\nrbamtools\n\nReading, manipulation and writing BAM (Binary alignment) files.\nAuthor: Wolfgang Kaisers.\n\nrcppbugs\n\nR binding for cppbugs. Author: Whit Armstrong.\n\nrdryad\n\nDryad API interface. Authors: Scott Chamberlain [aut, cre], Carl\nBoettiger [aut], Karthik Ram [aut].\n\nreadMLData\n\nReading machine learning benchmark data sets from different sources\nin their original format. Author: Petr Savicky.\n\nreadbitmap\n\nRead bitmap images (BMP, JPEG, PNG) without external dependencies.\nAuthor: Gregory Jefferis.\n\nreams\n\nResampling-Based Adaptive Model Selection. Authors: Philip Reiss and\nLei Huang.\n\nrehh\n\nSearching for footprints of selection using Haplotype Homozygosity\nbased tests. Authors: Mathieu Gautier and Renaud Vitalis.\n\nrelSim\n\nRelative Simulator. Author: James M. Curran.\n\nreplicationDemos\n\nAgnotology. Author: Rasmus E. Benestad.\n\nrepresent\n\nDetermine the representativity of two multidimensional data sets.\nAuthor: Harmen Draisma.\n\nrgbif\n\nInterface to the Global Biodiversity Information Facility API\nmethods. Authors: Scott Chamberlain [aut, cre], Carl Boettiger\n[aut], Karthik Ram [aut].\n\nri\n\nri: R package for performing randomization-based inference for\nexperiments. Authors: Peter M. Aronow and Cyrus Samii.\n\nrisaac\n\nA fast cryptographic random number generator using ISAAC by Robert\nJenkins. Author: David L Gibbs.\n\nriskRegression\n\nRisk regression for survival analysis. Authors: Thomas Alexander\nGerds, Thomas Harder Scheike. In view:\nSurvival.\n\nrknn\n\nRandom KNN Classification and Regression. Author: Shengqiao Li.\n\nrngSetSeed\n\nInitialization of the R base random number generator\nMersenne-Twister with a vector of an arbitrary length. Author: Petr\nSavicky.\n\nrobustHD\n\nRobust methods for high-dimensional data. Author: Andreas Alfons.\n\nrobustfa\n\nAn Object Oriented Framework for Robust Factor Analysis. Author:\nYing-Ying Zhang (Robert).\n\nrolasized\n\nSolarized colours in R. Author: Christian Zang.\n\nror\n\nRobust Ordinal Regression MCDA library. Author: Tommi Tervonen.\n\nrpartScore\n\nClassification trees for ordinal responses. Authors: Giuliano\nGalimberti, Gabriele Soffritti, Matteo Di Maso.\n\nrplos\n\nInterface to PLoS Journals API methods. Authors: Scott Chamberlain,\nCarl Boettiger.\n\nrportfolios\n\nRandom portfolio generation. Author: Frederick Novomestky.\n\nrreval\n\nRemote R Evaluator (rreval). Author: Barnet Wagman. In view:\nHighPerformanceComputing.\n\nrriskDistributions\n\nCollection of functions for fitting distributions (related to the\n‘rrisk’ project). Authors: Natalia Belgorodski, Matthias Greiner,\nKristin Tolksdorf, Katharina Schueller.\n\nrsgcc\n\nGini methodology-based correlation and clustering analysis of both\nmicroarray and RNA-Seq gene expression data. Authors: Chuang Ma,\nXiangfeng Wang.\n\nrstiefel\n\nRandom orthonormal matrix generation on the Stiefel manifold.\nAuthor: Peter Hoff.\n\nsROC\n\nNonparametric Smooth ROC Curves for Continuous Data. Author:\nXiao-Feng Wang.\n\nscam\n\nShape constrained additive models. Author: Natalya Pya.\n\nscio\n\nSparse Column-wise Inverse Operator. Authors: Xi (Rossi) Luo and\nWeidong Liu.\n\nsdprisk\n\nMeasures of Risk for the Compound Poisson Risk Process with\nDiffusion. Authors: Benjamin Baumgartner, Riccardo Gatto.\n\nsemGOF\n\nGoodness-of-fit indeces for structural equations models. Author:\nElena Bertossi.\n\nsemTools\n\nUseful tools for structural equation modeling. Authors: Sunthud\nPornprasertmanit, Patrick Miller, Alex Schoemann, Yves Rosseel.\n\nsentiment\n\nTools for Sentiment Analysis. Author: Timothy P. Jurka.\n\nsessionTools\n\nTools for saving, restoring and teleporting R sessions. Author:\nMatthew D. Furia.\n\nsetwidth\n\nSet the value of options(\"width\") on terminal emulators. Author:\nJakson Aquino.\n\nsft\n\nFunctions for Systems Factorial Technology Analysis of Data.\nAuthors: Joe Houpt, Leslie Blaha.\n\nshotGroups\n\nAnalyze shot group data. Author: Daniel Wollschlaeger.\n\nsimSummary\n\nSimulation summary. Author: Gregor Gorjanc.\n\nsimsem\n\nSIMulated Structural Equation Modeling. Authors: Sunthud\nPornprasertmanit, Patrick Miller, Alexander Schoemann.\n\nsitools\n\nFormat a number to a string with SI prefix. Authors: Jonas Stein,\nBen Tupper.\n\nskewtools\n\nTools for analyze Skew-Elliptical distributions and related models.\nAuthor: Javier E. Contreras-Reyes.\n\nsmcure\n\nFit Semiparametric Mixture Cure Models. Authors: Chao Cai, Yubo Zou,\nYingwei Peng, Jiajia Zhang.\n\nsoilDB\n\nSoil Database Interface. Authors: D.E. Beaudette and J.M. Skovlin.\n\nsoobench\n\nSingle Objective Optimization Benchmark Functions. Author: Olaf\nMersmann Bernd Bischl.\n\nspMC\n\nContinuous Lag Spatial Markov Chains. Author: Luca Sartore.\n\nspaceExt\n\nExtension of SPACE. Author: Shiyuan He.\n\nspacom\n\nSpatially weighted context data for multilevel modelling. Authors:\nTill Junge, Sandra Penic, Guy Elcheroth.\n\nsparseLTSEigen\n\nRcppEigen back end for sparse least trimmed squares regression.\nAuthor: Andreas Alfons.\n\nsparsenet\n\nFit sparse linear regression models via nonconvex optimization.\nAuthors: Rahul Mazumder, Trevor Hastie, Jerome Friedman.\n\nspartan\n\nSpartan (Simulation Parameter Analysis R Toolkit ApplicatioN).\nAuthors: Kieran Alden, Mark Read, Paul Andrews, Jon Timmis, Henrique\nVeiga-Fernandes, Mark Coles.\n\nspatialprobit\n\nSpatial Probit Models. Authors: Stefan Wilhelm and Miguel Godinho de\nMatos.\n\nspcadjust\n\nFunctions for calibrating control charts. Authors: Axel Gandy and\nJan Terje Kvaloy.\n\nspclust\n\nSelective phenotyping for experimental crosses. Author: Emma Huang.\n\nspcov\n\nSparse Estimation of a Covariance Matrix. Authors: Jacob Bien and\nRob Tibshirani.\n\nspeedglm\n\nFitting Linear and Generalized Linear Models to large data sets.\nAuthor: Marco ENEA. In view:\nHighPerformanceComputing.\n\nsplm\n\nEconometric Models for Spatial Panel Data. Authors: Giovanni Millo,\nGianfranco Piras.\n\nstabledist\n\nStable Distribution Functions. Authors: Diethelm Wuertz, Martin\nMaechler and Rmetrics core team members. In view:\nDistributions.\n\nstellaR\n\nstellar evolution tracks and isochrones. Authors: Matteo\nDell’Omodarme [aut, cre], Giada Valle [aut]. In view:\nChemPhys.\n\nstpp\n\nSpace-Time Point Pattern simulation, visualisation and analysis.\nAuthors: Edith Gabriel, Peter J Diggle, stan function by Barry\nRowlingson.\n\nsuperdiag\n\nR Code for Testing Markov Chain Nonconvergence. Authors: Tsung-han\nTsai, Jeff Gill and Jonathan Rapkin.\n\nsurvSNP\n\nPower and Sample Size Calculations for SNP Association Studies with\nCensored Time to Event Outcomes. Authors: Kouros Owzar, Zhiguo Li,\nNancy Cox, Sin-Ho Jung and Chanhee Yi.\n\nsvHttp\n\nSciViews GUI API — R HTTP server. Author: Philippe Grosjean.\n\nsvKomodo\n\nSciViews GUI API — Functions to interface with Komodo Edit/IDE.\nAuthor: Philippe Grosjean.\n\nsybil\n\nSyBiL — Efficient constrained based modelling in R. Authors:\nGabriel Gelius-Dietrich [cre], C. Jonathan Fritzemeier [ctb],\nRajen Piernikarczyk [ctb], Benjamin Braasch [ctb].\n\nsybilDynFBA\n\nDynamic FBA : dynamic flux balance analysis. Author: Abdelmoneim\nAmer Desouki.\n\nsynbreed\n\nFramework for the analysis of genomic prediction data using R.\nAuthors: Valentin Wimmer, Theresa Albrecht, Hans-Juergen Auinger,\nChris-Carolin Schoen with contributions by Larry Schaeffer, Malena\nErbe, Ulrike Ober and Christian Reimer.\n\nsynbreedData\n\nData for the synbreed package. Authors: Valentin Wimmer, Theresa\nAlbrecht, Hans-Juergen Auinger, Chris-Carolin Schoen with\ncontributions by Malena Erbe, Ulrike Ober and Christian Reimer.\n\ntawny.types\n\nCommon types for tawny. Author: Brian Lee Yung Rowe.\n\ntempdisagg\n\nMethods for Temporal Disaggregation and Interpolation of Time\nSeries. Authors: Christoph Sax, Peter Steiner. In view:\nTimeSeries.\n\nternvis\n\nVisualisation, verification and calibration of ternary probabilistic\nforecasts. Author: Tim Jupp.\n\ntfplot\n\nTime Frame User Utilities. Author: Paul Gilbert.\n\ntimetools\n\nprovides objects and tools to manipulate irregular unhomogeneous\ntime data and subtime data. Author: Vladislav Navel.\n\ntlmec\n\nLinear Student-t Mixed-Effects Models with Censored Data. Authors:\nLarissa Matos, Marcos Prates and Victor Lachos. In view:\nSurvival.\n\ntm.plugin.factiva\n\nA plug-in for the tm text mining framework to import articles from\nFactiva. Author: Milan Bouchet-Valat.\n\ntpe\n\nTree preserving embedding. Authors: Albert D. Shieh, Tatsunori B.\nHashimoto, and Edoardo M. Airoldi.\n\ntranslate\n\nBindings for the Google Translate API v2. Author: Peter Danenberg.\n\ntruncdist\n\nTruncated Random Variables. Authors: Frederick Novomestky, Saralees\nNadarajah.\n\nturboEM\n\nA Suite of Convergence Acceleration Schemes for EM and MM\nalgorithms. Authors: Jennifer F. Bobb, Hui Zhao, and Ravi Varadhan.\n\nvacem\n\nVaccination Activities Coverage Estimation Model. Authors: Justin\nLessler, Jessica Metcalf.\n\nvarbvs\n\nVariational inference for Bayesian variable selection. Author: Peter\nCarbonetto.\n\nvec2dtransf\n\n2D Cartesian Coordinate Transformation. Author: German Carrillo. In\nview: Spatial.\n\nvimcom\n\nIntermediate the communication between Vim and R. Author: Jakson\nAquino.\n\nvisreg\n\nVisualization of regression functions. Authors: Patrick Breheny,\nWoodrow Burchett.\n\nvisualFields\n\nStatistical methods for visual fields. Authors: Ivan Marin-Franch,\nPaul H Artes.\n\nwaffect\n\nA package to simulate constrained phenotypes under a disease model\nH1. Authors: Gregory Nuel and Vittorio Perduca.\n\nweightedKmeans\n\nWeighted KMeans Clustering. Authors: Graham Williams, Joshua Z\nHuang, Xiaojun Chen, Qiang Wang, Longfei Xiao.\n\nwfe\n\nWeighted Linear Fixed Effects Estimators for Causal Inference.\nAuthors: In Song Kim, Kosuke Imai.\n\n2 Other changes\nThe following packages which were previously double-hosted on CRAN\nand Bioconductor were moved to the Archive, and are now solely\navailable from Bioconductor: aroma.light, DART.\nThe following packages which were previously double-hosted on CRAN\nand Omegahat were moved to the Archive, and are now solely available\nfrom Omegahat: CGIwithR, Rstem, XMLSchema.\nThe following packages were moved to the Archive: Aelasticnet,\nBARD, BioIDMapper, CoCo, CoCoCg, CoCoGraph,\nDiagnosisMed, FEST, FactoClass, FracSim, GGally, GLDEX,\nIniStatR, LLAhclust, MMG, OSACC, Package:, RFreak,\nRImageJ, ROracleUI, RPPanalyzer, SSOAP, Sim.DiffProcGUI,\nSoPhy, SocrataR, SubpathwayMiner, TSTutorial,\nTradeStrategyAnalyzer, agsemisc, binomSamSize, caMassClass,\ncatmap, cheatmap, dmRTools, doSMP, dummies, egarch,\nfarmR, formula.tools, fso, geoPlot, geofd, ggcolpairs,\ngllm, glpk, gmaps, gmvalid, gsc, hsmm, kernelPop,\nkinship, knnflex, lago, last.call, latentnet, lcd,\nlog10, makesweave, mapReduce, marelacTeaching, mirf,\nmvgraph, mvtnormpcs, ncomplete, nnDiag, nonrandom,\nnoverlap, nvis, ofp, operator.tools, optpart, pheno,\npkDACLASS, press, pressData, revoIPC, rimage, rmetasim,\nrpvm, segclust, siatclust, snpXpert, spef, statnet,\nstringkernels, svcR, time, treelet, ttime, twopartqtl,\nurn, yest.\nThe following packages were resurrected from the Archive:\nDescribeDisplay, EMC, EMCC, G1DBN, SMC, diseasemapping,\nfArma, irtProb, partsm, powerpkg, riv.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2012-1-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2012-1 issue.",
    "author": [
      {
        "name": "Martyn Plummer",
        "url": {}
      }
    ],
    "date": "2012-06-01",
    "categories": [],
    "contents": "\n\nEarlier this week I was at the “Premières Rencontres R” in Bordeaux, the\nfirst francophone meeting of R users (although I confess that I gave my\ntalk in English). This was a very enjoyable experience, and not just\nbecause it coincided with the Bordeaux wine festival. The breadth and\nquality of the talks were both comparable with the International UseR!\nconferences. It was another demonstration of the extent to which R is\nused in diverse disciplines.\nAs R continues to expand into new areas, we see the development of\npackages designed to address the specific needs of different user\ncommunities. This issue of The R Journal contains articles on two such\npackages. Karl Ropkins and David Carslaw describe how the design of the\nopenair package was\ninfluenced by the need to make an accessible set of tools available for\npeople in the air quality community who are not experts in R. Elizabeth\nHolmes and colleagues introduce the\nMARSS package for\nmultivariate autoregressive state-space models. Such models are used in\nmany fields, but the MARSS package was motivated by the particular\nneeds of researchers in the natural and environmental sciences,\nThere are two articles on the use of R outside the desktop computing\nenvironment. Sarah Anoke and colleagues describe the use of the Apple\nXgrid system to do distributed computing on Mac OS X computers, and\nTimothy Bergsma and Michael Smith demonstrate the Sumo web application,\nwhich includes an embedded R session.\nTwo articles are of particular interest to developers. Daniel Adler\ndemonstrates a Foreign Function Interface for R to call arbitrary native\nfunctions without the need for C wrapper code. There is also an article\nfrom our occasional series “From the Core”, designed to highlight ideas\nand methods in the words of R development core team members. This\narticle by Kurt Hornik, Duncan Murdoch and Achim Zeilies explains the\nnew facilities for handling bibliographic information introduced in R\n2.12.0 and R 2.14.0. I strongly encourage package authors to read this\narticle and implement the changes to their packages. Doing so will\ngreatly facilitate the bibliometric analyses and investigations of the\nsocial structure of the R community.\nElsewhere in this issue, we have articles describing the\nseason package for\ndisplaying and analyzing seasonal data, which is a companion to the book\nAnalysing Seasonal Data by Adrian Barnett and Annette Dobson; the\nVdgraph package for\ndrawing variance dispersion graphs; and the\nmaxent package which\nallows fast multinomial logistic regression with a low memory footprint,\nand is designed for applications in text classification.\nThe R Journal continues to be the journal of record for the R project.\nThe usual end matter summarizes recent changes to R itself and on CRAN.\nIt is worth spending some time browsing these sections in order to catch\nup on changes you may have missed, such as the new CRAN Task View on\ndifferential equations. Peter Dalgaard highlighted the importance of\nthis area in his editorial for volume 2, issue 2.\nOn behalf of the editorial board I hope you enjoy this issue.\n\n\nCRAN packages used\nopenair, MARSS, season, Vdgraph, maxent\nCRAN Task Views implied by cited packages\nEnvironmetrics, Hydrology, SpatioTemporal, TimeSeries\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2012-1-r-changes/",
    "title": "Changes in R",
    "description": "The 'Changes in R' article from the 2012-1 issue.",
    "author": [
      {
        "name": "The R Core Team",
        "url": {}
      }
    ],
    "date": "2012-06-01",
    "categories": [],
    "contents": "\n\nCHANGES IN R VERSION 2.15.1\n\nNEW FEATURES\nsource() now uses withVisible() rather than\n.Internal(eval.with.vis). This sometimes alters tracebacks\nslightly.\ninstall.packages(\"pkg_version.tgz\") on Mac OS X now has sanity\nchecks that this is actually a binary package (as people have tried\nit with incorrectly named source packages).\nsplineDesign() and spline.des() in package splines have a new\noption sparse which can be used for efficient construction of a\nsparse B-spline design matrix (via Matrix).\nnorm() now allows type = \"2\" (the ‘spectral’ or 2-norm) as well,\nmainly for didactical completeness.\npmin() and pmax()) now also work when one of the inputs is of\nlength zero and others are not, returning a zero-length vector,\nanalogously to, say, +.\ncolorRamp() (and hence colorRampPalette()) now also works for\nthe boundary case of just one color when the ramp is flat.\nqqline() has new optional arguments distribution, probs and\nqtype, following the example of lattice’s panel.qqmathline().\n.C() gains some protection against the misuse of character vector\narguments. (An all too common error is to pass character(N), which\ninitializes the elements to \"\", and then attempt to edit the\nstrings in-place, sometimes forgetting to terminate them.)\nCalls to the new function globalVariables() in package utils\ndeclare that functions and other objects in a package should be\ntreated as globally defined, so that CMD check will not note them.\nprint(packageDescription(*)) trims the Collate field by default.\nThe included copy of zlib has been updated to version 1.2.7.\nA new option \"show.error.locations\" has been added. When set to\nTRUE, error messages will contain the location of the most recent\ncall containing source reference information. (Other values are\nsupported as well; see ?options.)\nThe NA warning messages from e.g. pchisq() now report the call to\nthe closure and not that of the .Internal.\nAdded Polish translations by Łukasz Daniel.\n\n\nPERFORMANCE IMPROVEMENTS\nIn package parallel, makeForkCluster() and the multicore-based\nfunctions use native byte-order for serialization (deferred from\n2.15.0).\nlm.fit(), lm.wfit(), glm.fit() and lsfit() do less copying\nof objects, mainly by using .Call() rather than .Fortran().\n.C() and .Fortran() do less copying: arguments which are raw,\nlogical, integer, real or complex vectors and are unnamed are not\ncopied before the call, and (named or not) are not copied after the\ncall. Lists are no longer copied (they are supposed to be used\nread-only in the C code).\ntabulate() makes use of .C(DUP = FALSE) and hence does not copy\nbin. (Suggested by Tim Hesterberg.) It also avoids making a copy\nof a factor argument bin.\nOther functions (often or always) doing less copying include\ncut(), dist(), the complex case of eigen(), hclust(),\nimage(), kmeans(), loess(), stl() and svd(LINPACK = TRUE).\nThere is less copying when using primitive replacement functions\nsuch as names(), attr() and attributes().\n\n\nDEPRECATED AND DEFUNCT\nThe converters for use with .C() (see\n?getCConverterDescriptions) are deprecated: use the .Call()\ninterface instead. There are no known examples (they were never\nfully documented).\n\n\nUTILITIES\nFor R CMD check, a few people have reported problems with\njunctions on Windows (although they were tested on Windows 7, XP and\nServer 2008 machines and it is unknown under what circumstances the\nproblems occur). Setting the environment variable\nR_WIN_NO_JUNCTIONS to a non-empty value (e.g. in\n~/.R/check.Renviron) will force copies to be used instead.\n\n\nINSTALLATION\nR CMD INSTALL with _R_CHECK_INSTALL_DEPENDS_ set to a true value\n(as done by R CMD check –as-cran) now restricts the packages\navailable when lazy-loading as well as when test-loading (since\npackages such as\nETLUtils and\nagsemisc had\ntop-level calls to library() for undeclared packages).\nThis check is now also available on Windows.\n\n\nC-LEVEL FACILITIES\nC entry points mkChar and mkCharCE now check that the length of\nthe string they are passed does not exceed \\(2^{31}-1\\) bytes: they\nused to overflow with unpredictable consequences.\nC entry points R_GetCurrentSrcref and R_GetSrcFilename have been\nadded to the API to allow debuggers access to the source references\non the stack.\n\n\nWINDOWS-SPECIFIC CHANGES\nWindows-specific changes will now be announced in this file\n(NEWS). Changes up and including R 2.15.0 remain in the CHANGES\nfile.\nThere are two new environment variables which control the defaults\nfor command-line options.\nIf R_WIN_INTERNET2 is set to a non-empty value, it is as if\n–internet2 was used.\nIf R_MAX_MEM_SIZE is set, it gives the default memory limit if\n–max-mem-size is not specified: invalid values being ignored.\n\n\nBUG FIXES\nlsfit() lost the names from the residuals.\nMore cases in which merge() could create a data frame with\nduplicate column names now give warnings. Cases where names\nspecified in by match multiple columns are errors.\nNonsense uses such as seq(1:50, by = 5) (from package\nplotrix) and\nseq.int(1:50, by = 5) are now errors.\nThe residuals in the 5-number summary printed by summary() on an\n\"lm\" object are now explicitly labelled as weighted residuals when\nnon-constant weights are present. (Wish of PR#14840.)\ntracemem() reported that all objects were copied by .C() or\n.Fortran() whereas only some object types were ever copied.\nIt also reported and marked as copies some transformations such as\nrexp(n, x): it no longer does so.\nThe plot() method for class \"stepfun\" only used the optional\nxval argument to compute xlim and not the points at which to\nplot (as documented). (PR#14864)\nNames containing characters which need to be escaped were not\ndeparsed properly. (PR#14846)\nTrying to update (recommended) packages in R_HOME/library without\nwrite access is now dealt with more gracefully. Further, such\npackage updates may be skipped (with a warning), when a newer\ninstalled version is already going to be used from .libPaths().\n(PR#14866)\nhclust() is now fast again (as up to end of 2003), with a\ndifferent fix for the \"median\"/\"centroid\" problem. (PR#4195).\nget_all_vars() failed when the data came entirely from vectors in\nthe global environment. (PR#14847)\nR CMD check with _R_CHECK_NO_RECOMMENDED_ set to a true value\n(as done by the –as-cran option) could issue false errors if there\nwas an indirect dependency on a recommended package.\nformatC() uses the C entry point str_signif which could write\nbeyond the length allocated for the output string.\nMissing default argument added to implicit S4 generic for\nbacksolve(). (PR#14883)\nSome bugs have been fixed in handling load actions that could fail\nto export assigned items or generate spurious warnings in\nCMD check on loading.\nFor tiff(type = \"windows\"), the numbering of per-page files except\nthe last was off by one.\nOn Windows, loading package stats (which is done for a default\nsession) would switch line endings on stdout and stderr from\nCRLF to LF. This affected Rterm and R CMD BATCH.\nOn Windows, the compatibility function x11() had not kept up with\nchanges to windows(), and issued warnings about bad parameters.\n(PR#14880)\nOn Windows, the Sys.glob() function did not handle UNC paths as it\nwas designed to try to do. (PR#14884)\nIn package parallel, clusterApply() and similar failed to handle\na (pretty pointless) length-1 argument. (PR#14898)\nQuartz Cocoa display reacted asynchronously to dev.flush() which\nmeans that the redraw could be performed after the plot has been\nalready modified by subsequent code. The redraw is now done\nsynchronously in dev.flush() to allow animations without sleep\ncycles.\nSource locations reported in traceback() were incorrect when\nbyte-compiled code was on the stack.\nplogis(x, lower = FALSE, log.p = TRUE) no longer underflows early\nfor large x (e.g. 800).\n?Arithmetic’s “1 ^ y and y ^ 0 are 1, always” now also\napplies for integer vectors y.\nX11-based pixmap devices like png(type = \"Xlib\") were trying to\nset the cursor style, which triggered some warnings and hangs.\nCode executed by the built-in HTTP server no longer allows other\nHTTP clients to re-enter R until the current worker evaluation\nfinishes, to prevent cascades.\nThe plot() and Axis() methods for class \"table\" now respect\ngraphical parameters such as cex.axis. (Reported by Martin\nBecker.)\nUnder some circumstances package.skeleton() would give out\nprogress reports that could not be translated and so were displayed\nby question marks. Now they are always in English. (This was seen\nfor CJK locales on Windows, but may have occurred elsewhere.)\nThe evaluator now keeps track of source references outside of\nfunctions, e.g. when source() executes a script.\nThe replacement method for window() now works correctly for\nmultiple time series of class \"mts\". (PR#14925)\nis.unsorted() gave incorrect results on non-atomic objects such as\ndata frames. (Reported by Matthew Dowle.)\nThe value returned by tools::psnice() for invalid pid values was\nnot always NA as documented.\nClosing an X11() window while locator() was active could abort\nthe R process.\ngetMethod(f, sig) produced an incorrect error message in some\ncases when f was not a string.\nUsing a string as a “call” in an error condition with\noptions(showErrorCalls=TRUE) could cause a segfault. (PR#14931)\nThe string \"infinity\" allowed by C99 was not accepted as a\nnumerical string value by e.g. scan() and as.character().\n(PR#14933)\nIn legend(), setting some entries of lwd to NA was\ninconsistent (depending on the graphics device) in whether it would\nsuppress those lines; now it consistently does so. (PR#14926)\nby() failed for a zero-row data frame. (Reported by Weiqiang Qian)\nYates correction in chisq.test() could be bigger than the terms it\ncorrected, previously leading to an infinite test statistic in some\ncorner cases which are now reported as NaN.\nxgettext() and related functions sometimes returned items that\nwere not strings for translation. (PR#14935)\nplot(<lm>, which=5) now correctly labels the factor level\ncombinations for the special case where all \\(h_{ii}\\) are the same.\n(PR#14837)\n\nCHANGES IN R VERSION 2.15.0\n\nSIGNIFICANT USER-VISIBLE CHANGES\nThe behaviour of unlink(recursive = TRUE) for a symbolic link to a\ndirectory has changed: it now removes the link rather than the\ndirectory contents (just as rm -r does).\nOn Windows it no longer follows reparse points (including junctions\nand symbolic links).\n\n\nNEW FEATURES\nEnvironment variable RD2DVI_INPUTENC has been renamed to\nRD2PDF_INPUTENC.\n.Deprecated() becomes a bit more flexible, getting an old\nargument.\nEven data-only packages without R code need a namespace and so may\nneed to be installed under R 2.14.0 or later.\nassignInNamespace() has further restrictions on use apart from at\ntop-level, as its help page has warned. Expect it to be disabled\nfrom programmatic use in the future.\nsystem() and system2() when capturing output report a non-zero\nstatus in the new \"status\" attribute.\nkronecker() now has an S4 generic in package methods on which\npackages can set methods. It will be invoked by X %x% Y if either\nX or Y is an S4 object.\npdf() accepts forms like file = \"|lpr\" in the same way as\npostscript().\npdf() accepts file = NULL. This means that the device does NOT\ncreate a PDF file (but it can still be queried, e.g., for font\nmetric info).\nformat() (and hence print()) on \"bibentry\" objects now uses\noptions(\"width\") to set the output width.\nlegend() gains a text.font argument. (Suggested by Tim Paine,\nPR#14719.)\nnchar() and nzchar() no longer accept factors (as integer\nvectors). (Wish of PR#6899.)\nsummary() behaves slightly differently (or more precisely, its\nprint() method does). For numeric inputs, the number of NAs is\nprinted as an integer and not a real. For dates and datetimes, the\nnumber of NAs is included in the printed output (the latter being\nthe wish of PR#14720).\nThe \"data.frame\" method is more consistent with the default\nmethod: in particular it now applies zapsmall() to numeric/complex\nsummaries.\nThe number of items retained with options(warn = 0) can be set by\noptions(nwarnings=).\nA new function assignInMyNamespace() uses the namespace of the\nfunction it is called from.\nattach() allows the default name for an attached file to be\noverridden.\nbxp(), the work horse of boxplot(), now uses a more sensible\ndefault xlim in the case where at is specified differently from\n1:n, see the discussion on R-devel,\nhttps://stat.ethz.ch/pipermail/r-devel/2011-November/062586.html.\nNew function paste0(), an efficient version of paste(*, sep=\"\"),\nto be used in many places for more concise (and slightly more\nefficient) code.\nFunction setClass() in package methods now returns, invisibly, a\ngenerator function for the new class, slightly preferred to calling\nnew(), as explained on the setClass help page.\nThe \"dendrogram\" method of str() now takes its default for\nlast.str from option str.dendrogram.last.\nNew simple fitted() method for \"kmeans\" objects.\nThe traceback() function can now be called with an integer\nargument, to display a current stack trace. (Wish of PR#14770.)\nsetGeneric() calls can be simplified when creating a new generic\nfunction by supplying the default method as the def argument. See\n?setGeneric.\nserialize() has a new option xdr = FALSE which will use the\nnative byte-order for binary serializations. In scenarios where only\nlittle-endian machines are involved (these days, close to universal)\nand (un)serialization takes an appreciable amount of time this may\nspeed up noticeably transferring data between systems.\nThe internal (un)serialization code is faster for long vectors,\nparticularly with XDR on some platforms. (Based on a suggested patch\nby Michael Spiegel.)\nFor consistency, circles with zero radius are omitted by points()\nand grid.circle(). Previously this was device-dependent, but they\nwere usually invisible.\nNROW(x) and NCOL(x) now work whenever dim(x) looks\nappropriate, e.g., also for more generalized matrices.\nPCRE has been updated to version 8.30.\nThe internal R_Srcref variable is now updated before the browser\nstops on entering a function. (Suggestion of PR#14818.)\nThere are ‘bare-bones’ functions .colSums(), .rowSums(),\n.colMeans() and .rowMeans() for use in programming where\nultimate speed is required.\nThe function .package_dependencies() from package tools for\ncalculating (recursive) (reverse) dependencies on package databases,\nwhich was formerly internal, has been renamed to\npackage_dependencies() and is now exported.\nThere is a new function optimHess() to compute the (approximate)\nHessian for an optim() solution if hessian = TRUE was forgotten.\n.filled.contour() is a ‘bare-bones’ function to add a\nfilled-contour rectangular plot to an already prepared plot region.\nThe stepping in debugging and single-step browsing modes has changed\nslightly: now left braces at the start of the body are stepped over\nfor if statements as well as for for and while statements.\n(Wish of PR#14814.)\nlibrary() no longer warns about a conflict with a function from\npackage:base if the function has the same code as the base one but\nwith a different environment. (An example is Matrix::det().)\nWhen deparsing very large language objects, as.character() now\ninserts newlines after each line of approximately 500 bytes, rather\nthan truncating to the first line.\nNew function rWishart() generates Wishart-distributed random\nmatrices.\nPackages may now specify actions to be taken when the package is\nloaded (setLoadActions()).\noptions(max.print = Inf) and similar now give an error (instead of\nwarnings later).\nThe \"difftime\" replacement method of units tries harder to\npreserve other attributes of the argument. (Wish of PR#14839.)\npoly(raw = TRUE) no longer requires more unique points than the\ndegree. (Requested by John Fox.)\n\n\nPACKAGE parallel\nThere is a new function mcmapply(), a parallel version of\nmapply(), and a wrapper mcMap(), a parallel version of Map().\nA default cluster can be registered by the new function\nsetDefaultCluster(): this will be used by default in functions\nsuch as parLapply().\nclusterMap() has a new argument .scheduling to allow the use of\nload-balancing.\nThere are new load-balancing functions parLapplyLB() and\nparSapplyLB().\nmakePSOCKCluster() has a new option useXDR = FALSE which can be\nused to avoid byte-shuffling for serialization when all the nodes\nare known to be little-endian (or all big-endian).\n\n\nPACKAGE INSTALLATION\nNon-ASCII vignettes without a declared encoding are no longer\naccepted.\nC/C++ code in packages is now compiled with -NDEBUG to mitigate\nagainst the C/C++ function assert being called in production use.\nDevelopers can turn this off during package development with\nPKG_CPPFLAGS = -UNDEBUG.\nR CMD INSTALL has a new option –dsym which on Mac OS X (Darwin)\ndumps the symbols alongside the .so file: this is helpful when\ndebugging with valgrind (and especially when installing packages\ninto R.framework). [This can also be enabled by setting the\nundocumented environment variable PKG_MAKE_DSYM, since R 2.12.0.]\nR CMD INSTALL will test loading under all installed\nsub-architectures even for packages without compiled code, unless\nthe flag –no-multiarch is used. (Pure R packages can do things\nwhich are architecture-dependent: in the case which prompted this,\nlooking for an icon in a Windows R executable.)\nThere is a new option install.packages(type = \"both\") which tries\nsource packages if binary packages are not available, on those\nplatforms where the latter is the default.\nThe meaning of install.packages( dependencies = TRUE) has\nchanged: it now means to install the essential dependencies of the\nnamed packages plus the Suggests, but only the essential\ndependencies of dependencies. To get the previous behaviour, specify\ndependencies as a character vector.\nR CMD INSTALL –merge-multiarch is now supported on OS X and other\nUnix-alikes using multiple sub-architectures.\nR CMD INSTALL –libs-only now by default does a test load on\nUnix-alikes as well as on Windows: suppress with –no-test-load.\n\n\nUTILITIES\nR CMD check now gives a warning rather than a note if it finds\ninefficiently compressed datasets. With bzip2 and xz compression\nhaving been available since R 2.10.0, it only exceptionally makes\nsense to not use them.\nThe environment variable _R_CHECK_COMPACT_DATA2_ is no longer\nconsulted: check is always done if _R_CHECK_COMPACT_DATA_ has a\ntrue value (its default).\nWhere multiple sub-architectures are to be tested, R CMD check now\nruns the examples and tests for all the sub-architectures even if\none fails.\nR CMD check can optionally report timings on various parts of the\ncheck: this is controlled by environment variable\n_R_CHECK_TIMINGS_ documented in ‘Writing R Extensions’. Timings\n(in the style of R CMD BATCH) are given at the foot of the output\nfiles from running each test and the R code in each vignette.\nThere are new options for more rigorous testing by R CMD check\nselected by environment variables – see the ‘Writing R Extensions’\nmanual.\nR CMD check now warns (rather than notes) on undeclared use of\nother packages in examples and tests: increasingly people are using\nthe metadata in the DESCRIPTION file to compute information about\npackages, for example reverse dependencies.\nThe defaults for some of the options in R CMD check (described in\nthe ‘R Internals’ manual) have changed: checks for unsafe and\n.Internal() calls and for partial matching of arguments in R\nfunction calls are now done by default.\nR CMD check has more comprehensive facilities for checking\ncompiled code and so gives fewer reports on entry points linked into\n.so/.dll files from libraries (including C++ and Fortran\nruntimes).\nChecking compiled code is now done on FreeBSD (as well as the\nexisting supported platforms of Linux, Mac OS X, Solaris and\nWindows).\nR CMD build has more options for –compact-vignettes: see\nR CMD build –help.\nR CMD build has a new option –md5 to add an MD5 file (as done\nby CRAN): this is used by R CMD INSTALL to check the integrity of\nthe distribution.\nIf this option is not specified, any existing (and probably stale)\nMD5 file is removed.\n\n\nDEPRECATED AND DEFUNCT\nR CMD Rd2dvi is now defunct: use R CMD Rd2pdf.\nOptions such –max-nsize, –max-vsize and the function\nmem.limits() are now defunct. (Options –min-nsize and\n–min-vsize remain available.)\nUse of library.dynam() without specifying all the first three\narguments is now disallowed.\nUse of an argument chname in library.dynam() including the\nextension .so or .dll (which was never allowed according to the\nhelp page) is defunct. This also applies to library.dynam.unload()\nand to useDynLib directives in NAMESPACE files.\nThe internal functions .readRDS() and .saveRDS() are now\ndefunct.\nThe off-line help() types \"postscript\" and \"ps\" are defunct.\nSys.putenv(), replaced and deprecated in R 2.5.0, is finally\nremoved.\nSome functions/objects which have been defunct for five or more\nyears have been removed completely. These include .Alias(),\nLa.chol(), La.chol2inv(), La.eigen(), Machine(),\nPlatform(), Version, codes(), delay(), format.char(),\ngetenv(), httpclient(), loadURL(), machine(), parse.dcf(),\nprintNoClass(), provide(), read.table.url(), restart(),\nscan.url(), symbol.C(), symbol.For() and unix().\nThe ENCODING argument to .C() is deprecated. It was intended to\nsmooth the transition to multi-byte character strings, but can be\nreplaced by the use of iconv() in the rare cases where it is still\nneeded.\n\n\nINSTALLATION\nBuilding with a positive value of –with-valgrind-instrumentation\nnow also instruments logical, complex and raw vectors.\n\n\nC-LEVEL FACILITIES\nPassing R objects other than atomic vectors, functions, lists and\nenvironments to .C() is now deprecated and will give a warning.\nMost cases (especially NULL) are actually coding errors. NULL\nwill be disallowed in future.\n.C() now passes a pairlist as a SEXP to the compiled code. This\nis as was documented, but pairlists were in reality handled\ndifferently as a legacy from the early days of R.\ncall_R and call_S are deprecated. They still exist in the\nheaders and as entry points, but are no longer documented and should\nnot be used for new code.\n\n\nBUG FIXES\nstr(x, width) now obeys its width argument also for function\nheaders and other objects x where deparse() is applied.\nThe convention for x %/% 0L for integer-mode x has been changed\nfrom 0L to NA_integer_. (PR#14754)\nThe exportMethods directive in a NAMESPACE file now exports S4\ngenerics as necessary, as the extensions manual said it does. The\nmanual has also been updated to be a little more informative on this\npoint.\nIt is now required that there is an S4 generic (imported or created\nin the package) when methods are to be exported.\nReference methods cannot safely use non-exported entries in the\nnamespace. We now do not do so, and warn in the documentation.\nThe namespace import code was warning when identical S4 generic\nfunctions were imported more than once, but should not (reported by\nBrian Ripley, then Martin Morgan).\nmerge() is no longer allowed (in some ways) to create a data frame\nwith duplicate column names (which confused PR#14786).\nFixes for rendering raster images on X11 and Windows devices when\nthe x-axis or y-axis scale is reversed.\ngetAnywhere() found S3 methods as seen from the utils namespace\nand not from the environment from which it was called.\nselectMethod(f, sig) would not return inherited group methods when\ncaching was off (as it is by default).\ndev.copy2pdf(out.type = \"cairo\") gave an error. (PR#14827)\nVirtual classes (e.g., class unions) had a NULL prototype even if\nthat was not a legal subclass. See ?setClassUnion.\nThe C prototypes for zdotc and zdotu in R_ext/BLAS.h have been\nchanged to the more modern style rather than that used by f2c.\n(Patch by Berwin Turlach.)\nisGeneric() produced an error for primitives that can not have\nmethods.\n.C() or .Fortran() had a lack-of-protection error if the\nregistration information resulted in an argument being coerced to\nanother type.\nboxplot(x=x, at=at) with non finite elements in x and non\ninteger at could not generate a warning but failed.\nheatmap(x, symm=TRUE, RowSideColors=*) no longer draws the colors\nin reversed order.\npredict(<ar>) was incorrect in the multivariate case, for p >= 2.\nprint(x, max=m) is now consistent when x is a \"Date\"; also the\n“reached ... max.print ..” messages are now consistently using\nsingle brackets.\nClosed the <li> tag in pages generated by Rd2HTML().\n(PR#14841.)\nAxis tick marks could go out of range when a log scale was used.\n(PR#14833.)\nSignature objects in methods were not allocated as S4 objects\n(caused a problem with trace() reported by Martin Morgan).\n\nCHANGES IN R VERSION 2.14.2\n\nNEW FEATURES\nThe internal untar() (as used by default by R CMD INSTALL) now\nknows about some pax headers which bsdtar (e.g., the default\ntar for Mac OS >= 10.6) can incorrectly include in tar files,\nand will skip them with a warning.\nPCRE has been upgraded to version 8.21: as well as bug fixes and\ngreater Perl compatibility, this adds a JIT pattern compiler, about\nwhich PCRE’s news says ‘large performance benefits can be had in\nmany situations’. This is supported on most but not all R platforms.\nFunction compactPDF() in package tools now takes the default for\nargument gs_quality from environment variable GS_QUALITY: there\nis a new value \"none\", the ultimate default, which prevents\nGhostScript being used in preference to qpdf just because\nenvironment variable R_GSCMD is set. If R_GSCMD is unset or set\nto \"\", the function will try to find a suitable GhostScript\nexecutable.\nThe included version of zlib has been updated to 1.2.6.\nFor consistency with the logLik() method, nobs() for \"nls\"\nfiles now excludes observations with zero weight. (Reported by\nBerwin Turlach.)\n\n\nUTILITIES\nR CMD check now reports by default on licenses not according to\nthe description in ‘Writing R Extensions’.\nR CMD check has a new option –as-cran to turn on most of the\ncustomizations that CRAN uses for its incoming checks.\n\n\nPACKAGE INSTALLATION\nR CMD INSTALL will now no longer install certain file types from\ninst/doc: these are almost certainly mistakes and for some\npackages are wasting a lot of space. These are Makefile, files\ngenerated by running LaTeX, and unless the package uses a\nvignettes directory, PostScript and image bitmap files.\nNote that only PDF vignettes have ever been supported: some of these\nfiles come from DVI/PS output from the Sweave defaults prior to R\n2.13.0.\n\n\nBUG FIXES\nR configured with –disable-openmp would mistakenly set\nHAVE_OPENMP (internal) and SUPPORT_OPENMP (in Rconfig.h) even\nthough no OpenMP flags were populated.\nThe getS3method() implementation had an old computation to find an\nS4 default method.\nreadLines() could overflow a buffer if the last line of the file\nwas not terminated. (PR#14766)\nR CMD check could miss undocumented S4 objects in packages which\nused S4 classes but did not Depends: methods in their\nDESCRIPTION file.\nThe HTML Help Search page had malformed links. (PR#14769)\nA couple of instances of lack of protection of SEXPs have been\nsquashed. (PR#14772, PR#14773)\nimage(x, useRaster=TRUE) misbehaved on single-column x.\n(PR#14774)\nNegative values for options(\"max.print\") or the max argument to\nprint.default() caused crashes. Now the former are ignored and the\nlatter trigger an error. (PR#14779)\nThe text of a function body containing more than 4096 bytes was not\nproperly saved by the parser when entered at the console.\nForgetting the #endif tag in an Rd file could cause the parser to\ngo into a loop. (Reported by Hans-Jorg Bibiko.)\nstr(*, ....., strict.width=\"cut\") now also obeys list.len = n.\n(Reported by Vogel.)\nPrinting of arrays did not have enough protection (C level), e.g.,\nin the context of capture.output(). (Reported by Hervé Pagès and\nMartin Morgan.)\npdf(file = NULL) would produce a spurious file named NA.\n(PR#14808)\nlist2env() did not check the type of its envir argument.\n(PR#14807)\nsvg() could segfault if called with a non-existent file path.\n(PR#14790)\nmake install can install to a path containing + characters.\n(PR#14798)\nThe edit() function did not respect the options(\"keep.source\")\nsetting. (Reported by Cleridy Lennert.)\npredict.lm(*, type=\"terms\", terms=*, se.fit=TRUE) did not work.\n(PR#14817)\nThere is a partial workaround for errors in the TRE\nregular-expressions engine with named classes and repeat counts of\nat least 2 in a MBCS locale (PR#14408): these are avoided when TRE\nis in 8-bit mode (e.g. for useBytes = TRUE and when all the data\nare ASCII).\nThe C function R_ReplDLLdo1() did not call top-level handlers.\nThe Quartz device was unable to detect window sessions on Mac OS X\n10.7 (Lion) and higher and thus it was not used as the default\ndevice on the console. Since Lion any application can use window\nsessions, so Quartz will now be the default device if the user’s\nwindow session is active and R is not run via ssh which is at\nleast close to the behavior in prior OS X versions.\nmclapply() would fail in code assembling the translated error\nmessage if some (but not all) cores encountered an error.\nformat.POSIXlt(x) raised an arithmetic exception when x was an\ninvalid object of class \"POSIXlt\" and parts were empty.\ninstalled.packages() has some more protection against package\ninstalls going on in parallel.\n.Primitive() could be mis-used to call .Internal() entry points.\n\nCHANGES IN R VERSION 2.14.1\n\nNEW FEATURES\nparallel::detectCores() is now able to find the number of physical\ncores (rather than CPUs) on Sparc Solaris.\nIt can also do so on most versions of Windows; however the default\nremains detectCores(logical = TRUE) on that platform.\nReference classes now keep a record of which fields are locked.\n$lock() with no arguments returns the names of the locked fields.\nHoltWinters() reports a warning rather than an error for some\noptimization failures (where the answer might be a reasonable one).\ntools::dependsOnPkg() now accepts the shorthand\ndependencies = \"all\".\nparallel::clusterExport() now allows specification of an\nenvironment from which to export.\nThe quartz() device now does tilde expansion on its file\nargument.\ntempfile() on a Unix-alike now takes the process ID into account.\nThis is needed with\nmulticore (and as\npart of parallel) because the parent and all the children share a\nsession temporary directory, and they can share the C random number\nstream used to produce the unique part. Further, two children can\ncall tempfile() simultaneously.\nOption print in Sweave’s RweaveLatex() driver now emulates\nauto-printing rather than printing (which can differ for an S4\nobject by calling show() rather than print()).\nfilled.contour() now accepts infinite values: previously it might\nhave generated invalid graphics files (e.g. containing NaN values).\n\n\nINSTALLATION\nOn 64-bit Linux systems, configure now only sets LIBnn to\nlib64 if /usr/lib64 exists. This may obviate setting LIBnn\nexplicitly on Debian-derived systems.\nIt is still necessary to set LIBnn = lib (or lib32) for 32-bit\nbuilds of R on a 64-bit OS on those Linux distributions capable for\nsupporting that concept.\nconfigure looks for inconsolata.sty, and if not found adjusts\nthe default R_RD4PDF to not use it (with a warning, since it is\nneeded for high-quality rendering of manuals).\n\n\nPACKAGE INSTALLATION\nR CMD INSTALL will now do a test load for all sub-architectures\nfor which code was compiled (rather than just the primary\nsub-architecture).\n\n\nUTILITIES\nWhen checking examples under more than one sub-architecture,\nR CMD check now uses a separate directory examples_arch for each\nsub-architecture, and leaves the output in file\npkgname-Ex_arch.Rout. Some packages expect their examples to be\nrun in a clean directory ….\n\n\nBUG FIXES\nstack() now gives an error if no vector column is selected, rather\nthan returning a 1-column data frame (contrary to its\ndocumentation).\nsummary.mlm() did not handle objects where the formula had been\nspecified by an expression. (Reported by Helios de Rosario\nMartinez).\ntools::deparseLatex(dropBraces=TRUE) could drop text as well as\nbraces.\ncolormodel = \"grey\" (new in R 2.14.0) did not always work in\npostscript() and pdf().\nfile.append() could return TRUE for failures. (PR#14727)\ngzcon() connections are no longer subject to garbage collection:\nit was possible for this to happen when unintended (e.g. when\ncalling load()).\nnobs() does not count zero-weight observations for glm() fits,\nfor consistency with lm(). This affects the BIC() values\nreported for such glm() fits. (Spotted by Bill Dunlap.)\noptions(warn = 0) failed to end a (C-level) context with more than\n50 accumulated warnings. (Spotted by Jeffrey Horner.)\nThe internal plot.default() code did not do sanity checks on a\ncex argument, so invalid input could cause problems. (Reported by\nBen Bolker.)\nanyDuplicated(<array>, MARGIN=0) no longer fails. (Reported by\nHervé Pagès.)\nread.dcf() removes trailing blanks: unfortunately on some\nplatforms this included \\\\xa0 (non-breaking space) which is the\ntrailing byte of a UTF-8 character. It now only considers ASCII\nspace and tab to be ‘blank’.\nThere was a sign error in part of the calculations for the variance\nreturned by KalmanSmooth(). (PR#14738)\npbinom(10, 1e6, 0.01, log.p = TRUE) was NaN thanks to the buggy\nfix to PR#14320 in R 2.11.0. (PR#14739)\nRweaveLatex() now emulates auto-printing rather than printing, by\ncalling methods::show() when auto-printing would.\nduplicated() ignored fromLast for a one-column data frame.\n(PR#14742)\nsource() and related functions did not put the correct timestamp\non the source references; srcfilecopy() has gained a new argument\ntimestamp to support this fix. (PR#14750)\nsrcfilecopy() has gained a new argument isFile and now records\nthe working directory, to allow debuggers to find the original\nsource file. (PR#14826)\nLaTeX conversion of Rd files did not correctly handle preformatted\nbackslashes. (PR#14751)\nHTML conversion of Rd files did not handle markup within tabular\ncells properly. (PR#14708)\nsource() on an empty file with keep.source = TRUE tried to read\nfrom stdin(), in R 2.14.0 only. (PR#14753)\nThe code to check Rd files in packages would abort if duplicate\ndescription sections were present.\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2012-1-r-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2012-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2012-06-01",
    "categories": [],
    "contents": "\n1 Donations and new members\nDonations\nIlker Esener, Switzerland\nGreenwich Statistics, France\nKansai University, Faculty Commerce, Japan\nOlaf Krenz, Germany\nPhil Shepherd, New Zealand\nJoshua Wiley, USA\nNew benefactors\nGreenwich Statistics, France\nQuantide, Italy\nNew supporting institutions\nClinical Trial Unit, University Hospital Basel, Switzerland\nNew supporting members\nBenjamin French, USA\nArthur W. Green, USA\nScott Kostyshak, USA\nPhilippe Baril Lecavalier, Canada\nThomas Roth, Germany\nMathe W. Woodyard, USA\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2011-2-bioconductor/",
    "title": "News from the Bioconductor Project",
    "description": "\"News from the Bioconductor Project\" published in The R Journal.",
    "author": [
      {
        "name": "Bioconductor Team",
        "url": {}
      }
    ],
    "date": "2011-12-01",
    "categories": [],
    "contents": "\n\nWe are pleased to announce Bioconductor 2.9, released on 14 October\n2011. Bioconductor 2.9 is compatible with R 2.14.0, and consists of 516\nsoftware packages and more than 500 up-to-date annotation packages.\nThere are 60 new software packages, and enhancements to many others.\nExplore Bioconductor at http://bioconductor.org. Install packages with\n> source(\"http://bioconductor.org/biocLite.R\")\n> # install standard packages...\n> biocLite()\n> # ...or only VariantAnnotation\n> biocLite(\"VariantAnnotation\")\nA Bioconductor Amazon Machine Instance is available; see\nhttp://bioconductor.org/help/bioconductor-cloud-ami.\n1 New and revised packages\nThis release includes new packages for diverse areas of high-throughput\nanalysis. Highlights include:\n\nHigh-throughput sequencing:\nDEXSeq,\nDiffBind,\nEDASeq,\nREDseq,\nReQON,\nRepitools,\nTSSi,\nVariantAnnotation,\ncummeRbund,\nfastseg,\nhtSeqTools,\nnucleR,\nr3Cseq,\ntweeDEseq.\nMicroarrays:\nAGDEX,\nCNAnorm,\nCellNOptR,\nCormotif,\nDECIPHER,\nGWASTools,\nMmPalateMiRNA,\ncn.mops,\ncqn,\nexomeCopy,\nminfi,\nrqubic,\nstepwiseCM.\nAdvanced statistical implementations:\nDTA,\nRCASPAR,\ndks,\nrandPack,\nsva,\ntrigger.\nNetworks and pathways:\nDOSE,\nGOFunction,\nGRENITS,\nGeneExpressionSignature,\nIdMappingRetrieval,\nPAN,\nPREDA,\nRTopper,\nRamiGO,\nRedeR,\ngraphite,\ninSilicoDb,\npredictionet.\nMass spectrometry, qPCR, and flow cytometry:\nNormqPCR,\nReadqPCR,\nflowType,\nflowWorkspace,\niontree,\nisobar,\nmzR,\nncdfFlow.\nVisualization:\nbiovizBase,\nggbio,\nqtbase,\nqtpaint.\n\nOur large collection of microarray- and organism-specific annotation\npackages have, as usual, been updated to include current information.\nThis release introduces a select interface to annotation packages,\nsimplifying queries for multiple types of annotation within and between\ndata sources. The new\nVariantAnnotation\npackage processes VCF files, including interfaces to SIFT and PolyPhen\ndata bases for assessing consequences of sequence changes.\nFurther information on new and existing packages can be found on the\nBioconductor web site; ‘BiocViews’ identify coherent groups of packages,\nwith links to package descriptions, vignettes, reference manuals, and\nuse statistics. Our web site has been enhanced with easier access to\npackage NEWS and other support files.\n2 Other activities\nA meeting in December highlighted contributions from our European\ndeveloper community; we look forward to Seattle’s Annual Meeting on\n23-25 July 2012. The active Bioconductor mailing lists\n(http://bioconductor.org/help/mailing-list/) connect users with each\nother, to domain experts, and to maintainers eager to ensure that their\npackages satisfy the needs of leading edge approaches. Bioconductor\npackage maintainers and the Bioconductor team invest considerable effort\nin producing high-quality software. The Bioconductor team continues to\nensure quality software through technical and scientific reviews of new\npackages, and daily builds of released packages on Linux, Windows, and\nMacOS platforms.\n3 Looking forward\nOur contributors provide a tremendous diversity of high-quality\npackages. These are enhancing areas of existing strength in statistical\nanalysis of microarrays, while driving project growth in high-throughput\nsequence analysis and emerging domains like mass spectrometry and qPCR.\nThese directions provide an important incentive for infrastructure,\ncontributed by the Bioconductor core team and others, to support\nprocessing and visualization of very large data sets.\nImportant directions for the Bioconductor core team include\nrepresentation and manipulation of complex sequence alignments and\nvariants, convenient and integrated approaches to gene and genome\nannotation, continued efforts to ease cloud-based use of Bioconductor,\nand approaches to ease development and support of increasingly\ninter-related packages.\n\n\nBioconductor packages used\nDEXSeq, DiffBind, EDASeq, REDseq, ReQON, Repitools, TSSi, VariantAnnotation, cummeRbund, fastseg, htSeqTools, nucleR, r3Cseq, tweeDEseq, AGDEX, CNAnorm, CellNOptR, Cormotif, DECIPHER, GWASTools, MmPalateMiRNA, cn.mops, cqn, exomeCopy, minfi, rqubic, stepwiseCM, DTA, RCASPAR, dks, randPack, sva, trigger, DOSE, GOFunction, GRENITS, GeneExpressionSignature, IdMappingRetrieval, PAN, PREDA, RTopper, RamiGO, RedeR, graphite, inSilicoDb, predictionet, NormqPCR, ReadqPCR, flowType, flowWorkspace, iontree, isobar, mzR, ncdfFlow, biovizBase, ggbio, qtbase, qtpaint\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2011-2-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2011-2 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2011-12-01",
    "categories": [],
    "contents": "\n\n1 New packages in CRAN task views\nBayesian\n\nBCBCSF, PottsUtils, bayesQR, profdpm.\n\nChemPhys\n\nhyperSpec.\n\nCluster\n\nmritc, protoclust, tclust.\n\nDistributions\n\nAtelieR, glogis, smoothmest.\n\nEconometrics\n\nmvProbit, rms.\n\nEnvironmetrics\n\nEcoHydRology, HydroMe, aqp, climatol, forecast,\nhydroGOF, hydroTSM, latticeDensity, oce, openair, seas,\nsimba, soil.spec, soiltexture, topmodel, wasim.\n\nExperimentalDesign\n\nDiceEval, DiceView, GAD, TEQR, Vdgraph, asd, gsDesign,\nmkssd, mxkssd, odprism, osDesign, qtlDesign,\nqualityTools, support.CEs.\n\nFinance\n\nNMOF, PairTrading, betategarch, lifecontingencies,\nmaRketSim, opefimor, rugarch.\n\nHighPerformanceComputing\n\nOpenCL.\n\nNaturalLanguageProcessing\n\nRTextTools.\n\nOfficialStatistics\n\nSeleMix, deducorrect, editrules.\n\nOptimization\n\nROI\\(^*\\), Rmosek, minpack.lm.\n\nPhylogenetics\n\nOUwie, caper, distory, motmot, phylosim, phytools,\ntreebase.\n\nPsychometrics\n\nEstCRM, KernSmoothIRT, TripleR, cacIRT, fwdmsa, mRm,\nmirt\\(^*\\), mixRasch, modelfree, psychomix, psychotools.\n\nRobust\n\nFRB, RobAStBase, RobustAFT, multinomRob, rgam.\n\nSocialSciences\n\nrms.\n\nSpatial\n\nMetadata, UScensus2000blkgrp, UScensus2000cdp,\nUScensus2000tract, adehabitat, landsat.\n\nTimeSeries\n\nctarma, cts, hydroGOF, hydroTSM, wq.\n\n(* = core package)\n2 New contributed packages\nACNE, ANN, APSIMBatch, AUCRF, AWS.tools, Aelasticnet,\nAtelieR, AutoSEARCH, BCBCSF, BNPdensity, BaSTA, Barnard,\nBinNor, BiomarkeR, CDM, CHCN, CLSOCP, CONOR, CONORData,\nCRM, CatDyn, CityPlot, CommonTrend, CompModSA, DATforDCEMRI,\nDPM.GGM, DWD, DiagTest3Grp, DirichletReg, Dodge, EL,\nEcoHydRology, EstCRM, ExomeCNV, FFD, FIAR, FLLat,\nFastRWeb, FlexParamCurve, ForImp, FourScores, GGEBiplotGUI,\nGMD, GMMBoost, GUTS, GWAtoolbox, GhcnDaily, HAC, HMP,\nHMPTrees, HTSCluster, HiveR, Hotelling, IBDsim, ISDA.R,\nISIPTA, ISOweek, JoSAE, KRLS, KernSmoothIRT, KoNLP,\nLDcorSV, LEAPFrOG, LGS, LN3GV, LTPDvar, LaF, Lahman,\nLargeRegression, LatticeKrig, LifeTables, M3, MAINT.Data,\nMBCluster.Seq, MCUSUM, MDM, MFSAS, MIPHENO, MPCI, MPTinR,\nMSeasy, MSeasyTkGUI, MVPARTwrap, MVR, Maeswrap, Mangrove,\nMatrixEQTL, McParre, MergeGUI, Metadata, MigClim,\nMindOnStats, MissingDataGUI, MultiPhen, NBDdirichlet, NMOF,\nNPsimex, NSA, NanoStringNorm, NeMo, ODB, ORCME, OUwie,\nOpenCL, OpenRepGrid, PACE, PAWL, PCICt, PP, PSCBS,\nPairTrading, PerfMeas, PhaseType, PoiClaClu, PopGenKit,\nPrecipStat, QLSpline, R1magic, R2STATS, RDF, REGENT, RHT,\nRHive, RMAWGEN, RMongo, RNetLogo, ROI, ROI.plugin.glpk,\nROI.plugin.quadprog, ROI.plugin.symphony, RRF, RSKC, RSofia,\nRTextTools, RVowpalWabbit, RWeather, RXKCD, Rcell,\nRclusterpp, RcmdrPlugin.KMggplot2, RcmdrPlugin.coin,\nRcmdrPlugin.mosaic, RcppEigen, Rdrools, Rdroolsjars,\nRearrangement, ResourceSelection, Rfun, RghcnV3, Rjms,\nRjmsjars, Rknots, Rlof, Rmosek, RobustAFT, Rwinsteps,\nSBSA, SNPRelate, SPEI, SPIAssay, SVGMapping, SearchTrees,\nSeleMix, SpatialVx, SpatioTemporal, SportsAnalytics,\nStateTrace, StochaTR, StreamingLm, SuperLearner, Survgini,\nSynergizeR, TAHMMAnnot, TDMR, TSPC, TextRegression,\nThreeWay, Tinflex, TradeStrategyAnalyzer, Tsphere,\nUScensus2010, VBLPCM, VBMA4hmm, Vdgraph, VisCov, WaveletCo,\nabcdeFBA, abn, aggrisk, allelematch, alphashape3d, anaglyph,\naqfig, arf3DS4, arrayhelpers, ascrda, auteur, bamdit,\nbarcode, batade, bcool, bdpv, betategarch, betfairly, bfa,\nbimetallic, binomTools, bios2mds, biseVec, blm, blme,\nbstats, bwsurvival, cacIRT, calibFit, calmate, caper,\ncapushe, cardidates, caribou, cccrm, cda, cghseg, cit,\nclimdex.pcic, clpAPI, clusterPower, coefplot, colorout,\ncomorbidities, confReg, conjoint, cotrend, cplexAPI, cplm,\ncrimCV, crn, crs, ctarma, cvTools, cvplogistic, cyphid,\ncytoDiv, dbstats, dcens, dcmle, detect, devtools, dgof,\ndhglm, dielectric, dinamic, dmRTools, doRNG, drawExpression,\ndynpred, dynsurv, ebal, edcc, edesign, eigeninv,\nelec.strat, emdist, emma, epade, etable, evtree,\nexcel.link, ezsim, fairselect, fdaMixed, fdrci, features,\nfinebalance, fitDRC, flexsurv, flip, forams, fpp, fun,\ngRim, gamboostLSS, gb, gbRd, gcmr, genridge, ggdendro,\nggmap, glm2, glmmLasso, glogis, glpkAPI, goric, gpairs,\ngranovaGG, graphComp, gridSVG, growthrate, gsmoothr,\ngstudio, gtx, gwrr, h5r, hdlm, holdem, iFad, iRefR,\niRegression, idr, informR, int64, intRegGOF, intergraph,\nisopat, iteRates, itsmr, jpeg, kBestShortestPaths, kinship2,\nklausuR, last.call, latticeDensity, lazyWeave, lgcp,\nlibamtrack, lifecontingencies, liso, lmmfit, logconcens,\nlogcondiscr, lorec, maRketSim, mail, maxent, metaLik,\nmetrumrg, minimax, mirt, mixcat, mixexp, mleur, mmeln,\nmotmot, mpc, multicool, multitable, mvProbit, mvtsplot,\nndl, ndvits, nfda, nloptr, objectProperties, objectSignals,\nobliqueRF, ocomposition, odprism, opefimor, opencpu.encode,\noposSOM, orsk, osDesign, osmar, paloma, partykit,\npbkrtest, pcrcoal, pdist, permute, phytools, pks, planar,\nplayitbyr, plsRbeta, plumbr, polyphemus, polytomous, ppcor,\nppiPre, prLogistic, pragma, probemapper, productplots,\nprotoclust, psychomix, psychotools, pxR, qPCR.CT, qmrparser,\nqqplotter, qrfactor, qtlmt, rJPSGCS, rJavax, randomNames,\nrasclass, rasterVis, rationalfun, rdatamarket,\nrecommenderlabBX, recommenderlabJester, reglogit, rfPermute,\nrfishbase, rje, rmongodb, robeth, robustreg, rockchalk,\nrococo, roxygen2, rplotengine, rrBlupMethod6, rrlda, rsae,\nrsem, rtf, rtfbs, rugarch, rzmq, s4vd, saemix, sampSurf,\nsas7bdat, scales, semdiag, separationplot, siatclust,\nsmcUtils, smfsb, softclassval, sperich, spider, spt,\nsquash, sss, standGL, stratasphere, stremo, support.CEs,\nsurvC1, swst, taRifx, tables, tabplotGTK, tabuSearch,\ntilting, topologyGSA, treebase, trifield, truncSP, txtplot,\nuseful, vegclust, viopoints, walkscoreAPI, weightedScores,\nwhisker, wordcloud, xgrid\n3 Other changes\nThe following packages which were previously double-hosted on CRAN\nand Bioconductor were moved to the Archive, and are now solely\navailable from Bioconductor: CORREP, Icens, RBGL, RLMM,\ngpls, graphite, hopach, impute, maanova, qvalue.\nThe following packages were moved to the Archive: ADaCGH, Ardec,\nBhat, DescribeDisplay, Design, LLdecomp, MAMA,\nMHadaptive, Peak2Trough, QRMlib, RBrownie, RStackExchange,\nRsac, SQLiteDF, TreeRank, ZIGP, arrayImpute,\narrayMissPattern, atmi, bdoc, bs, diseasemapping, fArma,\nfCalendar, fSeries, fUtilities, flexCrossHaz,\ngooglebigquery, halp, infochimps, irtProb, maticce,\nminiGUI, muS2RC, muStat, muUtil, npmc, powerpkg,\ntpsDesign, uniPlot.\nThe following packages were resurrected from the Archive: SNPMaP,\nSNPMaP.cdm, SoPhy, birch, csampling, cts, elec,\nformula.tools, hierfstat, marg, sabreR.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2011-2-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2011-2 issue.",
    "author": [
      {
        "name": "Heather Turner",
        "url": {}
      }
    ],
    "date": "2011-12-01",
    "categories": [],
    "contents": "\n\nFollowing the guiding principles set down by its predecessor R News,\nthe journal has maintained the policy of allowing authors to retain\ncopyright of their published articles. However the lack of an explicit\nlicence has meant that the rights of others regarding material published\nin the journal has been unclear. Therefore from this issue, all articles\nwill be licensed under the Creative Commons Attribution 3.0 Unported\nlicense (CC BY 3.0, http://creativecommons.org/licenses/by/3.0/). This\nlicense is the standard set by the SPARC Europe Seal for Open Access\nJournals and ensures compatibility with other open access journals such\nas the Journal of Statistical Software.\nThe key features of the CC BY 3.0 license are that anyone is free to\nshare or to adapt the licensed work, including for commercial use,\nprovided that they cite the original article. This increases the value\nof articles published in The R Journal, whilst ensuring that authors\nreceive appropriate credit for their work.\nIn the immediate term, the new licensing policy will mean that members\nof the community are free to translate articles in the journal, an\ninitiative already planned by the R User’s Group in South Korea\n(http://www.openstatistics.net/). It also opens up other\npossibilities, such as distributing sources alongside articles, that\ncould be considered in future.\nThe selection of contributed articles in this issue is again testament\nto the diverse concerns of the R community. In the area of statistical\nmethodlogy, Taylor Arnold and John Emerson introduce new functions for\nnon-parametric goodness-of-fit tests, whilst Ian Marschner and joint\nauthors Haizhou Wang and Mingzhou Song propose improved algorithms for\ngeneralized linear models and 1-D \\(k\\) means clustering respectively. On\ngraphics, Han Lin Shang introduces the rainbow package for visualizing\ntime series; Markus Gesmann and Diego de Castillo demonstrate use of the\nGoogle visualistion API with R, and Maxime Hervé presents a GUI designed\nto help R novices create publication-quality graphics in R. Providing\neasier access to R’s functionality is also the focus of our first\narticle, which demonstrates how to create an Excel application from an R\npackage, using rpart as an\nexample. Finally the area of documentation and reproducible research is\nrepresented by articles on the spell-checking of Rd files and vignettes,\nand the implementation of the compendium concept with Sweave and\nDOCSTRIP.\nIn addition to these articles, we have the first Programmer’s Niche\narticle since becoming The R Journal. This column is intended to provide\n“programming pearls” for R developers—short articles that elucidate\nprogramming concepts or technical issues in developing R packages. In\nthis instance, the article is not on R itself, but on writing portable\nC++ for R packages, problems with which cause many an error, especially\non Solaris systems.\nIn the usual round up of news, readers are particularly encouraged to\ntake a look at the report on R’s Participation in the Google Summer of\nCode 2011. As well as reporting back on an especially productive season,\nthe GSoC 2011 administrators discuss the costs and benefits of\ninvolvement in this scheme and note that suggestions for 2012 projects\nare already being collected.\nFinally I would like to thank the associate editors and column editors\nfor their work and support during my year’s tenure as Editor-in-Chief.\nIn 2012, this role will be taken on by Martyn Plummer. Peter Dalgaard\nwill stand down from the editorial board after four years of service and\nDeepayan Sarkar will join us to fill his place. As Deepayan is currently\nbased in Delhi, the editorial board will thus span three continents,\nwith myself and Martyn in Europe and Hadley Wickham in the US. Such\ninternational diversity is important, when the R community itself is\nspread around the globe. Hopefully as the R Journal continues to\nestablish itself and we look to expand the editorial board, the\ndiversity of the R community will be increasingly represented.\n\n\nCRAN packages used\nrpart\nCRAN Task Views implied by cited packages\nEnvironmetrics, MachineLearning, Survival\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2011-2-forthcoming-user/",
    "title": "Forthcoming Events: useR! 2012",
    "description": "\"Forthcoming Events: useR! 2012\" published in The R Journal.",
    "author": [
      {
        "name": "Frank Harrell (chair), Stephania McNeal-Goddard, Matt Shotwell, JoAnn\nAlvarez, John Bock, Audrey Carvajal, WJ Cunningham, Chris Fonnesbeck,\nTatsuki Koyama, Yanna Song, Sherry Stokes, Yuwei Zhu",
        "url": {}
      }
    ],
    "date": "2011-12-01",
    "categories": [],
    "contents": "\n\nThe eighth international R user conference useR! 2012 will take place\nat Vanderbilt University, Nashville, Tennessee, USA, 12–15 June 2012.\nFollowing previous useR! conferences, this meeting of the R user\ncommunity will\n\nfocus on R as the ‘lingua franca’ of data analysis and statistical\ncomputing;\nprovide a platform for R users to discuss and exchange ideas on how R\ncan be used for statistical computation, data analysis, visualization\nand exciting applications in various fields;\ngive an overview of the new features of the ever evolving R project.\n\nThe program comprises invited talks, user-contributed sessions,\nlightning talks, a poster session, and pre-conference tutorials and\nshort courses.\n1 Invited talks\nThe program of invited talks will represent the spectrum of interest\nfrom important technical developments to exciting applications of R,\npresented by experts in the field. The list of invited talks will be\nannounced shortly.\n2 User-contributed sessions\nIn the contributed sessions, presenters will share innovative and\ninteresting uses of R, covering topics such as:\n\nBayesian statistics\nBig data\nBioinformatics\nBusiness analytics and financial modeling\nChemometrics and computational physics\nData mining\nEconometrics & finance\nEnvironmetrics & ecological modeling\nHigh performance computing\nImaging\nInterfaces with other languages/software\nMachine learning\nMultivariate statistics\nNonparametric statistics\nPharmaceutical statistics\nPsychometrics\nSpatial statistics\nStatistics in the social and political sciences\nTeaching\nVisualization & graphics\nWeb services with R\n\nAbstracts may be submitted for oral or poster presentation. The poster\nsession will be part of a major social event on one of the evenings\nduring the conference, or during the main program of talks. Submissions\nfor contributed talks will be considered for the following types of\nsession:\n\nuseR! Kaleidoscope: These sessions give a broad overview of the many\ndifferent applications of R and should appeal to a wide audience.\nuseR! Focus Session: These sessions cover topics of special interest\nand may be more technical.\n\nIn addition to the main program of talks and based on their successful\nintroduction at useR! 2011, all participants are invited to present a\nLightning Talk, for which no abstract is required. These talks provide\na 5-minute platform to speak on any R-related topic and should\nparticularly appeal to those new to R. A variation of the pecha\nkucha1 and ignite2 formats will be used in which speakers must\nprovide 15 slides to accompany their talk and each slide will be shown\nfor 20 seconds.\nThe scientific program is organized by members of the program committee\ncomprising Claudia Beleites, Dirk Eddelbuettel, John Fox, Benjamin\nFrench, Tal Galili, Jeffrey Horner, Andy Liaw, Uwe Ligges, Steve Miller,\nKate Mullen, Bill Pikounis, Matt Shotwell, Heather Turner, Ravi\nVaradhan, and Achim Zeileis.\n3 Pre-conference training\nTutorials\nBefore the start of the official program, half-day tutorials will be\noffered on Tuesday, June 12th. The tutorials will address such topics as\nR for beginners, R for users of other statistical packages, R for\nstatistical modeling, reproducible reporting with Sweave, web services\nwith R, and graphics.\nShort courses\nA new feature of useR! 2012 is the full-day pre-conference short\ncourses, to be held on Monday, June 11. These will include Frank\nHarrell’s Regression Modeling Strategies and the rms Package course.\nTutorial/short course presenters include Bill Venables, Terry Therneau,\nRobert Muenchen, Hadley Wickham, Doug Bates, Jeffrey Horner, Uwe Ligges,\nand Frank Harrell.\n4 Location & surroundings\nParticipants will be well catered for at Vanderbilt University, with\nmultiple nearby hotels as well as on-campus housing available. The\nUniversity is near downtown Nashville which is close to a major airport.\nNashville is in middle Tennessee and is known as Music City USA for good\nreason, being the heart of country music, having a world-class symphony\norchestra which has won 6 Grammy awards in the past 3 years, and hosting\ngreat jazz, bluegrass, blues, and many other types of music.\nOne of the largest music festivals in the US, Bonnaroo, takes place\nJune 7–10 only 65 miles from Nashville. Another large festival, the\ncountry music CMA Fest, takes place in Nashville over the same days.\nThe Cirque du Soleil show, Michael Jackson THE IMMORTAL World Tour\ncomes to Nashville on June 12–13.\n5 Further information\nA web page offering more information on useR! 2012, including details\nregarding registration and abstract submission, is available at\nhttp://www.R-project.org/useR-2012.\nWe hope to meet you in Nashville!\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\nhttp://en.wikipedia.org/wiki/Pecha_Kucha↩︎\nhttp://en.wikipedia.org/wiki/Ignite_(event)\n\n↩︎\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2011-2-gsoc/",
    "title": "R's Participation in the Google Summer of Code 2011",
    "description": "This article describes the activity of R in the 2011 Google Summer of\nCode (GSoC), which Wikipedia describes as follows.\\\nThe Google Summer of Code (GSoC) is an annual program, first held from\nMay to August 2005, in which Google awards stipends (of 5000 USD, as\nof 2010) to hundreds of students who successfully complete a requested\nfree or open source software coding project during the summer.",
    "author": [
      {
        "name": "John C. Nash",
        "url": {}
      },
      {
        "name": "Claudia Beleites",
        "url": {}
      }
    ],
    "date": "2011-12-01",
    "categories": [],
    "contents": "\n\n1 Essential elements of GSoC\nGoogle has structured the GSoC to provide student resources for coding\nto open source software projects. While results can be used as part of a\nthesis or article, the focus is coding. Students receive a stipend of\nUS$ 5000 paid in 3 installments, which are only paid after each of the\nstudent’s proposal, mid-term and final work has passed an evaluation.\nThe open source projects, of which the R Foundation for Statistical\nComputing is one, are required to provide mentors for each student who\nmakes a proposal, and the mentoring organization is given a gratuity of\nUS$ 500 per student who is funded.\nThe task of proposing coding projects falls to the mentoring\norganizations, and can be initiated by either prospective mentors or\nprospective students. Mentoring organizations “appoint” administrators\nfor the GSoC activity. This year (2011) was the first we have had two\npeople as co-admins. We can both attest that without this sharing, R’s\neffort this year would very likely have foundered due to events in our\nlives that would have prevented critical tasks from being completed. The\nadministrators shepherd the development of proposals from either mentors\nor students, try to encourage students to rework these proposals (the\nfinal proposals must come from the students), and guide the process of\nranking them. Google has provided a web-based system (Melange) to manage\nthe several thousand proposals, their ranking, and awarding of “slots”\n(funded students).\nGoogle decides the number of slots each mentoring organization will\nreceive. In 2008 and 2009, R got 4 slots, in 2010 we got 5, but in 2011\nwe were offered 15. The workload for the mentors and administrators grew\nsimilarly, as we had to rank approximately 40 proposals from which the\nfunded 15 were chosen. It is possible for a student to propose more than\none activity and be ranked highly by two mentoring organizations. The\nadministrators (including us) were therefore required to participate in\nan online chat “Deduplication” meeting, though there have not been such\nconflicts with the R GSoC student candidates.\n2 Completed proposals in 2011\nSadly, one of our students did not carry out the proposed work but\nvanished for weeks without satisfactory explanation. This is not\nunknown; in the past 10–20% of GSoC students failed to complete their\nwork (this year: 12%) (Google Summer of Code 2011). We had one out of five in\n2010. However, we did get 14 projects to a satisfactory state of\ncompletion this year. Seven of these related to graphical user\ninterfaces (GUIs), images or visualization, four were related to\noptimization (two of these were also in the GUI/visualisation category),\nand one was related to OpenMP. We will very briefly summarize these,\nnaming the students and mentors.\nAndrew Rich:\n\nManipulating RStudio Graphics Towards Creating Intuitive\nMathematical Comprehension\n(mentored by Daniel Kaplan & J. J. Allaire)\nExtends the popular RStudio infrastructure to provide some\ninteractive graphical tools useful in teaching mathematical and\nstatistical concepts.\n\nSebastian Mellor:\n\nDeveloping a hyperSpec GUI\n(mentored by Claudia Beleites and ColinGillespie)\ndeveloped hyperSpecGUI\nwith a graphical user interface to guide spike filtering for Raman\nspectra as demo application.\n\nXiaoyue Cheng:\n\nCranvastime: Interactive longitudinal and temporal data plots\n(mentored by Di Cook and Heike Hofmann)\nis part of cranvas,\ninteractive plots in R. Tools to explore for irregular periodicity\nby wrapping and folding time series, zoom and pan to focus details,\nlink to other statistical plots and explore cross-correlation in\nmultiple series, and individual patterns in longitudinal data.\n\nYixuan Qiu:\n\nA GUI based package to assist optimization problems in R\n(mentored by John Nash and Ben Bolker)\nThe optimgui package from this project is directed towards the\ntask of writing the objective function and related functions used by\nR optim () and related tools. Users frequently find writing such\nobjective functions is prone to errors or numerical instabilities.\n\nPaula Moraga:\n\nDClusterm: Model-based detection of disease clusters\n(mentored by Virgilio Gómez-Rubio and Barry Rowlingson)\nproduced package\nDClusterm implements\nseveral methods for the detection of disease clusters in spatial and\nspatio-temporal data.\nThe methods implemented in the package allow the use of GLM, GLMM\nand zero-inflated models for modelling the data.\n\nKåre Jacobsen:\n\nExploratory visualization of dynamic stochastic processes.\n(mentored by Niels Richard Hansen)\nwrote processDataAnim.\n\nTuo Zhao:\n\nHUGE: High-dimensional Undirected Graph Estimation\n(mentored by Kathryn Roeder and Han Liu)\nproduced package huge.\n\nSunil Kumar:\n\nImage Analysis in R\n(mentored by Ian Fellows)\nlead to RImageJ.\n\nLei Jiang:\n\nOpenMP parallel framework for R\n(mentored by Ferdinand Jamitzky, George Ostruchov, and\nPragneshkumar B. Patel)\nPackages ROpenMP and forpar implement sequential-to-parallel\nsource code transformation based on user-added OpenMP style\ndirectives (as comments in the code) using existing parallel\npackages in R and load the desired parallel backend in an on-the-fly\nmanner for more ease in benchmarking, respectively.\n\nAlexander\n\noptile Category order optimization for graphical displays of\ncategorical data\n(mentored by Antony Unwin)\nproduced package\nextracat.\n\nYu Chen:\n\nTradeAnalytics toolchain enhancements\n(mentored by Brian Peterson)\nThe toolchain is used for forensic analysis of trades on financial\nmarkets.\n\nJennifer Feder Bobb:\n\nConvergence acceleration of the Expectation-Maximization (EM)\nalgorithms in computational statistics: A suite of cutting-edge\nacceleration schemes\n(mentored by Ravi Varadhan)\nThis work extended\nSQUAREM to build the\nturboEM package, for which different algorithms and documentation\nwere developed in the following work.\n\nHui Zhao:\n\nR-EM-Accelerator—Smarter Iterative Schemes Save Your Time\n(mentored by Roger Peng and Ravi Varadhan)\nimplemented EM accelerator and benchmark examples in package\nturboEM.\n\nJuemin Yang:\n\nSpAM: an implementation of the Sparse Additive Models (SpAM)\n(mentored by Han Liu)\nThe package SpAM provides an implementation of the Sparse Additive\nModels (SpAM) and Greedy Sparse Additive Models (G-SpAM). Both the\nmodels are modern nonparametric predictive methods. They\nsimultaneously conduct prediction (e.g. regression/classification),\nfunction estimation (e.g. smoothing and curve fitting), and feature\nselection. We targeted high-dimensional data analysis d >> n.\n\nThe packages can be accessed at\nhttp://code.google.com/p/google-summer-of-code-2011-r/.\n3 Outcomes, benefits and costs\nThe main outcome of a GSoC student effort should be the code that\nbecomes part of the mentoring organization’s project, in our case,\nR packages. However, the short duration of the GSoC “Summer” means that\nit is more realistic to view the contribution as advancing the\nparticular project of the student or mentor. An important adjunct to\nthis is that the student is introduced into the developer community. In\nthe longer term, we may see some impact from the code, as, for example,\nwith the roxygen package. Furthermore, we have had GSoC students in\none year return as mentors in another (e.g., I. Fellows, F.\nThe very presence of R in the GSoC list of mentoring organizations is a\nbenefit in bringing student attention to the R Foundation and its work.\nThe student stipends and modest gratuity are more concrete benefits.\nThere are considerable costs associated with these benefits of course.\nThe mentors and administrators, as well as the students, are under a\nfairly tight timeline dictated by Google. This timeline is really only\nsensible in the context of the North American – possibly even\nCalifornian – academic calendar. Several of our 2011 students had major\nexams in the middle of their work period. The timeline is shown in the\nfigure below.\n\nBefore the organization can apply to participate in GSoC, mentors have\nto prepare a statement of “project ideas”. Students can later respond to\nthese or propose others, then after communicating with the mentors\nprepare a project proposal. Due to the tight and strict deadlines,\nmentors should start to develop ideas and possibly also to look out for\nstudents early (thin line in the time graph). It is strongly encouraged\nthat the mentors pose some form of test or other evaluation of the\ncapability of the student to do the coding.\nOnce the student proposals are submitted (this is done on the Melange\nsystem), the mentors must then rank them over a roughly two-week period.\nThis is, in our opinion, one of the least pleasant aspects of GSoC. In\nsome cases, we noted good projects from students that did not find a\nsuitable mentor. And mentors really are the champions of particular\nproposals. We also saw several good proposals for one topic, and only\nweaker ones for another. Choosing was not easy.\nBesides the quality of the proposal, more parameters for the selection\nwere needed. While these could have been challenged by mentors, there\nwas very little criticism of them. They were:\nTo favour projects with a primary and alternate mentor over those\nwith just one mentor.\nTo allow only one project to be funded per primary mentor.\nTo try to find a level of balance between topic areas.\nTo accept complete proposals only.\nAs administrators, our most troubling issue was a mentor proposal that\nreceived almost unanimous criticism from other mentors as scientifically\nunsound and the project was subsequently rejected. Our main concern is\nless with an unhappy prospective mentor than with the student who put in\neffort to prepare a proposal that is rejected through misjudgement or\nmisdirection of the mentor rather than bad quality of the student’s\nproposal. Possibly we could benefit from a separate committee to review\nmentor ideas before these are suggested for student consideration.\nHowever, the time line is very tight, and our resources are already very\nlimited.\nWe managed communications for the collective of students and mentors\nwith the Google Groups mailing list\ngsoc-r@googlegroups.com. For\nmentors-only communication, a separate mailing list\ngsoc-mentors@r-project.org is\navailable. In addition, Melange automatically put students on a student\nGSoC mailing list, and mentors on the list\ngoogle-summer-of-code-mentors-list@googlegroups.com.\nWhile traffic on the gsoc-r list was relatively light, the\ngoogle-summer-of-code-mentors-list was quite “noisy”, with many trivial\nor non-GSoC items.\nThe Melange system Google chose to use for managing the GSoC effort is\nan in-house Google project, and is constantly being developed. This made\nit at times unstable. While Google staff was very friendly and replied\npromptly to our problems, mentors as well as students had to ask for\nassistance more than once.\nOnce the projects are going, we encouraged mentors and students to keep\nin regular communication. Some were lucky enough to be able to have\nface-to-face meetings. For the rest, we had email, Skype, and instant\nmessaging, but for at least one of us, there were issues of time-zone\ndifferences which made it critical to agree when to communicate.\nFor the administrators, it was important to hear from the mentors and\ntheir students, and in this we are less satisfied. Essentially, we need\na “status board” that has green, yellow and red lights to let us know\nwhich projects are going well, possibly in difficulty, or moribund\nrespectively.\nAs mentioned, we had one “vanishing mentor” who turned up just in time\nfor both mid-term and final evaluations, and this for a project with but\none mentor. In that case, the mentor was having to relocate – ordinary\nlife got in the way of GSoC. For the student, however, this is not a\nvery good situation, and we were fortunate to have a student who was\nself-reliant and competent. In future, we would push harder to ensure\nthat each project is well supported by at least two mentors. In addition\nwe would wish the student had contacted us earlier when he did not get\nresponse from the mentor. The “status board” idea, however implemented,\nwould be high on our priorities for such reasons.\nWe had one student who did very little work and did not reply for an\nextended period and was failed at the mid-term point. This is, of\ncourse, extremely unfortunate, but seems to be an anticipated occurrence\nin that the overall GSoC failure rate appears to be between 10 and 20%\nand related traffic at the GSoC mentors mailing list refers to it as a\nknown issue. While it is recommended that proposals from mentors include\na “test” to demonstrate student capability, there is little to assess\nreliability. Possibly proposals from students would have a higher chance\nof avoiding such drop-outs.\nOn the other hand, we were very happy when one of the high-ranked\nstudents told us promptly that he had got a proper job offer and would\nlike to withdraw his proposal. This was early enough so that the slot\ncould be awarded to another student.\n4 Advice for future students, mentors and administrators\nOur main piece of advice to all is to begin early. The project ideas,\ninitial communications between students and mentors to organize good\nproposals, and the preparation and refinement of student proposals all\nbenefit from as much time as possible. In fact it is now the time to\nfill in the GSoC2012 project idea page at the R-Wiki\n(http://rwiki.sciviews.org/doku.php?id=developers:projects:gsoc2012).\nProspective mentors should arrange for backup in the form of a\nco-mentor. As administrators, we would recommend that the R GSoC effort\nnot qualify any proposal without both a primary and backup mentor.\nMentors should also recognize that the GSoC coding and a research\npracticum or thesis work are not the same. Our understanding is that\nGoogle regards the stipend as for coding, not as a general scholarship\nor bursary. The very name “Summer of Code” connotes a view that the\ncoding is a form of summer employment. Mentors should also be aware that\nstudents can range in level from a first-year undergraduate to a PhD\nstudent about to defend.\nAs we have already suggested, we have particular concerns that students\nwho make proposals based on mentors’ ideas appear to have a large\nadvantage over students with their own proposal. It is clear we need to\nfind mentors for students with their own proposal. At the time when the\nproposals are being refined, it is late in the day to arrange suitable\nsupport and guidance for students who we cannot expect to be\nwell-connected to our R community. Can we ask for volunteer potential\nmentors who are willing to work with students who bring their own\nproposal? If so, we need to work out how to match such students with\nappropriate prospective mentors.\nNext year’s admins will be Toby Dylan Hocking and John C. Nash with\nVirgilio Gómez-Rubio as backup.\n\n\n\n\nCRAN packages used\nhuge, RImageJ, extracat, SQUAREM\nCRAN Task Views implied by cited packages\nGraphicalModels, NumericalMathematics\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\nGoogle Summer of Code. ProgramStatistics: Program Information for Past Years. 2011. http://code.google.com/p/google-summer-of-code/wiki/ProgramStatistics?ts=1315502962&updated=ProgramStatistics.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2011-2-r-changes/",
    "title": "Changes in R",
    "description": "The 'Changes in R' article from the 2011-2 issue.",
    "author": [
      {
        "name": "The R Core Team",
        "url": {}
      }
    ],
    "date": "2011-12-01",
    "categories": [],
    "contents": "\n\nCHANGES IN R VERSION 2.14.0\n\nSIGNIFICANT USER-VISIBLE CHANGES\nAll packages must have a namespace, and one is created on\ninstallation if not supplied in the sources. This means that any\npackage without a namespace must be re-installed under this version\nof R (but previously-installed data-only packages without R code can\nstill be used).\nThe yLineBias of the X11() and windows() families of devices\nhas been changed from 0.1 to 0.2: this changes slightly the vertical\npositioning of text in the margins (including axis annotations).\nThis is mainly for consistency with other devices such as quartz()\nand pdf(). (Wish of PR#14538.)\nThere is a new graphics parameter \"ylbias\" which allows the y-line\nbias of the graphics device to be tweaked, including to reproduce\noutput from earlier versions of R.\nLabeling of the p-values in various anova tables has been\nrationalized to be either \"Pr(>F)\" or \"Pr(>Chi)\" (i.e. the\n\"Pr(F)\", \"Pr(Chi)\" and \"P(>|Chi|)\" variants have been\neliminated). Code which extracts the p value via indexing by name\nmay need adjustment.\n:: can now be used for datasets made available for lazy-loading in\npackages with namespaces (which makes it consistent with its use for\ndata-only packages without namespaces in earlier versions of R).\nThere is a new package parallel.\nIt incorporates (slightly revised) copies of packages multicore\nand snow (excluding MPI, PVM and NWS clusters). Code written to\nuse the higher-level API functions in those packages should work\nunchanged (apart from changing any references to their namespaces to\na reference to parallel, and links explicitly to multicore or\nsnow on help pages).\nIt also contains support for multiple RNG streams following L’Ecuyer\net al (2002), with support for both mclapply and snow\nclusters. This replaces functions like clusterSetupRNG() from\nsnow (which are not in parallel).\nThe version released for R 2.14.0 contains base functionality:\nhigher-level convenience functions are planned (and some are already\navailable in the ‘R-devel’ version of R).\nBuilding PDF manuals (for R itself or packages, e.g. via\nR CMD check) by default requires the LaTeX package inconsolata:\nsee the section on ‘Making the manuals’ in the ‘R Installation and\nAdministration Manual’.\naxTicks(*, log=TRUE) has changed in some cases to satisfy the\ndocumented behavior and be consistent.\n\n\nNEW FEATURES\ntxtProgressBar() can write to an open connection instead of the\nconsole.\nNon-portable package names ending in . are no longer allowed. Nor\nare single-character package names (R was already disallowed).\nregexpr() and gregexpr() with perl = TRUE allows Python-style\nnamed captures. (Wish and contribution of PR#14518.)\nThe placement of ‘plotmath’ text in the margins of plots done by\nbase graphics now makes the same vertical adjustment as ordinary\ntext, so using ordinary and plotmath text on the same margin line\nwill seem better aligned (but not exactly aligned, since ordinary\ntext has descenders below the baseline and plotmath places them on\nthe baseline). (Related to PR#14537.)\nsunflowerplot() now has a formula interface. (Wish of PR#14541.)\niconv() has a new argument toRaw to handle encodings such as\nUTF-16 with embedded nuls (as was possible before the CHARSXP\ncache was introduced).\nIt will also accept as input the type of list generated with\ntoRaw = TRUE.\nGarbage-collecting an unused input text connection no longer gives a\nwarning (since it ‘connects’ to nothing outside R).\nread.table() and scan() have gained a text argument, to allow\nreading data from a (possibly literal) character string.\noptim(*, method = .) now allows method = \"Brent\" as an interface\nto optimize(), for use in cases such as mle() where optim() is\nused internally.\nmosaicplot() gains a border argument. (Wish of PR#14550.)\nsmooth.spline() gains a tol argument which controls how\ndifferent x values need to be to be treated as distinct. The\ndefault has been changed to be more reliable for inputs whose range\nis small compared to their maximum absolute value. (Wish of\nPR#14452.)\ngl() runs faster by avoiding calling factor().\nThe print() method for object.size() accepts B as well as b\nas an abbreviation for ‘bytes’.\nunlink() gains a force argument to work like rm -f and if\npossible override restrictive permissions.\npbirthday() and qbirthday() now use exact calculations for\ncoincident = 2.\nunzip() and unz() connections have been updated with support for\nmore recent Zip64 features (including large file sizes and bzip2\ncompression, but not UTF-8 file names).\nunzip() has a new option to restore file times from those recorded\n(in an unknown timezone) in the zip file.\nupdate.packages() now accepts a character vector of package names\nfor the oldPkgs argument. (Suggestion of Tal Galili.)\nThe special reference class fields .self and .refClassDef are\nnow read-only to prevent corrupting the object.\ndecompose() now returns the original series as part of its value,\nso it can be used (rather than reconstructed) when plotting.\n(Suggestion of Rob Hyndman.)\nRao’s efficient score test has been implemented for glm objects.\nSpecifically, the add1, drop1, and anova methods now allow\ntest = \"Rao\".\nIf a saved workspace (e.g. .RData) contains objects that cannot be\nloaded, R will now start with an warning message and an empty\nworkspace, rather than failing to start.\nstrptime() now accepts times such as 24:00 for midnight at the\nend of the day, for although these are disallowed by POSIX\n1003.1-2008, ISO 8601:2004 allows them.\nAssignment of names() to S4 objects now checks for a corresponding\n\"names\" slot, and generates a warning or an error if that slot is\nnot defined. See the section on slots in ?Classes.\nThe default methods for is.finite(), is.infinite() and\nis.nan() now signal an error if their argument is not an atomic\nvector.\nThe formula method for plot() no longer places package stats on\nthe search path (it loads the namespace instead).\nThere now is a genuine \"function\" method for plot() rather than\nthe generic dispatching internally to graphics::plot.function().\nIt is now exported, so can be called directly as plot.function().\nThe one-sided ks.test() allows exact = TRUE to be specified in\nthe presence of ties (but the approximate calculation remains the\ndefault: the ‘exact’ computation makes assumptions known to be\ninvalid in the presence of ties).\nThe behaviour of curve(add = FALSE) has changed: it now no longer\ntakes the default x limits from the previous plot (if any): rather\nthey default to c(0, 1) just as the \"function\" method for\nplot(). To get the previous behaviour use curve(add = NA), which\nalso takes the default for log-scaling of the x-axis from the\nprevious plot.\nBoth curve() and the plot() method for functions have a new\nargument xname to facilitate plots such as sin(t) vs t.\nThe local argument to source() can specify an environment as\nwell as TRUE (parent.env()) and FALSE (.GlobalEnv). It gives\nbetter error messages for other values, such as NA.\nvcov() gains methods for classes \"summary.lm\" and\n\"summary.glm\".\nThe plot() method for class \"profile.nls\" gains ylab and lty\narguments, and passes ... on to plot.default.\nCharacter-string arguments such as the mode argument of\nvector(), as.vector() and is.vector() and the description\nargument of file() are required to be of length exactly one,\nrather than any further elements being silently discarded. This\nhelps catch incorrect usage in programming.\nThe length argument of vector() and its wrappers such as\nnumeric() is required to be of length exactly one (other values\nare now an error rather than giving a warning as previously).\nvector(len) and length(x) <- len no longer acccept\nTRUE/FALSE for len (not that they were ever documented to, but\nthere was special-casing in the C code).\nThere is a new function Sys.setFileTime() to set the time of a\nfile (including a directory). See its help for exactly which times\nit sets on various OSes.\nThe file times reported by file.info() are reported to sub-second\nresolution on systems which support it. (Currently the POSIX 2008\nand FreeBSD/Darwin/NetBSD methods are detected.)\nNew function getCall(m) as an abstraction for m$call, enabling\nupdate()’s default method to apply more universally. (NB: this can\nbe masked by existing functions in packages.)\nSys.info() gains a euser component to report the ‘effective’\nuser on OSes which have that concept.\nThe result returned by try() now contains the original error\ncondition object as the \"condition\" attribute.\nAll packages with R code are lazy-loaded irrespective of the\nLazyLoad field in the DESCRIPTION file. A warning is given if\nthe LazyLoad field is overridden.\nRd markup has a new \\bsl{}figure tag so that figures can be\nincluded in help pages when converted to HTML or LaTeX. There are\nexamples on the help pages for par() and points().\nThe built-in httpd server now allows access to files in the session\ntemporary directory tempdir(), addressed as the /session\ndirectory on the httpd server.\nDevelopment versions of R are no longer referred to by the number\nunder which they might be released, e.g. in the startup banner,\nR –version and sessionUtils(). The correct way to refer to a\ndevelopment version of R is ‘R-devel’, preferably with the date and\nSVN version number.\nE.g. R-devel (2011-07-04 r56266)\nThere is a new function texi2pdf() in package tools, currently a\nconvenience wrapper for texi2dvi(pdf = TRUE).\nThere are two new options for typesetting PDF manuals from Rd files.\nThese are beramono and inconsolata, and used the named font for\nmonospaced output. They are intended to be used in combination with\ntimes, and times,inconsolata,hyper is now the default for the\nreference manual and package manuals. If you do not have that font\ninstalled, you can set R_RD4PF to one of the other options: see\nthe ‘R Installation and Administration Manual’.\nAutomatic printing for reference classes is now done by the\n$show() method. A method is defined for class envRefClass and\nmay be overriden for user classes (see the ?ReferenceClasses\nexample). S4 show() methods should no longer be needed for\nreference classes.\ntools::Rdiff (by default) and R CMD Rdiff now ignore differences\nin pointer values when comparing printed environments, compiled byte\ncode, etc.\nThe \"source\" attribute on functions created with\nkeep.source=TRUE has been replaced with a \"srcref\" attribute.\nThe \"srcref\" attribute references an in-memory copy of the source\nfile using the \"srcfilecopy\" class or the new \"srcfilealias\"\nclass.\nNew items “User Manuals” and Technical\nPapers have been added to\nthe HTML help main page. These link to vignettes in the base and\nrecommended packages and to a collection of papers about R issues,\nrespectively.\nDocumentation and messages have been standardized to use “namespace”\nrather than “name space”.\nsetGeneric() now looks in the default packages for a non-generic\nversion of a function if called from a package with a namespace. (It\nalways did for packages without a namespace.)\nSetting the environment variable _R_WARN_ON_LOCKED_BINDINGS_ will\ngive a warning if an attempt is made to change a locked binding.\n\\\\SweaveInput is now supported when generating concordances in\nSweave().\nfindLineNum() and setBreakpoint() now allow the environment to\nbe specified indirectly; the latter gains a clear argument to\nallow it to call untrace().\nThe body of a closure can be one of further types of R objects,\nincluding enviroments and external pointers.\nThe Rd2HTML() function in package tools now has a stylesheet\nargument, allowing pages to be displayed in alternate formats.\nNew function requireNamespace() analogous to require(),\nreturning a logical value after attempting to load a namespace.\nThere is a new type of RNG, \"L’Ecuyer-CMRG\", implementing L’Ecuyer\n(1999)‘s ’combined multiple-recursive generator’ MRG32k3a. See the\ncomments on ?RNG.\nhelp.search() and ?? can now display vignettes and demos as well\nas help pages. The new option \"help.search.types\" controls the\ntypes of documentation and the order of their display.\nThis also applies to HTML searches, which now give results in all of\nhelp pages, vignettes and demos.\nsocketConnection() now has a timeout argument. It is now\ndocumented that large values (package snow used a year) do not\nwork on some OSes.\nThe initialization of the random-number generator now uses the\nprocess ID as well as the current time, just in case two R processes\nare launched very rapidly on a machine with low-resolution wall\nclock (some have a resolution of a second; modern systems have\nmicrosecond-level resolution).\nNew function pskill() in the tools package to send a terminate\nsignal to one or more processes, plus constants such as SIGTERM to\nprovide a portable way to refer to signals (since the numeric values\nare OS-dependent).\nNew function psnice() in the tools package to return or change\nthe ‘niceness’ of a process. (Refers to the ‘priority class’ on\nWindows.)\nlist.dirs() gains a recursive argument.\nAn Authors@R field in a package DESCRIPTION file can now be used\nto generate Author and Maintainer fields if needed, and to\nauto-generate package citations.\nNew utility getElement() for accessing either a list component or\na slot in an S4 object.\nstars() gains a col.lines argument, thanks to Dustin Sallings.\n(Wish of PR#14657.)\nNew function regmatches() for extracting or replacing matched or\nnon-matched substrings from match data obtained by regexpr(),\ngregexpr() and regexec().\nhelp(package = \"pkg_name\", help_type = \"HTML\") now gives HTML help\non the package rather than text help. (This gives direct access to\nthe HTML version of the package manual shown via help.start()‘s\n’Packages’ menu.)\nagrep() gains a fixed argument to optionally allow approximate\nregular expression matching, and a costs argument to specify\npossibly different integer match costs for insertions, deletions and\nsubstitutions.\nread.dcf() and write.dcf() gain a keep.white argument to\nindicate fields where whitespace should be kept as is.\navailable.packages() now works around servers that fail to return\nan error code when PACKAGES.gz does not exist. (Patch submitted by\nSeth Schommer.)\nreadBin() can now read more than \\(2^{31}-1\\) bytes in a single call\n(the previously documented limitation).\nNew function regexec() for finding the positions of matches as\nwell as all substrings corresponding to parenthesized subexpressions\nof the given regular expression.\nNew function adist() in package utils for computing ‘edit’\n(generalized Levenshtein) distances between strings.\nClass \"raster\" gains an is.na method to avoid confusion from the\nmisuse of the matrix method (such as PR#14618).\nThe identical() function gains an ignore.bytecode argument to\ncontrol comparison of compiled functions.\npmin and pmax now warn if an argument is partially recycled\n(wish of PR#14638).\nThe default for image(useRaster=) is now taken from option\n\"preferRaster\": for the small print see ?image.\nstr() now displays reference class objects and their fields,\nrather than treating them as classical S4 classes.\nNew function aregexec() in package utils for finding the\npositions of approximate string matches as well as all substrings\ncorresponding to parenthesized subexpressions of the given regular\nexpression.\ndownload.file() has an extra argument to pass additional\ncommand-line options to the non-default methods using command-line\nutilities.\ncacheOK = FALSE is now supported for method = \"curl\".\ninteraction.plot(*, type = .) now also allows type \"o\" or \"c\".\naxTicks(*, log=TRUE) did sometimes give more values than the ticks\nin the corresponding graphics::axis(). By default, it now makes\nuse of the new (graphics-package independent) axisTicks() which\ncan make use of a new utility .axisPars(). Further, it now returns\na decreasing sequence (as for log=FALSE) when usr is decreasing.\nUsing fix() or edit() on a R object (except perhaps a matrix or\ndata frame) writes its temporary file with extension .R so editors\nwhich select their mode based on the extension will select a\nsuitable mode.\n\n\nGRAPHICS DEVICES\nThe pdf() device makes use of Flate compression: this is\ncontrolled by the new logical argument compress, and is enabled by\ndefault.\nDevices svg(), cairo_pdf() and cairo_ps() gain a family\nargument.\nOn a Unix-alike X11() gains a family argument. This is one of\nthe x11.options() and so can be passed as an argument to the\nbmp(), jpeg(), png() and tiff() devices.\nAnalogous changes have been made on Windows, so all built-in R\ngraphics devices now have a family argument except pictex()\n(which has no means to change fonts).\nThe bmp(), jpeg(), png() and tiff() devices now make use of\nthe antialias argument for type = \"quartz\".\nThere are several new built-in font mappings for\nX11(type = \"Xlib\"): see the help on X11Fonts().\nThere is a new type X11(type = \"dbcairo\") which updates the\nscreeen less frequently: see its help page.\nThe X11() device now makes use of cursors to distinguish its\nstates. The normal cursor is an arrow (rather than a crosshair); the\ncrosshair is used when the locator is in use, and a watch cursor is\nshown when plotting computations are being done. (These are the\nstandard names for X11 cursors: how they are actually displayed\ndepends on the window manager.)\nNew functions dev.hold() and dev.flush() for use with graphics\ndevices with buffering. These are used for most of the high-level\ngraphics functions such as boxplot(), so that the plot is only\ndisplayed when the page is complete.\nCurrently implemented for windows(buffered = TRUE), quartz() and\nthe cairographics-based X11() types with buffering (which are the\ndefault on-screen devices).\nNew function dev.capture() for capture of bitmap snapshots of\nimage-based devices (a superset of the functionality provided by\ngrid.cap() in grid).\nThe default colormodel for pdf() and postscript() is now\ncalled \"srgb\" to more accurately describe it. (Instead of \"rgb\",\nand in the case of postscript() it no longer switches to and from\nthe gray colorspace, by default.)\nThe colormodel for postscript() which does use both gray and\nsRGB colorspaces is now called \"srgb+gray\".\nPlots which are known to use only black/white/transparent can\nadvantageously use colormodel = \"gray\" (just as before, but there\nis now slightly more advantage in doing so).\npostscript() with values colormodel = \"rgb\" and\ncolormodel = \"rgb-nogray\" give the behaviour prior to R 2.13.0 of\nuncalibrated RGB, which under some circumstances can be rendered\nmuch faster by a viewer.\npdf(colormodel = \"rgb\") gives the behaviour prior to R 2.13.0 of\nuncalibrated RGB, which under some circumstances can be rendered\nfaster by a viewer, and the files will be smaller (by about 9KB if\ncompression is not used).\nThe postscript() device only includes the definition of the sRGB\ncolorspace in the output file for the colormodels which use it.\nThe postscript() and pdf() devices now output greyscale raster\nimages (and not RGB) when colormodel = \"gray\".\npostscript(colormodel = \"gray\") now accepts non-grey colours and\nuses their luminance (as pdf() long has).\ncolormodel = \"grey\" is allowed as an alternative name for\npostscript() and pdf().\npdf() in the default sRGB colorspace outputs many fewer changes of\ncolorspace, which may speed up rendering in some viewing\napplications.\nThere is a new function dev.capabilities() to query the\ncapabilities of the current device. The initial set of capabilities\nare support for semi-transparent colours, rendering and capturing\nraster images, the locator and for interactive events.\nFor pdf(), maxRasters is increased as needed so the argument is\nno longer used.\n\n\nSWEAVE & VIGNETTES\nOptions keep.source = TRUE, figs.only = FALSE are now the default.\nThe way the type of user-defined options is determined has changed.\nPreviously they were all regarded as logical: now the type is\ndetermined by the value given at first use.\nThe allowed values of logical options are now precisely those\nallowed for character inputs to as.logical(): this means that t\nand f are no longer allowed (although T and F still are).\nThe preferred location for vignette sources is now the directory\nvignettes and not inst/doc: R CMD build will now re-build\nvignettes in directory vignettes and copy the .Rnw (etc) files\nand the corresponding PDFs to inst/doc. Further files to be copied\nto inst/doc can be specified via the file\nvignettes/.install_extras.\nR CMD Sweave now supports a –driver option to select the Sweave\ndriver: the default is equivalent to –driver=RweaveLatex.\nR CMD Sweave and R CMD Stangle support options –encoding and\n–options.\nThe Rtangle() driver allows output = \"stdout\" or\noutput = \"stderr\" to select the output or message connection. This\nis convenient for scripting using something like\n–options=’output=\"stdout\"’foo2.R\nThere is a new option pdf.compress controlling whether PDF figures\nare generated using Flate compression (they are by default).\nR CMD Sweave now has a –pdf option to produce a PDF version of\nthe processed Sweave document.\nIt is no longer allowed to have two vignettes with the same vignette\nbasename (e.g. vig.Rnw and vig.Snw). (Previously one vignette\nhid the other in the vignette() function.)\n\n\nC-LEVEL FACILITIES\nFunction R_tmpnam2 has been added to the API to allow a temporary\nfilename to include a specified extension.\n\n\nPACKAGE INSTALLATION\nPackage DESCRIPTION file field KeepSource forces the package to\nbe installed with keep.source = TRUE (or FALSE). (Suggestion of\nGreg Snow. Note that as all packages are lazy-loaded, this is now\nonly relevant at installation.)\nThere are corresponding options –with-keep.source and\n–without-keep.source for R CMD INSTALL.\nR CMD INSTALL has a new option –byte-compile to byte-compile the\npackages during installation (since all packages are now\nlazy-loaded). This can be controlled on a per-package basis by the\noptional field ByteCompile in the DESCRIPTION file.\nA package R code but without a NAMESPACE file will have a default\none created at R CMD build or R CMD INSTALL time, so all\npackages will be installed with namespaces. A consequence of this is\nthat .First.lib() functions need to be copied to .onLoad()\n(usually) or .onAttach(). For the time being, if there is an\nauto-generated NAMESPACE file and no .onLoad() nor .onAttach()\nfunction is found but .First.lib() is, it will be run as the\nattach hook (unless the package is one of a list of known\nexceptions, when it will be run as the load hook).\nA warning is given if test-loading a package changes a locked\nbinding in a package other than itself. It is likely that this will\nbe disallowed in future releases. (There are pro tem some\nexceptions to the warning.)\nA dependency on SVN revision is allowed for R, e.g.\nR (>= r56550). This should be used in conjunction with a version\nnumber, e.g. R (>= 2.14.0), R (>= r56550) to distinguish beteen\nR-patched and R-devel versions with the same SVN revision.\ninstalled.packages() now hashes the names of its cache files to\navoid very rare problems with excessively long path names.\n(PR#14669)\nA top-level COPYING file in a package is no longer installed (file\nnames LICENSE or LICENCE having long been preferred).\n\n\nUTILITIES\nR CMD check now gives an error if the R code in a vignette fails\nto run, unless this is caused by a missing package.\nR CMD check now unpacks tarballs in the same way as\nR CMD INSTALL, including making use of the environment variable\nR_INSTALL_TAR to override the default behaviour.\nR CMD check performs additional code analysis of package startup\nfunctions, and notifies about incorrect argument lists and\n(incorrect) calls to functions which modify the search path or\ninappropriately generate messages.\nR CMD check now also checks compiled code for symbols\ncorresponding to functions which might terminate R or write to\nstdout/stderr instead of the console.\nR CMD check now uses a pdf() device when checking examples\n(rather than postscript()).\nR CMD check now checks line-endings of makefiles and C/C++/Fortran\nsources in subdirectories of src as well as in src itself.\nR CMD check now reports as a NOTE what look like methods\ndocumented with their full names even if there is a namespace and\nthey are exported. In almost all cases they are intended to be used\nonly as methods and should use the \\\\method markup. In the other\nrare cases the recommended form is to use a function such as\ncoefHclust which would not get confused with a method, document\nthat and register it in the NAMESPACE file by\ns3method(coef, hclust, coefHclust).\nThe default for the environment variable _R_CHECK_COMPACT_DATA2_\nis now true: thus if using the newer forms of compression introduced\nin R 2.10.0 would be beneficial is now checked (by default).\nReference output for a vignette can be supplied when checking a\npackage by R CMD check: see ‘Writing R Extensions’.\nR CMD Rd2dvi allows the use of LaTeX package inputenx rather\nthan inputenc: the value of the environment variable\nRD2DVI_INPUTENC is used. (LaTeX package inputenx is an optional\ninstall which provides greater coverage of the UTF-8 encoding.)\nRscript on a Unix-alike now accepts file names containing spaces\n(provided these are escaped or quoted in the shell).\nR CMD build on a Unix-alike (only) now tries to preserve dates on\nfiles it copies from its input directory. (This was the undocumented\nbehaviour prior to R 2.13.0.)\n\n\nDEPRECATED AND DEFUNCT\nrequire() no longer has a save argument.\nThe gamma argument to hsv(), rainbow(), and rgb2hsv() has\nbeen removed.\nThe –no-docs option for R CMD build –binary is defunct: use\n–install-args instead.\nThe option –unsafe to R CMD INSTALL is defunct: use the\nidentical option –no-lock instead.\nThe entry point pythag formerly in Rmath.h is defunct: use\ninstead the C99 function hypot.\nR CMD build –binary is formally defunct: R CMD INSTALL –build\nhas long been the preferred alternative.\nzip.file.extract() is now defunct: use unzip() or unz()\ninstead.\nR CMD Rd2dvi without the –pdf option is now deprecated: only PDF\noutput will be supported in future releases (since this allows the\nuse of fonts only supported for PDF), and only R CMD Rd2pdf will\nbe available.\nOptions such as –max-nsize and the function mem.limits() are now\ndeprecated: these limits are nowadays almost never used, and are\nreported by gc() when they are in use.\nForms like binomial(link = \"link\") for GLM families deprecated\nsince R 2.4.0 are now defunct.\nThe declarativeOnly argument to loadNamespace() (not relevant\nsince R 2.13.0) has been removed.\nUse of library.dynam() without specifying all the first three\narguments is deprecated. (It is often called from a namespace, and\nthe defaults are only appropriate to a package.)\nUse of chname in library.dynam() with the extension .so or\n.dll (which is clearly not allowed according to the help page) is\ndeprecated. This also applies to library.dynam.unload() and\nuseDynLib directives in NAMESPACE files.\nIt is deprecated to use mean(x) and sd(x) directly on data\nframes (or also matrices, for sd) x, instead of simply using\nsapply.\nIn the same spirit, median(x) now gives an error for a data frame\nx (it often gave nonsensical results).\nThe keep.source argument to library() and require() is\ndeprecated: it was only used for packages installed without\nlazy-loading, and now all packages are lazy-loaded.\nUsing a false value for the DESCRIPTION field LazyLoad is\ndeprecated.\n\n\nINSTALLATION\nThe base and recommended packages are now byte-compiled (equivalent\nto make bytecode in R 2.13.x).\nConfigure option –with-system-zlib now only makes use of the basic\ninterface of zlib and not the C function gzseek which has shown\nerroneous behaviour in zlib 1.2.4 and 1.2.5.\nThe zlib in the R sources is now version 1.2.5. (This is safe even\non 32-bit Linux systems because only the basic interface is now\nused.)\nThe .afm files in package grDevices are now installed as\ncompressed files (as long done on Windows), saving ca 2MB on the\ninstalled size.\nThe non-screen cairo-based devices are no longer in the X11 module\nand so can be installed without X11. (We have never seen a\nUnix-alike system with cairographics installed but not X11, but a\nuser might select –without-x.)\nConfigure will try to use -fobjc-exceptions for the Objective-C\ncompiler (if present) to ensure that even compilers that do not\nenable exceptions by default (such as vanilla gcc) can be used.\n(Objective-C is currently only used on Mac OS X.)\nThe system call times is required.\nThe C99 functions acosh, asinh, atanh, snprintf and\nvsnprintf are now required.\nThere is no longer support for making DVI manuals via make dvi,\nmake install-dvi and similar. Only PDF manuals are supported (to\nallow the use of fonts which are only available for PDF.)\nThe configure arguments used during configuration of R are\nincluded as a comment in Makeconf for informative purposes on\nUnix-alikes in a form suitable for shell execution. Note that those\nare merely command-line arguments, they do not include environment\nvariables (one more reason to use configure variables instead) or\nsite configuration settings.\nFramework installation now supports DESTDIR (Mac OS X only).\nJava detection (R CMD javareconf) works around bogus\njava.library.path property in recent Oracle Java binaries.\n\n\nBUG FIXES\nThe locale category LC_MONETARY was only being set on startup on\nWindows: that is now done on Unix-alikes where supported.\nReference class utilities will detect an attempt to modify methods\nor fields in a locked class definition (e.g., in a namespace) and\ngenerate an error.\nThe formula methods for lines(), points() and text() now work\neven if package stats is not on the search path.\nIn principle, S4 classes from different packages could have the same\nname. This has not previously worked. Changes have now been\ninstalled that should allow such classes and permit methods to use\nthem. New functions className() and multipleClasses() are\nrelated tools for programming.\nWork around an issue in Linux (a system select call resetting\ntv) which prevented internet operations from timing out properly.\nSeveral stack trampling and overflow issues have been fixed in TRE,\ntriggered by agrep and friends with long patterns. (PR#14627.)\n(“design infelicity”) Field assignments in reference classes are now\nconsistent with slots in S4 classes: the assigned value must come\nfrom the declared class (if any) for the field or from a subclass.\nThe methods objects constructed for \"coerce\" and \"coerce<-\" were\nlacking some essential information in the generic, defined and\ntarget slots; as() did not handle duplicate class definitions\ncorrectly.\nThe parser no longer accepts the digit 8 in an octal character\ncode in a string, nor does it accept unterminated strings in a file.\n(Reported by Bill Dunlap.)\nThe print() method for class \"summary.aov\" did not pass on\nargument digits when summary() was called on a single object,\nand hence used more digits than documented.\nThe X11() device’s cairo back-end produced incorrect capture\nsnapshot images on big-endian machines.\nloglin() gave a spurious error when argument margin consisted of\na single element of length one. (PR#14690)\nloess() is better protected against misuse, e.g. zero-length\nspan. (PR#14691)\nHoltWinters() checks that the optimization succeeded. (PR#14694)\nThe (undocumented) inclusion of superclass objects in default\ninitializing of reference classes overwrote explicit field\narguments. The bug is fixed, the feature documented and a test\nadded.\nround(x, -Inf) now does something sensible (return zero rather\nthan NA).\nsignif(x, -Inf) now behaves as documented (signif(x, 1)) rather\nthan giving zero.\nThe \"table\" method for Axis() hardcoded side = 1, hence calls\nto plot(<vector>, <table>) labelled the wrong axis. (PR#14699)\nCreating a connection might fail under gctorture(TRUE).\nstack() and unstack() converted character columns to factors.\nunstack() sometimes produced incorrect results (a list or a\nvector) if the factor on which to un-split had only one level.\nOn some systems help(\".C\", help_type = \"pdf\") and similar\ngenerated file names that TeX was unable to handle.\nNon-blocking listening socket connections continued to report\nisIncomplete() as true even when the peer had closed down and all\navailable input had been read.\nThe revised HTML search system now generates better hyperlinks to\nhelp topics found: previously it gave problems with help pages with\nnames containing e.g. spaces and slashes.\nA late change in R 2.13.2 broke \\\\Sexpr expressions in Rd files.\nThe creation of ticks on log axes (including axTicks() sometimes\nincorrectly omitted a tick at one end\nThe creation of ticks on log axes (including by axTicks())\nsometimes incorrectly omitted a tick at one end of the range by\nrounding error in a platform-dependent way. This could be seen in\nthe examples for axTicks(), where with axis limits c(0.2, 88)\nthe tick for 0.2 was sometimes omitted.\nqgamma() for small shape underflows to 0 rather than sometimes\ngiving NaN. (PR#8528, PR#14710)\nmapply() now gives an explicit error message (rather than an\nobscure one) is inputs of zero and positive length are mixed.\nSetting a Hershey font family followed by string height query would\ncrash R.\nR CMD javareconf -e would fail for some shells due to a shift\nerror. Also the resulting paths will no longer contain\n$(JAVA_HOME) as that can result in an unintended substitution\nbased on Makeconf instead of the shell setting.\n\nCHANGES IN R VERSION 2.13.2\n\nNEW FEATURES\nmem.limits() now reports values larger than the maximum integer\n(previously documented to be reported as NA), and allows larger\nvalues to be set, including Inf to remove the limit.\nThe print() methods for classes \"Date\", \"POSIXct\" and\n\"POSIXlt\" respect the option \"max.print\" and so are much faster\nfor very long datetime vectors. (Suggestion of Yohan Chalabi.)\nuntar2() now works around errors generated with tar files that\nuse more than the standard 6 digits for the checksum. (PR#14654)\ninstall.packages() with Ncpus > 1 guards against simultaneous\ninstallation of indirect dependencies as well as direct ones.\nSweave now knows about a few more Windows’ encodings (including\ncp1250 and cp1257) and some inputenx encodings such as\nkoi8-r.\npostscript(colormodel = \"rgb-nogray\") no longer sets the sRGB\ncolorspace for each colour and so some viewers may render its files\nmuch faster than the default colormodel =\"rgb\".\nThe default for pdf(maxRasters=) has been increased from 64 to\n\n\nreadBin() now warns if signed = FALSE is used inappropriately\n(rather than being silently ignored).\nIt enforces the documented limit of \\(2^{31}-1\\) bytes in a single\ncall.\nPCRE has been updated to version 8.13, a bug-fix release with\nupdated Unicode tables (version 6.0.0). An additional patch (r611\nfrom PCRE 8.20-to-be) has been added to fix a collation symbol\nrecognition issue.\n\n\nINSTALLATION\nIt is possible to build in src/extra/xdr on more platforms.\n(Needed since glibc 2.14 hides its RPC implementation.)\nconfigure will find the Sun TI-RPC implementation of xdr (in\nlibtirpc) provided its header files are in the search path: see\nthe ‘R Installation and Administration Manual’.\n\n\nPACKAGE INSTALLATION\nUsing a broad exportPattern directive in a NAMESPACE file is no\nlonger allowed to export internal objects such as .onLoad and\n.__S3MethodsTable__. .\nThese are also excluded from imports, along with .First.lib.\n\n\nBUG FIXES\nfisher.test() had a buglet: If arguments were factors with unused\nlevels, levels were dropped and you would get an error saying that\nthere should be at least two levels, inconsistently with\npre-tabulated data. (Reported by Michael Fay).\npackage.skeleton() will no longer dump S4 objects supplied\ndirectly rather than in a code file. These cannot be restored\ncorrectly from the dumped version.\nBuild-time expressions in help files did not have access to\nfunctions in the package being built (with R CMD build).\nBecause quote() did not mark its result as being in use,\nmodification of the result could in some circumstances modify the\noriginal call.\nPlotting pch = ’.’ now guarantees at least a one-pixel dot if\ncex > 0.\nThe very-rarely-used command-line option –max-vsize was\nincorrectly interpreted as a number of Vcells and not in bytes as\ndocumented. (Spotted by Christophe Rhodes.)\nThe HTML generated by Rd2HTML() comes closer to being standards\ncompliant.\nfilter(x, recursive = TRUE) gave incorrect results on a series\ncontaining NAs. (Spotted by Bill Dunlap.)\nProfiling stats::mle() fits with a fixed parameter was not\nsupported. (PR#14646)\nretracemem() was still using positional matching. (PR#14650)\nThe quantile method for \"ecdf\" objects now works and is\ndocumented.\nxtabs(~ .., ..., sparse=TRUE) now also works together with an\nexclude = .. specification.\ndecompose() computed an incorrect seasonal component for time\nseries with odd frequencies.\nThe pdf() device only includes the definition of the sRGB\ncolorspace in the output file for the \"rgb\" colormodel (and not\nfor \"gray\" nor \"cmyk\"): this saves ca 9KB in the output file.\n.hasSlot() wrongly gave FALSE in some cases.\nSweave() with keep.source=TRUE could generate spurious NA\nlines when a chunk reference appeared last in a code chunk.\n\\\\Sexpr[results=rd] in an .Rd file now first tries\nparse_Rd(fragment=FALSE) to allow Rd section-level macros to be\ninserted.\nThe print() method for class \"summary.aov\" did not pass on\narguments such as signif.stars when summary() was called on a\nsingle object. (PR#14684)\nIn rare cases ks.test() could return a p-value very slightly less\nthan 0 by rounding error. (PR#14671)\nIf trunc() was called on a \"POSIXlt\" vector and the result was\nsubsetted, all but the first element was converted to NA.\n(PR#14679)\ncbind() and rbind() could cause memory corruption when used on a\ncombination of raw and logical/integer vectors.\n\nCHANGES IN R VERSION 2.13.1\n\nNEW FEATURES\niconv() no longer translates NA strings as \"NA\".\npersp(box = TRUE) now warns if the surface extends outside the box\n(since occlusion for the box and axes is computed assuming the box\nis a bounding box). (PR#202.)\nRShowDoc() can now display the licences shipped with R, e.g.\nRShowDoc(\"GPL-3\").\nNew wrapper function showNonASCIIfile() in package tools.\nnobs() now has a \"mle\" method in package stats4.\ntrace() now deals correctly with S4 reference classes and\ncorresponding reference methods (e.g., $trace()) have been added.\nxz has been updated to 5.0.3 (very minor bugfix release).\ntools::compactPDF() gets more compression (usually a little,\nsometimes a lot) by using the compressed object streams of PDF 1.5.\ncairo_ps(onefile = TRUE) generates encapsulated EPS on platforms\nwith cairo >= 1.6.\nBinary reads (e.g. by readChar() and readBin()) are now\nsupported on clipboard connections. (Wish of PR#14593.)\nas.POSIXlt.factor() now passes ... to the character method\n(suggestion of Joshua Ulrich). [Intended for R 2.13.0 but\naccidentally removed before release.]\nvector() and its wrappers such as integer() and double() now\nwarn if called with a length argument of more than one element.\nThis helps track down user errors such as calling double(x)\ninstead of as.double(x).\n\n\nINSTALLATION\nBuilding the vignette PDFs in packages grid and utils is now\npart of running make from an SVN checkout on a Unix-alike: a\nseparate make vignettes step is no longer required.\nThese vignettes are now made with keep.source = TRUE and hence\nwill be laid out differently.\nmake install-strip failed under some configuration options.\nPackages can customize non-standard installation of compiled code\nvia a src/install.libs.R script. This allows packages that have\narchitecture-specific binaries (beyond the package’s shared\nobjects/DLLs) to be installed in a multi-architecture setting.\n\n\nSWEAVE & VIGNETTES\nSweave() and Stangle() gain an encoding argument to specify\nthe encoding of the vignette sources if the latter do not contain a\n\\\\usepackage[]{inputenc} statement specifying a single input\nencoding.\nThere is a new Sweave option figs.only = TRUE to run each figure\nchunk only for each selected graphics device, and not first using\nthe default graphics device. This will become the default in R\n2.14.0.\nSweave custom graphics devices can have a custom function\nfoo.off() to shut them down.\nWarnings are issued when non-portable filenames are found for\ngraphics files (and chunks if split = TRUE). Portable names are\nregarded as alphanumeric plus hyphen, underscore, plus and hash\n(periods cause problems with recognizing file extensions).\nThe Rtangle() driver has a new option show.line.nos which is by\ndefault false; if true it annotates code chunks with a comment\ngiving the line number of the first line in the sources (the\nbehaviour of R >= 2.12.0).\nPackage installation tangles the vignette sources: this step now\nconverts the vignette sources from the vignette/package encoding to\nthe current encoding, and records the encoding (if not ASCII) in a\ncomment line at the top of the installed .R file.\n\n\nLICENCE\nNo parts of R are now licensed solely under GPL-2. The licences for\npackages rpart and survival have been changed, which means that\nthe licence terms for R as distributed are GPL-2 | GPL-3.\n\n\nDEPRECATED AND DEFUNCT\nThe internal functions .readRDS() and .saveRDS() are now\ndeprecated in favour of the public functions readRDS() and\nsaveRDS() introduced in R 2.13.0.\nSwitching off lazy-loading of code via the LazyLoad field of the\nDESCRIPTION file is now deprecated. In future all packages will be\nlazy-loaded.\nThe off-line help() types \"postscript\" and \"ps\" are\ndeprecated.\n\n\nUTILITIES\nR CMD check on a multi-architecture installation now skips the\nuser’s .Renviron file for the architecture-specific tests (which\ndo read the architecture-specific Renviron.site files). This is\nconsistent with single-architecture checks, which use –no-environ.\nR CMD build now looks for DESCRIPTION fields BuildResaveData\nand BuildKeepEmpty for per-package overrides. See ‘Writing R\nExtensions’.\n\n\nBUG FIXES\nplot.lm(which = 5) was intended to order factor levels in\nincreasing order of mean standardized residual. It ordered the\nfactor labels correctly, but could plot the wrong group of residuals\nagainst the label. (PR#14545)\nmosaicplot() could clip the factor labels, and could overlap them\nwith the cells if a non-default value of cex.axis was used.\n(Related to PR#14550.)\ndataframe[[row,col]] now dispatches on [[ methods for the\nselected column. (Spotted by Bill Dunlap).\nsort.int() would strip the class of an object, but leave its\nobject bit set. (Reported by Bill Dunlap.)\npbirthday() and qbirthday() did not implement the algorithm\nexactly as given in their reference and so were unnecessarily\ninaccurate.\npbirthday() now solves the approximate formula analytically rather\nthan using uniroot() on a discontinuous function.\nThe description of the problem was inaccurate: the probability is a\ntail probablity (‘2 or more people share a birthday’)\nComplex arithmetic sometimes warned incorrectly about producing NAs\nwhen there were NaNs in the input.\nseek(origin = \"current\") incorrectly reported it was not\nimplemented for a gzfile() connection.\nc(), unlist(), cbind() and rbind() could silently overflow\nthe maximum vector length and cause a segfault. (PR#14571)\nThe fonts argument to X11(type = \"Xlib\") was being ignored.\nReading (e.g. with readBin()) from a raw connection was not\nadvancing the pointer, so successive reads would read the same\nvalue. (Spotted by Bill Dunlap.)\nParsed text containing embedded newlines was printed incorrectly by\nas.character.srcref(). (Reported by Hadley Wickham.)\ndecompose() used with a series of a non-integer number of periods\nreturned a seasonal component shorter than the original series.\n(Reported by Rob Hyndman.)\nfields = list() failed for setRefClass(). (Reported by Michael\nLawrence.)\nReference classes could not redefine an inherited field which had\nclass \"ANY\". (Reported by Janko Thyson.)\nMethods that override previously loaded versions will now be\ninstalled and called. (Reported by Iago Mosqueira.)\naddmargins() called numeric(apos) rather than\nnumeric(length(apos)).\nThe HTML help search sometimes produced bad links. (PR#14608)\nCommand completion will no longer be broken if tail.default() is\nredefined by the user. (Problem reported by Henrik Bengtsson.)\nLaTeX rendering of markup in titles of help pages has been improved;\nin particular, \\\\eqn{} may be used there.\nisClass() used its own namespace as the default of the where\nargument inadvertently.\nRd conversion to latex mis-handled multi-line titles (including\ncases where there was a blank line in the \\bsl{}title section).\n(It seems this happened only in 2.13.0 patched.)\npostscript() with an sRGB colormodel now uses sRGB for raster\nimages (in R 2.13.[01] it used uncalibrated RGB).\nThere is no longer an undocumented 21845-pixel limit on raster\nimages.\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2011-2-r-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2011-2 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2011-12-01",
    "categories": [],
    "contents": "\n1 Donations and new members\nDonations\nGeoffrey S Hubona, The Georgia R School, USA\nPackt Publishing Limited, UK\nNew supporting members\nPhilippe Bartil Lecavalier, Canada\nBernhard Lehnert, Germany\nJoshua Wiley, USA\nThomas Zumbrunn, Switzerland\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2011-2-user/",
    "title": "Conference Report: useR! 2011",
    "description": "The 'Conference Report: useR! 2011' article from the 2011-2 issue.",
    "author": [
      {
        "name": "Heather Turner",
        "url": {}
      }
    ],
    "date": "2011-12-01",
    "categories": [],
    "contents": "\n\nThe seventh international R user conference, useR! 2011, took place at\nthe University of Warwick, Coventry, 16–18 August 2011.\nFollowing previous useR! conferences, this meeting of the R user\ncommunity aimed to provide a platform for R users to discuss and\nexchange ideas of how R can be used for statistical computation, data\nanalysis and visualization.\nThe conference attracted close to 450 participants, from 36 countries\nacross North and South America, Europe, Africa, Asia and Australasia.\nThe technical program comprised 136 regular talks, 30 lightning talks,\ntwo panel sessions, 21 regular posters and another 16 late-breaking\nposters, as well as eight invited talks. The social program consisted of\nan opening mixer, a poster reception sponsored by Revolution Analytics\nand a conference dinner sponsored by RStudio.\n1 Pre-conference Tutorials\nPrior to the conference, sixteen half-day tutorials were hrld. As in\nprevious years, these tutorials were extremely popular, with 167\nparticipants attending one or more of the following courses:\nDouglas Bates: Fitting and evaluating mixed models using\nlme4.\nRoger Bivand and Edzer Pebesma: Handling and analyzing\nspatio-temporal data in R.\nMarine Cadoret and Sébastien Lê: Analysing categorical data in R.\nStephen Eglen: Emacs Speaks Statistics.\nAndrea Foulkes: High-dimensional data methods with R.\nFrank E Harrell Jr: Regression modeling strategies using the R\npackage rms.\nSøren Højsgaard: Graphical models and Bayesian networks with R.\nG. Jay Kerns: Introductory probability and statistics using R.\nMax Kuhn: Predictive modeling with R and the\ncaret package.\nFausto Molinari, Enrico Branca, Francesco De Filippo and Rocco\nClaudio Cannizzaro: R-Adamant: Applied financial analysis & risk\nmanagement.\nMartin Morgan: Bioconductor for the analysis of high-throughput\ngenomic data.\nPaul Murrell: Introduction to grid graphics.\nGiovanni Petris: State space models in R.\nKarline Soetaert and Thomas Petzoldt: Simulating differential\nequation models in R.\nAntony Unwin: Graphical data analysis.\nBrandon Whitcher, Polzehl, Karsten Tabelow: Medical image analysis\nfor MRI.\n2 Invited Talks\nThe invited talks provided a focus point for the conference, where the\nparticipants gathered to hear from distinguished R users/developers. The\nlogistical constraint of having to divide into two rooms, one with the\nspeaker and one with a video link, seemed to pose little inconvenience\nto participants and overall there was a positive response to the\nfollowing talks:\nAdrian Bowman: Modelling Three-dimensional Surfaces in R.\nLee Edlefsen: High Performance Computing in R.\nUlrike : Design of Experiments in R.\nWolfgang Huber: From Genomes to Phenotypes.\nBrian Ripley: The R Development Process.\nJonathan Rougier: Nomograms for visualising relationships between\nthree variables.\nSimon Urbanek: R Graphics: Supercharged - Recent Advances in\nVisualization and Analysis of Large Data in R.\nBrandon Whitcher: Quantitative Analysis of Medical Imaging Data in\n\n\n3 User-contributed Sessions\nThe themes of this year’s Focus sessions were as follows:\nComputational Physics and Chemometrics\nData Management\nData Mining\nDevelopment of R\nDimensionality Reduction and Variable Selection\nEcology and Ecological Modelling\nFinance\nGenomics and Bioinformatics\nHigh Performance Computing\nHydrology and Soil Science\nInference\nInterfaces\nModelling Systems and Networks\nMultivariate Data\nNeuroscience\nOfficial and Social Statistics\nPopulation Genetics\nProcess Optimization\nProgramming\nPsychometrics\nStatistical Modelling\nReporting Technologies and Workflows\nR in the Business World\nSpatio-Temporal Statistics\nTeaching\nVisualisation and Graphics\nThese themes were also represented in the poster session and in the\nseven kaleidoscope sessions that presented talks particularly suitable\nfor a wider audience.\nA new feature of the useR! 2011 conference was the opportunity for\nparticipants to give a Lightning Talk, a 5-minute presentation on any\nR-related topic aimed particularly at those new to R. This resulted in\nthree highly enjoyable sessions on the themes:\n\nCommunity and Communication\nStatistics and Programming\nPackage Showcase\n\nParticipants seemed to appreciate this fast-paced introduction to a wide\nrange of topics and it provided lots of scope for discussion as we moved\non to dinner and the evening poster reception.\n4 Organisers\nMany thanks go to this year’s program committee:\n\nRamón Díaz-Uriarte, John Fox, Romain François, Robert Gramacy, Paul\nHewson, Torsten Hothorn, Kate Mullen, Brian Peterson, Thomas Petzoldt,\nAnthony Rossini, Barry Rowlingson, Carolin Strobl, Stefan Theussl,\nHeather Turner, Hadley Wickham and Achim Zeileis.\n\nand also the local organisers:\n\nJohn Aston, Julia Brettschneider, David Firth, Ashley Ford, Ioannis\nKosmidis, Tom Nichols, Elke and Heather Turner.\n\n5 Further Information\nThe useR! 2011 website, http://www.R-project.org/useR-2011/ provides\na record of the conference. Where authors have made them available,\nslides are accessible via the online conference schedule. In addition\nvideos of several of the invited talks have been put on the R-bloggers\nwebsite: http://www.r-bloggers.com/RUG/category/user-conference/.\n\n\nCRAN packages used\nlme4, rms, caret\nCRAN Task Views implied by cited packages\nEconometrics, Environmetrics, HighPerformanceComputing, MachineLearning, MixedModels, Psychometrics, ReproducibleResearch, SpatioTemporal, Survival\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2011-1-bioconductor/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2011-1 issue.",
    "author": [
      {
        "name": "Bioconductor Team",
        "url": {}
      }
    ],
    "date": "2011-06-01",
    "categories": [],
    "contents": "\n\nWe are pleased to announce Bioconductor 2.8, released on 14 April 2011.\nBioconductor 2.8 is compatible with R 2.13.0, and consists of 467\nsoftware packages and more than 500 up-to-date annotation packages.\nThere are 49 new software packages, and enhancements to many others.\nExplore Bioconductor at http://bioconductor.org, and install packages\nwith\n> source(\"http://bioconductor.org/biocLite.R\")\n> biocLite() # install standard packages...\n> biocLite(\"IRanges\") # ...or only IRanges\nA Bioconductor machine instance for use with Amazon’s cloud service is\navailable; see http://bioconductor.org/help/bioconductor-cloud-ami.\n1 New and revised packages\nThis release includes new packages for diverse areas of high-throughput\nanalysis. Highlights include:\nNext-generation sequencing:\n\nArrayExpressHTS\n(RNA-seq),\nmosaics\n(ChIP-seq),\nRsubread\n(alignment),\nqrqc,\nseqbias,\nTEQC\n(quality assessment),\nclst,\nclstutils\n(taxonomic placement).\n\nSNPs and small variants:\n\ninveRsion,\nchopsticks,\nsnpStats.\n\nFlow cytometry and proteomics:\n\nflowPhyto,\nflowPlots.\nIPPD,\nMSnbase,\nprocoil.\n\nMicroarray:\n\nThe\na4\ncollection of packages,\nExiMiR,\npvac,\nsnm,\nTurboNorm.\n\nCopy number variation:\n\ncn.farms,\ngenoset,\nVega.\n\nAdvanced statistical implementations:\n\nanota,\nClonality,\nclusterProfiler,\ngaia,\ngenefu,\nGSVA,\nibh,\njoda,\nlol,\nmgsa,\nMLP,\nphenoDist,\nphenoTest,\nRNAinteract,\nsurvcomp,\nTDARACNE.\n\nAnnotation and visualization:\n\nAnnotationFuncs,\nNCIgraph,\nENVISIONQuery,\nmcaGUI.\n\nOur large collection of microarray- and organism-specific annotation\npackages have, as usual, been updated to include current information.\nDevelopments in the\nGenomicFeatures\npackage allow users to retrieve and easily save annotation tracks found\nat the UCSC genome browser. This provides easy access to diverse\ninformation about, e.g., binding factor locations or nucleosome\npositions, and complements known gene annotations already available as\nTranscriptDb objects.\nFurther information on new and existing packages can be found on the\nBioconductor web site; ‘BiocViews’ identify coherent groups of packages,\nwith links to package descriptions, vignettes, reference manuals, and\nuse statistics.\n2 Other activities\nThe Bioconductor community meets on July 27-29 at our annual conference\n(https://secure.bioconductor.org/BioC2011) in Seattle for a\ncombination of scientific talks and hands-on tutorials; a developer\nmeeting in the late fall will highlight contributions from the European\ndeveloper community. The active Bioconductor mailing lists\n(http://bioconductor.org/help/mailing-list/) connect users with each\nother, to domain experts, and to maintainers eager to ensure that their\npackages satisfy the needs of leading edge approaches. Bioconductor\npackage maintainers and the Bioconductor team invest considerable effort\nin producing high-quality software. The Bioconductor team continues to\nensure quality software through technical and scientific reviews of new\npackages, and daily builds of released packages on Linux, Windows, and\nMacOS platforms.\n3 Looking forward\nContributions from the Bioconductor community shape each release; we are\nseeing a tremendous number of new contributed packages addressing\nsequence, advanced microarray, and other diverse areas of\nhigh-throughput genomic analysis.\nSequence analysis continues to pose significant statistical and\ncomputational challenges, although remarkable progress is being made\nboth in the Bioconductor community and more generally. The next release\nwill see contributions enabling common data management (e.g.,\nefficiently querying very large sequence alignments), representation\n(e.g., of gapped alignments and small variants), and work flow (e.g.,\nRNA-seq read counts and estimation) tasks.\nImportant developments in the annotation domain include efforts to\nenhance reproducibility by providing transcript annotation packages, and\nthe ability to easily generate packages for non-model organisms. New\nefforts are also under way to better use existing and new annotation\nresources to help users with common tasks in next-generation sequence\nwork flows, for instance immediately identifying whether single\nnucleotide and other small variants disrupt protein production.\n\n\nBioconductor packages used\nArrayExpressHTS, mosaics, Rsubread, qrqc, seqbias, TEQC, clst, clstutils, inveRsion, chopsticks, snpStats, flowPhyto, flowPlots, IPPD, MSnbase, procoil, a4, ExiMiR, pvac, snm, TurboNorm, cn.farms, genoset, Vega, anota, Clonality, clusterProfiler, gaia, genefu, GSVA, ibh, joda, lol, mgsa, MLP, phenoDist, phenoTest, RNAinteract, survcomp, TDARACNE, AnnotationFuncs, NCIgraph, ENVISIONQuery, mcaGUI, GenomicFeatures\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2011-1-book-review/",
    "title": "Book Review : Forest Analytics with R (Use R)",
    "description": "Book Info : Forest Analytics with R (Use R) by Andrew R. [Robinson]{.smallcaps} and Jeff D. [Hamann]{.smallcaps}. Berlin: Springer, 2011. ISBN 978-1-4419-7761-8. xv + 339 pp. €57.99 (paperback).",
    "author": [
      {
        "name": "Carsten F. Dormann",
        "url": {}
      }
    ],
    "date": "2011-06-01",
    "categories": [],
    "contents": "\n\nForestry is a broad field touching economical management as well as\nlandscape planning, survey design/analysis, spatial statistics, growth\nsimulations and much more. Accordingly, also the topics related to\nstatistical computing (and hence R) cover a lot of ground. The present\nbook has luckily refrained from trying to cover all possible aspects,\nwhile at the same time still being surprisingly comprehensive. It aims\nat forest scientists, managers, researchers and students, who have\nlittle experience with R.\nThe book is organised in four parts. Part I, Introduction and Data\nManagement, introduces R and typical forest data sets, of which several\nare provided in the companion R-package FAwR. Part II, Sampling and\nMapping, illustrates the use of the survey package to estimate mean\nand variance of typical forest survey designs. It then continues to\nbriefly sketch imputation and spatial interpolation techniques. Part\nIII, Allometry and Fitting Models, covers regression, non-linear\nregression and mixed effect models. Part IV, Simulation and\nOptimization introduce the interaction of C-code with R through two\nforest growth models and uses a question from forest planing to\nillustrate the use of linear programming for optimisation.\nThe four parts differ greatly in their style, depth and quality. Part I\ncan easily be skipped by the more experienced R-user, but offers a\nuseful and gentle introduction to general R functionality with respect\nto the following three parts. To appreciate the sampling analyses of\npart II (including, for example, simple random and systematic sampling,\ncluster and two-stage sampling), a more detailed knowledge of the\nsurvey package (Lumley 2010) and of sampling designs in general\n(e.g., Lohr 2009) is required. I found the notation for variance\nestimation somewhat unsavoury, because it deviated from both these\nbooks, as well as the book dedicated to forest sampling\n(Gregoire and H. T. Valentine 2008). Imputation and interpolation techniques receive only a\nsuperficial brush, e.g. focussing on (spatial!) nearest-neighbour\nimputation without mentioning regression-based imputation (Harrell 2001)\nat all.\nIn stark contrast, regression, non-linear and mixed models are dealt\nwith much more carefully and very competently. While the purpose of the\nbook is not to explain so much why, but how, to carry out certain\ncomputations, this section is a showcase of how to teach model\ninterpretation. Even after a decade of stats teaching I found this part\ninspiring. The key ingredient, I think, is that the authors carry a\nsingle example through different analyses. They show improvements (or\nlack thereof) compared to previous models, explain very accurately the\nmodel output and they give intuitive and rule-of-thumb guidance on which\n“knobs to turn” during analysis.\nThe final part is again rather different in style. It provides\nwalk-through examples without much explanation of why one would want to\nuse this specific forest growth model (provided through the\nrconifers package: Hamann, M. Ritchie, and the R Core team 2010) or any implementational details. The\noptimisation section using linear programming is virtually\nincomprehensible without parallel reading on the subject. This fourth\npart feels like an incomplete draft shoved in for the sake of topic\ncoverage.\nOverall, Forest Analytics with R offers an entry to several statistical\ncomputation topics encountered by forestry students and practitioners.\nThe sampling-section is sufficient for many standard designs. Only the\nregression-section is both in-depth and generic, while the simulation\nstudies are too specific to offer themselves to an easy transfer to\nother problems.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\nT. G. Gregoire and H. T. Valentine. Sampling Strategies for Natural Resources and the Environment. Chapman; Hall/CRC New York, 2008.\n\n\nJ. Hamann, M. Ritchie, and the R Core team. rconifers: Alternative Interface to the CONIFERS Forest Growth Model, . R package version 1.0.5, 2010.\n\n\nF. E. Harrell. Regression Modeling Strategies - with Applications to Linear Models, Logistic Regression, and Survival Analysis. Springer New York, 2001.\n\n\nS. L. Lohr. Sampling: Design and Analysis. Duxbury Press North Scituate Mass. 2nd edition, 2009.\n\n\nT. Lumley. Complex Surveys: A Guide to Analysis Using R. Wiley Hoboken NJ, 2010.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2011-1-Cook/",
    "title": "Tips for Presenting Your Work",
    "description": "With the international R user conference, useR! 2011, approaching, many participants may be contemplating how to put their thoughts together for presentation. This paper provides some suggestions for giving presentations and making posters.",
    "author": [
      {
        "name": "Dianne Cook",
        "url": {}
      }
    ],
    "date": "2011-06-01",
    "categories": [],
    "contents": "\n\n1 Some background\nJust after completing a practice of the talk I planned to give about my\nPhD research in several upcoming academic job interviews, my advisor,\nAndreas Buja, sat me down, and completely re-drafted my talk! I had\nproduced what I had seen many times presented by numerous speakers in\nweekly seminars at Rutgers University, slide after slide of details.\nAndreas explained that while this might be appropriate for a paper it is\nnot the best approach for a talk. We laid out the key problem that my\nwork addressed, and then put in a slide that simply said “Stay\ntuned….” The next few slides addressed the methodology, and the key\nanswers to the problem came near the end of the talk.\nThe “Stay tuned” sticks with me.\nAlthough, today this phrase might be something of a cliché, overused by\nthe electronic media to keep your attention through another barrage of\nadvertising, the effect is useful to re-create. What did this phrase do\nfor the talk at the time? It allowed it to build interest in the topic\nearly, and let the audience know they would be rewarded later. The\nmiddle of the talk also showed a VHS video of high-dimensional data\nbeing explored using various tours – computers that could display\nvideos were not so portable in 1993! (That video is now available in\nFlash format at http://stat-graphics.org/movies/grand-tour.html.)\n2 Key pointers\nThe web sites (Schoeberl and B. Toon. (2011)) and (Marle. (2007)) have some useful tips on giving\nscientific presentations. Here are a few collected from my experiences.\nIf your audience remembers and takes away one thing your talk is a\nsuccess. What is this going to be for your talk?\nMake a plan, map out the start, with motivation, middle and finish.\nSketch out the slides, and what you want to communicate with each\nslide.\nAvoid slide after slide of bullet points (the Powerpoint syndrome),\nor slide after slide of equations.\nEstablish your credentials. For a traditional audience this might be\na few equations, and the key parts to a proof. For the statistical\ncomputing and computational statistics audience show some code\nfragments – ones that may be particularly elegant, or illustrate\nthe critical pieces. (Some colleagues and I have occasionally jested\nthat watching programmer program might be more interesting than\nlistening to some talks. This is only partially in jest because\nwatching seasoned programmers tackling a computational problem can\nbe very insightful.)\nDraw the audience in with convention, a usual format, style of\nslides, font, …. Familiarity is in-groupness, shows the audience\nthat they are like you, that you are bringing them with you, and\nthat you can be trusted.\n\nbreaking the rules. Do something unexpected, too.\n\n\nKeep the audience’s attention, and curiosity, by\n\nUse pictures, that is, plots (of data). BUT, BUT, please don’t say\n“You can see from the picture that ….” without helping interpret\nwith something like “because the points follow a curved pattern”.\nThat is, explain the pattern in the graphical elements of the plot\nthat allows one to make the analytical leap.\nUse pictures, or, cartoons, to help explain concepts.\nUse pictures, for visual stimulation. Not because they “are devices\nfor showing the obvious to the ignorant” or to “prevent the dullards\nin the audience from falling asleep” (Tufte. (1990)) but because graphics\nare beautiful. Plots evoke creativity.\nTell a story.\n3 Practicalities\nMany statisticians use LaTeX, with Beamer style, to make the slides for\ntheir talk. This is convenient for equations, and makes elegant,\nbeautifully typeset slides. It has a lot of flexibility to make colored\ntext, different fonts, navigation strips, including figures and even\nanimations or movies. My preference, however, is to use keynote on the\nMac. It provides a lot more flexibility in the formatting, the ability\nto use wild fonts, such as my own handwriting, and seamless\nincorporation of movies and animations. To include equations I have a\ngeneric tmp.tex file on my computer with all the equations that I have\never used, and I cut and paste these out of the pdf from Preview.\nKeynote maintains the quality of the equations, and images, through\nresizing, unlike Powerpoint. It also, like TeX, keeps figures in\nseparate files, actually the slides.key might look like a file but is\nreally a directory.\nJust out of graduate school I would meticulously write down every word\nthat I wanted to say in association with the talk. I would practice, and\npractice, and practice, then throw the notes away to actually give the\ntalk. I still occasionally do this. Why? With a limited time frame, and\nunder the glare of my colleagues, making language precise helps get the\nmessage across, which is respectful of the audience. Making the notes\nmakes the language precise, but giving the talk without notes lends\nspontaneity.\nCheck the equipment. How does your font and the graphics appear from the\nback of the room? Does your computer work with the projector? Or does\nthe provided computer have the software that you need for your\npresentation?\nHow do you choose colors? The\ncolorspace (Ihaka, P. Murrell, K. Hornik, A. Zeleis. (2011))\npackage in R provides are reasonable selection of color palettes for\nplots, more specifically applied to statistical graphics than Cynthia\nBrewer’s map work in the\nRColorBrewer\npackage (Neuwirth. (2011)). Several web sites (Dougherty and A. Wade. (2011); Etre Limited. (2011)) provide\ntools to help color blind proof your work.\n(Robbins. (2006)) is a basic guide to good graphics. The R package ggplot2\n(Wickham. (2009)) has elegant and cognitively perceptive plot defaults.\n4 Not a talk, a poster!\nSlides from a 2007 Joint Statistical Meetings Introductory Overview\nLecture (Cook. (2007)) give guidelines for constructing a poster. Posters\nallow the presenter to engage the audience in small group individualized\ndiscussion. But in order to engage a small audience you need to attract\nthe attention of passers-by. Designing your poster with a visual focal\npoint that can be seen from several feet away will draw people to your\nwork.\nSome of the key recommendations in this lecture are:\nPlan the layout and flow of the poster.\nAs with a talk, decide on the main message, and determine who is\nyour audience.\nChoose your color scheme, keeping in mind color blindness\nlimitations, readability, and avoid color combinations that have\nsubliminal meanings, e.g. red, yellow and black of the German flag.\nChoose your text size and font. Titles should be about 100pt font,\nheadings 50pt and text in the body at least 25pt. Avoid all\ncapitals.\nData plots make good focal points. A contextual image can help the\nvisitors grasp the context of the data quickly, and provide people\nwith something familiar to draw their attention. Good quality\ngraphics are important, generated by R software for example.\nA movie, or audio recording, can help draw the attention of\npassers-by. These should not be substitutes for engaging the\naudience in discussion.\nRemember that there are lots of bad examples of posters at Statistics\nmeetings. The excuse of “this is how everyone else does their poster” is\nnot a reasonable justification for perpetuating poor scholarship. Each\ngeneration is held to higher and higher standards as we develop our\nunderstanding about good practices. Excellent advice on producing\nposters can be found at the web site by Cape Higher Education Consortium. (2011). Also the web site by\nPurrington. (2011) has some useful discussion about designing scientific\nposters. The Data Expo competitions (American Statistical Association. (2011)) run in conjunction with the\nJoint Statistical Meetings often have examples of good posters, and\nexamples of previous useR! posters can be found via\nhttp://www.r-project.org/conferences.html.\n5 Responsible audience?\nOccasionally, well maybe, more than occasionally, I hear some members of\nour profession extolling the virtues of a talk – but it is clear they\ndidn’t have a clue what the talk was about. There is a responsibility of\nthe audience to not be impressed because they are snowballed by a\nspeaker. The audience has a right to expect the speaker to make the work\nclear, and easier to understand, and to do some of the work of\ndeciphering the material for them.\n6 Last words\nBe mindful, that giving a talk in front of peers is a privilege – not\nmany people in this world have the opportunity to speak their mind and\nbe listened to, particularly in a prominent setting such as useR!.\nMany people enthuse about a TED talk (Rosling. (2006)). I’ve recently been\npointed to another by Chris Wild. (2009) which is a marvellous statistical\npresentation.\n\n\n\nCRAN packages used\ncolorspace, RColorBrewer\nCRAN Task Views implied by cited packages\nSpatial\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\nAmerican Statistical Association. (2011). Data Expo Posters.URL http://stat-computing.org/dataexpo/.\n\n\nCape Higher Education Consortium. (2011). Information Literacy.URL http://www.lib.uct.ac.za/infolit/poster.htm.\n\n\nD. Cook. (2007). Improving Statistical Posters.URL http://www.amstat.org/meetings/jsm/2008/pdfs/ImprovingStatisticalPosters.pdf.\n\n\nB. Dougherty and A. Wade. (2011). URL http://www.vischeck.com/vischeck/.\n\n\nEtre Limited. (2011). URL http://www.etre.com/tools/colourblindsimulator/.\n\n\nR. Ihaka, P. Murrell, K. Hornik, A. Zeleis. (2011). colorspace: Color Space Manipulation.URL http://cran.r-project.org.\n\n\nA. J. van Marle. (2007). The Art of Scientific Presentations.  scranmer/vanmarle_talks.html#Technical_preparation, URL https://www.cfa.harvard.edu/.\n\n\nE. Neuwirth. (2011). RColorBrewer: ColorBrewer palettes.URL http://cran.r-project.org.\n\n\nC. Purrington. (2011). Advice on Designing Scientific Posters.URL http://www.swarthmore.edu/NatSci/cpurrin1/posteradvice.htm.\n\n\nN. Robbins. (2006). Creating More Effective Graphs.URL http://www.wiley.com.\n\n\nH. Rosling. (2006). GapMinder.URL http://www.ted.com/talks/lang/eng/hans_rosling_shows_the_best_stats_you_ve_ever_seen.html.\n\n\nM. Schoeberl and B. Toon. (2011). Ten Secrets to Giving a Good Scientific Talk.URL http://www.cgd.ucar.edu/cms/agu/scientific_talk.html.\n\n\nE. Tufte. (1990). The Visual Display of Quantitative Information. Graphics Press Cheshire CT,\n\n\nH. Wickham. (2009). ggplot2: Elegant graphics for data analysis. useR Springer,\n\n\nC. Wild. (2009). Early Statistical Inferences: The Eyes Have It.  wild/09.wild.USCOTS.html, URL http://www.stat.auckland.ac.nz/.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2011-1-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2011-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2011-06-01",
    "categories": [],
    "contents": "\n\n1 New packages in CRAN task views\nBayesian\n\nBLR, BMS, BaBooN, BayesDA, BayesX, Bmix,\nLaplacesDemon, SampleSizeMeans, SampleSizeProportions, abc,\nbayespack, bbemkr, bclust, bfp, bisoreg, bnlearn,\ncatnet, cudaBayesreg, dclone, ebdbNet, factorQR,\ngausspred, mlogitBMA, mombf, predbayescor, predmixcor,\nrWMBAT, sbgcop, spikeSlabGAM, varSelectIP.\n\nChemPhys\n\nChemoSpec, ChemometricsWithR, ChemometricsWithRData.\n\nCluster\n\nHDclassif, MOCCA, MetabolAnalyze, SDisc, clusterCons,\ndpmixsim, edci, fastcluster, isa2, isopam, kernlab,\nkml, kml3d, lcmm, mixsmsn, movMF, optpart, pdfCluster,\nprofdpm, sigclust, sparcl.\n\nDistributions\n\nCompQuadForm, FAdist, GB2, GeneralizedHyperbolic, HI,\nPearsonDS\\(^*\\), RMTstat, SkewHyperbolic, distrEllipse, emg,\ngaussDiff, hyperdirichlet, loglognorm, mgpd, movMF,\nmvtBinaryEP, poibin, poilog, poistweedie, reliaR\\(^*\\),\nskellam, spd, stabledist, trapezoid.\n\nEconometrics\n\napt, censReg, erer, ordinal.\n\nEnvironmetrics\n\ndiveMove, wq.\n\nFinance\n\nRTAQ.\n\nHighPerformanceComputing\n\nRInside, doSMP.\n\nMachineLearning\n\nCORElearn, Cubist, ahaz, ncvreg, rminer.\n\nOptimization\n\nRcppDE, alabama, cmaes, dclone, neldermead, pso,\nrneos, soma.\n\nPhylogenetics\n\nPHYLOGR, RBrownie, TreePar, diversitree.\n\nPsychometrics\n\nirtoys, mpt, qgraph, semPLS.\n\nSpatial\n\nGeneland, adehabitatHR, adehabitatHS, adehabitatLT,\nadehabitatMA, gdistance, rgeos.\n\nSurvival\n\nBiograph, NADA, PermAlgo, bujar, compeir, concreg,\ncrrSC, frailtyHL, globalboosttest, msSurv, plsRcox,\npowerSurvEpi, risksetROC, survAUC, survJamda, survivalBIV.\n\nTimeSeries\n\nFitARMA, Rssa, egarch, fastVAR, lubridate, season.\n\n(* = core package)\n2 New contributed packages\nADM3\n\nAn interpretation of the ADM method — automated detection\nalgorithm. Author: Tomas William Fitzgerald.\n\nAgreement\n\nStatistical Tools for Measuring Agreement. Author: Yue Yu and\nLawrence Lin.\n\nAnnotLists\n\nData extraction tool from annotations files. Author: Nicolas\nCagnard.\n\nBCA\n\nBusiness and Customer Analytics. Author: Dan Putler.\n\nBaBooN\n\nBayesian Bootstrap Predictive Mean Matching — Multiple and single\nimputation for discrete data. Author: Florian Meinfelder. In view:\nBayesian.\n\nBessel\n\nBessel Functions Computations and Approximations. Author: Martin\nMaechler.\n\nBiGGR\n\nCreates an interface to BiGG database, provides a framework for\nsimulation and produces flux graphs. Author: Anand K. Gavai.\n\nBioMark\n\nFind biomarkers in two-class discrimination problems. Authors: Ron\nWehrens and Pietro Franceschi.\n\nBiograph\n\nExplore life histories. Author: Frans Willekens. In view:\nSurvival.\n\nCCM\n\nCorrelation classification method (CCM). Authors: Garrett M. Dancik\nand Yuanbin Ru.\n\nCDVine\n\nStatistical inference of C- and D-vine copulas. Authors: Ulf\nSchepsmeier and Eike Christian Brechmann.\n\nCGene\n\nCausal Genetic Analysis. Author: Peter Lipman.\n\nCITAN\n\nCITation ANalysis toolpack. Author: Marek Gagolewski.\n\nCRTSize\n\nSample Size Estimation Functions for Cluster Randomized Trials.\nAuthor: Michael A Rotondi.\n\nChemoSpec\n\nExploratory Chemometrics for Spectroscopy. Authors: Bryan A. Hanson\nDePauw University, Greencastle Indiana USA. In view:\nChemPhys.\n\nChemometricsWithR\n\nChemometrics with R — Multivariate Data Analysis in the Natural\nSciences and Life Sciences. Author: Ron Wehrens. In view:\nChemPhys.\n\nChemometricsWithRData\n\nData for package ChemometricsWithR. Author: Ron Wehrens. In view:\nChemPhys.\n\nCommonJavaJars\n\nUseful libraries for building a Java based GUI under R. Author:\nKornelius Rohmeyer.\n\nCompareTests\n\nEstimate diagnostic accuracy (sensitivity, specificity, etc) and\nagreement statistics when one test is conducted on only a subsample\nof specimens. Authors: Hormuzd A. Katki and David W. Edelstein.\n\nCovpath\n\nImplements a pathwise algorithm for covariance selection. Author:\nVijay Krishnamurthy.\n\nCubist\n\nRule- and Instance-Based Regression Modeling. Authors: Max Kuhn,\nSteve Weston, and Chris Keefer. C code for Cubist by R. Quinlan. In\nview:\nMachineLearning.\n\nDAGGER\n\nConsensus genetic maps. Author: Jeffrey Endelman.\n\nDALY\n\nDALY Calculator — A GUI for stochastic DALY calculation in R.\nAuthors: Brecht Devleesschauwer, Arie Havelaar, Juanita Haagsma,\nNicolas Praet, and Niko Speybroeck.\n\nDART\n\nDenoising Algorithm based on Relevance network Topology. Authors:\nYan Jiaoa and Andrew E. Teschendorff.\n\nDARTData\n\nExample data set for DART package. Author: Yan Jiao.\n\nDBGSA\n\nMethods of distance-based gene set functional enrichment analysis.\nAuthors: Li Jin and Huang Meilin.\n\nDIME\n\nDifferential Identification using Mixture Ensemble. Author: Cenny\nTaslim, with contributions from Dustin Potter, Abbasali Khalili, and\nShili Lin.\n\nDOBAD\n\nAnalysis of Discretely Observed linear\nBirth-And-Death(-and-immigration) Markov Chains. Author: Charles\nDoss.\n\nDeducerMMR\n\nA Deducer plugin for moderated multiple regressions and simple\nslopes analysis. Authors: Alberto Mirisola, Luciano Seta, Manuel\nGentile, and Dario La Guardia.\n\nENmisc\n\nNeuwirth miscellaneous. Author: Erich Neuwirth.\n\nESPRESSO\n\nPower Analysis and Sample Size Calculation. Authors: Amadou Gaye and\nPaul Burton.\n\nEuclideanMaps\n\nDisplays Euclidean Maps. Author: Elisa Frutos Bernal.\n\nFAdist\n\nDistributions that are sometimes used in hydrology. Author: François\nAucoin. In view:\nDistributions.\n\nFAmle\n\nMaximum Likelihood and Bayesian Estimation of Univariate Probability\nDistributions. Author: François Aucoin.\n\nFRBData\n\nDownload financial data from FRB’s website. Author: Shinichi\nTakayanagi.\n\nFisherEM\n\nModel-Based Clustering in the Fisher Discriminative Subspace.\nAuthors: J. Loisel, T. Souvannarath, M. Tchebanenko, C. Bouveyron,\nand C. Brunet.\n\nFuncMap\n\nHive Plots of R Package Function Calls. Author: Bryan A. Hanson.\n\nGA4Stratification\n\nA genetic algorithm approach to determine stratum boundaries and\nsample sizes of each stratum in stratified sampling. Authors: Sebnem\nEr, Timur Keskinturk, and Charlie Daly.\n\nGANPA\n\nGene Association Network-based Pathway Analysis. Authors: Zhaoyuan\nFang, Weidong Tian, and Hongbin Ji.\n\nGANPAdata\n\nThe GANPA Datasets Package. Authors: Zhaoyuan Fang, Weidong Tian,\nand Hongbin Ji.\n\nGB2\n\nGeneralized Beta Distribution of the Second Kind: properties,\nlikelihood, estimation. Authors: Monique Graf and Desislava\nNedyalkova. In view:\nDistributions.\n\nGenSA\n\nR functions for Generalized Simulated Annealing. Authors: Sylvain\nGubian, Yang Xiang, Brian Suomela, and Julia Hoeng.\n\nGrapheR\n\nA multiplatform GUI for drawing customizable graphs in R. Author:\nMaxime Hervé.\n\nGriegSmith\n\nUses Grieg-Smith method on 2 dimensional spatial data. Author: Brian\nMcGuire.\n\nHLMdiag\n\nDiagnostic tools for two-level normal hierarchical linear models.\nAuthor: Adam Loy.\n\nHPbayes\n\nHeligman Pollard mortality model parameter estimation using Bayesian\nMelding with Incremental Mixture Importance Sampling. Author: David\nJ Sharrow.\n\nHSROC\n\nJoint meta-analysis of diagnostic test sensitivity and specificity\nwith or without a gold standard reference test. Authors: Ian\nSchiller and Nandini Dendukuri.\n\nHiDimDA\n\nHigh Dimensional Discriminant Analysis. Author: António Pedro Duarte\nSilva.\n\nICC\n\nFunctions facilitating the estimation of the Intraclass Correlation\nCoefficient. Author: Matthew Wolak.\n\nIQMNMR\n\nIdentification and Quantification of Metabolites by Using 1D 1H NMR\nFID. Author: XuSong.\n\nImageMetrics\n\nFacilitates image analysis for social scientists. Author: Solomon\nMessing.\n\nIndependenceTests\n\nNonparametric tests of independence between random vectors. Authors:\nP Lafaye de Micheaux and M Bilodeau.\n\nInfDim\n\nInfine-dimensional model (IDM) to analyse phenotypic variation in\ngrowth trajectories. Authors: Anna Kuparinen and Mats\n\nInterpol\n\nInterpolation of amino acid sequences. Author: Dominik Heider.\n\nIsotopeR\n\nEstimates diet contributions from isotopic sources using JAGS.\nAuthors: Jack Hopkins and Jake Ferguson.\n\nJohnson\n\nJohnson Transformation. Author: Edgar Santos Fernandez.\n\nJulia\n\nFractal Image Data Generator. Author: Mehmet Suzen.\n\nKrigInv\n\nKriging-based Inversion for Deterministic and Noisy Computer\nExperiments. Authors: Victor Picheny and David Ginsbourger.\n\nKsPlot\n\nCheck the power of a statistical model. Author: Issei Kurahashi.\n\nLCAextend\n\nLatent Class Analysis (LCA) with familial dependence in extended\npedigrees. Authors: Arafat Tayeb, Alexandre Bureau, and Aurelie\nLabbe.\n\nLaplacesDemon\n\nSoftware for Bayesian Inference. Author: Byron Hall. In view:\nBayesian.\n\nLeLogicielR\n\nFunctions and datasets to accompany the book “Le logiciel R:\nMaîtriser le langage, Effectuer des analyses statistiques” (in\nFrench). Authors: Lafaye de Micheaux Pierre, Drouilhet Rémy, and\nLiquet Benoit.\n\nMALDIquant\n\nQuantitative analysis of MALDI-TOF MS data. Author: Sebastian Gibb.\n\nMAPLES\n\nSmoothed age profile estimation. Author: Roberto Impicciatore.\n\nMAT\n\nMultidimensional Adaptive Testing (MAT). Author: Seung W. Choi.\n\nMDR\n\nDetect gene-gene interactions using multifactor dimensionality\nreduction. Author: Stacey Winham.\n\nMEWMA\n\nMultivariate Exponentially Weighted Moving Average (MEWMA) Control\nChart. Author: Edgar Santos Fernandez.\n\nMHadaptive\n\nGeneral Markov Chain Monte Carlo for Bayesian Inference using\nadaptive Metropolis-Hastings sampling. Author: Corey Chivers.\n\nMISA\n\nBayesian Model Search and Multilevel Inference for SNP Association\nStudies. Author: Melanie Wilson.\n\nMLPAstats\n\nMLPA analysis to detect gains and loses in genes. Authors: Alejandro\nCáceres and Juan R González.\n\nMSG\n\nData and functions for the book “Modern Statistical Graphics”.\nAuthor: Yihui Xie.\n\nMUCflights\n\nMunich Franz-Josef-Strauss Airport Pattern Analysis. Authors: The\nstudents of the “Advanced R Programming Course”: Basil Abou\nEl-Komboz, Andreas Bender, Abdelilah El Hadad, Laura Roman Hornung,\nMax Hughes-Brandl, Christian Lindenlaub, Christina Riedel, Ariane\nStraub, Florian Wickler, under the supervision of Manuel Eugster and\nTorsten Hothorn.\n\nMVA\n\nAn Introduction to Applied Multivariate Analysis with R. Authors:\nBrian S. Everitt and Torsten Hothorn.\n\nMetABEL\n\nMeta-analysis of genome-wide SNP association results. Authors:\nMaksim Struchalin and Yurii Aulchenko.\n\nMetaPCA\n\nMeta-analysis in the Dimension Reduction of Genomic data. Author:\nDon Kang.\n\nMetaQC\n\nQuantitative Quality Assessment for Inclusion/Exclusion Criteria of\nGenomic Meta-Analysis. Author: Don Kang.\n\nMeth27QC\n\nSample quality analysis and sample control analysis. Authors: Ling\nTeng, Chao Chen, and Chunyu Liu.\n\nMethComp\n\nFunctions for analysis of method comparison studies. Authors: Bendix\nCarstensen and Lyle Gurrin.\n\nMiney\n\nImplementation of the Well-Known Game to Clear Bombs from a Given\nField (Matrix). Author: Roland Rau.\n\nNBPSeq\n\nThe NBP Negative Binomial Model for Assessing Differential Gene\nExpression from RNA-Seq. Authors: Yanming Di and Daniel W. Schafer,\nwith contributions from Jason S. Cumbie and Jeff H. Chang.\n\nNightDay\n\nNight and Day Boundary Plot Funtion. Author: Max Hughes-Brandl.\n\nNippon\n\nJapanese utility functions and data. Author: Susumu Tanimura.\n\nPBImisc\n\nA set of datasets used in my classes or in the book “Modele liniowe\ni mieszane w R, wraz z przykładami w analizie danych”. Author:\nPrzemysław Biecek.\n\nPL.popN\n\nPopulation Size Estimation. Author: Jakub Stoklosa.\n\nPSCN\n\nParent Specific DNA Copy Number Estimation. Authors: Hao Chen,\nHaipeng Xing, and Nancy R. Zhang.\n\nPeak2Trough\n\nEstimation of the peak-to-trough ratio of a seasonal variation\ncomponent. Author: Anette Luther Christensen.\n\nPoissonSeq\n\nSignificance analysis of sequencing data based on a Poisson log\nlinear model. Author: Jun Li.\n\nPottsUtils\n\nUtility Functions of the Potts Models. Author: Dai Feng.\n\nPredictABEL\n\nAssessment of risk prediction models. Authors: Suman Kundu, Yurii S.\nAulchenko, A. Cecile, and J.W. Janssens.\n\nProfileLikelihood\n\nProfile Likelihood for a Parameter in Commonly Used Statistical\nModels. Author: Leena Choi.\n\nQTLRel\n\nTools for mapping of quantitative traits of genetically related\nindividuals and calculating identity coefficients from a pedigree.\nAuthor: Riyan Cheng.\n\nR2SWF\n\nConvert R Graphics to Flash Animations. Authors: Yixuan Qiu and\nYihui Xie.\n\nRAD\n\nFit RAD models to biological data. Authors: Piers K Dunstan and\nScott D Foster.\n\nRAtmosphere\n\nStandard Atmosperic profiles. Author: Gionata Biavati.\n\nRISmed\n\nSearch Pubmed, Make bibliographic content analyzable. Author: S. A.\nKovalchik.\n\nRMark\n\nR Code for MARK Analysis. Author: Jeff Laake.\n\nRMediation\n\nMediation Analysis. Authors: Davood Tofighi and David P. MacKinnon.\n\nRNCEP\n\nObtain, organize, and visualize NCEP weather data. Authors:\nMichael U. Kemp, with contributions from E. Emiel van Loon, Judy\nShamoun-Baranes, and Willem Bouten.\n\nROAuth\n\nR interface to liboauth. Author: Jeff Gentry.\n\nROCwoGS\n\nNon-parametric estimation of ROC curves without Gold Standard Test.\nAuthor: Chong Wang.\n\nRStackExchange\n\nR based StackExchange client. Author: Jeff Gentry.\n\nRTAQ\n\nTools for the analysis of trades and quotes in R. Authors: Kris\nBoudt and Jonathan Cornelissen. In view:\nFinance.\n\nRVAideMemoire\n\nFonctions diverses accompagnant l’ouvrage “Aide-memoire de\nstatistique appliquee a la biologie”. Author: Maxime Hervé.\n\nRXMCDA\n\nAuthors: Patrick Meyer and Sébastien Bigaret.\n\nRcmdrPlugin.BCA\n\nRcmdr Plug-In for Business and Customer Analytics. Author: Dan\nPutler.\n\nRcmdrPlugin.depthTools\n\nR commander Depth Tools Plug-In. Authors: Sara López-Pintado and\nAurora Torrente.\n\nRcppBDT\n\nRcpp bindings for the Boost Date Time library. Authors: Dirk\nEddelbuettel and Romain François.\n\nRcppClassic\n\nDeprecated ‘classic’ Rcpp API. Authors: Dirk Eddelbuettel and Romain\nFrançois, with contributions by David Reiss, and based on code\nwritten during 2005 and 2006 by Dominick Samperi.\n\nRcppDE\n\nGlobal optimization by differential evolution in C++. Authors: Dirk\nEddelbuettel extending DEoptim (by David Ardia, Katharine Mullen,\nBrian Peterson, Joshua Ulrich) which itself is based on DE-Engine\n(by Rainer Storn). In view:\nOptimization.\n\nRepeatedHighDim\n\nDetection of global group effect in microarrays data. Author: Klaus\nJung.\n\nRiDMC\n\nR interface to the idmclib library. Authors: Antonio, Fabio Di\nNarzo.\n\nRnavGraph\n\nUsing graphs as a navigational infrastructure. Authors: Adrian R.\nWaddell and R. Wayne Oldford.\n\nRnavGraphImageData\n\nSome image data used in the RnavGraph package demos. Authors:\nAdrian R. Waddell and R. Wayne Oldford.\n\nRobustRankAggreg\n\nMethods for robust rank aggregation. Authors: Raivo Kolde and Sven\nLaur.\n\nRook\n\nA web server interface for R. Author: Jeffrey Horner.\n\nRssa\n\nA collection of methods for singular spectrum analysis. Author:\nAnton Korobeynikov. In view:\nTimeSeries.\n\nRz\n\nGUI Tool for Data Management like SPSS or Stata. Author: Masahiro\nHayashi.\n\nSPARQL\n\nSPARQL client. Author: Willem Robert van Hage.\n\nSPECIES\n\nStatistical package for species richness estimation. Author: Ji-Ping\nWang.\n\nSSsimple\n\nState space models. Author: Dave Zes.\n\nSVMMaj\n\nSVMMaj algorithm. Authors: Hoksan Yip, Patrick J.F. Groenen, and\nGeorgi Nalbantov.\n\nSYNCSA\n\nAnalysis of functional and phylogenetic patterns in metacommunities.\nAuthor: Vanderlei Júlio Debastiani.\n\nSamplingStrata\n\nOptimal stratification of sampling frames for multipurpose sampling\nsurveys. Author: Giulio Barcaroli.\n\nSemiParBIVProbit\n\nSemiparametric Bivariate Probit Modelling. Authors: Giampiero Marra\nand Rosalba Radice.\n\nSim.DiffProc\n\nSimulation of Diffusion Processes. Authors: Boukhetala Kamal and\nGuidoum Arsalane.\n\nSim.DiffProcGUI\n\nGraphical User Interface for Simulation of Diffusion Processes.\nAuthors: Boukhetala Kamal and Guidoum Arsalane.\n\nSimultAnR\n\nCorrespondence and Simultaneous Analysis. Authors: Amaya Zarraga and\nBeatriz Goitisolo.\n\nSixSigma\n\nSix Sigma Tools for Quality and Process Improvement. Authors: Emilio\nLópez, Andrés Redchuk, Javier M.Moguerza.\n\nSpeciesMix\n\nFit Mixtures of Archetype Species. Authors: Piers K Dunstan, Scott D\nFoster and Ross Darnell.\n\nTERAplusB\n\nTest for A+B Traditional Escalation Rule. Author: Eun-Kyung Lee.\n\nTSgetSymbol\n\nTime Series Database Interface extension to connect with getSymbols.\nAuthor: Paul Gilbert.\n\nTSxls\n\nTime Series Database Interface extension to connect to spreadsheets.\nAuthor: Paul Gilbert.\n\nTSzip\n\nTime Series Database Interface extension to connect to zip files.\nAuthor: Paul Gilbert.\n\nTauP.R\n\nEarthquake Traveltime Calculations for 1-D Earth Models. Authors:\nJake Anderson and Jonathan Lees.\n\nTwoPhaseInd\n\nTwo-Phase Independence. Author: James Dai.\n\nTwoStepCLogit\n\nConditional logistic regression: A two-step estimation method.\nAuthors: Radu V. Craiu, Thierry Duchesne, Daniel Fortin and Sophie\nBaillargeon.\n\nVBmix\n\nVariational Bayesian mixture models. Author: Pierrick Bruneau.\n\nVennDiagram\n\nGenerate high-resolution Venn and Euler plots. Author: Hanbo Chen.\n\nXLConnect\n\nExcel Connector for R. Author: Mirai Solutions GmbH.\n\nXLConnectJars\n\nJAR dependencies for the XLConnect package. Author: Mirai\nSolutions GmbH.\n\nYjdnJlp\n\nText Analysis by Yahoo! Japan Develper Network. Author: Yohei Sato.\n\nabd\n\nThe Analysis of Biological Data. Authors: Kevin M. Middleton and\nRandall Pruim.\n\nadehabitatHR\n\nHome Range Estimation. Author: Clément Calenge, contributions from\nScott Fortmann-Roe. In view:\nSpatial.\n\nadehabitatHS\n\nAnalysis of habitat selection by animals. Author: Clément Calenge,\ncontributions from Mathieu Basille. In view:\nSpatial.\n\nadehabitatLT\n\nAnalysis of animal movements. Author: Clément Calenge, contributions\nfrom Stéphane Dray and Manuela Royer. In view:\nSpatial.\n\nadehabitatMA\n\nTools to Deal with Raster Maps. Author: Clément Calenge,\ncontributions from Mathieu Basille. In view:\nSpatial.\n\nafmtools\n\nEstimation, Diagnostic and Forecasting Functions for ARFIMA models.\nAuthors: Javier Contreras-Reyes, Georg M. Goerg, and Wilfredo Palma.\n\nagridat\n\nAgricultural datasets. Author: Kevin Wright.\n\nahaz\n\nRegularization for semiparametric additive hazards regression.\nAuthor: Anders Gorst-Rasmussen. In view:\nMachineLearning.\n\nallanvar\n\nAllan Variance Analysis. Author: Javier Hidalgo Carrió.\n\napt\n\nAsymmetric Price Transmission. Author: Changyou Sun. In view:\nEconometrics.\n\narulesViz\n\nVisualizing Association Rules and Frequent Itemsets. Authors:\nMichael Hahsler and Sudheer Chelluboina.\n\naudit\n\nBounds for Accounting Populations. Author: Glen Meeden.\n\nbaseline\n\nBaseline Correction of Spectra. Authors: Kristian Hovde Liland and\nBjørn-Helge Mevik.\n\nbasicspace\n\nRecover a Basic Space from Issue Scales. Authors: Keith Poole,\nHoward Rosenthal, Jeffrey Lewis, James Lo, and Royce Carroll.\n\nbayesLife\n\nBayesian Projection of Life Expectancy. Authors: Hana Ševčíková,\nAdrian Raftery; original WinBugs code written by Jennifer Chunn.\n\nbayesQR\n\nBayesian quantile regression. Authors: Dries F. Benoit, Rahim\nAl-Hamzawi, Keming Yu, and Dirk Van den Poel.\n\nbayespack\n\nNumerical Integration for Bayesian Inference. Authors: Alan Genz\n(BAYESPACK Fortran source code) and Bornkamp (R interface and minor\nadaptions in Fortran source code). In view:\nBayesian.\n\nbayespref\n\nHierarchical Bayesian analysis of ecological count data. Authors:\nZachariah Gompert and James A. Fordyce.\n\nbgmm\n\nGaussian Mixture Modeling algorithms, including the belief-based\nmixture modeling. Author: Przemysław Biecek and Ewa Szczurek.\n\nbiGraph\n\nAnalysis Toolbox For Bipartite Graphs. Author: Ingo Vogt.\n\nbisoreg\n\nBayesian Isotonic Regression with Bernstein Polynomials. Author: S.\nMcKay Curtis. In view:\nBayesian.\n\nblender\n\nAnalyze biotic homogenization of landscapes. Author: David J.\nHarris.\n\nbmem\n\nMediation analysis with missing data using bootstrap. Authors:\nZhiyong Zhang and Lijuan Wang.\n\nbsml\n\nBasis Selection from Multiple Libraries. Authors: Junqing Wu, Jeff\nSklar, Yuedong Wang and Wendy Meiring.\n\nbst\n\nGradient Boosting. Author: Zhu Wang.\n\nbujar\n\nBuckley-James Regression for Survival Data with High-Dimensional\nCovariates. Author: Zhu Wang. In view:\nSurvival.\n\nc3net\n\nInfering large-scale gene networks with C3NET. Authors: Gokmen Altay\nand Frank Emmert-Streib.\n\ncaschrono\n\nSéries temporelles avec R — Méthodes et cas. Author: Yves Aragon.\n\ncems\n\nConditional expectatation manifolds. Author: Samuel Gerber.\n\ncg\n\nComparison of groups. Authors: Bill Pikounis and John Oleynick.\n\nchangepoint\n\nContains funcions that run various single and multiple changepoint\nmethods. Authors: Rebecca Killick and Idris A. Eckley.\n\ncitbcmst\n\nAssigning tumor samples to CIT Breast Cancer Molecular Subtypes from\ngene expression data. Authors: Laetitia Marisa, Aurélien de Reyniès,\nMickael Guedj.\n\nclime\n\nConstrained \\(L_1\\)-minimization for Inverse (covariance) Matrix\nEstimation. Authors: T. Tony Cai, Weidong Liu and Xi (Rossi) Luo.\n\ncncaGUI\n\nCanonical Non-symmetrical Correspondence Analysis in R. Authors: Ana\nBelén Nieto Librero, Priscila Willems, Purificación Galindo\nVillardón.\n\ncompeir\n\nEvent-specific incidence rates for competing risks data. Authors:\nNadine Grambauer and Andreas Neudecker. In view:\nSurvival.\n\nconcreg\n\nConcordance regression. Authors: R by Meinhard Ploner, Daniela\nDunkler and Georg Heinze; Fortran by Georg Heinze. In view:\nSurvival.\n\ncopBasic\n\nBasic Copula Functions. Author: William H. Asquith.\n\ncopulaedas\n\nEstimation of Distribution Algorithms Based on Copula Theory.\nAuthors: Yasser González-Fernández and Marta Soto.\n\ncosso\n\nCOSSO, adaptive COSSO, variable selection for nonparametric\nsmoothing spline models. Author: Hao Helen Zhang.\n\ncrrSC\n\nCompeting risks regression for Stratified and Clustered data.\nAuthors: Bingqing Zhou and Aurélien Latouche. In view:\nSurvival.\n\ndarts\n\nStatistical Tools to Analyze Your Darts Game. Author: Ryan\nTibshirani.\n\ndataview\n\nHuman readable data presentation. Author: Christofer Backlin.\n\ndbConnect\n\nProvides a graphical user interface to connect with databases that\nuse MySQL. Authors: Dason Kurkiewicz, Heike Hofmann, Ulrike\nGenschel.\n\ndbEmpLikeGOF\n\nGoodness-of-fit and two sample comparison tests using sample\nentropy. Authors: Jeffrey C. Miecznikowski, Lori A. Shepherd, and\nAlbert Vexler.\n\ndeducorrect\n\nDeductive correction of simple rounding, typing and sign errors.\nAuthors: Mark van der Loo, Edwin de Jonge, and Sander Scholtus.\n\ndepthTools\n\nDepth Tools. Authors: Sara López-Pintado and Aurora Torrente.\n\ndetrendeR\n\nA Graphical User Interface (GUI) to process and visualize tree-ring\ndata using R. Author: Filipe Campelo.\n\ndevEMF\n\nEMF graphics output device. Authors: Philip Johnson, with code from\nR-core.\n\ndfoptim\n\nDerivative-free Optimization. Author: Ravi Varadhan.\n\ndiff\n\nStatistics: What’s the Difference?. Authors: Andrew Gelman, Vincent\nDorie, Val Chan, and Daniel Lee.\n\ndiversitree\n\nComparative phylogenetic tests of diversification. Authors:\nRichard G. FitzJohn, with GeoSSE by Emma E. Goldberg. In view:\nPhylogenetics.\n\ndlmodeler\n\nGeneralized Dynamic Linear Modeler. Author: Cyrille Szymanski.\n\ndmt\n\nDependency Modeling Toolkit. Authors: Leo Lahti and Olli-Pekka\nHuovilainen.\n\ndoSMP\n\nForeach parallel adaptor for the revoIPC package. Author:\nRevolution Analytics. In view:\nHighPerformanceComputing.\n\neaf\n\nPlots of the Empirical Attainment Function. Authors: Carlos Fonseca,\nLuís Paquete, Thomas Stützle, Manuel López-Ibáñez and Marco\nChiarandini.\n\neditrules\n\nParsing and manipulating edit rules. Authors: Edwin de Jonge and\nMark van der Loo.\n\nenglish\n\nTranslate integers into English. Authors: John Fox and Bill\nVenables.\n\nenrichvs\n\nEnrichment assessment of virtual screening approaches. Author:\nHiroaki Yabuuchi.\n\nepoc\n\nEPoC (Endogenous Perturbation analysis of Cancer). Authors: Rebecka\nJornsten, Tobias Abenius, and Sven Nelander.\n\nerer\n\nEmpirical Research in Economics with R. Author: Changyou Sun. In\nview:\nEconometrics.\n\nergm.userterms\n\nUser-specified terms for the statnet suite of packages. Authors:\nMark S. Handcock, David R. Hunter, Carter T. Butts, Steven M.\nGoodreau, Martina Morris and Pavel N. Krivitsky.\n\nesotericR\n\nesotericR articles from lemnica.com. Author: Jeffrey A. Ryan.\n\nextfunnel\n\nAdditional Funnel Plot Augmentations. Authors: Dean Langan,\nAlexander Sutton, Julian PT Higgins, and Walter Gregory.\n\neyetracking\n\nEyetracking Helper Functions. Author: Ryan M. Hope.\n\nfactualR\n\nThin wrapper for the Factual.com server API. Author: Ethan McCallum.\n\nfastVAR\n\nFast implementations to estimate Vector Autoregressive models and\nVector Autoregressive models with Exogenous Inputs. Author: Jeffrey\nWong. In view:\nTimeSeries.\n\nfastcluster\n\nFast hierarchical clustering routines for R and Python. Author:\nDaniel Müllner. In view:\nCluster.\n\nfastmatch\n\nFast match() function. Author: Simon Urbanek.\n\nfda.usc\n\nFunctional Data Analysis and Utilities for Statistical Computing.\nAuthors: Febrero-Bande, M. and Oviedo de la Fuente, M.\n\nffbase\n\nBasic statistical functions for package ff. Author: Edwin de\nJonge.\n\nflux\n\nFlux rate calculation from dynamic closed chamber measurements.\nAuthors: Gerald Jurasinski and Franziska Koebsch.\n\nfractaldim\n\nEstimation of fractal dimensions. Authors: Hana Ševčíková, Tilmann\nGneiting, and Don Percival.\n\nfrailtyHL\n\nFrailty Models via H-likelihood. Authors: Il Do HA, Maengseok Noh,\nand Youngjo Lee. In view:\nSurvival.\n\nfunctional\n\nCurry, Compose, and other higher-order functions. Author: Peter\nDanenberg.\n\ngaussquad\n\nCollection of functions for Gaussian quadrature. Author: Frederick\nNovomestky.\n\ngdistance\n\nDistances and routes on geographical grids. Author: Jacob van Etten.\nIn view: Spatial.\n\ngdsfmt\n\nCoreArray Generic Data Structurs (GDS) R Interface. Author: Xiuwen\nZheng.\n\ngeoPlot\n\nPerforms Address Comparison. Authors: Randall Shane.\n\nggcolpairs\n\nCombination of GGplot2 plots into a matrix based on data columns.\nAuthors: Fernando Fuentes and George Ostrouchov.\n\nglmnetcr\n\nFit a penalized constrained continuation ratio model for predicting\nan ordinal response. Author: Kellie J. Archer.\n\nglobalboosttest\n\nTesting the additional predictive value of high-dimensional data.\nAuthors: Anne-Laure Boulesteix and Torsten Hothorn. In view:\nSurvival.\n\ngooJSON\n\nGoogle JSON Data Interpreter for R. Author: Christopher Steven\nMarcum.\n\ngraphite\n\nGRAPH Interaction from pathway Topological Environment. Authors:\nGabriele Sales, Enrica Calura, and Chiara Romualdi.\n\ngtcorr\n\nCalculate efficiencies of group testing algorithms with correlated\nresponses. Author: Sam Lendle.\n\ngwerAM\n\nControlling the genome-wide type I error rate in association mapping\nexperiments. Authors: Benjamin Stich, Bettina Müller, and Hans-Peter\nPiepho.\n\nhive\n\nHadoop InteractiVE. Authors: Ingo Feinerer and Stefan Theussl.\n\nhomeR\n\nFunctions useful for building physics. Author: Neurobat AG.\n\nhypred\n\nSimulation of genomic data in applied genetics. Author: Frank\nTechnow.\n\niSubpathwayMiner\n\nGraph-based reconstruction, analyses, and visualization of the KEGG\npathways. Author: Chunquan Li.\n\niWebPlots\n\nInteractive web-based scatter plots. Authors: Eleni Chatzimichalia\nand Conrad Bessant.\n\nieeeround\n\nFunctions to set and get the IEEE rounding mode. Author: Gianluca\nAmato.\n\nimputation\n\nFill missing values in a data matrix using SVD, SVT, or kNN\nimputation. Author: Jeffrey Wong.\n\ninfoDecompuTE\n\nInformation Decomposition of Two-phase Experiments. Authors: Kevin\nChang and Katya Ruggiero.\n\ninsideRODE\n\nFunctions with deSolve solver and C/FORTRAN interfaces to nlme,\ntogether with compiled codes. Authors: Yuzhuo Pan and Xiaoyu Yan.\n\nirlba\n\nFast partial SVD by implicitly-restarted Lanczos bidiagonalization.\nAuthors: Jim Baglama and Lothar Reichel.\n\nisocir\n\nIsotonic Inference for Circular Data. Author: The implementation in\nR was done by Sandra Barragan based on the SAS routines written by\nMiguel A. Fernández.\n\niterLap\n\nApproximate probability densities by iterated Laplace\nApproximations. Author: Bornkamp.\n\nkerdiest\n\nNonparametric kernel estimation of the distribution function.\nBandwidth selection and estimation of related functions. Authors:\nAlejandro Quintela del Río and Graciela Estévez Pérez.\n\nknn\n\nknn-gcv. Authors: Ernest Liu, Daisy Sun and Aaron Swoboda.\n\nkulife\n\nData sets and functions from the Faculty of Life Sciences,\nUniversity of Copenhagen. Authors: Claus Ekstrøm, Ib M. Skovgaard,\nand Torben Martinussen.\n\nlassoshooting\n\n\\(L_1\\) regularized regression (Lasso) solver using the Cyclic\nCoordinate Descent algorithm aka Lasso Shooting. Author: Tobias\nAbenius.\n\nlcmr\n\nBayesian estimation of latent class models with random effects.\nAuthors: Liangliang Wang and Nandini Dendukuri.\n\nldlasso\n\nLD LASSO Regression for SNP Association Study. Author: Samuel G.\nYounkin.\n\nlfe\n\nLinear Group Fixed Effects. Authors: Simen Gaure, The Ragnar Frisch\nCentre for Economic Research.\n\nlinkcomm\n\nTools for Generating, Visualizing, and Analysing Link Communities in\nNetworks. Author: Alex T. Kalinka.\n\nlmSupport\n\nSupport for Linear Models. Author: John Curtin.\n\nlmmlasso\n\nLinear mixed-effects models with Lasso. Author: Jürg Schelldorfer.\n\nmRm\n\nConditional maximum likelihood estimation in mixed Rasch models.\nAuthor: David Preinerstorfer.\n\nmargLikArrogance\n\nMarginal Likelihood Computation via Arrogance Sampling. Author:\nBenedict Escoto.\n\nmaxLinear\n\nConditional Samplings for Max-Linear Models. Author: Yizao Wang.\n\nmcga\n\nMachine Coded Genetic Algorithms for the Real Value Optimization\nProblems. Author: Mehmet Hakan Satman.\n\nmederrRank\n\nBayesian Methods for Identifying the Most Harmful Medication Errors.\nAuthors: Sergio Venturini and Jessica Myers.\n\nmefa4\n\nMultivariate Data Handling with S4 Classes and Sparse Matrices.\nAuthor: Peter Solymos.\n\nmgpd\n\nFunctions for multivariate generalized Pareto distribution (MGPD of\nType II). Author: Pal Rakonczai. In view:\nDistributions.\n\nmht\n\nMultiple Hypotheses Testing For Variable Selection. Author: F.\nRohart.\n\nmiP\n\nMultiple Imputation Plots. Author: Paul Brix.\n\nmiRtest\n\nCombined miRNA- and mRNA-testing. Authors: Stephan Artmann, Klaus\nJung, and Tim Beissbarth.\n\nmicrobenchmark\n\nSub microsecond accurate timing functions. Author: Olaf Mersmann.\n\nminPtest\n\nGene region-level testing procedure for SNP data, using the min P\ntest resampling approach. Author: Stefanie Hieke.\n\nmissForest\n\nNonparametric Missing Value Imputation using Random Forest. Author:\nDaniel J. Stekhoven.\n\nmnspc\n\nMultivariate Nonparametric Statistical Process Control. Authors:\nMartin Bezener and Peihua Qiu.\n\nmosaic\n\nProject MOSAIC (mosaic-web.org) math and stats teaching utilities.\nAuthors: Randall Pruim, Daniel Kaplan, and Nicholas Horton.\n\nmoult\n\nModels for Analysing Moult Data. Authors: Birgit Erni. Based on\nmodels developed by Underhill and Zucchini (1988,1990).\n\nmovMF\n\nMixtures of von Mises Fisher Distributions. Authors: Kurt Hornik and\nBettina Grün. In views:\nCluster,\nDistributions.\n\nmpa\n\nCoWords Method. Author: Daniel Hernando Rodríguez & Campo Elías\nPardo.\n\nmsSurv\n\nNonparametric Estimation for Multistate Models. Authors: Nicole\nFerguson, Guy Brock, and Somnath Datta. In view:\nSurvival.\n\nmsir\n\nModel-based Sliced Inverse Regression. Author: Luca Scrucca.\n\nmsr\n\nMorse-Smale approximation, regression and visualization. Authors:\nSamuel Gerber, Kristi Potter, and Oliver Ruebel.\n\nmtcreator\n\nCreating MAGE-TAB files using mtcreator. Author: Fabian Grandke.\n\nmultiPIM\n\nVariable Importance Analysis with Population Intervention Models.\nAuthors: Stephan Ritter, Alan Hubbard, and Nicholas Jewell.\n\nmultibiplotGUI\n\nMultibiplot Analysis in R. Authors: Ana Belén Nieto Librero, Nora\nBaccala, Purificación Vicente Galindo, and Purificación Galindo\nVillardon.\n\nmultxpert\n\nCommon Multiple Testing Procedures and Gatekeeping Procedures.\nAuthors: Alex Dmitrienko, Eric Nantz, and Gautier Paux, with\ncontributions by Thomas Brechenmacher.\n\nmvmeta\n\nMultivariate meta-analysis and meta-regression. Author: Antonio\nGasparrini.\n\nmxkssd\n\nEfficient mixed-level \\(k\\)-circulant supersaturated designs. Author:\nB N Mandal.\n\nneariso\n\nNear-Isotonic Regression. Authors: Holger Hoefling, Ryan Tibshirani,\nand Robert Tibshirani.\n\nnullabor\n\nTools for graphical inference. Author: Hadley Wickham.\n\nnumConversion\n\nTest of accuracy of as.character() for a numeric input using the\nstandard arithmetic. Author: Petr Savicky.\n\nnutshellDE\n\nBeispieldaten zu “R in a Nutshell” (deutsche Ausgabe). Author:\nJoseph Adler (Autor des nutshell-Pakets) and Beyer (deutsche\nÜbersetzung und Bearbeitung; ergänzender Code).\n\nnvis\n\nCombination of visualization functions for nuclear data using\nggplot2 and ggcolpairs. Authors: Fernando Fuentes and George\nOstrouchov.\n\noncomodel\n\nMaximum likelihood tree models for oncogenesis. Authors: Anja von\nHeydebreck, contributions from Christiane Heiss.\n\norclus\n\nORCLUS subspace clustering. Author: Gero Szepannek.\n\nordPens\n\nSelection and/or Smoothing of Ordinal Predictors. Author: Jan\nGertheiss.\n\norddom\n\nOrdinal Dominance Statistics. Author: Jens J. Rogmann.\n\npalaeoSig\n\nSignificance tests for palaeoenvironmental reconstructions. Author:\nRichard Telford.\n\nparamlink\n\nParametric linkage analysis. Author: Magnus Dehli Vigeland.\n\nparmigene\n\nParallel Mutual Information estimation for Gene Network\nreconstruction. Authors: Gabriele Sales and Chiara Romualdi.\n\npbivnorm\n\nVectorized Bivariate Normal CDF. Authors: Fortran code by Alan Genz.\nR code by Brenton Kenkel, based on Adelchi Azzalini’s mnormt\npackage.\n\npdfCluster\n\nCluster analysis via nonparametric density estimation. Authors:\nAdelchi Azzalini, Giovanna Menardi and Tiziana Rosolin. In view:\nCluster.\n\npenalizedLDA\n\nPenalized classification using Fisher’s linear discriminant. Author:\nDaniela Witten.\n\npencopula\n\nFlexible Copula Density Estimation with Penalized Hierarchical\nB-Splines. Author: Christian Schellhase.\n\npensim\n\nSimulation of high-dimensional data and parallelized repeated\npenalized regression. Authors: L. Waldron, M. Pintilie, C.\nHuttenhower* and I. Jurisica* (*equal contribution).\n\nphyext\n\nAn extension of some of the classes in phylobase. Tree objects now\nsupport subnodes on branches. Author: J. Conrad Stack.\n\npkDACLASS\n\nA complete statistical analysis of MALDI-TOF mass spectrometry\nproteomics data. Authors: Juliet Ndukum, Mourad Atlas, and Susmita\nDatta.\n\nplotmo\n\nPlot a model’s response while varying the values of the predictors.\nAuthor: Stephen Milborrow.\n\nplsRcox\n\nPartial least squares Regression for Cox models and related\ntechniques. Authors: Frederic Bertrand, Myriam Maumy-Bertrand, and\nNicolas Meyer. In view:\nSurvival.\n\npoibin\n\nThe Poisson Binomial Distribution. Author: Yili Hong. In view:\nDistributions.\n\npracma\n\nPractical Numerical Math Functions. Author: Hans W Borchers.\n\npress\n\nProtein REsidue-level Structural Statistics. Authors: Yuanyuan\nHuang, Stephen Bonett, and Zhijun Wu.\n\npressData\n\nData sets for package press. Authors: Yuanyuan Huang, Stephen\nBonett, and Zhijun Wu.\n\npycno\n\nPycnophylactic Interpolation. Author: Chris Brunsdon.\n\nqat\n\nQuality Assurance Toolkit. Author: Andre Duesterhus.\n\nqgraph\n\nVisualize data as networks. Authors: Sacha Epskamp, Angelique O. J.\nCramer, Lourens J. Waldorp, Verena D. Schmittmann, and Denny\nBorsboom. In view:\nPsychometrics.\n\nqueueing\n\nBasic Markovian queueing models. Author: Pedro Canadilla.\n\nrCUR\n\nCUR decomposition package. Authors: Andras Bodor and Norbert\nSolymosi.\n\nrChoiceDialogs\n\nrChoiceDialogs collection. Authors: Alex Lisovich and Roger Day.\n\nrdyncall\n\nImproved Foreign Function Interface (FFI) and Dynamic Bindings to C\nLibraries (e.g. OpenGL). Author: Daniel Adler.\n\nreadBrukerFlexData\n\nReads mass spectrometry data in Bruker *flex format. Author:\nSebastian Gibb.\n\nreadMzXmlData\n\nReads mass spectrometry data in mzXML format. Authors: Jarek\nTuszynski and Sebastian Gibb.\n\nrebmix\n\nRandom univariate and multivariate finite mixture generation.\nAuthor: Marko Nagode.\n\nreliaR\n\nPackage for some probability distributions. Authors: Vijay Kumar and\nUwe Ligges. In view:\nDistributions.\n\nreshapeGUI\n\nA GUI for the reshape2 and plyr packages. Author: Jason Crowley.\n\nreview\n\nManage Review Logs. Author: Tim Bergsma.\n\nrevoIPC\n\nShared memory parallel framework for multicore machines. Author:\nRevolution Analytics.\n\nrgam\n\nRobust Generalized Additive Model. Authors: Matías Salibián-Barrera,\nDavor Cubranic, and Azadeh Alimadad.\n\nrgeos\n\nInterface to Geometry Engine — Open Source (GEOS). Authors: Roger\nBivand and Colin Rundel. In view:\nSpatial.\n\nrich\n\nSpecies richness estimation and comparison. Author: Jean-Pierre\nRossi.\n\nrminer\n\nSimpler use of data mining methods (e.g. NN and SVM) in\nclassification and regression. Author: Paulo Cortez. In view:\nMachineLearning.\n\nrneos\n\nXML-RPC Interface to NEOS. Author: Bernhard Pfaff. In view:\nOptimization.\n\nrocplus\n\nROC, Precision-Recall, Convex Hull and other plots. Author: Bob\nWheeler.\n\nrpart.plot\n\nPlot rpart models. An enhanced version of plot.rpart(). Author:\nStephen Milborrow.\n\nrrBLUP\n\nGenomic selection and association analysis. Author: Jeffrey\nEndelman.\n\nrrdf\n\nSupport for the Resource Description Framework. Author: Egon\nWillighagen.\n\nrrdflibs\n\nJena libraries for use with rrdf. Author: Egon Willighagen.\n\nrsdepth\n\nRay Shooting Depth (i.e., RS Depth) functions for bivariate\nanalysis. Authors: Nabil Mustafa, Saurabh Ray, and Mudassir Shabbir.\n\nrtape\n\nManage and manipulate large collections of R objects stored as\ntape-like files. Author: Miron B. Kursa.\n\nrvmbinary\n\nRVM Binary Classification. Author: Robert Lowe.\n\nrysgran\n\nGrain size analysis, textural classifications and distribuition of\nuncosolidated sediments. Authors: Maurício Garcia de Camargo,\nEliandro Ronael Gilbert, Leonardo Sandrini-Neto.\n\ns3x\n\nEnhanced S3-Based Programming. Author: Charlotte Maia.\n\nsaves\n\nFast load variables. Author: Gergely Daróczi.\n\nscaleCoef\n\nScale regression coefficients. Author: Sandrah P. Eckel.\n\nscriptests\n\nTranscript-based unit tests that are easy to create and maintain.\nAuthor: Tony Plate.\n\nseg\n\nA set of tools for residential segregation research. Authors:\nSeong-Yun Hong, David O’Sullivan.\n\nsfa\n\nStochastic Frontier Analysis. Authors: Ariane Straub, under the\nsupervision of Torsten Hothorn.\n\nsideChannelAttack\n\nSide Channel Attack. Authors: Liran Lerman, Gianluca Bontempi, and\nOlivier Markowitch.\n\nsimboot\n\nSimultaneous Confidence Intervals and Adjusted \\(p\\)-values for\nDiversity Indices. Author: Ralph Scherer.\n\nskills\n\nSkills in Knowledge Space Theory. Author: Angela Pilhoefer.\n\nsmco\n\nA simple Monte Carlo optimizer using adaptive coordinate sampling.\nAuthor: Juan David Velásquez.\n\nsnort\n\nSocial Network-Analysis On Relational Tables. Authors: Eugene\nDubossarsky and Mark Norrie.\n\nsoma\n\nGeneral-purpose optimisation with the Self-Organising Migrating\nAlgorithm. Author: Jon Clayden; based on the work of Ivan Zelinka.\nIn view:\nOptimization.\n\nsomplot\n\nVisualisation of hexagonal Kohonen maps. Authors: Benjamin Schulz\nand Andreas Dominik.\n\nsos4R\n\nAn R client for the OGC Sensor Observation Service. Author: Daniel\nNüst.\n\nspa\n\nImplements The Sequential Predictions Algorithm. Author: Mark Culp.\n\nspacodiR\n\nSpatial and Phylogenetic Analysis of Community Diversity. Authors:\nJonathan Eastman, Timothy Paine, and Olivier Hardy.\n\nspd\n\nSemi Parametric Distribution. Author: Alexios Ghalanos. In view:\nDistributions.\n\nspeedR\n\nA GUI based importing and filtering tool. Author: Ilhami Visne.\n\nspeedRlibTF\n\nspeedR’s table filter library. Author: Ilhami Visne.\n\nspeedRlibs\n\nLibraries (jars) for speedR. Author: Ilhami Visne.\n\nspi\n\nCompute SPI index. Author: Josemir Neves.\n\nspikeSlabGAM\n\nBayesian variable selection and model choice for generalized\nadditive mixed models. Author: Fabian Scheipl. In view:\nBayesian.\n\nsporm\n\nSemiparametric proportional odds rate model. Authors: Zhong Guan and\nCheng Peng.\n\nsra\n\nSelection Response Analysis. Author: Arnaud Le Rouzic.\n\nstabledist\n\nStable Distribution Functions. Authors: Diethelm Wuertz, Martin\nMaechler and Rmetrics core team members. In view:\nDistributions.\n\nstepp\n\nSubpopulation Treatment Effect Pattern Plot (STEPP). Author: Wai-ki\nYip, with contributions from Ann Lazar, David Zahrieh, Chip Cole,\nAnn Lazar, Marco Bonetti, and Richard Gelber.\n\nsuperMDS\n\nImplements the supervised multidimensional scaling (superMDS)\nproposal of Witten and Tibshirani (2011). Author: Daniela M. Witten.\n\nsurvAUC\n\nEstimators of prediction accuracy for time-to-event data. Authors:\nSergej Potapov, Werner Adler and Matthias Schmid. In view:\nSurvival.\n\nsurvivalBIV\n\nEstimation of the Bivariate Distribution Function. Authors: Ana\nMoreira and Luis Meira-Machado. In view:\nSurvival.\n\nsvd\n\nInterfaces to various state-of-art SVD and eigensolvers. Author:\nAnton Korobeynikov.\n\nswamp\n\nAnalysis and visualization of high-dimensional data in respect to\nsample annotations. Author: Martin Lauss.\n\ntabplot\n\nTableplot, a visualization of large statistical datasets. Authors:\nMartijn Tennekes and Edwin de Jonge.\n\ntexmex\n\nThreshold exceedences and multivariate extremes. Authors: Harry\nSouthworth and Janet E. Heffernan.\n\ntextir\n\nInverse Regression for Text Analysis. Author: Matt Taddy.\n\ntimeordered\n\nTime-ordered and time-aggregated network analyses. Author: Benjamin\nBlonder.\n\ntm.plugin.dc\n\nText Mining Distributed Corpus Plug-In. Authors: Ingo Feinerer and\nStefan Theussl.\n\ntmle\n\nTargeted Maximum Likelihood Estimation of additive treatment effect.\nAuthor: Susan Gruber, in collaboration with Mark van der Laan.\n\ntonymisc\n\nFunctions for Econometrics Output. Author: J. Anthony Cookson.\n\ntrack\n\nTrack Objects. Author: Tony Plate.\n\ntrapezoid\n\nThe Trapezoidal Distribution. Author: Jeremy Thoms Hetzel. In view:\nDistributions.\n\ntreecm\n\nEstimating and plotting the centre of mass of a tree. Author: Marco\nBascietto.\n\ntriggr\n\nFast, simple RPC controller for R. Author: Miron B. Kursa.\n\ntwo.stage.boot\n\nTwo-stage cluster sample bootstrap algorithm. Author: Patrick\nZimmerman.\n\nudunits2\n\nudunits-2 bindings for R. Author: James Hiebert.\n\nunknownR\n\nYou didn’t know you didn’t know? Author: Matthew Dowle.\n\nvarSelectIP\n\nObjective Bayes Model Selection. Authors: Gopal, V. and\nNovelo, L. L. and Casella, G. In view:\nBayesian.\n\nvarcompci\n\nComputation of Confidence Intervals for Variance Components of Mixed\nModels in R. Authors: Civit, S., Vilardell, M., Hess, A., Matthew,\nZ., Ge, Y., Caballe, A.\n\nvines\n\nMultivariate Dependence Modeling with Vines. Authors: Yasser\nGonzález-Fernández and Marta Soto.\n\nvisualizationTools\n\nA few functions to visualize statistical circumstances. Authors:\nThomas Roth and Etienne Stockhausen.\n\nvoronoi\n\nMethods and applications related to Voronoi tessellations. Authors:\nChristopher D. Barr, Travis A. Gerke, and David M. Diez.\n\nvwr\n\nUseful functions for visual word recognition research. Author:\nEmmanuel Keuleers.\n\nwavemulcor\n\nWavelet routine for multiple correlation. Author: Javier\nFernandez-Macho (UPV/EHU).\n\nwebsockets\n\nHTML 5 Websocket Interface for R. Author: B. W. Lewis.\n\nweights\n\nWeighting and Weighted Statistics. Author: Josh Pasek.\n\nxtermStyle\n\nBasic text formatting using xterm escape sequences. Author:\nChristofer Backlin.\n\nzipcode\n\nU.S. ZIP Code database. Author: Jeffrey Breen.\n\n3 Other changes\nThe following packages which were previously double-hosted on CRAN\nand Bioconductor were moved to the Archive, and are now solely\navailable from Bioconductor: LMGene, gene2pathway, genefu,\ngraph, minet, multtest, survcomp, vbmp.\nThe following packages were moved to the Archive: EMC, EMCC,\nEffectiveDose, FunctSNP, G1DBN, ISA, PermuteNGS,\nRSeqMeth, SMC, cxxPack, distributions, elec,\nformula.tools, hierfstat, muscor, pARccs, ripa, ris,\nsigma2tools, tossm, tradeCosts.\nThe following packages were resurrected from the Archive: NADA,\nglmc, ifa, ipptoolbox, locfdr, nparcomp, ramps,\nrisksetROC, rv.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2011-1-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2011-1 issue.",
    "author": [
      {
        "name": "Heather Turner",
        "url": {}
      }
    ],
    "date": "2011-06-01",
    "categories": [],
    "contents": "\n\nThis issue comes approximately one month after CRAN passed a new\nmilestone: the number of packages in the repository had reached 3000.\nWith such a large number of packages (and the number is still rising of\ncourse) it becomes increasingly difficult for package authors to get\ntheir work known and for R users to find packages that will be useful to\nthem. The R Journal plays an important role in this context; it provides\na platform for developers to introduce their packages in a user-friendly\nform and although the presented packages are not validated, publication\nin The R Journal gives the quality assurance that comes from thorough\npeer review.\nGiven that The R Journal only publishes around 20 contributed articles a\nyear however, there is more that needs to be done to communicate\ndevelopments on CRAN. The editorial board had some discussion recently\nover whether to keep the traditional “Changes on CRAN´´ section.\nAlthough there are other ways to keep up-to-date with CRAN news, notably\nCRANberries (http://dirk.eddelbuettel.com/cranberries/) and crantastic\n(http://crantastic.org/), some people still appreciate an occasional\nround-up that they can browse through. So this section stays for now,\nbut we are open to suggested improvements.\nAnother important way to keep abreast of developments in the R community\nis via conferences and workshops. As program chair for useR! 2011, I\nhave been pulling together the program for this conference at the same\ntime as preparing this issue. At this year’s useR! there will be around\n150 contributed talks and more than 30 contributed posters from across\nthe R community. Looking forward to this conference, we invited Rob\nHyndman and Di Cook to share their presentation tips in the Help Desk\ncolumn of this issue. Of course, useRs present their work at many and\nvaried conferences, and this is reflected in our News section where we\nhave a report of an experimental format used for the Polish R Users’\nConference and a report of workshops run by Project MOSAIC, a\nstatistical education initiative in which R features prominently.\nAlthough Vince Carey officially stepped down from the editorial board at\nthe end of last year, this issue features several articles that he saw\nthrough to publication, so we thank him once again for all his work on\nthe Journal. We welcome Hadley Wickham on board, an enthusiastic\ncontributor to the R community, as evidenced not only by his own article\nin this issue, but by the social network analysis of R mailing lists\npresented by Angela Bohn and colleagues. These two articles are just the\nstart of a fine collection of contributed articles and we also have a\nnew book review to report.\nI hope this issue goes some way to helping useRs navigate their way\nthrough the R world!\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2011-1-Hyndman/",
    "title": "Giving a useR! Talk",
    "description": "Giving a UseR! talk at the the international R user conference is a balancing act in which you have to try to impart some new ideas, provide sufficient background and keep the audience interested, all in a very short period of time.",
    "author": [
      {
        "name": "Rob J Hyndman",
        "url": {}
      }
    ],
    "date": "2011-06-01",
    "categories": [],
    "contents": "\n\nI’ve sat through more than my fair share of bad conference talks. Slides\nfull of equations flashing past quickly, tables containing tiny figures\nthat no-one can read, most of the audience lost on the third slide.\nAnyone who has attended even one conference will have seen these\nexamples and more.\n1 What is the aim of the talk?\nThe problems often stem from confusion about the purpose of the talk.\nSome speakers clearly think the aim of a talk is to impress the audience\nwith their technical skills, even (or especially) if that means the\naudience does not understand what they are talking about. Others\nspeakers appear to believe that talks are for those few members of the\naudience who are working in the same narrow research area — and so no\nattempt is made to provide an introduction to the topic. Still others\nsee conference talks as an oral version of an academic paper, in all its\npainful detail.\nInstead, I like to think of conference talks as advertisements for the\nassociated paper or R package, or shared wisdom gained through valuable\nexperience. The talk is not intended to cover everything you have done,\nor even to summarize what you have done. In giving a talk, I am hoping\nthat (1) everyone in the audience will have a clear idea of what I have\nbeen working on; and (2) some of those in the audience will be motivated\nto read my paper, download the associated R package, or put into\npractice some of my advice.\nThese aims mean that I never bother with proofs or derivations — they\nare for the people who read the paper. Similarly, there is no point\ndiscussing the internals of R code or algorithm technicalities. Those\nwho care will explore the details afterwards.\nInstead, I tend to spend at least half the time going through a\nmotivating example and reviewing the relevant background — most of the\naudience will need that context in order to understand what the talk is\nabout. In fact, it is reasonable to assume that the audience knows about\nas much as you did at the start of your work in this area. That is,\nprobably very little. So it is important to spend some time providing\nbackground information or you will lose the audience quickly. Do not\nassume the audience already knows what you have spent long hours\nlearning on your own.\n2 Consider the context\nFor a useR! talk, there is the additional challenge of getting the right\nbalance of code, technical and application detail. The appropriate mix\ndepends on the session.\nIf you are giving a kaleidoscope talk (for a wide audience), you need to\nmake a particular effort to make your talk accessible, keeping examples\nsimple and minimising technical detail. Speakers in focus sessions\nshould consider what other talks are in their session in order to\ndetermine how specialised the audience is likely to be (e.g., people at\na high performance computing session are probably comfortable with\ntechnical details, but those at a session on ecology are likely to be\nmore interested in the application detail.)\nLooking at some related talks from previous years can be useful. Many\ntalks from previous useR! conferences can be found on the conference\nwebsites (see http://www.r-project.org/conferences.html for links).\n3 A suggested structure\nI recommend the following structure for a conference talk:\nStart with a motivating example demonstrating the problem you are\ntrying to solve;\nExplain existing approaches to the problem and their weaknesses;\nDescribe your main contributions;\nShow how your ideas solve the problem/example you started with.\nThis structure will not necessarily work for every talk, but it is a\ngood place to start. In particular, beginning with a motivating example\nis much better than setting up the problem algebraically.\nFor a 15 minute conference presentation, I divide the time approximately\ninto 3/4/6/2 minute sections.\nUsing this structure, you will have barely started on your own\ncontributions when you are half way through your allocated time. Resist\nthe temptation to trim the first two sections. The audience needs time\nto absorb the purpose of your work and the context in which it is set.\n4 Keeping to time\nDo not deliver a 30-minute talk in 15 minutes. Nothing irritates an\naudience more than a rushed presentation. It is like trying to get a\ndrink out of a fire hydrant. Your objective is to engage the audience\nand have them understand your message. Do not flood them with more than\nthey can absorb.\nPresent only as much material as can reasonably fit into the allocated\ntime. Generally that means no more than one slide per minute. I tend to\nuse an average of about 0.8 slides per minute of talking. It is helpful\nto use some slides as time-markers and make sure you are at the relevant\nslide at the right time.\nNever go over time. Keep an eye out for signals from the session chair\nindicating when you need to conclude. If necessary, be prepared to cut\nyour talk short and finish with a quick summary.\nRehearsing is invaluable. Practise. Out loud. Standing up. Using a data\nprojector. Get colleagues to listen to you, including some who are not\nknowledgeable on the topic of your talk; they will be able to point out\nplaces where you may not come across clearly. If several people in your\nresearch group are attending the same conference, get together\nbeforehand and practice your talks to each other. Make such rehearsals\nas realistic as possible and time them. After the rehearsal, you may\nwish to delete some of your material to ensure the talk can be delivered\nwithin the allocated time.\nBalance the amount of material you present with a reasonable pace of\npresentation. If you feel rushed when you practise, then you have too\nmuch material. Budget your time to take a minute or two less than your\nmaximum allotment.\n5 Preparing slides\nHigh quality slides are an important part of a good presentation. I\nrecommend using the beamer package with LaTeX. MS-Powerpoint is also\npopular, but it makes it much harder to format mathematical symbols and\nequations nicely.\nAvoid distracting slide transitions and dazzling slide themes. You want\nthe audience to focus on your content, not wonder how you implemented\nsome gimmick. Save animation for aiding interpretation.\nUse at least a 20-point font so everyone in the room can read your\nmaterial. (The default font size in beamer is generally too small —\nuse a 14pt font in beamer which is equivalent to 23pt on the screen.)\nSimilarly, view your slides at 50% on screen to check that code and\nfigures are legible. Unreadable material is worse than useless — it\ninspires a negative attitude by the audience to your work and,\nultimately, to you. Many R users are near-sighted; do not make it any\nharder for them.\nLimit the material on each slide, keeping the number of words to a\nminimum. Do not include every detail of what you plan to say. Keep it\nsimple. It is easy, but boring, to have bulleted lists summarizing your\nmain points. Instead, use pictures and graphics as much as possible.\nResort to text only when illustrations fail you.\nIf you must present tables, only show the essential information. No-one\nis going to read a slide full of tiny numbers, let alone absorb the\ninformation. Very often, a table can be replaced with a suitable\ngraphic.\nGive only the most necessary mathematical details. People not working in\nthe research area can find equations difficult to follow as part of a\nrapidly delivered presentation. When you do need to use equations,\ndefine your notation.\nAvoid showing too much R code. Trim it back to the bare minimum so the\naudience can focus on the essential details. Use different colours to\nclearly distinguish R code from output.\nSlides are not there to remind you what to say — use a page of notes\nfor that purpose. The slides are for the audience — make sure\neverything on your slides is there because it will help the audience\nunderstand what you are saying.\nOn your last slide, give your website or email address for people to\ncontact you if they want to read the paper or download your R code or\njust ask a question.\nIt is useful to add slide numbers so the audience can refer back to\nspecific slides in question time.\nI spend a lot of time going over my slides looking for ways to improve\nthem. After a presentation is essentially complete, I go through all the\nslides to see what I can remove — less text is better. I also look for\nplaces where I can simplify the presentation, where I can replace text\nwith graphics, and where the titles can be improved. I often spend\nalmost as much time refining the slides as in creating the first\nversion.\nAlways preview your slides on the computer being used for the talk.\nYou will look foolish if symbols and Greek letters that looked OK on\nyour computer translate into something unreadable on the big screen.\nThis is much more common if you use MS-Powerpoint as the fonts may not\nbe embedded in the document and so equations lose important symbols.\n6 Giving the presentation\nBy the time you give the talk, you will have spent enough time preparing\nyour slides and practising your talk that you should feel confident of\ngiving a great presentation.\nAt the conference, make sure you talk to the session chair beforehand so\nthey are aware of who you are. Arrive at the meeting room 10 minutes\nbefore the session begins to take care of last-minute details.\nTalk at a pace that everybody in the audience can understand. Speak\nslowly, clearly, and loudly, especially if your English is heavily\naccented. Speak loudly enough to be easily heard by those sitting in the\nback row.\nEngage the audience — speak to them, not to the projector screen or to\nyour notes. It helps to move around, look at your audience and smile.\nNever apologize for your slides. Make apologies unnecessary by producing\ngreat slides in the first place. Do not say, “I know you can’t see this,\nbut …” If the audience cannot read your slide, there is no point\ndisplaying it.\nDo not apologize for incomplete results either. Researchers understand\nthat all research is incomplete. Just present the results and let the\naudience judge. It is okay to say, “work is on-going”.\nWhen finished, thank the audience for their attention. Stay for the\nentire session, for the courtesy and benefit of your audience and your\nco-speakers. Afterwards, be available for people to ask you questions.\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2011-1-mosaic/",
    "title": "Conference Review: Kickoff Workshop for Project MOSAIC",
    "description": "The 'Conference Review: Kickoff Workshop for Project MOSAIC' article from the 2011-1 issue.",
    "author": [
      {
        "name": "Nicholas J. Horton",
        "url": {}
      },
      {
        "name": "Randall Pruim",
        "url": {}
      },
      {
        "name": "Danny Kaplan",
        "url": {}
      }
    ],
    "date": "2011-06-01",
    "categories": [],
    "contents": "\n\nProject MOSAIC (http://www.mosaic-web.org) is a community of educators\nworking to develop new ways of introducing modeling, statistics,\ncomputation and calculus to students in colleges and universities. The\nInstitute for Mathematics and its Applications at the University of\nMinnesota hosted the kickoff workshop for Project MOSAIC from June\n30–July 2, 2010.\nThe MOSAIC community helps educators share ideas and resources that will\nimprove undergraduate teaching, and to develop a curricular and\nassessment infrastructure to support the dissemination and evaluation of\nthese ideas and resources. Other goals of this NSF-funded project\n(0920350) are to develop important skills in students of science,\ntechnology, engineering, and mathematics that will be needed for their\nprofessional careers, with a particular focus on the integration of\ncapacities in four main areas:\nModeling\n\nThe ability to create useful and informative representations of\nreal-world situations.\n\nStatistics\n\nThe analysis of variability that draws on our ability to quantify\nuncertainty and to draw logical inferences from observations and\nexperiments.\n\nComputation\n\nThe capacity to think algorithmically, to manage data on large\nscales, to visualize and interact with models, and to automate tasks\nfor efficiency, accuracy, and reproducibility.\n\nCalculus\n\nThe traditional mathematical entry point for college and university\nstudents and a subject that still has the potential to provide\nimportant insights to today’s students.\n\nThe workshop, which spanned three days, provided an opportunity for\neducators to present curricular innovations that have already been\ndeveloped, to discuss the overall organization of curricula that will\neffectively unify the four areas outlined above, and to establish\nstrategic plans for Project MOSAIC. More than 30 people from nearly as\nmany institutions attended.\nR was featured as a computational environment for many of the\npresentations. These included examples of the use of R for teaching\ncalculus (Danny Kaplan, Macalester College), resampling in the\nintroductory statistics course (Nathan Tintle, Hope College), computer\nlanguages to support MOSAIC instruction (Randall Pruim, Calvin College),\nstock market simulation to better understand variability (Nicholas\nHorton, Smith College), statistical modeling for poets (Vittorio Addona,\nMacalester College), reproducible analysis (Nicholas Horton, Smith\nCollege) and the cost of information (Danny Kaplan, Macalester College)\nSince the workshop, the project organizers have been scheduling M-Casts.\nThese 20-minute webinars broadcast over the Internet on the 2nd, 4th,\nand 5th Friday of each month are designed to provide a quick and easy\nway for educators to share ideas, to get reactions from others, and to\nform collaborations. Recent R-related M-Casts include discussion of new\ndifferentiation and anti-differentiation operators in R for calculus,\nand using simulation in R to teach the logic of hypothesis tests. Future\nM-Casts are planned to encourage additional use of R as an environment\nfor computation within mathematics, science, statistics and modeling\ncourses.\nTo further promote and facilitate the use of R in these efforts, Project\nMOSAIC has developed the\nmosaic package, which is\nnow available on CRAN. It includes a number of datasets and functions\nwhich work to clarify and simplify integration of computing and modeling\nin introductory and intermediate statistics courses. This package was\nused extensively as part of the May 2011 Project MOSAIC USCOTS (United\nStates Conference on Teaching Statistics) pre-conference workshop on\nusing R to teach statistics. A low-volume discussion list\n(r-users@mosaic-web.org) has been\ncreated. For more information or to subscribe, see the URL at\nhttp://mailman-mail5.webfaction.com/listinfo/r-users.\n\n\n\n\n\nCRAN packages used\nmosaic\nCRAN Task Views implied by cited packages\nTeachingStatistics\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2011-1-polish-r-conf/",
    "title": "Conference Review: Third Meeting of Polish R Users, The Influenza Challenge ",
    "description": "The 'Conference Review: Third Meeting of Polish R Users, The Influenza Challenge ' article from the 2011-1 issue.",
    "author": [
      {
        "name": "Przemyslaw Biecek",
        "url": {}
      }
    ],
    "date": "2011-06-01",
    "categories": [],
    "contents": "\n\nThe third Polish R Users’ Conference took place at the Mathematical\nInstitute of Polish Academy of Sciences in Wrocław on 24-25 of September\n2010. The meeting was traditionally named WZUR, an abbreviation which\nhas the same meaning as “equation” in spoken Polish. This year the\nconference adopted a fresh format. I wish to share with you both the\nreasons behind changing the format and the afterthoughts of the\nconference participants.\nThis time the leading subject for the conference was the epidemiology of\ninfluenza. Almost 50 people from various parts of Poland and\nrepresenting numerous professions (statisticians, mathematicians,\nmedical doctors, students) gathered to find out more about influenza and\nmethods for analyzing data related to this disease. A few months in\nadvance of the conference, we had gathered weekly reports covering the\nlast 11 years of influenza occurrences in Poland. Both the absolute\nnumbers and the rates per 100,000 individuals of infections and\nmortalities were available for four age groups and for 16 different\nregions. All participants had access to the same data set and all of\nthem had time to experiment on the dataset using an assortment of\nstatistical methods. During the two-day conference various applications\nwere presented of existing statistical procedures available in R as well\nas newly developed methods.\nThe dataset was a common basis for all talks. We requested all\npresenters to prepare talks composed of three parts. In the first part\nthe statistical methods, the mathematical theory behind them along with\nsome insights were presented. In the second part a set of R functions\ncovering these methods was introduced. And finally in the third part a\nsample application of presented methods to the dataset described above\nwas demonstrated. All participants were familiarized with the dataset,\nand this created a common platform which facilitated better\ncommunication among statisticians and physicians. The epidemiology of\ninfluenza was tackled from different angles. Results from variety of\nstatistical procedures created a framework for discussion between people\nwho are developing new statistical methods and for people who are\napplying them.\nThe conference was conducted in Polish, and most of the conference\nmaterials are in Polish but the equations and figures are international,\nand presentations are available on the web site\nhttp://www.biecek.pl/WZUR. Almost all talks were recorded and the\nvideo files are freely available from the above address.\nList of presented talks:\nShort-term changes in mortality during influenza epidemics, Daniel\nRabczenko (PZH) ,\nCalibration estimators in the study of influenza, Tomek Józefowski,\nMarcin Szymkowiak (UE Poznań),\nTime series comparison using Dynamic Time Warping, Pawel Teisseyre\n(IPI PAN),\nSelected generalized linear models. Alicja Szabelska (UE Poznań),\nCUMSUM method in prediction of influenza epidemics. Konrad\nFurmańczyk, Marta Zalewska, Przemysław Biecek, Stanisław Jaworski\n(WUM+UW),\nThe ECAP study, the correspondence analysis in the asthma study.\nKonrad Furmańczyk, Stanisław Jaworski, Bolesław Samoliński, Marta\nZalewska (WUM),\nSesonality of influenza. Marta Musiał, Łukasz Wawrowski, Maciej\nBeręsewicz, Anita Mackowiak (UE Poznań),\nLogistic regression in the study of influenza. Piotr Ṡliwka (UKW).\nThe simecol package in Influenza study. Marta Markiewicz, Anna\nSikora, Katarzyna Zajączkowska, Michał Balcerek, Piotr Kupczyk\n(PWr),\nThe artificial neural networks in forecasting the influenza\nepidemics. Anna Noga, Roksana Kowalska, Maciej Kawecki, Paweł\nSzczypior (PWr),\nIntensity estimation with multiplicative intensity models. Anna\nDudek Piotr Majerski (AGH),\nInfluenza epidemiology, Grażyna Dulny (WUM).\nAdditionally, during the second day of the conference the survey\n“Epidemiology of Allergic Disease in Poland” was presented\n(http://ecap.pl/eng_www/material.html). The project was conducted with\nthe Department of Prevention of Environmental Hazards and Allergology at\nthe Medical University of Warsaw by the initiative of the Minister of\nHealth.\nThe organizing committee: Przemysław Biecek, Marta Zalewska, Konrad\nFurmańczyk , Stanisław Jaworski would like to thank:\nThe Scientific Committee\n\nProf. Leon Bobrowski, Prof Antoni Dawidowicz, Prof. Jacek Koronacki,\nDr Witold Kupść, Prof. Wojciech Niemiro, Dr Daniel Rabczenko, Prof.\nBolesław Samoliński, Prof. Łukasz Stettner, and Prof. Wojciech\nZieliński.\n\nOur host\n\nThe Polish Mathematical Society in Wrocław,\n\nOur generous sponsors and supporters\n\nNetezza, Warsaw University, The Medical University of Warsaw,\nGlaxoSmithKline, Sanofi Pasteur, and The Independent Public Central\nClinical Hospital.\n\nWe are looking forward to the next WZUR. This time we will focus on the\ndata set “Social Diagnosis 2000-2011” (see:\nhttp://diagnoza.com/index-en.html). The challenge is to understand\nchanges in objective and subjective quality of life in Poland in last 11\nyears.\nAs always we warmly welcome new participants and sponsors!\nOn behalf of The Organizing Committee,\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2011-1-r-changes/",
    "title": "Changes in R",
    "description": "The 'Changes in R' article from the 2011-1 issue.",
    "author": [
      {
        "name": "The R Core Team",
        "url": {}
      }
    ],
    "date": "2011-06-01",
    "categories": [],
    "contents": "\n\nCHANGES IN R VERSION 2.13.0\n\nSIGNIFICANT USER-VISIBLE CHANGES\nreplicate() (by default) and vapply() (always) now return a\nhigher-dimensional array instead of a matrix in the case where the\ninner function value is an array of dimension \\(\\ge 2\\).\nPrinting and formatting of floating point numbers is now using the\ncorrect number of digits, where it previously rarely differed by a\nfew digits. (See “scientific” entry below.) This affects many\n*.Rout.save checks in packages.\n\n\nNEW FEATURES\nnormalizePath() has been moved to the base package (from\nutils): This is so it can be used by library() and friends.\nIt now does tilde expansion.\nIt gains new arguments winslash (to select the separator on\nWindows) and mustWork to control the action if a canonical path\ncannot be found.\nThe previously barely documented limit of 256 bytes on a symbol name\nhas been raised to 10,000 bytes (a sanity check). Long symbol names\ncan sometimes occur when deparsing expressions (for example, in\nmodel.frame).\nreformulate() gains a intercept argument.\ncmdscale(add = FALSE) now uses the more common definition that\nthere is a representation in n-1 or less dimensions, and only\ndimensions corresponding to positive eigenvalues are used. (Avoids\nconfusion such as PR#14397.)\nNames used by c(), unlist(), cbind() and rbind() are marked\nwith an encoding when this can be ascertained.\nR colours are now defined to refer to the sRGB color space.\nThe PDF, PostScript, and Quartz graphics devices record this fact.\nX11 (and Cairo) and Windows just assume that your screen conforms.\nsystem.file() gains a mustWork argument (suggestion of Bill\nDunlap).\nnew.env(hash = TRUE) is now the default.\nlist2env(envir = NULL) defaults to hashing (with a suitably sized\nenvironment) for lists of more than 100 elements.\ntext() gains a formula method.\nIQR() now has a type argument which is passed to quantile().\nas.vector(), as.double(), etc., duplicate less when they leave\nthe mode unchanged but remove attributes.\nas.vector(mode = \"any\") no longer duplicates when it does not\nremove attributes. This helps memory usage in matrix() and\narray().\nmatrix() duplicates less if data is an atomic vector with\nattributes such as names (but no class).\ndim(x) <- NULL duplicates less if x has neither dimensions nor\nnames (since this operation removes names and dimnames).\nsetRepositories() gains an addURLs argument.\nchisq.test() now also returns a stdres component, for\nstandardized residuals (which have unit variance, unlike the Pearson\nresiduals).\nwrite.table() and friends gain a fileEncoding argument, to\nsimplify writing files for use on other OSes (e.g. a spreadsheet\nintended for Windows or Mac OS X Excel).\nAssignment expressions of the form foo::bar(x) <- y and\nfoo:::bar(x) <- y now work; the replacement functions used are\nfoo::‘bar<-‘ and foo:::‘bar<-‘.\nSys.getenv() gains a names argument so\nSys.getenv(x, names = FALSE) can replace the common idiom of\nas.vector(Sys.getenv()). The default has been changed to not name\na length-one result.\nLazy loading of environments now preserves attributes and locked\nstatus. (The locked status of bindings and active bindings are still\nnot preserved; this may be addressed in the future).\noptions(\"install.lock\") may be set to FALSE so that\ninstall.packages() defaults to –no-lock installs, or (on\nWindows) to TRUE so that binary installs implement locking.\nsort(partial = p) for large p now tries Shellsort if quicksort\nis not appropriate and so works for non-numeric atomic vectors.\nsapply() gets a new option simplify = \"array\" which returns a\n“higher rank” array instead of just a matrix when FUN() returns a\ndim() length of two or more.\nreplicate() has this option set by default, and vapply() now\nbehaves that way internally.\naperm() becomes S3 generic and gets a table method which\npreserves the class.\nmerge() and as.hclust() methods for objects of class\n\"dendrogram\" are now provided.\nas.POSIXlt.factor() now passes ... to the character method\n(suggestion of Joshua Ulrich).\nThe character method of as.POSIXlt() now tries to find a format\nthat works for all non-NA inputs, not just the first one.\nstr() now has a method for class \"Date\" analogous to that for\nclass \"POSIXt\".\nNew function file.link() to create hard links on those file\nsystems (POSIX, NTFS but not FAT) that support them.\nNew Summary() group method for class \"ordered\" implements\nmin(), max() and range() for ordered factors.\nmostattributes<-() now consults the \"dim\" attribute and not the\ndim() function, making it more useful for objects (such as data\nframes) from classes with methods for dim(). It also uses\nattr<-() in preference to the generics name<-(), dim<-() and\ndimnames<-(). (Related to PR#14469.)\nThere is a new option \"browserNLdisabled\" to disable the use of an\nempty (e.g. via the ‘Return’ key) as a synonym for c in\nbrowser() or n under debug(). (Wish of PR#14472.)\nexample() gains optional new arguments character.only and\ngive.lines enabling programmatic exploration.\nserialize() and unserialize() are no longer described as\n‘experimental’. The interface is now regarded as stable, although\nthe serialization format may well change in future releases.\n(serialize() has a new argument version which would allow the\ncurrent format to be written if that happens.)\nNew functions saveRDS() and readRDS() are public versions of the\n‘internal’ functions .saveRDS() and .readRDS() made available\nfor general use. The dot-name versions remain available as several\npackage authors have made use of them, despite the documentation.\nsaveRDS() supports compress = \"xz\".\nMany functions when called with a not-open connection will now\nensure that the connection is left not-open in the event of error.\nThese include read.dcf(), dput(), dump(), load(), parse(),\nreadBin(), readChar(), readLines(), save(), writeBin(),\nwriteChar(), writeLines(), .readRDS(), .saveRDS() and\ntools::parse_Rd(), as well as functions calling these.\nPublic functions find.package() and path.package() replace the\ninternal dot-name versions.\nThe default method for terms() now looks for a \"terms\" attribute\nif it does not find a \"terms\" component, and so works for model\nframes.\nhttpd() handlers receive an additional argument containing the\nfull request headers as a raw vector (this can be used to parse\ncookies, multi-part forms etc.). The recommended full signature for\nhandlers is therefore function(url, query, body, headers, ...).\nfile.edit() gains a fileEncoding argument to specify the\nencoding of the file(s).\nThe format of the HTML package listings has changed. If there is\nmore than one library tree, a table of links to libraries is\nprovided at the top and bottom of the page. Where a library contains\nmore than 100 packages, an alphabetic index is given at the top of\nthe section for that library. (As a consequence, package names are\nnow sorted case-insensitively whatever the locale.)\nisSeekable() now returns FALSE on connections which have\nnon-default encoding. Although documented to record if ‘in\nprinciple’ the connection supports seeking, it seems safer to report\nFALSE when it may not work.\nR CMD REMOVE and remove.packages() now remove file R.css when\nremoving all remaining packages in a library tree. (Related to the\nwish of PR#14475: note that this file is no longer installed.)\nunzip() now has a unzip argument like zip.file.extract(). This\nallows an external unzip program to be used, which can be useful\nto access features supported by Info-ZIP’s unzip version 6 which\nis now becoming more widely available.\nThere is a simple zip() function, as wrapper for an external zip\ncommand.\nbzfile() connections can now read from concatenated bzip2 files\n(including files written with bzfile(open = \"a\")) and files\ncreated by some other compressors (such as the example of PR#14479).\nThe primitive function c() is now of type BUILTIN.\nplot(<dendrogram>, .., nodePar=*) now obeys an optional xpd\nspecification (allowing clipping to be turned off completely).\nnls(algorithm=\"port\") now shares more code with nlminb(), and is\nmore consistent with the other nls() algorithms in its return\nvalue.\nxz has been updated to 5.0.1 (very minor bugfix release).\nimage() has gained a logical useRaster argument allowing it to\nuse a bitmap raster for plotting a regular grid instead of polygons.\nThis can be more efficient, but may not be supported by all devices.\nThe default is FALSE.\nlist.files()/dir() gains a new argument include.dirs() to\ninclude directories in the listing when recursive = TRUE.\nNew function list.dirs() lists all directories, (even empty ones).\nfile.copy() now (by default) copies read/write/execute permissions\non files, moderated by the current setting of Sys.umask().\nSys.umask() now accepts mode = NA and returns the current\numask value (visibly) without changing it.\nThere is a ! method for classes \"octmode\" and \"hexmode\": this\nallows xor(a, b) to work if both a and b are from one of those\nclasses.\nas.raster() no longer fails for vectors or matrices containing\nNAs.\nNew hook \"before.new.plot\" allows functions to be run just before\nadvancing the frame in plot.new, which is potentially useful for\ncustom figure layout implementations.\nPackage tools has a new function compactPDF() to try to reduce\nthe size of PDF files via qpdf or gs.\ntar() has a new argument extra_flags.\ndotchart() accepts more general objects x such as 1D tables\nwhich can be coerced by as.numeric() to a numeric vector, with a\nwarning since that might not be appropriate.\nThe previously internal function create.post() is now exported\nfrom utils, and the documentation for bug.report() and\nhelp.request() now refer to that for create.post().\nIt has a new method = \"mailto\" on Unix-alikes similar to that on\nWindows: it invokes a default mailer via open (Mac OS X) or\nxdg-open or the default browser (elsewhere).\nThe default for ccaddress is now getOption(\"ccaddress\") which is\nby default unset: using the username as a mailing address nowadays\nrarely works as expected.\nThe default for options(\"mailer\") is now \"mailto\" on all\nplatforms.\nunlink() now does tilde-expansion (like most other file\nfunctions).\nfile.rename() now allows vector arguments (of the same length).\nThe \"glm\" method for logLik() now returns an \"nobs\" attribute\n(which stats4::BIC() assumed it did).\nThe \"nls\" method for logLik() gave incorrect results for zero\nweights.\nThere is a new generic function nobs() in package stats, to\nextract from model objects a suitable value for use in BIC\ncalculations. An S4 generic derived from it is defined in package\nstats4.\nCode for S4 reference-class methods is now examined for possible\nerrors in non-local assignments.\nfindClasses, getGeneric, findMethods and hasMethods are\nrevised to deal consistently with the package= argument and be\nconsistent with soft namespace policy for finding objects.\ntools::Rdiff() now has the option to return not only the status\nbut a character vector of observed differences (which are still by\ndefault sent to stdout).\nThe startup environment variables , , and are now treated more\nconsistently. In all cases an empty value is considered to be set\nand will stop the default being used, and for the last two tilde\nexpansion is performed on the file name. (Note that setting an empty\nvalue is probably impossible on Windows.)\nUsing R –no-environ CMD, R –no-site-file CMD or\nR –no-init-file CMD sets environment variables so these settings\nare passed on to child R processes, notably those run by INSTALL,\ncheck and build. R –vanilla CMD sets these three options (but\nnot –no-restore).\nsmooth.spline() is somewhat faster. With cv=NA it allows some\nleverage computations to be skipped,\nThe internal (C) function scientific(), at the heart of R’s\nformat.info(x), format(x), print(x), etc, for numeric x, has\nbeen re-written in order to provide slightly more correct results,\nfixing PR#14491, notably in border cases including when\ndigits >= 16, thanks to substantial contributions (code and\nexperiments) from Petr Savicky. This affects a noticable amount of\nnumeric output from R.\nA new function grepRaw() has been introduced for finding subsets\nof raw vectors. It supports both literal searches and regular\nexpressions.\nPackage compiler is now provided as a standard package. See\n?compiler::compile for information on how to use the compiler.\nThis package implements a byte code compiler for R: by default the\ncompiler is not used in this release. See the ‘R Installation and\nAdministration Manual’ for how to compile the base and recommended\npackages.\nProviding an exportPattern directive in a NAMESPACE file now\ncauses classes to be exported according to the same pattern, for\nexample the default from package.skeleton() to specify all names\nstarting with a letter. An explicit directive to\nexportClassPattern will still over-ride.\nThere is an additional marked encoding \"bytes\" for character\nstrings. This is intended to be used for non-ASCII strings which\nshould be treated as a set of bytes, and never re-encoded as if they\nwere in the encoding of the currrent locale: useBytes = TRUE is\nautmatically selected in functions such as writeBin(),\nwriteLines(), grep() and strsplit().\nOnly a few character operations are supported (such as substr()).\nPrinting, format() and cat() will represent non-ASCII bytes in\nsuch strings by a \\\\xab escape.\nThe new function removeSource() removes the internally stored\nsource from a function.\n\"srcref\" attributes now include two additional line number values,\nrecording the line numbers in the order they were parsed.\nNew functions have been added for source reference access:\ngetSrcFilename(), getSrcDirectory(), getSrcLocation() and\ngetSrcref().\nSys.chmod() has an extra argument use_umask which defaults to\ntrue and restricts the file mode by the current setting of umask.\nThis means that all the R functions which manipulate file/directory\npermissions by default respect umask, notably R CMD INSTALL.\ntempfile() has an extra argument fileext to create a temporary\nfilename with a specified extension. (Suggestion and initial\nimplementation by Dirk Eddelbuettel.)\nThere are improvements in the way Sweave() and Stangle() handle\nnon-ASCII vignette sources, especially in a UTF-8 locale: see\n‘Writing R Extensions’ which now has a subsection on this topic.\nfactanal() now returns the rotation matrix if a rotation such as\n\"promax\" is used, and hence factor correlations are displayed.\n(Wish of PR#12754.)\nThe gctorture2() function provides a more refined interface to the\nGC torture process. Environment variables , , and can also be used\nto control the GC torture process.\nfile.copy(from, to) no longer regards it as an error to supply a\nzero-length from: it now simply does nothing.\nrstandard.glm gains a type argument which can be used to request\nstandardized Pearson residuals.\nA start on a Turkish translation, thanks to Murat Alkan.\n.libPaths() calls normalizePath(winslash = \"/\") on the paths:\nthis helps (usually) present them in a user-friendly form and should\ndetect duplicate paths accessed via different symbolic links.\n\n\nSWEAVE CHANGES\nSweave() has options to produce PNG and JPEG figures, and to use a\ncustom function to open a graphics device (see ?RweaveLatex).\n(Based in part on the contribution of PR#14418.)\nThe default for Sweave() is to produce only PDF figures (rather\nthan both EPS and PDF).\nEnvironment variable can be used to supply defaults for existing or\nnew options to be applied after the Sweave driver setup has been\nrun.\nThe Sweave manual is now included as a vignette in the utils\npackage.\nSweave() handles keep.source=TRUE much better: it could\nduplicate some lines and omit comments. (Reported by John Maindonald\nand others.)\n\n\nC-LEVEL FACILITIES\nBecause they use a C99 interface which a C++ compiler is not\nrequired to support, Rvprintf and REvprintf are only defined by\nR_ext/Print.h in C++ code if the macro R_USE_C99_IN_CXX is\ndefined when it is included.\npythag duplicated the C99 function hypot. It is no longer\nprovided, but is used as a substitute for hypot in the very\nunlikely event that the latter is not available.\nR_inspect(obj) and R_inspect3(obj, deep, pvec) are (hidden)\nC-level entry points to the internal inspect function and can be\nused for C-level debugging (e.g., in conjunction with the p\ncommand in gdb).\nCompiling R with –enable-strict-barrier now also enables\nadditional checking for use of unprotected objects. In combination\nwith gctorture() or gctorture2() and a C-level debugger this can\nbe useful for tracking down memory protection issues.\n\n\nUTILITIES\nR CMD Rdiff is now implemented in R on Unix-alikes (as it has been\non Windows since R 2.12.0).\nR CMD build no longer does any cleaning in the supplied package\ndirectory: all the cleaning is done in the copy.\nIt has a new option –install-args to pass arguments to\nR CMD INSTALL for –build (but not when installing to rebuild\nvignettes).\nThere is new option, –resave-data, to call\ntools::resaveRdaFiles() on the data directory, to compress\ntabular files (.tab, .csv etc) and to convert .R files to\n.rda files. The default, –resave-data=gzip, is to do so in a way\ncompatible even with years-old versions of R, but better compression\nis given by –resave-data=best, requiring R >= 2.10.0.\nIt now adds a datalist file for data directories of more than\n1Mb.\nPatterns in .Rbuildignore are now also matched against all\ndirectory names (including those of empty directories).\nThere is a new option, –compact-vignettes, to try reducing the\nsize of PDF files in the inst/doc directory. Currently this tries\nqpdf: other options may be used in future.\nWhen re-building vignettes and a inst/doc/Makefile file is found,\nmake clean is run if the makefile has a clean: target.\nAfter re-building vignettes the default clean-up operation will\nremove any directories (and not just files) created during the\nprocess: e.g. one package created a .R_cache directory.\nEmpty directories are now removed unless the option\n–keep-empty-dirs is given (and a few packages do deliberately\ninclude empty directories).\nIf there is a field BuildVignettes in the package DESCRIPTION\nfile with a false value, re-building the vignettes is skipped.\nR CMD check now also checks for filenames that are\ncase-insensitive matches to Windows’ reserved file names with\nextensions, such as nul.Rd, as these have caused problems on some\nWindows systems.\nIt checks for inefficiently saved data/*.rda and data/*.RData\nfiles, and reports on those large than 100Kb. A more complete check\n(including of the type of compression, but potentially much slower)\ncan be switched on by setting environment variable to TRUE.\nThe types of files in the data directory are now checked, as\npackages are still misusing it for non-R data files.\nIt now extracts and runs the R code for each vignette in a separate\ndirectory and R process: this is done in the package’s declared\nencoding. Rather than call tools::checkVignettes(), it calls\ntool::buildVignettes() to see if the vignettes can be re-built as\nthey would be by R CMD build. Option –use-valgrind now applies\nonly to these runs, and not when running code to rebuild the\nvignettes. This version does a much better job of suppressing output\nfrom successful vignette tests.\nThe 00check.log file is a more complete record of what is output\nto stdout: in particular contains more details of the tests.\nIt now check all syntactically valid Rd usage entries, and warns\nabout assignments (unless these give the usage of replacement\nfunctions).\n.tar.xz compressed tarballs are now allowed, if tar supports\nthem (and setting environment variable to internal ensures so on\nall platforms).\nR CMD check now warns if it finds inst/doc/makefile, and\nR CMD build renames such a file to inst/doc/Makefile.\n\n\nINSTALLATION\nInstalling R no longer tries to find perl, and R CMD no longer\ntries to substitute a full path for awk nor perl – this was a\nlegacy from the days when they were used by R itself. Because a\ncouple of packages do use awk, it is set as the make (rather\nthan environment) variable .\nmake check will now fail if there are differences from the\nreference output when testing package examples and if environment\nvariable is set to a true value.\nThe C99 double complex type is now required.\nThe C99 complex trigonometric functions (such as csin) are not\ncurrently required (FreeBSD lacks most of them): substitutes are\nused if they are missing.\nThe C99 system call va_copy is now required.\nIf environment variable is set during configuration (for example in\nconfig.site) it is used unchanged in file etc/ldpaths rather\nthan being appended to.\nconfigure looks for support for OpenMP and if found compiles R\nwith appropriate flags and also makes them available for use in\npackages: see ‘Writing R Extensions’.\nThis is currently experimental, and is only used in R with a single\nthread for colSums() and colMeans(). Expect it to be more widely\nused in later versions of R.\nThis can be disabled by the –disable-openmp flag.\n\n\nPACKAGE INSTALLATION\nR CMD INSTALL –clean now removes copies of a src directory which\nare created when multiple sub-architectures are in use. (Following a\ncomment from Berwin Turlach.)\nFile R.css is now installed on a per-package basis (in the\npackage’s html directory) rather than in each library tree, and\nthis is used for all the HTML pages in the package. This helps when\ninstalling packages with static HTML pages for use on a webserver.\nIt will also allow future versions of R to use different stylesheets\nfor the packages they install.\nA top-level file .Rinstignore in the package sources can list (in\nthe same way as .Rbuildignore) files under inst that should not\nbe installed. (Why should there be any such files? Because all the\nfiles needed to re-build vignettes need to be under inst/doc, but\nthey may not need to be installed.)\nR CMD INSTALL has a new option –compact-docs to compact any PDFs\nunder the inst/doc directory. Currently this uses qpdf, which\nmust be installed (see ‘Writing R Extensions’).\nThere is a new option –lock which can be used to cancel the effect\nof –no-lock or –pkglock earlier on the command line.\nOption –pkglock can now be used with more than one package, and is\nnow the default if only one package is specified.\nArgument lock of install.packages() can now be use for Mac\nbinary installs as well as for Windows ones. The value \"pkglock\"\nis now accepted, as well as TRUE and FALSE (the default).\nThere is a new option –no-clean-on-error for R CMD INSTALL to\nretain a partially installed package for forensic analysis.\nPackages with names ending in . are not portable since Windows\ndoes not work correctly with such directory names. This is now\nwarned about in R CMD check, and will not be allowed in R 2.14.x.\nThe vignette indices are more comprehensive (in the style of\nbrowseVignetttes()).\n\n\nDEPRECATED & DEFUNCT\nrequire(save = TRUE) is defunct, and use of the save argument is\ndeprecated.\nR CMD check –no-latex is defunct: use –no-manual instead.\nR CMD Sd2Rd is defunct.\nThe gamma argument to hsv(), rainbow(), and rgb2hsv() is\ndeprecated and no longer has any effect.\nThe previous options for R CMD build –binary (–auto-zip,\n–use-zip-data and –no-docs) are deprecated (or defunct): use the\nnew option –install-args instead.\nWhen a character value is used for the EXPR argument in\nswitch(), only a single unnamed alternative value is now allowed.\nThe wrapper utils::link.html.help() is no longer available.\nZip-ing data sets in packages (and hence R CMD INSTALL options\n–use-zip-data and –auto-zip, as well as the ZipData: yes field\nin a DESCRIPTION file) is defunct.\nInstalled packages with zip-ed data sets can still be used, but a\nwarning that they should be re-installed will be given.\nThe ‘experimental’ alternative specification of a name space via\n.Export() etc is now defunct.\nThe option –unsafe to R CMD INSTALL is deprecated: use the\nidentical option –no-lock instead.\nThe entry point pythag in Rmath.h is deprecated in favour of the\nC99 function hypot. A wrapper for hypot is provided for R 2.13.x\nonly.\nDirect access to the \"source\" attribute of functions is\ndeprecated; use deparse(fn, control=\"useSource\") to access it, and\nremoveSource(fn) to remove it.\nR CMD build –binary is now formally deprecated:\nR CMD INSTALL –build has long been the preferred alternative.\nSingle-character package names are deprecated (and R is already\ndisallowed to avoid confusion in Depends: fields).\n\n\nBUG FIXES\ndrop.terms and the [ method for class \"terms\" no longer add\nback an intercept. (Reported by Niels Hansen.)\naggregate preserves the class of a column (e.g. a date) under some\ncircumstances where it discarded the class previously.\np.adjust() now always returns a vector result, as documented. In\nprevious versions it copied attributes (such as dimensions) from the\np argument: now it only copies names.\nOn PDF and PostScript devices, a line width of zero was recorded\nverbatim and this caused problems for some viewers (a very thin line\ncombined with a non-solid line dash pattern could also cause a\nproblem). On these devices, the line width is now limited at 0.01\nand for very thin lines with complex dash patterns the device may\nforce the line dash pattern to be solid. (Reported by Jari Oksanen.)\nThe str() method for class \"POSIXt\" now gives sensible output\nfor 0-length input.\nThe one- and two-argument complex maths functions failed to warn if\nNAs were generated (as their numeric analogues do).\nAdded .requireCachedGenerics to the dont.mind list for\nlibrary() to avoid warnings about duplicates.\n$<-.data.frame messed with the class attribute, breaking any S4\nsubclass. The S4 data.frame class now has its own $<- method,\nand turns dispatch on for this primitive.\nMap() did not look up a character argument f in the correct\nframe, thanks to lazy evaluation. (PR#14495)\nfile.copy() did not tilde-expand from and to when to was a\ndirectory. (PR#14507)\nIt was possible (but very rare) for the loading test in\nR CMD INSTALL to crash a child R process and so leave around a\nlock directory and a partially installed package. That test is now\ndone in a separate process.\nplot(<formula>, data=<matrix>,..) now works in more cases;\nsimilarly for points(), lines() and text().\nedit.default() contained a manual dispatch for matrices (the\n\"matrix\" class didn’t really exist when it was written). This\ncaused an infinite recursion in the no-GUI case and has now been\nremoved.\ndata.frame(check.rows = TRUE) sometimes worked when it should have\ndetected an error. (PR#14530)\nscan(sep= , strip.white=TRUE) sometimes stripped trailing spaces\nfrom within quoted strings. (The real bug in PR#14522.)\nThe rank-correlation methods for cor() and cov() with\nuse = \"complete.obs\" computed the ranks before removing missing\nvalues, whereas the documentation implied incomplete cases were\nremoved first. (PR#14488)\nThey also failed for 1-row matrices.\nThe perpendicular adjustment used in placing text and expressions in\nthe margins of plots was not scaled by par(\"mex\"). (Part of\nPR#14532.)\nQuartz Cocoa device now catches any Cocoa exceptions that occur\nduring the creation of the device window to prevent crashes. It also\nimposes a limit of \\(144 \\text{ft}^2\\) on the area used by a window to\ncatch user errors (unit misinterpretation) early.\nThe browser (invoked by debug(), browser() or otherwise) would\ndisplay attributes such as \"wholeSrcref\" that were intended for\ninternal use only.\nR’s internal filename completion now properly handles filenames with\nspaces in them even when the readline library is used. This resolves\nPR#14452 provided the internal filename completion is used (e.g., by\nsetting rc.settings(files = TRUE)).\nInside uniroot(f, ...), -Inf function values are now replaced by\na maximally negative value.\nrowsum() could silently over/underflow on integer inputs (reported\nby Bill Dunlap).\nas.matrix() did not handle \"dist\" objects with zero rows.\n\nCHANGES IN R VERSION 2.12.2 patched\n\nNEW FEATURES\nmax() and min() work harder to ensure that NA has precedence\nover NaN, so e.g. min(NaN, NA) is NA. (This was not previously\ndocumented except for within a single numeric vector, where compiler\noptimizations often defeated the code.)\n\n\nBUG FIXES\nA change to the C function R_tryEval had broken error messages in\nS4 method selection; the error message is now printed.\nPDF output with a non-RGB color model used RGB for the line stroke\ncolor. (PR#14511)\nstats4::BIC() assumed without checking that an object of class\n\"logLik\" has an \"nobs\" attribute: glm() fits did not and so\nBIC() failed for them.\nIn some circumstances a one-sided mantelhaen.test() reported the\np-value for the wrong tail. (PR#14514)\nPassing the invalid value lty = NULL to axis() sent an invalid\nvalue to the graphics device, and might cause the device to\nsegfault.\nSweave() with concordance=TRUE could lead to invalid PDF files;\nSweave.sty has been updated to avoid this.\nNon-ASCII characters in the titles of help pages were not rendered\nproperly in some locales, and could cause errors or warnings.\ncheckRd() gave a spurious error if the \\\\href macro was used.\n\nCHANGES IN R VERSION 2.12.2\n\nSIGNIFICANT USER-VISIBLE CHANGES\nComplex arithmetic (notably z^n for complex z and integer n)\ngave incorrect results since R 2.10.0 on platforms without C99\ncomplex support. This and some lesser issues in trignometric\nfunctions have been corrected.\nSuch platforms were rare (we know of Cygwin and FreeBSD). However,\nbecause of new compiler optimizations in the way complex arguments\nare handled, the same code was selected on x86_64 Linux with\ngcc 4.5.x at the default -O2 optimization (but not at -O).\nThere is a workaround for crashes seen with several packages on\nsystems using zlib 1.2.5: see the INSTALLATION section.\n\n\nNEW FEATURES\nPCRE has been updated to 8.12 (two bug-fix releases since 8.10).\nrep(), seq(), seq.int() and seq_len() report more often when\nthe first element is taken of an argument of incorrect length.\nThe Cocoa back-end for the quartz() graphics device on Mac OS X\nprovides a way to disable event loop processing temporarily (useful,\ne.g., for forked instances of R).\nkernel()’s default for m was not appropriate if coef was a set\nof coefficients. (Reported by Pierre Chausse.)\nbug.report() has been updated for the current R bug tracker, which\ndoes not accept emailed submissions.\nR CMD check now checks for the correct use of $(LAPACK_LIBS) (as\nwell as $(BLAS_LIBS)), since several CRAN recent submissions have\nignored ‘Writing R Extensions’.\n\n\nINSTALLATION\nThe zlib sources in the distribution are now built with all\nsymbols remapped: this is intended to avoid problems seen with\npackages such as XML and rggobi which link to zlib.so.1 on\nsystems using zlib 1.2.5.\nThe default for and with gfortran on x86_64 Linux has been changed\nback to -g -O2: however, setting -g -O may still be needed for\ngfortran 4.3.x.\n\n\nPACKAGE INSTALLATION\nA LazyDataCompression field in the DESCRIPTION file will be used\nto set the value for the –data-compress option of R CMD INSTALL.\nFiles R/sysdata.rda of more than 1Mb are now stored in the\nlazyload database using xz compression: this for example halves\nthe installed size of package Imap.\nR CMD INSTALL now ensures that directories installed from inst\nhave search permission for everyone.\nIt no longer installs files inst/doc/Rplots.ps and\ninst/doc/Rplots.pdf. These are almost certainly left-overs from\nSweave runs, and are often large.\n\n\nDEPRECATED & DEFUNCT\nThe ‘experimental’ alternative specification of a name space via\n.Export() etc is now deprecated.\nzip.file.extract() is now deprecated.\nZip-ing data sets in packages (and hence\nR CMD INSTALL –use-zip-data and the ZipData: yes field in a\nDESCRIPTION file) is deprecated: using efficiently compressed\n.rda images and lazy-loading of data has superseded it.\n\n\nBUG FIXES\nidentical() could in rare cases generate a warning about\nnon-pairlist attributes on CHARSXPs. As these are used for internal\npurposes, the attribute check should be skipped. (Reported by Niels\nRichard Hansen).\nIf the filename extension (usually .Rnw) was not included in a\ncall to Sweave(), source references would not work properly and\nthe keep.source option failed. (PR#14459)\nformat.data.frame() now keeps zero character column names.\npretty(x) no longer raises an error when x contains solely\nnon-finite values. (PR#14468)\nThe plot.TukeyHSD() function now uses a line width of 0.5 for its\nreference lines rather than lwd = 0 (which caused problems for\nsome PDF and PostScript viewers).\nThe big.mark argument to prettyNum(), format(), etc. was\ninserted reversed if it was more than one character long.\nR CMD check failed to check the filenames under man for Windows’\nreserved names.\nThe \"Date\" and \"POSIXt\" methods for seq() could overshoot when\nto was supplied and by was specified in months or years.\nThe internal method of untar() now restores hard links as file\ncopies rather than symbolic links (which did not work for\ncross-directory links).\nunzip() did not handle zip files which contained filepaths with\ntwo or more leading directories which were not in the zipfile and\ndid not already exist. (It is unclear if such zipfiles are valid and\nthe third-party C code used did not support them, but PR#14462\ncreated one.)\ncombn(n, m) now behaves more regularly for the border case\n\\(m = 0\\). (PR#14473)\nThe rendering of numbers in plotmath expressions (e.g.\nexpression(10^2)) used the current settings for conversion to\nstrings rather than setting the defaults, and so could be affected\nby what has been done before. (PR#14477)\nThe methods of napredict() and naresid() for\nna.action = na.exclude fits did not work correctly in the very\nrare event that every case had been omitted in the fit. (Reported by\nSimon Wood.)\nweighted.residuals(drop0=TRUE) returned a vector when the\nresiduals were a matrix (e.g. those of class \"mlm\"). (Reported by\nBill Dunlap.)\nPackage HTML index files <pkg>/html/00Index.html were generated\nwith a stylesheet reference that was not correct for static browsing\nin libraries.\nccf(na.action = na.pass) was not implemented.\nThe parser accepted some incorrect numeric constants, e.g. 20x2.\n(Reported by Olaf Mersmann.)\nformat(*, zero.print) did not always replace the full zero parts.\nFixes for subsetting or subassignment of \"raster\" objects when not\nboth i and j are specified.\nR CMD INSTALL was not always respecting the ZipData: yes field\nof a DESCRIPTION file (although this is frequently incorrectly\nspecified for packages with no data or which specify lazy-loading of\ndata).\nR CMD INSTALL –use-zip-data was incorrectly implemented as\n–use-zipdata since R 2.9.0.\nsource(file, echo=TRUE) could fail if the file contained #line\ndirectives. It now recovers more gracefully, but may still display\nthe wrong line if the directive gives incorrect information.\natan(1i) returned NaN+Infi (rather than 0+Infi) on platforms\nwithout C99 complex support.\nlibrary() failed to cache S4 metadata (unlike loadNamespace())\ncausing failures in S4-using packages without a namespace (e.g.\nthose using reference classes).\nThe function qlogis(lp, log.p=TRUE) no longer prematurely\noverflows to Inf when exp(lp) is close to 1.\nUpdating S4 methods for a group generic function requires resetting\nthe methods tables for the members of the group (patch contributed\nby Martin Morgan).\nIn some circumstances (including for package XML), R CMD INSTALL\ninstalled version-control directories from source packages.\nAdded PROTECT calls to some constructed expressions used in C\nlevel eval calls.\nutils:::create.post() (used by bug.report() and\nhelp.request()) failed to quote arguments to the mailer, and so\noften failed.\nbug.report() was naive about how to extract maintainer email\naddresses from package descriptions, so would often try mailing to\nincorrect addresses.\ndebugger() could fail to read the environment of a call to a\nfunction with a ... argument. (Reported by Charlie Roosen.)\nprettyNum(c(1i, NA), drop0=TRUE) or str(NA_complex_) now work\ncorrectly.\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2011-1-r-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2011-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2011-06-01",
    "categories": [],
    "contents": "\n1 Donations and new members\nDonations\nJoseph J. Allaire, RStudio Inc., USA\nJ. Brian Loria, USA\nJeffrey R. Stevens, Germany\nNew benefactors\nJoseph J. Allaire, RStudio Inc., USA\nNew supporting members\nMasoud Charkhabi, Canada\nJames Davis, USA\nPatrick Hausmann, Germany\nSebastian Germany\nDieter Menne, Germany\nFausto Molinari, Sweden\nStefan Wyder, Switzerland\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2010-2-bioconductor/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2010-2 issue.",
    "author": [
      {
        "name": "Bioconductor Team",
        "url": {}
      }
    ],
    "date": "2010-12-01",
    "categories": [],
    "contents": "\n\nWe are pleased to announce Bioconductor 2.7, released on October 18,\n2010. Bioconductor 2.7 is compatible with R 2.12.0, and consists of 419\npackages. There are 34 new packages, and enhancements to many others.\nExplore Bioconductor at http://bioconductor.org, and install packages\nwith\n> source(\"http://bioconductor.org/biocLite.R\")\n> biocLite() # install standard packages...\n> biocLite(\"IRanges\") # ...or IRanges\n1 New and revised packages\nThis release includes new packages for diverse areas of high-throughput\nanalysis. Highlights include:\nNext-generation sequencing\n\npackages for ChIP\n(iSeq,\nRMAPPER),\nmethylated DNA immunoprecipitation\n(MEDIPS),\nand RNA-seq\n(rnaSeqMap)\nwork flows, 454 sequencing\n(R453Plus1Toolbox)\nand management of microbial sequences\n(OTUbase).\n\nMicroarray\n\nanalysis of domain-specific applications (array CGH,\nADaCGH2;\ntiling arrays,\nles;\nmiRNA,\nLVSmiRNA;\nand bead arrays,\nMBCB);\nspecialized statistical methods\n(fabia,\nfarms,\nRDRToolbox),\nand graphical tools\n(IsoGeneGUI).\n\nGene set, network, and graph\n\noriented approaches and tools include\ngage,\nHTSanalyzeR,\nPatientGeneSets,\nBioNet,\nnetresponse,\nattract,\nCoGAPS,\nontoCAT,\nDEgraph,\nNTW,\nand\nRCytoscape.\n\nAdvanced statistical and modeling implementations\n\nrelevant to high-throughtput genetic analysis include\nBHC\n(Bayesian Hierarchical Clustering),\nCGEN\n(case-control studies in genetic epidemiology), and\nSQUADD.\n\nImage, cell-based, and other assay\n\npackages, include\nimageHTS,\nCRImage,\ncoRNAi,\nGeneGA,\nNuPoP.\n\nOur large collection of microarray- and organism-specific annotation\npackages have been updated to include information current at the time of\nthe Bioconductor release. These annotation packages contain biological\ninformation about microarray probes and the genes they are meant to\ninterrogate, or contain gene-based annotations of whole genomes. They\nare particularly valuable in providing stable annotations for repeatable\nresearch.\nSeveral developments in packages maintained by the Bioconductor core\nteam are noteworthy. The graphBAM class in the\ngraph\npackage is available to manipulate very large graphs. The\nGenomicRanges,\nGenomicFeatures,\nand\nBiostrings\npackages have enhanced classes such as TranscriptDb for representing\ngenome-scale ‘track’ annotations from common data resources,\nMultipleAlignment for manipulating reference (and other\nmoderate-length) sequences in a microbiome project, and\nSummarizedExperiment to collate range-based count data across samples\nin sequence experiments. The\nchipseq\npackage has enhanced functionality for peak calling, and has been\nupdated to use current data structures.\nFurther information on new and existing packages can be found on the\nBioconductor web site, which contains ‘views’ that identify coherent\ngroups of packages. The views link to on-line package descriptions,\nvignettes, reference manuals, and use statistics.\n2 Other activities\nThe Bioconductor community met on July 28-30 at our annual conference in\nSeattle for a combination of scientific talks and hands-on tutorials,\nand on November 17-18 in Heidelberg, Germany for a meeting highlight\ncontributions from the European developer community. The active\nBioconductor mailing lists\n(http://bioconductor.org/docs/mailList.html) connect users with each\nother, to domain experts, and to maintainers eager to ensure that their\npackages satisfy the needs of leading edge approaches. Bioconductor\npackage maintainers and the Bioconductor team invest considerable effort\nin producing high-quality software. The Bioconductor team continues to\nensure quality software through technical and scientific reviews of new\npackages, and daily builds of released packages on Linux, Windows, and\nMacintosh platforms.\n3 Looking forward\nContributions from the Bioconductor community play an important role in\nshaping each release. We anticipate continued efforts to provide\nstatistically informed analysis of next generation sequence data,\nespecially in the down-stream analysis of comprehensive, designed\nsequencing experiments and integrative analyses. The next release cycle\npromises to be one of active scientific growth and exploration.\n\n\nBioconductor packages used\niSeq, RMAPPER, MEDIPS, rnaSeqMap, R453Plus1Toolbox, OTUbase, ADaCGH2, les, LVSmiRNA, MBCB, fabia, farms, RDRToolbox, IsoGeneGUI, gage, HTSanalyzeR, PatientGeneSets, BioNet, netresponse, attract, CoGAPS, ontoCAT, DEgraph, NTW, RCytoscape, BHC, CGEN, SQUADD, imageHTS, CRImage, coRNAi, GeneGA, NuPoP, graph, GenomicRanges, GenomicFeatures, Biostrings, chipseq\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2010-2-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2010-2 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2010-12-01",
    "categories": [],
    "contents": "\n\n1 New CRAN task views\nOfficialStatistics\n\nTopic: Official Statistics & Survey Methodology. Maintainer:\nMatthias Templ. Packages: Amelia, EVER, Hmisc, MImix,\nRecordLinkage, SDaA, SeqKnn, StatMatch, TeachingSampling,\nVIM, cat, impute, ineq, laeken, lme4, memisc, mi,\nmicEcon, mice, missMDA, mitools, mix, nlme, norm,\nodfWeave.survey, pan, pps, reweight, robCompositions,\nrrcovNA, sampfling, sampling, samplingbook, sdcMicro,\nsdcTable, simFrame, simPopulation, spsurvey,\nstratification, survey\\(^*\\), surveyNG, urn, x12,\nyaImpute.\n\nReproducibleResearch\n\nTopic: Reproducible Research. Maintainer: Max Kuhn. Packages:\nDesign\\(^*\\), Hmisc\\(^*\\), R.cache, R.rsp, R2HTML\\(^*\\),\nR2PPT, R2wd, SRPM, SweaveListingUtils, TeachingSampling,\nanimation, apsrtable, ascii, brew, cacheSweave, cxxPack,\nexams, highlight, hwriter, memisc, odfWeave,\nodfWeave.survey, pgfSweave, quantreg, r2lh, reporttools,\nrms\\(^*\\), svSweave, tikzDevice, xtable\\(^*\\).\n\n(* = core package)\nNew packages in CRAN task views\nBayesian\n\nRatings, RxCEcolInf, SimpleTable, spikeslab.\n\nChemPhys\n\nOrgMassSpecR, plsRglm\\(^*\\), solaR.\n\nClinicalTrials\n\nDoseFinding, MCPMod.\n\nDistributions\n\nmc2d, nacopula, truncnorm.\n\nEnvironmetrics\n\nDSpat, SPACECAP, secr.\n\nExperimentalDesign\n\nDoseFinding.\n\nFinance\n\norderbook, rrv, schwartz97.\n\nHighPerformanceComputing\n\ngcbd, magma, rpud.\n\nMachineLearning\n\nBoruta, LiblineaR, LogicForest, LogicReg, RSNNS, SDDA,\nhda, quantregForest, rda, rgp, sda.\n\nMedicalImaging\n\nRNiftyReg\\(^*\\), dpmixsim\\(^*\\), mritc\\(^*\\).\n\nOptimization\n\nRcgmin, Rsolnp\\(^*\\), Rvmmin, minqa\\(^*\\), optimx\\(^*\\).\n\nPsychometrics\n\nQuantPsyc, REQS, catR, equate, plsRglm.\n\nSpatial\n\nCompRandFld, MarkedPointProcess, constrainedKriging,\ndivagis, geosphere, raster\\(^*\\), sparr, sphet, vardiag.\n\nSurvival\n\naster, aster2, censReg, exactRankTests, glrt, saws,\nsimexaft, spef, splinesurv, survPresmooth.\n\nTimeSeries\n\nMARSS, TSAgg, mondate, pomp.\n\ngR\n\ncatnet.\n\n(* = core package)\n2 New contributed packages\nACCLMA\n\nACC & LMA Graph Plotting. Authors: Tal Carmi, Liat Gaziel.\n\nAMA\n\nAnderson-Moore Algorithm. Authors: Gary Anderson, Aneesh\nRaghunandan.\n\nAllPossibleSpellings\n\nComputes all of a word’s possible spellings. Author: Antoine\nTremblay, IWK Health Center.\n\nBMS\n\nBayesian Model Averaging Library. Authors: Martin Feldkircher and\nStefan Zeugner. In view:\nBayesian.\n\nBayHap\n\nBayesian analysis of haplotype association using Markov Chain Monte\nCarlo. Authors: Raquel Iniesta and Victor Moreno.\n\nBenchmarking\n\nBenchmark and frontier analysis using DEA and SFA (BeDS). Authors:\nPeter Bogetoft and Lars Otto.\n\nBlakerCI\n\nBlaker’s binomial confidence limits. Author: J. Klaschka.\n\nCFL\n\nCompensatory Fuzzy Logic. Authors: Pablo Michel Marin Ortega,\nKornelius Rohmeyer.\n\nCNVassoc\n\nAssociation analysis of CNV data. Authors: Juan R González, Isaac\nSubirana.\n\nCOSINE\n\nCOndition SpecIfic sub-NEtwork. Author: Haisu Ma.\n\nCOUNT\n\nFunctions, data and code for count data. Author: Joseph M Hilbe.\n\nCkmeans.1d.dp\n\nOptimal distance-based clustering for one-dimensional data. Authors:\nJoe Song and Haizhou Wang.\n\nClustOfVar\n\nClustering of variables. Authors: Marie Chavent and Vanessa Kuentz\nand Benoit Liquet and Jerome Saracco.\n\nCompQuadForm\n\nDistribution function of quadratic forms in normal variables.\nAuthor: P. Lafaye de Micheaux.\n\nCompRandFld\n\nComposite-likelihood based Analysis of Random Fields. Authors:\nSimone Padoan, Moreno Bevilacqua. In view:\nSpatial.\n\nDCGL\n\nDifferential Coexpression Analysis of Gene Expression Microarray\nData. Authors: Bao-Hong Liu, Hui Yu.\n\nDECIDE\n\nDEComposition of Indirect and Direct Effects. Author: Christiana\nKartsonaki.\n\nDMwR\n\nFunctions and data for “Data Mining with R”. Author: Luis Torgo.\n\nDNAtools\n\nTools for analysing forensic genetic DNA data. Authors: Torben\nTvedebrink and James Curran.\n\nDeducerExtras\n\nAdditional dialogs and functions for Deducer. Author: Ian Fellows.\n\nDeducerPlugInScaling\n\nReliability and factor analysis plugin. Authors: Alberto Mirisola\nand Ian Fellows.\n\nDiceView\n\nPlot methods for computer experiments design and models. Authors:\nYann Richet, Yves Deville, Clement Chevalier.\n\nEMA\n\nEasy Microarray data Analysis. Author: EMA group.\n\nEquiNorm\n\nNormalize expression data using equivalently expressed genes.\nAuthors: Li-Xuan Qin, Jaya M. Satagopan.\n\nFAwR\n\nFunctions and Datasets for “Forest Analytics with R”. Authors:\nAndrew Robinson and Jeff Hamann.\n\nFeaLect\n\nScores features for Feature seLection. Author: Habil Zare.\n\nFitARMA\n\nFitARMA: Fit ARMA or ARIMA using fast MLE algorithm. Author: A.I.\nMcLeod.\n\nFourierDescriptors\n\nGenerate images using Fourier descriptors. Author: John Myles White.\n\nGAD\n\nGeneral ANOVA Design (GAD): Analysis of variance from general\nprinciples. Author: Leonardo Sandrini-Neto & Mauricio G. Camargo.\n\nGPseq\n\nUsing the generalized Poisson distribution to model sequence read\ncounts from high throughput sequencing experiments. Authors: Sudeep\nSrivastava, Liang Chen.\n\nGWASExactHW\n\nExact Hardy-Weinburg testing for Genome Wide Association Studies.\nAuthor: Ian Painter, GENEVA project, University of Washington.\n\nHDclassif\n\nHigh Dimensionnal Classification. Authors: R. Aidan, L. Berge, C.\nBouveyron, S. Girard.\n\nHWEintrinsic\n\nObjective Bayesian Testing for the Hardy-Weinberg Equilibrium\nProblem. Author: Sergio Venturini.\n\nHapEstXXR\n\nHaplotype-based analysis of association for genetic traits. Authors:\nSven Knueppel and Klaus Rohde.\n\nHumMeth27QCReport\n\nQuality control and preprocessing of Illumina’s Infinium\nHumanMethylation27 BeadChip methylation assay. Author: F.M. Mancuso.\n\nIMIS\n\nIncremental Mixture Importance Sampling. Authors: Adrian Raftery, Le\nBao.\n\nImpactIV\n\nIdentifying Causal Effect for Multi-Component Intervention Using\nInstrumental Variable Method. Author: Peng Ding.\n\nIniStatR\n\nInitiation à la Statistique avec R. Authors: Frederic Bertrand,\nMyriam Maumy-Bertrand.\n\nLMERConvenienceFunctions\n\nAn assortment of functions to facilitate modeling with linear\nmixed-effects regression (LMER). Author: Antoine Tremblay.\n\nLPCM\n\nLocal principal curve methods. Authors: Jochen Einbeck and Ludger\nEvers.\n\nLSD\n\nLots of Superior Depictions. Authors: Bjoern Schwalb, Achim Tresch,\nRomain Francois.\n\nLVQTools\n\nLearning Vector Quantization Tools. Author: Sander Kelders.\n\nLogicForest\n\nLogic Forest. Author: Bethany Wolf. In view:\nMachineLearning.\n\nMARSS\n\nMultivariate Autoregressive State-Space Modeling. Authors: Eli\nHolmes, Eric Ward, and Kellie Wills, NOAA, Seattle, USA. In view:\nTimeSeries.\n\nMCLIME\n\nSimultaneous Estimation of the Regression Coefficients and Precision\nMatrix. Authors: T. Tony Cai, Hongzhe Li, Weidong Liu and Jichun\nXie.\n\nMMST\n\nDatasets from “Modern Multivariate Statistical Techniques” by Alan\nJulian Izenman. Author: Keith Halbert.\n\nMOCCA\n\nMulti-objective optimization for collecting cluster alternatives.\nAuthor: Johann Kraus.\n\nMSToolkit\n\nThe MSToolkit library for clinical trial design. Authors: Mango\nSolutions & Pfizer.\n\nMatrixModels\n\nModelling with Sparse And Dense Matrices. Authors: Douglas Bates and\nMartin Maechler.\n\nMeDiChI\n\nMeDiChI ChIP-chip deconvolution library. Author: David J Reiss.\n\nMetabolAnalyze\n\nProbabilistic latent variable models for metabolomic data. Authors:\nNyamundanda Gift, Isobel Claire Gormley and Lorraine Brennan.\n\nModalclust\n\nHierarchical Modal Clustering. Authors: Surajit Ray and Yansong\nCheng.\n\nMsatAllele\n\nVisualizes the scoring and binning of microsatellite fragment sizes.\nAuthor: Filipe Alberto.\n\nNCBI2R\n\nNavigate and annotate genes and SNPs. Author: Scott Melville.\n\nNetCluster\n\nClustering for networks. Authors: Mike Nowak, Solomon Messing, Sean\nJ Westwood, and Dan McFarland.\n\nNetData\n\nNetwork Data for McFarland’s SNA R labs. Authors: Mike Nowak, Sean J\nWestwood, Solomon Messing, and Dan McFarland.\n\nNetworkAnalysis\n\nStatistical inference on populations of weighted or unweighted\nnetworks. Author: Cedric E Ginestet.\n\nORDER2PARENT\n\nEstimate parent distributions with data of several order statistics.\nAuthor: Cheng Chou.\n\nOSACC\n\nOrdered Subset Analysis for Case-Control Studies. Authors: Xuejun\nQin, Elizabeth R. Hauser, Silke Schmidt (Center for Human Genetics,\nDuke University).\n\nOrgMassSpecR\n\nOrganic Mass Spectrometry. Authors: Nathan G. Dodder, Southern\nCalifornia Coastal Water Research Project (SCCWRP). Contributions\nfrom Katharine M. Mullen. In view:\nChemPhys.\n\nPERregress\n\nRegression Functions and Datasets. Author: Peter Rossi.\n\nPKreport\n\nA reporting pipeline for checking population pharmacokinetic model\nassumption. Author: Xiaoyong Sun.\n\nPermAlgo\n\nPermutational algorithm to simulate survival data. Authors:\nMarie-Pierre Sylvestre, Thad Edens, Todd MacKenzie, Michal\nAbrahamowicz.\n\nPhysicalActivity\n\nProcess Physical Activity Accelerometer Data. Authors: Leena Choi,\nZhouwen Liu, Charles E. Matthews, and Maciej S. Buchowski.\n\nPoMoS\n\nPolynomial (ordinary differential equation) Model Search. Authors:\nMangiarotti S., Coudret R., Drapeau L.\n\nProjectTemplate\n\nAutomates the creation of new statistical analysis projects. Author:\nJohn Myles White.\n\nQSARdata\n\nQuantitative Structure Activity Relationship (QSAR) Data Sets.\nAuthor: Max Kuhn.\n\nQuACN\n\nQuantitative Analysis of Complex Networks. Author: Laurin Mueller.\n\nR4dfp\n\n4dfp MRI Image Read and Write Routines. Author: Kevin P. Barry with\ncontributions from Avi Z. Snyder.\n\nRBrownie\n\nContinuous and discrete ancestral character reconstruction and\nevolutionary rate tests. Authors: J. Conrad Stack, Brian O’Meara,\nLuke Harmon.\n\nRGCCA\n\nRegularized Generalized Canonical Correlation Analysis. Author:\nArthur Tenenhaus.\n\nRGtk2Extras\n\nData frame editor and dialog making wrapper for RGtk2. Authors:\nTom Taverner, with contributions from John Verzani and Iago Conde.\n\nRJSONIO\n\nSerialize R objects to JSON, JavaScript Object Notation. Author:\nDuncan Temple Lang.\n\nRMC\n\nFunctions for fitting Markov models. Author: Scott D. Foster.\n\nRNCBI\n\nThe java ncbi interface to R. Author: Martin Schumann.\n\nRNCBIAxis2Libs\n\nAxis2 libraries for use in the R environment. Author: Martin\nSchumann.\n\nRNCBIEUtilsLibs\n\nEUtils libraries for use in the R environment. Author: Martin\nSchumann.\n\nRNiftyReg\n\nMedical image registration using the NiftyReg library. Authors: Jon\nClayden; based on original code by Marc Modat and Pankaj Daga. In\nview:\nMedicalImaging.\n\nRSNNS\n\nNeural Networks in R using the Stuttgart Neural Network Simulator\n(SNNS). Author: Christoph Bergmeir. In view:\nMachineLearning.\n\nRSearchYJ\n\nSearch with Yahoo Japan. Author: Yohei Sato.\n\nRWebMA\n\nAn R interface toWebMA of Yahoo Japan. Author: Yohei Sato.\n\nRWekajars\n\nR/Weka interface jars. Author: Kurt Hornik.\n\nRandForestGUI\n\nAuthors: Rory Michelland, Genevieve Grundmann.\n\nRcmdrPlugin.EHESsampling\n\nTools for sampling in European Health Examination Surveys (EHES).\nAuthor: Statistics Norway.\n\nRcmdrPlugin.SensoMineR\n\nGraphical User Interface for SensoMineR. Authors: F. Husson, J.\nJosse, S. Le.\n\nRcmdrPlugin.TextMining\n\nRcommander plugin for tm package. Author: Dzemil Lusija.\n\nRcppGSL\n\nRcpp integration for GNU GSL vectors and matrices. Authors: Romain\nFrancois and Dirk Eddelbuettel.\n\nRd2roxygen\n\nConvert Rd to roxygen documentation. Authors: Hadley Wickham and\nYihui Xie.\n\nRecords\n\nRecord Values and Record Times. Author: Magdalena Chrapek.\n\nRenext\n\nRenewal method for extreme values extrapolation. Authors: Yves\nDeville, IRSN.\n\nRfit\n\nRank Estimation for Linear Models. Author: John Kloke.\n\nRramas\n\nMatrix population models. Author: Marcelino de la Cruz.\n\nRuniversal\n\nConvert R objects to Java variables and XML. Author: Mehmet Hakan\nSatman.\n\nRunuranGUI\n\nA GUI for the UNU.RAN random variate generators. Author: Josef\nLeydold.\n\nSAPP\n\nStatistical Analysis of Point Processes. Author: The Institute of\nStatistical Mathematics.\n\nSE.IGE\n\nStandard errors of estimated genetic parametes. Author: Piter Bijma.\n\nSII\n\nCalculate ANSI S3.5-1997 Speech Intelligibility Index. Author:\nGregory R. Warnes.\n\nSMCP\n\nSmoothed minimax concave penalization (SMCP) method for genome-wide\nassociation studies. Author: Jin (Gordon) Liu.\n\nSPOT\n\nSequential Parameter Optimization. Authors: T. Bartz-Beielstein with\ncontributions from J. Ziegenhirt, W. Konen, O. Flasch, P. Koch, M.\nZaefferer.\n\nSQUAREM\n\nSquared extrapolation methods for accelerating fixed-point\niterations. Author: Ravi Varadhan.\n\nSSSR\n\nServer Side Scripting with R. Author: Mehmet Hakan Satman.\n\nSamplerCompare\n\nA framework for comparing the performance of MCMC samplers. Author:\nMadeleine Thompson.\n\nSlimPLS\n\nSlimPLS multivariate feature selection. Author: Michael Gutkin.\n\nSortableHTMLTables\n\nTurns a data frame into an HTML file containing a sortable table.\nAuthor: John Myles White.\n\nTEQR\n\nTarget Equavelence Range Design. Author: M. Suzette Blanchard.\n\nTRIANGG\n\nGeneral discrete triangular distribution. Authors: Tristan Senga\nKiessé, Francial G. Libengué, Silvio S. Zocchi, Célestin C.\nKokonendji.\n\nTSAgg\n\nTime series Aggregation. Author: JS Lessels. In view:\nTimeSeries.\n\nThreeGroups\n\nML Estimator for Baseline-Placebo-Treatment (Three-group) designs.\nAuthor: Holger L. Kern.\n\nTilePlot\n\nThis package performs various analyses of functional gene tiling DNA\nmicroarrays for studying complex microbial communities. Author: Ian\nMarshall.\n\nTreePar\n\nEstimating diversification rate changes in phylogenies. Author:\nTanja Stadler.\n\nTunePareto\n\nMulti-objective parameter tuning for classifiers. Authors: Christoph\nMuessel, Hans Kestler.\n\nVecStatGraphs2D\n\nVector analysis using graphical and analytical methods in 2D.\nAuthors: Juan Carlos Ruiz Cuetos, Maria Eugenia Polo Garcia, Pablo\nGarcia Rodriguez.\n\nVecStatGraphs3D\n\nVector analysis using graphical and analytical methods in 3D.\nAuthors: Juan Carlos Ruiz Cuetos, Maria Eugenia Polo Garcia, Pablo\nGarcia Rodriguez.\n\nWDI\n\nSearch and download data from the World Bank’s World Development\nIndicators. Author: Vincent Arel-Bundock.\n\nWGCNA\n\nWeighted Gene Co-Expression Network Analysis. Authors: Peter\nLangfelder and Steve Horvath with contributions by Jun Dong, Jeremy\nMiller, Lin Song, Andy Yip, and Bin Zhang.\n\nWMTregions\n\nExact calculation of WMTR. Author: Pavel Bazovkin.\n\nabc\n\nFunctions to perform Approximate Bayesian Computation (ABC) using\nsimulated data. Authors: Katalin Csillery, with contributions from\nMichael Blum and Olivier Francois.\n\nadaptivetau\n\nTau-leaping stochastic simulation. Author: Philip Johnson.\n\nalabama\n\nConstrained nonlinear optimization. Author: Ravi Varadhan (with\ncontributions from Gabor Grothendieck).\n\nallan\n\nAutomated Large Linear Analysis Node. Author: Alan Lee.\n\nandrews\n\nAndrews curves. Author: Jaroslav Myslivec.\n\naratio\n\nAssessment ratio analysis. Author: Daniel McMillen.\n\nares\n\nEnvironment air pollution epidemiology: a library for time series\nanalysis. Authors: Washington Junger and Antonio Ponce de Leon.\n\naster2\n\nAster Models. Author: Charles J. Geyer. In view:\nSurvival.\n\nbayesDem\n\nGraphical User Interface for bayesTFR. Author: Hana Sevcikova.\n\nbayesTFR\n\nBayesian Fertility Projection. Authors: Hana Sevcikova, Leontine\nAlkema, Adrian Raftery.\n\nbbemkr\n\nBayesian bandwidth estimation for multivariate kernel regression\nwith Gaussian error. Authors: Han Lin Shang and Xibin Zhang.\n\nbeadarrayMSV\n\nAnalysis of Illumina BeadArray SNP data including MSV markers.\nAuthor: Lars Gidskehaug.\n\nbeeswarm\n\nThe bee swarm plot, an alternative to stripchart. Author: Aron\nCharles Eklund.\n\nbelief\n\nContains basic functions to manipulate belief functions and\nassociated mass assignments. Authors: N. Maillet, B.\nCharnomordic, S. Destercke.\n\nbenchmark\n\nBenchmark Experiments Toolbox. Author: Manuel J. A. Eugster.\n\nber\n\nBatch Effects Removal. Author: Marco Giordan.\n\nbfp\n\nBayesian Fractional Polynomials. Author: Daniel Sabanes Bove.\n\nbild\n\nBInary Longitudinal Data. Authors: M. Helena Gonçalves, M. Salomé\nCabral and Adelchi Azzalini; incorporates Fortran-77 code written\nby R. Piessens and E. de Doncker in ‘Quadpack’.\n\nbisoreg\n\nBayesian Isotonic Regression with Bernstein Polynomials.\n\nbivarRIpower\n\nSample size calculations for bivariate longitudinal data.\nAuthors: W. Scott Comulada and Robert E. Weiss.\n\ncMonkey\n\ncMonkey intgrated biclustering algorithm. Authors: David J Reiss,\nInstitute for Systems Biology.\n\ncare\n\nCAR Estimation, Variable Selection, and Regression. Authors: Verena\nZuber and Korbinian Strimmer.\n\ncaspar\n\nClustered and sparse regression (CaSpaR). Author: Daniel Percival.\n\ncatR\n\nProcedures to generate IRT adaptive tests (CAT). Authors: David\nMagis (U Liege, Belgium), Gilles Raiche (UQAM, Canada). In view:\nPsychometrics.\n\ncccd\n\nClass Cover Catch Digraphs. Author: David J. Marchette.\n\ncensReg\n\nCensored Regression (Tobit) Models. Author: Arne Henningsen. In\nview: Survival.\n\ncgdsr\n\nR-Based API for accessing the MSKCC Cancer Genomics Data Server\n(CGDS). Author: Anders Jacobsen.\n\ncharlson\n\nConverts listwise icd9 data into comorbidity count and Charlson\nIndex. Author: Vanessa Cox.\n\ncherry\n\nMultiple testing methods for exploratory research. Author: Jelle\nGoeman.\n\nclustsig\n\nSignificant Cluster Analysis. Authors: Douglas Whitaker and Mary\nChristman.\n\ncolcor\n\nTests for column correlation in the presence of row correlation.\nAuthor: Omkar Muralidharan.\n\ncompareGroups\n\nDescriptives by groups. Authors: Héctor Sanz, Isaac Subirana, Joan\nVila.\n\nconstrainedKriging\n\nConstrained, covariance-matching constrained and universal point or\nblock kriging. Author: Christoph Hofer. In view:\nSpatial.\n\ncorrsieve\n\nCorrSieve. Author: Michael G. Campana.\n\ncostat\n\nTime series costationarity determination and tests of stationarity.\nAuthors: Guy Nason and Alessandro Cardinali.\n\ncrossmatch\n\nThe cross-match test. Authors: Ruth Heller, Dylan Small, Paul\nRosenbaum.\n\ncudaBayesregData\n\nData sets for the examples used in the package cudaBayesreg.\nAuthor: Adelino Ferreira da Silva.\n\ncumSeg\n\nChange point detection in genomic sequences. Author: Vito M.R.\nMuggeo.\n\ncurvHDR\n\ncurvHDR filtering. Authors: George Luta, Ulrike Naumann and Matt\nWand.\n\ncxxPack\n\nR/C++ Tools for Literate Statistical Practice. Author: Dominick\nSamperi. In view:\nReproducibleResearch.\n\ndafs\n\nData analysis for forensic scientists. Authors: James Curran, Danny\nChang.\n\ndcv\n\nConventional Cross-validation statistics for climate-growth model.\nAuthor: Zongshan Li with contributions from Jinlong Zhang.\n\nddepn\n\nDynamical Deterministic Effects Propagation Networks: Infer\nsignalling networks for timecourse RPPA data. Author: Christian\nBender.\n\ndelftfews\n\ndelftfews R extensions. Authors: Mario Frasca, Michèl van Leeuwen.\n\ndemography\n\nForecasting mortality, fertility, migration and population data.\nAuthors: Rob J Hyndman with contributions from Heather Booth, Leonie\nTickle and John Maindonald.\n\ndicionariosIBGE\n\nDictionaries for reading survey microdata from IBGE. Authors: Erick\nFonseca, Alexandre Rademaker.\n\ndirectlabels\n\nDirect labels for plots. Author: Toby Dylan Hocking.\n\ndiscretization\n\nData preprocessing, discretization for classification. Authors:\nKim, H. J.\n\ndismo\n\nSpecies distribution modeling. Authors: Robert Hijmans, Steven\nPhillips, John Leathwick and Jane Elith.\n\ndistory\n\nDistance Between Phylogenetic Histories. Authors: John Chakerian and\nSusan Holmes.\n\ndivisors\n\nFind the divisors of a number. Author: Greg Hirson.\n\ndixon\n\nNearest Neighbour Contingency Table Analysis. Authors: Marcelino de\nla Cruz Rot and Philip M. Dixon.\n\ndpa\n\nDynamic Path Approach. Author: Emile Chappin.\n\neVenn\n\nA powerful tool to compare lists and draw Venn diagrams. Author:\nNicolas Cagnard.\n\necoreg\n\nEcological regression using aggregate and individual data. Author:\nChristopher Jackson.\n\negarch\n\nEGARCH simulation and fitting. Author: Kerstin Konnerth.\n\nemg\n\nExponentially Modified Gaussian (EMG) Distribution. Author: Shawn\nGarbett.\n\nevaluate\n\nParsing and evaluation tools that provide more details than the\ndefault. Author: Hadley Wickham.\n\nexpm\n\nMatrix exponential. Authors: Vincent Goulet, Christophe Dutang,\nMartin Maechler, David Firth, Marina Shapira, Michael Stadelmann.\n\nfANCOVA\n\nNonparametric Analysis of Covariance. Author: Xiao-Feng Wang.\n\nfactorQR\n\nBayesian quantile regression factor models. Author: Lane Burgette.\n\nfastR\n\nData sets and utilities for Foundations and Applications of\nStatistics by R Pruim. Author: Randall Pruim.\n\nfmsb\n\nFunctions for medical statistics book with some demographic data.\nAuthor: Minato Nakazawa.\n\nfutile.paradigm\n\nA framework for working in a functional programming paradigm in R.\nAuthor: Brian Lee Yung Rowe.\n\nfwdmsa\n\nForward search for Mokken scale analysis. Author: Wobbe P. Zijlstra.\n\ngMCP\n\nA graphical approach to sequentially rejective multiple test\nprocedures. Author: Kornelius Rohmeyer.\n\ngalts\n\nGenetic algorithms and C-steps based LTS estimation. Author: Mehmet\nHakan Satman.\n\ngames\n\nStatistical Estimation of Game-Theoretic Models. Authors: Curtis S.\nSignorino and Brenton Kenkel.\n\ngaussDiff\n\nDifference measures for multivariate Gaussian probability density\nfunctions. Author: Henning Rust.\n\ngcbd\n\nGPU/CPU Benchmarking in Debian-based systems. Author: Dirk\nEddelbuettel. In view:\nHighPerformanceComputing.\n\ngenepi\n\nGenetic Epidemiology Design and Inference. Author: Venkatraman E.\nSeshan.\n\ngeofd\n\nSpatial prediction for function value data. Authors: Ramon Giraldo,\nPedro Delicado, Jorge Mateu.\n\nglmpathcr\n\nFit a penalized continuation ratio model for predicting an ordinal\nresponse. Author: Kellie J. Archer.\n\nglrt\n\nGeneralized Logrank Tests for Interval-censored Failure Time Data.\nAuthors: Qiang Zhao and Jianguo Sun. In view:\nSurvival.\n\ngoogleVis\n\nUsing the Google Visualisation API with R. Authors: Markus Gesmann,\nDiego de Castillo.\n\ngptk\n\nGaussian Processes Tool-Kit. Authors: Alfredo A. Kalaitzis, Pei Gao,\nAntti Honkela, Neil D. Lawrence.\n\ngridExtra\n\nfunctions in Grid graphics. Author: Baptiste Auguie.\n\ngrt\n\nGeneral Recognition Theory. Authors: The original Matlab toolbox by\nLeola A. Alfonso-Reese. R port, with several significant\nmodifications by Kazunaga Matsuki.\n\ngsc\n\nGeneralised Shape Constraints. Author: Charlotte Maia.\n\nhelpr\n\nHelp for R. Authors: Hadley Wickham and Barret Schloerke.\n\nhisemi\n\nHierarchical Semiparametric Regression of Test Statistics. Authors:\nLong Qu, Dan Nettleton, Jack Dekkers.\n\nhotspots\n\nHot spots. Author: Anthony Darrouzet-Nardi.\n\nhuge\n\nHigh-dimensional Undirected Graph Estimation. Authors: Tuo Zhao, Han\nLiu, Kathryn Roeder, John Lafferty, Larry Wasserman.\n\nhydroGOF\n\nGoodness-of-fit functions for comparison of simulated and observed\nhydrological time series. Author: Mauricio Zambrano Bigiarini.\n\nhydroTSM\n\nTime series management, analysis and interpolation for hydrological\nmodelling. Author: Mauricio Zambrano-Bigiarini.\n\nicaOcularCorrection\n\nIndependent Components Analysis (ICA) based eye-movement correction.\nAuthors: Antoine Tremblay, IWK Health Center.\n\nigraphtosonia\n\nConvert iGraph graps to SoNIA .son files. Author: Sean J Westwood.\n\nimguR\n\nShare plots using the image hosting service imgur.com. Author: Aaron\nStatham.\n\nindicspecies\n\nFunctions to assess the strength and significance of relationship of\nspecies site group associations. Authors: Miquel De Caceres, Florian\nJansen.\n\ninference\n\nFunctions to extract inferential values of a fitted model object.\nAuthor: Vinh Nguyen.\n\ninfochimps\n\nAn R wrapper for the infochimps.com API services. Author: Drew\nConway.\n\ninteractivity\n\ntoggle R interactive mode. Authors: Jeffrey Horner, Jeroen Ooms.\n\nipdmeta\n\nIndividual patient and Mixed-level Meta-analysis of Time-to-Event\nOutcomes. Author: S. Kovalchik.\n\nisdals\n\nProvides data sets for “Introduction to Statistical Data Analysis\nfor the Life Sciences”. Authors: Claus Ekstrom and Helle Sorensen.\n\nisva\n\nIndependent Surrogate Variable Analysis. Author: Andrew E\nTeschendorff.\n\niv\n\nInformation Visualisation with UML and Graphs. Author: Charlotte\nMaia.\n\nlabeling\n\nAxis Labeling. Author: Justin Talbot.\n\nlaeken\n\nLaeken indicators for measuring social cohesion. Authors: Andreas\nAlfons, Josef Holzer and Matthias Templ. In view:\nOfficialStatistics.\n\nlandsat\n\nRadiometric and topographic correction of satellite imagery. Author:\nSarah Goslee.\n\nlessR\n\nLess Code, More Results. Authors: David W. Gerbing, School of\nBusiness Administration, Portland State University.\n\nlist\n\nMultivariate Statistical Analysis for the Item Count Technique.\nAuthors: Graeme Blair, Kosuke Imai.\n\nlog4r\n\nA simple logging system for R, based on log4j. Author: John Myles\nWhite.\n\nlongpower\n\nSample size calculations for longitudinal data. Authors: Michael C.\nDonohue, Anthony C. Gamst, Steven D. Edland.\n\nlubridate\n\nMake dealing with dates a little easier. Authors: Garrett Grolemund,\nHadley Wickham.\n\nmagma\n\nMatrix Algebra on GPU and Multicore Architectures. Author: Brian J\nSmith. In view:\nHighPerformanceComputing.\n\nmakesweave\n\nLiterate Programming with Make and Sweave. Author: Charlotte Maia.\n\nmaxLinear\n\nConditional Samplings for Max-Linear Models. Author: Yizao Wang.\n\nmcmcplots\n\nCreate Plots from MCMC Output. Author: S. McKay Curtis.\n\nmcprofile\n\nMultiple Contrast Profiles. Author: Daniel Gerhard.\n\nmem\n\nMoving Epidemics Method R Package. Author: Jose E. Lozano Alonso.\n\nmemoise\n\nMemoise functions. Author: Hadley Wickham.\n\nmetatest\n\nFit and test metaregression models. Author: Hilde M. Huizenga &\nIngmar Visser.\n\nmfr\n\nMinimal Free Resolutions of Graph Edge Ideals. Author: David J.\nMarchette.\n\nmhurdle\n\nEstimation of models with limited dependent variables. Authors:\nFabrizio Carlevaro, Yves Croissant, Stephane Hoareau.\n\nmixedQF\n\nEstimator with Qudratics Forms in Mixeds Models. Authors:\nJean-Benoist Leger, ENS Cachan & Jean-Benoist Leger, INRA.\n\nmixsep\n\nForensic Genetics DNA Mixture Separation. Author: Torben Tvedebrink.\n\nmixsmsn\n\nFitting finite mixture of scale mixture of skew-normal\ndistributions. Authors: Marcos Prates, Victor Lachos and Celso\nCabral.\n\nmkssd\n\nEfficient multi-level k-circulant supersaturated designs. Author: B\nN Mandal.\n\nmodelcf\n\nModeling physical computer codes with functional outputs using\nclustering and dimensionality reduction. Author: Benjamin Auder.\n\nmodelfree\n\nModel-free estimation of a psychometric function. Authors: Ivan\nMarin-Franch, Kamila Zychaluk, and David H. Foster.\n\nmondate\n\nKeep track of dates in terms of months. Author: Dan Murphy. In view:\nTimeSeries.\n\nmpmcorrelogram\n\nMultivariate Partial Mantel Correlogram. Author: Marcelino de la\nCruz.\n\nmpt\n\nMultinomial Processing Tree (MPT) Models. Author: Florian\nWickelmaier.\n\nmr\n\nMarginal regresson models for dependent data. Authors: Guido\nMasarotto and Cristiano Varin.\n\nmritc\n\nMRI tissue classification. Authors: Dai Feng and Luke Tierney. In\nview:\nMedicalImaging.\n\nmtsdi\n\nMultivariate time series data imputation. Authors: Washington Junger\nand Antonio Ponce de Leon.\n\nmultitaper\n\nMultitaper Spectral Analysis. Author: Karim Rahim.\n\nmutoss\n\nUnified multiple testing procedures. Authors: MuToss Coding Team\n(Berlin 2010), Gilles Blanchard, Thorsten Dickhaus, Niklas Hack,\nFrank Konietschke, Kornelius Rohmeyer, Jonathan Rosenblatt, Marsel\nScheer, Wiebke Werft.\n\nmutossGUI\n\nA graphical user interface for the MuToss Project. Authors: MuToss\nCoding Team (Berlin 2010), Gilles Blanchard, Thorsten Dickhaus,\nNiklas Hack, Frank Konietschke, Kornelius Rohmeyer, Jonathan\nRosenblatt, Marsel Scheer, Wiebke Werft.\n\nnacopula\n\nNested Archimedean Copulas. Authors: Marius Hofert and Martin\nMaechler. In view:\nDistributions.\n\nneuRosim\n\nFunctions to generate fMRI data including activated data, noise data\nand resting state data. Authors: Marijke Welvaert with contributions\nfrom Joke Durnez, Beatrijs Moerkerke, Yves Rosseel and Geert\nVerdoolaege.\n\nnnc\n\nNearest Neighbor Autocovariates. Authors: A. I. McLeod and M. S.\nIslam.\n\nnncRda\n\nImproved RDA Using nnc. Authors: M. S. Islam and A. I. McLeod.\n\nnormwhn.test\n\nNormality and White Noise Testing. Author: Peter Wickham.\n\nnpst\n\nA generalization of the nonparametric seasonality tests of Hewitt et\nal. (1971) and Rogerson (1996). Author: Roland Rau.\n\nopenair\n\nTools for the analysis of air pollution data. Authors: David Carslaw\nand Karl Ropkins.\n\noperator.tools\n\nUtilities for working with R’s operators. Author: Christopher Brown.\n\noptimx\n\nA replacement and extension of the optim() function. Authors: John C\nNash and Ravi Varadhan. In view:\nOptimization.\n\norQA\n\nOrder Restricted Assessment Of Microarray Titration Experiments.\nAuthor: Florian Klinglmueller.\n\norderbook\n\nOrderbook visualization/Charting software. Authors: Andrew Liu,\nKhanh Nguyen, Dave Kane. In view:\nFinance.\n\nparfossil\n\nParallelized functions for palaeoecological and palaeogeographical\nanalysis. Author: Matthew Vavrek.\n\npartitionMap\n\nPartition Maps. Author: Nicolai Meinshausen.\n\npathClass\n\nClassification using biological pathways as prior knowledge. Author:\nMarc Johannes.\n\npathmox\n\nSegmentation Trees in Partial Least Squares Path Modeling. Authors:\nGaston Sanchez, and Tomas Aluja.\n\npbapply\n\nAdding Progress Bar to ‘*apply’ Functions. Author: Peter Solymos.\n\npequod\n\nModerated regression package. Author: Alberto Mirisola & Luciano\nSeta.\n\npesticides\n\nAnalysis of single serving and composite pesticide residue\nmeasurements. Author: David M Diez.\n\npfda\n\nPaired Functional Data Analysis. Author: Andrew Redd.\n\npglm\n\npanel generalized linear model. Author: Yves Croissant.\n\npheatmap\n\nPretty Heatmaps. Author: Raivo Kolde.\n\nphitest\n\nNonparametric goodness-of-fit methods based on phi-divergences.\nAuthor: Leah R. Jager.\n\nphybase\n\nBasic functions for phylogenetic analysis. Author: Liang Liu. In\nview:\nPhylogenetics.\n\nphylosim\n\nR packge for simulating biological sequence evolution. Authors:\nBotond Sipos, Gregory Jordan.\n\nphylotools\n\nPhylogenetic tools for ecologists. Authors: Jinlong Zhang,\nXiangcheng Mi, Nancai Pei.\n\npi0\n\nEstimating the proportion of true null hypotheses for FDR. Authors:\nLong Qu, Dan Nettleton, Jack Dekkers.\n\nplotGoogleMaps\n\nPlot HTML output with Google Maps API and your own data. Author:\nMilan Kilibarda.\n\nplsRglm\n\nPartial least squares Regression for generalized linear models.\nAuthors: Frederic Bertrand, Nicolas Meyer, Myriam Maumy-Bertrand. In\nviews: ChemPhys,\nPsychometrics.\n\npmr\n\nProbability Models for Ranking Data. Authors: Paul H. Lee and\nPhilip L. H. Yu.\n\npolysat\n\nTools for Polyploid Microsatellite Analysis. Author: Lindsay V.\nClark.\n\nportes\n\nPortmanteau Tests for ARMA, VARMA, ARCH, and FGN Models. Author:\nEsam Mahdi & A. Ian McLeod.\n\nppstat\n\nPoint Process Statistics. Author: Niels Richard Hansen.\n\nprocessdata\n\nProcess Data. Author: Niels Richard Hansen.\n\npso\n\nParticle Swarm Optimization. Author: Claus Bendtsen.\n\nptinpoly\n\nPoint-In-Polyhedron Test (3D). Authors: Jose M. Maisog, Yuan Wang,\nGeorge Luta, Jianfei Liu.\n\npvclass\n\nP-values for Classification. Authors: Niki Zumbrunnen, Lutz\nDuembgen.\n\nqualityTools\n\nStatistical Methods for Quality Science. Author: Thomas Roth.\n\nrAverage\n\nParameter estimation for the Averaging model of Information\nIntegration Theory. Authors: Giulio Vidotto, Stefano Noventa, Davide\nMassidda, Marco Vicentini.\n\nrDNA\n\nR Bindings for the Discourse Network Analyzer. Author: Philip\nLeifeld.\n\nrJython\n\nR interface to Python via Jython. Authors: G. Grothendieck and\nCarlos J. Gil Bellosta (authors of Jython itself are Jim Hugunin,\nBarry Warsaw, Samuele Pedroni, Brian Zimmer, Frank Wierzbicki and\nothers; Bob Ippolito is the author of the simplejson Python module).\n\nrTOFsPRO\n\nTime-of-flight mass spectra signal processing. Authors: Dariya\nMalyarenko, Maureen Tracy and William Cooke.\n\nrefund\n\nRegression with Functional Data. Authors: Philip Reiss and Lei\nHuang.\n\nrelevent\n\nRelational Event Models. Author: Carter T. Butts.\n\nreportr\n\nA general message and error reporting system. Author: Jon Clayden.\n\nreshape2\n\nFlexibly reshape data: a reboot of the reshape package. Author:\nHadley Wickham.\n\nrmac\n\nCalculate RMAC or FMAC agreement coefficients. Author: Jennifer\nKirk.\n\nrphast\n\nR interface to PHAST software for comparative genomics. Authors:\nMelissa Hubisz, Katherine Pollard, and Adam Siepel.\n\nrpud\n\nR functions for computation on GPU. Author: Chi Yau. In view:\nHighPerformanceComputing.\n\nrrcovNA\n\nScalable Robust Estimators with High Breakdown Point for Incomplete\nData. Author: Valentin Todorov. In view:\nOfficialStatistics.\n\nrseedcalc\n\nEstimation of Proportion of GM Stacked Seeds in Seed Lots. Authors:\nKevin Wright, Jean-Louis Laffont.\n\nrvgtest\n\nTools for Analyzing Non-Uniform Pseudo-Random Variate Generators.\nAuthors: Josef Leydold and Sougata Chaudhuri.\n\nsatin\n\nFunctions for reading and displaying satellite data for\noceanographic applications with R. Authors: Héctor Villalobos and\nEduardo González-Rodríguez.\n\nschwartz97\n\nA package on the Schwartz two-factor commodity model. Authors:\nPhilipp Erb, David Luethi, Juri Hinz, Simon Otziger. In view:\nFinance.\n\nsdcMicroGUI\n\nGraphical user interface for package sdcMicro. Author: Matthias\nTempl.\n\nselectMeta\n\nEstimation weight functions in meta analysis. Author: Kaspar\nRufibach.\n\nseqCBS\n\nCN Profiling using Sequencing and CBS. Authors: Jeremy J. Shen,\nNancy R. Zhang.\n\nseqRFLP\n\nSimulation and visualization of restriction enzyme cutting pattern\nfrom DNA sequences. Authors: Qiong Ding, Jinlong Zhang.\n\nsharx\n\nModels and Data Sets for the Study of Species-Area Relationships.\nAuthor: Peter Solymos.\n\nsigclust\n\nStatistical Significance of Clustering. Authors: Hanwen Huang,\nYufeng Liu & J. S. Marron.\n\nsimexaft\n\nAuthors: Juan Xiong, Wenqing He, Grace Y. Yi. In view:\nSurvival.\n\nsinartra\n\nA simple web app framework for R, based on sinatra. Author: Hadley\nWickham.\n\nsmirnov\n\nProvides two taxonomic coefficients from E. S. Smirnov “Taxonomic\nanalysis” (1969) book. Author: Alexey Shipunov (with help of Eugenij\nAltshuler).\n\nsmoothmest\n\nSmoothed M-estimators for 1-dimensional location. Author: Christian\nHennig.\n\nsoil.spec\n\nSoil spectral data exploration and regression functions. Author:\nThomas Terhoeven-Urselmans.\n\nsoiltexture\n\nFunctions for soil texture plot, classification and transformation.\nAuthors: Julien MOEYS, contributions from Wei Shangguan.\n\nsomeMTP\n\nFunctions for Multiplicty Correction and Multiple Testing. Author:\nLivio Finos.\n\nspacetime\n\nclasses and methods for spatio-temporal data. Author: Edzer Pebesma.\n\nsplinesurv\n\nNonparametric bayesian survival analysis. Authors: Emmanuel Sharef,\nRobert L. Strawderman, and David Ruppert. In view:\nSurvival.\n\nsprint\n\nSimple Parallel R INTerface. Author: University of Edinburgh SPRINT\nTeam.\n\nsurvJamda\n\nSurvival prediction by joint analysis of microarray gene expression\ndata. Author: Haleh Yasrebi.\n\nsurvJamda.data\n\nAuthor: Haleh Yasrebi.\n\nsynchronicity\n\nBoost mutex functionality for R. Author: Michael J. Kane.\n\ntableplot\n\nRepresents tables as semi-graphic displays. Authors: Ernest Kwan and\nMichael Friendly.\n\ntfer\n\nForensic Glass Transfer Probabilities. Authors: James Curran and\nTingYu Huang.\n\nthgenetics\n\nGenetic Rare Variants Tests. Author: Thomas Hoffmann.\n\ntpsDesign\n\nDesign and analysis of two-phase sampling and case-control studies.\nAuthors: Takumi Saegusa, Sebastien Haneuse, Nilanjan Chaterjee,\nNorman Breslow.\n\ntreemap\n\nTreemap visualization. Author: Martijn Tennekes.\n\ntriads\n\nTriad census for networks. Authors: Solomon Messing, Sean J\nWestwood, Mike Nowak and Dan McFarland.\n\nvalidator\n\nExternal and Internal Validation Indices. Author: Marcus Scherl.\n\nviolinmplot\n\nCombination of violin plot with mean and standard deviation. Author:\nRaphael W. Majeed.\n\nwSVM\n\nWeighted SVM with boosting algorithm for improving accuracy.\nAuthors: SungHwan Kim and Soo-Heang Eo.\n\nweirs\n\nA Hydraulics Package to Compute Open-Channel Flow over Weirs.\nAuthor: William Asquith.\n\nwild1\n\nR Tools for Wildlife Research and Management. Authors: Glen A.\nSargeant, USGS Northern Prairie Wildlife Research Center.\n\nwvioplot\n\nWeighted violin plot. Author: Solomon Messing.\n\nxpose4\n\nXpose 4. Authors: E. Niclas Jonsson, Andrew Hooker and Mats\nKarlsson.\n\nxpose4classic\n\nXpose 4 Classic Menu System. Authors: E. Niclas Jonsson, Andrew\nHooker and Mats Karlsson.\n\nxpose4data\n\nXpose 4 Data Functions Package. Authors: E. Niclas Jonsson, Andrew\nHooker and Mats Karlsson.\n\nxpose4generic\n\nXpose 4 Generic Functions Package. Authors: E. Niclas Jonsson,\nAndrew Hooker and Mats Karlsson.\n\nxpose4specific\n\nXpose 4 Specific Functions Package. Authors: E. Niclas Jonsson,\nAndrew Hooker and Mats Karlsson.\n\n3 Other changes\nThe following packages were moved to the Archive: AIS,\nBayesPanel, BootCL, DEA, FKBL, GRASS, MSVAR, NADA,\nPhySim, RGtk2DfEdit, Rfwdmv, Rlsf, SNPMaP, SharedHT2,\nTwslmSpikeWeight, VDCutil, VaR, XReg, aaMI, asuR,\nbayesCGH, bicreduc, bim, birch, celsius, csampling,\ncts, demogR, dprep, glmc, grasp, grnnR, ifa, ig,\ninetwork, ipptoolbox, knnTree, lnMLE, locfdr, logilasso,\nlvplot, marg, mlCopulaSelection, mmlcr, netmodels,\nnormwn.test, npde, nytR, ofw, oosp, pga, pinktoe,\nppc, qgen, risksetROC, rjacobi, rv, sabreR,\nsinglecase, smd.and.more, stochasticGEM, titecrm, and\nudunits.\nThe following packages were resurrected from the Archive: MIfuns,\nagsemisc, assist, gllm, mlmmm, mvgraph, nlts, rgr, and\nsupclust.\nThe following packages were removed from CRAN: seaflow and\nsimpleR.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2010-2-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2010-2 issue.",
    "author": [
      {
        "name": "Peter Dalgaard",
        "url": {}
      }
    ],
    "date": "2010-12-01",
    "categories": [],
    "contents": "\n\nWelcome to the 2nd issue of the 2nd volume of The R Journal.\nI am pleased to say that we can offer ten peer-reviewed papers this\ntime. Many thanks go to the authors and the reviewers who ensure that\nour articles live up to high academic standards. The transition from R\nNews to The R Journal is now nearly completed. We are now listed by\nEBSCO and the registration procedure with Thomson Reuters is well on the\nway. We thereby move into the framework of scientific journals and away\nfrom the grey-literature newsletter format; however, it should be\nstressed that R News was a fairly high-impact piece of grey literature:\nA cited reference search turned up around 1300 references to the just\nover 200 papers that were published in R News!\nI am particularly happy to see the paper by Soetart et al. on\ndifferential equation solvers. In many fields of research, the natural\nformulation of models is via local relations at the infinitesimal level,\nrather than via closed form mathematical expressions, and quite often\nsolutions rely on simplifying assumptions. My own PhD work, some 25\nyears ago, concerned diffusion of substances within the human eye, with\nthe ultimate goal of measuring the state of the blood-retinal barrier.\nSolutions for this problem could be obtained for short timespans, if one\nassumed that the eye was completely spherical. Extending the solutions\nto accommodate more realistic models (a necessity for fitting actual\nexperimental data) resulted in quite unwieldy formulas, and even then,\ndid not give you the kind of modelling freedom that you really wanted to\nelucidate the scientific issue.\nIn contrast, numerical procedures could fairly easily be set up and\nmodified to better fit reality. The main problem was that they tended to\nbe computationally demanding. Especially for transient solutions in two\nor three spatial dimensions, computers simply were not fast enough in a\ntime where numerical performance was measured in fractions of a MFLOPS\n(million floating point operations per second). Today, the relevant\nmeasure is GFLOPS and we should be getting much closer to practicable\nsolutions.\nHowever, raw computing power is not sufficient; there are non-obvious\naspects of numerical analysis that should not be taken lightly, notably\nissues of stability and accuracy. There is a reason that numerical\nanalysis is a scientific field in its own right.\nFrom a statistician’s perspective, being able to fit models to actual\ndata is of prime importance. For models with only a few parameters, you\ncan get quite far with nonlinear regression and a good numerical solver.\nFor ill-posed problems with functional parameters (the so-called\n“inverse problems”), and for stochastic differential equations, there\nstill appears to be work to be done. Soetart et al. do not go into these\nissues, but I hope that their paper will be an inspiration for further\nwork.\nWith this issue, in accordance with the rotation rules of the Editorial\nBoard, I step down as Editor-in-Chief, to be succeded by Heather Turner.\nHeather has already played a key role in the transition from R News to\nThe R Journal, as well as being probably the most efficient Associate\nEditor on the Board. The Editorial Board will be losing last year’s\nEditor-in-Chief, Vince Carey, who has now been on board for the full\nfour years. We shall miss Vince, who has always been good for a precise\nand principled argument and in the process taught at least me several\nnew words. We also welcome Hadley Wickham as a new Associate Editor and\nmember of the Editorial Board.\nSeason’s greetings and best wishes for a happy 2011!\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2010-2-forthcoming-user/",
    "title": "Forthcoming Events: useR! 2011",
    "description": "\"Forthcoming Events: useR! 2011\" published in The R Journal.",
    "author": [
      {
        "name": "John Aston, Julia Brettschneider, David Firth, Ashley Ford, Ioannis\nKosmidis, Tom Nichols, Elke and Heather Turner",
        "url": {}
      }
    ],
    "date": "2010-12-01",
    "categories": [],
    "contents": "\n\nThe seventh international R user conference, useR! 2011, will take\nplace at the University of Warwick, Coventry, 16–18 August 2011.\nFollowing previous useR! conferences, this meeting of the R user\ncommunity will provide a platform for R users to discuss and exchange\nideas of how R can be used for statistical computation, data analysis\nand visualization.\nThe program will consist of invited talks, user-contributed sessions and\npre-conference tutorials.\n1 Invited Talks\nThe invited talks represent the spectrum of interest, ranging from\nimportant technical developments to exciting applications of R,\npresented by experts in the field:\nAdrian Bowman: Modelling Three-dimensional Surfaces in R.\nLee Edlefsen: High Performance Computing in R.\nUlrike : Design of Experiments in R.\nWolfgang Huber: From Genomes to Phenotypes.\nBrian Ripley: The R Development Process.\nJonathan Rougier: Calibration and Prediction for Stochastic\nDynamical Systems Arising in Environmental Science.\nSimon Urbanek: R Graphics: Supercharged - Recent Advances in\nVisualization and Analysis of Large Data in R.\nBrandon Whitcher: Quantitative Analysis of Medical Imaging Data in\n\n\n2 User-contributed Sessions\nIn the contributed sessions, presenters will share innovative and\ninteresting uses of R, covering topics such as:\nBayesian statistics\nBioinformatics\nChemometrics and computational physics\nData mining\nEconometrics and finance\nEnvironmetrics and ecological modeling\nHigh performance computing\nImaging\nInterfaces with other languages/software\nMachine learning\nMultivariate statistics\nNonparametric statistics\nPharmaceutical statistics\nPsychometrics\nSpatial statistics\nStatistics in the social and political sciences\nTeaching\nVisualization and graphics\nAbstracts may be submitted for the poster session, which will be a major\nsocial event on the evening of the first day of the conference, or for\nthe main program of talks. Submissions for contributed talks will be\nconsidered for the following types of session:\nuseR! Kaleidoscope: These sessions give a broad overview of the\nmany different applications of R and should appeal to a wide\naudience.\nuseR! Focus Session: These sessions cover topics of special\ninterest and may be more technical.\nThe scientific program is organized by members of the program committee,\ncomprising Ramón Díaz-Uriarte, John Fox, Romain François, Robert\nGramacy, Paul Hewson, Torsten Hothorn, Kate Mullen, Brian Peterson,\nThomas Petzoldt, Anthony Rossini, Barry Rowlingson, Carolin Strobl,\nStefan Theussl, Heather Turner, Hadley Wickham and Achim Zeileis.\nIn addition to the main program of talks and new for useR! 2011, all\nparticipants are invited to present a Lightning Talk, for which no\nabstract is required. These talks provide a 5-minute platform to speak\non any R-related topic and should particularly appeal to those new to R.\nA variation of the pecha kucha1 and ignite2 formats will be used\nin which speakers must provide 15 slides to accompany their talk and\neach slide will be shown for 20 seconds.\n3 Pre-conference Tutorials\nBefore the start of the official program, the following half-day\ntutorials will be offered on Monday, 15 August:\nDouglas Bates: Fitting and evaluating mixed models using\nlme4\nRoger Bivand and Edzer Pebesma: Handling and analyzing\nspatio-temporal data in R\nMarine Cadoret and Sébastien Lê: Analysing categorical data in R\nStephen Eglen: Emacs Speaks Statistics\nAndrea Foulkes: High-dimensional data methods with R\nFrank E Harrell Jr: Regression modeling strategies using the R\npackage rms\nSøren Højsgaard: Graphical models and Bayesian networks with R\nG. Jay Kerns: Introductory probability and statistics using R\nMax Kuhn: Predictive modeling with R and the\ncaret package\nNicholas Lewin Koh: Everyday R: Statistical consulting with R\nFausto Molinari, Enrico Branca, Francesco De Filippo and Rocco\nClaudio Cannizzaro: R-Adamant: Applied financial analysis and\nrisk management\nMartin Morgan: Bioconductor for the analysis of high-throughput\ngenomic data\nPaul Murrell: Introduction to grid graphics\nGiovanni Petris: State space models in R\nShivani Rao: Topic modeling of large datasets with R using Amazon\nEMR\nKarline Soetaert and Thomas Petzoldt: Simulating differential\nequation models in R\nAntony Unwin: Graphical data analysis\nBrandon Whitcher, Polzehl, Karsten Tabelow: Medical image analysis\nfor MRI\n4 Location & Surroundings\nParticipants will be well catered for at the University of Warwick, with\nmeals and accommodation available on campus. The university is in the\ncity of Coventry which offers a number of places to visit such as the\ncathedral and city art gallery. In the heart of England, the city is\nwithin easy reach of other attractions such as Warwick’s medieval castle\nand the new Royal Shakespeare and Swan Theatres in Stratford-upon-Avon\n(Shakespeare’s birthplace).\n5 Further Information\nA web page offering more information on useR! 2011, including details\nregarding registration and abstract submission, is available at\nhttp://www.R-project.org/useR-2011/\nWe hope to meet you in Coventry!\n\nCRAN packages used\nlme4, rms, caret\nCRAN Task Views implied by cited packages\nEconometrics, Environmetrics, HighPerformanceComputing, MachineLearning, MixedModels, Psychometrics, ReproducibleResearch, SpatioTemporal, Survival\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\nhttp://en.wikipedia.org/wiki/Pecha_Kucha↩︎\nhttp://en.wikipedia.org/wiki/Ignite_(event)\n\n↩︎\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2010-2-r-changes/",
    "title": "Changes in R",
    "description": "The 'Changes in R' article from the 2010-2 issue.",
    "author": [
      {
        "name": "The R Core Team",
        "url": {}
      }
    ],
    "date": "2010-12-01",
    "categories": [],
    "contents": "\n\nCHANGES IN R VERSION 2.12.1\n\nNEW FEATURES\nThe DVI/PDF reference manual now includes the help pages for all the\nstandard packages: splines, stats4 and tcltk were previously\nomitted (intentionally).\nhttp://www.rforge.net has been added to the default set of\nrepositories known to setRepositories().\nxz-utils has been updated to version 5.0.0.\nreshape() now makes use of sep when forming names during\nreshaping to wide format. (PR#14435)\nlegend() allows the length of lines to be set by the end user\nvia the new argument seg.len.\nNew reference class utility methods copy(), field(),\ngetRefClass() and getClass() have been added.\nWhen a character value is used for the EXPR argument in\nswitch(), a warning is given if more than one unnamed alternative\nvalue is given. This will become an error in R 2.13.0.\nStructTS(type = \"BSM\") now allows series with just two seasons.\n(Reported by Birgit Erni.)\n\n\nINSTALLATION\nThe PDF reference manual is now built as PDF version 1.5 with object\ncompression, which on platforms for which this is not the default\n(notably MiKTeX) halves its size.\nVariable can be set during configuration, for any additional library\nflags needed when linking a shared object with the Fortran 9x\ncompiler. (Needed with Solaris Studio 12.2.)\n\n\nBUG FIXES\nseq.int() no longer sometimes evaluates arguments twice.\n(PR#14388)\nThe data.frame method of format() failed if a column name was\nlonger than 256 bytes (the maximum length allowed for an R name).\npredict(<lm object>, type =\"terms\", ...) failed if both terms\nand interval were specified. (Reported by Bill Dunlap.)\nAlso, if se.fit = TRUE the standard errors were reported for all\nterms, not just those selected by a non-null terms.\nThe TRE regular expressions engine could terminate R rather than\ngive an error when given certain invalid regular expressions.\n(PR#14398)\ncmdscale(eig = TRUE) was documented to return \\(n-1\\) eigenvalues\nbut in fact only returned k. It now returns all \\(n\\) eigenvalues.\ncmdscale(add = TRUE) failed to centre the return configuration and\nsometimes lost the labels on the points. Its return value was\ndescribed wrongly (it is always a list and contains component ac).\npromptClass() in package methods now works for reference classes\nand gives a suitably specialized skeleton of documentation.\nAlso, callSuper() now works via the methods() invocation as well\nas for initially specified methods.\ndownload.file() could leave the destination file open if the URL\nwas not able to be opened. (PR#14414)\nAssignment of an environment to functions or as an attribute to\nother objects now works for S4 subclasses of \"environment\".\nUse of [[<- for S4 subclasses of \"environment\" generated an\ninfinite recursion from the method. The method has been replaced by\ninternal code.\nIn a reference class S4 method, callSuper() now works in\ninitialize() methods when there is no explicit superclass method.\n! dropped attributes such as names and dimensions from a\nlength-zero argument. (PR#14424)\nWhen list2env() created an environment it was missing a PROTECT\ncall and so was vulnerable to garbage collection.\nSweave() with keep.source=TRUE dropped comments at the start and\nend of code chunks. It could also fail when \\\\SweaveInput was\ncombined with named chunks.\nThe Fortran code used by nls(algorithm = \"port\") could\ninfinite-loop when compiled with high optimization on a modern\nversion of gcc, and SAFE_FFLAGS is now used to make this less\nlikely. (PR#14427, seen with 32-bit Windows using gcc 4.5.0 used\nfrom R 2.12.0.)\nsapply() with default simplify = TRUE and mapply() with\ndefault SIMPLIFY = TRUE wrongly simplified language-like results,\nas, e.g., in\nmapply(1:2, c(3,7), FUN = function(i,j) call(’:’,i,j)).\nBackreferences to undefined patterns in [g]sub(pcre = TRUE) could\ncause a segfault. (PR#14431)\nThe format() (and hence the print()) method for class \"Date\"\nrounded fractional dates towards zero: it now always rounds them\ndown.\nReference S4 class creation could generate ambiguous inheritance\npatterns under very special circumstances.\n[[<- turned S4 subclasses of \"environment\" into plain\nenvironments.\nLong titles for help pages were truncated in package indices and a\nfew other places.\nAdditional utilities now work correctly with S4 subclasses of\n\"environment\" (rm, locking tools and active bindings).\nspec.ar() now also work for the \"ols\" method. (Reported by\nHans-Ruedi Kuensch.)\nThe initialization of objects from S4 subclasses of \"environment\"\nnow allocates a new environment object.\nR CMD check has more protection against (probably erroneous)\nexample or test output which is invalid in the current locale.\nqr.X() with column names and pivoting now also pivots the column\nnames. (PR#14438)\nunit.pmax() and unit.pmin() in package grid gave incorrect\nresults when all inputs were of length 1. (PR#14443)\nThe parser for NAMESPACE files ignored misspelled directives,\nrather than signalling an error. For 2.12.x a warning will be\nissued, but this will be correctly reported as an error in later\nreleases. (Reported by Charles Berry.)\nFix for subsetting of \"raster\" objects when only one of i or j\nis specified.\ngrid.raster() in package grid did not accept \"nativeRaster\"\nobjects (like rasterImage() does).\nRendering raster images in PDF output was resetting the clipping\nregion.\nRendering of raster images on Cairo X11 device was wrong,\nparticularly when a small image was being scaled up using\ninterpolation.\nWith Cairo < 1.6, will be better than before, though still a little\nclunky. With Cairo >= 1.6, should be sweet as.\nSeveral bugs fixed in read.DIF(): single column inputs caused\nerrors, cells marked as \"character\" could be converted to other\ntypes, and (in Windows) copying from the clipboard failed.\n\nCHANGES IN R VERSION 2.12.0\n\nNEW FEATURES\nReading a package’s CITATION file now defaults to ASCII rather\nthan Latin-1: a package with a non-ASCII CITATION file should\ndeclare an encoding in its DESCRIPTION file and use that encoding\nfor the CITATION file.\ndifftime() now defaults to the \"tzone\" attribute of \"POSIXlt\"\nobjects rather than to the current timezone as set by the default\nfor the tz argument. (Wish of PR#14182.)\npretty() is now generic, with new methods for \"Date\" and\n\"POSIXt\" classes (based on code contributed by Felix Andrews).\nunique() and match() are now faster on character vectors where\nall elements are in the global CHARSXP cache and have unmarked\nencoding (ASCII). Thanks to Matthew Dowle for suggesting\nimprovements to the way the hash code is generated in unique.c.\nThe enquote() utility, in use internally, is exported now.\n.C() and .Fortran() now map non-zero return values (other than\nNA_LOGICAL) for logical vectors to TRUE: it has been an implicit\nassumption that they are treated as true.\nThe print() methods for \"glm\" and \"lm\" objects now insert\nlinebreaks in long calls in the same way that the print() methods\nfor \"summary.[g]lm\" objects have long done. This does change the\nlayout of the examples for a number of packages, e.g. MASS.\n(PR#14250)\nconstrOptim() can now be used with method \"SANN\". (PR#14245)\nIt gains an argument hessian to be passed to optim(), which\nallows all the ... arguments to be intended for f() and\ngrad(). (PR#14071)\ncurve() now allows expr to be an object of mode \"expression\"\nas well as \"call\" and \"function\".\nThe \"POSIX[cl]t\" methods for Axis() have been replaced by a\nsingle method for \"POSIXt\".\nThere are no longer separate plot() methods for \"POSIX[cl]t\" and\n\"Date\": the default method has been able to handle those classes\nfor a long time. This inter alia allows a single date-time object\nto be supplied, the wish of PR#14016.\nThe methods had a different default (\"\") for xlab.\nClasses \"POSIXct\", \"POSIXlt\" and \"difftime\" have generators\n.POSIXct(), .POSIXlt() and .difftime(). Package authors are\nadvised to make use of them (they are available from R 2.11.0) to\nproof against planned future changes to the classes.\nThe ordering of the classes has been changed, so \"POSIXt\" is now\nthe second class. See the document ‘Updating packages for changes in\nR 2.12.x’ on http://developer.r-project.org for the consequences\nfor a handful of CRAN packages.\nThe \"POSIXct\" method of as.Date() allows a timezone to be\nspecified (but still defaults to UTC).\nNew list2env() utility function as an inverse of\nas.list(<environment>) and for fast multi-assign() to existing\nenvironment. as.environment() is now generic and uses list2env()\nas list method.\nThere are several small changes to output which ‘zap’ small numbers,\ne.g. in printing quantiles of residuals in summaries from \"lm\" and\n\"glm\" fits, and in test statistics in print.anova().\nSpecial names such as \"dim\", \"names\", etc, are now allowed as\nslot names of S4 classes, with \"class\" the only remaining\nexception.\nFile .Renviron can have architecture-specific versions such as\n.Renviron.i386 on systems with sub-architectures.\ninstalled.packages() has a new argument subarch to filter on\nsub-architecture.\nThe summary() method for packageStatus() now has a separate\nprint() method.\nThe default summary() method returns an object inheriting from\nclass \"summaryDefault\" which has a separate print() method that\ncalls zapsmall() for numeric/complex values.\nThe startup message now includes the platform and if used,\nsub-architecture: this is useful where different (sub-)architectures\nrun on the same OS.\nThe getGraphicsEvent() mechanism now allows multiple windows to\nreturn graphics events, through the new functions\nsetGraphicsEventHandlers(), setGraphicsEventEnv(), and\ngetGraphicsEventEnv(). (Currently implemented in the windows()\nand X11() devices.)\ntools::texi2dvi() gains an index argument, mainly for use by\nR CMD Rd2pdf.\nIt avoids the use of texindy by texinfo‘s texi2dvi >= 1.157,\nsince that does not emulate ’makeindex’ well enough to avoid\nproblems with special characters (such as (, {, !) in indices.\nThe ability of readLines() and scan() to re-encode inputs to\nmarked UTF-8 strings on Windows since R 2.7.0 is extended to\nnon-UTF-8 locales on other OSes.\nscan() gains a fileEncoding argument to match read.table().\npoints() and lines() gain \"table\" methods to match plot().\n(Wish of PR#10472.)\nSys.chmod() allows argument mode to be a vector, recycled along\npaths.\nThere are |, & and xor() methods for classes \"octmode\" and\n\"hexmode\", which work bitwise.\nEnvironment variables , , , are no longer used nor set in an R\nsession. (With the move to tools::texi2dvi(), the conventional\nenvironment variables , and will be used. options(\"dvipscmd\")\ndefaults to the value of , then to \"dvips\".)\nNew function isatty() to see if terminal connections are\nredirected.\nsummaryRprof() returns the sampling interval in component\nsample.interval and only returns in by.self data for functions\nwith non-zero self times.\nprint(x) and str(x) now indicate if an empty list x is named.\ninstall.packages() and remove.packages() with lib unspecified\nand multiple libraries in .libPaths() inform the user of the\nlibrary location used with a message rather than a warning.\nThere is limited support for multiple compressed streams on a file:\nall of [bgx]zfile() allow streams to be appended to an existing\nfile, but bzfile() reads only the first stream.\nFunction person() in package utils now uses a given/family\nscheme in preference to first/middle/last, is vectorized to handle\nan arbitrary number of persons, and gains a role argument to\nspecify person roles using a controlled vocabulary (the MARC relator\nterms).\nPackage utils adds a new \"bibentry\" class for representing and\nmanipulating bibliographic information in enhanced BibTeX style,\nunifying and enhancing the previously existing mechanisms.\nA bibstyle() function has been added to the tools package with\ndefault JSS style for rendering \"bibentry\" objects, and a\nmechanism for registering other rendering styles.\nSeveral aspects of the display of text help are now customizable\nusing the new Rd2txt_options() function.\noptions(\"help_text_width\") is no longer used.\nAdded \\\\href tag to the Rd format, to allow hyperlinks to URLs\nwithout displaying the full URL.\nAdded \\\\newcommand and \\\\renewcommand tags to the Rd format, to\nallow user-defined macros.\nNew toRd() generic in the tools package to convert objects to\nfragments of Rd code, and added \"fragment\" argument to Rd2txt(),\nRd2HTML(), and Rd2latex() to support it.\nDirectory R_HOME/share/texmf now follows the TDS conventions, so\ncan be set as a texmf tree (‘root directory’ in MiKTeX parlance).\nS3 generic functions now use correct S4 inheritance when dispatching\non an S4 object. See ?Methods, section on “Methods for S3 Generic\nFunctions” for recommendations and details.\nformat.pval() gains a ... argument to pass arguments such as\nnsmall to format(). (Wish of PR#9574)\nlegend() supports title.adj. (Wish of PR#13415)\nAdded support for subsetting \"raster\" objects, plus assigning to a\nsubset, conversion to a matrix (of colour strings), and comparisons\n(== and !=).\nAdded a new parseLatex() function (and related functions\ndeparseLatex() and latexToUtf8()) to support conversion of\nbibliographic entries for display in R.\nText rendering of \\\\itemize in help uses a Unicode bullet in UTF-8\nand most single-byte Windows locales.\nAdded support for polygons with holes to the graphics engine. This\nis implemented for the pdf(), postscript(), x11(type=\"cairo\"),\nwindows(), and quartz() devices (and associated raster formats),\nbut not for x11(type=\"Xlib\") or xfig() or pictex(). The\nuser-level interface is the polypath() function in graphics and\ngrid.path() in grid.\nFile NEWS is now generated at installation with a slightly\ndifferent format: it will be in UTF-8 on platforms using UTF-8, and\notherwise in ASCII. There is also a PDF version, NEWS.pdf,\ninstalled at the top-level of the R distribution.\nkmeans(x, 1) now works. Further, kmeans now returns between and\ntotal sum of squares.\narrayInd() and which() gain an argument useNames. For\narrayInd, the default is now false, for speed reasons.\nAs is done for closures, the default print method for the formula\nclass now displays the associated environment if it is not the\nglobal environment.\nA new facility has been added for inserting code into a package\nwithout re-installing it, to facilitate testing changes which can be\nselectively added and backed out. See ?insertSource.\nNew function readRenviron to (re-)read files in the format of\n~/.Renviron and Renviron.site.\nrequire() will now return FALSE (and not fail) if loading the\npackage or one of its dependencies fails.\naperm() now allows argument perm to be a character vector when\nthe array has named dimnames (as the results of table() calls do).\nSimilarly, array() allows MARGIN to be a character vector.\n(Based on suggestions of Michael Lachmann.)\nPackage utils now exports and documents functions\naspell_package_Rd_files() and aspell_package_vignettes() for\nspell checking package Rd files and vignettes using Aspell, Ispell\nor Hunspell.\nPackage news can now be given in Rd format, and news() prefers\nthese inst/NEWS.Rd files to old-style plain text NEWS or\ninst/NEWS files.\nNew simple function packageVersion().\nThe PCRE library has been updated to version 8.10.\nThe standard Unix-alike terminal interface declares its name to\nreadline as ‘R’, so that can be used for conditional sections in\n~/.inputrc files.\n‘Writing R Extensions’ now stresses that the standard sections in\n.Rd files (other than \\\\alias, \\\\keyword and \\\\note) are\nintended to be unique, and the conversion tools now drop duplicates\nwith a warning.\nThe .Rd conversion tools also warn about an unrecognized type in a\n\\\\docType section.\necdf() objects now have a quantile() method.\nformat() methods for date-time objects now attempt to make use of\na \"tzone\" attribute with \"%Z\" and \"%z\" formats, but it is not\nalways possible. (Wish of PR#14358.)\ntools::texi2dvi(file, clean = TRUE) now works in more cases (e.g.\nwhere emulation is used and when file is not in the current\ndirectory).\nNew function droplevels() to remove unused factor levels.\nsystem(command, intern = TRUE) now gives an error on a Unix-alike\n(as well as on Windows) if command cannot be run. It reports a\nnon-success exit status from running command as a warning.\nOn a Unix-alike an attempt is made to return the actual exit status\nof the command in system(intern = FALSE): previously this had been\nsystem-dependent but on POSIX-compliant systems the value return was\n256 times the status.\nsystem() has a new argument ignore.stdout which can be used to\n(portably) ignore standard output.\nsystem(intern = TRUE) and pipe() connections are guaranteed to\nbe available on all builds of R.\nSys.which() has been altered to return \"\" if the command is not\nfound (even on Solaris).\nA facility for defining reference-based S4 classes (in the OOP style\nof Java, C++, etc.) has been added experimentally to package\nmethods; see ?ReferenceClasses.\nThe predict method for \"loess\" fits gains an na.action\nargument which defaults to na.pass rather than the previous\ndefault of na.omit.\nPredictions from \"loess\" fits are now named from the row names of\nnewdata.\nParsing errors detected during Sweave() processing will now be\nreported referencing their original location in the source file.\nNew adjustcolor() utility, e.g., for simple translucent color\nschemes.\nqr() now has a trivial lm method with a simple (fast) validity\ncheck.\nAn experimental new programming model has been added to package\nmethods for reference (OOP-style) classes and methods. See\n?ReferenceClasses.\nbzip2 has been updated to version 1.0.6 (bug-fix release). now\nrequires at least version 1.0.6.\nR now provides jss.cls and jss.bst (the class and bib style file\nfor the Journal of Statistical Software) as well as RJournal.bib\nand Rnews.bib, and R CMD ensures that the .bst and .bib\nfiles are found by BibTeX.\nFunctions using the environment variable no longer quote the value\nwhen making system calls. This allows values such as\ntar –force-local, but does require additional quotes in, e.g.,\nTAR = \"’/path with spaces/mytar’\".\n\n\nDEPRECATED & DEFUNCT\nSupplying the parser with a character string containing both\noctal/hex and Unicode escapes is now an error.\nFile extension .C for C++ code files in packages is now defunct.\nR CMD check no longer supports configuration files containing Perl\nconfiguration variables: use the environment variables documented in\n‘R Internals’ instead.\nThe save argument of require() now defaults to FALSE and\nsave = TRUE is now deprecated. (This facility is very rarely\nactually used, and was superseded by the Depends field of the\nDESCRIPTION file long ago.)\nR CMD check –no-latex is deprecated in favour of .\nR CMD Sd2Rd is formally deprecated and will be removed in R\n2.13.0.\n\n\nPACKAGE INSTALLATION\ninstall.packages() has a new argument libs_only to optionally\npass to R CMD INSTALL and works analogously for Windows binary\ninstalls (to add support for 64- or 32-bit Windows).\nWhen sub-architectures are in use, the installed architectures are\nrecorded in the Archs field of the DESCRIPTION file. There is a\nnew default filter, \"subarch\", in available.packages() to make\nuse of this.\nCode is compiled in a copy of the src directory when a package is\ninstalled for more than one sub-architecture: this avoid problems\nwith cleaning the sources between building sub-architectures.\nR CMD INSTALL –libs-only no longer overrides the setting of\nlocking, so a previous version of the package will be restored\nunless is specified.\n\n\nUTILITIES\nR CMD Rprof|build|check are now based on R rather than Perl\nscripts. The only remaining Perl scripts are the deprecated\nR CMD Sd2Rd and install-info.pl (used only if install-info is\nnot found) as well as some maintainer-mode-only scripts.\nbecause these have been completely rewritten, users should not\nexpect undocumented details of previous implementations to have been\nduplicated.\nR CMD no longer manipulates the environment variables and .\nR CMD check has a new argument to confine tests to those needed to\ncheck an additional sub-architecture.\nIts check for “Subdirectory ‘inst’ contains no files” is more\nthorough: it looks for files, and warns if there are only empty\ndirectories.\nEnvironment variables such as and those used for customization can\nbe set for the duration of checking via a file\n~/.R/check.Renviron (in the format used by .Renviron, and with\nsub-architecture specific versions such as\n~/.R/check.Renviron.i386 taking precedence).\nThere are new options to check the package under all of the\ninstalled sub-architectures and to confine checking to the\nsub-architecture under which check is invoked. If neither option\nis supplied, a test is done of installed sub-architectures and all\nthose which can be run on the current OS are used.\nUnless multiple sub-architectures are selected, the install done by\ncheck for testing purposes is only of the current sub-architecture\n(via R CMD INSTALL –no-multiarch).\nIt will skip the check for non-ascii characters in code or data if\nthe environment variables or are respectively set to . (Suggestion\nof Vince Carey.)\nR CMD build no longer creates an INDEX file (R CMD INSTALL\ndoes so), and –force removes (rather than overwrites) an existing\nINDEX file.\nIt supports a file ~/.R/build.Renviron analogously to check.\nIt now runs build-time \\\\Sexpr expressions in help files.\nR CMD Rd2dvi makes use of tools::texi2dvi() to process the\npackage manual. It is now implemented entirely in R (rather than\npartially as a shell script).\nR CMD Rprof now uses utils::summaryRprof() rather than Perl. It\nhas new arguments to select one of the tables and to limit the\nnumber of entries printed.\nR CMD Sweave now runs R with –vanilla so the environment setting\nof will always be used.\n\n\nC-LEVEL FACILITIES\nlang5() and lang6() (in addition to pre-existing lang[1-4]())\nconvenience functions for easier construction of eval() calls. If\nyou have your own definition, do wrap it inside\n#ifndef lang5 .... #endif to keep it working with old and new R.\nHeader R.h now includes only the C headers it itself needs, hence\nno longer includes errno.h. (This helps avoid problems when it is\nincluded from C++ source files.)\nHeaders Rinternals.h and R_ext/Print.h include the C++ versions\nof stdio.h and stdarg.h respectively if included from a C++\nsource file.\n\n\nINSTALLATION\nA C99 compiler is now required, and more C99 language features will\nbe used in the R sources.\nTcl/Tk >= 8.4 is now required (increased from 8.3).\nSystem functions access, chdir and getcwd are now essential to\nconfigure R. (In practice they have been required for some time.)\nmake check compares the output of the examples from several of the\nbase packages to reference output rather than the previous output\n(if any). Expect some differences due to differences in\nfloating-point computations between platforms.\nFile NEWS is no longer in the sources, but generated as part of\nthe installation. The primary source for changes is now\ndoc/NEWS.Rd.\nThe popen system call is now required to build R. This ensures the\navailability of system(intern = TRUE), pipe() connections and\nprinting from postscript().\nThe pkg-config file libR.pc now also works when R is installed\nusing a sub-architecture.\nR has always required a BLAS that conforms to IE60559 arithmetic,\nbut after discovery of more real-world problems caused by a BLAS\nthat did not, this is tested more thoroughly in this version.\n\n\nBUG FIXES\nCalls to selectMethod() by default no longer cache inherited\nmethods. This could previously corrupt methods used by as().\nThe densities of non-central chi-squared are now more accurate in\nsome cases in the extreme tails, e.g. dchisq(2000, 2, 1000), as a\nseries expansion was truncated too early. (PR#14105)\npt() is more accurate in the left tail for ncp large, e.g.\npt(-1000, 3, 200). (PR#14069)\nThe default C function (R_binary) for binary ops now sets the S4\nbit in the result if either argument is an S4 object. (PR#13209)\nsource(echo=TRUE) failed to echo comments that followed the last\nstatement in a file.\nS4 classes that contained one of \"matrix\", \"array\" or \"ts\" and\nalso another class now accept superclass objects in new(). Also\nfixes failure to call validObject() for these classes.\nConditional inheritance defined by argument test in\nmethods::setIs() will no longer be used in S4 method selection\n(caching these methods could give incorrect results). See ?setIs.\nThe signature of an implicit generic is now used by setGeneric()\nwhen that does not use a definition nor explicitly set a signature.\nA bug in callNextMethod() for some examples with \"...\" in the\narguments has been fixed. See file\nsrc/library/methods/tests/nextWithDots.R in the sources.\nmatch(x, table) (and hence %in%) now treat \"POSIXlt\"\nconsistently with, e.g., \"POSIXct\".\nBuilt-in code dealing with environments (get(), assign(),\nparent.env(), is.environment() and others) now behave\nconsistently to recognize S4 subclasses; is.name() also recognizes\nsubclasses.\nThe abs.tol control parameter to nlminb() now defaults to 0.0\nto avoid false declarations of convergence in objective functions\nthat may go negative.\nThe standard Unix-alike termination dialog to ask whether to save\nthe workspace takes a EOF response as n to avoid problems with a\ndamaged terminal connection. (PR#14332)\nAdded warn.unused argument to hist.default() to allow\nsuppression of spurious warnings about graphical parameters used\nwith plot=FALSE. (PR#14341)\npredict.lm(), summary.lm(), and indeed lm() itself had issues\nwith residual DF in zero-weighted cases (the latter two only in\nconnection with empty models). (Thanks to Bill Dunlap for spotting\nthe predict() case.)\naperm() treated resize = NA as resize = TRUE.\nconstrOptim() now has an improved convergence criterion, notably\nfor cases where the minimum was (very close to) zero; further, other\ntweaks inspired from code proposals by Ravi Varadhan.\nRendering of S3 and S4 methods in man pages has been corrected and\nmade consistent across output formats.\nSimple markup is now allowed in \\\\title sections in .Rd files.\nThe behaviour of as.logical() on factors (to use the levels) was\nlost in R 2.6.0 and has been restored.\nprompt() did not backquote some default arguments in the \\\\usage\nsection. (Reported by Claudia Beleites.)\nwriteBin() disallows attempts to write 2GB or more in a single\ncall. (PR#14362)\nnew() and getClass() will now work if Class is a subclass of\n\"classRepresentation\" and should also be faster in typical calls.\nThe summary() method for data frames makes a better job of names\ncontaining characters invalid in the current locale.\n[[ sub-assignment for factors could create an invalid factor\n(reported by Bill Dunlap).\nNegate(f) would not evaluate argument f until first use of\nreturned function (reported by Olaf Mersmann).\nquietly=FALSE is now also an optional argument of library(), and\nconsequently, quietly is now propagated also for loading dependent\npackages, e.g., in require(*, quietly=TRUE).\nIf the loop variable in a for loop was deleted, it would be\nrecreated as a global variable. (Reported by Radford Neal; the fix\nincludes his optimizations as well.)\nTask callbacks could report the wrong expression when the task\ninvolved parsing new code. (PR#14368)\ngetNamespaceVersion() failed; this was an accidental change in\n2.11.0. (PR#14374)\nidentical() returned FALSE for external pointer objects even\nwhen the pointer addresses were the same.\nL$a@x[] <- val did not duplicate in a case it should have.\ntempfile() now always gives a random file name (even if the\ndirectory is specified) when called directly after startup and\nbefore the R RNG had been used. (PR#14381)\nquantile(type=6) behaved inconsistently. (PR#14383)\nbackSpline(.) behaved incorrectly when the knot sequence was\ndecreasing. (PR#14386)\nThe reference BLAS included in R was assuming that 0*x and x*0\nwere always zero (whereas they could be NA or NaN in IEC 60559\narithmetic). This was seen in results from tcrossprod, and for\nexample that log(0) %*% 0 gave 0.\nThe calculation of whether text was completely outside the device\nregion (in which case, you draw nothing) was wrong for screen\ndevices (which have [0, 0] at top-left). The symptom was (long)\ntext disappearing when resizing a screen window (to make it\nsmaller). (PR#14391)\nmodel.frame(drop.unused.levels = TRUE) did not take into account\nNA values of factors when deciding to drop levels. (PR#14393)\nlibrary.dynam.unload required an absolute path for libpath.\n(PR#14385)\nBoth library() and loadNamespace() now record absolute paths for\nuse by searchpaths() and getNamespaceInfo(ns, \"path\").\nThe self-starting model NLSstClosestX failed if some deviation was\nexactly zero. (PR#14384)\nX11(type = \"cairo\") (and other devices such as png using\ncairographics) and which use Pango font selection now work around a\nbug in Pango when very small fonts (those with sizes between 0 and 1\nin Pango’s internal units) are requested. (PR#14369)\nAdded workaround for the font problem with X11(type = \"cairo\") and\nsimilar on Mac OS X whereby italic and bold styles were\ninterchanged. (PR#13463 amongst many other reports.)\nsource(chdir = TRUE) failed to reset the working directory if it\ncould not be determined – that is now an error.\nFix for crash of example(rasterImage) on x11(type=\"Xlib\").\nForce Quartz to bring the on-screen display up-to-date immediately\nbefore the snapshot is taken by grid.cap() in the Cocoa\nimplementation. (PR#14260)\nmodel.frame had an unstated 500 byte limit on variable names.\n(Example reported by Terry Therneau.)\nThe 256-byte limit on names is now documented.\nSubassignment by [, [[ or $ on an expression object with value\nNULL coerced the object to a list.\n\nCHANGES IN R VERSION 2.11.1 patched\n\nNEW FEATURES\ninstall.packages() has a new optional argument INSTALL_opts\nwhich can be used to pass options to R CMD INSTALL for\nsource-package installs.\nR CMD check now runs the package-specific tests with to facilitate\ncomparison to .Rout.save files.\nsessionInfo() gives more detailed platform information, including\n32/64-bit and the sub-architecture if one is used.\n\n\nDEPRECATED & DEFUNCT\nThe use of Perl configuration variables for R CMD check (as\npreviously documented in ‘Writing R Extensions’) is deprecated and\nwill be removed in R 2.12.0. Use the environment variables\ndocumented in ‘R Internals’ instead.\n\n\nBUG FIXES\nR CMD Rd2dvi failed if run from a path containing space(s). This\nalso affected R CMD check, which calls Rd2dvi.\nstripchart() could fail with an empty factor level. (PR#14317)\nText help rendering of \\\\tabular{} has been improved: under some\ncircumstances leading blank columns were not rendered.\nstrsplit(x, fixed=TRUE) marked UTF-8 strings with the local\nencoding when no splits were found.\nweighted.mean(NA, na.rm=TRUE) and similar now returns NaN again,\nas it did prior to R 2.10.0.\nR CMD had a typo in its detection of whether the environment\nvariable was set (reported by Martin Morgan).\nThe command-line parser could mistake for one of the options for\nsetting limits for Ncells or Vcells.\nThe internal strptime() could corrupt its copy of the timezone\nwhich would then lead to spurious warnings. (PR#14338)\ndir.create(recursive = TRUE) could fail if one of the components\nexisted but was a directory on a read-only file system. (Seen on\nSolaris, where the error code returned is not even listed as\npossible on the man page.)\nThe postscript() and pdf() devices will now allow lwd values\nless than 1 (they used to force such values to be 1).\nFixed font face for CID fonts in pdf() graphics output. (PR#14326)\nGERaster() now checks for width or height of zero and does nothing\nin those cases; previously the behaviour was undefined, probably\ndevice-specific, and possibly dangerous.\nwilcox.test(x, y, conf.int = TRUE) failed with an unhelpful\nmessage if x and y were constant vectors, and similarly in the\none-sample case. (PR#14329)\nImproperly calling Recall() from outside a function could cause a\nsegfault. (Reported by Robert McGehee.)\n\\\\Sexpr[result=rd] in an Rd file added a spurious newline, which\nwas displayed as extra whitespace when rendered.\nrequire(save = TRUE) recorded the names of packages it failed to\nload.\npackageStatus() could return a data frame with duplicate row names\nwhich could then not be printed.\ntxtProgressBar(style = 2) did not work correctly.\ntxtProgressBar(style = 3) did not display until a non-minimum\nvalue was set.\ncontour() did not display dashed line types properly when contour\nlines were labelled. (Reported by David B. Thompson.)\ntools::undoc() again detects undocumented data objects. Of course,\nthis also affects R CMD check.\nksmooth(x,NULL) no longer segfaults.\napproxfun(), approx(), splinefun() and spline() could be\nconfused by x values that were different but so close as to print\nidentically. (PR#14377)\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2010-2-r-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2010-2 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2010-12-01",
    "categories": [],
    "contents": "\n1 Donations and new members\nDonations\nAgrocampus Ouest, France\nHelsana Versicherungen AG, Switzerland\nKristian Kieselman, Sweden\nNew benefactors\neoda, Germany\nGiannasca Corrado & Montagna Maria, Italy\nNew supporting institutions\nMarine Scotland Science, UK\nNew supporting members\nIan M. Cook, USA\nChris Evans, UK\nMartin Fewsow, Germany\nLaurence Frank, Netherlands\nSusan Gruber, USA\nRobert A. Muenchen, USA\nGeoff Potvin, USA\nIvo Welch, USA\nAlex Zolot, USA\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2010-2-user/",
    "title": "useR! 2010",
    "description": "A summary of the useR! 2010 conference.",
    "author": [
      {
        "name": "Katharine Mullen",
        "url": {}
      }
    ],
    "date": "2010-12-01",
    "categories": [],
    "contents": "\n\nThe R user conference, useR! 2010, took place on the Gaithersburg,\nMaryland, USA campus of the National Institute of Standards and\nTechnology (NIST) July 21-23 2010. Following the five previous useR!\nconferences (held in Austria, Germany, Iowa, and France), useR! 2010\nfocused on\nR as the ‘lingua franca’ of data analysis and statistical computing,\nproviding a venue to discuss and exchange ideas on the use of R for\nstatistical computations, data analysis, visualization, and exciting\napplications in various fields and\nproviding an overview of the new features of the rapidly evolving R\nproject.\nThe conference drew over 450 R users hailing from 29 countries. The\ntechnical program was composed of 167 contributed presentations, seven\ninvited lectures, a poster session, and a panel discussion on\n‘Challenges of Bringing R into Commercial Environments’. The social\nprogram of the conference included several receptions and a dinner at\nthe National Zoo.\n1 Program, organizing and conference committees\nOrganization of the conference was thanks to individuals participating\nin the following committees:\nProgram Committee:\nLouis Bajuk-Yorgan, Dirk Eddelbuettel, John Fox, Virgilio Gómez-Rubio,\nRichard Heiberger, Torsten Hothorn, Aaron King, Jan de Leeuw, Nicholas\nLewin-Koh, Andy Liaw, Uwe Ligges, Martin Mächler, Katharine Mullen,\nHeather Turner, Ravi Varadhan, H. D. Vinod, John Verzani, Alan\nZaslavsky, Achim Zeileis\nOrganizing Committee:\nKevin Coakley, Nathan Dodder, David Gil, William Guthrie, Olivia Lau,\nWalter Liggett, John Lu, Katharine Mullen, Jonathon Phillips, Antonio\nPossolo, Daniel Samarov, Ravi Varadhan\nR Conference Committee:\nTorsten Hothorn, Achim Zeileis\n2 User-contributed presentations\nThe diversity of interests in the R community was reflected in the\nthemes of the user-contributed sessions. The themes were:\nBioinformatics workflows\nBiostatistics (three sessions)\nBiostatistics workflows\nBusiness intelligence\nCloud computing\nCommercial applications (two sessions)\nComputer experiments and simulation\nData manipulation and classification\nData mining, machine learning\nFinance and resource allocation\nfMRI\nFene expressions, genetics\nGrid computing\nGraphical User Interfaces (two sessions)\nHigh-performance-computing\nInterfaces\nLists and objects\nLongitudinal data analysis\nMetRology\nOptimization\nParallel computing\nPedagogy (three sessions)\nReal-time computing\nReproducible research and generating reports\nR social networks\nRuG panel discussion\nSocial sciences\nSpatio-temporal data analysis\nSpreadsheets and RExcel\nTime series\nVisualization\nIn addition to sessions on these themes, research was presented in a\nposter session and in Kaleidescope sessions aimed at a broad audience.\n3 Tutorials\nThe day before the official start of the conference, on July 20, the\nfollowing nineteen 3-hour tutorials were given by R experts:\nDouglas Bates: Fitting and evaluating mixed models using lme4\nPeter Danenberg and Manuel Eugster: Literate programming with\nRoxygen\nKarin Groothuis-Oudshoorn and Stef van Buuren: Handling missing\ndata in R with MICE\nFrank Harrell Jr: Statistical presentation graphics\nFrançois Husson and Julie Josse: Exploratory data analysis with\na special focus on clustering and multiway methods\nUwe Ligges: My first R package\nDaniel Samarov, Errol Strain and Elaine McVey: R for Eclipse\nJing Hua Zhao: Genetic analysis of complex traits\nAlex Zolot: Work with R on Amazon’s Cloud\nKarim Chine: Elastic-R, a google docs-like portal for data\nanalysis in the cloud\nDirk Eddelbuettel: Introduction to high-performance computing\nwith R\nMichael Fay: Interval censored data analysis\nVirgilio Gómez-Rubio: Applied spatial data analysis with R\nFrank Harrell Jr: Regression modeling strategies using the R\npackage rms\nOlivia Lau: A crash course in R programming\nFriedrich Leisch: Sweave - Writing dynamic and reproducible\ndocuments\nJohn Nash: Optimization and related nonlinear modelling\ncomputations in R\nBrandon Whitcher, Pierre Lafaye de Micheaux, Bradley Buchsbaum and\nPolzehl: Medical image analysis for structural and functional MRI\n4 Invited lectures\nThe distinguished invited lecturers were:\nMark S. Handcock: Statistical Modeling of Networks in R\nFrank E. Harrell Jr: Information Allergy\nFriedrich Leisch: Reproducible Statistical Research in Practice\nUwe Ligges: Prospects and Challenges for CRAN - with a glance on\n64-bit Windows binaries\nRichard M. Stallman: Free Software in Ethics and in Practice\nLuke Tierney: Some possible directions for the R engine\nDiethelm Würtz: The Hull, the Feasible Set, and the Risk\nSurface: A Review of the Portfolio Modeling Infrastructure in\nR/Rmetrics\nIn addition, Antonio Possolo (Chief of the Statistical Engineering\nDivision at NIST) began the conference with a rousing speech to welcome\nparticipants.\n5 Conference-related information and thanks\nThe conference webpage http://www.R-project.org/useR-2010 makes\navailable abstracts and slides associated with presentations, as well as\nlinks to video of plenary sessions. Questions regarding the conference\nmay be addressed to useR-2010@R-project.org.\nMany thanks to all those who contributed to useR! 2010. The talks,\nposters, ideas, and spirit of cooperation that R users from around the\nworld brought to Gaithersburg made the conference a great success.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2010-2-whats-new/",
    "title": "What's New?",
    "description": "We discuss how news in R and add-on packages can be disseminated. R 2.10.0 has added facilities for computing on news in a common plain text format. In R 2.12.0, the Rd format has been further enhanced so that news can be very conveniently recorded in Rd, allowing for both improved rendering and the development of new news services.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Duncan Murdoch",
        "url": {}
      }
    ],
    "date": "2010-12-01",
    "categories": [],
    "contents": "\n\nThe R development community has repeatedly discussed how to best\nrepresent and disseminate the news in R and R add-on packages. The GNU\nCoding Standards\n(http://www.gnu.org/prep/standards/html_node/NEWS-File.html) say\n\nIn addition to its manual, the package should have a file named NEWS\nwhich contains a list of user-visible changes worth mentioning. In\neach new release, add items to the front of the file and identify the\nversion they pertain to. Don’t discard old items; leave them in the\nfile after the newer items. This way, a user upgrading from any\nprevious version can see what is new.\nIf the NEWS file gets very long, move some of the older items into a\nfile named ONEWS and put a note at the end referring the user to\nthat file.\n\nFor a very long time R itself used a three-layer (series, version,\ncategory) plain text NEWS file recording individual news items in\nitemize-type lists, using ‘o’ as item tag and aligning items to a common\ncolumn (as quite commonly done in open source projects).\nR 2.4.0 added a function readNEWS() (eventually moved to package\ntools) for reading the R NEWS file into a news hierarchy (a series\nlist of version lists of category lists of news items). This makes it\npossible to compute on the news (e.g. changes are displayed daily in the\nRSS feeds available from\nhttp://developer.r-project.org/RSSfeeds.html), and to transform the\nnews structure into sectioning markup (e.g. when creating an HTML\nversion for reading via the on-line help system). However, the items\nwere still plain text: clearly, it would be useful to be able to\nhyperlink to resources provided by the on-line help system\n(Murdoch and Urbanek 2009) or other URLs, e.g., those\nproviding information on bug reports. In addition, it has always been\nquite a nuisance to add LaTeX markup to the news items for the release\nnotes in the R Journal (and its predecessor, R News). The R Core team\nhad repeatedly discussed the possibilities of moving to a richer markup\nsystem (and generating plain text, HTML and LaTeX from\nthis), but had been unable to identify a solution that would be\nappropriate in terms of convenience as well as the effort required.\nR add-on packages provide news-type information in a variety of places\nand plain text formats, with a considerable number of NEWS files in\nthe package top-level source directory or its inst subdirectory, and\nin the spirit of a one- or two-layer variant of the R news format.\nWhereas all these files can conveniently be read by “users”, the lack of\nstandardization implies that reliable computation on the news items is\nbarely possible, even though this could be very useful. For example,\nupgrading packages could optionally display the news between the\navailable and installed versions of packages (similar to the\napt-listchanges facility in Debian-based Linux systems). One could\nalso develop repository-level services extracting and disseminating the\nnews in all packages in the repository (or suitable groups of these,\nsuch as task views (Zeileis 2005)) on a regular basis. In\naddition, we note that providing the news in plain text limits the\nusefulness in package web pages and for possible inclusion in package\nreference manuals (in PDF format).\nR 2.10.0 added a function news() (in package utils) to possibly\nextract the news for R or add-on packages into a simple (plain text)\ndata base, and use this for simple queries. The data base is a character\nframe with variables Version, Category, Date and Text, where the\nlast contains the entry texts read, and the other variables may be NA\nif they were missing or could not be determined. These variables can be\nused in the queries. E.g., we build a data base of all currently\navailable R news entries:\n> db <- news()\nThis has 2950 news entries, distributed according to version as follows:\n> with(db, table(Version))\nVersion\n         2.0.1  2.0.1 patched          2.1.0 \n            56             27            223 \n         2.1.1  2.1.1 patched         2.10.0 \n            56             31            153 \n        2.10.1 2.10.1 patched         2.11.0 \n            43             35            132 \n        2.11.1          2.2.0          2.2.1 \n            28            188             63 \n 2.2.1 patched          2.3.0          2.3.1 \n            18            250             38 \n 2.3.1 patched          2.4.0          2.4.1 \n            28            225             60 \n 2.4.1 patched          2.5.0          2.5.1 \n            15            208             50 \n 2.5.1 patched          2.6.0          2.6.1 \n            16            177             31 \n         2.6.2  2.6.2 patched          2.7.0 \n            53             14            186 \n         2.7.1          2.7.2  2.7.2 patched \n            66             45              6 \n         2.8.0          2.8.1  2.8.1 patched \n           132             59             27 \n         2.9.0          2.9.1          2.9.2 \n           124             56             26 \n 2.9.2 patched \n             5 \n(This shows “versions” such as ‘2.10.1 patched’, which correspond to\nnews items in the time interval between the last patchlevel release and\nthe next minor or major releases of R (in the above, 2.10.1 and 2.11.0),\nrespectively. These are not valid version numbers, and are treated as\nthe corresponding patchlevel version in queries.) To extract all bug\nfixes since R 2.11.0 that include a PR number from a formal bug report,\nwe can query the news db as follows:\n> items <- news(Version >= \"2.11.0\" & \n+               grepl(\"^BUG\", Category) & \n+               grepl(\"PR#\", Text),\n+               db = db)\nThis finds 22 such items, the first one being\n> writeLines(strwrap(items[1, \"Text\"]))\nThe C function mkCharLenCE now no longer\nreads past 'len' bytes (unlikely to be a\nproblem except in user code). (PR#14246)\nTrying to extract the news for add-on packages involved a\ntrial-and-error process to develop a reasonably reliable default reader\nfor the NEWS files in a large subset of available packages, and\nsubsequently documenting the common format (requirements). This reader\nlooks for version headers and splits the news file into respective\nchunks. It then tries to read the news items from the chunks, after\npossibly splitting according to category. For each chunk found, it\nrecords whether (it thinks) it successfully processed the chunk. To\nassess how well this reader actually works, we apply it to all NEWS\nfiles in the CRAN packages. As of 2010-09-11, there are 427 such files\nfor a “news coverage” of about 20%. For 67 files, no version chunks are\nfound. For 40 files, all chunks are marked as bad (indicating that we\nfound some version headers, but the files really use a different\nformat). For 60 files, some chunks are bad, with the following summary\nof the frequencies of bad chunks:\n    Min.  1st Qu.   Median     Mean  3rd Qu. \n0.005747 0.057280 0.126800 0.236500 0.263800 \n    Max. \n0.944400 \nFinally, for 260 files, no chunks are marked as bad, suggesting a\nsuccess rate of about 61 percent. Given the lack of formal\nstandardization, this is actually “not bad for a start”, but certainly\nnot good enough. Clearly, package maintainers could check readability\nfor themselves and fix incompatibilities with the default format, or\nswitch to it (or contribute readers for their own formats). But ideally,\nmaintainers could employ a richer format allowing for more reliable\ncomputations and better processing.\nIn R 2.12.0, the new Rd format was enhanced in several important ways.\nThe \\subsection and \\newcommand macros were added, to allow for\nsubsections within sections, and user-defined macros. One can now\nconvert R objects to fragments of Rd code, and process these. And\nfinally, the rendering (of text in particular) is more customizable.\nGiven the availability of \\subsection, one can now conveniently map\none- and two-layer hierarchies of item lists into sections (and\nsubsections) of Rd \\itemize lists. Altogether, the new Rd format\nobviously becomes a very attractive (some might claim, the canonical)\nformat for maintaining R and package news information, in particular\ngiven that most R developers will be familiar with the Rd format and\nthat Rd can be rendered as text, HTML (for on-line help)\nand LaTeX (for PDF manuals).\nR 2.12.0 itself has switched to the Rd format for recording its news. To\nsee the effect, run help.start(), click on the NEWS link and note that\ne.g. bug report numbers are now hyperlinked to the respective pages in\nthe bug tracking system. The conversion was aided by the (internal)\nutility function news2Rd() in package tools which converted the\nlegacy plain text NEWS to Rd, but of course required additional effort\nenriching the markup.\nR 2.12.0 is also aware of inst/NEWS.Rd files in add-on packages, which\nare used by news() in preference to the plain text NEWS and\ninst/NEWS files. For NEWS files in a format which can successfully\nbe handled by the default reader, package maintainers can use\ntools:::news2Rd(dir, \"NEWS.Rd\"), possibly with additional argument\ncodify = TRUE, with dir a character string specifying the path to a\npackage’s root directory. Upon success, the NEWS.Rd file can be\nfurther improved and then be moved to the inst subdirectory of the\npackage source directory. For now, the immediate benefits of switching\nto the new format is that news() will work more reliably, and that the\npackage news web pages on CRAN will look better.\nAs packages switch to Rd format for their news, additional services\ntaking advantage of the new format can be developed and deployed. For\nthe near future, we are planning to integrate package news into the\non-line help system, and to optionally integrate the news when\ngenerating the package reference manuals. A longer term goal is to\nenhance the package management system to include news computations in\napt-listchanges style. We hope that repository “news providers” will\ntake advantage of the available infrastructure to enhance their news\nservices (e.g., using news diffs instead of, or in addition to, the\ncurrently employed recursive diff summaries). But perhaps most\nimportantly, we hope that the new format will make it more attractive\nfor package maintainers to actually provide valuable news information.\n\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\nD. Murdoch and S. Urbanek. The new R help system. The R Journal, 1(2): 60–65, 2009.\n\n\nA. Zeileis. CRAN task views. R News, 5(1): 39–40, 2005. URL http.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2010-1-biconductor/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2010-1 issue.",
    "author": [
      {
        "name": "Bioconductor Team",
        "url": {}
      }
    ],
    "date": "2010-06-01",
    "categories": [],
    "contents": "\n\nWe are pleased to announce Bioconductor 2.6, released on April 23, 2010.\nBioconductor 1.6 is compatible with R 2.11.1, and consists of 389\npackages. There are 37 new packages, and enhancements to many others.\nExplore Bioconductor at http://bioconductor.org, and install packages\nwith\nsource(\"http://bioconductor.org/biocLite.R\")\nbiocLite() # install standard packages...\nbiocLite(\"IRanges\") # ...or IRanges\n1 New and revised packages\nSequence analysis\n\npackages address infrastructure\n(GenomicRanges,\nRsamtools,\ngirafe);\nChIP-seq\n(BayesPeak,\nCSAR,\nPICS);\ndigital gene expression and RNA-seq\n(DESeq,\ngoseq,\nsegmentSeq);\nand motif discovery\n(MotIV,\nrGADEM).\n\nMicroarray analysis\n\npackages introduce new approaches to pre-process and\ntechnology-specific assays\n(affyILM,\nfrma,\nfrmaTools,\nBeadDataPackR,\nMassArray);\nanalysis of specific experimental protocols\n(charm,\ngenoCN,\niChip,\nmethVisual);\nand novel statistical methods\n(ConsensusClusterPlus,\nExpressionView,\neisa,\nGSRI,\nPROMISE,\ntigre).\n\nFlow cytometry\n\npackages include\nSamSPECTRAL,\nflowMeans,\nflowTrans,\nand\niFlow.\n\nAnnotation and integrative analysis\n\npackages facilitate interfacing with GEO\n(GEOsubmission),\nthe Sequence Read Archive\n(SRAdb),\nand tabulation of genome sequence project data\n(genomes);\nthe\nGSRI\npackage to estimate differentially expressed genes in a gene set;\nPCA and CCA dependency modeling\n(pint);\nand updated access to exon array annotations\n(xmapcore).\n\nFurther information on new and existing packages can be found on the\nBioconductor web site, which contains ‘views’ that identify coherent\ngroups of packages. The views link to on-line package descriptions,\nvignettes, reference manuals, and use statistics.\n2 Other activities\nTraining courses and a European developer conference were important\naspects of Bioconductor, with recent successful offerings ranging from\nmicroarray and sequence analysis through advanced R programming\n(http://bioconductor.org/workshops). The active Bioconductor mailing\nlists (http://bioconductor.org/docs/mailList.html) connect users with\neach other, to domain experts, and to maintainers eager to ensure that\ntheir packages satisfy the needs of leading edge approaches. The\nBioconductor team continues to ensure quality software through technical\nand scientific reviews of new packages, and daily builds of released\npackages on Linux, Windows (32- and now 64-bit), and Macintosh\nplatforms.\n3 Looking forward\nBioC2010 is the Bioconductor annual conference, scheduled for July\n29–30 at the Fred Hutchinson Cancer Research Centre in Seattle,\nWashington, and with a developer day on July 28. The conference features\nmorning scientific talks and afternoon practical sessions\n(https://secure.bioconductor.org/BioC2010/). European developers will\nhave an opportunity to meet in Heidelberg, Germany, on 17–18 November.\nContributions from the Bioconductor community play an important role in\nshaping each release. We anticipate continued efforts to provide\nstatistically informed analysis of next generation sequence data, as\nwell as development of algorithms for advanced analysis of microarrays.\nAreas of opportunity include the ChIP-seq, RNA-seq, rare variant, and\nstructural variant domains. The next release cycle promises to be one of\nactive scientific growth and exploration!\n\n\nBioconductor packages used\nGenomicRanges, Rsamtools, girafe, BayesPeak, CSAR, PICS, DESeq, goseq, segmentSeq, MotIV, rGADEM, affyILM, frma, frmaTools, BeadDataPackR, MassArray, charm, genoCN, iChip, methVisual, ConsensusClusterPlus, ExpressionView, eisa, GSRI, PROMISE, tigre, SamSPECTRAL, flowMeans, flowTrans, iFlow, GEOsubmission, SRAdb, genomes, pint, xmapcore\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2010-1-book-review/",
    "title": "A Beginner's Guide to R",
    "description": "Book info :  Alain F. , Elena N. , and Erik H.W.G. . New York, NY: Springer, 2009. ISBN 978-0-387-93836-3. xv + 218 pp. \\$59.95 (P).",
    "author": [
      {
        "name": "Laura M. Schultz",
        "url": {}
      }
    ],
    "date": "2010-06-01",
    "categories": [],
    "contents": "\n\nA Beginner’s Guide to R is just what it’s title implies, a quick-start\nguide for the newest R users. A unique feature of this welcome addition\nto Springer’s Use R! series is that it is devoted solely to getting\nthe user up and running on R. Unlike other texts geared towards R\nbeginners, such as Verzani (2005), this text does not make the mistake\nof trying to simultaneously teach statistics. The experienced R user\nwill not have much use for this book, except perhaps for adoption as a\ntextbook. To this end, there are straightforward homework exercises\nprovided throughout (no answers, though), and the data sets can be\ndownloaded from the authors’ website http://www.highstat.com. It\nshould be noted, however, that the examples and exercises are limited to\nthe authors’ area of expertise – ecology.\nThe book starts at the very beginning by instructing the user how to\ninstall R and load packages from CRAN. One small weakness is that the\nbook is directed almost exclusively toward PC users. In particular, I\nwas disappointed by the paucity of information concerning R text editors\nthat are compatible with the Mac. (After a fair amount of trial and\nerror, I finally determined that gedit would do the job for me.) A\nnice feature of Chapter 1 is an annotated bibliography of \"must-have\"\nR books. Early on, the authors sagely direct the reader toward the\nuniverse of R assistance available online (and console the panicked\nreader that even experienced R users can be intimidated by the sheer\namount of information contained in R help files).\nThe remainder of the book is devoted to demonstrating how to do the most\nbasic tasks with R. Chapter 2 describes several methods for getting data\ninto R (useful information for anybody facing the daunting prospect of\nimporting a large data set into R for the first time). To appease the\nnovice hungering for some \"fancy\" R output, the authors provide\neasy-to-follow instructions for constructing both simple (Chapters 5 and\n7) and not-so-simple (Chapter 8) graphical displays. Standard plots from\nthe introductory statistics curriculum are included (e.g., the\nhistogram, boxplot, scatterplot, and dotplot), and the lattice package\nis introduced for the benefit of readers with more advanced graphical\nneeds. Other topics include data management (Chapter 3) and simple\nfunctions and loops (Chapters 4 and 6). Chapter 9 concludes the book by\nsuggesting solutions to some problems commonly encountered by R users,\nbeginners and old pros alike.\nIn sum, A Beginner’s Guide to R is an essential resource for the R\nnovice, whether an undergraduate learning statistics for the first time\nor a seasoned statistician biting the bullet and making the switch to R.\nTo get the most bang for the buck (the cost is a bit steep for such a\nshort paperback), I advise the user to set aside a weekend (or a week)\nto launch R and work through the book from start to finish. It will be\ntime well spent — just keep in mind that this book is all about\nlearning to play a scale; you’ll be disappointed if you expect to emerge\nwith all the skills required to perform a concerto.\n\n\n\n\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\nJ. Verzani. em Using R for Introductory Statistics. Boca Raton FL: Chapman & Hall, 2005.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2010-1-chinese-r-conf/",
    "title": "Conference Review: The 2nd Chinese R Conference",
    "description": "The 'Conference Review: The 2nd Chinese R Conference' article from the 2010-1 issue.",
    "author": [
      {
        "name": "Jing Jiao",
        "url": {}
      },
      {
        "name": "Jingjing Guan",
        "url": {}
      },
      {
        "name": "Yihui Xie",
        "url": {}
      }
    ],
    "date": "2010-06-01",
    "categories": [],
    "contents": "\n\nThe 2nd Chinese R Conference was successfully held in December 2009 in\nBeijing and Shanghai. This conference was organized in two cities so\nthat more people would be able to enjoy similar talks without additional\ntraveling cost. The Beijing session, held in the Renmin University of\nChina (RUC) on December 5–6, 2009, was sponsored and organized by the\nCenter for Applied Statistics and the School of Statistics, RUC. Yanping\nChen served as the chair of the conference while Janning Fan was the\nsecretary. Yixuan Qiu and Jingjing Guan were in charge of local\narrangements. The Shanghai session took place in the East China Normal\nUniversity (ECNU) on December 12–13, 2009; it was organized by the\nSchool of Resources and Environment Science (SRES) and the School of\nFinance and Statistics, ECNU, and sponsored by Mango Solutions. Jing\nJiao and Xiang Zhang served as the chairs of the conference; the\nMolecular Ecology Group in SRES was in charge of local arrangements.\nBoth sessions were co-organized by the web community “Capital of\nStatistics” (http://cos.name).\nBeside promoting the communication among Chinese R users as the 1st\nChinese R Conference did, the 2nd Chinese R Conference concentrated on\nthe applications of R in statistical computing and graphics in various\ndisciplines. The slogan of this conference was “useR eveRywheRe”,\nindicating R is wide-spread in a variety of fields as well as there are\na large amount of useRs in China now.\nIn total, more than 300 participants from over 90 institutions took part\nin this conference. There were 19 talks in the Beijing session:\nOpening\n\nA review on the history of the Chinese R Conference and a brief\nintroduction to R by Yanping Chen;\n\nStatistical Graphics\n\nIntroduction to R base graphics by Tao Gao and Cheng Li; Matrix\nvisualization using the package corrplot by Taiyun Wei;\n\nStatistical Models\n\nNonparametric methods and robust estimation of quantile regression\nby Chen Zuo; R and WinBUGS by Peng Ding; Grey System Theory in R by\nTan Xi;\n\nSoftware Development\n\nIntegrating R into C/C++ applications using Visual C++ by Yu Gong;\nUsing R in online data analysis by Zhiyi Huang;\n\nIndustrial Applications\n\nR in establishing standards for the food industry by Qiding Zhong;\nInvestigation and monitoring on geological environment with R by\nYongsheng Liu; R in marketing research by Yingchun Zhu; Zhiyi Huang\nalso gave an example on handling atmosphere data with R; R in\nnear-infrared spectrum analysis by Die Sun;\n\nData Mining\n\nJingjing Guan introduced RExcel with applications in data mining\nand the trend of data mining focused on ensemble learning; Dealing\nwith large data and reporting automation by Sizhe Liu;\n\nKaleidoscope\n\nDiscussing security issues of R by Nan Xiao; Using R in economics\nand econometrics by Liyun Chen; R in psychology by Xiaoyan Sun and\nTing Wang; R in spatial analysis by Huaru Wang; Optimization of\nmolecular structure parameter matrix in QSAR with the package omd\nby Bin Ma;\n\nMore than 150 people from nearly 75 institutions all over China\nparticipated in the Shanghai session. Among these participants, we were\nhonored to meet some pioneer Chinese useRs such as Prof Yincai Tang, the\nfirst teacher introducing R in the School of Finance and Statistics of\nECNU. There were 13 talks given in the Shanghai session which partially\noverlapped with the Beijing session:\nOpening\n\nIntroduction of the 2nd Chinese R conference (Shanghai session) by\nJing Jiao, and opening address by Prof Yincai Tang and Prof Xiaoyong\nChen (Vice President of SRES);\n\nTheories\n\nBayesian Statistics with R and WinBUGS by Prof Yincai Tang; Grey\nSystem Theory in R by Tan Xi;\n\nGraphics\n\nIntroduction to R base graphics by Tao Gao and Cheng Li; Matrix\nvisualization using the package corrplot by Taiyun Wei;\n\nApplications\n\nUsing R in economics and econometrics by Liyun Chen; Marketing\nanalytical framework by Zhenshun Lin; Decision tree with the rpart\npackage by Weijie Wang; Optimization of molecular structure\nparameter matrix in QSAR with the package omd by Bin Ma; Survival\nanalysis in R by Yi Yu; The application of R and statistics in the\nsemiconductor industry by Guangqi Lin;\n\nSoftware Development\n\nDealing with large data and reporting automation by Sizhe Liu; JAVA\ndevelopment and optimization in R by Jian Li; Discussing security\nissues of R by Nan Xiao;\n\nOn the second day there was a training session for R basics (Learning R\nin 153 minutes by Sizhe Liu) and extensions (Writing R packages by Sizhe\nLiu and Yihui Xie; Extending R by Jian Li); a discussion session was\narranged after the training. The conference was closed with a speech by\nXiang Zhang.\nOverall, participants were very interested in the topics contributed on\nthe conference and the discussion session has reflected there was the\nstrong need of learning and using R in China. After this conference, we\nhave also decided to make future efforts on:\nIncreasing the number of sessions of this conference to meet the\ndemand of useRs in other areas;\nPromoting the communication between statistics and other disciplines\nvia using R;\nInteracting with different industries through successful\napplications of R;\nAll slides are available online at\nhttp://cos.name/2009/12/2nd-chinese-r-conference-summary/. We thank\nProf Xizhi Wu for his consistent encouragement on this conference, and\nwe are especially grateful to Prof Yanyun Zhao, Dean of the School of\nStatistics of RUC, for his great support on the Beijing session. We look\nforward to the next R conference in China and warmly welcome more people\nto attend it. The main session is tentatively arranged in the Summer of\n2010. Inquiries and suggestions can be sent to or\nhttp://cos.name/ChinaR/ChinaR-2010.\n\n\n\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2010-1-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2010-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2010-06-01",
    "categories": [],
    "contents": "\n\n1 New CRAN task views\nPhylogenetics\n\nPhylogenetics, especially comparative methods.\nPackages: MCMCglmm, PHYLOGR, PhySim, TreeSim, ade4,\nadephylo, apTreeshape, ape\\(^*\\), geiger, laser, maticce,\nouch, paleoTS, phangorn, phybase, phyclust, phylobase,\nphyloclim, picante, scaleboot, vegan.\nMaintainer: Brian O’Meara.\n\n(* = core package)\n2 New packages in CRAN task views\nBayesian\n\nGLMMarp, zic.\n\nCluster\n\napcluster.\n\nEconometrics\n\nBayesPanel, VGAM, effects, fxregime, gam, gamlss,\nmgcv, micEconCES, micEconSNQP, truncreg.\n\nEnvironmetrics\n\nFD.\n\nExperimentalDesign\n\nDiceDesign, DiceKriging, FrF2.catlg128, dae.\n\nFinance\n\nSV.\n\nHighPerformanceComputing\n\nRdsm, batch, biglars, doMPI, doRedis.\n\nMedicalImaging\n\nPTAk, cudaBayesreg, dcemriS4\\(^*\\), oro.dicom\\(^*\\),\noro.nifti\\(^*\\).\n\nPsychometrics\n\nBradleyTerry2, CMC, caGUI, lavaan\\(^*\\), lordif, pscl.\n\nSpatial\n\nGuerry, cshapes, rworldmap.\n\nSurvival\n\nAIM, Cprob, DTDA, TraMineR, flexCrossHaz, ipw, mspath.\n\nTimeSeries\n\nrtv.\n\ngR\n\nparcor.\n\n(* = core package)\n3 New contributed packages\nAIM\n\nAIM: adaptive index model. Authors: L. Tian and R. Tibshirani. In\nview: Survival.\n\nB2Z\n\nBayesian Two-Zone Model. Authors: João Vitor Dias Monteiro, Sudipto\nBarnejee and Gurumurthy Ramachandran.\n\nBBMM\n\nThis package fits a Brownian bridge movement model to observed\nlocations in space and time. Authors: Ryan Nielson, Hall Sawyer and\nTrent McDonald.\n\nBLR\n\nBayesian Linear Regression. Authors: Gustavo de los Campos and\nPaulino Pérez Rodríguez.\n\nBTSPAS\n\nBayesian Time-Stratified Population Analysis. Authors: Carl J\nSchwarz and Simon J Bonner.\n\nBayesPanel\n\nBayesian methods for panel data modeling and inference. Authors:\nChunhua Wu and Siddhartha Chib. In view:\nEconometrics.\n\nBayesQTLBIC\n\nBayesian multi-locus QTL analysis based on the BIC criterion.\nAuthor: Rod Ball.\n\nBergm\n\nBayesian inference for exponential random graph models. Authors:\nAlberto Caimo and Nial Friel.\n\nBioPhysConnectoR\n\nConnecting sequence information and biophysical models Authors:\nFranziska Hoffgaard, with contributions from Philipp Weil and Kay\nHamacher.\n\nBioStatR\n\nCompanion to the book “Exercices et problèmes de statistique avec le\nlogiciel R”. Authors: Frederic Bertrand and Myriam Maumy-Bertrand.\n\nBmix\n\nBayesian sampling for stick-breaking mixtures. Author: Matt Taddy.\nIn view: Cluster.\n\nBoSSA\n\nA bunch of structure and sequence analysis. Author: Pierre Lefeuvre.\n\nBolstad2\n\nBolstad functions. Author: James Curran.\n\nBoolNet\n\nGeneration, reconstruction, simulation and analysis of synchronous,\nasynchronous, and probabilistic Boolean networks. Authors: Christoph\nMüssel, Martin Hopfensitz, Dao Zhou and Hans Kestler.\n\nBoruta\n\nA tool for finding significant attributes in information systems.\nAuthors: Algorithm by Witold R. Rudnicki, R implementation by\nMiron B. Kursa.\n\nBradleyTerry2\n\nBradley-Terry models. Authors: Heather Turner and David Firth. In\nview:\nPsychometrics.\n\nCAVIAR\n\nCambial Activity and wood formation data processing, VIsualisation\nand Analysis using R. Author: Cyrille Rathgeber.\n\nCCMtools\n\nClustering through “Correlation Clustering Model” (CCM) and cluster\nanalysis tools. Author: Mathieu Vrac.\n\nCCP\n\nSignificance tests for Canonical Correlation Analysis (CCA). Author:\nUwe Menzel.\n\nCMC\n\nCronbach-Mesbah Curve. Authors: Michela Cameletti and Valeria\nCaviezel. In view:\nPsychometrics.\n\nCOMPoissonReg\n\nConway-Maxwell Poisson (COM-Poisson) Regression. Author: Kimberly\nSellers.\n\nCausalGAM\n\nEstimation of causal effects with Generalized Additive Models.\nAuthors: Adam Glynn and Kevin Quinn.\n\nCoCoCg\n\nGraphical modelling by CG regressions. Author: Jens Henrik Badsberg.\n\nCoCoGraph\n\nInteractive and dynamic graphs for the CoCo objects. Author: Jens\nHenrik Badsberg.\n\nCollocInfer\n\nCollocation inference for dynamic systems. Authors: Giles Hooker,\nLuo Xiao and James Ramsay.\n\nCorrBin\n\nNonparametrics with clustered binary data. Author: Aniko Szabo.\n\nCprob\n\nConditional probability function of a competing event. Author:\nArthur Allignol. In view:\nSurvival.\n\nDAMisc\n\nDave Armstrong’s miscellaneous functions. Author: Dave Armstrong.\n\nDEMEtics\n\nCalculation of Gst and D values characterizing the genetic\ndifferentiation between populations. Authors: Alexander Jueterbock,\nPhilipp Kraemer, Gabriele Gerlach and Jana Deppermann.\n\nDOSim\n\nComputation of functional similarities between DO terms and gene\nproducts; DO enrichment analysis; Disease Ontology annotation.\nAuthor: Jiang Li.\n\nDatABEL\n\nFile-based access to large matrices stored on HDD in binary format.\nAuthors: Yurii Aulchenko and Stepan Yakovenko.\n\nDeducerPlugInExample\n\nDeducer plug-in example. Author: Ian Fellows.\n\nDesignPatterns\n\nDesign patterns in R to build reusable object-oriented software.\nAuthors: Jitao David Zhang, supported by Stefan Wiemann and Wolfgang\nHuber.\n\nDiceDesign\n\nDesigns of computer experiments. Authors: Jessica Franco, Delphine\nDupuy and Olivier Roustant. In view:\nExperimentalDesign.\n\nDiceEval\n\nConstruction and evaluation of metamodels. Authors: D. Dupuy and C.\nHelbert.\n\nDiceKriging\n\nKriging methods for computer experiments. Authors: O. Roustant, D.\nGinsbourger and Y. Deville. In view:\nExperimentalDesign.\n\nDiceOptim\n\nKriging-based optimization for computer experiments. Authors: D.\nGinsbourger and O. Roustant.\n\nDistributionUtils\n\nDistribution utilities. Author: David Scott.\n\nDoseFinding\n\nPlanning and analyzing dose finding experiments. Authors: Bornkamp,\nJosé Pinheiro and Frank Bretz.\n\nEMT\n\nExact Multinomial Test: Goodness-of-fit test for discrete\nmultivariate data. Author: Uwe Menzel.\n\nFAMT\n\nFactor Analysis for Multiple Testing (FAMT): Simultaneous tests\nunder dependence in high-dimensional data. Authors: David Causeur,\nChloé Friguet, Magalie Houée-Bigot and Maela Kloareg.\n\nFNN\n\nFast Nearest Neighbor search algorithms and applications. Author:\nShengqiao Li.\n\nFrF2.catlg128\n\nComplete catalogues of resolution IV 128 run 2-level fractional\nfactorials up to 24 factors. Author: Ulrike In view:\nExperimentalDesign.\n\nFunctSNP\n\nSNP annotation data methods and species specific database builder.\nAuthors: S. J. Goodswen with contributions from N. S.\nWatson-Haigh, H. N. Kadarmideen and C. Gondro.\n\nGAMens\n\nApplies GAMbag, GAMrsm and GAMens ensemble classifiers for binary\nclassification. Authors: Koen W. De Bock, Kristof Coussement and\nDirk Van den Poel.\n\nGEVcdn\n\nGEV conditonal density estimation network. Author: Alex J. Cannon.\n\nGGally\n\nExtension to ggplot2. Authors: Barret Schloerke, Di Cook, Heike\nHofmann and Hadley Wickham.\n\nGWRM\n\nA package for fitting Generalized Waring Regression Models. Authors:\nA.J. Saez-Castillo, J. Rodríguez-Avi, A. Conde-Sánchez, M.J.\nOlmo-Jiménez and A.M. Martinez-Rodriguez.\n\nGeneralizedHyperbolic\n\nThe generalized hyperbolic distribution. Author: David Scott.\n\nGrassmannOptim\n\nGrassmann Manifold Optimization. Authors: Kofi Placid Adragni and\nSeongho Wu.\n\nGuerry\n\nGuerry: maps, data and methods related to Guerry (1833) “Moral\nStatistics of France”. Authors: Michael Friendly and Stephane Dray.\nIn view: Spatial.\n\nHDMD\n\nStatistical analysis tools for High Dimension Molecular Data (HDMD).\nAuthor: Lisa McFerrin.\n\nHGLMMM\n\nHierarchical Generalized Linear Models. Author: Marek Molas.\n\nHMM\n\nHidden Markov Models. Authors: Scientific Software Development —\nDr. Lin Himmelmann.\n\nHistData\n\nData sets from the history of statistics and data visualization.\nAuthors: Michael Friendly, with contributions by Stephane Dray and\nHadley Wickham.\n\nIFP\n\nIdentifying functional polymorphisms in genetic association studies.\nAuthor: Leeyoung Park.\n\nImap\n\nInteractive Mapping. Author: John R. Wallace.\n\nJJcorr\n\nCalculates polychorical correlations for several copula families.\nAuthors: Jeroen Ooms and Joakim\n\nJOP\n\nJoint Optimization Plot. Authors: Sonja Kuhnt and Nikolaus Rudak.\n\nLDdiag\n\nLink function and distribution diagnostic test for social science\nresearchers. Author: Yongmei Ni.\n\nLS2W\n\nLocally stationary two-dimensional wavelet process estimation\nscheme. Authors: Idris Eckley and Guy Nason.\n\nLiblineaR\n\nLinear predictive models based on the Liblinear C/C++ Library.\nAuthor: Thibault Helleputte.\n\nLogitNet\n\nInfer network based on binary arrays using regularized logistic\nregression. Authors: Pei Wang, Dennis Chao and Li Hsu.\n\nMADAM\n\nThis package provides some basic methods for meta-analysis. Author:\nKarl Kugler.\n\nMAMA\n\nMeta-Analysis of MicroArray. Author: Ivana Ihnatova.\n\nMAc\n\nMeta-analysis with correlations. Author: AC Del Re and William T.\nHoyt.\n\nMAd\n\nMeta-analysis with mean differences. Author: AC Del Re and\nWilliam T. Hoyt.\n\nMFDF\n\nModeling Functional Data in Finance. Author: Wei Dou.\n\nMImix\n\nMixture summary method for multiple imputation. Authors: Russell\nSteele, Naisyin Wang and Adrian Raftery.\n\nMNM\n\nMultivariate Nonparametric Methods. An approach based on spatial\nsigns and ranks. Authors: Klaus Nordhausen, Jyrki Mottonen and Hannu\nOja.\n\nMTSKNN\n\nMultivariate two-sample tests based on K-Nearest-Neighbors. Authors:\nLisha Chen, Peng Dai and Wei Dou.\n\nMVpower\n\nGive power for a given effect size using multivariate classification\nmethods. Authors: Raji Balasubramanian and Yu Guo.\n\nMaXact\n\nExact max-type Cochran-Armitage trend test (CATT). Authors: Jianan\nTian and Chenliang Xu.\n\nModelGood\n\nValidation of prediction models. Author: Thomas A. Gerds.\n\nMortalitySmooth\n\nSmoothing Poisson counts with P-splines. Author: Carlo G. Camarda.\n\nMplusAutomation\n\nAutomating Mplus model estimation and interpretation. Author:\nMichael Hallquist.\n\nMuMIn\n\nMulti-model inference. Author: Kamil Bartoń.\n\nNMF\n\nAlgorithms and framework for Nonnegative Matrix Factorization (NMF).\nAuthor: Renaud Gaujoux.\n\nNMFN\n\nNon-Negative Matrix Factorization. Authors: Suhai (Timothy) Liu\nbased on multiplicative updates (Lee and Sung 2001) and alternating\nleast squares algorithm; Lars Kai Hansen’s nnmf_als Matlab\nimplementation; Torsten Hothorn’s Moore-Penrose inverse function.\n\nOligoSpecificitySystem\n\nOligo Specificity System. Authors: Rory Michelland and Laurent\nCauquil.\n\nPBSadmb\n\nPBS ADMB. Authors: Jon T. Schnute and Rowan Haigh.\n\nPKgraph\n\nModel diagnostics for pharmacokinetic models. Author: Xiaoyong Sun.\n\nPKmodelFinder\n\nSoftware for Pharmacokinetic model. Authors: Eun-Kyung Lee, Gyujeong\nNoh and Hyeong-Seok Lim.\n\nPermuteNGS\n\nSignificance testing of transcriptome profiling for RNA-sequencing\ndata. Authors: Taeheon Lee, Bo-Young Lee, Hee-Seok Oh, Heebal Kim.\n\nPowerTOST\n\nPower and sample size based on two-one-sided-t-tests (TOST) for BE\nstudies. Author: Detlew Labes.\n\nProDenICA\n\nProduct Density Estimation for ICA using tilted Gaussian density\nestimates. Authors: Trevor Hastie and Rob Tibshirani.\n\nPropCIs\n\nComputes confidence intervals for proportions, differences in\nproportions, an odds-ratio and the relative risk in a \\(2 \\times 2\\)\ntable. Author: Ralph Scherer.\n\nQT\n\nQT Knowledge Management System. Author: Christoffer W. Tornoe.\n\nQTLNetworkR\n\nInteractive software package for QTL visualization. Author: Zheng\nWenjun.\n\nR2Cuba\n\nMultidimensional numerical integration. Authors: The Cuba library\nhas been written by Thomas Hahn; Interface to R was written by Annie\nBouvier and Kiên Kiêu.\n\nR2PPT\n\nSimple R Interface to Microsoft PowerPoint using rcom. Author:\nWayne Jones.\n\nRANN\n\nFast Nearest Neighbour Search. Authors: Samuel E. Kemp and Gregory\nJefferis.\n\nRFLPtools\n\nTools to analyse RFLP data. Authors: Fabienne Flessa, Alexandra\nKehl, Matthias Kohl.\n\nRFinanceYJ\n\nJapanese stock market from Yahoo!-finance-Japan Authors: Yohei Sato\nand Nobuaki Oshiro.\n\nRGtk2DfEdit\n\nImproved data frame editor for RGtk2. Authors: Tom Taverner, with\ncontributions from John Verzani.\n\nRH2\n\nDBI/RJDBC interface to H2 Database. Author: G. Grothendieck. Author\nof H2 is Thomas Mueller.\n\nRODM\n\nR interface to Oracle Data Mining. Authors: Pablo Tamayo and Ari\nMozes.\n\nROracleUI\n\nConvenient Tools for Working with Oracle Databases. Author: Arni\nMagnusson.\n\nRPPanalyzer\n\nReads, annotates, and normalizes reverse phase protein array data.\nAuthor: Heiko Mannsperger with contributions from Stephan Gade.\n\nRProtoBuf\n\nR interface to the Protocol Buffers API. Authors:\nRomain François and Dirk Eddelbuettel.\n\nRSQLite.extfuns\n\nMath and String Extension Functions for RSQLite. Author: Seth\nFalcon.\n\nRcgmin\n\nConjugate gradient minimization of nonlinear functions with box\nconstraints. Author: John C. Nash.\n\nRcmdrPlugin.MAc\n\nMeta-analysis with correlations (MAc) Rcmdr Plug-in. Author: AC\nDel Re.\n\nRcmdrPlugin.MAd\n\nMeta-analysis with mean differences (MAd) Rcmdr Plug-in. Author:\nAC Del Re.\n\nRcmdrPlugin.PT\n\nSome discrete exponential dispersion models: Poisson-Tweedie.\nAuthors: David Pechel Cactcha, Laure Pauline Fotso and Célestin C\nKokonendji.\n\nRcmdrPlugin.SLC\n\nSLC Rcmdr plug-in. Authors: Antonio Solanas and Rumen Manolov.\n\nRcmdrPlugin.doex\n\nRcmdr plugin for Stat 4309 course. Author: Erin Hodgess.\n\nRcmdrPlugin.sos\n\nEfficiently search R Help pages. Author: Liviu Andronic.\n\nRcmdrPlugin.steepness\n\nSteepness Rcmdr plug-in. Author: David Leiva and Han de Vries.\n\nRcppArmadillo\n\nRcpp/Armadillo bridge. Authors: Romain François, Dirk Eddelbuettel\nand Doug Bates.\n\nRcppExamples\n\nExamples using Rcpp to interface R and C++. Authors: Dirk\nEddelbuettel and Romain François, based on code written during 2005\nand 2006 by Dominick Samperi.\n\nRdsm\n\nThreads-Like Environment for R. Author: Norm Matloff. In view:\nHighPerformanceComputing.\n\nRecordLinkage\n\nRecord linkage in R. Authors: Andreas Borg and Murat Sariyar.\n\nRhh\n\nCalculating multilocus heterozygosity and\nheterozygosity-heterozygosity correlation. Authors: Jussi Alho and\nKaisa Välimäki.\n\nRobLoxBioC\n\nInfinitesimally robust estimators for preprocessing omics data.\nAuthor: Matthias Kohl.\n\nRpgSQL\n\nDBI/RJDBC interface to PostgreSQL database. Author: G. Grothendieck.\n\nRsolnp\n\nGeneral non-linear optimization. Authors: Alexios Ghalanos and\nStefan Theussl.\n\nRvmmin\n\nVariable metric nonlinear function minimization with bounds\nconstraints. Author: John C. Nash.\n\nSDMTools\n\nSpecies Distribution Modelling Tools: Tools for processing data\nassociated with species distribution modelling exercises. Authors:\nJeremy VanDerWal, Luke Shoo and Stephanie Januchowski. This package\nwas made possible in part by support from Lorena Falconi and Collin\nStorlie, and financial support from the Australian Research Council\n& ARC Research Network for Earth System Science.\n\nSDisc\n\nIntegrated methodology for the identification of homogeneous\nprofiles in data distribution. Author: Fabrice Colas.\n\nSHIP\n\nSHrinkage covariance Incorporating Prior knowledge. Authors: Monika\nJelizarow and Vincent Guillemot.\n\nSLC\n\nSlope and level change. Authors: Antonio Solanas, Rumen Manolov and\nPatrick Onghena.\n\nSOAR\n\nMemory management in R by delayed assignments. Authors: Bill\nVenables, based on original code by David Brahm.\n\nSPACECAP\n\nA program to estimate animal aabundance and density using\nSpatially-Explicit Capture-Recapture. Authors: Pallavi Singh,\nArjun M. Gopalaswamy, Andrew J. Royle, N. Samba Kumar and K. Ullas\nKaranth with contributions from Sumanta Mukherjee, Vatsaraj and\nDipti Bharadwaj.\n\nSQN\n\nSubset quantile normalization. Author: Zhijin(Jean) Wu.\n\nSV\n\nIndirect inference in non-Gaussian stochastic volatility models.\nAuthor: Øivind Skare. In view:\nFinance.\n\nSampleSizeMeans\n\nSample size calculations for normal means. Authors: Lawrence Joseph\nand Patrick Belisle.\n\nSampleSizeProportions\n\nCalculating sample size requirements when estimating the difference\nbetween two binomial proportions. Authors: Lawrence Joseph, Roxane\ndu Berger and Patrick Belisle.\n\nSkewHyperbolic\n\nThe Skew Hyperbolic Student t-distribution. Authors: David Scott and\nFiona Grimson.\n\nSleuth2\n\nData sets from Ramsey and Schafer’s “Statistical Sleuth (2nd ed)”.\nAuthors: Original by F.L. Ramsey and D.W. Schafer, modifications by\nDaniel W Schafer, Jeannie Sifneos and Berwin A Turlach.\n\nSpatialEpi\n\nPerforms various spatial epidemiological analyses. Author: Albert Y.\nKim.\n\nStMoSim\n\nSimulate QQ-Norm and TA-Plot. Author: Matthias Salvisberg.\n\nTANOVA\n\nTime Course Analysis of Variance for Microarray. Authors: Baiyu Zhou\nand Weihong Xu.\n\nTGUICore\n\nTeaching GUI — Core functionality. Authors: Matthias Templ,\nGerlinde Dinges, Alexander Kowarik and Bernhard Meindl.\n\nTGUITeaching\n\nTeaching GUI — prototype. Authors: Matthias Templ, Gerlinde\nDinges, Alexander Kowarik and Bernhard Meindl.\n\nToxLim\n\nIncorporating ecological data and associated uncertainty in\nbioaccumulation modeling. Authors: Frederik De Laender and Karline\nSoetaert.\n\nTreeRank\n\nImplementation of the TreeRank methodology for building tree-based\nranking rules for bipartite ranking through ROC curve optimization.\nAuthor: Nicolas Baskiotis.\n\nTreeSim\n\nSimulating trees under the birth-death model. Author: Tanja Stadler.\nIn view:\nPhylogenetics.\n\nUScensus2000\n\nUS Census 2000 suite of R Packages. Author: Zack W. Almquist. In\nview: Spatial.\n\nUScensus2000add\n\nUS Census 2000 suite of R Packages: Demographic add. Author: Zack W.\nAlmquist.\n\nUScensus2000blkgrp\n\nUS Census 2000 block group shapefiles and additional Demographic\nData. Author: Zack W. Almquist.\n\nUScensus2000cdp\n\nUS Census 2000 designated places shapefiles and additional\ndemographic data. Author: Zack W. Almquist.\n\nUScensus2000tract\n\nUS Census 2000 tract level shapefiles and additional demographic\nData. Author: Zack W. Almquist.\n\nUnicode\n\nUnicode data and utilities. Author: Kurt Hornik.\n\nVHDClassification\n\nDiscrimination/Classification in very high dimension with linear and\nquadratic rules. Author: Robin Girard.\n\nVPdtw\n\nVariable Penalty Dynamic Time Warping. Authors: David Clifford and\nGlenn Stone.\n\nVhayuR\n\nVhayu R interface. Author: The Brookhaven Group. In view:\nTimeSeries.\n\nVizCompX\n\nVisualisation of Computer Models. Author: Neil Diamond.\n\nWMBrukerParser\n\nWilliam and Mary Parser for Bruker-Ultraflex mass spectrometry data.\nAuthors: William Cooke, Maureen Tracy and Dariya Malyarenko.\n\nWaveCD\n\nWavelet change point detection for array CGH data. Author: M.\nShahidul Islam.\n\nadephylo\n\nExploratory analyses for the phylogenetic comparative method.\nAuthors: Thibaut Jombart and Stephane Dray. In view:\nPhylogenetics.\n\nagilp\n\nExtracting and preprocessing Agilent express arrays. Author: Benny\nChain.\n\namba\n\nAdditive Models for Business Applications. Author: Charlotte Maia.\n\nanesrake\n\nANES Raking Implementation. Author: Josh Pasek.\n\napcluster\n\nAffinity Propagation Clustering. Authors: Ulrich Bodenhofer and\nAndreas Kothmeier. In view:\nCluster.\n\naqp\n\nAlgorithms for Quantitative Pedology. Author: Dylan Beaudette.\n\naroma.cn\n\nCopy-number analysis of large microarray data sets. Authors: Henrik\nBengtsson and Pierre Neuvial.\n\naroma.light\n\nLight-weight methods for normalization and visualization of\nmicroarray data using only basic R data types. Author: Henrik\nBengtsson.\n\nasbio\n\nA collection of statistical tools for biologists. Authors: Ken Aho;\nmany thanks to V. Winston and D. Roberts.\n\nasd\n\nSimulations for adaptive seamless designs. Author: Nick parsons.\n\nbase64\n\nBase 64 encoder/decoder. Authors: Romain François, based on code by\nBob Trower available at http://base64.sourceforge.net/.\n\nbatch\n\nBatching routines in parallel and passing command-line arguments\nto R. Author: Thomas Hoffmann. In view:\nHighPerformanceComputing.\n\nbfast\n\nBFAST: Breaks For Additive Seasonal and Trend. Authors: Jan\nVerbesselt, with contributions from Rob Hyndman.\n\nbibtex\n\nBibTeX parser. Author: Romain François.\n\nbiganalytics\n\nA library of utilities for \"big.matrix\" objects of package\nbigmemory. Authors: John W. Emerson and Michael J. Kane.\n\nbiglars\n\nScalable Least-Angle Regression and Lasso. Authors: Mark Seligman,\nChris Fraley and Tim Hesterberg. In view:\nHighPerformanceComputing.\n\nbigtabulate\n\ntable-, tapply-, and split-like functionality for \"matrix\"\nand \"big.matrix\" objects. Authors: Michael J. Kane and John W.\nEmerson.\n\nbinhf\n\nHaar-Fisz functions for binomial data. Author: Matt Nunes.\n\nboolfun\n\nCryptographic Boolean functions. Author: F. Lafitte.\n\nbootruin\n\nA bootstrap test for the probability of ruin in the classical risk\nprocess. Authors: Benjamin Baumgartner, Riccardo Gatto.\n\ncatnet\n\nCategorical Bayesian network inference. Authors: Nikolay Balov and\nPeter Salzman.\n\nclusterCons\n\nCalculate the consensus clustering result from re-sampled clustering\nexperiments with the option of using multiple algorithms and\nparameter. Authors: Dr. T. Ian Simpson.\n\ncmaes\n\nCovariance Matrix Adapting Evolutionary Strategy. Authors: Heike\nTrautmann, Olaf Mersmann and David Arnu.\n\ncoarseDataTools\n\nA collection of functions to help with analysis of coarse infectious\ndisease data. Author: Nicholas G. Reich.\n\ncodep\n\nMultiscale codependence analysis. Authors: Guillaume Guenard, with\ncontributions from Bertrand Pages.\n\ncoenoflex\n\nGradient-Based Coenospace Vegetation Simulator. Author: David W.\nRoberts.\n\ncompute.es\n\nCompute Effect Sizes. Author: AC Del Re.\n\ncorrplot\n\nVisualization of a correlation matrix. Author: Taiyun Wei.\n\ncrmn\n\nCCMN and other noRMalizatioN methods for metabolomics data. Author:\nHenning Redestig.\n\ncthresh\n\nComplex wavelet denoising software. Author: Stuart Barber.\n\ncubature\n\nAdaptive multivariate integration over hypercubes. Authors: C code\nby Steven G. Johnson, R by Balasubramanian Narasimhan.\n\ncusp\n\nCusp Catastrophe Model Fitting Using Maximum Likelihood. Author:\nRaoul P. P. P. Grasman.\n\ndae\n\nFunctions useful in the design and ANOVA of experiments. Author:\nChris Brien. In view:\nExperimentalDesign.\n\ndagR\n\nR functions for directed acyclic graphs. Author: Lutz P Breitling.\n\ndatamap\n\nA system for mapping foreign objects to R variables and\nenvironments. Author: Jeffrey Horner.\n\ndcemriS4\n\nA Package for Medical Image Analysis (S4 implementation). Authors:\nBrandon Whitcher and Volker Schmid, with contributions from Andrew\nThornton. In view:\nMedicalImaging.\n\ndclone\n\nData Cloning and MCMC Tools for Maximum Likelihood Methods. Author:\nPeter Solymos.\n\ndecon\n\nDeconvolution Estimation in Measurement Error Models. Authors:\nXiao-Feng Wang and Bin Wang.\n\ndegenes\n\nDetection of differentially expressed genes. Author: Klaus Jung.\n\ndigitize\n\nA plot digitizer in R. Author: Timothee Poisot.\n\ndistrEllipse\n\nS4 classes for elliptically contoured distributions. Author: Peter\nRuckdeschel.\n\ndoMPI\n\nForeach parallel adaptor for the Rmpi package. Author: Steve\nWeston. In view:\nHighPerformanceComputing.\n\ndoRedis\n\nForeach parallel adapter for the rredis package. Author: B. W.\nLewis. In view:\nHighPerformanceComputing.\n\ndpmixsim\n\nDirichlet Process Mixture model simulation for clustering and image\nsegmentation. Author: Adelino Ferreira da Silva.\n\ndvfBm\n\nDiscrete variations of a fractional Brownian motion. Author:\nJean-Francois Coeurjolly.\n\ndynaTree\n\nDynamic trees for learning and design. Authors: Robert B. Gramacy\nand Matt A. Taddy.\n\nebdbNet\n\nEmpirical Bayes Estimation of Dynamic Bayesian Networks. Author:\nAndrea Rau.\n\nedrGraphicalTools\n\nProvide tools for dimension reduction methods. Authors: Benoit\nLiquet and Jerome Saracco.\n\nedtdbg\n\nIntegrating R’s debug() with Your Text Editor. Author: Norm\nMatloff.\n\negonet\n\nTool for ego-centric measures in Social Network Analysis.\nAuthors: A. Sciandra, F. Gioachin and L. Finos.\n\nemoa\n\nEvolutionary Multiobjective Optimization Algorithms. Author: Olaf\nMersmann.\n\nenvelope\n\nEnvelope normality test. Author: Felipe Acosta.\n\nepinet\n\nA collection of epidemic/network-related tools. Authors: Chris\nGroendyke, David Welch and David R. Hunter.\n\nequate\n\nStatistical methods for test score equating. Author: Anthony Albano.\n\nesd4all\n\nFunctions for post-processing and gridding empirical-statistical\ndownscaled climate scenarios. Author: Rasmus E. Benestad.\n\nexactci\n\nExact p-values and matching confidence intervals for simple discrete\nparametric cases. Author: M. P. Fay.\n\nexpectreg\n\nExpectile regression. Authors: Fabian Sobotka, Thomas Kneib, Sabine\nSchnabel and Paul Eilers.\n\nextracat\n\nGraphic axtensions for categorical data. Author: Alexander\n\nextremevalues\n\nUnivariate outlier detection. Author: Mark van der Loo.\n\nfCertificates\n\nBasics of certificates and structured products valuation. Author:\nStefan Wilhelm.\n\nfavir\n\nFormatted actuarial vignettes in R. Author: Benedict Escoto.\n\nfdth\n\nFrequency Distribution Tables, Histograms and Poligons. Author: Jose\nClaudio Faria and Enio Jelihovschi.\n\nfftw\n\nFast FFT and DCT based on FFTW. Author: Sebastian Krey, Uwe Ligges\nand Olaf Mersmann.\n\nfisheyeR\n\nFisheye and hyperbolic-space-alike interactive visualization tools\nin R. Author: Eduardo San Miguel Martin.\n\nflexCrossHaz\n\nFlexible crossing hazards in the Cox model. Authors: Vito M.R.\nMuggeo and Miriam Tagliavia. In view:\nSurvival.\n\nforensim\n\nStatistical tools for the interpretation of forensic DNA mixtures.\nAuthor: Hinda Haned.\n\nformatR\n\nFormat R code automatically. Author: Yihui Xie.\n\nformula.tools\n\nTools for working with formulas, expressions, calls and other R\nobjects. Author: Christopher Brown.\n\nfptdApprox\n\nApproximation of first-passage-time densities for diffusion\nprocesses. Authors: Patricia Román-Román, Juan J. Serrano-Pérez and\nFrancisco Torres-Ruiz.\n\nfutile.any\n\nFutile library to provide some polymorphism. Author: Brian Lee Yung\nRowe.\n\nfutile.logger\n\nFutile logger subsystem. Author: Brian Lee Yung Rowe.\n\nfutile.matrix\n\nFutile matrix utilities. Author: Brian Lee Yung Rowe.\n\nfutile.options\n\nFutile options management. Author: Brian Lee Yung Rowe.\n\ngamlss.add\n\nGAMLSS additive. Authors: Mikis Stasinopoulos and Bob Rigby.\n\ngamlss.demo\n\nDemos for GAMLSS. Authors: Mikis Stasinopoulos, Bob Rigby, Paul\nEilers and Brian Marx with contributions from Larisa Kosidou.\n\ngamlss.util\n\nGAMLSS utilities. Authors: Mikis Stasinopoulos, Bob Rigby, Paul\nEilers.\n\ngcolor\n\nProvides an inequation algorithm function and a solution to import\nDIMACS files. Authors: Jeffrey L. Duffany, Ph.D. and Euripides\nRivera Negron.\n\ngenefu\n\nRelevant functions for gene expression analysis, especially in\nbreast cancer. Authors: Benjamin Haibe-Kains, Gianluca Bontempi and\nChristos Sotiriou.\n\ngenoPlotR\n\nPlot publication-grade gene and genome maps. Author: Lionel Guy.\n\ngenomatic\n\nManages microsatellite projects. Creates 96-well maps, genotyping\nsubmission forms, rerun management, and import into statistical\nsoftware. Author: Brian J. Knaus.\n\ngeophys\n\nGeophysics, continuum mechanics, Mogi model. Author: Jonathan M.\nLees.\n\ngeosphere\n\nSpherical trigonometry. Authors: Robert J. Hijmans, Ed Williams and\nChris Vennes.\n\ngrofit\n\nThe package was developed to fit many growth curves obtained under\ndifferent conditions. Authors: Matthias Kahm and Maik Kschischo.\n\nhaarfisz\n\nSoftware to perform Haar Fisz transforms. Author: Piotr Fryzlewicz.\n\nhalp\n\nShow certain type of comments from function bodies as “live-help”.\nAuthor: Daniel Haase.\n\nhda\n\nHeteroscedastic Discriminant Analysis. Author: Gero Szepannek.\n\nheavy\n\nEstimation in the linear mixed model using heavy-tailed\ndistributions. Author: Felipe Osorio.\n\nhergm\n\nHierarchical Exponential-family Random Graph Models. Author: Michael\nSchweinberger.\n\nhgam\n\nHigh-dimensional Additive Modelling. Authors: The students of the\n“Advanced R Programming Course” Hannah Frick, Ivan Kondofersky,\nOliver S. Kuehnle, Christian Lindenlaub, Georg Pfundstein, Matthias\nSpeidel, Martin Spindler, Ariane Straub, Florian Wickler and\nKatharina Zink, under the supervision of Manuel Eugster and Torsten\nHothorn.\n\nhglm\n\nHierarchical Generalized Linear Models. Authors: Moudud Alam, Lars\nRonnegard, Xia Shen.\n\nhighlight\n\nSyntax highlighter. Author: Romain François.\n\nhistogram\n\nConstruction of regular and irregular histograms with different\noptions for automatic choice of bins. Authors: Thoralf Mildenberger,\nYves Rozenholc and David Zasada.\n\nhts\n\nHierarchical time series. Authors: Rob J Hyndman, Roman A Ahmed, and\nHan Lin Shang.\n\nhyperSpec\n\nInterface for hyperspectral data sets, i.e., spectra + meta\ninformation (spatial, time, concentration, …). Author: Claudia\nBeleites.\n\niBUGS\n\nAn interface to R2WinBUGS by gWidgets. Author: Yihui Xie.\n\niCluster\n\nIntegrative clustering of multiple genomic data types. Author:\nRonglai Shen.\n\nibr\n\nIterative Bias Reduction. Authors: Pierre-Andre Cornillon, Nicolas\nHengartner and Eric Matzner-Lober.\n\nipw\n\nEstimate inverse probability weights. Author: Willem M. van der Wal.\nIn view: Survival.\n\nisopam\n\nIsopam (hierarchical clustering). Author: Sebastian Schmidtlein.\n\nitertools\n\nIterator tools. Authors: Steve Weston and Hadley Wickham.\n\nkinfit\n\nRoutines for fitting kinetic models to chemical degradation data.\nAuthor: Johannes Ranke.\n\nkml3d\n\nK-means for joint longitudinal data. Author: Christophe Genolini.\n\nlavaan\n\nLatent Variable Analysis. Author: Yves Rosseel. In view:\nPsychometrics.\n\nlcmm\n\nEstimation of latent class mixed models. Authors: Cecile Proust-Lima\nand Benoit Liquet.\n\nleiv\n\nBivariate linear errors-in-variables estimation. Author: David\nLeonard.\n\nlimitplot\n\nJitter/Box Plot with Ordered Points Below the Limit of Detection.\nAuthor: Omar E. Olmedo.\n\nlmPerm\n\nPermutation tests for linear models. Author: Bob Wheeler.\n\nlog10\n\nDecimal log plotting in two and three dimensions. Author: Timothée\nPoisot.\n\nlogging\n\nA tentative logging package. Author: Mario Frasca.\n\nlossDev\n\nRobust loss development using MCMC. Authors: Christopher W. Laws and\nFrank A. Schmid.\n\nlqa\n\nPenalized likelihood inference for GLMs. Author: Jan Ulbricht.\n\nmagnets\n\nSimulate micro-magnets dynamics. Author: Hai Qian.\n\nmbmdr\n\nModel Based Multifactor Dimensionality Reduction. Authors: Victor\nUrrea, Malu Calle, Kristel Van Steen and Nuria Malats.\n\nmclogit\n\nMixed Conditional Logit. Author: Martin Elff.\n\nmecdf\n\nMultivariate ECDF-Based Models. Author: Charlotte Maia. In view:\nDistributions.\n\nmicEconAids\n\nDemand analysis with the Almost Ideal Demand System (AIDS). Author:\nArne Henningsen. In view:\nEconometrics.\n\nmicEconCES\n\nAnalysis with the Constant Elasticity of Scale (CES) function.\nAuthors: Arne Henningsen and Geraldine Henningsen. In view:\nEconometrics.\n\nmicEconSNQP\n\nSymmetric Normalized Quadratic Profit Function. Author: Arne\nHenningsen. In view:\nEconometrics.\n\nmigui\n\nGraphical User Interface of the mi Package. Authors: Daniel Lee\nand Yu-Sung Su.\n\nminiGUI\n\ntktcl quick and simple function GUI. Author: Jorge Luis Ojeda\nCabrera.\n\nminqa\n\nDerivative-free optimization algorithms by quadratic approximation.\nAuthors: Douglas Bates, Katharine M. Mullen, John C. Nash and Ravi\nVaradhan.\n\nmiscTools\n\nMiscellanneous Tools and Utilities. Author: Arne Henningsen.\n\nmissMDA\n\nHandling missing values with/in multivariate data analysis\n(principal component methods). Authors: François Husson and Julie\nJosse.\n\nmixOmics\n\nIntegrate omics data project. Authors: Sébastien Dejean, Ignacio\nGonzález and Kim-Anh Lê Cao.\n\nmkin\n\nRoutines for fitting kinetic models with one or more state variables\nto chemical degradation data. Author: Johannes Ranke.\n\nmlogitBMA\n\nBayesian Model Averaging for multinomial logit models. Authors: Hana\nŠevčíková and Adrian Raftery.\n\nmmap\n\nMap pages of memory. Author: Jeffrey A. Ryan.\n\nmonmlp\n\nMonotone multi-layer perceptron neural network. Author: Alex J.\nCannon.\n\nmrdrc\n\nModel-robust concentration-response analysis. Authors: Christian\nRitz and Mads Jeppe Tarp-Johansen.\n\nmseq\n\nModeling non-uniformity in short-read rates in RNA-Seq data. Author:\nJun Li.\n\nmspath\n\nMulti-state Path-dependent models in discrete time. Authors: Ross\nBoylan and Peter Bacchetti, building on the work of Christopher H.\nJackson. Thorsten Ottosen for the ptr_container library. Gennadiy\nRozental for the Boost Test Library. And the authors of other Boost\nlibraries used by the previous two. In view:\nSurvival.\n\nmtsc\n\nMultivariate timeseries cluster-based models. Author: Charlotte\nMaia.\n\nmugnet\n\nMixture of Gaussian Bayesian network model. Author: Nikolay Balov.\n\nmultisensi\n\nMultivariate Sensitivity Analysis. Authors: Matieyendou Lamboni and\nHervé Monod.\n\nmunfold\n\nMetric Unfolding. Author: Martin Elff.\n\nmutatr\n\nMutable objects for R. Author: Hadley Wickham.\n\nmvabund\n\nStatistical methods for analysing multivariate abundance data.\nAuthors: Ulrike Naumann, Yi Wang, Stephen Wright and David Warton.\n\nmvngGrAd\n\nSoftware for moving grid adjustment in plant breeding field trials.\nAuthor: Frank Technow.\n\nnanop\n\nTools for nanoparticle simulation and PDF calculation. Author:\nKatharine Mullen.\n\nncdf4\n\nInterface to Unidata netCDF (version 4 or earlier) format data\nfiles. Author: David Pierce.\n\nncvreg\n\nRegularization paths for SCAD- and MCP-penalized regression models.\nAuthor: Patrick Breheny.\n\nneldermead\n\nR port of the Scilab neldermead module. Authors: Sebastien Bihorel\nand Michael Baudin (author of the original module).\n\nnga\n\nNGA earthquake ground motion prediction equations. Authors: James\nKaklamanos and Eric M. Thompson.\n\nnlADG\n\nRegression in the Normal Linear ADG Model. Authors: Lutz F. Gruber\n\nnnDiag\n\nk-Nearest Neighbor diagnostic tools. Authors: Brian Walters,\nAndrew O. Finley and Zhen Zhang.\n\nnonparaeff\n\nNonparametric methods for measuring efficiency and productivity.\nAuthor: Dong-hyun Oh.\n\nnonrandom\n\nStratification and matching by the propensity score. Author: Susanne\nStampf.\n\nnpRmpi\n\nParallel nonparametric kernel smoothing methods for mixed data\ntypes. Authors: Tristen Hayfield and Jeffrey S. Racine.\n\nnppbib\n\nNonparametric Partially-Balanced Incomplete Block Design Analysis.\nAuthors: David Allingham and D.J. Best.\n\nnutshell\n\nData for “R in a Nutshell”. Author: Joseph Adler.\n\nnytR\n\nProvides access to the NY Times API. Author: Shane Conway.\n\nofp\n\nObject-Functional Programming. Author: Charlotte Maia.\n\nomd\n\nFilter the molecular descriptors for QSAR. Author: Bin Ma.\n\nopenintro\n\nOpen Intro data sets and supplement functions. Authors: David M Diez\nand Christopher D Barr.\n\noptimbase\n\nR port of the Scilab optimbase module. Authors: Sebastien Bihorel\nand Michael Baudin (author of the original module).\n\noptimsimplex\n\nR port of the Scilab optimsimplex module. Authors: Sebastien Bihorel\nand Michael Baudin (author of the original module).\n\noptparse\n\nCommand line option parser. Authors: Trevor Davis. getopt\nfunction, some documentation and unit tests ported from Allen Day’s\ngetopt package. Based on the optparse Python library by the Python\nSoftware Foundation.\n\noptpart\n\nOptimal partitioning of similarity relations. Author: David W.\nRoberts.\n\nordinal\n\nRegression models for ordinal data. Author: Rune Haubo B\nChristensen.\n\noro.dicom\n\nRigorous — DICOM Input / Output. Author: Brandon Whitcher. In\nview:\nMedicalImaging.\n\noro.nifti\n\nRigorous — NIfTI Input / Output. Authors: Brandon Whitcher, Volker\nSchmid and Andrew Thornton. In view:\nMedicalImaging.\n\npGLS\n\nGeneralized Least Square in comparative Phylogenetics. Authors:\nXianyun Mao and Timothy Ryan.\n\npROC\n\nDisplay and analyze ROC curves. Authors: Xavier Robin, Natacha\nTurck, Alexandre Hainard, Natalia Tiberti, Frédérique Lisacek,\nJean-Charles Sanchez and Markus Müller.\n\npaleoMAS\n\nPaleoecological Analysis. Authors: Alexander Correa-Metrio, Dunia\nUrrego, Kenneth Cabrera, Mark Bush.\n\npamctdp\n\nPrincipal Axes Methods for Contingency Tables with Partition\nStructures on Rows and Columns. Author: Campo Elías Pardo.\n\npartitionMetric\n\nCompute a distance metric between two partitions of a set. Authors:\nDavid Weisman and Dan Simovici.\n\nparviol\n\nParviol combines parallel coordinates and violin plot. Author:\nJaroslav Myslivec.\n\npedantics\n\nFunctions to facilitate power and sensitivity analyses for genetic\nstudies of natrual popualtions. Author: Michael Morrissey.\n\npgfSweave\n\nQuality speedy graphics compilation with Sweave. Authors: Cameron\nBracken and Charlie Sharpsteen.\n\nphyclust\n\nPhylogenetic Clustering (Phyloclustering). Author: Wei-Chen Chen. In\nview:\nPhylogenetics.\n\nphylobase\n\nBase package for phylogenetic structures and comparative data.\nAuthors: R Hackathon et al. (alphabetically: Ben Bolker, Marguerite\nButler, Peter Cowan, Damien de Vienne, Thibaut Jombart, Steve\nKembel, François Michonneau, David Orme, Brian O’Meara, Emmanuel\nParadis, Jim Regetz, Derrick Zwickl). In view:\nPhylogenetics.\n\nphyloclim\n\nIntegrating phylogenetics and climatic niche modelling. Author:\nChristoph Heibl. In view:\nPhylogenetics.\n\nplgp\n\nParticle Learning of Gaussian Processes. Author: Robert B. Gramacy.\n\nplsdof\n\nDegrees of freedom and confidence intervals for Partial Least\nSquares regression. Authors: Nicole Krämer and Mikio L. Braun.\n\npmlr\n\nPenalized Multinomial Logistic Regression. Authors: Sarah Colby,\nSophia Lee, Juan Pablo Lewinger and Shelley Bull.\n\npng\n\nRead and write PNG images. Author: Simon Urbanek.\n\npoistweedie\n\nPoisson-Tweedie exponential family models. Authors: David Pechel\nCactcha, Laure Pauline Fotso and Célestin C Kokonendji.\n\npolySegratio\n\nSimulate and test marker dosage for dominant markers in\nautopolyploids. Author: Peter Baker.\n\npolySegratioMM\n\nBayesian mixture models for marker dosage in autopolyploids. Author:\nPeter Baker.\n\npopPK\n\nSummary of population pharmacokinetic analysis. Author:\nChristoffer W. Tornoe and Fang Li.\n\npowerMediation\n\nPower/sample size calculation for mediation analysis. Author:\nWeiliang Qiu.\n\nppMeasures\n\nPoint pattern distances and prototypes. Authors: David M Diez,\nKatherine E Tranbarger Freier, and Frederic P Schoenberg.\n\nprofdpm\n\nProfile Dirichlet Process Mixtures. Author: Matt Shotwell.\n\npsychotree\n\nRecursive partitioning based on psychometric models. Authors: Achim\nZeileis, Carolin Strobl and Florian Wickelmaier. In view:\nPsychometrics.\n\nptw\n\nParametric Time Warping. Authors: Jan Gerretzen, Paul Eilers, Hans\nWouters, Tom Bloemberg and Ron Wehrens. In view:\nTimeSeries.\n\npyramid\n\nFunctions to draw population pyramid. Author: Minato Nakazawa.\n\nqrnn\n\nQuantile regression neural network. Author: Alex J. Cannon.\n\nquaternions\n\nArithmetics and linear algebra with Quaternions. Author: K. Gerald\nvan den Boogaart.\n\nr2dRue\n\n2dRue: 2d Rain Use Efficience model. Authors: Gabriel del Barrio,\nJuan Puigdefabregas, Maria E. Sanjuan and Alberto Ruiz.\n\nr2lh\n\nR to LaTeX and HTML. Authors: Christophe Genolini, Bernard\nDesgraupes, Lionel Riou Franca.\n\nr4ss\n\nR code for Stock Synthesis. Authors: Ian Taylor, Ian Stewart, Tommy\nGarrison, Andre Punt, John Wallace, and other contributors.\n\nrEMM\n\nExtensible Markov Model (EMM) for data stream clustering in R.\nAuthors: Michael Hahsler and Margaret H. Dunham.\n\nrandom.polychor.pa\n\nA parallel analysis with polychoric correlation matrices. Author:\nFabio Presaghi and Marta Desimoni.\n\nrangeMapper\n\nA package for easy generation of biodiversity (species richness) or\nlife-history traits maps using species geographical ranges. Authors:\nMihai Valcu and James Dale.\n\nraster\n\nGeographic analysis and modeling with raster data. Author: Robert J.\nHijmans and Jacob van Etten.\n\nrecommenderlab\n\nLab for testing and developing recommender algorithms for binary\ndata. Author: Michael Hahsler.\n\nremix\n\nRemix your data. Author: David Hajage.\n\nrgp\n\nR genetic programming framework. Authors: Oliver Flasch, Olaf\nMersmann, Thomas Bartz-Beielstein and Joerg Stork.\n\nris\n\nRIS package for bibliographic analysis. Author: Stephanie Kovalchik.\n\nrngWELL\n\ntoolbox for WELL random number generators. Authors: C code by F.\nPanneton, P. L’Ecuyer and M. Matsumoto; R port by Christophe Dutang\nand Petr Savicky.\n\nrocc\n\nROC based classification. Author: Martin Lauss.\n\nrpsychi\n\nStatistics for psychiatric research. Author: Yasuyuki Okumura.\n\nrredis\n\nRedis client for R. Author: B. W. Lewis.\n\nrrules\n\nGeneric rule engine for R. Authors: Oliver Flasch, Olaf Mersmann,\nThomas Bartz-Beielstein.\n\nrworldmap\n\nFor mapping global data: rworldmap. Authors: Andy South, with\ncontributions from Barry Rowlingson, Roger Bivand, Matthew Staines\nand Pru Foster. In view:\nSpatial.\n\nsamplesize\n\nA collection of sample size functions. Author: Ralph Scherer.\n\nsamplingbook\n\nSurvey sampling procedures. Authors: Juliane Manitz, contributions\nby Mark Hempelmann, Kauermann, Helmut Küchenhoff, Cornelia\nOberhauser, Nina Westerheide, Manuel Wiesenfarth.\n\nsaws\n\nSmall-Sample Adjustments for Wald tests Using Sandwich Estimators.\nAuthor: Michael Fay.\n\nscaRabee\n\nOptimization toolkit for pharmacokinetic-pharmacodynamic models.\nAuthor: Sebastien Bihorel.\n\nscrapeR\n\nTools for scraping data from HTML and XML documents. Author: Ryan M.\nActon.\n\nsecr\n\nSpatially explicit capture-recapture. Author: Murray Efford.\n\nsemPLS\n\nStructural Equation Modeling using Partial Least Squares. Author:\nArmin Monecke.\n\nsensitivityPStrat\n\nPrincipal stratification sensitivity analysis functions. Author:\nCharles Dupont.\n\nsifds\n\nSwedish inflation forecast data set. Author: Michael Lundholm.\n\nsimPopulation\n\nSimulation of synthetic populations for surveys based on sample\ndata. Authors: Stefan Kraft and Andreas Alfons.\n\nsisus\n\nSISUS: Stable Isotope Sourcing using Sampling. Author: Erik Barry\nErhardt.\n\nsmd.and.more\n\nt-test with Graph of Standardized Mean Difference, and More.\nAuthors: David W. Gerbing, School of Business Administration,\nPortland State University.\n\nsolaR\n\nSolar photovoltaic aystems. Author: Oscar Perpiñán Lamigueiro.\n\nsomeKfwer\n\nControlling the Generalized Familywise Error Rate. Authors: L. Finos\nand A. Farcomeni.\n\nspaa\n\nSpecies Association Analysis. Author: Jinlong Zhang Qiong Ding\nJihong Huang.\n\nspace\n\nSparse PArtial Correlation Estimation. Authors: Jie Peng , Pei Wang,\nNengfeng Zhou and Ji Zhu.\n\nsparcl\n\nPerform sparse hierarchical clustering and sparse k-means\nclustering. Authors: Daniela M. Witten and Robert Tibshirani.\n\nsparkTable\n\nSparklines and graphical tables for TeXand HTML. Authors: Alexander\nKowarik, Bernhard Meindl and Stefan Zechner.\n\nsparr\n\nThe sparr package: SPAtial Relative Risk. Authors: T.M. Davies, M.L.\nHazelton and J.C. Marshall.\n\nspef\n\nSemiparametric estimating functions. Authors: Xiaojing Wang and Jun\nYan.\n\nsphet\n\nSpatial models with heteroskedastic innovations. Author: Gianfranco\nPiras.\n\nspikeslab\n\nPrediction and variable selection using spike and slab regression.\nAuthor: Hemant Ishwaran.\n\nstam\n\nSpatio-Temporal Analysis and Modelling. Author: Zhijie Zhang.\n\nsteepness\n\nTesting steepness of dominance hierarchies. Author: David Leiva and\nHan de Vries.\n\nstockPortfolio\n\nBuild stock models and analyze stock portfolios. Authors: David Diez\nand Nicolas Christou. In view:\nFinance.\n\nstoichcalc\n\nR functions for solving stoichiometric equations. Author: Peter\nReichert.\n\nstratification\n\nUnivariate stratification of survey populations. Authors: Sophie\nBaillargeon and Louis-Paul Rivest.\n\nstratigraph\n\nToolkit for the plotting and analysis of stratigraphic and\npalaeontological data. Author: Walton A. Green.\n\nstringr\n\nMake it easier to work with strings. Author: Hadley Wickham.\n\nsurvPresmooth\n\nPresmoothed estimation in survival analysis. Authors: Ignacio\nLopez-de-Ullibarri and Maria Amalia Jacome.\n\nsymbols\n\nSymbol plots. Author: Jaroslav Myslivec.\n\nsymmoments\n\nSymbolic central moments of the multivariate normal distribution.\nAuthor: Kem Phillips.\n\ntclust\n\nRobust trimmed clustering. Authors: Agustín Mayo Iscar, Luis Angel\nGarcía Escudero and Heinrich Fritz.\n\ntestthat\n\nTestthat code. Tools to make testing fun :). Author: Hadley Wickham.\n\ntgram\n\nFunctions to compute and plot tracheidograms. Authors: Marcelino de\nla Cruz and Lucia DeSoto.\n\ntopicmodels\n\nTopic models. Authors: Bettina Grün and Kurt Hornik.\n\ntourr\n\nImplement tour methods in pure R code. Authors: Dianne Cook and\nHadley Wickham.\n\ntourrGui\n\nA Tour GUI using gWidgets. Authors: Bei, Dianne Cook, and Hadley\nWickham.\n\ntraitr\n\nAn interface for creating GUIs modeled in part after traits UI\nmodule for Python. Author: John Verzani.\n\ntrex\n\nTruncated exact test for two-stage case-control design for studying\nrare genetic variants. Authors: Schaid DJ and Sinnwell JP.\n\ntrio\n\nDetection of disease-associated SNP interactions in case-parent trio\ndata. Authors: Qing Li and Holger Schwender.\n\ntsne\n\nT-distributed Stochastic Neighbor Embedding for R (t-SNE). Author:\nJustin Donaldson.\n\nttime\n\nTranslate neurodevelopmental event timing across species. Author:\nRadhakrishnan Nagarajan.\n\ntwiddler\n\nInteractive manipulation of R expressions. Authors: Oliver Flasch\nand Olaf Mersmann.\n\ntwopartqtl\n\nQTL Mapping for Point-mass Mixtures. Author: Sandra L. Taylor.\n\numlr\n\nOpen Source Development with UML and R. Author: Charlotte Maia.\n\nunmarked\n\nModels for Data from Unmarked Animals. Authors: Ian Fiske and\nRichard Chandler.\n\nvcdExtra\n\nvcd additions. Authors: Michael Friendly with Heather Turner, David\nFirth, Achim Zeileis and Duncan Murdoch.\n\nvegdata\n\nFunctions to use vegetation databases (Turboveg) for vegetation\nanalyses in R. Author: Florian Jansen.\n\nvenneuler\n\nVenn and Euler Diagrams. Author: Lee Wilkinson.\n\nvmv\n\nVisualization of Missing Values. Author: Waqas Ahmed Malik.\n\nwaterfall\n\nWaterfall Charts in R. Authors: James P. Howard, II.\n\nwaveband\n\nComputes credible intervals for Bayesian wavelet shrinkage. Author:\nStuart Barber.\n\nwebvis\n\nCreate graphics for the web from R. Author: Shane Conway.\n\nwq\n\nExploring water quality monitoring data. Authors: Alan D. Jassby and\nJames E. Cloern.\n\nxlsx\n\nRead, write, format Excel 2007 (xlsx) files. Author: Adrian A.\nDragulescu.\n\nxlsxjars\n\nPackage required jars for the xlsx package. Author: Adrian A.\nDragulescu.\n\nzic\n\nBayesian Inference for Zero-Inflated Count Models. Author: Markus\nJochmann. In view:\nBayesian.\n\n4 Other changes\nThe following packages were moved to the Archive: CTFS,\nComPairWise, DICOM, GFMaps, HFWutils, IQCC, JointGLM,\nMIfuns, RGrace, RII, SimHap, SoPhy, adapt, agce,\nagsemisc, assist, cir, connectedness, dirichlet,\nempiricalBayes, gcl, gtm, latentnetHRT,\nmarkerSelectionPower, mcgibbsit, networksis, nlts, popgen,\npoplab, qdg, r2lUniv, rankreg, spatclus, staRt,\nsublogo, tdist, tutoR, vabayelMix, and varmixt.\nThe following packages were resurrected from the Archive:\nProbForecastGOP, SciViews, apTreeshape, far, norm,\nvardiag and xlsReadWrite.\nPackage atm was renamed to amba.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2010-1-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2010-1 issue.",
    "author": [
      {
        "name": "Peter Dalgaard",
        "url": {}
      }
    ],
    "date": "2010-06-01",
    "categories": [],
    "contents": "\n\nWelcome to the 1st issue of the 2nd volume of The R Journal.\nI am writing this after returning from the NORDSTAT 2010 conference on\nmathematical statistics in Voss, Norway, followed by co-teaching a\ncourse on Statistical Practice in Epidemiology in Tartu, Estonia.\nIn Voss, I had the honour of giving the opening lecture entitled “R: a\nsuccess story with challenges”. I shall spare you the challenges here,\nbut as part of the talk, I described the amazing success of R, and a\nshow of hands in the audience revealed that only about 10% of the\naudience was not familiar with R. I also got to talk about the general\nrole of free software in science and I think my suggestion that\nclosed-source software is “like a mathematician hiding his proofs” was\ntaken quite well.\nR 2.11.1 came out recently. The 2.11.x series displays the usual large\nnumber of additions and corrections to R, but if a single major landmark\nis to be pointed out, it must be the availability of a 64-bit version\nfor Windows. This has certainly been long awaited, but it was held back\nby the lack of success with a free software 64-bit toolchain (a port\nusing a commercial toolchain was released by REvolution Computing in\n2009), despite attempts since 2007. On January 4th this year, however,\nGong Yu sent a message to the R-devel mailing list that he had succeeded\nin building R using a version of the MinGW-w64 tools. On January 9th,\nBrian Ripley reported that he was now able to build a version as well.\nDuring Winter and Spring this developed into almost full-blown platform\nsupport in time for the release of R 2.11.0 in April. Thanks go to Gong\nYu and the “R Windows Trojka”, Brian Ripley, Duncan Murdoch, and Uwe\nLigges, but the groundwork by the MinGW-w64 team should also be\nemphasized. The MinGW-w64 team leader, Kai Tietz, was also very helpful\nin the porting process.\nThe transition from R News to The R Journal was always about enhancing\nthe journal’s scientific credibility, with the strategic goal of\nallowing researchers, especially young researchers, due credit for their\nwork within computational statistics. The R Journal is now entering a\nconsolidation phase, with a view to becoming a “listed journal”. To do\nso, we need to show that we have a solid scientific standing with good\neditorial standards, giving submissions fair treatment and being able to\npublish on time. Among other things, this has taught us the concept of\nthe “healthy backlog”: You should not publish so quickly that there\nmight be nothing to publish for the next issue!\nWe are still aiming at being a relatively fast-track publication, but it\nmay be too much to promise publication of even uncontentious papers\nwithin the next two issues. The fact that we now require two reviewers\non each submission is also bound to cause some delay.\nAnother obstacle to timely publication is that the entire work of the\nproduction of a new issue is in the hands of the editorial board, and\nthey are generally four quite busy people. It is not good if a\nsubmission turns out to require major copy editing of its LaTeX markup\nand there is a new policy in place to require up-front submission of\nLaTeX sources and figures. For one thing, this allows reviewers to\nadvise on the LaTeX if they can, but primarily it gives better time for\nthe editors to make sure that an accepted paper is in a state where it\nrequires minimal copy editing before publication. We are now able to\nenlist student assistance to help with this. Longer-term, I hope that it\nwill be possible to establish a front-desk to handle submissions.\nFinally, I would like to welcome our new Book Review editor, Jay Kerns.\nThe first book review appears in this issue and several more are waiting\nin the wings.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2010-1-npp/",
    "title": "Introducing NppToR: R Interaction for Notepad++",
    "description": "The 'Introducing NppToR: R Interaction for Notepad++' article from the 2010-1 issue.",
    "author": [
      {
        "name": "Andrew Redd",
        "url": {}
      }
    ],
    "date": "2010-06-01",
    "categories": [],
    "contents": "\n\n1 Introduction\nA good practice when programming or doing analysis in R is to keep the\ncommands in a script that can be saved and reused. An appropriate editor\nmakes programming in R much more efficient and less error prone.\nOn Linux/Unix systems, users typically use either Vim or EMACS with ESS.\nBoth of these have features to improve programming in R. Features like\nsyntax highlighting, which means certain keywords are colored or marked\nto indicate they have special meaning, and code folding, where lines of\ncode can be automatically grouped and temporarily hidden from view.\nPerhaps the most important feature is the ability to directly evaluate\nlines of code in the R interpreter. This facilitates quick and easy\nprogramming while maintaining a solid record in a reusable script.\nThe version of R for Microsoft Windows comes with a built in editor.\nThis editor does have the interaction features like VIM and EMACS, but\nlacks the other features like syntax highlighting and code folding.\nThere are several alternative code editors for Windows, such as\nNotepad++, WinEDT, Tinn-R, and Eclipse, that do possess advanced\nfeatures but many novice users are simply unaware of them.\nNppToR is a native windows solution that brings the advantages that\nusers of other platforms have to Windows users. NppToR works with the\npowerful and popular code editor Notepad++\n(http://notepad-plus.sourceforge.net/). Notepad++ has a natural\nwindows feel to it and so the learning curve for getting started is\nalmost nonexistent, but as users become more accustomed to the advanced\nfeatures of Notepad++ the real power comes out.\nNppToR tries to follow the easy use and low learning curve of Notepad++.\nIt not only simply works, but also becomes more powerful as users become\nmore familiar with it’s features. NppToR has been under development for\nover a year and has gained a serious user base without ever being\npromoted outside of the R mailing lists. NppToR can be downloaded from\nSourceForge (http://sourceforge.net/projects/npptor/).\n2 Interaction\nThe primary purpose of NppToR is to add R interaction capability to\nNotepad++. It does this through the use of hotkeys. When the hotkey is\npressed it triggers an action such as evaluating a line of code.\nFigure 1 lists the hotkeys and what action they perform.\nThe hotkeys are totally configurable through the settings.\nNppToR Default Hotkeys and Actions\nF8\n\nEvaluate a line of code or selection.\n\nCtrl+F8\n\nEvaluate the entire current file.\n\nShift+F8\n\nEvaluate the file to the point of the cursor.\n\nCtrl+Alt+F8\n\nEvaluate as a batch file and examine the results.\n\n\nFigure 1: The default hotkeys for evaluating code with NppToR.\nNppToR sits in in the system tray, as shown in\nFigure 2. The menu, where the settings and extra\nfeatures are found, is accessed by right clicking on the NppToR icon in\nthe system tray.\nFigure 2:  NppToR sits as a\nutility in the system tray.One of the ways that NppToR just works is that when evaluating code from\nNotepad++, NppToR looks for a current open R GUI session in which to\nevaluate the code. If R is not running, a new R session will be started\nand the code evaluated there. The R home directory is automatically\nfound through the windows registry. One advantage of having NppToR\nstarting R is that the working directory for R is set to the directory\nof the open script in Notepad++. This means that file names for data\nfiles and other scripts can be made relative rather than absolute. For\nexample, if the script reads in a data file data.txt and the data file\nis in the same directory as the script the file reference can simply be\nmade as\ndata <- read.table(\"data.txt\")\nrather than using the absolute path,\ndata <- read.table(\"C:/path/to/data.txt\")\nwhich is not only longer than necessary to type but not portable either.\nSimply moving a file or renaming a folder could break all the file\nreferences. For already open R sessions there is a menu item that will\nset the working directory to the current script directory.\nNppToR is designed to be very small and non-intrusive. It is designed to\nsit in the background and is only active when Notepad++ is in use.\nOccasional users of R may not like having the utility running on\nstartup; for those users when NppToR is run manually it will also launch\nNotepad++.\n3 Other features\nAlthough Notepad++ now has native support for the R language, it is a\nrecent addition. NppToR also generates syntax files for use with\nNotepad++’s user defined language system, which is an artifact from when\nNotepad++ did not have support for R. This feature has been retained\nbecause it still offers advantages over the built in syntax rules. For\nexample, NppToR generates the syntax files dynamically, and can take\nadvantage of a library to include the keywords from installed packages.\nThis method ensures that all major keywords are highlighted, and can\neasily be updated to possible changes in the R distribution, as well as\nthe addition of new packages. The generated language differs also in\nenforcing case sensitivity and proper word boundaries.\nR is an ideal environment for performing simulation studies. These\nsimulations can run for a long time, and are typically run in the batch\nmode. NppToR not only provides an easy hotkey to run these simulations\nbut also provides a simulation monitor to keep track of active\nsimulations, monitor how long they have been running and provide an easy\nway to terminate those that need to be stopped early.\nFigure 3 shows the simulation monitor.\nFigure 3:  NppToR monitors\nactive simulations allowing for an easy way to kill off simulations that\nhave been running to long.4 Summary\nNotepad++ benefits from a large user base, and is constantly updated and\nimproved, including several extensions that also help with developing\nfor R. Notepad++ with NppToR mirrors the advantages of editors on other\nplatforms but with a native windows feel. The power and strength of\nNppToR comes in its simplicity. It enhances an already powerful editor\nto become a superior editor for R.\nBoth Notepad++ and NppToR are easy to use and easy to learn, but as\nusers become proficient with the vast array of keyboard commands and the\nmacro system the true power of Notepad++ is revealed. NppToR should be\nconsidered by any who work with R on Windows.\nAcknowledgments\nThe author’s research was supported by a grant from the National Cancer\nInstitute (CA57030).\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2010-1-r-changes/",
    "title": "Changes in R 2.10.1--2.11.1",
    "description": "The 'Changes in R 2.10.1--2.11.1' article from the 2010-1 issue.",
    "author": [
      {
        "name": "The R Core Team",
        "url": {}
      }
    ],
    "date": "2010-06-01",
    "categories": [],
    "contents": "\n\n1 R 2.11.1 changes\nNew features\nR CMD INSTALL checks if dependent packages are available early on\nin the installation of source packages, thereby giving clearer error\nmessages.\nR CMD INSTALL –build now names the file in the format used for Mac\nOS X binary files on that platform.\nBIC() in package stats4 now also works with multiple fitted\nmodels, analogously to AIC().\nDeprecated & defunct\nUse of file extension .C for C++ code in packages is now\ndeprecated: it has caused problems for some makes on\ncase-insensitive file systems (although it currently works with the\nrecommended toolkits).\nInstallation changes\nCommand gnutar is preferred to tar when configure sets TAR.\nThis is needed on Mac OS 10.6, where the default tar, bsdtar\n2.6.2, has been reported to produce archives with illegal extensions\nto tar (according to the POSIX standard).\nBug fixes\nThe C function mkCharLenCE now no longer reads past len bytes\n(unlikely to be a problem except in user code). (PR#14246)\nOn systems without any defaultLD_LIBRARY_PATH (not even /usr/local/lib),\n[DY]LIB_LIBRARY_PATH is now set without a trailing colon.\n(PR#13637)\nMore efficient utf8ToInt() on long multi-byte strings with many\nmulti-byte characters. (PR#14262)\naggregate.ts() gave platform-depedent results due to rounding\nerror for ndeltat != 1.\npackage.skeleton() sometimes failed to fix filenames for .R or .Rd\nfiles to start with an alphanumeric. (PR#14253) It also failed when\nonly an S4 class without any methods was defined. (PR#14280)\nsplinefun(*, method = \"monoH.FC\") was not quite monotone in rare\ncases. (PR#14215)\nRhttpd no longer crashes due to SIGPIPE when the client closes the\nconnection prematurely. (PR#14266)\nformat.POSIXlt() could cause a stack overflow and crash when used\non very long vectors. (PR#14267)\nRd2latex() incorrectly escaped special characters in \\usage\nsections.\nmcnemar.test() could alter the levels (dropping unused levels) if\npassed x and y as factors (reported by Greg Snow).\nRd2pdf sometimes needed a further pdflatex pass to get\nhyperlinked pages correct.\ninteraction() produced malformed results when levels were\nduplicated, causing segfaults in split().\ncut(d, breaks = <n>) now also works for \"Date\" or \"POSIXt\"\nargument d. (PR#14288)\nmemDecompress() could decompress incompletely rare xz-compressed\ninput due to incorrect documentation of xz utils. (Report and\npatch from Olaf Mersmann.)\nThe S4 initialize() methods for \"matrix\", \"array\", and \"ts\"\nhave been fixed to call validObject(). (PR#14284)\nR CMD INSTALL now behaves the same way with or without\n–no-multiarch on platforms with only one installed architecture.\n(It used to clean the src directory without –no-multiarch.)\n[<-.data.frame was not quite careful enough in assigning (and\npotentially deleting) columns right-to-left. (PR#14263)\nrbeta(n, a,b) no longer occasionally returns NaN for\na >> 1 > b. (PR#14291)\npnorm(x, log.p = TRUE) could return NaN not -Inf for x near\n(minus for lower.tail=TRUE) the largest representable number.\nCompressed data files*.(txt|tab|csv).(gz|bz2|xz)\nwere not recognized for the list of data topics and hence for\npackages using LazyData. (PR#14273)\ntextConnection() did an unnecessary translation on strings in a\nforeign encoding (e.g. UTF-8 strings on Windows) and so was slower\nthan it could have been on very long input strings. (PR#14286)\ntools::Rd2txt() did not render poorly written Rd files\nconsistently with other renderers.\nna.action() did not extract the na.action component as\ndocumented.\n2 R 2.11.0 changes\nSignificant user-visible changes\nPackages must have been installed under\nR\\({}\\ge{}\\)2.10.0, as the current help system is the\nonly one now supported.\nA port to 64-bit Windows is now available as well as binary package\nrepositiories: see the ‘R Administration and Installation Manual’.\nArgument matching for primitive functions is now done in the same\nway as for interpreted functions except for the deliberate\nexceptions\n  call switch .C .Fortran .Call .External\nall of which use positional matching for their first argument, and\nalso some internal-use-only primitives.\nThe default device for command-line R at the console on Mac OS X is\nnow quartz() and not X11().\nNew features\nThe open modes for connections are now interpreted more\nconsistently. open = \"r\" is now equivalent to open = \"rt\" for\nall connections. The default open = \"\" now means \"rt\" for all\nconnections except the compressed file connections gzfile(),\nbzfile() and xzfile() for which it means \"rb\".\nR CMD INSTALL now uses the internal untar() in package utils:\nthis ensures that all platforms can install bzip2- and\nxz-compressed tarballs. In case this causes problems (as it has on\nsome Windows file systems when run from Cygwin tools) it can be\noverridden by the environment variable R_INSTALL_TAR: setting this\nto a modern external tar program will speed up unpacking of large\n(tens of Mb or more) tarballs.\nhelp(try.all.packages = TRUE) is much faster (although the time\ntaken by the OS to find all the packages the first time it is used\ncan dominate the time).\nR CMD check has a new option –timings to record per-example\ntimings in file <pkg>.Rcheck/<pkg>-Ex.timings.\nThe TRE library has been updated to version 0.8.0 (minor bugfixes).\ngrep[l](), [g]sub() and [g]regexpr() now work in bytes in an\n8-bit locales if there is no marked UTF-8 input string: this will be\nsomewhat faster, and for [g]sub() give the result in the native\nencoding rather than in UTF-8 (which returns to the behaviour prior\nto R 2.10.0).\nA new argument skipCalls has been added to browser() so that it\ncan report the original context when called by other debugging\nfunctions.\nMore validity checking of UTF-8 and MBCS strings is done by\nagrep() and the regular-expression matching functions.\nThe undocumented restriction on gregexpr() to length(text) > 0\nhas been removed.\nPackage tcltk now sends strings to Tcl in UTF-8: this means that\nstrings with a marked UTF-8 encoding are supported in non-UTF-8\nlocales.\nThe graphics engine now supports rendering of raster (bitmap)\nimages, though not all graphics devices can provide (full) support.\nPackages providing graphics devices (e.g., Cairo, RSvgDevice,\ncairoDevice) will need to be reinstalled.\nThere is also support in the graphics engine for capturing raster\nimages from graphics devices (again not supported on all graphics\ndevices).\nR CMD check now also checks if the package and namespace can be\nunloaded: this provides a check of the .Last.lib() and\n.onUnload() hook functions (unless –install=fake).\nprop.table(x) now accepts a one-dimensional table for x.\nA new function vapply() has been added, based on a suggestion from\nBill Dunlap. It requires that a template for the function value be\nspecified, and uses it to determine the output type and to check for\nconsistency in the function values.\nThe main HTML help page now links to a reformatted copy of this\nNEWS file. (Suggested by Henrik Bengtsson.) Package index files\nlink to the package DESCRIPTION and NEWS files and a list of\ndemos when using dynamic help.\nThe [ method for class \"AsIs\" allows the next method to change\nthe underlying class. (Wish of Jens Oehlschlägel.)\nwrite.csv[2]() no longer allow append to be changed: as ever,\ndirect calls to write.table() give more flexibility as well as\nmore room for error.\nThe index page for HTML help for a package now collapses multiple\nsignatures for S4 methods into a single entry.\nThe use of .required by require() and detach() has been\nreplaced by .Depends which is set from the Depends field of a\npackage (even in packages with name spaces). By default detach()\nprevents such dependencies from being detached: this can be\noverridden by the argument force.\nbquote() has been extended to work on function definitions (wish\nof PR#14031).\ndetach() when applied to an object other than a package returns\nthe environment that has been detached, to parallel attach().\nreadline() in non-interactive use returns \"\" and does not\nattempt to read from the “terminal”.\nNew function file_ext() in package tools.\nxtfrm() is now primitive and internally generic, as this allows S4\nmethods to be set on it without name-space scoping issues.\nThere are now \"AsIs\" and \"difftime\" methods, and the default\nmethod uses unclass(x) if is.numeric(x) is true (which will be\nfaster but relies on is.numeric() having been set correctly for\nthe class).\nis.numeric(x) is now false for a \"difftime\" object\n(multiplication and division make no sense for such objects).\nThe default method of weighted.mean(x, w) coerces w to be\nnumeric (aka double); previously only integer weights were coerced.\nZero weights are handled specially so an infinite value with zero\nweight does not force an NaN result.\nThere is now a \"difftime\" method.\nbug.report() now has package and lib.loc arguments to generate\nbug reports about packages. When this is used, it looks for a\nBugReports field in the package DESCRIPTION file, which will be\nassumed to be a URL at which to submit the report, and otherwise\ngenerates an email to the package maintainer. (Suggested by Barry\nRowlingson.)\nquantile() now has a method for the date-time class \"POSIXt\",\nand types 1 and 3 (which never interpolate) work for Dates and\nordered factors.\nlength(<POSIXlt>) now returns the length of the corresponding\nabstract timedate-vector rather than always 9 (the length of the\nunderlying list structure). (Wish of PR#14073 and PR#10507.)\nThe readline completion backend no longer sorts possible completions\nalphabetically (e.g., function argument names) if R was built with\nreadline \\(\\ge\\) 6.\nselect.list() gains a graphics argument to allow Windows/Mac\nusers to choose the text interface. This changes the behaviour of\nnew.packages(ask=TRUE) to be like update.packages(ask=TRUE) on\nthose platforms in using a text menu: use ask=\"graphics\" for a\ngraphical menu.\nNew function chooseBioCmirror() to set the \"BioC_mirror\" option.\nThe R grammar prevents using the argument name in signatures of S4\nmethods for $ and $<-, since they will always be called with a\ncharacter string value for name. The implicit S4 generic functions\nhave been changed to reflect this: packages which included name in\nthe signature of their methods need to be updated and re-installed.\nThe handling of the method argument of glm() has been refined\nfollowing suggestions by Ioannis Kosmidis and Heather Turner.\nstr() gains a new argument list.len with default 99, limiting\nthe number of list() items (per level), thanks to suggestions from\nDavid Winsenius.\nHaving formal arguments of an S4 method in a different order from\nthe generic is now an error (the warning having been ignored by some\npackage maintainers for a long time).\nNew functions enc2native() and enc2utf8() convert character\nvectors with possibly marked encodings to the current locale and\nUTF-8 respectively.\nUnrecognized escapes and embedded nuls in character strings are now\nan error, not just a warning. Thus option \"warnEscapes\" is no\nlonger needed. rawToChar() now removes trailing nuls silently, but\nother embedded nuls become errors.\nInformational messages about masked objects displayed when a package\nis attached are now more compact, using strwrap() instead of one\nobject per line.\nprint.rle() gains argument prefix.\ndownload.file() gains a \"curl\" method, mainly for use on\nplatforms which have curl but not wget, but also for some\nhard-to-access URLs.\nIn Rd, \\eqn and \\deqn will render in HTML (and convert to text)\nupper- and lower-case Greek letters (entered as \\alpha …),\n\\ldots, \\dots, \\ge and \\le.\nutf8ToInt() and intToUtf8() now map NA inputs to NA outputs.\nfile() has a new argument raw which may help if it is used with\nsomething other than a regular file, e.g. a character device.\nNew function strtoi(), a wrapper for the C function strtol.\nas.octmode() and as.hexmode() now allow inputs of length other\nthan one.\nThe format() and print() methods for \"octmode\" now preserve\nnames and dimensions (as those for \"hexmode\" did).\nThe format() methods for classes \"octmode\" and \"hexmode\" gain\na width argument.\nseq.int() returns an integer result in some further cases where\nseq() does, e.g. seq.int(1L, 9L, by = 2L).\nAdded \\subsection{}{} macro to Rd syntax, for subsections within\nsections.\nn-dimensional arrays with dimension names can now be indexed by an\nn-column character matrix. The indices are matched against the\ndimension names. NA indices are propagated to the result.\nUnmatched values and \"\" are not allowed and result in an error.\ninteraction(drop=TRUE) uses less memory (related to PR#14121).\nsummary() methods have been added to the \"srcref\" and\n\"srcfile\" classes, and various encoding issues have been cleaned\nup.\nIf option \"checkPackageLicense\" is set to TRUE (not currently\nthe default), users will be asked to agree to non-known-to-be-FOSS\npackage licences at first use.\nChecking setAs(a,b) methods only gives a message instead of a\nwarning, when one of a or b is unknown.\nNew function norm() to compute a matrix norm. norm() and also\nbacksolve() and sample() have implicit S4 generics.\nRenviron.site and Rprofile.site can have architecture-specific\nversions on systems with sub-architectures.\nR CMD check now (by default) also checks Rd files for\nauto-generated content in need of editing, and missing argument\ndescriptions.\naggregate() gains a formula method thanks to a contribution by\nArni Magnusson. The data frame method now allows summary functions\nto return arbitrarily many values.\npath.expand() now propagates NA values rather than converting\nthem to \"NA\".\nfile.show() now disallows NA values for file names, headers, and\npager.\nThe ‘fuzz’ used by seq() and seq.int() has been reduced from\n1e-7 to 1e-10, which should be ample for the double-precision\ncalculations used in R. It ensures that the fuzz never comes into\nplay with sequences of integers (wish of PR#14169).\nThe default value of RSiteSearch(restrict=) has been changed to\ninclude vignettes but to exclude R-help. The R-help archives\navailable have been split, with a new option of \"Rhelp10\" for\nthose from 2010.\nNew function rasterImage() in the graphics package for drawing\nraster images.\nstats:::extractAIC.coxph() now omits aliased terms when computing\nthe degrees of freedom (suggestion of Terry Therneau).\ncor() and cov() now test for misuse with non-numeric arguments,\nsuch as the non-bug report PR#14207.\npchisq(ncp =, log.p = TRUE) is more accurate for probabilities\nnear one. E.g. pchisq(80, 4, ncp=1, log.p=TRUE). (Maybe what was\nmeant in PR#14216.)\nmaintainer() has been added, to give convenient access to the name\nof the maintainer of a package (contributed by David Scott).\nsample() and sample.int() allow zero items to be sampled from a\nzero-length input. sample.int() gains a default value size=n to\nbe more similar to sample().\nswitch() returned NULL on error (not previously documented on\nthe help page): it now does so invisibly, analogously to\nif-without-else.\nIt is now primitive: this means that EXPR is always matched to the\nfirst argument and there is no danger of partial matching to later\nnamed arguments.\nPrimitive functions UseMethod(), attr(), attr<-(),\non.exit(), retracemem() and substitute() now use standard\nargument matching (rather than positional matching). This means that\nall multi-argument primitives which are not internal now use\nstandard argument matching except where positional matching is\ndesirable (as for switch(), call(), .C(), …).\nAll the one-argument primitives now check that any name supplied for\ntheir first argument is a partial match to the argument name as\ndocumented on the help page: this also applies to replacement\nfunctions of two arguments.\nbase::which() uses a new .Internal function when arr.ind is\nFALSE resulting in a 10x speedup. Thanks to Patrick Aboyoun for\nimplementation suggestions.\nHelp conversion to text now uses the first part of \\enc{}{} markup\nif it is representable in the current output encoding. On the other\nhand, conversion to LaTeX with the default\noutputEncoding = \"ASCII\" uses the second part.\nA new class \"listOfMethods\" has been introduced to represent the\nmethods in a methods table, to replace the deprecated class\n\"MethodsList\".\nany() and all() return early if possible. This may speed up\noperations on long vectors.\nstrptime() now accepts \"%z\" (for the offset from UTC in the\nRFC822 format of +/-hhmm).\nThe PCRE library has been updated to version 8.02, a bug-fix release\nwhich also updates tables to Unicode 5.02.\nFunctions which may use a graphical select.list() (including\nmenu() and install.packages()) now check on a Unix-alike that Tk\ncan be started (and not just capabilities(\"tcltk\") &&\ncapabilities(\"X11\")).\nThe parser no longer marks strings containing octal or hex escapes\nas being in UTF-8 when entered in a UTF-8 locale.\nOn platforms with cairo but not Pango (notably Mac OS X) the initial\ndefault X11() type is set to \"Xlib\": this avoids several\nproblems with font selection when done by cairo rather than Pango\n(at least on Mac OS X).\nNew arrayInd() such that which(x, arr.ind = TRUE) for an array\nx is now equivalent to arrayInd(which(x), dim(x),\ndimnames(x)).\nDeprecated & defunct\nBundles of packages are defunct.\nstats::clearNames() is defunct: use unname().\nBasic regular expressions are defunct, and strsplit(), grep(),\ngrepl(), sub(), gsub(), regexpr() and gregexpr() no longer\nhave an extended argument.\nmethods::trySilent() is defunct.\nindex.search() (which was deprecated in 2.10.0) is no longer\nexported and has a different argument list.\nUse of multiple arguments to return() is now defunct.\nThe use of UseMethod() with more than two arguments is now\ndefunct.\nIn the methods package, the MethodsList metadata objects which had\nbeen superseded by hash tables (environments) since R 2.8.0 are\nbeing phased out. Objects of this class are no longer assigned or\nused as metadata by the package.\ngetMethods() is now deprecated, with its internal use replaced by\nfindMethods() and other changes. Creating objects from the\nMethodsList class is also deprecated.\nParsing strings containing both octal/hex and Unicode escapes now\ngives a warning and will become an error in R 2.12.0.\nInstallation changes\nUTF-8 is now used for the reference manual and package manuals. This\nrequires LaTeX 2005/12/01 or later.\nconfigure looks for a POSIX compliant tr, Solaris’s /usr/ucb/tr\nhaving been found to cause Rdiff to malfunction.\nconfigure is now generated with autoconf-2.65, which works better on\nrecent systems and on Mac OS X.\nPackage installation changes\nCharacters in R source which are not translatable to the current\nlocale are now handled more tolerantly: these will be converted to\nhex codes with a warning. Such characters are only really portable\nif they appear in comments.\nR CMD INSTALL now tests that the installed package can be loaded\n(and backs out the installation if it cannot): this can be\nsuppressed by –no-test-load. This avoids installing/updating a\npackage that cannot be used: common causes of failures to load are\nmissing/incompatible external software and missing/broken dependent\npackages.\nPackage installation on Windows for a package with a src directory\nnow checks if a DLL is created unless there is a src/Makefile.win\nfile: this helps catch broken installations where the toolchain has\nnot reported problems in building the DLL. (Note: this can be any\nDLL, not just one named <pkg-name>.dll.)\nBug fixes\nUsing with(), eval() etc with a list with some unnamed elements\nnow works. (PR#14035)\nThe “quick” dispatch of S4 methods for primitive functions was not\nhappening, forcing a search each time. (Dispatch for closures was\nnot affected.) A side effect is that default values for arguments in\na method that do not have defaults in the generic will now be\nignored.\nTrying to dispatch S4 methods for primitives during the search for\ninherited methods slows that search down and potentially could cause\nan infinite recursion. An internal switch was added to turn off all\nsuch methods from findInheritedMethods().\nR framework installation (on Mac OS X) would not work properly if a\nrogue Resources directory was present at the top level. Such a\nnon-symlink will now be renamed to Resources.old (and anything\npreviously named Resources.old removed) as part of the framework\ninstallation process.\nThe checks for conforming S4 method arguments could fail when the\nsignature of the generic function omitted some of the formal\narguments (in addition to ...). Arguments omitted from the method\ndefinition but conforming (per the documentation) should now be\nignored (treated as \"ANY\") in dispatching.\nThe computations for S4 method evaluation when ... was in the\nsignature could fail, treating ... as an ordinary symbol. This has\nbeen fixed, for the known cases.\nVarious ar() fitting methods have more protection for singular\nfits.\ncallNextMethod() now works again with the drop= argument in ‘\nparse() and parse_Rd() miscounted columns when multibyte UTF-8\ncharacters were present.\nFormatting of help pages has had minor improvements: extra blank\nlines have been removed from the text format, and empty package\nlabels removed from HTML.\ncor(A, B) where A has \\(n \\times 1\\) and B a 1-dimensional array\nsegfaulted or gave an internal error. (The case cor(B, A) was\nPR#7116.)\ncut.POSIXt() applied to a start value after the DST transition on\na DST-change day could give the wrong time for breaks in units of\ndays or longer. (PR#14208)\ndo_par() UNPROTECTed too early (PR#14214)\nsubassignment x[[....]] <- y didn’t check for a zero-length right\nhand side, and inserted rubbish value. (PR#14217)\nfisher.test() no longer gives a P-value very slightly > 1, in\nsome borderline cases.\nInternal function matchArgs() no longer modifies the general\npurpose bits of the SEXPs that make up the formals list of R\nfunctions. This fixes an invalid error message that would occur when\na garbage collection triggered a second call to matchArgs for the\nsame function via a finalizer.\ngsub() in 2.10.x could fail from stack overflow for extremely long\nstrings due to temporary data being allocated on the stack. Also,\ngsub() with fixed=TRUE is in some circumstances considerably\nfaster.\nSeveral primitives, including attributes(), attr<-()\ninteractive(), nargs() and proc.time(), did not check that\nthey were called with the correct number of arguments.\nA potential race condition in list.files() when other processes\nare operating on the directory has been fixed; the code now\ndynamically allocates memory for file listings in a single pass\ninstead of making an initial count pass.\nmean(x, trim=, na.rm = FALSE) failed to return NA if x\ncontained missing values. (Reported by Bill Dunlap.)\nExtreme tail behavior of, pbeta() and hence pf(), e.g.,\npbeta(x, 3, 2200, lower.tail=FALSE, log.p=TRUE) now returns finite\nvalues instead of jumping to -Inf too early (PR#14230).\nparse(text=x) misbehaved for objects x that were not coerced\ninternally to character, notably symbols. (Reported to R-devel by\nBill Dunlap.)\nThe internal C function coerceSymbol now handles coercion to\ncharacter, and warns if coercion fails (rather than silently\nreturning NULL). This allows a name to be given where a character\nvector is required in functions which coerce internally.\nThe interpretation by strptime() of that it is ever advisable to\nuse locale- and system-specific input formats).\ncapabilities(\"X11\") now works the same way on Mac OS X as on other\nplatforms (and as documented: it was always true for R built with\n–with-aqua, as the CRAN builds are).\nThe X11() device with cairo but not Pango (notably Mac OS X) now\nchecks validity of text strings in UTF-8 locales (since Pango does\nbut cairo it seems does not).\nread.fwf() misread multi-line records when n was specified.\n(PR#14241)\nall.equal(*, tolerance = e) passes the numeric tolerance also to\nthe comparison of the attributes.\npgamma(0,0), a boundary case, now returns 0, its limit from the\nleft, rather than the limit from the right.\nIssuing POST requests to the internal web server could stall the\nrequest under certain circumstances.\ngzcon( <textConnection> ), an error, no longer damages the\nconnection (in a way to have it seg.fault). (PR#14237)\nAll the results from hist() now use the nominal breaks not those\nadjusted by the numeric fuzz: in recent versions the nominal\nbreaks were reported but the density referred to the intervals\nused in the calculation — which mattered very slightly for one of\nthe extreme bins. (Based on a report by Martin Becker.)\nIf xy[z].coords() (used internally by many graphics functions) are\ngiven a list as x, they now check that the list has suitable names\nand give a more informative error message. (PR#13936)\n3 R 2.10.1 patched changes\nNew features\nThe handling of line textures in the postscript() and pdf()\ndevices was set up for round end caps (the only type which existed\nat the time): it has now been adjusted for butt endcaps.\nlchoose(a,k) is now defined aslog(abs(choose(a,k))), analogously to lfactorial().\nAlthough \\eqn{} in Rd files is defined as a verbatim macro, many\npackages expected \\dots and \\ldots to be interpreted there (as\nwas the case in R < 2.10.0), so this is now done (using an ellipsis\nin HTML rendering).\nEscaping of braces in quoted strings in R-code sections of Rd files\nis allowed again. This had been changed for the new Rd format in R\n2.10.0 but was only documented on the developer site and was handled\ninconsistently by the converters: text and example conversion\nremoved the escapes but HTML conversion did not.\nThe PCRE library has been updated to version 8.01, a bug-fix\nrelease.\ntools::readNEWS() now accepts a digit as the first character of a\nnews section.\nBug fixes\nUsing read.table(header=TRUE) on a header with an embedded new\nline would copy part of the header into the data. (PR#14103)\nqpois(p = 1, lambda = 0) now gives 0 as for all other p.\n(PR#14135)\nFunctions related to string comparison (e.g. unique(), match())\ncould cause crashes when used with strings not in the native\nencoding, e.g. UTF-8 strings on Windows. (PR#14114 and PR#14125)\nx[ , drop=TRUE] dropped an NA level even if it was in use.\nThe dynamic HTML help system reported the wrong MIME type for the\nstyle sheet.\ntools::codoc() (used by R CMD check) was missing cases where the\nfunction had no arguments but was documented to have some.\nHelp links containing special characters (e.g. \"?\") were not\ngenerated correctly when rendered in HTML. (PR#14155)\nlchoose(a,k) no longer wrongly gives NaN for negative a.\nks.test() could give a p-value that was off by one observation due\nto rounding error. (PR#14145)\nreadBin()/readChar() when reading millions of character strings in\na single call used excessive amounts of memory (which also slowed\nthem down).\nR CMD SHLIB could fail if used with paths that were not\nalphanumeric, e.g. contained +. (PR#14168)\nsprintf() was not re-entrant, which potentially caused problems if\nan as.character() method called it.\nThe quartz() device did not restore the clipping region when\nfilling the background for a new page. This could be observed in\nmulti-page bitmap output as stale outer regions of the plot.\np.adjust(*, method, n) now works correctly for the rare case\nn > length(p), also when method differs from \"bonferroni\" or\n\"none\", thanks to a patch from Gordon Smyth.\ntools::showNonASCII() failed to detect non-ASCII characters if\niconv() (incorrectly) converted them to different ASCII\ncharacters. (Seen on Windows only.)\ntcrossprod() wrongly failed in some cases when one of the\narguments was a vector and the other a matrix.\n[cr]bind(..., deparse.level=2) was not always giving names when\ndocumented to do so. (Discovered whilst investigating PR#14189.)\nmatch(incomparables=<non-NULL>) could in rare cases infinite-\nloop.\npoisson.test() needed to pass conf.level to binom.test()\n(PR#14195)\nThe \"nls\" method for df.residual() gave incorrect results for\nmodels fitted with na.action = na.exclude. (PR#14194)\nA change to options(scipen=) was only implemented when printing\nnext occurred, even though it should have affected intervening calls\nto axis(), contour() and filledcontour().\nprettyNum(drop0trailing=TRUE) did not handle signs of imaginary\nparts of complex numbers correctly (and this was used by str():\nPR#14201).\nsystem.time() had sys.child component wrong (copied user.child\ninstead) on systems with HAVE_GETRUSAGE (PR#14210)\nChanging both line texture and line cap (end) resulted in the latter\nto be ommitted form the PDF code. In addition, line cap (end) and\njoin are now set explicitly in PDF output to ensure correct\ndefaults.\nThe suppression of auto-rotation in bitmap() and dev2bitmap()\nwith the pdfwrite device was not working correctly.\nplot(ecdf(), log=\"x\") no longer gives an incorrect warning.\nread.fwf() works again when file is a connection.\nStartup files will now be found if their paths exceed 255 bytes.\n(PR#14228)\ncontrasts<- (in the stats package) no longer has an undeclared\ndependence on methods (introduced in 2.10.0).\n4 R 2.10.1 changes since previous Journal Issue\n(Most of the changes to what was then “2.10.0 Patched” were described in\nVol 1/2.)\nBug fixes\nswitch(EXPR = \"A\") now returns NULL, as switch(1) which used\nto signal an error.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2010-1-r-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2010-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2010-06-01",
    "categories": [],
    "contents": "\n1 Donations and new members\nDonations\nVies Animales, France\nOwen Jones, Robert Maillardet, and Andrew Robinson, Australia:\ndonating a proportion of the royalties for the book “Introduction to\nScientific Programming and Simulation using R”, recently\npublished (2009) by Chapman & Hall/CRC\nJogat Sheth, USA\nNew benefactors\nOpenAnalytics, Belgium\nRitter and Danielson Consulting, Belgium\nSaorstat Limited, Ireland\nNew supporting institutions\nMarine Scotland Science (UK)\nDFG Research Group “Mind and Brain Dynamics”, Universität Potsdam\n(Germany)\nChaire d’actuariat, Université Laval (Canada)\nNew supporting members\nJosé Banda, USA\nKapo Martin Coulibaly, USA\nAndreas Eckner, USA\nMarco Geraci, UK\nDavid Monterde, Spain\nGuido Germany\nAlexandre Salvador, France\nAjit de Silva, USA\nWen Hsiang Wie, Taiwan\nTomas Zelinsky, Slovakia\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:08+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2009-2-bioconductor/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2009-2 issue.",
    "author": [
      {
        "name": "Bioconductor Team",
        "url": {}
      }
    ],
    "date": "2009-12-01",
    "categories": [],
    "contents": "\n\nWe are pleased to announce Bioconductor 2.5, released on October 28,\n2009. Bioconductor 2.5 is compatible with R 2.10.0, and consists of 352\npackages. There are 34 new packages, and enhancements to many others.\nExplore Bioconductor at http://bioconductor.org, and install packages\nwith\n> source(\"http://bioconductor.org/biocLite.R\")\n> biocLite() # install standard packages...\n> biocLite(\"IRanges\") # ...or IRanges\n1 New and revised packages\nThis release includes new packages for diverse areas of high-throughput\nanalysis. Highlights include:\nNext-generation sequence analysis\n\npackages for ChIP-seq\n(chipseq,\nChIPseqR,\nchIPpeakAnno,\nChIPsim),\ndifferential expression\n(DEGseq,\nbaySeq),\nannotation\n(GenomicFeatures),\nand image processing\n(Rolexa).\n\nAdvanced statistical methods\n\nfor microarray classification\n(BioSeqClass),\ndifferential expression\n(cycle,\nLiquidAssociation,\nSpeCond),\nand probe reliability\n(RPA).\n\nMicroarray domain-specific analysis\n\nof copy number, array CGH, tiling\n(CNTools,\nCNVtools,\nStarr,\nCGHnormaliter,\nmBPCR),\nmicro-RNA\n(AgiMicroRna,\nRmiR,\nMiChip),\nand methylation\n(methylumi)\narrays.\n\nFlow cytometry\n\nfingerprinting\n(flowFP),\ncluster merging\n(flowMerge),\nand plate-based assays\n(plateCore).\n\nDiverse assays\n\nrelated to high-throughput qPCR\n(ddCt,\nHTqPCR),\nclinical proteomics\n(clippda),\nand RTCA\n(RTCA).\n\nIntegrative tools\n\nfor data mining\n(RTools4TB),\nannotation\n(GeneAnswers),\nnetwork reconstruction\n(BUS),\nand visualization\n(ChromHeatMap).\n\nOur large collection of microarray- and organism-specific annotation\npackages have been updated to include information current at the time of\nthe Bioconductor release. These annotation packages contain biological\ninformation about microarray probes and the genes they are meant to\ninterrogate, or contain gene-based annotations of whole genomes. They\nare particularly valuable in providing stable annotations for repeatable\nresearch.\nFurther information on new and existing packages can be found on the\nBioconductor web site, which contains ‘views’ that identify coherent\ngroups of packages. The views link to on-line package descriptions,\nvignettes, reference manuals, and use statistics.\n2 Other activities\nThe Bioconductor community met on July 27-28 at our annual conference in\nSeattle for a combination of scientific talks and hands-on tutorials.\nThe active Bioconductor mailing lists\n(http://bioconductor.org/docs/mailList.html) connect users with each\nother, to domain experts, and to maintainers eager to ensure that their\npackages satisfy the needs of leading edge approaches. Bioconductor\npackage maintainers and the Bioconductor team invest considerable effort\nin producing high-quality software. The Bioconductor team continues to\nensure quality software through technical and scientific reviews of new\npackages, and daily builds of released packages on Linux, Windows, and\nMacintosh platforms.\n3 Looking forward\nContributions from the Bioconductor community play an important role in\nshaping each release. In addition to development of high-quality\nalgorithms for microarray data, we anticipate continued efforts to\nprovide statistically informed analysis of next generation sequence\ndata. Areas of opportunity include the ChIP-seq, RNA-seq, rare variant,\nand structural variant domains. Analysis of next generation sequence\ndata poses significant challenges in data representation, annotation,\nand manipulation; the Bioconductor team is actively working on solutions\nto address these software infrastructure challenges. We also anticipate\ndevelopment of improved graph representations, important for\nmanipulating large networks of biological data. The next release cycle\npromises to be one of active scientific growth and exploration!\n\n\nBioconductor packages used\nchipseq, ChIPseqR, chIPpeakAnno, ChIPsim, DEGseq, baySeq, GenomicFeatures, Rolexa, BioSeqClass, cycle, LiquidAssociation, SpeCond, RPA, CNTools, CNVtools, Starr, CGHnormaliter, mBPCR, AgiMicroRna, RmiR, MiChip, methylumi, flowFP, flowMerge, plateCore, ddCt, HTqPCR, clippda, RTCA, RTools4TB, GeneAnswers, BUS, ChromHeatMap\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2009-2-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2009-2 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      }
    ],
    "date": "2009-12-01",
    "categories": [],
    "contents": "\n\n1 New CRAN task views\nClinicalTrials\n\nDesign, Monitoring, and Analysis of Clinical Trials.\nPackages: ClinicalRobustPriors\\(^*\\), GroupSeq\\(^*\\), HH,\nHmisc\\(^*\\), MChtest\\(^*\\), PwrGSD\\(^*\\), asypow,\nbifactorial\\(^*\\), binomSamSize, blockrand\\(^*\\), clinfun\\(^*\\),\ncoin, copas, epibasix, epicalc, experiment\\(^*\\),\ngsDesign\\(^*\\), ldbounds\\(^*\\), meta, metafor, multcomp,\nrmeta, seqmon\\(^*\\), speff2trial\\(^*\\), ssanv, survival\\(^*\\).\nMaintainer: Ed Zhang.\n\nMedicalImaging\n\nMedical Image Analysis.\nPackages: AnalyzeFMRI\\(^*\\), DICOM\\(^*\\), PET\\(^*\\),\nRniftilib\\(^*\\), VR, adimpro\\(^*\\), bitops, dcemri\\(^*\\),\ndti\\(^*\\), fmri\\(^*\\), minpack.lm, tractor.base\\(^*\\).\nMaintainer: Brandon Whitcher.\n\n(* = core package)\n2 New packages in CRAN task views\nBayesian\n\nBAS, glmmBUGS.\n\nChemPhys\n\nAquaEnv, CHNOSZ, NMRS, gpls, nlreg, paltran, plspm,\nquantchem, spls.\n\nCluster\n\nnnclust.\n\nDistributions\n\nLmoments, VarianceGamma, denstrip, evdbayes, evir,\nfExtremes, fitdistrplus, gamlss.dist\\(^*\\), gamlss.mx, ig.\n\nEconometrics\n\nCADFtest, Mcomp, Zelig, aod, expsmooth, fma, forecast.\n\nEnvironmetrics\n\naod, primer, vegetarian.\n\nExperimentalDesign\n\nDoE.base\\(^*\\), DoE.wrapper\\(^*\\), RcmdrPlugin.DoE.\n\nFinance\n\nYieldCurve, atmi, forecast, ttrTests.\n\nHighPerformanceComputing\n\ncudaBayesreg, doMC, doSNOW, foreach, speedglm.\n\nMachineLearning\n\npenalizedSVM.\n\nNaturalLanguageProcessing\n\nopenNLPmodels.en, openNLPmodels.es.\n\nOptimization\n\nRcsdp, nleqslv.\n\nPsychometrics\n\nMLCM, SEMModComp, irtProb, latdiag.\n\nSpatial\n\nRgoogleMaps, nlme.\n\nSurvival\n\nAER, BMA, BayHaz, DAAG, Epi, ICE, LearnBayes,\nLogicReg, MAMSE, MCMCglmm, MCMCpack, OrdFacReg, SMIR,\nSMPracticals, SimHap, VGAM, XReg, clinfun, cmprskContin,\ncoin, condGEE, coxme, epiR, etm, fitdistrplus, gbm,\ngof, gss, interval, ipred, km.ci, kmi, lmec, locfit,\nlogspline, maxstat, mixAK, mstate, multcomp, multtest,\nmvpart, nltm, p3state.msm, pamr, party, penalized,\nphmm, polspline, quantreg, rankhazard, rhosp,\nrisksetROC, rms\\(^*\\), spatstat, superpc, survcomp,\nsurvey, uniCox.\n\nTimeSeries\n\nCADFtest, EvalEst, KFAS, Mcomp, dlnm, expsmooth, fma,\nforecast\\(^*\\), fractalrock, mar1s, tiger, tis.\n\n(* = core package)\n3 New contributed packages\nADGofTest\n\nAnderson-Darling GoF test with p-value calculation based on\nMarsaglia’s 2004 paper “Evaluating the Anderson-Darling\nDistribution”. By Carlos J. Gil Bellosta.\n\nAGSDest\n\nEstimation in adaptive group sequential trials. By Niklas Hack and\nWerner Brannath.\n\nCDFt\n\nStatistical downscaling through CDF transform. Also performs\ncomputation of the Cramèr-von Mises and Kolmogorov-Smirnov\nstatistics. By Mathieu Vrac and Paul-Antoine Michelangeli.\n\nCOP\n\nVariables selection for index models via correlation pursuit. By\nWenxuan Zhong.\n\nCORElearn\n\nA machine learning suite for classification, regression, feature\nevaluation and ordinal evaluation, based on C++ code. Contains\nseveral model learning techniques in classification and regression,\nfor example decision and regression trees with optional constructive\ninduction and models in the leafs, random forests, kNN, naive Bayes,\nand locally weighted regression. Especially strong in feature\nevaluation algorithms where it contains several variants of Relief\nalgorithm and many impurity based attribute evaluation functions,\ne.g., Gini, information gain, MDL, DKM, etc. Additional strengths\nare its ordEval algorithm and its visualization used for ordinal\nfeatures and classes. By Marko Robnik-Sikonja and Petr Savicky.\n\nCalciOMatic\n\nSimulate and analyze calcium imaging data obtained with ratiometric\ndyes. By Sebastien Joucla, Christophe Pouzat.\n\nCircNNTSR\n\nStatistical analysis of circular data using non-negative\ntrigonometric sums (NNTS) models. Includes functions for calculation\nof densities and distributions, the estimation of parameters,\nplotting and more. By Juan José Fernández-Durán and Maria Mercedes\nGregorio-Domínguez.\n\nCircSpatial\n\nA collection of functions for color continuous high resolution\nimages of circular spatial data, circular kriging, and simulation of\ncircular random fields. By Bill Morphet.\n\nDRI\n\nDR-Integrator: Integrative analysis of DNA copy number and gene\nexpression data described in Salari et al (2009). By Keyan Salari,\nRobert Tibshirani, and Jonathan R. Pollack.\n\nDTDA\n\nDoubly Truncated Data Analysis. Implements different algorithms for\nanalyzing randomly, one-sided and two-sided (i.e., doubly) truncated\ndata. By Carla Moreira, Jacobo de Uña-Álvarez and Rosa Crujeiras.\n\nDaim\n\nDiagnostic accuracy of classification models. Several functions for\nevaluating the accuracy of classification models. Provides\nperformance measures ‘cv’, ‘0.632’ and ‘0.632+’, estimation of the\nmisclassification rate, sensitivity, specificity and AUC. If an\napplication is computationally intensive, parallel execution can be\nused to reduce the time taken. By Sergej Potapov, Werner Adler and\nBerthold Lausen.\n\nDeducer\n\nAn intuitive graphical data analysis system for use with JGR. By\nIan Fellows.\n\nDiversitySampler\n\nFunctions for re-sampling a community matrix to compute Shannon’s\nDiversity index at different sampling levels. By Matthew K. Lau.\n\nDoE.base\n\nCreation of full factorial experimental designs and designs based on\northogonal arrays for (industrial) experiments. Additionally\nprovides some utility functions used also by other DoE packages. By\nUlrike\n\nDoE.wrapper\n\nWrapper package for design of experiments functionality. Creates\nvarious kinds of designs for (industrial) experiments by using and\npossibly enhancing design generation routines from other packages.\nCurrently, response surface designs from package rsm and latin\nhypercube samples from package lhs have been implemented. By\nUlrike\n\nEQL\n\nExtended Quasi Likelihood function (EQL). Computation of the EQL for\na given family of variance functions, Saddlepoint-approximations and\nrelated auxiliary functions (e.g., Hermite polynomials). By Thorn\nThaler.\n\nElectroGraph\n\nEnhanced routines for plotting and analyzing valued relational data,\nconsidering valued ties. In particular, relative distances are\ncalculated using social conductance methods. By Andrew C. Thomas.\n\nEnQuireR\n\nA package dedicated to questionnaires. By Fournier Gwenaëlle,\nCadoret Marine, Fournier Olivier, Le Poder François, Bouche Jérôme,\nand Lê Sébastien.\n\nEvalEst\n\nDynamic Systems Estimation (DSE) extensions. By Paul Gilbert.\n\nFEST\n\nIdentification of family relations using linked markers. By Øivind\nSkare.\n\nFME\n\nA Flexible Modeling Environment for inverse modeling, sensitivity,\nidentifiability, Monte Carlo analysis. Intended to work with models\nwritten as a set of differential equations that are solved either by\nan integration routine from package deSolve, or a steady-state\nsolver from package rootSolve, but can also be used with other\ntypes of functions. By Karline Soetaert and Thomas Petzoldt.\n\nFRB\n\nRobust inference based on applying Fast and Robust Bootstrap on\nrobust estimators. Available methods are multivariate regression,\nPCA and Hotelling tests. By Ella Roelant, Stefan Van Aelst and Gert\nWillems.\n\nGGMselect\n\nGaussian Graphs Models selection: graph estimation in Gaussian\nGraphical Models. The main functions return the adjacency matrix of\nan undirected graph estimated from a data matrix. By Annie Bouvier,\nChristophe Giraud, Sylvie Huet, and Verzelen N.\n\nGLMMarp\n\nGeneralized Linear Multilevel Model with AR(p) errors. Functions to\nestimate the GLMM-AR(p) model for analyzing discrete time-series\ncross-sectional data via MCMC simulation. Also contains several\nuseful utility functions, including an independent function for\ncomputing the Bayes factor with GLMM-AR(p) output, a function to\nrecover the random coefficients at the individual level, and a\nfunction to do prediction by using the posterior distributions. By\nXun Pang.\n\nGOFSN\n\nGoodness-Of-Fit tests for the family of Skew-Normal models.\nImplements a method for checking if a skew-normal model fits the\nobserved dataset, when all parameters are unknown. While location\nand scale parameters are estimated by moment estimators, the shape\nparameter is integrated with respect to the prior predictive\ndistribution, as proposed in Box (1980). A default and proper prior\non skewness parameter is used to obtain the prior predictive\ndistribution, as proposed in Cabras, & Castellanos (2008). By\nVeronica Paton Romero.\n\nGWAF\n\nGenome-Wide Association analyses with Family data: Functions to test\ngenetic associations between SNPs and a continuous/dichotomous trait\nusing family data, and to make genome-wide p-value plots and QQ\nplots. By Ming-Huei Chen and Qiong Yang.\n\nGeneReg\n\nInfer time delay gene regulatory networks using time course gene\nexpression profiles. The main idea of the time delay linear model is\nto fit a linear regression model using a set of putative regulators\nto estimate the transcription pattern of a specific target gene. By\nTao Huang.\n\nGeneclust\n\nSimulation and analysis of spatial structure of population genetics\ndata. By Sophie Ancelet.\n\nHMR\n\nStatistical analysis of static chamber concentration data for trace\ngas flux estimation. By Asger R. Pedersen.\n\nHSAUR2\n\nA Handbook of Statistical Analyses Using R (2nd Edition). Functions,\ndata sets, analyses and examples from the second edition of the book\n“A Handbook of Statistical Analyses Using R” (Brian S. Everitt and\nTorsten Hothorn, Chapman & Hall/CRC, 2008). By Brian S. Everitt and\nTorsten Hothorn.\n\nHTMLUtils\n\nFacilitates automated HTML report creation, in\nparticular framed HTML pages and dynamically sortable\ntables. By Markus Loecher.\n\nHWEBayes\n\nBayesian investigation of Hardy-Weinberg Equilibrium via estimation\nand testing. Three models are currently considered: HWE, a model\nparametrized in terms of the allele frequencies and a single\ninbreeding coefficient f, and the saturated model. Testing is based\non Bayes factors. By Jon Wakefield.\n\nHaplin\n\nPerforms a genetic association analysis of case-parent triad (trio)\ndata with multiple markers. Can also incorporate complete or\nincomplete control triads, for instance independent control\nchildren. Estimation is based on haplotypes, for instance SNP\nhaplotypes, even though phase is not known from the genetic data.\nEstimates relative risk and p-values associated with each haplotype.\nUses MLE to make optimal use of data from triads with missing\ngenotypic data, for instance if some SNPs has not been typed for\nsome individuals. Also allows estimation of effects of maternal\nhaplotypes, particularly appropriate in perinatal epidemiology.\nBy H. K. Gjessing.\n\nHybridMC\n\nAn implementation of the Hybrid Monte Carlo and Multipoint Hybrid\nMonte Carlo sampling techniques described in Liu (2001), “Monte\nCarlo Strategies in Computing”. By Richard D. Morey.\n\nIsoGene\n\nTesting for monotonic relationship between gene expression and doses\nin a microarray experiment. Several testing procedures including the\nglobal likelihood ratio test (Bartholomew, 1961), Williams (1971,\n1972), Marcus (1976), M (Hu et al. 2005) and the modified M (Lin et\nal. 2007) are used to test for the monotonic trend in gene\nexpression with respect to doses. BH (Benjamini and Hochberg 1995)\nand BY (Benjamini and Yekutilie 2004) FDR controlling procedures are\napplied to adjust the raw p-values obtained from the permutations.\nBy Dan Lin et al.\n\nKFAS\n\nFunctions for fast Kalman filtering, state and disturbance\nsmoothing, forecasting and simulation of multivariate time-variant\nstate space models. All functions can use exact diffuse\ninitialization when distributions of some or all elements of initial\nstate vector are unknown. Filtering, state smoothing and simulation\nfunctions use the sequential processing algorithm, which is faster\nthan standard approach, and also allows singularity of the\nprediction error variance matrix. By Jouni Helske.\n\nLLdecomp\n\nDecomposes a set of variables into cliques and separators depending\non their association which is measured using Random Forests. By\nCorinne Dahinden.\n\nMCMChybridGP\n\nHybrid Markov chain Monte Carlo using Gaussian Processes. Uses\nhybrid MCMC to simulate from a multimodal target distribution. A\nGaussian process approximation makes this possible when derivatives\nare unknown. Serves to minimize the number of function evaluations\nin Bayesian calibration of computer models using parallel tempering.\nAllows replacement of the true target distribution in high\ntemperature chains, or complete replacement of the target. Mark J.\nFielding.\n\nMLCM\n\nMaximum Likelihood Conjoint Measurement. Conjoint measurement is a\npsychophysical procedure in which stimulus pairs are presented that\nvary along 2 or more dimensions and the observer is required to\ncompare the stimuli along one of them. This package contains\nfunctions to estimate the contribution of the \\(n\\) scales to the\njudgment by a maximum likelihood method under several hypotheses of\nhow the perceptual dimensions interact. By Kenneth Knoblauch and\nLaurence T. Maloney.\n\nMMIX\n\nImplement different types of model mixing and model selection\nmethods for linear or logistic models. By Marie Morfin and David\nMakowski.\n\nNeatMap\n\nNon-clustered heatmap alternatives. Creates heatmap like plots in 2\nand 3 dimensions, without the need for cluster analysis. Like the\nheatmap, the plots created display both a dimensionally reduced\nrepresentation of the data as well as the data itself. They are\nintended to be used in conjunction with dimensional reduction\ntechniques such as PCA. By Satwik Rajaram and Yoshi Oono.\n\nORIClust\n\nOrder-restricted Information Criterion-based Clustering of genes.\nClusters are given by genes matched to prespecified profiles across\nvarious ordered treatment groups. Particularly useful for analyzing\ndata obtained from short time-course or dose-response microarray\nexperiments. By Tianqing Liu, Nan Lin, Ningzhong Shi and Baoxue\nZhang.\n\nOjaNP\n\nFunctions for the Oja median, Oja signs and ranks and methods based\nupon them. By Daniel Fischer, Jyrki Klaus Nordhausen and Daniel\nVogel.\n\nPCIT\n\nPartial Correlation Coefficient with Information Theory. Provides\nthe PCIT algorithm developed by Reverter and Chan (2008) which\nidentifies significant gene to gene associations to define edges in\na weighted network. By Nathan S. Watson-Haigh.\n\nPCS\n\nCalculate the probability of correct selection (PCS). Given \\(k\\)\npopulations (can be in thousands), what is the probability that a\ngiven subset of size \\(t\\) contains the true top \\(t\\) populations? This\npackage finds this probability and offers three tuning parameters\n(\\(G\\), \\(d\\), \\(L\\)) to relax the definition. By Jason Wilson.\n\nPLIS\n\nMultiplicity control using Pooled LIS (PLIS) statistics. PLIS is a\nmultiple testing procedure for testing several groups of hypotheses.\nLinear dependency is expected from the hypotheses within the same\ngroup and is modeled by hidden Markov Models. It is noted that, for\nPLIS, a smaller p value does not necessarily imply more significance\nbecause of dependency among the hypotheses. A typical application of\nPLIS is to analyze genome wide association studies datasets, where\nSNPs from the same chromosome are treated as a group and exhibit\nstrong linear genomic dependency. By Zhi Wei & Wenguang Sun.\n\nPearsonDS\n\nImplementation of the Pearson distribution system, including full\nsupport for the (d,p,q,r)-family of functions for probability\ndistributions and fitting via method of moments and maximum\nlikelihood method. By Martin Becker.\n\nQCA3\n\nFunctions for Qualitative Comparative Analysis (QCA). Can be used\nfor all three types of QCA. Has methods for simplifying assumption\nand contradictory simplifying assumption, and can return constrained\nresults by including or excluding specific conditions. By Ronggui\nHuang.\n\nR.filesets\n\nEasy handling of and access to files organized in structured\ndirectories. A file set refers to a set of files located in one or\nmore directories on the file system. This package provides classes\nand methods to locate, setup, subset, navigate and iterative over\nsuch sets. The API is designed such that these classes can be\nsubsetted to provide for instance a richer API for special file\nformats. By Henrik Bengtsson.\n\nR2PPT\n\nSimple R Interface to Microsoft PowerPoint using rcom. By Wayne\nJones.\n\nR2wd\n\nWrite MS-Word documents from R, using the statconnDCOM server to\ncommunicate with MS-Word via the COM interface. By Christian Ritter.\n\nRBerkeley\n\nInterface to Embedded Oracle Berkeley DB(tm). By Jeffrey A. Ryan.\n\nRC\n\nReproducible Computing. Allows the user to create and use\nreproducible computations for the purpose of research and education.\nThe meta data about the computations are stored in a remote\nrepository which is hosted at\nwww.freestatistics.org. By\nPatrick Wessa.\n\nREEMtree\n\nEstimates regression trees with random effects as a way to use data\nmining techniques to describe longitudinal or panel data. By Rebecca\nSela and Jeffrey Simonoff.\n\nRImageJ\n\nBindings between R and the ImageJ Java based image processing and\nanalysis platform. By Romain François and Philippe Grosjean.\n\nRInside\n\nC++ classes to embed R in C++ applications. By Dirk Eddelbuettel.\n\nRLastFM\n\nR interface to last.fm API. By Greg Hirson.\n\nRPMM\n\nRecursively Partitioned Mixture Model for Beta and Gaussian\nMixtures. This is a model-based clustering algorithm that returns a\nhierarchy of classes, similar to hierarchical clustering, but also\nsimilar to finite mixture models. By E. Andres Houseman.\n\nRSiena\n\nSimulation Investigation for Empirical Network Analysis. Fits models\nto longitudinal networks. By various authors.\n\nRassoc\n\nRobust tests for case-control genetic association studies: allelic\nbased test, Cochran-Armitage trend test, maximin efficiency robust\ntest, MAX3 test and genetic model selection test. By Yong Zang,\nWingkam Fung and Gang Zheng.\n\nRcmdrPlugin.DoE\n\nRcmdr plugin for (industrial) Design of Experiments. Currently in\nbeta status. By Ulrike\n\nRcmdrPlugin.qual\n\nAn Rcmdr plug-in based on the Quality control class Stat 4300. By\nErin Hodgess.\n\nReacTran\n\nRoutines for developing models that describe reaction and\nadvective-diffusive transport in one, two or three dimensions.\nIncludes transport routines in porous media, in estuaries, and in\nbodies with variable shape. By Karline Soetaert and Filip Meysman.\n\nReadImages\n\nFunctions for reading JPEG and PNG files, requiring libjpeg. By\nMarkus Loecher.\n\nRelativeRisk\n\nRelative risk estimation for prospective and retrospective data. By\nBob Wheeler.\n\nRmpfr\n\nR MPFR - Multiple Precision Floating-Point Reliable. Aims to provide\nS4 classes and methods for arithmetic including transcendental\n(“special”) functions for arbitrary precision floating point\nnumbers. To this end, it interfaces to the LGPL’ed MPFR (Multiple\nPrecision Floating-Point Reliable) Library which itself is based on\nthe GMP (GNU Multiple Precision) Library. By Martin Mächler.\n\nRniftilib\n\nR interface to nifticlib to read/write ANALYZE(TM)7.5/NIfTI-1 volume\nimages. By Oliver Granert.\n\nRthroughExcelWorkbooksInstaller\n\nWorkbooks in Excel that illustrate statistical concepts by accessing\nR functions from Excel. These workbooks use the automatic\nrecalculation mode of Excel to update calculations and graphs in R.\nDownloads an executable which installs the workbooks on MS Windows\nsystems where RExcel has already been installed. By Richard M.\nHeiberger and Erich Neuwirth.\n\nSAFD\n\nStatistical Analysis of Fuzzy Data. Aims to provide some basic\nfunctions for doing statistics with one dimensional fuzzy data (in\nthe form of polygonal fuzzy numbers). Contains functions for the\nbasic operations on the class of fuzzy numbers (sum, scalar product,\nmean, Hukuhara difference) as well as for calculating (Bertoluzza)\ndistance, sample variance, sample covariance, sample correlation,\nand the Dempster-Shafer (levelwise) histogram. Includes\nfunctionality to simulate fuzzy random variables, bootstrap tests\nfor the equality of means, and to do linear regression given\ntrapezoidal fuzzy data. By Wolfgang Trutschnig and Asun Lubiano.\n\nSEL\n\nSemiparametric elicitation. Implements a novel method for\ntransferring expert statements about an uncertain bounded quantity\ninto a probability distribution (see Bornkamp and Ickstadt (2009)\nfor a detailed description). For this purpose B-splines are used,\nand the density is obtained by penalized least squares, where the\npenalty encourages to distribute probability mass as uniformly as\npossible. Provides methods for fitting the expert’s distribution as\nwell as methods for evaluating the underlying density and cdf. In\naddition methods for plotting the expert’s distribution, drawing\nrandom numbers and calculating quantiles of the expert’s\ndistribution are provided. By Bornkamp.\n\nSHARE\n\nSNP-Haplotype Adaptive REgression (SHARE): an adaptive algorithm to\nselect the most informative set of SNPs for genetic association. By\nJames Y. Dai.\n\nSIS\n\n(Iterative) Sure Independence Screening for Generalized Linear\nModels and Cox’s Proportional Hazards models. By Jianqing Fan, Yang\nFeng, Richard Samworth and Yichao Wu.\n\nSWordInstaller\n\nSWord: Use R in Microsoft Word (Installer). Creating articles and\nreports in Word is easy. Adding R results (figures, tables,\nsummaries) requires manually copying the data from R to Word.\nChanging the data requires redoing the analyses in R and\nre-inserting the results into Word manually. SWord integrates R\nscripts and results into Word documents. Documents can be edited and\nread even without R installed (or without any knowledge of R). The\nfunctionality of embedding the scripts is somewhat similar to what\nSweave does for LaTeX documents. By Thomas Baier.\n\nSigWinR\n\nImplementation of the SigWin-detector for the detection of regions\nof increased or decreased gene expression (RIDGEs and anti-RIDGES)\nin transcriptome maps and the presentation in so called RIDGEOGRAMs\nas described by Marcia A. Inda et al. (2008). By Wim de Leeuw.\n\nTripleR\n\nSocial Relation Model (SRM) analyses for single round-robin groups.\nThese analyses are either based on one manifest variable, one latent\nconstruct measured by two manifest variables, two manifest variables\nand their bivariate relations, or two latent constructs each\nmeasured by two manifest variables (in the last case, four\nRound-Robin matrices have to be provided). By S.C. Schmukle, F.D.\nSchoenbrodt and M.D. Back.\n\nWMCapacity\n\nA GUI implementation of hierarchical Bayesian models of working\nmemory, used for analyzing change detection data. By Richard D.\nMorey.\n\nYieldCurve\n\nModeling and estimation of the yield curve, implementing the\nNelson-Siegel, Diebold-Li and Svensson models. Also includes the\ndata of the term structure of interest rate of Federal Reserve and\nEuropean Central Bank. By Sergio Salvino Guirreri.\n\naCGH.Spline\n\nRobust spline interpolation for dual color array comparative genomic\nhybridisation data. By Tomas William Fitzgerald.\n\nadaptTest\n\nAdaptive two-stage tests. Currently, four tests are included: Bauer\nand Koehne (1994), Lehmacher and Wassmer (1999), Vandemeulebroecke\n(2006), and the horizontal conditional error function. By Marc\nVandemeulebroecke.\n\namer\n\nFit generalized additive mixed models based on the mixed model\nalgorithm of lme4. By Fabian Scheipl.\n\nanchors\n\nStatistical analysis of surveys with anchoring vignettes. By\nJonathan Wand, Gary King, and Olivia Lau.\n\nant\n\nVersion of the ant apache build tool, with a few R specific tasks to\nease use of ant within an R package. By Romain François.\n\naroma.affymetrix\n\nAnalysis of large Affymetrix microarray data sets. Implements\nclasses for files and sets of files for various Affymetrix file\nformats, e.g., AffymetrixCdfFile, AffymetrixCelFile, and\nAffymetrixCelSet. These are designed to be memory efficient but\nstill being fast. The idea is to keep all data on file and only read\ndata into memory when needed. Clever caching mechanisms are used to\nminimize the overhead of data I/O. All of the above is hidden in the\npackage API and for the developer (and the end user), the data is\nqueried as if it lives in memory. With this design it is only the\ndiskspace that limits what number of arrays can be analyzed. By\nHenrik Bengtsson, Ken Simpson, Elizabeth Purdom, and Mark Robinson.\n\naroma.core\n\nPrivate support package for aroma.affymetrix et al., with the\npackage API still in alpha/beta. By Henrik Bengtsson.\n\natm\n\nCreation of additive models with semiparametric predictors,\nemphasizing term objects, especially (1) implementation of a term\nclass hierarchy, and (2) interpretation and evaluation of term\nestimates as functions of explanatories. By Charlotte Maia.\n\natmi\n\nAnalysis and usage of the trading rules, which are based on\ntechnical market indicators as well as on the time series analysis.\nBy Waldemar Kemler and Peter Schaffner.\n\nbclust\n\nBayesian clustering using spike-and-slab hierarchical model,\nsuitable for clustering high-dimensional data. Builds a dendrogram\nwith log posterior as a natural distance defined by the model. Can\nalso compute Bayesian discrimination probabilities equivalent to the\nimplemented Bayesian clustering. Spike-and-Slab models are adopted\nin a way to be able to produce an importance measure for clustering\nand discriminant variables. The method works properly for data with\nsmall sample size and high dimensions. The model parameter\nestimation maybe difficult, depending on data structure and the\nchosen distribution family. By Vahid Partovi Nia and Anthony C.\nDavison.\n\nbcv\n\nCross-Validation for the SVD (Bi-Cross-Validation). This package\nimplements methods for choosing the rank of an SVD approximation via\ncross validation. It provides both Gabriel-style “block” holdouts\nand Wold-style “speckled” holdouts. Also included is an\nimplementation of the SVDImpute algorithm. See Owen & Perry’s 2009\nAOAS article (http://arxiv.org/abs/0908.2062) and Perry’s 2009 PhD\nthesis (http://arxiv.org/abs/0909.3052) for more information about\nBi-crossvalidation. By Patrick O. Perry.\n\nbdoc\n\nBayesian Discrete Ordered Classification of DNA Barcodes. By Michael\nAnderson.\n\nbdsmatrix\n\nRoutines for Block Diagonal Symmetric matrices, a special case of\nsparse matrices, used by coxme and kinship. By Terry Therneau.\n\nbestglm\n\nBest subset GLM using AIC, BIC, EBIC, BICq or Cross-Validation. For\nthe normal case, the “leaps” is used; otherwise, a slower exhaustive\nsearch. By A.I. McLeod and Changjiang Xu.\n\nbinomSamSize\n\nConfidence intervals and sample size determination for a binomial\nproportion under simple random sampling and pooled sampling. Such\ncomputations are e.g. of interest when investigating the incidence\nor prevalence in populations. Contains functions to compute coverage\nprobabilities and coverage coefficients of the provided confidence\nintervals procedures. Sample size calculations are based on expected\nlength. By Michael with contributions by Wei Liu.\n\nbootRes\n\nCalculation of bootstrapped response and correlation functions for\nuse in dendroclimatology. By Christian Zang.\n\nbvpSolve\n\nSolvers for boundary value problems (BVPs) of systems of ordinary\ndifferential equations (ODEs) via an interface to the FORTRAN\nfunction twpbvp and an R implementation of the shooting method. By\nKarline Soetaert.\n\ncaGUI\n\nA Tcl/Tk GUI for computation and visualization of simple, multiple\nand joint correspondence analysis with the ca package. By Angelos\nMarkos.\n\ncaroline\n\nA collection of functions useful for various general situations. By\nDavid M. Schruth.\n\ncimis\n\nA set of functions for retrieving data from CIMIS, the California\nIrrigation Management Information System. By Greg Hirson.\n\ncmm\n\nCategorical Marginal Models: Quite extensive package for the\nestimation of marginal models for categorical data. By Wicher\nBergsma and Andries van der Ark.\n\ncmprskContin\n\nEstimation and testing of continuous mark-specific relative risks in\ntwo groups as described in Gilbert, McKeague & Sun (2008).\nImplements the methods presented in the paper for testing\nmark-specific hazards ratios and for estimation of mark-specific\nincidence ratios that are cumulative in time or cumulative in both\ntime and the continuous mark. By Peter Gilbert, Ian McKeague, and\nYanqing Sun.\n\ncmrutils\n\nA collection of useful helper routines developed by students of the\nCenter for the Mathematical Research, Stankin, Moscow. By Andrey\nParamonov.\n\ncolbycol\n\nRead big text files column by column: tries to solve the memory\nrestrictions posed by such files by breaking them into columns which\nare subsequently read individually into R. By Carlos J. Gil\nBellosta.\n\ncondGEE\n\nSolves for the mean parameters, the variance parameter, and their\nasymptotic variance in a conditional GEE for recurrent event gap\ntimes, as described by Clement and Strawderman (2009). Makes a\nparametric assumption for the length of the censored gap time. By\nDavid Clement.\n\ncountrycode\n\nCreate and manipulate data frames that contain country names or\ncountry coding schemes. Standardizes country names, converts them\ninto one of seven coding schemes, assigns region descriptors, and\ngenerates empty dyadic or country-year dataframes from the coding\nschemes. By Vincent Arel-Bundock.\n\ncoxme\n\nMixed Effects Cox Models: Cox proportional hazards models containing\nGaussian random effects, also known as frailty models. By Terry\nTherneau.\n\ncrantastic\n\nVarious R tools for http://crantastic.org/. By Bjørn Arild\nMaeland.\n\ncshapes\n\nPackage for CShapes, a GIS dataset of country boundaries\n(1946–2008). Includes functions for data extraction and the\ncomputation of weights matrices. By Nils B. Weidmann, Doreen Kuse,\nand Kristian Skrede Gleditsch.\n\ncudaBayesreg\n\nCUDA Parallel Implementation of a Bayesian Multilevel Model for fMRI\nData Analysis. Compute Unified Device Architecture (CUDA) is a\nsoftware platform for massively parallel high-performance computing\non NVIDIA GPUs. This package provides a CUDA implementation of a\nBayesian multilevel model for the analysis of brain fMRI data. By\nAdelino Ferreira da Silva.\n\ndcemri\n\nA collection of routines and documentation that allows one to\nperform a quantitative analysis of dynamic contrast-enhanced or\ndiffusion-weighted MRI data. Medical imaging data should be\norganized using either the Analyze or NIfTI data formats. By Brandon\nWhitcher and Volker Schmid, with contributions from Andrew Thornton.\n\ndescr\n\nDescriptive statistics: functions to describe weighted categorical\nvariables and functions to facilitate the character encoding\nconversion of objects. By Jakson Aquino. Includes R source code\nand/or documentation written by Dirk Enzmann, Marc Schwartz, and\nNitin Jain.\n\ndesire\n\nHarrington and Derringer-Suich type desirability functions. By Heike\nTrautmann and Detlef Steuer and Olaf Mersmann.\n\ndifR\n\nSome traditional methods to detect dichotomous differential item\nfunctioning (DIF) in psychometrics. Both uniform and non-uniform DIF\neffects can be detected, with methods relying upon item response\nmodels or not. Some methods deal with more than one focal group. By\nSébastien Béland, David Magis and Gilles Raîche.\n\ndigeR\n\nAn easy to use Graphical User Interface for spots correlation\nanalysis, score plot, classification, feature selection and power\nanalysis for 2D DIGE experiment data. By Yue Fan, Thomas Brendan\nMurphy, and R. William G. Watson.\n\ndirmult\n\nEstimate parameters in Dirichlet-Multinomial and compute profile\nlog-likelihoods. By Torben Tvedebrink.\n\ndlnm\n\nDistributed Lag Non-linear Models. Contains functions to specify\nbasis and cross-basis matrices in order to run distributed lag\nmodels and their non-linear extension, then to predict and graph the\nresults for a fitted model. By Antonio Gasparrini and Ben Armstrong.\n\ndoMC\n\nProvides a parallel backend for the foreach %dopar% function\nusing Simon Urbanek’s multicore package. By REvolution Computing.\n\ndoSNOW\n\nProvides a parallel backend for the foreach %dopar% function\nusing Luke Tierney’s snow package. By REvolution Computing.\n\ndummies\n\nExpands factors, characters and other eligible classes into\ndummy/indicator variables. By Christopher Brown.\n\ndynGraph\n\nInteractive visualization of dataframes and factorial planes. By\nJulien Durand, Sébastien Lê.\n\nel.convex\n\nEmpirical likelihood ratio tests for means. By Dan Yang, Dylan\nSmall.\n\nendogMNP\n\nFits a Bayesian multinomial probit model with endogenous selection,\nwhich is sometimes called an endogenous switching model. This can be\nused to model discrete choice data when respondents select\nthemselves into one of several groups. This package is based on the\nMNP package by Kosuke Imai and David A. van Dyk. By Lane F.\nBurgette.\n\nestout\n\nEstimates Output: stores the estimates of several models, and\nformats these to a table of the form estimate starred and standard\nerror. below. Default output is LaTeX but output to CSV for later\nediting in a spreadsheet tool is possible as well. Works for linear\nmodels and panel models from package plm. By Felix Kaminsky.\n\nexact2x2\n\nExact Conditional Tests and Confidence Intervals for \\(2 \\times 2\\)\ntables. Calculates Fisher’s exact and Blaker’s exact tests. By M.P.\nFay.\n\nfarmR\n\nA mixed integer description of an arable farm. Finds optimal farming\nplans given economic and social preference information. By Ira R.\nCooke.\n\nfds\n\nFunctional data sets. By Han Lin Shang and Rob J Hyndman.\n\nflsa\n\nPath algorithm for the general Fused Lasso Signal Approximator. By\nHolger\n\nflubase\n\nEstimates the baseline of mortality free of influenza epidemics, and\nthe respective excess deaths, for more than one time series (age\ngroups, gender, regions, etc.). By Nunes B, Natario I and Carvalho\nL.\n\nforeach\n\nSupport for the foreach looping construct. Foreach is an idiom that\nallows for iterating over elements in a collection, without the use\nof an explicit loop counter. Intended to be used for its return\nvalue, rather than for its side effects. Using foreach without\nside effects also facilitates executing the loop in parallel. By\nREvolution Computing.\n\nfractalrock\n\nGenerate fractal time series with non-normal returns distribution.\nThe basic principle driving fractal generation of time series is\nthat data is generated iteratively based on increasing levels of\nresolution. The initial series is defined by a so-called initiator\npattern and then generators are used to replace each segment of the\ninitial pattern. Regular, repeatable patterns can be produced by\nusing the same seed and generators. By using a set of generators,\nnon-repeatable time series can be produced. This technique is the\nbasis of the fractal time series process in this package. By Brian\nLee Yung Rowe.\n\nfrbf\n\nImplementation of the “Flexible kernels for RBF network” algorithm.\nBy Fernando Martins.\n\nfreqMAP\n\nEstimates a frequency Moving Average Plot (MAP) from multinomial\ndata and a continuous covariate. The frequency MAP is a moving\naverage estimate of category frequencies, where frequency means and\nposterior bounds are estimated. Comparisons of two frequency MAPs as\nwell as odds ratios can be plotted. By Colin McCulloch.\n\nftsa\n\nFunctional time series analysis. By Rob J Hyndman and Han Lin Shang.\n\ngPdtest\n\nComputes the bootstrap goodness-of-fit test for the generalized\nPareto distribution proposed by Villaseñor-Alva and González-Estrada\n(2009). The null hypothesis includes heavy and non-heavy tailded\ngPd’s. Also provides functionality for fitting the gPd to data using\nthe parameter estimation methods proposed in the same article. By\nElizabeth González Estrada, José A. Villaseñor Alva.\n\ngRapHD\n\nEfficient selection of undirected graphical models for\nhigh-dimensional datasets. Provides tools for selecting trees,\nforests and decomposable models minimizing information criteria such\nas AIC or BIC, and for displaying the independence graphs of the\nmodels. Also some useful tools for analyzing graphical structures.\nIt supports the use of discrete, continuous, or both types of\nvariables. By Gabriel Coelho Goncalves de Abreu, Rodrigo Labouriau,\nand David Edwards.\n\ngamesNws\n\nPlaying games using a NWS Server. Allows playing different card\ngames (e.g. uno, poker, …) using an NWS Server as the card table.\nBy Markus Schmidberger and Fabian Grandke.\n\ngamlss.data\n\nData for GAMLSS models. By Mikis Stasinopoulos and Bob Rigby.\n\ngamm4\n\nFit generalized additive mixed models via a version of mgcv’s\ngamm() function, using lme4 for estimation via Fabian Scheipl’s\ntrick. By Simon Wood.\n\ngausspred\n\nPredict the discrete response based on selected high dimensional\nfeatures, such as gene expression data. The data are modeled with\nBayesian Gaussian models. When a large number of features are\navailable, one may like to select only a subset of features to use,\ntypically those features strongly correlated with the response in\ntraining cases. Such a feature selection procedure is however\ninvalid since the relationship between the response and the features\nwill appear stronger. This package provides a way to avoid this bias\nand yields well-calibrated prediction for the test cases when one\nuses F-statistic to select features. By Longhai Li.\n\ngeneARMA\n\nSimulate, model, and display data from a time-course microarray\nexperiment with periodic gene expression. Fits models in a normal\nmixture model framework with mean approximated by a truncated\nFourier series and covariance structure modeled by an ARMA\\((p,q)\\)\nprocess. Estimation is performed with the EM algorithm. By Timothy\nMcMurry and Arthur Berg.\n\ngeneListPie\n\nMap a gene list to function categories defined in GOSlim or Kegg.\nThe results can be plotted as a pie chart to provide a quick view of\nthe distribution of the gene list among the function categories. By\nXutao Deng.\n\nglmdm\n\nSimulation of GLMDM. By Jeff Gill, George Casella, Minjung Kyung and\nJonathan Rapkin.\n\nglmperm\n\nA permutation test for inference in generalized linear models.\nUseful when parameter estimates in ordinary GLMs fail to converge or\nare unreliable due to small sample size. By Wiebke Werft and\nDouglas M. Potter.\n\nglmulti\n\nGLM model selection and multimodel inference made easy: automated\nmodel selection for GLMs. Provides a wrapper for glm() and similar\nfunctions, automatically generating all possible models (under\nconstraints set by the user) with the specified response and\nexplanatory variables, and finding the best models in terms of some\nInformation Criterion (AIC, AICc or BIC). Can handle very large\nnumbers of candidate models. Features a Genetic Algorithm to find\nthe best models when an exhaustive screening of the candidates is\nnot feasible. By Vincent Calcagno.\n\ngnumeric\n\nRead data from files readable by gnumeric. Can read a whole sheet or\na range, from several file formats, including the native format of\ngnumeric. Reading is done by using ssconvert (a file converter\nutility included in the gnumeric distribution\nhttp://projects.gnome.org/gnumeric/) to convert the requested part\nto CSV. By Karoly Antal.\n\ngsDesign\n\nDerive group sequential designs and describe their properties. By\nKeaven Anderson.\n\niGenomicViewer\n\nTool for sending interactive bioinformatic heatmaps with tool-tip\ncontent. By Daniel P Gaile, Lori A. Shepherd, Lara Sucheston, Andrew\nBruno, and Kenneth F. Manly.\n\ninfotheo\n\nImplements various measures of information theory based on several\nentropy estimators. By Patrick E. Meyer.\n\ninlinedocs\n\nConvert inline comments to documentation. Generates Rd files from R\nsource code with comments, providing for quick, sustainable package\ndevelopment. The syntax keeps code and documentation close together,\nand is inspired by the Don’t Repeat Yourself principle. By Toby\nDylan Hocking.\n\nintamap\n\nClasses and methods for automated spatial interpolation. By Edzer\nPebesma, Jon Skøien and others.\n\nintegrOmics\n\nIntegrate Omics data project. Supplies two efficient methodologies,\nregularized CCA and sparse PLS, to unravel relationships between two\nheterogeneous data sets of size \\(n \\times p\\) and \\(n \\times q\\) where\nthe \\(p\\) and \\(q\\) variables are measured on the same samples or\nindividuals \\(n\\). These data may come from high throughput\ntechnologies, such as omics data (e.g., transcriptomics,\nmetabolomics or proteomics data) that require an integrative or\njoint analysis. However, integrOmics can also be applied to any\nother large data sets where \\(p+q \\gg n\\). rCCA is a regularized\nversion of CCA to deal with the large number of variables. sPLS\nallows variable selection in a one step procedure and two frameworks\nare proposed: regression and canonical analysis. Numerous graphical\noutputs are provided to help interpreting the results. By Sébastien\nDejean, Ignacio González and Kim-Anh Lê Cao.\n\nintegrativeME\n\nintegrative mixture of experts. Mixture of experts models (Jacobs et\nal., 1991) were introduced to account for nonlinearities and other\ncomplexities in the data, and are of interest due to their wide\napplicability and the advantages of fast learning via the\nexpectation-maximization (EM) algorithm. The package features an ME\nextension to combine categorical clinical factors and continuous\nmicroarray data in a binary classification framework to analyze\ncancer studies. By Kim-Anh Lê Cao.\n\ninterval\n\nWeighted Logrank Tests and NPMLE for interval censored data. By\nMichael P. Fay.\n\nisa2\n\nThe Iterative Signature Algorithm (ISA), a biclustering algorithm\nthat finds modules in an input matrix. A module or bicluster is a\nblock of the reordered input matrix. By Gábor Csárdi.\n\niterators\n\nIterator construct for R. Iterators allow a programmer to traverse\nthrough all the elements of a vector, list, or other collection of\ndata. By REvolution Computing.\n\nkmi\n\nKaplan-Meier multiple imputation to recover the missing potential\ncensoring information from competing risks events, so that standard\nright-censored methods could be applied to the imputed data sets to\nperform analyses of the cumulative incidence functions. By Arthur\nAllignol.\n\nlatdiag\n\nWrites a file of commands for the dot program to draw a graph\nproposed by Rosenbaum and useful for checking some properties of\nvarious sorts of latent scale. By Michael Dewey.\n\nlatticedl\n\nDirect labeling functions that use the lattice package. By Toby\nDylan Hocking.\n\nlda\n\nCollapsed Gibbs sampling methods for topic models. Implements Latent\nDirichlet allocation (LDA) and related models, including (but not\nlimited to) sLDA, corrLDA, and the mixed-membership stochastic\nblockmodel. Inference for all of these models is implemented via a\nfast collapsed Gibbs sampler written in C. Utility functions for\nreading/writing data typically used in topic models, as well as\ntools for examining posterior distributions are also included. By\nJonathan Chang.\n\nlemma\n\nLaplace approximated EM Microarray Analysis. LEMMA is used to detect\n“nonnull genes” — genes for which the average response in\ntreatment group 1 is significantly different from the average\nresponse in group 2, in normalized microarray data. LEMMA is an\nimplementation of an approximate EM algorithm to estimate the\nparameters in the assumed linear model in Bar, Booth, Schifano,\nWells (2009). By Haim Bar and Elizabeth Schifano.\n\nlongitudinalData\n\nTools for Longitudinal Data. By Christophe Genolini.\n\nlordif\n\nLOgistic Regression Differential Item Functioning (DIF) using Item\nResponse Theory (IRT): analysis of DIF for dichotomous and\npolytomous items using an iterative hybrid of (ordinal) logistic\nregression and IRT. By Seung W. Choi, with contributions from\nLaura E. Gibbons and Paul K. Crane.\n\nmar1s\n\nMultiplicative AR(1) with Seasonal Processes, a stochastic process\nmodel built on top of AR(1). Provides the following procedures for\nMAR(1)S processes: fit, compose, decompose, advanced simulate and\npredict. By Andrey Paramonov.\n\nmarelacTeaching\n\nDatasets and tutorials for use in the MArine, Riverine, Estuarine,\nLAcustrine and Coastal sciences. By Karline Soetaert, Thomas\nPetzoldt, and Filip Meysman.\n\nmaticce\n\nMApping Transitions In Continuous Character Evolution. Tools for an\ninformation-theoretic approach to estimating the probability of\ncontinuous character transitions on phylogenetic trees. By Andrew\nHipp, with contributions from Marcial Escudero.\n\nmatrixStats\n\nMethods that apply to rows and columns of a matrix. Methods are\noptimized for speed and memory. Currently in a beta phase. By Henrik\nBengtsson (partly by Robert Gentleman).\n\nmcclust\n\nMethods for processing a sample of (hard) clusterings, e.g., the\nMCMC output of a Bayesian clustering model. Includes methods that\nfind a single best clustering to represent the sample, which are\nbased on the posterior similarity matrix or a relabeling algorithm.\nBy Arno Fritsch.\n\nmediation\n\nParametric and nonparametric causal mediation analysis. Implements\nthe methods and suggestions in Imai, Keele, and Yamamoto (2008) and\nImai, Keele, Tingley (2009). In addition to the estimation of causal\nmediation effects, allows researchers to conduct sensitivity\nanalysis for certain parametric models. By Luke Keele, Dustin\nTingley, Teppei Yamamoto, Kosuke Imai.\n\nmetafor\n\nA collection of functions for conducting meta-analyses in R. Fixed-\nand random-effects models (with and without moderators) can be\nfitted via the general linear (mixed-effects) model. For\n\\(2 \\times 2\\) table data, the Mantel-Haenszel and Peto’s method are\nalso implemented. By Wolfgang Viechtbauer.\n\nmixfdr\n\nFits normal mixture models to data and uses them to compute effect\nsize estimates and local and tail area false discovery rates. To\nmake this precise, suppose you have many normally distributed \\(z\\)s,\nand each \\(z_i\\) has mean \\(\\delta_i\\). This package will estimate\n\\(\\delta_i\\) based on the \\(z\\)s (effect sizes), \\(P(\\delta_i=0|z_i)\\)\n(local false discovery rates) and \\(P(\\delta_i=0\\;|\\;|z_i|>z)\\) (tail\narea false discovery rates). By Omkar Muralidharan, with many\nsuggestions from Bradley Efron.\n\nmodTempEff\n\nModeling temperature effects using time series data. Fits a\nconstrained segmented distributed lag regression model to\nepidemiological time series of mortality, temperature, and other\nconfounders. By Vito M. R. Muggeo.\n\nmrt\n\nDatasets and functions from Wright and London’s Modern Regression\nTechniques. By Daniel B. Wright.\n\nmstate\n\nFunctions for data preparation, descriptives, hazard estimation and\nprediction with Aalen-Johansen or simulation in competing risks and\nmulti-state models. By Hein Putter, Liesbeth de Wreede, and Marta\nFiocco.\n\nmuRL\n\nMailmerge using R, LaTeX, and the Web. Provides mailmerge methods\nfor reading spreadsheets of addresses and other relevant information\nto create standardized but customizable letters. Provides a method\nfor mapping US ZIP codes, including those of letter recipients.\nProvides a method for parsing and processing HTML code\nfrom online job postings of the American Political Science\nAssociation. By Ryan T. Moore and Andrew Reeves.\n\nmultmod\n\nTesting of multiple outcomes using i.i.d. decompositions. By\nChristian B. Pipper, Christian Ritz.\n\nmunsell\n\nFunctions for exploring and using the Munsell colour system. By\nCharlotte Wickham.\n\nmvShapiroTest\n\nGeneralized Shapiro-Wilk test for multivariate normality as proposed\nby Villaseñor-Alva and González-Estrada (2009). By Elizabeth\nGonzález Estrada and José A. Villaseñor Alva.\n\nmvsf\n\nMultivariate generalization of the Shapiro-Francia test for\nnormality. By David Delmail.\n\nnbpMatching\n\nFunctions for non-bipartite optimal matching. By Bo Lu, Robert\nGreevy, Cole Beck.\n\nnnclust\n\nNearest-neighbor tools for clustering. Finds nearest neighbors and\nthe minimum spanning tree (MST) for large data sets, and does\nclustering using the MST. By Thomas Lumley.\n\nnodeHarvest\n\nCompute and visualize the Node Harvest estimator. Node harvest is a\nsimple interpretable tree-like estimator for high-dimensional\nregression and classification. A few nodes are selected from an\ninitially large ensemble of nodes, each associated with a positive\nweight. New observations can fall into one or several nodes and\npredictions are the weighted average response across all these\ngroups. By Nicolai Meinshausen.\n\nnparLD\n\nNonparametric Analysis of Longitudinal Data in Factorial\nExperiments. By Kimihiro Noguchi, Mahbub Latif, Karthinathan\nThangavelu, Frank Konietschke, Yulia R. Gel, and Edgar Brunner.\n\noblique.tree\n\nGrows oblique trees to classification data. By Alfred Truong.\n\nodfWeave.survey\n\nodfWeave support for the survey package. By Thomas Lumley.\n\noosp\n\nObject Oriented Statistical Programming. Support for OOSP,\nespecially by extending S3 capabilities, providing pointer and\ncomponent objects, and providing basic support for symbolic-numeric\nstatistical programming. By Charlotte Maia.\n\noptBiomarker\n\nEstimation of optimal number of biomarkers for two-group microarray\nbased classifications at a given error tolerance level for various\nclassification rules. By Mizanur Khondoker.\n\np3state.msm\n\nAnalyzing survival data from illness-death models. By Luís\nMeira-Machado and Javier Roca-Pardiñas.\n\npackS4\n\nToy example of an S4 package, to illustrate the book “Petit Manuel\nde Programmation Orientee Objet sous R”. By Christophe Genolini.\n\npackdep\n\nElucidates the dependencies between user-contributed R packages and\nidentifies key packages according to social network analysis\nmetrics. By Radhakrishnan Nagarajan and Marco Scutari.\n\npamm\n\nSimulation functions to assess or explore the power of a dataset to\nestimate significant random effects (intercept or slope) in a mixed\nmodel. Based on the lme4 package. By Julien Martin.\n\nparser\n\nDetailed source code parser, based on the standard R parser but\norganizing the information differently. By Romain François.\n\npedigreemm\n\nFit pedigree-based mixed-effects models. By Douglas Bates and Ana\nInes Vazquez.\n\npegas\n\nPopulation and Evolutionary Genetics Analysis System. Provides\nfunctions for reading, writing, plotting, analysing, and\nmanipulating allelic data, and for the analysis of population\nnucleotide sequences including coalescence analyses. By Emmanuel\nParadis.\n\npendensity\n\nEstimation of penalized (conditional) densities. By Christian\nSchellhase.\n\nperm\n\nExact or Asymptotic permutation tests. By Michael Fay.\n\npgs\n\nPrecision of Geometric Sampling. Computes mean squared errors of\nstereological predictors. By Kien Kieu and Marianne Mora.\n\nphull\n\nComputes the p-hull of a finite planar set, which is a\ngeneralization of the convex hull, X-Y hull and bounding rectangle.\nA fast, \\(O(n \\log n)\\) Graham-scan based routine is used. By Marek\nGagolewski.\n\nphybase\n\nBasic functions for phylogenetic analysis. Provides functions to\nread, write, manipulate, estimate, and summarize phylogenetic trees\nincluding species trees which contain not only the topology and\nbranch lengths but also population sizes. The input/output functions\ncan read tree files in which trees are presented in parenthetic\nformat. The trees are read in as a string and then transformed to a\nmatrix which describes the relationship of nodes and branch lengths.\nThe nodes matrix provides an easy access for developers to further\nmanipulate the tree, while the tree string provides interface with\nother phylogenetic R packages such as ape. The input/output\nfunctions can also be used to change the format of tree files\nbetween NEXUS and PHYLIP. Some basic functions have already been\nestablished in the package for manipulating trees such as deleting\nand swapping nodes, rooting and unrooting trees, changing the root\nof the tree. The package also includes functions for summarizing\nphylogenetic trees, calculating the coalescence time, population\nsize, and tree distance, and to estimate the species tree from\nmultiple gene trees. By Liang Liu.\n\nplus\n\nPenalized Linear Unbiased Selection. Efficient procedures for\nfitting an entire regression sequences with different model types.\nBy Cun-Hui Zhang and Ofer Melnik.\n\npooh\n\nPartial Orders and Relations: functions for computing closures of\nrelations. By Charles J. Geyer.\n\npotts\n\nMarkov Chain Monte Carlo for Potts Models. By Charles J. Geyer.\n\npsgp\n\nProjected Spatial Gaussian Process methods for package intamap. By\nBen Ingram and Remi Barillec.\n\nrWMBAT\n\nThe William and Mary Bayesian Analysis Tool. By Karl Kuschner, Qian\nSi and William Cooke, College of William and Mary.\n\nrainbow\n\nRainbow plots, bagplots and boxplots for functional data. By Han Lin\nShang and Rob J Hyndman.\n\nrankhazard\n\nRank-hazard plots (Karvanen and Harrell, Statistics in\nMedicine, 2009) which visualize the relative importance of\ncovariates in a proportional hazards model. The key idea is to rank\nthe covariate values and plot the relative hazard as a function of\nranks scaled to interval \\([0,1]\\). The relative hazard is plotted\nwith respect to the reference hazard, which can be e.g. the hazard\nrelated to the median of the covariate. Transformation to scaled\nranks allows plotting of covariates measured in different units in\nthe same graph, which helps in the interpretation of the\nepidemiological relevance of the covariates. Rank-hazard plots show\nthe difference of hazards between the extremes of the covariate\nvalues present in the data and can be used as a tool to check if the\nproportional hazards assumption leads to reasonable estimates for\nindividuals with extreme covariate values. Alternative covariate\ndefinitions or different transformations applied to covariates can\nbe also compared using rank-hazard plots. By Juha Karvanen.\n\nringscale\n\nImplementation of the “Ringscale” method as proposed in the student\nresearch project “Detection of faint companions around young stars\nin speckle patterns of VLT/NACO cube mode images by means of\npost-processing” at the Friedrich-Schiller-University of Jena. By\nDaniel Haase.\n\nrioja\n\nAnalysis of Quaternary science data, including constrained\nclustering, WA, WAPLS, IKFA, MLRC and MAT transfer functions, and\nstratigraphic diagrams. By Steve Juggins.\n\nripa\n\nR Image Processing and Analysis. Makes it possible to process and\nanalyze RGB, LAN (multispectral) and AVIRIS (hyperspectral) images.\nBy Talita Perciano, with contributions from Alejandro C Frery.\n\nrms\n\nRegression Modeling Strategies: regression modeling, testing,\nestimation, validation, graphics, prediction, and typesetting by\nstoring enhanced model design attributes in the fit. A collection of\nabout 225 functions that assist with and streamline modeling. Also\ncontains functions for binary and ordinal logistic regression models\nand the Buckley-James multiple regression model for right-censored\nresponses, and implements penalized maximum likelihood estimation\nfor logistic and ordinary linear models. rms works with almost any\nregression model, but it was especially written to work with binary\nor ordinal logistic regression, Cox regression, accelerated failure\ntime models, ordinary linear models, the Buckley-James model,\ngeneralized least squares for serially or spatially correlated\nobservations, generalized linear models, and quantile regression. By\nFrank E Harrell Jr.\n\nrobustX\n\neXperimental eXtraneous eXtraordinary functionality for Robust\nStatistics. By Werner Stahel, Martin Mächler and potentially others.\n\nrpartOrdinal\n\nFunctions that can be called in conjunction with rpart for\nderiving a classification tree when the response to be predicted is\nordinal. By Kellie J. Archer.\n\nrrv\n\nRandom Return Variables. Currently provides limited support for\nformatting money. By Charlotte Maia.\n\nsBF\n\nSmooth Backfitting for additive models using Nadaraya-Watson\nestimator. By A. Arcagni, L. Bagnato.\n\nsafeBinaryRegression\n\nSafe Binary Regression. Overloads the glm() function in the\nstats package so that a test for the existence of the maximum\nlikelihood estimate is included in the fitting procedure for binary\nregression models. By Kjell Konis.\n\nsculpt3d\n\nA simple toolbar GUI for brushing RGL plots. Controls for simple\nbrushing, highlighting, labeling, and mouseMode changes are provided\nby point-and-click rather than through the R terminal interface. By\nJustin Donaldson.\n\nsddpack\n\nSemidiscrete Decomposition (SDD), which approximates a matrix as a\nweighted sum of outer products formed by vectors with entries\nconstrained to be in the set \\(\\{-1, 0, 1\\}\\). By Tamara G. Kolda and\nDianne P. O’Leary.\n\nsdef\n\nSynthesizing list of Differentially Expressed Features. Performs two\ntests to evaluate if experiments are associated and returns a list\nof interesting features common to all the experiments. By Alberto\nCassese and Marta Blangiardo.\n\nseason\n\nRoutines for the seasonal analysis of health data, including\nregression models, time-stratified case-crossover, plotting\nfunctions and residual checks. By Adrian Barnett and Peter Baker.\n\nsendmailR\n\nA simple SMTP client which provides a portable solution for sending\nemails from within R. By Olaf Mersmann.\n\nsimFrame\n\nA general framework for statistical simulation. By Andreas Alfons.\n\nsimctest\n\nSequential (or Safe) Implementation of Monte Carlo tests with\nuniformly bounded resampling risk. Features efficient computation of\np-values for Monte Carlo tests, e.g., bootstrap tests. By Axel\nGandy.\n\nskellam\n\nFunctions for the Skellam distribution, including: pmf, cdf,\nquantiles and random variates. By Jerry W. Lewis.\n\nskmeans\n\nAlgorithms to compute spherical \\(k\\)-means partitions. Features\nseveral methods, including a genetic and a simple fixed-point\nalgorithm and an interface to the CLUTO vcluster program. By Kurt\nHornik, Ingo Feinerer and Martin Kober.\n\nslam\n\nSparse Lightweight Arrays and Matrices. Data structures and\nalgorithms for sparse arrays and matrices, based on index arrays and\nsimple triplet representations, respectively. By Kurt Hornik, David\nMeyer, and Christian Buchta.\n\nsos\n\nR related Search Engines. By Spencer Graves, Sundar Dorai-Raj, and\nRomain François.\n\nspatcounts\n\nFit spatial CAR count regression models using MCMC. By Holger\nSchabenberger.\n\nspeedglm\n\nFitting LMs and GLMs to large data sets by updating algorithms. By\nMarco ENEA.\n\nspeff2trial\n\nSemiparametric efficient estimation for a two-sample treatment\neffect: performs estimation and testing of the treatment effect in a\n2-group randomized clinical trial with a quantitative or dichotomous\nendpoint. The method is a special case of Robins, Rotnitzky, and\nZhao (1994, JASA). It improves efficiency by leveraging baseline\npredictors of the endpoint. The method uses inverse probability\nweighting to provide unbiased estimation when the endpoint is\nmissing at random. By Michal Juraska, with contributions from\nPeter B. Gilbert, Min Zhang, Marie Davidian, Anastasios A. Tsiatis\nand Xiaomin Lu.\n\nstringkernels\n\nGapped and word-based string kernels for use with kernlab. By\nMartin Kober.\n\nsublogo\n\nVisualize correlation in biological sequence data using sublogo\ndendrogram plots. By Toby Dylan Hocking.\n\nsugaR\n\nPlots to help optimizing diabetes therapy. Provides a series of\nplots to integrate glucose levels, basal rate, activities, events\nand carbohydrate uptake on a single page in a humanely interpretable\nmanner. It is meant for best-possibly representing the content of a\nwell-curated diabetes diary of up to a week’s time or of up to seven\ncomparable days, from which conclusions for adjusting the individual\ntreatment shall be drawn. By Steffen\n\nsvDialogs\n\nSciViews GUI API: dialog boxes. Rapidly\nconstruct dialog boxes for your GUI, including an\nautomatic function assistant. By Philippe Grosjean.\n\nsvSweave\n\nSciViews GUI API: Sweave support\nfunctions. By Philippe Grosjean.\n\nsvTools\n\nSciViews GUI API: tools, aimed at\nwrapping some of the functionalities of the packages tools,\nutils and codetools into a nicer format so that an\nIDE can use them. By Romain François.\n\nsvUnit\n\nSciViews GUI API: unit testing. A\ncomplete unit test system and functions to implement its\nGUI part. By Philippe Grosjean.\n\nsvWidgets\n\nSciViews GUI API: widgets & windows.\nHigh level management of widgets, windows and other graphical\nresources. By Philippe Grosjean.\n\ntextcat\n\nN-Gram based text categorization. By Kurt Hornik, Johannes Rauch,\nChristian Buchta, and Ingo Feinerer.\n\ntikzDevice\n\nA device for R graphics output in PGF/TikZ format. Enables\nLaTeX-ready output from R graphics functions, with LaTeX mathematics\nthat can be typeset directly into labels and annotations. Graphics\nproduced this way can also be annotated with custom TikZ commands.\nBy Charlie Sharpsteen and Cameron Bracken.\n\ntm.plugin.mail\n\nA plug-in for the tm text mining framework providing mail handling\nfunctionality. By Ingo Feinerer.\n\ntnet\n\nAnalysis of Weighted, Two-mode, and Longitudinal networks. By Tore\nOpsahl.\n\ntolerance\n\nFunctions for calculating tolerance intervals. Tolerance limits\nprovide the limits between which we can expect to find a specified\nproportion of a population with a given level of confidence.\nProvides functions for estimating tolerance limits for various\ndistributions, and plotting tolerance limits of continuous random\nvariables. By Derek S. Young.\n\ntractor.base\n\nBasic functions for the TractoR (tractography with R) bundle.\nConsists of functions for working with magnetic resonance images.\nCan read and write image files stored in Analyze, NIfTI and DICOM\nformats (DICOM support is read only), generate images for use as\nregions of interest, and manipulate and visualize images. By Jon\nClayden.\n\ntreethresh\n\nMethods for Tree-based Local Adaptive Thresholding. By Ludger Evers\nand Tim Heaton.\n\nttrTests\n\nStandard Backtests for Technical Trading Rules in Financial Data.\nFour core functions evaluate the efficacy of a technical trading\nrule: conditional return statistics, bootstrap resampling\nstatistics, test for data snooping bias among parameter choices, and\nrobustness of parameter choices. By David St John.\n\nttutils\n\nSome utility functions. By Thorn Thaler.\n\ntwitteR\n\nAn R based Twitter client via an interface to the Twitter web API.\nBy Jeff Gentry.\n\nvegetarian\n\nJost Diversity Measures for Community Data. Computes diversity for\ncommunity data sets using the methods outlined by Jost (2006, 2007),\nwhich offer the advantage of providing diversity numbers\nequivalents, independent alpha and beta diversities, and the ability\nto incorporate “order” as a continuous measure of the importance of\nrare species in the metrics. Computes alpha diversities, beta\ndiversities, gamma diversities, and similarity indices. Confidence\nintervals for diversity measures are calculated using a bootstrap\nmethod described by Chao et al. (2008). By Noah Charney, Sydne\nRecord.\n\nyhat\n\nMethods for variance partitioning for linear models and canonical\ncorrelation and methods for interpreting regression effects using\nbeta weights, standardized beta weights, structure coefficients, and\nadjusted effect sizes. By Kim Nimon and J. Kyle Roberts.\n\n4 Other changes\nRecommended bundle VR was unbundled into the recommended packages\nMASS, class, nnet and spatial, and moved to the Archive.\nBundle BACCO was unbundled into its packages approximator,\ncalibrator and emulator, and moved to the Archive.\nBundle forecasting was unbundled into its packages Mcomp,\nexpsmooth, fma and forecast, and moved to the Archive.\nBundle hoa was unbundled into its packages cond, csampling,\nmarg and nlreg, and moved to the Archive.\nPackages ARES, MDD, GeneNT, HTMLapplets, RiboSort,\nSLmisc, UNF, WaveCGH, WeedMap, agreement, bivpois,\nboost, clac, crq, ggplot, mclust02, norm, partsm,\npwr, sma, supclust, uroot and verify were moved to the\nArchive.\nPackages Multiclasstesting, Rlab, intcox, km.ci, mixlow,\nsdtalt and survBayes were resurrected from the Archive.\nPackage spectrino was removed from CRAN.\nPackage openNLPmodels was split into openNLPmodels.en and\nopenNLPmodels.es.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2009-2-DSC/",
    "title": "Conference Review: DSC 2009",
    "description": "The 'Conference Review: DSC 2009' article from the 2009-2 issue.",
    "author": [
      {
        "name": "Peter Dalgaard",
        "url": {}
      }
    ],
    "date": "2009-12-01",
    "categories": [],
    "contents": "\n\nThe sixth international workshop on Directions in Statistical Computing\n(DSC 2009) took place at the Center for Health and Society, University\nof Copenhagen, Denmark, 13th–14th of July 2009.\nThe aim of the workshop series is to provide a platform for exchanging\nideas about developments in statistical computing (rather than ‘only’\nthe usage of statistical software for applications).\nWe had 58 participants from many different countries. We listened to 26\ntalks in 11 sessions. Ten of the talks were given in plenary sessions\nand the rest in two parallel tracks. In keeping with the egalitarian\nnature of the conference, all talks had the same length, 35 minutes,\nincluding discussion.\nThe weather was slightly cool for high Summer in Copenhagen, but nicely\ndry, and the Conference dinner at the beautifully situated Furesø Marina\nturned out to be a very pleasant experience indeed.\nSelected papers from the conference will be published as a special issue\nof Computational Statistics. The peer review process is currently\nongoing.\nThe organizing committee, Peter Dalgaard, Claus Ekstrøm, Klaus K.\nHolst and Søren Højsgaard would like to thank\nThe Programme Committee: Roger Bivand, Peter Dalgaard, and\nBalasubramanian Narasimhan\nOur host, the Department of Biostatistics at the University of\nCopenhagen\n“Statistical Methods for Complex and High-dimensional Models”\n(a.k.a. the interfaculty Statistics Network at the University of\nCopenhagen)\nThe R Foundation\nREvolution Computing for sponsoring the conference bags\nNSF(USA) for travel grants\nDIS Congress Service A/S\nOn behalf of the Organizing Committee.\nPeter Dalgaard\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2009-2-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2009-2 issue.",
    "author": [
      {
        "name": "Vince Carey",
        "url": {}
      }
    ],
    "date": "2009-12-01",
    "categories": [],
    "contents": "\n\nThis issue of the R Journal comes on the heels of R 2.10.1. R 2.10\nsports a variety of changes to\nthe documentation system\nfactor handling\ndebugging and code analysis support\nencodings management\n[``[ semantics\nregular expression processing\ndata compression facilities\npackage installation and checking\namong other features. Most users will want to familiarize themselves\nwith the details of items described in R_HOME/NEWS and in this issue’s\n“Changes to R” article. Thanks are due to the core members and other\ncontributors who have introduced these enhancements, many of which will\nincrease the ease and scope of use of R in the growing set of domains\nfor which effectiveness requires excellent data analysis.\nThe R Journal also has some new or impending features of interest. A\nnumber of readers have inquired about subscriptions and RSS feeds. We\nnow have a feed, thanks to Heather Turner:\nhttp://journal.r-project.org/rss.xml. It is also a pleasure to\nannounce the addition of Jay Kerns as Book Review Editor; the Book\nReview section will be inaugurated in the next issue. Thanks to efforts\nof Achim Zeileis, we have added subsections to the “Changes on CRAN”\nregular feature that describe new CRAN task views and new allocations of\npackages to CRAN task views. In the PDF image of the Journal, these are\nall hyperlinked to the view or package resources on CRAN, so that\nreaders can quickly investigate or acquire packages in views of\ninterest. Finally, in this issue we have a nice piece by R core members\nDuncan Murdoch and Simon Urbanek describing changes to the R help markup\nlanguage and its processing. This article is the first for a recurring\njournal section “From the Core” where we plan to highlight new ideas and\nmethods in the words of core members themselves.\nIt has been a pleasure to assemble this number. We have a special item\non the sociology of the R project from our past editor-in-chief, John\nFox. Research articles cover topics in random forest interpretation,\nmeta-analysis, complex surveys in health policy research, data mining\nvia GUI, enhanced support for resource discovery, and issues in teaching\nabout convergence of sequences of random variables and large sample\ninference.\nMy tenure as Editor-in-Chief of the R Journal comes to a close with this\nissue. Peter Dalgaard now takes the reins. I am deeply indebted to\nPeter, John Fox, Heather Turner, Uwe Ligges, and Bill Venables for their\neditorial assistance, and to Martin Maechler for systems support. John\nFox is owed a special thanks for staying in the editorial group for an\nextra year; we welcome Martyn Plummer of IARC who is joining as\nAssociate Editor.\nTo close, I’d like to suggest to readers that they spend at least a\nlittle while in the “Changes on CRAN” section. There is much to be\nlearned there from the perspective of software interoperability alone,\nwith new packages defining interfaces to MS Word, Apache ant, NVIDIA\nCUDA, and sendmail, for example. Folks interested in working with AVIRIS\nhyperspectral images, NIfTI-formatted brain images, or the TikZ system\nfor algebraically specified vector graphics will find connections to R\nin this section. Owners of multicore hardware will want to get\nacquainted with new contributions from Revolution Computing, Inc.\nLastly, browsing the new contributions inspired me to learn that\n“quaternary science” denotes the study of the past 2.6 million years on\nEarth. Go CRAN!\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2009-2-Murdoch+Urbanek/",
    "title": "The New R Help System",
    "description": "Version 2.10.0 of R includes new code for processing `.Rd` help files. There are some changes to what is allowed, and some new capabilities and opportunities.",
    "author": [
      {
        "name": "Duncan Murdoch",
        "url": {}
      },
      {
        "name": "Simon Urbanek",
        "url": {}
      }
    ],
    "date": "2009-12-01",
    "categories": [],
    "contents": "\n\nOne of the reasons for the success of R is that package authors are\nrequired to write documentation in a structured format for all of the\nfunctions and datasets that they make visible in their packages. This\nmeans users can count on asking for help on a topic \"foo\" using either\nthe function call help(\"foo\"), or one of the shortcuts: entering\n?foo in the console, or finding help through the menu system in one of\nthe graphical user interfaces. The quality of the help is improved by\nthe structured format: the quality assurance tools such as R CMD check\ncan report inconsistencies between the documentation and the code,\nundocumented objects, and other errors, and it is possible to build\nindices automatically and do other computations on the text.\nThe original help system was motivated by the help system for S\n(Becker, J. M. Chambers, and A. R. Wilks 1988), and the look of the input files was loosely based on\nLaTeX (Lamport 1986). Perl (Wall, T. Christiansen, and J. Orwant 2000) scripts transformed the input files\ninto formatted text to display in the R console, LaTeX input files to be\nprocessed into Postscript or PDF documents, and HTML files to be viewed\nin a web browser.\nThese Perl scripts were hard to maintain, and inconsistencies crept into\nthe system: different output formats could inadvertently contain\ndifferent content. Moreover, since the scripts could only look for\nfairly simple patterns, the quality control software had trouble\ndetecting many errors which would slip through and result in rendering\nerrors in the help pages, unknown to the author.\nAt the useR! 2008 meeting in Dortmund, one of us (Murdoch) was convinced\nto write a full-fledged parser for .Rd files. This made it into the\n2.9.0 release in April, 2009, but only as part of the quality control\nsystem: and many package authors started receiving warning and error\nmessages. Over the summer since then several members of the R Core team\n(including especially Brian Ripley and Kurt Hornik, as well as the\nauthors of this article) have refined that parser, and written renderers\nto replace the Perl scripts, so that now all help processing is done in\nR code. We have also added an HTTP server to R to construct and deliver\nthe help pages to a web browser on demand, rather than relying on static\ncopies of the pages.\nThis article describes the components of the new help system.\nThe Parser\nIn the new help system, the transformation from an .Rd file to a\n.tex, .html or .txt file is a two-step process. The parse_Rd()\nfunction in the tools package converts the .Rd file to an R object\nwith class \"Rd\" representing its structure, and the renderers convert\nthat to the target form.\nRd Syntax\nThe syntax of .Rd files handled by the parser is in some ways more\ncomplicated than the syntax of R itself. It contains LaTeX-like markup,\nR-like sections of code, and occasionally code from other languages as\nwell. Figure 1 shows a near-minimal example.\n\n% Comments in .Rd files start with percent signs\n\\name{foo}\n\\alias{footopic}\n\\title{Title to Display at the Top of the Page}\n\\description{\n  A short description of what is being documented.\n}\n\\usage{\n  foo(arg = \"\\n\")\n}\n\\arguments{\n  \\item{arg}{the first argument.}\n}\n\\seealso{\n  \\code{\\link{bar}}.\n}\n\\examples{\n  ## call foo then \\link{bar} in a loop\n  for (i in 1:10) {\n    foo(1)\n    bar(2)\n  }\n}\n\\keyword{example}\n\n\nFigure 1: \nThe contents of a simplified .Rd file.\nLike LaTeX, a comment is introduced by a percent sign (%), and markup\nis prefixed with a backslash (\\). Braces ({}) are used to delimit\nthe arguments to markup macros. However, notice that in the\n\\examples{} section, we follow R syntax: braces are used to mark the\nbody of the for loop.\nIn fact, there are three different modes that the parser uses when\nparsing the .Rd file. It starts out in a LaTeX-like mode, where\nbackslashes and braces are used to indicate macros and their arguments.\nSome macros (e.g. \\usage{} or \\examples{}) switch into R-like mode:\nmacros are still recognized, but braces are used in the code, and don’t\nnecessarily indicate the arguments to macros. The third mode is mostly\nverbatim: it doesn’t recognize any macros at all. It is used in a few\nmacros like \\alias{}, where we might want to set an alias involving\nbackslashes, for instance. There are further complications in that\nstrings in quotes in R-like mode (e.g. \"\\n\") are handled slightly\ndifferently again, so the newline is not treated as a macro, and\nR comments in R-like mode have their own special rules.\nA good question to ask is why the syntax is so complicated. Largely this\nis a legacy of the earlier versions of the help system. Because there\nwas no parsing, just a single-step transformation to the output format,\nspecial characters were handled on a case-by-case basis, and not always\nconsistently. When writing the new parser, we wanted to minimize the\nnumber of previously correct .Rd files which triggered errors or were\nrendered incorrectly. The three-mode syntax described above is the\nresult.\nThe syntax rules are fully described in Murdoch (2009), but most users\nshould not need to know all the details. In almost all cases, the syntax\nis designed so that typing what you mean will give the result you want.\nA quick summary is as follows:\nThe characters \\, %, { and } have special meaning almost\neverywhere in an .Rd file.\nThe backslash \\ is used both to introduce macros and to escape the\nspecial meaning of the other characters.\nUnless escaped, the percent % character starts a comment. The\ncomment is included in the parsed object, but the renderers will not\ndisplay it to the user.\nUnless escaped, the braces { and } delimit the arguments to\nmacros. In R-like or verbatim text, they need not be escaped if they\nbalance.\nEnd of line (newline) characters mark the end of pieces of text,\neven when following a % comment.\nOther whitespace (spaces, tabs, etc.) is included as part of the\ntext, though the renderers may remove or change it.\nIn R-like text, quoted strings follow R rules: the delimiters must\nbalance, and braces within need not. Only a few macros are\nrecognized in R strings: \\var and those related to links. Other\nuses of a backslash, e.g. \"\\n\" are taken to be part of the string.\nIn R-like text, R comments using # are taken to be part of the\ntext.\nThe directives #ifdef ... #endif and #ifndef ... #endif are\ntreated as markup, so other macros must be completely nested within\nthem or completely contain them.\nThere are more than 60 macros recognized by the parser, from \\acronym\nto \\verb. Each of them takes from 0 to 3 arguments in braces, and some\nof them take optional arguments in brackets ([]). A complete list is\ngiven in Murdoch (2009), and their interpretation is described in the\nWriting R Extensions manual (R Development Core Team 2009).\nRd Objects\nThe output of the parse_Rd() function is a list with class \"Rd\".\nCurrently this is mostly intended for internal use, and the only methods\ndefined for that class are as.character.Rd() and print.Rd(). The\nelements of the list are the top level components of the .Rd file.\nEach element has an \"RdTag\" attribute labelling it as one of the three\nkinds of text, or a comment, or as a macro. There is a (currently\ninternal) function in the tools package to display all of the tags.\nFor example, using the help file from Figure 1, we get\nthe following results.\n> library(tools)\n> parsed <- parse_Rd(\"foo.Rd\")\n> tools:::RdTags(parsed)\n [1] \"COMMENT\"       \"TEXT\"         \n [3] \"\\\\name\"        \"TEXT\"         \n [5] \"\\\\alias\"       \"TEXT\"         \n [7] \"\\\\title\"       \"TEXT\"         \n [9] \"\\\\description\" \"TEXT\"         \n[11] \"\\\\usage\"       \"TEXT\"         \n[13] \"\\\\arguments\"   \"TEXT\"         \n[15] \"\\\\seealso\"     \"TEXT\"         \n[17] \"\\\\examples\"    \"TEXT\"         \n[19] \"\\\\keyword\"     \"TEXT\"         \nThe TEXT components between each section are simply the newlines that\nseparate them, and can be ignored. The components labelled with macro\nnames are themselves lists, with the same structure. For example,\ncomponent 15 is the \\seealso section, and it has this structure\n> tools:::RdTags(parsed[[15]])\n[1] \"TEXT\"   \"TEXT\"   \"\\\\code\" \"TEXT\"  \nand the \\code macro within it is a list, etc. Most users will have no\nneed to look at \"Rd\" objects at this level, but this is crucial for\nthe internal quality assurance code, and for the renderers described in\nthe next section. As R 2.10.0 is the first release where these objects\nare being fully used, there have been a number of changes since they\nwere introduced in R 2.9.0, and there may still be further changes in\nfuture releases: so users of the internal structure should pay close\nattention to changes taking place on the R development trunk.\nIncompatibilities\nOne of the design goals in writing the new parser was to accept valid\n.Rd files from previous versions. This was mostly achieved, but there\nare some incompatibilities arising from the new syntax rules given\nabove. A full description is included in Murdoch (2009); here we point out\nsome highlights.\nIn previous versions, the \\code{} macro was used for both R code and\ncode in other languages. However, the R code needs R-like parsing rules,\nand other languages often need verbatim parsing. Since R code is more\ncommonly used, it was decided to restrict \\code{} to handle R code and\nintroduce \\verb{} for the rest. At present, this mainly affects text\ncontaining quote marks, which must balance in a \\code{} block as in\nR code. At some point in the future legal R syntax might be more\nstrictly enforced.\nThe handling of #ifdef/#ifndef and the rules for escaping characters\nare now more regular.\nError Handling\nOne final feature of parse_Rd() is worth mentioning. We make a great\neffort to report errors in .Rd files at the point they occur, and\nbecause we now fully parse the file, we have detected a large number of\nerrors that previously went unnoticed. In most cases these errors\nresulted in help pages that were not being displayed as the author\nintended, but we don’t want to suddenly make hundreds of packages on\nCRAN unusable. The compromise we reached is as follows: when the parser\ndetects an error in a .Rd file, it reports an error or warning, and\nattempts to recover, possibly skipping some text. The package\ninstallation code will report these messages, but will not abort an\ninstallation because of them. Authors should not ignore these messages:\nin most cases, they indicate that something will not be displayed as\nintended.\nThe Renderers\nAs of version 2.10.0, R will present help in three different formats:\ntext, HTML, and PDF manuals. Previous versions also included compiled\nHTML on the Windows platform; that format is no longer supported, due\npartly to security concerns (Microsoft Support 2009), partly to the fact that it\nwill not support dynamic help, and partly to reduce the support load on\nthe R Core team. The displayed type is now controlled by a single option\nrather than a collection of options: for example, to see HTML help, use\noptions(help_type=\"html\") rather than options(htmlhelp=TRUE).\nThe three formats are produced by the functions Rd2txt(), Rd2HTML()\nand Rd2latex() in the tools package. The main purpose of these\nfunctions is to convert the parsed \"Rd\" objects to the output format;\nthey also accept .Rd files as input, calling parse_Rd() if\nnecessary.\nThere are two other related functions in tools. The Rd2ex() function\nextracts example code from a help page, and checkRd() performs checks\non the contents of an \"Rd\" object. The latter checks for the presence\nof all necessary sections (at most once in some cases, e.g. for the\n\\title{}). It is used to report errors and warnings during\nR CMD check processing of a package.\nOne big change from earlier versions of R is that these functions do\ntheir rendering on request. In earlier versions, all help processing was\ndone when the package was installed, and the text files, HTML files, and\nPDF manuals were installed with the package. Now the \"Rd\" objects are\nproduced at install time, but the human-readable displays are produced\nat the time the user asks to see them. As described below, this means\nthat help pages can include information computed just before the page is\ndisplayed. Not much use is made of this feature in 2.10.0, but the\ncapability is there, and we expect to make more use of it in later\nreleases of base R, and to see it being used in user-contributed\npackages even sooner.\nAnother advantage of “just-in-time” rendering is that cross-package\nlinks between help pages are handled better. In previous versions of R,\nthe syntax\n\\link[stats]{weighted.mean}\nmeant that the HTML renderer should link to the file named\nweighted.mean.html in the stats package, whereas\n\\link{weighted.mean}\nmeant to link to whatever file corresponded to the alias\nweighted.mean in the current package. This difference was necessary\nbecause the installer needed to build links at install time, but it\ncould not necessarily look up topics outside of the current package (the\ntarget package might not be installed yet). Unfortunately, the\ninconsistency was a frequent source of errors, even in the base\npackages. Now that calculation can be delayed until rendering time,\nR 2.10.0 supports both kinds of linking. For back-compatibility, it\ngives priority to linking by filename, but if that fails, it will try to\nlink by topic.\nThe HTTP server\nIn order to produce the help display in a web browser when the user\nrequests, it was necessary to add an HTTP server to R.\nAt a high level the goal of the server is to accept connections from\nbrowsers, convert each HTTP request on a TCP/IP port into a call to an R\nfunction and deliver the result back to the browser. Since the main use\nis to provide a dynamic help system based on the current state of the R\nsession (such as packages loaded, methods defined, …), it is important\nthat the function is evaluated in the current R session. This makes the\nimplementation more tricky as we could not use regular socket\nconnections and write the server entirely in R.\nInstead, a general asynchronous server infrastructure had to be created\nwhich handles multiple simultaneous connections and is yet able to\nsynchronize them into synchronous calls of the R evaluator. The\nprocessing of each connection is dispatched to an asynchronous worker\nwhich keeps track of the state of the connection, collects the entire\nHTTP request and issues a message to R to process the request when\ncomplete. The request is processed by calling the httpd function with\ntwo arguments: path from the URL and query parameters. The query\nparameters are parsed from the query string into a named string vector\nand decoded, so for example text=foo%3f&n=10 is passed as\nc(text=\"foo?\", n=\"10\").\nThe httpd() function is expected to produce output in the form of a\nlist that is meaningful to the browser. The list’s elements are\ninterpreted in sequence as follows: payload, content-type, headers\nand status code. Only the payload is mandatory so the returned list\ncan have one to four elements. The content type specifies the MIME-type\nof the payload (default is “text/html”), headers specify optional HTTP\nresponse headers as a named character vector (without CR/LF) and the\nerror code is an integer specifying the HTTP status code. The payload\nmust be either a string vector of length one or a raw vector. If the\npayload element is a string vector named “file” then the string is\ninterpreted as an absolute path to a file to be sent as the payload\n(useful for static content). Otherwise the payload is sent to the\nbrowser in verbatim. The httpd function is evaluated in a tryCatch\nblock such that errors are returned as a string from the function,\nresulting in a 500 status code (internal server error). An example of a\nsimple httpd function is listed below:\nhttpd <- function(path, query, ...) {\n  if (is.null(query)) query <- character(0)\n  pkg <- query['package']\n  if (is.na(pkg)) pkg <- 'base'\n  fn <- system.file(path, package = pkg)\n  if (file.exists(fn)) return(list(file = fn))\n  list(paste(\"Cannot find\", path),\n       \"text/html\", NULL, 404L)\n}\nThe signature of the httpd function should include … for future\nextensions. The above function checks for the package query parameter\n(defaulting to “base”) then attempts to find a file given by path in\nthat package. If successful the content of the file is served (as\ndefault text/html), otherwise a simple error page is created with a 404\nHTTP status code “not found”.\nAlthough the HTTP server is quite general and could be used for many\npurposes, R 2.10.0 has the limitation of one server per R instance which\nmakes it currently dedicated to the dynamic help. The user may set\noptions(\"help.ports\") to control which IP port is used by the server.\nIf not set, the port is assigned randomly to avoid collisions between\ndifferent R instances.\nNew Features in .Rd Files\nR Expressions in Help\nAs mentioned previously, help output is now being produced just before\ndisplay, and it is possible for the author to customize the display at\nthat time. This is supported by the new macro \\``Sexpr{}, which is\nmodelled after the macro of the same name in current versions of Sweave\n(Leisch 2002).\nUnlike Sweave, in .Rd files the \\``Sexpr{} macro takes optional\narguments to control how it is displayed, and when it is calculated. For\nexample, \\``Sexpr[results=verbatim,echo=TRUE]{x<-10;x^2} will result\nin a display similar to\n> x<-10;x^2\n[1] 100\nwhen the help page is displayed.\nSome of the options are similar to Sweave, but not always with the same\ndefaults. For example the options (with defaults) eval=TRUE,\necho=FALSE, keep.source=TRUE, and strip.white=TRUE do more or less\nthe same things as in Sweave. That is, they control whether the code is\nevaluated, echoed, reformatted, and stripped of white space before\ndisplay, respectively.\nThere are also options that are different from Sweave. The results\noption has the following possible values:\nresults=text\n\n(the default) The result should be inserted into the text at the\ncurrent point.\n\nresults=verbatim\n\nPrint the result as if it was executed at the console.\n\nresults=hide\n\nNo result should be shown.\n\nresults=rd\n\nThe result should be parsed as if it was .Rd file code.\n\nThe stage option controls when the code is run. It has the following\nvalues:\nstage=build\n\nThe code should be run when building the package. This option is not\ncurrently implemented, but is allowed; the code will not be executed\nin R 2.10.0.\n\nstage=install\n\n(the default) The code is run when installing the package from\nsource, or when building a binary version of the package.\n\nstage=render\n\nThe code is run just before the page is rendered.\n\nThe \\``Sexpr{} macro enables a lot of improvements to the help system.\nIt will allow help pages to include examples with results inline, so\nthat they can be mixed with descriptions, making explanations clearer.\nThe just-in-time rendering will also allow help pages to produce\ninformation customized to a particular session: for example, it would be\nhelpful to link from a page about a class to methods which mention it in\ntheir signatures. It will also be possible to prototype new types of\nsummary pages or indices for the whole help system, without requiring\nchanges to base R.\n0.1 Conditional markup\nThe help files have supported #ifdef/#ifndef conditionals for years,\nto allow selective inclusion of text depending on the computing platform\nwhere R is run. With version 2.10.0 more general conditional selection\nhas been added: the \\if{}{} and \\ifelse{}{}{} macros. The first\nargument to these describes the condition, the second is code to be\nincluded at render time if that condition holds, and the third if it\ndoes not.\nThe most common use of the conditionals is foreseen to be to select\ndisplays depending on the output format, to extend the idea of the\n\\eqn and \\deqn macros from previous versions. To support this use,\nthe condition is expressed as a comma-separated list of formats, chosen\nfrom example, html, latex, text, TRUE and FALSE. If the\ncurrent output format or TRUE is in the list, the condition is\nsatisfied. The logicals would normally be the result of evaluating an\n\\``Sexpr{} expression, so general run-time conditions are possible.\n0.2 Verbatim output\nTwo new macros have been added to support output of literal text. The\n\\verb{} macro parses its argument as verbatim text, and the renderers\noutput it as parsed, inserting whatever escapes and conversions are\nnecessary so that it renders the same in all formats. The \\out{} macro\nworks at a lower level. It also parses its argument as verbatim text,\nbut the renderers output it in raw form, without any processing. It\nwould almost certainly be used in combination with \\if or \\ifelse.\nFor example, to output a Greek letter alpha, the markup\n\\ifelse{html}{\\out{&alpha;}}{\n\\eqn{\\alpha}{alpha}}\ncould be used: this will output &alpha; when producing HTML and\n\\alpha when producing LaTeX, both of which will render as \\(\\alpha\\); it\nwill output alpha when producing text.\nThe Future\nOne of the development guidelines for R is that we don’t introduce many\nnew features in patch releases, so R 2.10.1 is not likely to differ much\nfrom what is described above. However, we would expect small changes to\nthe rendering of help pages as the renderers become more polished.\nFor version 2.11.0 or later, we would expect some of the following to be\nimplemented. The order of presentation is not necessarily the order in\nwhich they will appear, and some may never appear.\nThe \\``Sexpr{} macro will likely develop in several ways:\nWe will likely add in the processing of stage=build macros\nwhen the R CMD build code is rewritten in R.\nWe will likely change the prompt(), package.skeleton() and\nrelated functions to make use of \\``Sexpr{} macros, e.g. to\ndisplay the version of a package, or to list the classes\nsupporting a method, etc.\nWe will make information about the run-time environment\navailable to the \\``Sexpr{} code, so that it can tailor its\nbehaviour to the context in which it is being run.\nWe would expect users to develop contributed packages to provide\nconvenient functions to use in \\``Sexpr{} macros. Some of\nthese may need changes to base R.\nWe would like to allow figures to be inserted into help\ndisplays.\n\nThe quality control checks will continue to evolve, as we notice\ncommon errors and add code to checkRd() to detect them. There is\nalready support for spell checking of .Rd files in the aspell()\nfunction.\nThe .Rd format is very idiosyncratic, and not many tools exist\noutside of R for working with it. There may be an advantage to\nswitching to a different input format (e.g. one based on XML) in\norder to make use of more standard tools. Such a change would\nrequire conversion of the thousands of existing help pages already\nin .Rd format; the new parser may enable automatic translation if\nanyone wants to explore this possibility.\nThe HTTP server used in the help system is quite general, but is\ncurrently limited to serving R help pages. It may be extended to\nallow more general use in the future.\nChanging to the new help system has already helped to diagnose hundreds\nof errors in help pages that slipped by in the previous version, and\ndiagnostic messages are more informative than they were. As the\n\\``Sexpr{} macro is used in core R and by package writers, we will see\nbetter help than ever before, and the HTTP server will open up many\nother possibilities for R developers.\n\n\n\n\nR. A. Becker, J. M. Chambers, and A. R. Wilks. The New S Language. Wadsworth Pacific Grove California, 1988.\n\n\nL. Lamport. LaTeX: A Document Preparation System. Addison-Wesley Reading Massachusetts, 1986.\n\n\nF. Leisch. Sweave: Dynamic generation of statistical reports using literate data analysis. In W. H\"ardle; B. R\"onz editors Compstat —Proceedings in Computational Statistics pages Physica Verlag,Heidelberg  leisch/Sweave, 2002. URL http://www.stat.uni-muenchen.de/.\n\n\nMicrosoft Support. Ms05-026: A vulnerability in html help could allow remote code execution, . Retrieved from onNovember 5, 2009. URL http://support.microsoft.com/kb/896358.\n\n\nD. Murdoch. Parsing Rd files. 2009. URL http://developer.r-project.org/parseRd.pdf.\n\n\nR Development Core Team. Writing R Extensions, . Manual included with R version 2.10.0, 2009.\n\n\nL. Wall, T. Christiansen, and J. Orwant. Programming Perl. O’Reilly Media third edition, 2000.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2009-2-r-changes/",
    "title": "R Changes: 2.9.1-2.10.0 Patched",
    "description": "The 'R Changes: 2.9.1-2.10.0 Patched' article from the 2009-2 issue.",
    "author": [
      {
        "name": "The R Core team",
        "url": {}
      }
    ],
    "date": "2009-12-01",
    "categories": [],
    "contents": "\n\n1 Changes in R 2.10 patched\nNew features\nThe PCRE library has been updated to version 8.00.\nR CMD INSTALL has new options –no-R, –no-libs, –no-data,\n–no-help, –no-demo, –no-exec, and –no-inst to suppress\ninstallation of the specified part of the package. These are\nintended for special purposes (e.g. building a database of help\npages without fully installing all packages).\nThe documented line-length limit of 4095 bytes when reading from the\nconsole now also applies also to parse(file=\"\") (which previously\nhad a limit of around 1024 bytes).\nA Bioconductor mirror can be set for use by setRepositories() via\nthe option \"BioC_mirror\", e.g. the European mirror can be selected\nby options(BioC_mirror=\"http://bioconductor.statistik.tu-dortmund.de\")\nDouble-clicking in a tk_select.list() list box now selects the\nitem and closes the list box (as happens on the Windows\nselect.list() widget).\nInstallation changes\nconfigure will be able to find a usable libtiff in some rare\ncircumstances where it did not previously (where libtiff needed to\nbe linked explicitly against -ljpeg).\nMaking refman.pdf works around a problem with the indexing with\nhyperref 6.79d and later.\nDeprecated & defunct\nThe extended argument is deprecated in strsplit(), grep(),\ngrepl(), sub(), gsub(), regexpr() and gregexpr() (not just\nthe value extended = FALSE) and will be removed in R 2.11.0.\nBug fixes\ntrigamma(x) and other psigamma(x, n) calls are now accurate for\nvery large abs(x). (PR#14020)\n[g]sub(perl=FALSE, fixed=FALSE) could use excessive stack space\nwhen used with a very long vector containing some non-ASCII strings.\nThe default method of weighted.mean(na.rm = TRUE) did not omit\nweights for NA observations in 2.10.0. (PR#14032)\n[g]regexpr(pattern, fixed = TRUE) returned match positions in\nbytes (not characters) in an MBCS locale if pattern was a single\nbyte.\n[g]sub(fixed = TRUE) with a single-byte pattern could conceivably\nhave matched part of a multibyte character in a non-UTF-8 MBCS.\nfindLineNum() and setBreakpoint() would sometimes fail if the\nspecified file was not in the current directory.\nPackage tcltk’s demo(tkdensity) was broken in 2.9.0 when demo()\nwas changed to set par(ask = TRUE).\ngsub() with backrefs could fail on extremely long strings\n(hundreds of thousands of characters) due to integer overflow in a\nlength calculation.\nabline(*, untf=TRUE) now uses a better x-grid in log-scale, e.g.,\nfor plot(c(1,300), c(1,300), log=\"xy\") ;\nabline(4,1, untf=TRUE).\ndetach/unloadNamespace() arrange to flush the package’s lazyload\ncache of R objects once the package/namespace is no longer needed.\nThere have been small fixes to the rendering of help, e.g.\n\\command is now rendered verbatim (so e.g. – is not interpreted,\nPR#14045).\nAlso, there are many small changes to help files where the new\nconverters were not rendering them in the same way as before.\navailable.packages() would fail when run on a repository with no\npackages meeting the filtering conditions. (PR#14042)\nrep(x, times, each = 2) gave invalid results when the times\nargument is a vector longer than x. Reported by Bill Dunlap.\nAn error when unloadNamespace() attempted to run the .onUnload()\nfunction gave an error in the reporting function and so was not\nreported properly.\nText help rendering did not handle very long input lines properly.\npromptMethods() generated signature documentation improperly.\npgamma(x, a, lower.tail=FALSE) and qgamma(..) are now\nconsiderably more accurate in some regions for very small a.\nqgamma() now correctly returns 0 instead of NaN in similar extreme\ncases, and qgamma() no longer warns in the case of small a, see\n(PR#12324).\nunname() now also removes names from a zero length vector.\nPrinting results from ls.str() no longer evaluates unevaluated\ncalls.\ncomplete.cases() failed on a 0-column data frame argument.\n(Underlies PR#14066.)\nIt could return nonsensical results if no input determined the\nnumber of cases (seen in the no-segfault tests).\nAn error in nls() with a long formula could cause a segfault.\n(PR#14059)\nqchisq(p, df, ncp, lower.tail = FALSE) with ncp >= 80 was\ninaccurate for small p (as the help page said): it is now less\ninaccurate. (In part, PR#13999.)\nFor ncp less than but close to 80, pchisq() and qchisq() are\nmore accurate for probablilities very close to 1 (a series expansion\nwas truncated slightly too early).\npchisq(x, df, ncp) can no longer return values just larger than\none for large values of ncp.\nintToUtf8() could fail when asked to produce 10Mb or more strings,\nsomething it was never intended to do: unfortunately Windows crashed\nR (other OSes reported a lack of resources). (PR#14068)\nchisq.test() could fail when given argument x or y which\ndeparsed to more than one line. (Reported by Laurent Gauthier.)\nS4 methods are uncached whenever the name space containing them is\nunloaded (by unloadNamespace() as well as by\ndetach(unload = TRUE)).\nThe internal record-keeping by dyn.load /dyn.unload was\nincomplete, which could crash R if a DLL that registered .External\nroutines had earlier been unloaded.\nbessel[JY](x, nu) with nu a negative integer (a singular case) is\nnow correct, analogously to besselI(), see PR#13556, below.\ntools::file_path_as_absolute() doubled the file separator when\napplied to a file such as /vmunix or (on Windows) d:/afile in a\ndirectory for which getwd() would return a path with a trailing\nseparator (largely cosmetic, as reasonable file systems handle such\na path correctly). (Perhaps what was meant by PR#14078.)\nunsplit(drop = TRUE) applied to a data frame failed to pass drop\nto the computation of row names. (PR#14084)\nThe \"difftime\" method of mean() ignored its na.rm argument.\ntcltk::tk_select.list() is now more likely to remove the widget\nimmediately after selection is complete.\nAdding/subtracting a \"difftime\" object to/from a \"POSIXt\" or\n\"Date\" object works again (it was broken by the addition of\nOps.difftime).\nConversion to latex of an Rd file with no aliases failed.\nwilcox.test(*, conf.int = TRUE) hasachieved.level corrected and, for exact = FALSE, now gives an\n“estimate” which does not depend on the alternative used.\nhelp.search() failed when the package argument was specified.\n(PR#14113)\n2 R 2.10 changes\nInstallation\nconfigure will be able to find a usable libtiff in some rare\ncircumstances where it did not previously (where libtiff needed to\nbe linked explicitly against -ljpeg).\ncairo >= 1.2 is now required (1.2.0 was released in July 2006) for\ncairo-based graphics devices (which remain optional).\nA suitable iconv() is now required: support for configure option\n–without-iconv has been withdrawn (it was deprecated in R 2.5.0).\nPerl is no longer “essential”. R can be built without it, but\nscripts R CMD build, check, Rprof and Sd2d require it.\nA system function is now essential (a working Sys.glob() has been\nassumed since R 2.9.0 at least).\nC99 support for MBCS is now required, and configure option\n–disable-mbcs has been withdrawn.\nHaving a version of tar capable of automagically detecting\ncompressed archives is useful for utils::untar(), and so gtar (a\ncommon name for GNU tar) is preferred to tar: set environment\nvariable TAR to specify a particular tar command.\nDeprecated & defunct\nThe extended argument is deprecated in strsplit(), grep(),\ngrepl(), sub(), gsub(), regexpr() and gregexpr() (not just\nthe value extended = FALSE) and will be removed in R 2.11.0.\nUser-visible changes\nPackage help is now converted from Rd by the R-based converters that\nwere first introduced in 2.9.0. This means\n- Packages that were installed by R-devel after 2009-08-09 should\nnot be used with earlier versions of R, and most aspects of package\nhelp (including the runnable examples) will be missing if they are\nso used.\n- Text, HTML and latex help and examples for packages installed\nunder the new system are converted on-demand from stored parsed Rd\nfiles. (Conversions stored in packages installed under R < 2.10.0\nare used if no parsed Rd files are found. It is recommended that\nsuch packages be re-installed.)\nHTML help is now generated dynamically using an HTTP server running\nin the R process and listening on the loopback interface.\n- Those worried about security implications of such a server can\ndisable it by setting the environment variable R_DISABLE_HTTPD to\na non-empty value. This disables help.start() and HTML help (so\ntext help is shown instead).\n- The Java/Javascript search engine has been replaced by an HTML\ninterface to help.search(). help.start() no longer has an\nargument searchEngine as it is no longer needed.\n- The HTML help can now locate cross-references of the form\n\\link[pkg]{foo} and \\link[pkg:foo]{bar} where foo is an alias\nin the package, rather than the documented (basename of a) filename\n(since the documentation has been much ignored).\nNew features\npolygon(), pdf() and postscript() now have a parameter\nfillOddEven (default FALSE), which controls the mode used for\npolygon fills of self-intersecting shapes.\nNew debugonce() function; further,\ngetOption(\"deparse.max.lines\") is now observed when debugging,\nfrom a code suggestion by John Brzustowski. (PR#13647/8)\nplot() methods for \"stepfun\" and hence \"ecdf\" no longer plot\npoints by default for n \\(>=\\) 1000.\n{[g]sub(*, perl=TRUE)} now also supports '\\E' in order to\n*end* \\U and \\L case changes, thanks to a patch from Bill\nDunlap.\nfactor(), ‘levels<-‘(), etc, now ensure that the resulting\nfactor levels are unique (as was always the implied intention).\nFactors with duplicated levels are still constructible by low-level\nmeans, but are now declared illegal.\nNew print() (S3) method for class \"function\", also used for\nauto-printing. Further, .Primitive functions now print and\nauto-print identically. The new method is based on code suggestions\nby Romain François.\nThe print() and toLatex() methods for class \"sessionInfo\" now\nshow the locale in a nicer format and have arguments to suppress\nlocale information.\nIn addition to previously only round(), there are other ‘Math’\ngroup (S3) methods for \"difftime\", such as floor(), signif(),\nabs(), etc.\nFor completeness, old.packages() and available.packages() allow\ntype to be specified (you could always specify available or\ncontriburl).\navailable.packages() by default only returns information on the\nlatest versions of packages whose version requirements are\nsatisified by the currently running R.\ntools::write_PACKAGES() has a new argument latestOnly, which\ndefaults to TRUE when only the latest versions in the repository\nwill be listed in the index.\ngetOption() has a new argument default that is returned if the\nspecified option is not set. This simplifies querying a value and\nchecking whether it is NULL or not.\nparse() now warns if the requested encoding is not supported.\nThe \"table\" method of as.data.frame() gains a stringsAsFactors\nargument to allow the classifying factors to be returned as\ncharacter vectors rather than the default factor type.\nIf model.frame.default() encounters a character variable where\nxlev indicates a factor, it now converts the variable to a factor\n(with a warning).\ncurve() now returns a list containing the points that were drawn.\nspineplot() now accepts axes = FALSE, for consistency with other\nfunctions called by plot.factor().\nThe Kendall and Spearman methods of cor.test() can optionally use\ncontinuity correction when not computing exact p-values. (The\nKendall case is the wish of PR#13691.)\nR now keeps track of line numbers during execution for code sourced\nwith options(keep.source = TRUE). The source reference is\ndisplayed by debugging functions such as traceback(), browser(),\nrecover(), and dump.frames(), and is stored as an attribute on\neach element returned by sys.calls(). [Experimental]\nMore functions now have an implicit (S4) generic definition.\nquantile.default() now disallows factors (wish of PR#13631) and\nits help documents what numeric-like properties its input need to\nhave to work correctly.\nweighted.mean() is now generic and has \"Date\", \"POSIXct\" and\n\"POSIXlt\" methods.\nNaming subscripts (e.g. x[i=1, j=2]) in \"data.frame\" methods for\n[ and [[ now gives a warning. (Names are ignored in the default\nmethod, but could have odd semantics for other methods, and do for\nthe \"data.frame\" ones.)\nas.data.frame() has an \"aovproj\" method. (Wish of PR#13505)\nas.character(x) for numeric x no longer produces strings such as\n\"0.30\", i.e., with trailing zeros. This change also renders levels\nconstruction in factor() more consistent.\ncodocClasses(), which checks consistency of the documentation of\nS4 class slots, now does so in considerably more cases. The\ndocumentation of inherited slots (from superclasses) is now\noptional. This affects R CMD check <pkg> when the package defines\nS4 classes.\ncodoc() now also checks S4 methods for code/documentation\nmismatches.\nfor(), while(), and repeat() loops now always return NULL as\ntheir (invisible) value. This change was needed to address a\nreference counting bug without creating performance penalties for\nsome common use cases.\nThe print() method for ls.str() results now obeys an optional\ndigits argument.\nThe method argument of glm() now allows user-contributed\nmethods.\nMore general reorder.default() replaces functionality of\nreorder.factor() and reorder.character().\nThe function aspell() has been added to provide an interface to\nthe Aspell spell-checker.\nFilters RdTextFilter() and SweaveTeXFilter() have been added to\nthe tools package to provide support for aspell() or other spell\ncheckers.\nxtabs() with the new option sparse = TRUE now returns a sparse\nMatrix, using package Matrix.\ncontr.sum() etc gain an argument sparse which allows sparse\nmatrices to be returned.\ncontrasts() also gains a sparse argument which it passes to the\nactual contrast function if that has a formal argument sparse.\ncontrasts(f, .) <- val now also works when val is a sparse\nMatrix. It is planned that model.matrix() will work with such\nfactors f in the future.\nreadNEWS() will recognize a UTF-8 byte-order mark (BOM) in the\nNEWS file. However, it is safer to use only ASCII code there\nbecause not all editors recognize BOMs.\nNew utility function inheritedSlotNames() for S4 class\nprogramming.\ntabulate() now allows NAs to pass through (and be ignored).\nIf debug() is called on an S3 generic function then all methods\nare debugged as well.\nOutlier symbols drawn by boxplot() now obey the outlwd argument.\nReported by Jurgen Kluge.\nsvd(x) and eigen(x) now behave analogously to qr(x) in\naccepting logical matrices x.\nFile NEWS is now in UTF-8, and has a BOM (often invisible) on the\nfirst line, and Emacs local variables set for UTF-8 at the end.\nRShowDoc(\"NEWS\") should display this correctly, given suitable\nfonts.\nterms.formula(simplify = TRUE) now does not deparse the LHS and so\npreserves non-standard responses such as ‘a: b‘ (requested by\nSundar Dorai-Raj).\nNew function news() for building and querying R or package news\ninformation.\nz^n for integer n and complex z is more accurate now if\n\\(|n| <= 65536\\).\nfactor(NULL) now returns the same as factor(character(0))\ninstead of an error, and table(NULL) consequently does\nanalogously.\nas.data.frame.vector() (and its copies) is slightly faster by\navoiding a copy if there are no names (following a suggestion of Tim\nHesterberg).\nwriteLines(), writeBin() and writeChar() have a new argument\nuseBytes. If false, character strings with marked encodings are\ntranslated to the current locale (as before) but if true they are\nwritten byte-by-byte.\niconv() has a new argument mark which can be used (by experts)\nto suppress the declaration of encodings.\nDESCRIPTION ‘LinkingTo’ specs are now recognized as installation\ndependencies, and included in package management computations.\nStandardized DESCRIPTION ‘License’ specs are now available for\npackage management computations.\n\"\\uxxxx\" and \"\\Uxxxxxxxx\" escapes can now be parsed to a UTF-8\nencoded string even in non-UTF-8 locales (this has been implemented\non Windows since R 2.7.0). The semantics have been changed slightly:\na string containing such escapes is always stored in UTF-8 (and\nhence is suitable for portably including Unicode text in packages).\nNew as.raw() method for \"tclObj\" objects (wish of PR#13578).\nRd.sty now makes a better job of setting email addresses,\nincluding using a monospaced font.\ntextConnection() gains an encoding argument to determine how\ninput strings with marked encodings will be handled.\nR CMD Rd2pdf is available as a shortcut for R CMD Rd2dvi –pdf.\nR CMD check now checks links where a package is specified\n(\\link[pkg]{file} or \\link[pkg:file]{topic}), if the package is\navailable. It notes if the package is not available, as in many\ncases this is an error in the link.\nidentical() gains three logical arguments, which allow for even\nmore differentiation, notably -0 and 0.\nlegend() now can specify the border color of filled boxes,\nthanks to a patch from Frederic Schutz.\nIndexing with a vector index to [[]] has now been extended to all\nrecursive types.\nPairlists may now be assigned as elements of lists. (Lists could\nalways be created with pairlist elements, but [[<- didn’t support\nassigning them.)\nThe parser now supports C-preprocessor-like #line directives, so\nerror messages and source references may refer to the original file\nrather than an intermediate one.\nNew functions findLineNum() and setBreakpoint() work with the\nsource references to find the location of source lines and set\nbreakpoints (using trace()) at those lines.\nNamespace importing is more careful about warning on masked\ngenerics, thanks to a patch by Yohan Chalabi.\ndetach() now has an argument character.only with the same\nmeaning as for library() or require().\navailable.packages() gains a filters argument for specifying the\nfiltering operations performed on the packages found in the\nrepositories. A new built-in license/FOSS filter only retains\npackages for which installation can proceed solely based on packages\nwhich can be verified as Free or Open Source Software (FOSS)\nemploying the available license specifications.\nIn registering an S3 class by a call to setOldClass(), the data\npart (e.g., the object type) required for the class can be included\nas one of the superclasses in the Classes argument.\nThe argument f to showMethods() can be an expression evaluating\nto a generic function, allowing methods to be shown for non-exported\ngenerics and other nonstandard cases.\nsprintf() now supports %o for octal conversions.\nNew function Sys.readlink() for information about symbolic links,\nincluding if a file is a symbolic link.\nPackage tools has new functions checkRdaFiles() and\nresaveRdaFiles() to report on the format of .rda/.RData data\nfiles, and to re-save them in a different compressed format,\nincluding choosing the most compact format available.\nA new INSTALL option, –resave-data, makes use of this.\nFile ~/.R/config is used in preference to ~/.Rconfig, and these\nare now documented in ‘R Installation and Administration’.\nLogic operations with complex numbers now work, as they were always\ndocumented to, and as in S.\narrows() and segments() allow one of x1 or y1 to be omitted\nto simplify the specification of vertical or horizontal lines\n(suggestion of Tim Hesterberg).\napproxfun() is faster by avoiding repeated NA checks (diagnosis\nand patch by Karline Soetaert & Thomas Petzoldt).\nThere are the beginnings of a Nynorsk translation by Karl Ove\nHufthammer.\nstripchart() allows par bg to be passed in for the background\ncolour for pch = 21 (wish of PR#13984).\nNew generic function .DollarNames() to enable class authors to\ncustomize completion after the $ extractor.\nload(), save(), dput() and dump() now open a not-yet-open\nconnection in the appropriate mode (as other functions using\nconnections directly already did).\nRegular expressions\nA different regular expression engine is used for basic and extended\nregexps and is also for approximate matching. This is based on the\nTRE library of Ville Laurikari, a modifed copy of which is included\nin the R sources.\nThis is often faster, especially in a MBCS locale.\nSome known differences are that it is less tolerant of invalid\ninputs in MBCS locales, and in its interpretation of undefined\n(extended) regexps such as \"^*\". Also, the interpretation of\nranges such as [W-z] in caseless matching is no longer to map the\nrange to lower case.\nThis engine may in future be used in ‘literal’ mode for\nfixed = TRUE, and there is a compile-time option in\nsrc/main/grep.c to do so.\nThe use of repeated boundary regexps in gsub() and gregexpr() as\nwarned about in the help page does not work in this engine (it did\nin the previous one since 2005).\nExtended (and basic) regexps now support same set of options as for\nfixed = TRUE and perl = TRUE, including useBytes and support\nfor UTF-8-encoded strings in non-UTF-8 locales.\nagrep() now has full support for MBCS locales with a modest speed\npenalty. This enables help.search() to use approximate matching\ncharacter-wise rather than byte-wise.\n[g]sub use a single-pass algorithm instead of matching twice and\nso is usually faster.\nThe perl = TRUE versions now work correctly in a non-UTF-8 MBCS\nlocale, by translating the inputs to UTF-8.\nuseBytes = TRUE now inhibits the translation of inputs with marked\nencodings.\nstrsplit() gains a useBytes argument.\nThe algorithm used by strsplit() has been reordered to batch by\nelements of split: this can be much faster for fixed = FALSE (as\nmultiple compilation of regexps is avoided).\nThe help pages, including ?regexp, have been updated and should be\nconsulted for details of the new implementations.\nHelp & Rd file changes\nA new dynamic HTML help system is used by default, and may be\ncontrolled using tools::startDynamicHelp(). With this enabled,\nHTML help pages will be generated on request, resolving links by\nsearching through the current .libPaths(). The user may set\noptions(\"help.ports\") to control which IP port is used by the\nserver.\nhelp.start() no longer sets options(htmlhelp = TRUE) (it used to\non Unix but not on Windows). Nor does it on Unix reset the\n\"browser\" option if given an argument of that name.\nArguments update and remote are now available on all platforms:\nthe default is update = FALSE since the http server will update\nthe package index at first use.\nhelp() has a new argument help_type (with default set by the\noption of that name) to supersede offline, htmlhelp and\nchmhelp (although for now they still work if help_type is\nunset). There is a new type, \"PDF\" to allow offline PDF (rather\nthan PostScript).\nA function offline_help_helper() will be used if this exists in\nthe workspace or further down the search path, otherwise the\nfunction of that name in the ‘utils’ name space is used.\nPlain text help is now used as the fallback for HTML help (as it\nalways was for Compiled HTML help on Windows).\nIt is possible to ask for static HTML pages to be prebuilt via the\nconfigure option –enable-prebuilt-html. This may be useful for\nthose who wish to make HTML help available outside R, e.g. on a\nlocal web site.\nAn experimental tag \\Sexpr has been added to Rd files, to\nevaluate expressions at build, install, or render time. Currently\ninstall time and render time evaluation are supported.\nTags \\if, \\ifelse and \\out have been added to allow\nformat-specific (or more general, using \\Sexpr) conditional text\nin man pages.\nThe parse_Rd() parser has been made more tolerant of coding errors\nin Rd files: now all syntax errors are reported as warnings, and\nan attempt is made to continue parsing.\nparse_Rd() now has an argument fragment (default FALSE) to\naccept small fragments of Rd files (so that \\Sexpr can output Rd\ncode which is then parsed).\nparse_Rd() now always converts its input to UTF-8. The Rd2*\nrendering functions have a new parameter, outputEncoding, which\ncontrols how their output is encoded.\nparse_Rd() no longer includes the newline as part of a \"%\"-style\ncomment.\nThere have been various bug fixes and code reorganization in the Rd\nrenderers Rd2HTML, Rd2latex, Rd2txt, and Rd2ex.\nAll example files are now created with either ASCII or UTF-8\nencoding, and the encoding is only marked in the file if there is\nany non-UTF-8 code (previously it was marked if the help file had\nnon-ASCII contents, possibly in other sections).\nprint.Rd() now adds necessary escape characters so that printing\nand re-parsing an Rd object should produce an equivalent object.\nparse_Rd() was incorrectly handling multiple backslashes in R code\nstrings, converting 4n+3 backslashes to 2n+1 instead of 2n+2.\nparse_Rd() now recognizes the tag within a quoted string in R-like\ntext.\nparse_Rd() now treats the argument of as LaTeX-like, rather than\nverbatim.\nCompression\nNew function untar() to list or unpack tar archives, possibly\ncompressed. This uses either an external tar command or an\ninternal implementation.\nNew function tar() to create (possibly compressed) tar archives.\nNew functions memCompress() and memDecompress() for in-memory\ncompression and decompression.\nbzfile() has a compress argument to select the amount of effort\nput into compression when writing.\nNew function xzfile() for use with xz-compressed files. (This can\nalso read files compressed by some versions of ‘lzma’.)\ngzfile() looks at the file header and so can now also read\nbzip2-ed files and xz-compressed files.\nThere are the new options of save(compress = \"bzip2\") and \"xz\"\nto use bzip2 or xz compression (which will be slower, but can give\nsubstantially smaller files). Argument compression_level gives finer\ncontrol over the space/time tradeoffs.\nload() can read such saves (but only as from this version of R).\nR CMD INSTALL/check and writePACKAGES (tools) accept a wider\nrange of compressed tar archives. Precisely how wide depends on the\ncapabilities of the host system’s tar command: they almost always\ninclude .tar.bz2 archives, and with modern versions of tar other\nforms of compression such as lzma and xz, and arbitrary extensions.\nR CMD INSTALL has a new option –data-compress to control the\ncompression used when lazy-loading data. New possibilities are\n–data-compress=bzip2 which will give ca 15% better compression at\nthe expense of slower installation times, and –data-compress=xz,\noften giving even better compression on large datasets at the\nexpense of much longer installation times. (The latter is used for\nthe recommended packages: it is particularly effective for\nsurvival.)\nfile() for open = \"\", \"r\" or \"rt\" will automagically detect\ncompressed files (from gzip, bzip2 or xz). This means that\ncompressed files can be specified by file name (rather than via a\ngzfile() connection) to read.table(), readlines(), scan()\nand so on.\ndata() can handle compressed text files with extensions\n.{txt,tab,csv}.{gz,bz2,xz} .\nDeprecated & defunct\npng(type=\"cairo1\") is defunct: the value is no longer recognized.\ntools::Rd_parse() is defunct (as this version of R uses only Rd\nversion 2).\nUse of ~/.Rconf (which was deprecated in favour of ~/.Rconfig\nin 2004) has finally been removed.\nBundles of packages are deprecated. See ‘Writing R Extensions’ for\nthe steps needed to unbundle a bundle.\nhelp() arguments offline, htmlhelp and chmhelp are\ndeprecated in favour of help_type.\nclearNames() (stats) is deprecated for unname().\nBasic regular expressions (extended = FALSE) are deprecated in\nstrsplit, grep and friends. There is a precise POSIX standard for\nthem, but it is not what recent RE engines implement, and it seems\nthat in almost all cases package authors intended fixed = TRUE\nwhen using extended = FALSE.\nmethods::trySilent() is deprecated for try(*, silent=TRUE) or -\nmore efficiently and flexibly - something like\ntryCatch(*, error = function(e) e).\nindex.search() is deprecated: there are no longer directories of\ntypes other than ‘help’.\nInternationalization\nThere is some makefile support for adding/updating translations in\npackages: see po/README and ‘Writing R Extensions’.\nThere is support for the use of ‘dngettext’ for C-level translations\nin packages: see ‘Writing R Extensions’.\nBug fixes\ntrigamma(x) and other psigamma(x, n) calls are now accurate for\nvery large abs(x). (PR#14020)\n[g]sub() could use excessive stack space when used with a very\nlong vector of non-ASCII data.\nThe default method of weighted.mean(na.rm = TRUE) did not omit\nweights for NA observations in 2.10.0. (PR#14032)\nAssigning an extra 0-length column to a data frame by\nDF[, \"foo\"] <- value now works in most cases (by filling with\nNAs) or fails. (It used to give a corrupt data frame.)\nvalidObject() avoids an error during evaluation in the case of\nvarious incorrect slot definitions.\nn:m now returns a result of type \"integer\" in a few more\nboundary cases.\nThe zap.ind argument to printCoefmat() did not usually work as\nother code attempted to ensure that non-zero values had a non-zero\nrepresentation.\nprintCoefmat() formatted groups of columns together, not just the\ncs.ind group but also the zap.ind group and a residual group. It\nnow formats all columns except the cs.ind group separately (and zaps\nthe zap.ind group column-by-column). The main effect will be see\nin the output from print.anova, as this grouped SS-like columns in\nthe zap.ind group.\nR_ReplDLLinit() initializes the top-level jump so that some\nembedded applications on Windows no longer crash on error.\nidentical() failed to take the encoding of character strings into\naccount, so identical byte patterns are not necessarily identical\nstrings, and similarly Latin-1 and UTF-8 versions of the same string\ndiffer in byte pattern.\nmethods(f) used to warn unnecessarily for an S4 generic f which\nhad been created based on an existing S3 generic.\nThe check for consistent ordering of superclasses was not ignoring\nall conditional relations (the symptom was usually spurious warnings\nfor classes extending \"array\").\nTrying to assign into a raw vector with an index vector containing\nNAs could cause a segfault. Reported by Hervé Pagès.\nRscript could segfault if (by user error) its filename argument was\nmissing. Reported by Martin Morgan.\ngetAnywhere() (and functions that use it, including argument\ncompletion in the console) did not handle special built-in\nfunctions. Reported by Romain François.\norder() was missing a PROTECT() call and so could segfault when\ncalled on character data under certain (rare) circumstances\ninvolving marked non-native encodings.\nprettyNum(z, drop0trailing=TRUE) did not work correctly when z was\na complex vector. Consequently, str(z, ...) also did not.\n(PR#13985)\nmake distclean removed too many files in etc/ if\nbuilddir = srcdir.\nR CMD replaced TEXINPUTS rather than appending to it (as\ndocumented and intended).\nhelp.start() no longer fails on unix when \"browser\" is a\nfunction.\npbeta(x, *, log.p = TRUE) is sometimes more accurate, e.g., for\nvery small x.\nUnserializing a pre-2.8 workspace containing pure ASCII character\nobjects with a LATIN1 or UTF-8 encoding would corrupt the CHARSXP\ncache.\n3 Changes in R 2.9.2 patched\nNew features\nOn systems using ICU for collation (including Mac OS X), using\nSys.setlocale() to change the LC_COLLATE setting is more likely to\nchange the collation provided by ICU.\n4 Bug fixes\nNames of datasets could clash with temporary filenames used when\nrunning examples, causing errors.\nas.complex() sometimes warned about NAs on coercions and\nsometimes not (when the C function asComplex was used, e.g. on list\nelements). (PR#13942)\ncat() on an unopened connection could close it twice, and file()\nconnections segfaulted on some systems.\nPrinting a list could segfault if the elements are nested too\ndeeply.\n5 Changes in R 2.9.2\nNew features\ninstall.packages(NULL) now lists packages only once even if they\noccur in more than one repository (as the latest compatible version\nof those available will always be downloaded).\napproxfun() and approx() now accept a rule of length two, for\neasy specification of different interpolation rules on left and\nright.\nThey no longer segfault for invalid zero-length specification of\nyleft, yright, or f.\nseq_along(x) is now equivalent to seq_len(length(x)) even where\nlength() has an S3/S4 method; previously it (intentionally) always\nused the default method for length().\nPCRE has been updated to version 7.9 (for bug fixes).\nagrep() uses 64-bit ints where available on 32-bit platforms and\nso may do a better job with complex matches. (E.g. PR#13789, which\nfailed only on 32-bit systems.)\nDeprecated & defunct\nR CMD Rd2txt is deprecated, and will be removed in 2.10.0. (It is\njust a wrapper for R CMD Rdconv -t txt.)\ntools::Rd_parse() is deprecated and will be removed in 2.10.0\n(which will use only Rd version 2).\nBug fixes\nparse_Rd() still did not handle source reference encodings\nproperly.\nThe C utility function PrintValue no longer attempts to print\nattributes for CHARSXPs as those attributes are used internally for\nthe CHARSXP cache. This fixes a segfault when calling it on a\nCHARSXP from C code.\nPDF graphics output was producing two instances of anything drawn\nwith the symbol font face. (Report from Baptiste Auguié.)\nlength(x) <- newval and grep() could cause memory corruption.\n(PR#13837)\nIf model.matrix() was given too large a model, it could crash R.\n(PR#13838, fix found by Olaf Mersmann.)\ngzcon() (used by load()) would re-open an open connection,\nleaking a file descriptor each time. (PR#13841)\nThe checks for inconsistent inheritance reported by setClass() now\ndetect inconsistent superclasses and give better warning messages.\nprint.anova() failed to recognize the column labelled P(>|Chi|)\nfrom a Poisson/binomial GLM anova as a p-value column in order to\nformat it appropriately (and as a consequence it gave no\nsignificance stars).\nA missing PROTECT caused rare segfaults during calls to load().\n(PR#13880, fix found by Bill Dunlap.)\ngsub() in a non-UTF-8 locale with a marked UTF-8 input could in\nrare circumstances overrun a buffer and so segfault.\nR CMD Rdconv –version was not working correctly.\nMissing PROTECTs in nlm() caused \"random\" errors. (PR#13381 by\nAdam D.I. Kramer, analysis and suggested fix by Bill Dunlap.)\nSome extreme cases of pbeta(log.p = TRUE) are more accurate\n(finite values < -700 rather than -Inf). (PR#13786)\npbeta() now reports on more cases where the asymptotic expansions\nlose accuracy (the underlying TOMS708 C code was ignoring some of\nthese, including the PR#13786 example).\nnew.env(hash = TRUE, size = NA) now works the way it has been\ndocumented to for a long time.\ntcltk::tk_choose.files(multi = TRUE) produces better-formatted\noutput with filenames containing spaces. (PR#13875)\nR CMD check –use-valgrind did not run valgrind on the package\ntests.\nThe tclvalue() and the print() and as.xxx methods for class\n\"tclObj\" crashed R with an invalid object – seen with an object\nsaved from an earlier session.\nR CMD BATCH garbled options -d <debugger> (useful for\nvalgrind, although –debugger=valgrind always worked)\nINSTALL with LazyData and Encoding declared in DESCRIPTION might\nhave left options(\"encoding\") set for the rest of the package\ninstallation.\n6 Changes in R 2.9.1\nNew features\nNew function anyDuplicated(x) returns 0 (= FALSE) or the index\nof the first duplicated entry of x.\nmatplot(), matlines() and matpoints() now also obey a lend\nargument, determining line end styles. (Wish of PR#13619).\nbw.SJ(), bw.bcv() and bw.ucv() now gain an optional tol\nargument allowing more accurate estimates.\nnew.packages() no longer regards packages with the same name as a\nmember of an installed bundle as ‘new’ (this is now consistent with\nthe dependency checks in install.packages()).\nIt no longer reports on partially installed bundles (since members\ncan be updated individually if a bundle is unbundled).\nold.packages() and hence updates.packages() will look for\nupdates to members of package bundles before updates to the whole\nbundle: this allow bundles to be split and installations updated.\nnlminb() gives better non-convergence messages in some cases.\nS3 method dispatch will support S4 class inheritance for S3 methods,\nfor primitives and via UseMethod(), if the argument\nS3methods=TRUE is given to setClass(). S4 method dispatch will\nuse S3 per-object inheritance if S3Class() is set on the object.\nSee ?Methods and the paper referenced there.\nR CMD INSTALL is more tolerant of (malformed) packages with a\n‘man’ directory but no validly named .Rd files.\nR CMD check now reports where options are used that cause some of\nthe checks to be skipped.\nRSiteSearch has been updated to be consistent with the new layout\nof the search site itself, which now includes separate options for\nvignettes, views, and r-sig-mixed-models, as well as changed names\nfor r-help. (Contributed by Jonathan Baron.)\nThat R CMD check makes use of a\n<pkg>/tests/Examples/<pkg>-Ex.Rout.save file as a reference result\nis now documented in ‘Writing R Extensions’.\nDeprecated & defunct\nprint.atomic() (defunct since 1.9.0) has been removed since it\ncaused confusion for an S4 class union \"atomic\".\npng(type=\"cairo1\") is deprecated – it was only needed for\nplatforms with 1.0 \\(<=\\) cairo \\(<\\) 1.2.\nBug fixes\nThe ... argument was not handled properly when ... was found in\nthe enclosure of the current function, rather than in the function\nheader itself. (This caused integrate() to fail in certain cases.)\ninteraction() now ensures that the levels of the result are\nunique.\npackageDescription() and hence sessionInfo() now report the\ncorrect package version also for a non-attached loaded namespace of\na version different from the default lib.loc.\nsmoothScatter() now also works when e.g. xlim[2] < xlim[1].\nparse_Rd() would mishandle braces when they occurred at the start\nof a line within an R string in an Rd file (reported by Alex\nCouture-Beil) or when they occurred in an R comment (reported by\nMark Bravington).\nreadNEWS() missed version numbers with more than one digit.\nbuilding R –without-x no longer fails (PR#13665)\nprintCoefmat(cbind(0,1)) now works too (PR#13677)\nbw.SJ(c(1:99, 1e6)) now works too.\nRd2txt() could not handle empty descriptions of items in an Rd\nfile (reported by Mark Bravington), and did not wrap long lists of\narguments if they were given in a single item.\nstars() would do a partial plot when called with plot = FALSE;\nit now consistently returns the locations of the stars.\nRd2latex() could not handle empty sections.\nold.packages() and hence update.packages() would fail on a\nrepository which contained only one package but with multiple\nversions of that package.\nas.character.Rd() added extra braces when displaying two-argument\nmacros. (Report and fix by Manuel Eugster.)\nunsplit() was misbehaving in the case of single-column data\nframes. (Reported by Will Gray.)\nas(I(1), \"vector\") and similar coercions from objects of\n\"unregistered\" S3 classes now work.\nsrcref records produced by parse() and parse_Rd() did not record\nthe encoding of the source file. (Reported by Romain François.)\nThe X11 version of View() was misbehaving in MBCS locales, and\nPgUp/PgDn now behave better, thanks to a patch from Ei-ji Nakama.\nR CMD check looked at the environment variable PDFLATEX, but as\nfrom R 2.8.1 R CMD Rd2dvi used R_PDFLATEXCMD in preference, and\nthat was set by R CMD (and not PDFLATEX). Now R CMD check\nlooks at R_PDFLATEXCMD.\nThe new (in 2.9.0) stringsAsFactors argument to expand.grid()\nwas not working: it now does work but has default TRUE for\nbackwards compatibility.\ntcrossprod(<1d-array>, <matrix>) now does work when the arguments\nare of compatible dimensions.\nqbinom() now is accurate also in (large size, small prob) cases.\n(PR#13711)\nThe calculation of the Spearman p-value in cor.test() is slightly\nmore accurate in some cases. (PR#13574)\nThe digamma(), trigamma() and psigamma() functions could be\ninaccurate for values of x around 1e-15 due to cancellation.\n(PR#13714).\nmedian.default() was altered in 2.8.1 to use sum() rather than\nmean(), although it was still documented to use mean(). This\ncaused problems for POSIXt objects, for which mean() but not\nsum() makes sense, so the change has been reverted.\nAssigning an extra 0-length column to a data frame by\nDF$foo <- value gave a corrupt data frame rather than failing.\n(PR#13724) This also happened for DF[[\"foo\"]] <- value.\nR CMD INSTALL no longer gives a spurious warning about old R\nversions ignoring multiple dependencies, if the conditions are known\nto be satisfied.\nThe test for setting dim() allowed a value with two or more NAs\nto be set on a 0-length object. (PR#13729) Also, it allowed an even\nnumber of negative values.\nxtfrm(), rank(), sort() and order() did not always make use\nof custom comparison methods specific to the class of elements being\nsorted.\nIncrease NAMED value on seq value in for() loop so loop code\ncannot modify seq value.\nPrevent rectangles of size < 0.5 pixel from disappearing in Quartz\nwhen using rastered backend. (PR#13744)\nPrinting _NA_complex_ had a low-level thinko; patch thanks to Bill\nDunlap.\nCP1257 encoding for postscript/PDF has been corrected. (PR#13736)\naov() with an error term was evaluating the ... arguments in\n2.9.0 whilst checking their names, so could fail by evaluating them\nin the wrong place. (PR#13733)\nThe print() method for arima() failed if all coefs were fixed.\nR CMD INSTALL –no-latex was not implemented in 2.9.0 (only).\nAdded a needed PROTECT call in RunFinalizers to handle cases where\nthe routine is called recursively from a GC in a finalizer.\nConstructing error messages about unused arguments in calls to\nclosures no longer evaluates the arguments.\nqr(x, LAPACK=TRUE) did not coerce integer x to numeric.\nqr.coef() misbehaved in the LAPACK case with a matrix RHS, so that\nsolve(qr(x, LAPACK=TRUE)) gave wrong results. (Found by Avraham\nAdler, PR#13762 by Ravi Varadhan.)\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2009-2-r-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2009-2 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2009-12-01",
    "categories": [],
    "contents": "\n1 Donations and new members\nDonations\nJason Fisher, USA\nN. Srinivasan, USA\nNew benefactors\nTibco Software Inc., Palo Alto, USAThe Generations Network, San Francisco, USA\nNew supporting members\nStephan Robert Aichele, USA\nMatthias Burger, Germany\nJason Fisher, USA\nNicholas Horton, USA\nMichael J. Messner, USA\nJacob J. Michaelson, USA\nKenneth S. Spriggs, USA\nVincent Vinh-Hung, Belgium\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2009-1-bioconductor/",
    "title": "News from the Bioconductor Project",
    "description": "The 'News from the Bioconductor Project' article from the 2009-1 issue.",
    "author": [
      {
        "name": "Bioconductor Team\nProgram in Computational Biology\nFred Hutchinson Cancer Research Center\n",
        "url": {}
      }
    ],
    "date": "2009-06-01",
    "categories": [],
    "contents": "\n\nWe are pleased to announce Bioconductor 2.4, released on April 21, 2009.\nBioconductor 2.4 is compatible with R 2.9.0, and consists of 320\npackages. There are 28 new packages, and enhancements to many others.\nExplore Bioconductor at http://bioconductor.org, and install packages\nwith\n> source(\"http://bioconductor.org/biocLite.R\")\n> biocLite() # install standard packages...\n> biocLite(\"IRanges\") # ...or IRanges\n1 New packages\nThis release includes powerful new packages for diverse areas of\nhigh-throughput analysis, including:\nRefined differential expression\n\npower analysis, pre-processing and error estimation\n(SSPA,\ndyebias,\nspkTools,\nRmagpie,\nMCRestimate).\n\nFlow cytometry\n\ntools for data import\n(flowflowJo)\nand auto-gating\n(flowStats).\n\nAdvanced clustering and gene selection\n\napproaches\n(Rmagpie,\nMCRestimate,\nGeneSelectMMD,\ntspair,\nmetahdep,\nbetr).\n\nProbabilistic graphical models\n\nfor reverse engineering regulatory networks\n(qpgraph).\n\nPathway analysis\n\nusing novel approaches\n(KEGGgraph,\ngeen2pathway,\nGOSemSim,\nSPIA).\n\nTechnology-specific\n\npackages\n(AffyTiling,\nrMAT,\ncrlmm,\nGeneRegionScan).\n\nInterfaces\n\nto data base and other external resources\n(biocDatasets,\nPAnnBuilder,\nDAVIDQuery).\n\n2 Annotation\nBioconductor ‘annotation’ packages contain biological information about\nmicroarray probes and the genes they are meant to interrogate, or\ncontain ENTREZ gene based annotations of whole genomes. This release\nupdates existing database content, and lays the groundwork for 4 new\nspecies: Pan troglodytes, Macaca mulatta, Anopheles gambiae and\nXenopus laevis. These species will be available in the development\nbranch starting in May. In addition, the ‘yeast’ package now contains\nNCBI identifiers. A similarly enhanced Arabidopsis package will be in\nthe development branch in May.\n3 High-throughput sequencing\nThe stable of tools for high-throughput sequence analysis has developed\nconsiderably during this release cycle, particularly data structures and\nmethods for conveniently navigating this complex data. Examples include\nthe IRanges and related classes and methods for manipulating ranged\n(interval-based) data, the Rle class and its rich functionality for\nrun-length encoded data (e.g., genome-scale ‘pileup’ or coverage data),\nthe XDataFrame class allowing data frame-like functionality but with\nmore flexible column types (requiring only that the column object have\nmethods for length and subsetting), and the GenomeData and\nGenomeDataList objects and methods for manipulating collections of\nstructured (e.g., by chromosome or locus) data. The\nBiostrings\npackage continues to provide very flexible pattern matching facilities,\nwhile\nShortRead\nintroduces new I/O functionality and the generation of HTML-based\nquality assessment reports from diverse data sources.\n4 Other activities\nBioconductor package maintainers and the Bioconductor team invest\nconsiderable effort in producing high-quality software. A focus during\ndevelopment of Bioconductor 2.4 has been on more consistent and\nwidespread use of name spaces and package imports. These changes reduce\n‘collisions’ between user and package variable names, and make package\ncode more robust. The Bioconductor team continues to ensure quality\nsoftware through technical and scientific reviews of new packages, and\ndaily builds of released packages on Linux, Windows, and Macintosh\nplatforms. The Bioconductor web site is also evolving. Bioconductor\n‘views’ describing software functionality have been re-organized, and\npackage vignettes, reference manuals, and use statistics are readily\naccessible from package home pages.\n5 Looking forward\nThe Bioconductor community will meet on July 27-28 at our annual\nconference in Seattle for a combination of scientific talks and hands-on\ntutorials. The active Bioconductor mailing lists\n(http://bioconductor.org/docs/mailList.html) connect users with each\nother, to domain experts, and to maintainers eager to ensure that their\npackages satisfy the needs of leading edge approaches.\nThis will be a dynamic release cycle. New contributed packages are\nalready under review, and our build machines have started tracking the\nlatest development versions of R. In addition to development of\nhigh-quality algorithms to address microarray data analysis, we\nanticipate continued efforts to leverage diverse external data sources\nand to meet the challenges of presenting high volume data in rich\ngraphical contexts.\n\n\nBioconductor packages used\nSSPA, dyebias, spkTools, Rmagpie, MCRestimate, flowflowJo, flowStats, GeneSelectMMD, tspair, metahdep, betr, qpgraph, KEGGgraph, geen2pathway, GOSemSim, SPIA, AffyTiling, rMAT, crlmm, GeneRegionScan, biocDatasets, PAnnBuilder, DAVIDQuery, Biostrings, ShortRead\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2009-1-chinese-r-conf/",
    "title": "Conference Review: The 1st Chinese R Conference",
    "description": "The 'Conference Review: The 1st Chinese R Conference' article from the 2009-1 issue.",
    "author": [
      {
        "name": "Yihui Xie",
        "url": {}
      }
    ],
    "date": "2009-06-01",
    "categories": [],
    "contents": "\n\nThe first Chinese R conference took place at the Renmin University of\nChina (RUC), Beijing, China, December 13 – 14, 2008. The conference was\norganized and sponsored by the Center for Applied Statistics, RUC, and\nco-organized by the School of Statistics, RUC. Yihui Xie served as the\nchair of the conference and program committee; Qingping Zhang and Haoyu\nYu were in charge of local arrangements.\nDue to the lack of communication among Chinese R users in the past as\nwell as increasing need of using and learning R for users in China, this\npioneer meeting mainly focused on\nintroducing and popularizing R as a powerful tool for statistical\ncomputation and graphics;\ngathering Chinese R users and promoting communication between\ndifferent disciplines and industries;\nNearly 150 participants from 70 institutions all over China met in\nBeijing and heard 25 talks in the two-day conference, among which we\nwere honored to meet several Chinese pioneer useRs such as Prof Xizhi Wu\n(who was the first person introducig R in the School of Statistics, RUC\nmore than 7 years ago) and Guohui Ding (who contributed a lot of work in\ntranslating R manuals). Besides, we have also gained various support\nfrom overseas leading R/S people such as Richard Becker, John Maindonald\n(who was invited and tried to give a remote talk at the conference via\nSkype!) and Kurt Hornik.\nThe conference program included 13 sessions on several topics:\nOpening\n\nintroduction of the first R conference by Yihui Xie and opening\naddress by Prof Xizhi Wu;\n\nIntroduction to R\n\nhistory and development of R by Guohui Ding and Yihui Xie\nrespectively, and R basics by Sizhe Liu;\n\nStatistics Basics\n\nsurvey data analysis by Peng Zhan and statistical simulation by Tan\nXi;\n\nBiostatistics\n\nintroduction to Bioconductor and its application in bioinformatics\nby Gang Chen, application of R in genetics by Liping Hou, and\nresearch on biological competition by Hong Yu;\n\nData Mining\n\ndata mining with R by John Maindonald and Yihui Xie, introduction to\nvarious data mining methods in R by Sizhe Liu, and R in business\nintelligence by Jian Li;\n\nStatistical Models\n\nquantile regression in R by Chen Zuo;\n\nBayesian Statistics\n\nintroduction to Bayesian statistics in R by Peng Ding;\n\nStatistical Computation\n\noptimization in R by Taiyun Wei, and simulation and inference of\nstochastic differential equations using R by Yanping Chen;\n\nSoftware Development\n\nR web applications by Chongliang Li, and integration of R with\nMicrosoft Office via R (D)COM server by Jian Li;\n\nR in Industries\n\nvisualization of complex system by Xiang Zhang, fitting and\nprojections of mortality stochastic models based on R and Excel by\nYunmei Weng, and statistics and R in semiconductor industry by Ming\nLiu;\n\nTeaching\n\nintroduction to the R package\nanimation by Yihui\nXie;\n\nKaleidoscope\n\napplication of R on hydrological modeling by Huaru Wang, turning\nfrom SAS to R by Jian Wang, using R in Quantitative\nStructure-Activity Relationship by Bin Ma, exploring irregular data\nwith R by Yihui Xie;\n\nPublication\n\ndiscussion of publishing R-related materials in China by Xiaojie\nHan;\n\nParticipants were really amazed to see the wide applications of R and\nmade warm discussions after each presentation; session chairs often\ntried hard to control the time for discussion. This has reflected the\nstrong need of learning and using R for Chinese users.\nIn the end, we decided to make future efforts on\nfilling the gaps between statistics and other disciplines with the\nhelp of R;\nlocalization of R, e.g. form a special group to translate more\nmaterials on R;\npublishing more Chinese books and papers on R so that users could\nget started more easily (after this conference, there will be\nproceedings for publication);\nAll slides and pictures can be found in this Chinese web page:\nhttp://cos.name/2008/12/1st-chinese-r-conference-summary/. This\nconference was partially supported by the website http://cos.name,\nwhich is one of the largest statistical websites and main places for R\nhelp in China (see the board “S-Plus &\nR” in the forum). We look\nforward to the next R conference in China and warmly welcome more people\n(including overseas friends) to attend it.\n\n\nCRAN packages used\nanimation\nCRAN Task Views implied by cited packages\nReproducibleResearch, TeachingStatistics\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2009-1-cran/",
    "title": "Changes on CRAN",
    "description": "The 'Changes on CRAN' article from the 2009-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2009-06-01",
    "categories": [],
    "contents": "\n\nPublishing a source package on CRAN now adds the publication date and\nthe repository name (CRAN) to the package , and standardizes the license\nspecification if possible.\n1 CRAN package web\nThe CRAN package web pages (remember that these gained persistent URLs\nof the form\n\nhttp://CRAN.R-project.org/package=foo\n\nin early 2008) have again been enhanced.\nIf available, package citation (from , suitably HTMLified), installation\n(from a top-level file), classification ( Classification/ACM,\nClassification/JEL and Classification/MSC fields with subject\nclassifications using the Computing Classification System of the\nAssociation for Computing Machinery, the Journal of Economic Literature\nClassification System, and the Mathematics Subject Classification of the\nAmerican Mathematical Society, respectively) and language ( Language\nfield) information is now linked from the package web page.\nIn addition, the direct reverse dependencies of the package (i.e., the\nCRAN packages which depend on, import, suggest or enhance the package)\nare shown at the bottom of the package web page.\nStandardizable license specifications are fully hyperlinked to the\nrespective license texts.\nAll CRAN (HTML) web pages should now be valid XHTML.\n2 New contributed packages\nAIGIS\n\nAreal Interpolation for GIS data. Can be used to interpolate\nspatially associated data onto arbitrary target polygons which lack\nsuch data. Version 1.0 of the package is oriented toward convenient\ninterpolation of specific US census data for California, but the\ntools provided should work for any combination of GIS data source\nand target polygon, provided appropriate care is taken. Future\nversions will be aimed at facilitating more general applications. By\nBenjamin P. Bryant and Anthony Westerling.\n\nAnimal\n\nFunctions for analyzing animal (including human) behavior data\noriginating from a variety of sources, including functions to\nanalyze time coded behaviors from CowLog (open source software for\ncoding behaviors from digital video) data files and observation\nfiles with similar format. Other features include hourly, daily,\nweekly and monthly summaries of time coded data, analysis of RIC\n(roughage intake system, Insentec automation) data files and\nlabeling measurement data according to behavioral observations for\ne.g. model building purposes. By Matti Pastell.\n\nAquaEnv\n\nAn integrated development toolbox for aquatic chemical model\ngeneration focused on (ocean) acidification and CO\\(_2\\) air-water\nexchange. Contains all elements necessary to model the pH, the\nrelated CO\\(_2\\) air-water exchange, as well as aquatic acid-base\nchemistry in general for an arbitrary marine, estuarine or\nfreshwater system. Chemical batches can be modeled as well. In\naddition to the routines necessary to calculate desired information,\nAquaEnv also\ncontains a suite of tools to visualize this. Furthermore,\nAquaEnv can not only\nbe used to build dynamic models of aquatic systems, but can also\nserve as a simple desktop tool for the experimental aquatic chemist\nto generate and visualize all possible derived information from a\nset of measurements with one single easy to use R function. By\nAndreas F. Hofmann, Karline Soetaert, and Filip J. R. Meysman.\n\nBAMD\n\nBayesian association model for genomic data with missing covariates.\nFits a linear mixed model where the covariates for the random\neffects have missing values. By V. Gopal, Z. Li and G. Casella.\n\nBAS\n\nBayesian model averaging using Bayesian Adaptive Sampling. Performs\nBMA in linear models using stochastic or deterministic sampling\nwithout replacement from posterior distributions. Prior\ndistributions on coefficients are from Zellner’s \\(g\\)-prior or\nmixtures of \\(g\\)-priors corresponding to the Zellner-Siow Cauchy\nPriors or the Liang et al. hyper-\\(g\\) priors. Other model selection\ncriterion include AIC and BIC. Sampling probabilities may be updated\nbased on the sampled models. By Merlise Clyde, with contributions\nfrom Michael Littman.\n\nBGSIMD\n\nBlock Gibbs Sampler with Incomplete Multinomial Distribution.\nImplements an efficient block Gibbs sampler with incomplete data\nfrom a multinomial distribution taking values from the \\(k\\)\ncategories \\(1,2,\\ldots,k\\), where data are assumed to miss at random\nand each missing datum belongs to one and only one of \\(m\\) distinct\nnon-empty proper subsets \\(A_1, A_2, \\ldots, A_m\\) of \\(1,2,\\ldots,k\\)\nand the \\(k\\) categories are labeled such that only consecutive \\(A\\)’s\nmay overlap. By Kwang Woo Ahn and Kung-Sik Chan.\n\nBMN\n\nApproximate and exact methods for pairwise binary Markov models. The\nexact method uses an implementation of the junction tree algorithm\nfor binary graphical models. By Holger Hoefling.\n\nBSagri\n\nStatistical methods for safety assessment in agricultural field\ntrials. By Frank Schaarschmidt.\n\nBayesDA\n\nFunctions for Bayesian Data Analysis, with data sets from the book\n“Bayesian Data Analysis” (second edition) by Gelman, Carlin, Stern\nand Rubin. (Not all data sets yet.) Compiled by Kjetil Halvorsen.\n\nBayesX\n\nR Utilities Accompanying the BayesX software package for structured\nadditive regression. Provides functionality for exploring and\nvisualizing estimation results obtained with BayesX. Also provides\nfunctions that allow to read, write and manipulate map objects that\nare required in spatial analyses performed with BayesX. By Thomas\nKneib, Felix Heinzl, Andreas Brezger, and Daniel Sabanes Bove.\n\nCADFtest\n\nPerforms Hansen’s (1995) Covariate-Augmented Dickey-Fuller (CADF)\ntest. The \\(p\\)-values of the test are computed using a procedure\nproposed in Costantini, Lupi and Popp (2007), illustrated in Lupi\n(2008). By Claudio Lupi.\n\nCHNOSZ\n\nCalculation of the standard molal thermodynamic properties and\nchemical affinities of reactions between and among minerals,\ninorganic, organic, and/or biomolecular aqueous and crystalline\nspecies. Incorporation of an extensive database of thermodynamic\nproperties of species and algorithms for computing the standard\nthermodynamic properties of neutral and ionized proteins from amino\nacid group contributions. Generation of chemical speciation and\npredominance diagrams for stable and metastable equilibrium in open\nsystems as a function of temperature, pressure, and chemical\nactivities or fugacities of basis species. By Jeffrey M. Dick.\n\nClinicalRobustPriors\n\nRobust Bayesian priors in clinical trials. Fuquene, Cook, &\nPericchi (2008) (http://www.bepress.com/mdandersonbiostat/paper44)\nmake a comprehensive proposal putting forward robust, heavy-tailed\npriors over conjugate, light-tailed priors in Bayesian analysis. The\nbehavior of Robust Bayesian methods is qualitatively different from\nConjugate and short tailed Bayesian methods and arguably much more\nreasonable and acceptable to the practitioner and regulatory\nagencies. This package is useful to compute the distributions\n(prior, likelihood and posterior) and moments of the robust models:\nCauchy/Binomial, Cauchy/Normal and Berger/Normal. Both Binomial and\nNormal Likelihoods can be handled. Furthermore, allows assessment of\nthe hyper-parameters and posterior analysis. By A. Jairo and P.\nFuquene.\n\nConvCalendar\n\nConverts between the \"Date\" class and d/m/y for several calendars,\nincluding Persian, Islamic, and Hebrew. By ‘Project Pluto’\n(www.projectpluto.com/calendar)\nand Thomas Lumley.\n\nCvM2SL1Test\n\n\\(L_1\\) version of Cramer-von Mises two sample tests. Contains\nfunctions for computing the Cramer-von Mises two sample test scores\nand the exact \\(p\\)-value(s) for given test score(s) under the\nassumption that the populations under comparison have the same\nprobability distribution. The \\(L_1\\) Cramer-von Mises test, like its\n\\(L_2\\) counterpart, is distribution-free, but of less computational\nintensity. In certain cases, this version of Cramer-von Mises test\nis almost as powerful as its \\(L_2\\) counterpart. Simulation studies\nalso show that it is more powerful than the Kolmogorov-Smirnov test\nin certain cases. By Yuanhui Xiao and Ye Cui.\n\nDAKS\n\nData Analysis and Knowledge Spaces. Functions and example data sets\nfor the psychometric theory of knowledge spaces. Implements data\nanalysis methods and procedures for simulating data and transforming\ndifferent formulations in knowledge space theory. By Anatol Sargin\nand Ali Ünlü.\n\nDSpat\n\nSpatial modeling for distance sampling data. Provides functions for\nfitting spatial models to line transect sampling data and to\nestimate abundance within a region. By Devin Johnson, Jeff Laake,\nand Jay VerHoef.\n\nDTK\n\nFunctions for conducting and plotting Dunnett’s modified\nTukey-Kramer pairwise multiple comparison test accounting for\nunequal variance and unequal sample sizes. By Matthew K. Lau.\n\nDepela\n\nImplements semiparametric estimation of copula models, and deals\nwith structural break problems in copula modeling. By Andrew C. Chou\nand Jing Tao.\n\nEMJumpDiffusion\n\nEstimate parameters for Jump Diffusion processes via the EM\nalgorithm. The jump times are considered to be Bernoulli distributed\nwith normally distributed jump sizes. By Matthias Graser.\n\nEngrExpt\n\nData sets from Nelson, Coffin and Copeland “Introductory Statistics\nfor Engineering Experimentation” (Elsevier, 2003) with sample code.\nR port by Douglas Bates and Karen A. F. Copeland.\n\nExPD2D\n\nExact computation of bivariate projection depth based on Fortran\ncode. By Yijun Zuo and Xiangyang Ye.\n\nFBN\n\nFISH Based Normalization and copy number (CN) inference of SNP\nmicroarray data. Normalizes the data from a file containing the raw\nvalues of the SNP probes of microarray data by using the FISH probes\nand their corresponding CNs. By Adrian Andronache and Luca Agnelli.\n\nFD\n\nMeasuring functional diversity (FD) from multiple traits. Computes\ndifferent multidimensional FD indices. Implements a distance-based\nframework to measure FD that allows any number and type of\nfunctional traits, and can also consider species relative\nabundances. By Etienne Lalibert�.\n\nFKF\n\nFast Kalman Filter. A flexible implementation entirely written in C\nand fully relying on linear algebra subroutines contained in BLAS\nand LAPACK. Due to the speed of the filter, the fitting of\nhigh-dimensional linear state space models to large data sets\nbecomes possible. Also contains a function for the visualization of\nthe state vector and graphical diagnostics of the residuals. By\nDavid Lüthi and Philipp Erb.\n\nFSelector\n\nFunctions for selecting attributes from a given data set. Attribute\nsubset selection is the process of identifying and removing as much\nof the irrelevant and redundant information as possible. By Piotr\nRomanski.\n\nFactoClass\n\nMultivariate exploration of a data table with factorial analysis and\ncluster methods. By Campo Elías Pardo and Pedro César del Campo,\nwith contributions from Ivan Diaz and Mauricio Sadinle.\n\nFormula\n\nInfrastructure for extended formulas (e.g., with two parts on the\nright hand side). By Yves Croissant and Achim Zeileis.\n\nGFMaps\n\nVisualization technique for interpretation of high-throughput\ngenetic or proteomic experiments. Integrates data sets derived from\ngene expression profiles with preexisting information from public\ndatabases such as KEGG pathway or Gene Ontology using Gene Set\nEnrichment Analysis (GSEA) and introduces a framework allowing to\nvisualize biologically annotated data sets and relevant ratings of\ngenes via a color gradient. By Sanjay Bhatikar and Kanika Arora.\n\nGRRGI\n\nGauge R and R Confidence Intervals. Generates confidence intervals\nfor the variance components in Gauge R and R data using ANOVA with\nthe Satterthwaite approximation as well as the method of Generalized\nInference. By Walter Resch, with information from “Measurement\nSystem Assessment Via Generalized Inference” by Michael Hamada and\nSam Weerandi.\n\nGridR\n\nExecutes functions on remote hosts, clusters or grids. In addition,\nusers are provided with an interface to share variables and\nfunctions with other users. By Dennis Wegener, Malte Lohmeyer and\nStefan Rüping.\n\nHadoopStreaming\n\nA framework for writing map/reduce scripts for use in Hadoop\nStreaming. Also facilitates operating on data in a streaming\nfashion, without Hadoop. By David S. Rosenberg.\n\nHaploSim\n\nSimulate haplotypes through meioses. Allows specification of\npopulation parameters. By Albart Coster, John Bastiaansen.\n\nLIM\n\nFunctions that read and solve Linear Inverse Model (food web, linear\nprogramming) problems, which find solutions to linear or quadratic\nfunctions: min or max \\(f(x)\\), where \\(f(x) =  ||Ax-b||^2\\) or \\(f(x) = \\sum a_i x_i\\) subject to equality\nconstraints \\(Ex=f\\) and inequality constraints \\(Gx \\ge h\\). Uses\npackage limSolve.\nBy Karline Soetaert and Dick van Oevelen.\n\nLambertW\n\nLambert \\(W\\) parameter estimation, plots, simulation. Lambert \\(W\\)\nrandom variables offer a new way of dealing with slightly skewed\ndata. By Georg M. Goerg.\n\nLearnEDA\n\nFunctions for Learning Exploratory Data Analysis. By Jim Albert.\n\nMAMSE\n\nCalculation of the nonparametric Minimum Averaged Mean Squared Error\n(MAMSE) weights for univariate, right-censored or multivariate data.\nThe MAMSE weights can be used in a weighted likelihood or to define\na mixture of empirical distribution functions. By Jean-François\nPlante.\n\nMCE\n\nTools for evaluating Monte Carlo Error. Has functions to estimate MC\nerror in simulation studies, and functions helping with planning the\nnumber of replications required in a simulation study to reach a\nspecified level of certainty. By Elizabeth Koehler and Sebastien\nHaneuse.\n\nMCMCglmm\n\nMCMC Generalized Linear Mixed Models. By Jarrod Hadfield.\n\nMixSim\n\nSimulate data to study performance of clustering algorithms. By\nVolodymyr Melnykov, Wei-Chen Chen and Ranjan Maitra.\n\nModelMap\n\nCreate random forest and stochastic gradient boosting models, and\napply them to GIS files to build detailed prediction maps. Validates\nthe models with an independent test set, cross validation, or in the\ncase of random forest Models, with out of bag (OOB) predictions on\nthe training data. Creates graphs and tables of the model validation\nresults, and applies the models to GIS files of predictors to create\ndetailed prediction surfaces. Handles large predictor files for map\nmaking via chunking. By Elizabeth Freeman and Tracey Frescino.\n\nMulticlasstesting\n\nPerformance of \\(N\\)-ary classification testing. By C. Nardini and\nY.-H. Liu.\n\nNMRS\n\nNMR Spectroscopy. Developed to directly load spectra in the Bruker\nspectroscopy format. Displays the spectrum reference and manages\nbasic operations such as setting the chemical shift of a certain\ncompound (TSP or DSS) to 0 ppm, zero order and first order phase\ncorrections, baseline adjustment and spectral area selection. By\nJosé L. Izquierdo.\n\nOAIHarvester\n\nHarvest metadata using the Open Archives Initiative Protocol for\nMetadata Harvesting (OAI-PMH) version 2.0. By Kurt Hornik.\n\nOncotree\n\nOncogenetic trees: functions to construct and evaluate directed tree\nstructures that model the process of occurrence of genetic\nalterations during carcinogenesis. By Aniko Szabo and Lisa Pappas.\n\nOrdFacReg\n\nLeast squares, logistic, and Cox-regression with ordered predictors.\nIn biomedical studies, researchers are often interested in assessing\nthe association between one or more ordinal explanatory variables\nand an outcome variable, at the same time adjusting for covariates\nof any type. The outcome variable may be continuous, binary, or\nrepresent censored survival times. In the absence of a precise\nknowledge of the response function, using monotonicity constraints\non the ordinal variables improves efficiency in estimating\nparameters, especially when sample sizes are small. This package\nimplements an active set algorithm that efficiently computes such\nestimators. By Kaspar Rufibach.\n\nOrdMonReg\n\nCompute least squares estimates of one bounded or two ordered\nantitonic regression curves. Consider the problem of estimating two\nantitonic regression curves \\(f_1\\) and \\(f_2\\) under the constraint\nthat \\(f_1 \\ge f_2\\). Given two sets of \\(n\\) data points\n\\(g_1(x_1), \\ldots, g_1(x_n)\\) and \\(g_2(x_1), \\ldots, g_2(x_n)\\) that\nare observed at (the same) deterministic points \\(x_1, \\ldots, x_n\\),\nthe estimates are obtained by minimizing the Least Squares criterion\n\\(L(f_1, f_2) = \\sum_{i=1}^n (g_1(x_i) - f_1(x_i))^2 w_1(x_i) +  \\sum_{i=1}^n (g_2(x_i) - f_2(x_i))^2 w_2(x_i)\\) over the class of\npairs of functions \\((f_1, f_2)\\) such that \\(f_1\\) and \\(f_2\\) are\nantitonic and \\(f_1(x_i) \\ge f_2(x_i)\\) for all \\(i = 1, \\ldots, n\\).\nThe estimates are computed with a projected subgradient algorithm\nwhere the projection is calculated using a PAVA. By Fadoua\nBalabdaoui, Kaspar Rufibach, and Filippo Santambrogio.\n\nPMA\n\nPerforms Penalized Multivariate Analysis: a penalized matrix\ndecomposition, sparse principal components analysis, and sparse\ncanonical correlation analysis, described in “A penalized matrix\ndecomposition, with applications to sparse principal components and\ncanonical correlation analysis” by Witten, Tibshirani and Hastie\n(2009). By Daniela Witten and Rob Tibshirani.\n\nPairViz\n\nVisualization using Eulerian tours and Hamiltonian decompositions.\nBy C. B. Hurley and R. W. Oldford.\n\nPhViD\n\nPharmacovigilance signal detection methods extended to the multiple\ncomparison setting. Functions can be used as standard R functions or\nthrough an user friendly interface (PhViD.gui). By Ismail Ahmed and\nAntoine Poncet.\n\nRDS\n\nFunctionality for carrying out estimation with data collected using\nRespondent-Driven Sampling. Current functionality is extremely\nlimited. By W. Whipple Neely.\n\nREQS\n\nR/EQS Interface. Contains the function run.eqs() which calls an\nEQS script file, executes the EQS estimation, and, finally, imports\nthe results as R objects. These two steps can be performed\nseparately: call.eqs() calls and executes EQS, whereas\nread.eqs() imports existing EQS outputs as objects into R. By\nPatrick Mair and Eric Wu.\n\nRHRV\n\nHeart rate variability analysis of ECG data. By M. Lado, A.\nMéndez, D. Olivieri, L. Rodrı́guez-Liñares, and X. Vila.\n\nRMTstat\n\nDistributions and statistics from Random Matrix Theory. Functions\nfor working with the Tracy-Widom laws and other distributions\nrelated to the eigenvalues of large Wishart matrices. The tables for\ncomputing the Tracy-Widom densities and distribution functions were\ncomputed by Momar Dieng’s MATLAB package ‘RMLab’\n(http://math.arizona.edu/~momar/research.htm). By Patrick O.\nPerry, with contributions from Iain M. Johnstone, Zongming Ma, and\nMorteza Shahram.\n\nROptEstOld\n\nOptimally robust estimation using S4 classes and methods. Old\nversion still needed for current versions of\nROptRegTS and\nRobRex. By Matthias\nKohl.\n\nRQDA\n\nR-based Qualitative Data Analysis, currently only supporting plain\ntext. By Huang Ronggui.\n\nRSiteSearch\n\nAlternative interfaces to RSiteSearch. By Sundar Dorai-Raj, Romain\nFrançois and Spencer Graves.\n\nRSurvey\n\nAnalysis of Spatially Distributed Data. Processes such data and is\ncapable of error corrections and data visualization. Also provides a\ngraphical user interface. By Jason C. Fisher.\n\nRcmdrPlugin.SurvivalT\n\nAn Rcmdr plug-in based\non the survival\npackage for easier student access to survival analysis. By Daniel\nLeucuta.\n\nRcmdrPlugin.orloca\n\nAn Rcmdr plugin\nproviding a GUI for the\norloca package. By\nFernando Fernández-Palacı́n and Manuel Muñoz-Márquez.\n\nRcmdrPlugin.qcc\n\nAn Rcmdr plug-in based\non the qcc package,\nproviding an integration between the user and the tools of SPC. By\nRenan Cortes, with contributions of I. Prestes and Suzi Camey.\n\nRcmdrPlugin.survival\n\nAn Rcmdr plug-in for\nthe survival\npackage, with dialogs for Cox models, parametric survival regression\nmodels, estimation of survival curves, and testing for differences\nin survival curves, along with data-management facilities and a\nvariety of tests, diagnostics and graphs. By John Fox.\n\nRcpp\n\nRcpp R/C++ interface classes and examples. Maps data types between R\nand C++, and includes support for R types real, integer, character,\nvector, matrix, \"Date\", Date-Time (i.e., \"POSIXct\") at\nmicrosecond resolution, data frame, and function. Also supports\ncalling R functions from C++. By Dirk Eddelbuettel, with\ncontributions by Simon Urbanek and David Reiss.\n\nRcsdp\n\nR interface to the CSDP semidefinite programming library. Installs\nversion 6.0.1 of CSDP from the COIN-OR website if required. An\nexisting installation of CSDP may be used by passing the proper\nconfigure arguments to the installation command. By Hector Corrada\nBravo (CSDP by Brian Borchers).\n\nRgoogleMaps\n\nOverlays on Google map tiles in R. Serves two purposes: (i) provide\na comfortable R interface to query the Google server for static\nmaps, and (ii) use the map as a background image to overlay plots\nwithin R. By Markus Loecher.\n\nRlabkey\n\nImport data from a labkey database into an R data frame. By Valerie\nObenchain.\n\nRxCEcolInf\n\n\\(R \\times C\\) Ecological Inference With optional incorporation of\nsurvey information. Fits the \\(R \\times C\\) inference model described\nin Greiner and Quinn (2009). By D. James Greiner, Paul Baines, and\nKevin M. Quinn.\n\nSDaA\n\nFunctions and data sets from “Sampling: Design and Analysis” S. Lohr\n(1999), Duxbury. By Tobias Verbeke.\n\nSEMModComp\n\nModel Comparisons for structural equation modeling (SEM). Conduct\ntests of difference in fit for mean and covariance structure models\nas in SEM. By Roy Levy.\n\nSGCS\n\nSpatial Graph based Clustering Summaries for spatial point patterns.\nBy Tuomas Rajala.\n\nSMIR\n\nCompanion to “Statistical Modelling in R” by Aitkin et al (2009),\nOxford University Press. By Murray Aitkin, Brian Francis, John\nHinde, and Ross Darnell.\n\nScottKnott\n\nMultiple comparison test of means using the clustering method of\nScott & Knott. By Enio Jelihovschi, José Cláudio Faria, and Sérgio\nOliveira.\n\nSimComp\n\nSimultaneous Comparisons (tests and confidence intervals) for\ngeneral linear hypotheses when there is more than one primary\nresponse variable (endpoint). The procedure of Hasler (2009) is\napplied for differences or ratios of means of normally distributed\ndata. The covariance matrices (containing the covariances between\nthe endpoints) may be assumed to be equal or possibly unequal for\nthe different groups. By Mario Hasler.\n\nSpectralGEM\n\nDiscovering Genetic Ancestry Using Spectral Graph Theory. By Ann\nLee, Diana Luca, Bert Klei, Bernie Devlin, and Kathryn Roeder.\n\nStatFingerprints\n\nProcessing and statistical analysis of molecular fingerprint\nprofiles. By Rory Michelland and Laurent Cauquil.\n\nStem\n\nEstimation of the parameters of a spatio-temporal model using the EM\nalgorithm, estimation of the parameter standard errors using a\nspatio-temporal parametric bootstrap, and spatial mapping. By\nMichela Cameletti.\n\nSubpathwayMiner\n\nAnnotation and identification of the KEGG pathways. Facilitates\nsub-pathway annotation and identification of metabolic pathways.\nAlso provides annotation and identification of entire pathways. By\nChunquan Li.\n\nSweaveListingUtils\n\nUtilities for Sweave together with the TeX listings package.\nFeatures defining R/Rd as a listings “language” and including R/Rd\nsource files (snippets) copied from R-Forge in its most recent\nversion (or another URL) thereby avoiding inconsistencies between\nvignette and documented source code. By Peter Ruckdeschel.\n\nTRIANG\n\nDiscrete triangular distributions, which complete the classical\ndiscrete distributions like binomial, Poisson and Negative binomial.\nBy Tristan Senga Kiessé, Silvio S. Zocchi, and Célestin C.\nKokonendji.\n\nTSPostgreSQL\n\nTime Series database interface (TSdbi) extensions for PostgreSQL. By\nPaul Gilbert.\n\nTSfame\n\nTime Series database interface (TSdbi) extensions for fame. By Paul\nGilbert.\n\nTShistQuote\n\nTime Series database interface (TSdbi) extensions for\nget.hist.quote to retrieve data from historical quote URLs. By\nPaul Gilbert.\n\nTSodbc\n\nTime Series database interface (TSdbi) extensions for ODBC. By Paul\nGilbert.\n\nTeachingSampling\n\nFoundations of inference in survey sampling. By Hugo Andrés\nGutiérrez Rojas.\n\nVarianceGamma\n\nThe Variance Gamma Distribution. Provides density, distribution and\nquantile functions. In addition, there are also functions for random\nnumber generation and fitting of the variance gamma to data. By\nDavid Scott and Christine Yang Dong.\n\nWaveCGH\n\nWavelet Changepoint Detection for Array CGH. Detects changepoints\nand finds gain/loss regions. By M. S. Islam and A. I. McLeod.\n\nWriteXLS\n\nCross-platform Perl based R function to create Excel 2003 () files\nfrom one or more data frames. Each data frame will be written to a\nseparate named worksheet in the Excel spreadsheet. The worksheet\nname will be the name of the data frame it contains. By Marc\nSchwartz.\n\nYourCast\n\nMakes time series cross-sectional forecasts with multiple\ncross-sections based on your assumptions given a variety of\nsmoothing assumptions based on similarities among the levels or\ntrends in the expected value of the dependent variable rather than\nthe coefficients. By Federico Girosi, Gary King, and Elena Villalon.\n\nafc\n\nCalculate the Generalized Discrimination Score, also known as Two\nAlternatives Forced Choice Score (2AFC). By Andreas Weigel.\n\nagreement\n\nInvestigate agreement between two measurement methods using a\nsimulation approach. By Fabio Frascati and Bruno Mario Cesana.\n\nalphahull\n\nComputes the alpha-shape and alpha-convex hull of a given sample of\npoints in the plane. These concepts generalize the definition of the\nconvex hull of a finite set of points. The programming is based on\nthe duality between the Voronoi diagram and Delaunay triangulation.\nAlso includes a function that returns the Delaunay mesh of a given\nsample of points and its dual Voronoi diagram in one single object.\nBy Beatriz Pateiro-López and Alberto Rodrı́guez-Casal.\n\namei\n\nAdaptive Management of Epidemiological Interventions. Provides a\nflexible statistical framework for generating optimal\nepidemiological interventions that are designed to minimize the\ntotal expected cost of an emerging epidemic while simultaneously\npropagating uncertainty regarding underlying disease parameters\nthrough to the decision process via Bayesian posterior inference.\nThe strategies produced through this framework are adaptive:\nvaccination schedules are iteratively adjusted to reflect the\nanticipated trajectory of the epidemic given the current population\nstate and updated parameter estimates. By Daniel Merl, Leah R.\nJohnson, Robert B. Gramacy, and Marc Mangel.\n\narchetypes\n\nA framework for archetypal analysis supporting arbitrary problem\nsolving mechanisms for the different conceptual parts of the\nalgorithm. (Used as real-world test application for the Roxygen\ndocumentation system.) By Manuel J. A. Eugster.\n\narulesNBMiner\n\nAn implementation of the model-based mining algorithm for\nNB-frequent itemsets presented in “A model-based frequency\nconstraint for mining associations from transaction data” by M.\nHahsler (Data Mining and Knowledge, 2006). In addition, implements\nan extension for NB-precise rules. By Michael Hahsler.\n\nascii\n\nExport R objects to asciidoc or txt2tags. Comes with two drivers for\nSweave. By David Hajage.\n\naspect\n\nAspects of Multivariables. Consists of two main functions:\ncorAspect() performs optimal scaling by maximizing an aspect\n(i.e., target function such as sum of eigenvalues, sum of squared\ncorrelations, squared multiple correlations, etc.) of the\ncorresponding correlation matrix. lineals() performs optimal\nscaling by minimizing a non-correlational aspect based on pairwise\ncorrelations and correlation ratios. The resulting correlation\nmatrix and category scores can be used for further multivariate\nmethods such as SEM. A platform including related\nPsychoR packages is\nprovided on R-forge. By Jan de Leeuw and Patrick Mair.\n\nasympTest\n\nAsymptotic testing. By the Cqls Team.\n\nautomap\n\nPerforms automatic interpolation by automatically estimating the\nvariogram and then calling\ngstat. By Paul\nHiemstra.\n\naylmer\n\nA generalization of Fisher’s exact test that allows for structural\nzeros. By Robin K. S. Hankin (R) and Luke G. West (C++).\n\nbayesCGH\n\nBayesian analysis of array CGH data. A set of methods for Bayesian\nanalysis of proportions of chromosomal changes within clinical sets.\nBy Thomas Hardcastle.\n\nbayesclust\n\nTests/Searches for significant clusters in genetic data. By V.\nGopal, C. Fuentes and G. Casella.\n\nbeanplot\n\nVisualization via beanplots (univariate comparison graphs providing\nan alternative to boxplot, stripcharts and violin plots). By Peter\nKampstra.\n\nbethel\n\nThe sample size according to the Bethel’s procedure. By Michele De\nMeo.\n\nbinarySimCLF\n\nSimulate correlated binary data using an algorithm based on Qaqish\n(2003). By Kunthel By and Bahjat F. Qaqish.\n\nblockmodeling\n\nGeneralized and classical blockmodeling of valued networks. In\naddition, measures of similarity or dissimilarity based on\nstructural equivalence and regular equivalence (REGE algorithm) can\nbe computed and partitioned matrices can be plotted. By Ales\nZiberna.\n\nbootspecdens\n\nBootstrap for testing the hypothesis that the spectral densities of\na number \\(m \\ge 2\\) of not necessarily independent time series are\nequal. By Tatjana Kinsvater.\n\ncanvas\n\nR graphics device targeting the HTML canvas element. Implements the\nCanvasRenderingContext2D JavaScript API. By Jeffrey Horner.\n\nccems\n\nCombinatorially Complex Equilibrium Model Selection. Dissociation\nconstants of quasi-equilibriums of enzymes and protein-ligand\nbinding equilibriums in general are systematically scanned though\npossibilities of being infinity and/or equal to others. The\nautomatically generated space of models is then fitted to data. By\nTom Radivoyevitch.\n\ncellVolumeDist\n\nImplements a methodology for using cell volume distributions to\nestimate cell growth rates and division times as described in “Cell\nVolume Distributions Reveal Cell Growth Rates and Division Times” by\nMichael Halter, John T. Elliott, Joseph B. Hubbard, Alessandro Tona\nand Anne L. Plant (Journal of Theoretical Biology). By\nKatharine M. Mullen, Michael Halter, John Lu and Nathan Dodder.\n\nclinsig\n\nFunctions for calculating clinical significance. By Jim Lemon.\n\nclues\n\nA clustering method based on local shrinking. Contains functions for\nautomatically estimating the number of clusters and obtaining the\nfinal cluster partition without any input parameter except the\nstopping rule for convergence. Also provides functions to evaluate\nand compare the performances of partitions of a data set both\nnumerically and graphically. By Fang Chang, Vincent Carey, Weiliang\nQiu, Ruben H. Zamar, Ross Lazarus, and Xiaogang Wang.\n\ncorcounts\n\nGenerate high-dimensional correlated count random variables with a\nprespecified Pearson correlation. By Vinzenz Erhardt.\n\ncrawl\n\nThe (C)orrelated (RA)ndom (W)alk (L)ibrary of R functions for\nfitting continuous-time correlated random walk (CTCRW) models with\ntime indexed covariates. The model is fit using the Kalman-Filter on\na state space version of the continuous-time stochastic movement\nprocess. By Devin S. Johnson.\n\ndepth\n\nDepth functions methodology applied to multivariate analysis. Allows\ncalculation of depth values and depth-based location estimators, and\nincludes functions for drawing contour plots and perspective plots\nof depth functions. By Jean-Claude Massé and Jean-François Plante.\n\ndiffusionMap\n\nImplements the diffusion map method of data parametrization,\nincluding creation and visualization of diffusion map and\ncourse-graining using diffusion \\(K\\)-means. By Joseph Richards and\nAnn Lee.\n\ndiseasemapping\n\nCalculate SMR’s from population and case data. Works with regular\ndata set files and shape files. By Patrick Brown.\n\ndlmap\n\nDetection Localization Mapping for QTL. By Emma Huang and Andrew\nGeorge.\n\ndyad\n\nAnalysis of dyadic observational data. Contains original\nimplementation of the Gottman-Murray marriage model and revisions\nusing threshold autoregressive models. These programs allow modeling\nof dyadic observational data, such as interaction between husband\nand wife. Intended for researchers interested in modeling social\nbehavior. By Tara Madhyastha and Ellen Hamaker.\n\ndynCorr\n\nComputes dynamical correlation estimates and percentile bootstrap\nconfidence intervals for pairs of longitudinal responses, including\nconsideration of lags and derivatives. By Joel Dubin, Dandi Qiao,\nand Hans-Georg Müller.\n\nelec\n\nA bizarre collection of functions written to do various sorts of\nstatistical election audits. There are also functions to generate\nsimulated voting data, and simulated “truth” so as to do simulations\nto check characteristics of these methods. By Luke Miratrix.\n\nemplik2\n\nEmpirical likelihood test (two-sample, censored data). Calculates\nthe \\(p\\)-value for a mean-type hypothesis (or multiple mean-type\nhypotheses) based on two samples. By William H. Barton, under the\nsupervision of Mai Zhou.\n\nexams\n\nSweave-based automatic generation of standardized exams for\nlarge-lecture courses, with multiple-choice questions and arithmetic\nproblems. By Achim Zeileis and Bettina Grün.\n\nez\n\nFacilitates the analysis of factorial experiments, including purely\nwithin-Ss designs (a.k.a. “repeated measures”), purely between-Ss\ndesigns, and mixed within-and-between-Ss designs. The functions in\nthis package provide easy access to descriptive statistics, ANOVA,\npermutation tests, and visualization of results. By Michael A.\nLawrence.\n\nfast\n\nImplementation of the Fourier Amplitude Sensitivity Test (FAST), a\nmethod to determine global sensitivities of a model on parameter\nchanges with relatively few model runs. By Dominik Reusser.\n\nfechner\n\nFunctions and example data sets for Fechnerian scaling of discrete\nobject sets. Computes Fechnerian distances among objects\nrepresenting subjective dissimilarities, and other related\ninformation. By Thomas Kiefer and Ali Ünlü, based on original MATLAB\nsource by Ehtibar N. Dzhafarov.\n\nfishmethods\n\nFishery methods and models from Quinn and Deriso (1999), Haddon\n(2001), and literature. By Gary A. Nelson.\n\nfit4NM\n\nExploratory analysis for pharmacometrics via the NONMEM platform. By\nEun-Kyung Lee, Gyujeong Noh, and Hyeong-Seok Lim.\n\nfitdistrplus\n\nHelp to fit of a parametric distribution to non-censored or censored\ndata. Censored data may contain left censored, right censored and\ninterval censored values, with several lower and upper bounds. By\nMarie Laure Delignette-Muller, Régis Pouillot, and Jean-Baptiste\nDenis.\n\nflashClust\n\nImplementation of optimal hierarchical clustering. Code by Fionn\nMurtagh, packaging by Peter Langfelder.\n\nfoba\n\nGreedy variable selection via forward, backward, and foba sparse\nlearning algorithms for ridge regression, described in “Adaptive\nForward-Backward Greedy Algorithm for Learning Sparse\nRepresentations”. By Tong Zhang.\n\nfpow\n\nCompute the noncentrality parameter of the noncentral \\(F\\)\ndistribution for given probabilities of type I and type II error and\ndegrees of freedom of the numerator and the denominator. May be\nuseful for computing minimal detectable differences for general\nANOVA models. The program is documented in “On the computation of\nthe noncentral \\(F\\) and noncentral beta distribution” by A. Baharev\nand S. Kemeny (Statistics and Computing, 2008,\nhttp://dx.doi.org/10.1007/s11222-008-9061-3). By Ali Baharev.\n\nfutile\n\nA collection of utility functions to expedite software development.\nBy Brian Lee Yung Rowe.\n\ngcExplorer\n\nGraphical Cluster Explorer. Visualize cluster results and\ninvestigate additional properties of clusters using interactive\nneighborhood graphs. By clicking on the node representing the\ncluster, information about the cluster is provided using additional\ngraphics or summary statistics. For microarray data, tables with\nlinks to genetic databases like gene ontology can be created for\neach cluster. By Theresa Scharl, Ingo Voglhuber, and Friedrich\nLeisch.\n\ngof\n\nModel diagnostics based on cumulative residuals. By Klaus K. Holst.\n\ngogarch\n\nGeneralized Orthogonal GARCH (GO-GARCH) models. By Bernhard Pfaff.\n\ngputools\n\nProvides R interfaces to a handful of common data-mining algorithms\nimplemented in parallel using a mixture of nVidia’s CUDA language\nand cublas library. On a computer equipped with an nVidia GPU these\nfunctions may be substantially more efficient than native R\nroutines. By Josh Buckner, with contributions from Justin Wilson.\n\ngraphicsQC\n\nQuality Control for Graphics in R. Provides functions to generate\ngraphics files, compare them with “model” files, and report the\nresults. By Stephen Gardiner and Paul Murrell.\n\ngrpreg\n\nEfficient algorithms for fitting the regularization path for linear\nor logistic regression models penalized by the group lasso, group\nbridge, or group MCP methods. The algorithm is based on the idea of\na locally approximated coordinate descent. A technical report\ndescribing the methods and algorithms is available at\nhttp://www.stat.uiowa.edu/techrep/tr393.pdf. By Patrick Breheny.\n\nhacks\n\nConvenient R Functions. By Nathan Stephens and Vicky Yang.\n\nhash\n\nImplements a data structure using R environments similar to hashes\nin Perl and dictionaries in Python but with a purposefully R flavor.\nBy Christopher Brown.\n\nhexbin\n\nBinning and plotting functions for hexagonal bins. Now uses and\nrelies on grid graphics\nand formal (S4) classes and methods. By Dan Carr, ported by Nicholas\nLewin-Koh and Martin Mächler.\n\nhyperdirichlet\n\nA suite of routines for the hyperdirichlet distribution. By\nRobin K. S. Hankin.\n\nimprProbEst\n\nMinimum distance estimation in an imprecise probability model. The\nimprecise probability model consists of upper coherent previsions\nwhose credal sets are given by a finite number of constraints on the\nexpectations. The parameter set is finite. The estimator chooses\nthat parameter such that the empirical measure lies next to the\ncorresponding credal set with respect to the total variation norm.\nBy Robert Hable.\n\ninfluence.ME\n\nA collection of tools for calculating measures of influential data\nfor mixed effects models. The basic rationale behind identifying\ninfluential data is that when iteratively single units are omitted\nfrom the data, models based on these data should not produce\nsubstantially different estimates. To standardize the assessment of\nhow influential a (single group of) observation(s) is, several\nmeasures of influence are common practice. First, DFBETAS is a\nstandardized measure of the absolute difference between the estimate\nwith a particular case included and the estimate without that\nparticular case. Second, Cook’s distance provides an overall\nmeasurement of the change in all parameter estimates, or a selection\nthereof. By Rense Nieuwenhuis, Ben Pelzer, and Manfred te\nGrotenhuis.\n\nintrogress\n\nAnalysis of introgression of genotypes between divergent,\nhybridizing lineages, including estimation of genomic clines from\nmulti-locus genotype data and testing for deviations from neutral\nexpectations. Functions are also provided for maximum likelihood\nestimation of molecular hybrid index and graphical analysis. By\nZachariah Gompert and C. Alex Buerkle.\n\nipptoolbox\n\nUncertainty quantification and propagation in the framework of\nDempster-Shafer Theory and imprecise probabilities. By Philipp\nLimbourg.\n\nirtProb\n\nUtilities and probability distributions related to multidimensional\nperson Item Response Models (IRT). By Gilles Raiche.\n\nisotone\n\nActive set and generalized PAVA for isotone optimization. Contains\ntwo main functions: gpava() solves general isotone regression\nproblem using the pool-adjacent-violators algorithm (PAVA).\nactiveSet() provides a framework of active set methods for isotone\noptimization problems. Various loss functions are pre-specified. By\nJan de Leeuw, Kurt Hornik, and Patrick Mair.\n\njointDiag\n\nAlgorithms to perform approximate joint diagonalization of a finite\nset of square matrices. Depending on the algorithm, an orthogonal or\nnon-orthogonal diagonalizer is found. These algorithms are\nparticularly useful in the context of blind source separation. By\nCédric Gouy-Pailler.\n\nkst\n\nKnowledge Space Theory: a set-theoretical framework which proposes\nmathematical formalisms to operationalize knowledge structures in a\nparticular domain. Provides basic functionalities to generate,\nhandle, and manipulate knowledge structures and knowledge spaces. By\nChristina Stahl and David Meyer.\n\nlabeltodendro\n\nConvert labels or tables to a dendrogram, offering a dendrogram\nrepresentation of series of labels as especially needed in Markov\nChain Monte Carlo clustering. By Vahid Partovi Nia, Anthony Davison\nand Arpit Chaudhary.\n\nlatticist\n\nA graphical user interface for exploratory visualization. Primarily\nan interface to the Lattice graphics system, but also produces\ndisplays from the vcd\npackage for categorical data. Given a multivariate data set (either\na data frame or a table), it attempts to produce useful displays\nbased on the properties of the data. The displays can be customized\nby editing the calls used to generate them. By Felix Andrews.\n\nlcd\n\nLearn Chain graphs (and as a special case, Bayesian networks) via\nDecomposition. By Zongming Ma and Xiangrui Meng.\n\nlcda\n\nLatent Class Discriminant Analysis: local discrimination via latent\nclass models. By Michael Buecker.\n\nlmec\n\nLinear Mixed-Effects Models with Censored Responses. Fits a linear\nmixed-effects model in the formulation described in Laird and\nWare (1982) but allowing for censored normal responses. In this\nversion, the within group errors are assumed independent and\nidentically distributed. By Florin Vaida and Lin Liu.\n\nlmodel2\n\nComputes model II simple linear regression using ordinary least\nsquares (OLS), major axis (MA), standard major axis (SMA), and\nranged major axis (RMA). By Pierre Legendre.\n\nlmomRFA\n\nFunctions for regional frequency analysis using the methods in\n“Regional frequency analysis: an approach based on L-moments”\nby J. R. M. Hosking and J. R. Wallis (1997). By J. R. M. Hosking.\n\nlocaldepth\n\nSimplicial, Mahalanobis and ellipsoid local and global depth. By\nClaudio Agostinelli and Mario Romanazzi.\n\nlongRPart\n\nRecursive partitioning of longitudinal data using mixed-effects\nmodels. By Sam Stewart and Mohamed Abdolell.\n\nmapReduce\n\nA flexible mapReduce framework for parallel computation.\nProvides (a) a pure R implementation, (b) a syntax following the\nmapReduce paper, and (c) a flexible and parallelizable back end. By\nChristopher Brown.\n\nmarkerSearchPower\n\nCalculates statistical power of detecting associated markers based\non one of the model selection strategies: marginal selection,\nexhaustive search, or forward selection. With assumed genetic\neffects (including interaction effect), allele frequencies, noise\nlevel, sample size, number of genotyped markers, and control level\n(i.e., number of markers/models intended to select), this package\nprovides fast and accurate consultation on power of different model\nselection strategies. It helps researchers to decide a more\nefficient way for marker detection in genome-wide association\nstudies. By Zheyang Wu and Hongyu Zhao.\n\nmc2d\n\nVarious distributions and utilities to build and study\ntwo-dimensional Monte Carlo simulations. By Régis Pouillot, Marie\nLaure Delignette-Muller and Jean-Baptiste Denis.\n\nmcsm\n\nA collection of functions that allows the reenactment of the R\nprograms used in the book “EnteR Monte Carlo Methods” without\nfurther programming. Programs can also be modified by the user to\nconduct one’s own simulations. By Christian P. Robert.\n\nmedAdherence\n\nMedication Adherence: commonly used definitions. By Xiangyang Ye.\n\nmetaMA\n\nMeta-analysis for MicroArrays. Combines either \\(p\\)-values or\nmodified effect sizes from different studies to find differentially\nexpressed genes. By Guillemette Marot.\n\nmetacor\n\nMeta-analysis of correlation coefficients. Implement the\nDerSimonian-Laird (DSL) and Olkin-Pratt (OP) meta-analytical\napproaches with correlation coefficients as effect sizes. By Etienne\nLaliberté.\n\nmhsmm\n\nParameter estimation and prediction for hidden Markov and\nsemi-Markov models for data with multiple observation sequences. The\ntimes must be equidistant but missing values of the observables are\nallowed. The observables are allowed to be multivariate. It is\npossible to have multiple sequences of data. Estimation of the\nparameters of the models are made using EM-algorithms.\nComputationally demanding parts of the algorithm are implemented in\nC for performance. Finally, the package is designed to allow users\nto specify their own emission distributions, giving flexibility in\nthe type of data that may be analyzed. By Jared O’Connell and Søren\nHøjsgaard.\n\nminxent\n\nImplements entropy optimization distribution under specified\nconstraints. Also offers an R interface to the MinxEnt and MaxEnt\ndistributions. By Senay Asma.\n\nmixAK\n\nContains a mixture of statistical methods including MCMC methods to\nanalyze normal mixtures. By Arnošt Komárek.\n\nmixRasch\n\nMixture Rasch Models with JMLE. Estimates mixture Rasch models,\nincluding the dichotomous Rasch model, the rating scale model, and\nthe partial credit model. By John T. Willse.\n\nmmcm\n\nProvides an implementation of the Modified Maximum Contrast Method.\nThe current version features function mmcm.resamp which gives\n\\(p\\)-values for the modified maximum contrast statistics by using a\nresampling based procedure. By Kengo Nagashima and Yasunori Sato.\n\nmulticore\n\nProvides a way of running parallel computations in R on machines\nwith multiple cores or CPUs, and methods for results collection.\nJobs can share the entire initial workspace. By Simon Urbanek.\n\nmuscor\n\nMUlti-Stage COnvex Relaxation. Solves a number of convex/non-convex\nsparse regularization formulations for regression or binary\nclassification using the algorithm described in “Multi-stage Convex\nRelaxation for Learning with Sparse Regularization”. Loss functions\ninclude least squares, logistic, truncated ls/huber. By Tong Zhang.\n\nmvgraph\n\nMultivariate interactive visualization. By Moritz Gschwandtner.\n\nmvtBinaryEP\n\nGenerates correlated binary data based on the method of Emrich and\nPiedmonte (1991). By Kunthel By and Bahjat Qaqish.\n\nnleqslv\n\nSolve a system of non linear equations using a Broyden or a Newton\nmethod with a choice of global strategies such as linesearch and\ntrust region. There are options for using a numerical or an\nanalytical Jacobian and fixed or automatic scaling of parameters. By\nBerend Hasselman.\n\noperators\n\nA set of operators for common tasks such as regex manipulation. By\nRomain François.\n\northogonalsplinebasis\n\nOrthogonal \\(B\\)-spline basis functions. Represents the basis\nfunctions via a simple matrix formulation that facilitates taking\nintegrals, derivatives, and orthogonalizing the basis functions. By\nAndrew Redd.\n\nparcor\n\nEstimates the matrix of partial correlations based on different\nregularized regression methods: lasso, adaptive lasso, PLS, and\nRidge Regression. By Nicole Krämer and Juliane Schäfer.\n\npartDSA\n\nPartitioning using deletion, substitution, and addition moves, a\nnovel tool for generating a piecewise constant estimation list of\nincreasingly complex predictors based on an intensive and\ncomprehensive search over the entire covariate space. By Annette\nMolinaro, Karen Lostrito, and Steve Weston.\n\npedigree\n\nPedigree related functions. By Albart Coster.\n\npenalizedSVM\n\nFeature selection SVM using penalty functions. The smoothly clipped\nabsolute deviation (SCAD) and \\(L_1\\) norm penalties are available up\nto now. By Natalia Becker, Wiebke Werft, and Axel Benner.\n\nphmm\n\nProportional Hazards Mixed-effects Model (PHMM). Fits PHMMs using an\nEM algorithm using Markov Chain Monte Carlo at the E-step. By\nMichael Donohue and Ronghui Xu.\n\nplan\n\nTools for project planning. Supports the creation of burndown\ncharts. By Dan Kelley.\n\nplotpc\n\nPlot principal component histograms around a bivariate scatter plot.\nBy Stephen Milborrow.\n\nplspm\n\nPartial Least Squares (PLS) methods with emphasis on structural\nequation models with latent variables. By Gaston Sanchez.\n\npolydect\n\nFunctions for one-dimension jump position detection using one-sided\npolynomial kernel detectors (polynomial order from 0 to 3). By\nZhihua Su.\n\npowerGWASinteraction\n\nRoutines for power calculations for interactions for GWAS. By\nCharles Kooperberg.\n\npowerSurvEpi\n\nFunctions to calculate power and sample size for testing main effect\nor interaction effect in the survival analysis of epidemiological\nstudies (non-randomized studies), taking into account the\ncorrelation between the covariate of the interest and other\ncovariates. Some calculations also take into account the competing\nrisks. Also includes functions to calculate power and sample size\nfor testing main effect in the survival analysis of randomized\nclinical trials. By Weiliang Qiu, Jorge Chavarro, Ross Lazarus,\nBernard Rosner, and Jing Ma.\n\nprefmod\n\nUtilities to fit paired comparison models for preferences. Generates\ndesign matrix for analyzing real paired comparisons and derived\npaired comparison data (Likert type items, ratings or rankings)\nusing a log-linear approach. Fits log-linear Bradley-Terry model\n(LLBT) exploiting an eliminate feature. Computes pattern models for\npaired comparisons, rankings, and ratings. Some treatment of missing\nvalues (MCAR and MNAR). By Reinhold Hatzinger.\n\nprimer\n\nFunctions and data for the forthcoming book “A Primer of Ecology\nwith R”. Functions are primarily for systems of ordinary\ndifferential equations, difference equations, and eigenanalysis and\nprojection of demographic matrices; data are for examples. By M.\nHenry H. Stevens.\n\npspearman\n\nSpearman’s rank correlation test with improved accuracy. By Petr\nSavicky.\n\nqtlbook\n\nDatasets for the book “A guide to QTL Mapping with R/qtl”. By\nKarl W. Broman.\n\nrSymPy\n\nInterface to access the SymPy computer algebra system running under\nJython from R. By G. Grothendieck.\n\nrbenchmark\n\nBenchmarking routine for R. Inspired by the Perl module Benchmark,\nand intended to facilitate benchmarking of arbitrary R code.\nConsists of just one function, benchmark, which is a simple\nwrapper around system.time. Given a specification of the\nbenchmarking process (counts of replications, evaluation\nenvironment) and an arbitrary number of expressions, benchmark\nevaluates each of the expressions in the specified environment,\nreplicating the evaluation as many times as specified, and returning\nthe results conveniently wrapped into a data frame. By Wacek\nKusnierczyk.\n\nrcdklibs\n\nProvides the CDK libraries for use with R. To make use of the CDK\nwithin R, using the\nrcdk package, which\nexposes functionality in a more idiomatic way, is suggested;\nhowever, it is also possible to directly interact with CDK using\nrJava. By Rajarshi\nGuha.\n\nrconifers\n\nFunctions for simulating future forest conditions using the CONIFERS\ngrowth model. By Jeff D. Hamann and Martin W. Ritchie.\n\nrela\n\nItem analysis with alpha standard error and principal axis factoring\nfor continuous variable scales. By Michael Chajewski.\n\nremMap\n\nRegularized Multivariate Regression for Identifying Master\nPredictors. Developed for fitting multivariate response regression\nmodels under the high-dimension-low-sample-size setting. By Jie\nPeng, Pei Wang, and Ji Zhu.\n\nreporttools\n\nGenerate LaTeX tables of descriptive statistics. Especially helpful\nwhen writing data analysis reports using Sweave. By Kaspar Rufibach.\n\nrgrs\n\nFunctions for beginners and social sciences students or researchers.\nCurrently includes functions for cross-tabulation, weighting,\nresults export, and maps plotting. Documentation and help pages are\nwritten in French. By Julien Barnier.\n\nrngwell19937\n\nRandom number generator WELL19937a by F. Panneton, P. L’Ecuyer\nand M. Matsumoto with initialization using MRG32k5a by P. L’Ecuyer.\nWELL19937a is of similar type as Mersenne Twister and has the same\nperiod. It is slightly slower than Mersenne Twister, but has better\nequidistribution and “bit-mixing” properties and faster recovery\nfrom states with prevailing zeros than Mersenne Twister. The output\nfunction may be set to provide numbers with 53 or 32 random bits. By\nPetr Savicky.\n\nrobCompositions\n\nMethods for the imputation of compositional data including robust\nmethods, (robust) outlier detection for compositional data, (robust)\nprincipal component analysis for compositional data, (robust) factor\nanalysis for compositional data, and (robust) Anderson-Darling\nnormality tests for compositional data. By Matthias Templ, Karel\nHron, and Peter Filzmoser.\n\nrsm\n\nFunctions to generate response-surface designs, fit first- and\nsecond-order response-surface models, make contour plots, obtain the\npath of steepest ascent, and do canonical analysis. By Russell V.\nLenth.\n\nrtv\n\nConvenient representation and manipulation of realizations of Random\nTime Variables. By Charlotte Maia.\n\nsabreR\n\nStatistical analysis of multi-process random effect response data by\nproviding SABRE functionality from within R. Responses can take the\nform of binary, ordinal, count and linear recurrent events. Response\nsequences can be of different types. Such multi-process data is\ncommon in many research areas, e.g., the analysis of work and life\nhistories. May be used for analyzing longitudinal data sets surveys\neither with recurrent information collected over time or with a\nclustered sampling scheme. By R. Crouchley.\n\nscout\n\nImplements the Scout method for regression, described in\n“Covariance-regularized regression and classification for\nhigh-dimensional problems” by Witten and Tibshirani (2008, Journal\nof the Royal Statistical Society, Series B). By Daniela M. Witten\nand Robert Tibshirani.\n\nsda\n\nShrinkage Discriminant Analysis and feature selection. Provides an\nefficient framework for high-dimensional linear and diagonal\ndiscriminant analysis with feature selection. The classifier is\ntrained using Stein-type shrinkage estimators and features are\nranked using correlation-adjusted \\(t\\)-scores. Feature selection is\ncontrolled using false non-discovery rates or higher criticism\nscores. By Miika Ahdesmäki and Korbinian Strimmer.\n\nsdcTable\n\nStatistical disclosure control for tabular data. By Bernhard Meindl.\n\nsdtoolkit\n\nScenario Discovery Tools to support robust decision making.\nCurrently only implements a modified version of the Patient Rule\nInduction Method. By Benjamin P. Bryant.\n\nselectiongain\n\nCalculates the gain from a model selection, using part of\nTallis’ (1961) algorithm. By Xuefei Mi, Xuefei Mi, and Friedrich\nUtz.\n\nsimone\n\nStatistical Inference for MOdular NEtworks (SIMoNe). Iteratively\ncombines edge estimation and node classification on the basis of a\nmixture model for edge weight distributions. Edge inference may be\nmanaged via two alternative methods: GLasso and the\nMeinshausen-Bühlmann approach. Node Classification is managed by\nMixNet, a mixture model for random graphs. By Christophe Ambroise,\nJulien Chiquet, Gilles Grasseau, and Alexander Adam Smith.\n\nsisus\n\nStable Isotope Sourcing using Sampling: source partitioning using\nstable isotopes. By Erik Barry Erhardt.\n\nsparseLDA\n\nSparse linear discriminant analysis for gaussians and mixture of\ngaussians models. By Line Clemmensen, with contributions by Max\nKuhn.\n\nspatialsegregation\n\nFunctionals and indices for measuring segregation in multitype\nspatial point patterns with graph based neighborhood description.\nIncluded indices: Mingling, Shannon, Simpson; functionals: Mingling,\nShannon, Simpson, ISAR; neighborhoods: Geometric, \\(k\\)-nearest\nneighbors, Gabriel, Delauney. By Tuomas Rajala.\n\nspcosa\n\nSPatial COverage SAmpling and random sampling from compact\ngeographical strata created by \\(k\\)-means. By D. J. J.\nWalvoort, D. J. Brus, and J. J. de Gruijter.\n\nspls\n\nSparse Partial Least Squares (SPLS) regression. By Dongjun Chung,\nHyonho Chun, and Sunduz Keles.\n\nspuRs\n\nFunctions and data sets from “An Introduction to Scientific\nProgramming and Simulation, Using R”. By Owen Jones, Robert\nMaillardet, Andrew Robinson, Olga Borovkova, and Steven Carnie.\n\nsurvcomp\n\nFunctions to assess and compare the performance of risk prediction\n(survival) models. By Benjamin Haibe-Kains, Christos Sotiriou, and\nGianluca Bontempi.\n\ntawny\n\nProvides various portfolio optimization strategies including random\nmatrix theory and shrinkage estimators. Portfolio optimization\ntypically requires an estimate of a covariance matrix of asset\nreturns. There are many approaches for constructing such a\ncovariance matrix, some using the sample covariance matrix as a\nstarting point. This package provides implementations for two such\nmethods: random matrix theory and shrinkage estimation. Each method\nattempts to clean or remove noise related to the sampling process\nfrom the sample covariance matrix. By Brian Lee Yung Rowe.\n\nwasim\n\nHelpful tools for data processing and visualization of results of\nthe hydrological model WASIM-ETH. By Dominik Reusser, Till Francke.\n\ntimeDate\n\nChronological and calendarical objects for Rmetrics environment for\nteaching “Financial Engineering and Computational Finance”. By\nDiethelm Würtz and Yohan Chalabi.\n\ntimeSeries\n\nFinancial time series objects for the Rmetrics environment for\nteaching “Financial Engineering and Computational Finance”. By\nDiethelm Würtz and Yohan Chalabi.\n\ntlemix\n\nTrimmed maximum likelihood estimation: a general framework for\nrobust fitting of finite mixture models. Parameter estimation is\nperformed using the EM algorithm. By P. Neytchev, P. Filzmoser, R.\nPatnaik, A. Eisl and R. Boubela.\n\ntmvtnorm\n\nComputes truncated multivariate normal probabilities, quantiles and\ndensities, including one-dimensional marginal densities. By Stefan\nWilhelm.\n\ntruncnorm\n\nTrunctated normal distribution. By Heike Trautmann, Detlef Steuer,\nand Olaf Mersmann.\n\ntslars\n\nLeast angle regression for time series analysis. By Sarah Gelper.\n\nucminf\n\nAn algorithm for general-purpose unconstrained non-linear\noptimization. The algorithm is of quasi-Newton type with BFGS\nupdating of the inverse Hessian and soft line search with a trust\nregion type monitoring of the input to the line search algorithm.\nThe interface of\nucminf is designed\nfor easy interchange with optim. By Hans Bruun Nielsen and Stig\nBousgaard Mortensen.\n\nuniCox\n\nUnivarate shrinkage prediction for survival analysis using in the\nCox model. Especially useful for high-dimensional data, including\nmicroarray data. By Rob Tibshirani.\n\nvowels\n\nManipulation, normalization, and plotting of phonetic and\nsociophonetic vowel formant data. Used as the backend for the NORM\nwebsite. By Tyler Kendall and Erik R. Thomas.\n\nvrmlgen\n\nTranslates numerical data into 3-dimensional representations like 3D\nscatter plots, meshes, bar charts and graphs in the Virtual Reality\nMarkup Language (VRML). By Enrico Glaab.\n\nwasim\n\nHelpful tools for data processing and visualization of results of\nthe hydrological model WASIM-ETH. By Dominik Reusser, Till Francke.\n\nx12\n\nA wrapper function and GUI for the X12 binaries under Windows. By\nAlexander Kowarik.\n\nxterm256\n\nSupport for xterm256 escape sequences, enabling R functions to take\nadvantage of foreground color, background color, in capable\nterminals. By Romain François.\n\nyacca\n\nYet Another Canonical Correlation Analysis package. Provides an\nalternative canonical correlation/redundancy analysis function, with\nassociated print, plot, and summary methods. A method for generating\nhelio plots is also included. By Carter T. Butts.\n\nzyp\n\nZhang and Yue-Pilon trends package. Contains an efficient\nimplementation of Sen’s slope method plus implementation of Xuebin\nZhang’s (Zhang, 1999) and Yue-Pilon’s (Yue, 2002) prewhitening\napproaches to determining trends in climate data. By David Bronaugh\nand Arelia Werner for the Pacific Climate Impacts Consortium.\n\n3 Other changes\nPackage Matrix is\nrecommended for R \\(\\ge\\) 2.9.0.\nBundle SciViews was\nmoved to the Archive and is replaced by its unbundled packages\n(svGUI,\nsvIDE,\nsvMisc, and\nsvSocket).\nPackages DDHFm,\nGeneTS,\nLLN,\nProbForecastGOP,\nProbeR,\nRlab,\nRmdr,\nRmetrics,\nSparseLogReg,\ncaretLSF,\ncaretNWS,\nclassPP,\nfemmeR,\ngllm,\nknnFinder,\nintcox,\nmlica,\nmlmmm,\nmota,\npARtial,\nrggm,\nsdtalt,\nsurvBayes, and\nwaveclock were\nmoved to the Archive.\nFrontend gnomeGUI\nwas moved to the Archive.\n\n\nCRAN packages used\nAIGIS, Animal, AquaEnv, BAMD, BAS, BGSIMD, BMN, BSagri, BayesDA, BayesX, CADFtest, CHNOSZ, ClinicalRobustPriors, ConvCalendar, CvM2SL1Test, DAKS, DSpat, DTK, Depela, EMJumpDiffusion, EngrExpt, ExPD2D, FBN, FD, FKF, FSelector, FactoClass, Formula, GFMaps, GRRGI, GridR, HadoopStreaming, HaploSim, LIM, limSolve, LambertW, LearnEDA, MAMSE, MCE, MCMCglmm, MixSim, ModelMap, Multiclasstesting, NMRS, OAIHarvester, Oncotree, OrdFacReg, OrdMonReg, PMA, PairViz, PhViD, RDS, REQS, RHRV, RMTstat, ROptEstOld, ROptRegTS, RobRex, RQDA, RSiteSearch, RSurvey, RcmdrPlugin.SurvivalT, Rcmdr, survival, RcmdrPlugin.orloca, orloca, RcmdrPlugin.qcc, qcc, RcmdrPlugin.survival, Rcpp, Rcsdp, RgoogleMaps, Rlabkey, RxCEcolInf, SDaA, SEMModComp, SGCS, SMIR, ScottKnott, SimComp, SpectralGEM, StatFingerprints, Stem, SubpathwayMiner, SweaveListingUtils, TRIANG, TSPostgreSQL, TSfame, TShistQuote, TSodbc, TeachingSampling, VarianceGamma, WaveCGH, WriteXLS, YourCast, afc, agreement, alphahull, amei, archetypes, arulesNBMiner, ascii, aspect, PsychoR, asympTest, automap, gstat, aylmer, bayesCGH, bayesclust, beanplot, bethel, binarySimCLF, blockmodeling, bootspecdens, canvas, ccems, cellVolumeDist, clinsig, clues, corcounts, crawl, depth, diffusionMap, diseasemapping, dlmap, dyad, dynCorr, elec, emplik2, exams, ez, fast, fechner, fishmethods, fit4NM, fitdistrplus, flashClust, foba, fpow, futile, gcExplorer, gof, gogarch, gputools, graphicsQC, grpreg, hacks, hash, hexbin, grid, hyperdirichlet, imprProbEst, influence.ME, introgress, ipptoolbox, irtProb, isotone, jointDiag, kst, labeltodendro, latticist, vcd, lcd, lcda, lmec, lmodel2, lmomRFA, localdepth, longRPart, mapReduce, markerSearchPower, mc2d, mcsm, medAdherence, metaMA, metacor, mhsmm, minxent, mixAK, mixRasch, mmcm, multicore, muscor, mvgraph, mvtBinaryEP, nleqslv, operators, orthogonalsplinebasis, parcor, partDSA, pedigree, penalizedSVM, phmm, plan, plotpc, plspm, polydect, powerGWASinteraction, powerSurvEpi, prefmod, primer, pspearman, qtlbook, rSymPy, rbenchmark, rcdklibs, rcdk, rJava, rconifers, rela, remMap, reporttools, rgrs, rngwell19937, robCompositions, rsm, rtv, sabreR, scout, sda, sdcTable, sdtoolkit, selectiongain, simone, sisus, sparseLDA, spatialsegregation, spcosa, spls, spuRs, survcomp, tawny, wasim, timeDate, timeSeries, tlemix, tmvtnorm, truncnorm, tslars, ucminf, uniCox, vowels, vrmlgen, x12, xterm256, yacca, zyp, Matrix, SciViews, svGUI, svIDE, svMisc, svSocket, DDHFm, GeneTS, LLN, ProbForecastGOP, ProbeR, Rlab, Rmdr, Rmetrics, SparseLogReg, caretLSF, caretNWS, classPP, femmeR, gllm, knnFinder, intcox, mlica, mlmmm, mota, pARtial, rggm, sdtalt, survBayes, waveclock, gnomeGUI\nCRAN Task Views implied by cited packages\nActuarialScience, Agriculture, Bayesian, ChemPhys, ClinicalTrials, Cluster, Distributions, Econometrics, Environmetrics, Epidemiology, ExperimentalDesign, ExtremeValue, Finance, HighPerformanceComputing, MachineLearning, MetaAnalysis, MissingData, MixedModels, NumericalMathematics, OfficialStatistics, Omics, Optimization, Phylogenetics, Psychometrics, ReproducibleResearch, Robust, Spatial, SpatioTemporal, Survival, TeachingStatistics, TimeSeries, Tracking, WebTechnologies\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2009-1-DSC/",
    "title": "Forthcoming Events: DSC 2009",
    "description": "\"Forthcoming Events: DSC 2009\" published in The R Journal.",
    "author": [
      {
        "name": "Peter Dalgaard",
        "url": {}
      }
    ],
    "date": "2009-06-01",
    "categories": [],
    "contents": "\n\nAs mentioned in the last issue of R News, the sixth international\nworkshop on Directions in Statistical Computing (DSC 2009) will take\nplace at the Center for Health and Society, University of Copenhagen,\nDenmark, 13th–14th of July 2009. For details, see\nhttp://www.R-project.org/dsc-2009.\nThe paper selection process is now complete and the programme\ncommittee have approximately 25 presentations to assemble into a\nFinal Scientific Programme.\nProfessor Tue Tjur from the Copenhagen Business School has been\ninvited to give an opening lecture on statistical computing in the\nOld Days. (This was the teacher who introduced me to GENSTAT 30\nyears ago.)\nThe Social Programme includes an opening mixer at the conference\nvenue on Sunday evening and a Conference dinner on Monday at Furesø\nMarina. (http://marina-en.dk)\nEarly registration closed on May 15. Regular registration is\npossible until July 5.\nThe registration is now handled by a professional congress bureau.\nIn particular, this means that payment by credit card has become\npossible.\nOn behalf of the Organizing Committee,Peter Dalgaard\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2009-1-editorial/",
    "title": "Editorial",
    "description": "The 'Editorial' article from the 2009-1 issue.",
    "author": [
      {
        "name": "Vince Carey",
        "url": {}
      }
    ],
    "date": "2009-06-01",
    "categories": [],
    "contents": "\n\nEarly in the morning of January 7, 2009 — very early, from the\nperspective of readers in Europe and the Americas, as I was in Almaty,\nKazakhstan — I noticed a somewhat surprising title on the front web\npage of the New York Times: “Data Analysts Captivated by R’s Power”.\nMy prior probability that a favorite programming language would find its\nway to the Times front page was rather low, so I navigated to the\narticle to check. There it was: an early version, minus the photographs.\nLater a few nice pictures were added, and a Bits Blog\nhttp://bits.blogs.nytimes.com/2009/01/08/r-you-ready-for-r/ created.\nAs of early May, the blog includes 43 entries received from January 8 to\nMarch 12 and includes comment from Trevor Hastie clarifying historical\nroots of R in S, from Alan Zaslavsky reminding readers of John\nChambers’s ACM award and its role in funding an American Statistical\nAssociation prize for students’ software development, and from numerous\nothers on aspects of various proprietary and non-proprietary solutions\nto data analytic computing problems. Somewhat more recently, the Times\nblog was back in the fold, describing a SAS-to-R interface (February\n16). As a native New Yorker, it is natural for me to be aware, and glad,\nof the Times’ coverage of R; consumers of other mainstream media\nproducts are invited to notify me of comparable coverage events\nelsewhere.\nAs R’s impact continues to expand, R News has transitioned to The R\nJournal. You are now reading the first issue of this new periodical,\nwhich continues the tradition of the newsletter in various respects:\narticles are peer-reviewed, copyright of articles is retained by\nauthors, and the journal is published electronically through an archive\nof freely downloadable PDF issues, easily found on the R project\nhomepage and on CRAN. My role as Editor-In-Chief of this first issue of\nthe new Journal is purely accidental – the transition has been in\ndevelopment for several years now, with critical guidance and support\nfrom the R Foundation, from a number of R Core members, and from\nprevious editors. I am particularly thankful for John Fox’s assistance\nwith this transition, and we are all indebted to co-editors Peter\nDalgaard and Heather Turner for technical work on the new Journal’s\ncomputational infrastructure, undertaken on top of already substantial\ncommitments of editorial effort.\nWhile contemplating the impending step into a new publishing vehicle,\nJohn Fox conceived a series of special invited articles addressing views\nof “The Future of R”. This issue includes two articles in this projected\nseries. In the first, John Chambers analyzes R into facets that help us\nto understand the ‘richness’ and ‘messiness’ of R’s programming model.\nIn the second, Stefan Theußl and Achim Zeileis describe R-Forge, a new\ninfrastructure for contributing and managing source code of packages\ndestined for CRAN. A number of other future-oriented articles have been\npromised for this series; we expect to issue a special edition of the\nJournal collecting these when all have arrived.\nThe peer-reviewed contributions section includes material on programming\nfor diagram construction, HTML generation, probability model\nelicitation, integration of the multivariate normal density, Hilbert\nspectrum analysis, microarray study design, parallel computing support,\nand the predictive modeling markup language. Production of this issue\ninvolved voluntary efforts of 22 referees on three continents, who will\nbe acknowledged in the year-end issue.\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2009-1-r-changes/",
    "title": "Changes in R 2.9.0",
    "description": "The 'Changes in R 2.9.0' article from the 2009-1 issue.",
    "author": [
      {
        "name": "The R Core Team",
        "url": {}
      }
    ],
    "date": "2009-06-01",
    "categories": [],
    "contents": "\n\n1 Changes in R 2.9.0 patched release\nNew features\nnew anyDuplicated(x) returns 0 (= FALSE) or the index of the\nfirst duplicated entry of x.\nmatplot(), matlines() and matpoints() now also obey a ‘lend’\nargument, determining line end styles. (Wish of PR#13619.)\nBug fixes\nThe argument was not handled properly when was found in the\nenclosure of the current function, rather than in the function\nheader itself. (This caused integrate() to fail in certain cases.)\ncol2rgb(\"#00000080\", TRUE) would return the background colour.\n(Reported by Hadley Wickham.)\ninteraction() now ensures that its result’s levels are unique.\npackageDescription() and hence sessionInfo() now report the\ncorrect package version also for a non-attached loaded namespace of\na version different from the default lib.loc.\nsmoothScatter() now also works when e.g. xlim[2] < xlim[1].\nparse_Rd() would mishandle closing braces when they occurred at\nthe start of a line within an R string in an Rd file. (Reported by\nAlex Couture-Beil.)\nreadNEWS() missed version numbers with more than one digit.\nbuilding R no longer fails (PR#13665).\nprintCoefmat(cbind(0,1)) now works too (PR#13677).\n2 Changes in R 2.9.0 initial release\nSignificant user-visible changes\nexpand.grid() by default no longer coerces strings into factors.\nNew features\nPackage Matrix is now\na recommended package contained in the basic R distribution. It\nprovides S4 classes and methods for dense and sparse matrices, often\nby using the numerical libraries Lapack and from the SuiteSparse\ncollection CHOLMOD, CSparse, and SPQR among others.\npdf() and postscript() gain a useKerning argument to place\nstrings using kerning (which had previously been ignored in display\nbut not in strwidth), based in part on an idea and code from Ei-ji\nNakama. The default is TRUE.\nKerning involving spaces is now ignored (it was previously only used\nin the computation of string widths).\nseq.default() and seq.int() ensure that the result is within the\ninterval [from, to] even when the last value would previously have\nbeen slightly out of range because of the allowance for rounding\nerror in computing the number of elements.\nboxplot() gains a simple \"matrix\" method, enabling\nboxplot(mat) instead of boxplot(data.frame(mat)).\nzip.file.extract() gains an optional dir argument (but use\nunzip() instead).\nsource() with encoding specified (and not as \"unknown\") marks\nthe encoding of character strings in Latin-1 and UTF-8 locales.\nparse(text=z) now marks the encoding of character strings in\nLatin-1 and UTF-8 locales if z is of known encoding (that is all\nelements are either ASCII or marked as Latin-1 or UTF-8).\nsprintf() does stricter error checking on input formats to avoid\npassing invalid formats to the OS (which have a tendency to crash\nunder such inputs).\nexpand.grid() gains a stringsAsFactor argument to ask for\nautomatic conversion of character vectors to factors (which happened\nfor many years but was not previously documented, and is no longer\nthe default).\nbxp() now computes the ylim including the outliers only if\noutline = TRUE. (Wish of PR#13196.)\nbarplot() gains a args.legend argument. (Wish of PR#13265.)\nRweaveLatexSetup() now accepts all (and not just some) options\npassed through from Sweave().\ncumsum(x) and cumprod(x) for double precision x now use a long\ndouble accumulator where available and so more closely match sum()\nand prod() in potentially being more accurate.\nplot() methods for \"stepfun\" (and hence \"ecdf\") gain a col\nargument, allowing to set all three colors simultaneously.\nIterating over a factor in a for loop now coerces to a character\nvector (rather than using the integer codes).\ndata.frame() now recycles columns of list arguments, not just\nvectors and factors.\nplot.ts(plot.type=\"multiple\") now makes use of *.lab and\n*.axis graphical parameters (wish of PR#13134 and PR#13135).\nClasses can be exported from a name space using the NAMESPACE file\ndirective which has the same syntax as .\nstrftime() now converts its first argument with as.POSIXlt() and\nso is no longer an alias for format.POSIXLt.\nbody<-() now treats list values consistently with other types:\nthey no longer need to be wrapped in a list() call.\noption(\"pdfbrowser\") is now set on Windows as well as on\nUnix-alikes.\nobject.size() now returns an object of class and has a print()\nmethod.\n[col/row]Sums(), *Means() now have an additional argument, so\nthat they can more easily be turned into generic functions.\nPackage tools contains\ndependsOnPkgs() to compute reverse dependencies.\nStrict type checking is now turned on: this catches more internal\ncorruptions, and some badly written contributed code.\nThere are new functions in package\ntcltk,\ntk_choose.files(), tk_choose.dir() and tk_messageBox(),\nanalogues of functions available on Windows (the last is an analogue\nof winDialog).\nSys.glob() now does tilde expansion on all platforms.\nread.table() and friends gain a fileEncoding argument to make\nre-encoding of input just a little bit simpler.\ngrep() gains an invert argument mimicking .\nstrwrap() now allows a separate prefix for the first line.\ngrep() has a more efficient sibling grepl() that returns a\nlogical vector.\nxfig() has new arguments defaultFont and textSpecial\ncontributed by Sebastian Fischmeister.\nparse() and parse_Rd() now point to syntax errors in the\nreported error context, and include the filename and line and column\nnumbers so smart text editors can jump to the error location.\nstr(<1d-array>) now writes \"[1:n(1d)]\" instead of the previous\nless clear \"[, 1:n]\".\nNew function testInstalledPackage() in package\ntools allows the\nexamples (and if they were installed) any package-specific tests to\nbe run on an installed package.\ntestInstalledPackages() can run all the examples and tests in the\nstandard and/or recommended packages. Also testInstalledBasic()\ncan run the basic tests (if installed).\nfile.copy() now has a recursive argument.\nErrors in setOldClass() will cause a previous definition to be\nrestored.\nAmbiguities in class inheritance and method selection resulting from\nduplicates in superclasses are now resolved by requiring (if\npossible) consistency with all the superclass inheritance. The rules\nfor method selection have been revised to take advantage of the\nimproved ordering. See ?Methods and the reference there related to\ninheritance.\nNew function unzip() in package\nutils to expand or\nlist zip archives.\nReplacement functions for class() and oldClass() will unset the\nS4 bit when the replacement can’t be an S4 object; oldClass() will\nreturn the S3 class for S4 objects with slot .S3Class.\nclip() takes extra steps to avoid the next graphics call resetting\nthe clip region.\nNew function sample.int() to provide documented access to the\ninternal part of sample() (sampling from seq_len(n)).\nNew version of function withVisible() for better handling of cases\nlike withVisible(eval.parent(...)). Moved to package\nbase with a view to\nreplace .Internal(eval.with.vis) in source() later.\nshowClass() which is also used to auto-print class definitions,\nnow mentions the package where the class comes from, if there is\none.\nsimulate(obj) now also works for \"glm\" objects and for weighted\nfits, thanks in part to contributions from Ben Bolker and Heather\nTurner. There is now a means to extend the methods available for\n\"glm\" objects, as glm families can have an optional simulate\ncomponent.\nS4 classes that inherit from any of the \"structure\" classes or\nfrom \"vector\" will turn on methods for all the group of functions\nwhen the package containing the classes is loaded. See\nclass?structure.\nA mechanism now allows S4 classes to inherit from object types\n\"environment\", \"externalptr\" and symbol (\"name\"). See\n?setClass.\ndemo() gains echo and ask arguments, with defaults similar to\nexample().\nlibrary() no longer checks for the packages merged during the\nre-organization of 1.9.0.\nNew function poisson.test() in package\nstats for exact test\nof rates and rate ratios.\nNew function isdebugged() indicates whether its argument has the\ndebug flag set or not.\nls.str() [via print method] now also works when some objects\nin the environment are missing().\nSubsetting S4-objects (without an explicit \"[\" method) no longer\npreserves the class in cases like setClass(\"C\", contains=\"list\");\nThis reverts a “bug fix” activated in R 2.8.0.\n.packages() and .find.packages() no longer check the package\ninfo for installed packages with dumped metadata, since this was\nchecked when the package was installed. .packages() only considers\nsuch packages to be validly installed (any others were installed in\na long-obsolete version of R). Both changes speed up searches in\nlibraries of thousands of packages.\nboxplot() uses butt line endings for its median line (suggestion\nof Uwe Ligges, PR#13553).\nS4 objects passed to a non-default S3 method will be converted to a\nvalid S3 object with the S3 class. See the section on inheriting\nfrom non-S4 classes in ?Classes.\nA new class \"nonStructure\" has been defined; classes that extend a\nvector class but that should lose their slots under or functions\nshould extend this class. See class?nonStructure.\naxis.POSIXct() now plots in the timezone marked for its inputs (if\nany) rather than in the local time. The latter was a deliberate\nchoice, but is easy to select by removing the tzone attribute.\n(Suggestion of Dan Kelley.)\nA new function classesToAM() returns an adjacency matrix\nrepresenting the inheritance of the classes specified. Allows better\nhuman examination of the patterns, e.g. by using the matrix as input\nto one of the graph packages (see the documentation).\nX11options(antialias = \"none\") now works, for consistency with\nX11().\nsprintf() now allows zero-length arguments (with a zero-length\nresult). (Suggestion of Bill Dunlap.)\nunlink() is now able to remove broken symbolic links on\nUnix-alikes.\nNew selectSuperClasses() utility in package\nmethods.\nHoltWinters() now allows parameters alpha and beta to be fixed\nat 0 and hence beta = FALSE and gamma = FALSE are used to\nspecify restricted models.\nA new function smoothScatter() has been added to package\ngraphics. It is\nappropriate for very dense scatter plots and uses density estimation\nand color to reflect density of plotting.\nDeprecated & defunct\nallGenerics() is defunct.\nUse of is defunct and gives an error.\nThe compatibility define for graphics structure in\nGraphicsDevice.h has been removed.\nSupport for versioned installs ( and\ninstall.packages(installWithVers = TRUE)) has been removed.\nPackages installed with versioned names will be ignored.\nThe numeric and power(0.5) forms of argument to make.link()\nwhich were deprecated in 2.4.0 are now defunct: use power()\ndirectly.\nConversion to and by is now defunct.\nSupport for is now defunct (and package\ngnomeGUI has been\nwithdrawn as it used a long-obsolete version of GNOME).\non Windows will call the first target (not ) in Makevars[.win] in\nfuture versions: so make the first target if you have any.\nUtilities\nnow also uses a Makevars[.win] file for cleaning up src/.\nand are now able to cope with Cyrillic characters in UTF-8 if\nenvironment variable _R_CYRILLIC_TEX_ is set to a non-empty value\nand the LaTeX system has suitable fonts (thanks to a hint from\nAlexey Shipunov).\nNew function rtags() in package\nutils that provides\netags-like indexing capabilities for R code files.\nNew front-end script R CMD rtags provides an interface to the\nrtags() function (see for details).\nNew environment variable R_TEXI2DVICMD to hold the path (if any)\nto texi2dvi found at configure time: this now provides the default\nto option(\"texi2dvi\").\nmassage-Examples.pl has been replaced by the R function\ntools:::massageExamples().\nnow uses remove.packages() and hence removes all members of a\nbundle.\nis now an R script and has a new option aka to show what commands\nwould be run. The same code is used on Unix and Windows.\nhas new options and to set the corresponding fields in HTML\nconversion.\nruns the package tests with a custom startup file, currently\ncontaining .\nThose tests are run by an R script: using a tests/Makefile\n(undocumented) no longer works.\nnow knows about and , for use in configure files.\nhas a new option to suppress printing out the session timing.\ncan now work on an installed package.\nno longer loads package\ntcltk when checking\nfor code problems, so more problems may be reported.\nFor on Windows the default target only makes the DLL, and no longer\ncall targets and .\nRd conversion changes\nRd files have an optional \\Rdversion{} section, which if missing\ndefaults to 1.0. There is support for version 1.1, a slightly\nmodified version with the following changes:\n- The warnings for \\code{} inside \\examples are suppressed.\n- Whitespace between arguments in \\item and \\section is\naccepted without a warning (see below).\n- $ is treated literally in text, even for latex conversions.\n- \\ is only an escape before % { } \\ .\n- \\R, \\dots and \\ldots can be followed by {}, and it is\nrecommended that they are when not followed by whitespace.\n- The obsolete interpretation of \\Alpha etc is no longer done.\nRd conversion now handles ^ ~ < > | correctly in non-code\nenvironments (such as \\samp), and # and _ even in latex\nconversion (but $ still needs to be escaped in version 1.0).\nWhitespace between first and second arguments is now accepted for\n\\item and \\section, e.g. \\item{foo} some value. Previously\narguments after whitespace were silently ignored, and a warning is\ngiven for version 1.0 files.\nThe Rd files created by prompt() and friends are declared to be\nversion 1.1.\n\\alias now supports the escaping of { as well as of %, and\nthis is recommended.\nparse_Rd(), an experimental parser for Rd files, and Rd2txt(),\nRd2HTML(), Rd2latex() and Rd2ex(), even more experimental\nconverters, have been added to package\ntools.\nruns the package’s Rd files through parse_Rd() for a stricter\nsyntax check. This can be suppressed by setting _R_CHECK_RD_PARSE_\nto FALSE.\nAdded markup \\verb, which displays like \\code, but parses as\nverbatim text. Currently only supported by parse_Rd() and\nRd2HTML().\nInstallation changes\nThe shell used by the R script and other shell scripts intended to\nbe run directly can be specified at installation time by setting the\n(precious) configure variable R_SHELL.\nlibtool has been updated to 2.2.6a.\nis now the default: this means that ICU will be used for collation\non Mac OS \\(>=\\) 10.4.\ncan be used to install the test files, to allow an installed version\nof R to be tested – see the R-admin manual. This is also\nsupported by the function testInstalledPackages() in package\ntools.\nusing a parallel make should now work.\nnow always re-makes and re-runs the package examples, which are now\ncollated in the locale’s order (and not ASCII order).\nconfigure will now set the default optimization level for gfortran\non x86_64 Linux to as has caused problems with gfortran 4.3.x.\nPackage installation changes\ninstall.packages() is able to infer that repos=NULL was intended\nfrom the extension on the file name specified as pkgs.\nOn Mac OS X it now supports local binary packages with .tar.gz\nextension. Nonetheless .tgz remains the preferred extension and is\nexpected in repositories.\nIt now checks \\(>=\\) version dependencies for dependent packages, and\nso will install a newer version of a dependency if needed and\navailable on the repositories.\nThe library being installed into is considered when looking for\ninstalled packages if it is not already part of .libPaths() (as\nalready does).\nIt has a new argument Ncpus to support parallel installs of source\npackages.\nHTML links will be resolved first to the standard packages: this\navoids other installed packages diverting help on e.g. qr() and\nplot() to themselves. The HTML files are only \"touched\" if they\nhave changed.\nA check is done that the R files can be parsed: this both prevents a\nbroken package without lazy-loading from being installed and gives\nbetter diagnostics.\ninstall.packages() gains a configure.vars argument, and both\nthis and configure.args get their defaults from options().\nThere is a unified R script for on both Unix-alike and Windows that\ntakes option names used by either in the past.\nIt adds to disable building other than the main sub-architecture,\nand allows multiple instances of and (which will be concatenated).\nNew option will install any package-specific tests.\nTimes in the and fields are now recorded in UTC, and in most cases\nin ISO 8601 format.\nC-level facilities\nA helper function, asCharacterFactor, converts from factors to\ncharacter vectors.\nBug fixes\nThe postscript() output for setting text is faster and smaller.\nSubsetting a data frame with duplicate column names without\nselecting columns (e.g. z[i,]) no longer makes the column names\nunique. This was never documented, but some packages have assumed\nit.\ndata.frame() no longer ignores row names on objects if the first\nname is empty. (PR#13230: this has been the behaviour for a long\ntime, but apparently undocumented.)\ndeparse(control=\"S_compatible\") now never uses backticks.\nX-spline drawing is improved for cases where the control points are\nlocated well off the edges of the device.\nThe symptom of this problem is the error \"reached MAXNUMPTS\".\nexists() with will no longer run an active binding’s function.\nformat(c(1 + 2i, NA)) no longer has extraneous space in \" NA\".\nmood.test() could fail in 2.8.x on large samples because of\ninteger overflow.\nheatmap() without a dendrogram could fail (PR#13512).\nChecks for missing values will no longer occasionally result in an\ninfinite loop or stack overflow error, depending on the compiler.\nActive bindings are now always considered to be non-missing.\nRd conversion was not accepting \\p (as in \\CRANpkg) or (when\nusing Perl 5.10.x) \\k (as in \\kbd) in any preamble text in a\nsection, since those are nowadays interpreted by Perl (PR#13575).\nif(as.raw(1)) TRUE now works as expected (PR#13630). Also,\nc(as.raw(12), TRUE) or c(raw(3), pi) do.\nduplicated(<data frame>, incomparables = NA) now gives the\nintended error message (PR#13632).\nName handling of as.data.frame() has been sanitized somewhat.\nEvaluating an assignment expression with a string on the left hand\nside no longer destructively changes the string to a symbol in the\nexpression.\n\n\nCRAN packages used\nMatrix, tools, tcltk, utils, base, stats, methods, graphics, gnomeGUI\nCRAN Task Views implied by cited packages\nEconometrics, NumericalMathematics\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2009-1-r-foundation/",
    "title": "R Foundation News",
    "description": "The 'R Foundation News' article from the 2009-1 issue.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2009-06-01",
    "categories": [],
    "contents": "\n1 Donations and new members\nDonations\nStefan Wyder, Switzerland\nNew supporting members\nStephan Devriese, Belgium\nFrans van Dunné, Netherlands\nKarl Ove Hufthammer, Norway\nGeorge Ostrouchov, USA\nKem Phillips, USA\nJoon You, USA\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RJ-2009-1-vinod/",
    "title": "Forthcoming Events: Conference on Quantitative Social Science Research Using R",
    "description": "The 'Forthcoming Events: Conference on Quantitative Social Science Research Using R' article from the 2009-1 issue.",
    "author": [
      {
        "name": "H. D. Vinod",
        "url": {}
      }
    ],
    "date": "2009-06-01",
    "categories": [],
    "contents": "\n\nJune 18-19 (Thursday-Friday), 2009, Fordham University, 113 West 60th\nStreet, New York, NY. (next door to the Lincoln Center for Performing\nArts).\nConference website:\nhttp://www.cis.fordham.edu/QR2009\nThe conference offers opportunity to enthusiastic users of R to discuss\nimportant policy and research problems in social sciences, to learn,\nmeet and mingle.\nSpeakers include authors of books and /or packages for R, published\nresearchers and editors of important journals in Statistics and\nsocial sciences: Andrew Gelman (Columbia), Kosuke Imai (Princeton),\nRoger Koenker (Illinois), Keith A. Markus (CUNY), Bruce D.\nMcCullough (Drexel), H. D. Vinod (Fordham), Achim Zeileis (Vienna).\nConference proceedings book will be published by Springer (publisher\nof Use R! series) in 2009.\nOpportunity to present Replication / extension of published papers\nusing R, (poster session).\nOpportunity to present new useful R functions (including teaching\nmaterial) (poster session).\nA tutorial cum refresher session teaching R\n\n\nNote\nThis article is converted from a Legacy LaTeX article using the\ntexor package.\nThe pdf version is the official version. To report a problem with the html,\nrefer to CONTRIBUTE on the R Journal homepage.\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:07+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2008-2-bioc/",
    "title": "News from the Bioconductor Project",
    "description": "\"News from the Bioconductor Project\" published in R News.",
    "author": [
      {
        "name": "Bioconductor Team",
        "url": {}
      }
    ],
    "date": "2008-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2008-2-changes-in-r-version-280/",
    "title": "Changes in R Version 2.8.0",
    "description": "\"Changes in R Version 2.8.0\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2008-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2008-2-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2008-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2008-2-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "John Fox",
        "url": {}
      }
    ],
    "date": "2008-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2008-2-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2008-2-forthcoming-events-dsc-2009/",
    "title": "Forthcoming Events: DSC 2009",
    "description": "\"Forthcoming Events: DSC 2009\" published in R News.",
    "author": [],
    "date": "2008-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2008-2-forthcoming-events-user-2009/",
    "title": "Forthcoming Events: useR! 2009",
    "description": "\"Forthcoming Events: useR! 2009\" published in R News.",
    "author": [
      {
        "name": "David Causeur",
        "url": {}
      },
      {
        "name": "Julie Josse",
        "url": {}
      },
      {
        "name": "François Husson",
        "url": {}
      },
      {
        "name": "Maela Kloareg",
        "url": {}
      },
      {
        "name": "Sébastien Lê",
        "url": {}
      },
      {
        "name": "Eric Matzner-Løber",
        "url": {}
      },
      {
        "name": "Jérôme Pagès",
        "url": {}
      }
    ],
    "date": "2008-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2008-2-foundation/",
    "title": "R Foundation News",
    "description": "\"R Foundation News\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2008-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2008-2-user-2008/",
    "title": "useR! 2008",
    "description": "\"useR! 2008\" published in R News.",
    "author": [
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      },
      {
        "name": "Claus Weihs",
        "url": {}
      },
      {
        "name": "Gerd Kopp",
        "url": {}
      },
      {
        "name": "Friedrich Leisch",
        "url": {}
      },
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2008-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2008-1-bioc/",
    "title": "News from the Bioconductor Project",
    "description": "\"News from the Bioconductor Project\" published in R News.",
    "author": [
      {
        "name": "Bioconductor Team",
        "url": {}
      }
    ],
    "date": "2008-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2008-1-changes-in-r-version-270/",
    "title": "Changes in R Version 2.7.0",
    "description": "\"Changes in R Version 2.7.0\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2008-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2008-1-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2008-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2008-1-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "John Fox",
        "url": {}
      }
    ],
    "date": "2008-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2008-1-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2008-1-forthcoming-events-user-2008/",
    "title": "Forthcoming Events: useR! 2008",
    "description": "\"Forthcoming Events: useR! 2008\" published in R News.",
    "author": [
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      },
      {
        "name": "Claus Weihs",
        "url": {}
      },
      {
        "name": "Gerd Kopp",
        "url": {}
      },
      {
        "name": "Friedrich Leisch",
        "url": {}
      },
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2008-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2008-1-foundation/",
    "title": "R Foundation News",
    "description": "\"R Foundation News\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2008-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2008-1-r-help-desk/",
    "title": "R Help Desk",
    "description": "\"R Help Desk\" published in R News.",
    "author": [
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "John Fox",
        "url": {}
      }
    ],
    "date": "2008-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2008-1-r-news-referees-2007/",
    "title": "R News Referees 2007",
    "description": "\"R News Referees 2007\" published in R News.",
    "author": [
      {
        "name": "John Fox",
        "url": {}
      }
    ],
    "date": "2008-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2007-3-changes-in-r-261/",
    "title": "Changes in R 2.6.1",
    "description": "\"Changes in R 2.6.1\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2007-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2007-3-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2007-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2007-3-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2007-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2007-3-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2007-2-bioc/",
    "title": "News from the Bioconductor Project",
    "description": "\"News from the Bioconductor Project\" published in R News.",
    "author": [
      {
        "name": "Hervé Pagès",
        "url": {}
      },
      {
        "name": "Martin Morgan",
        "url": {}
      }
    ],
    "date": "2007-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2007-2-bioc/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 300,
    "preview_height": 225
  },
  {
    "path": "news/RN-2007-2-changes-in-r-260/",
    "title": "Changes in R 2.6.0",
    "description": "\"Changes in R 2.6.0\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2007-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2007-2-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2007-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2007-2-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2007-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2007-2-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2007-2-forthcoming-events-r-courses/",
    "title": "Forthcoming Events: R Courses in Munich",
    "description": "\"Forthcoming Events: R Courses in Munich\" published in R News.",
    "author": [
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2007-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2007-2-forthcoming-events-user-2008/",
    "title": "Forthcoming Events: useR! 2008",
    "description": "\"Forthcoming Events: useR! 2008\" published in R News.",
    "author": [
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Achim Zeileis",
        "url": {}
      },
      {
        "name": "Claus Weihs",
        "url": {}
      },
      {
        "name": "Gerd Kopp",
        "url": {}
      },
      {
        "name": "Friedrich Leisch",
        "url": {}
      },
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2007-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2007-2-foundation/",
    "title": "R Foundation News",
    "description": "\"R Foundation News\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2007-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2007-2-past-events-user-2007/",
    "title": "Past Events: useR! 2007",
    "description": "\"Past Events: useR! 2007\" published in R News.",
    "author": [
      {
        "name": "Duncan Murdoch",
        "url": {}
      },
      {
        "name": "Martin Maechler",
        "url": {}
      }
    ],
    "date": "2007-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2007-2-past-events-user-2007/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 300,
    "preview_height": 225
  },
  {
    "path": "news/RN-2007-1-changes-in-r-250/",
    "title": "Changes in R 2.5.0",
    "description": "\"Changes in R 2.5.0\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2007-04-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2007-1-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2007-04-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2007-1-dsc-2007/",
    "title": "DSC 2007",
    "description": "\"DSC 2007\" published in R News.",
    "author": [
      {
        "name": "Hadley Wickham",
        "url": {}
      }
    ],
    "date": "2007-04-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2007-1-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2007-04-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2007-1-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2007-1-forthcoming-events-user-2007/",
    "title": "Forthcoming Events: useR! 2007",
    "description": "\"Forthcoming Events: useR! 2007\" published in R News.",
    "author": [
      {
        "name": "Dianne Cook",
        "url": {}
      }
    ],
    "date": "2007-04-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2007-1-foundation/",
    "title": "R Foundation News",
    "description": "\"R Foundation News\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2007-04-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2007-1-new-journal-annals-of-applied/",
    "title": "New Journal: Annals of Applied Statistics",
    "description": "\"New Journal: Annals of Applied Statistics\" published in R News.",
    "author": [
      {
        "name": "Bradley Efron",
        "url": {}
      }
    ],
    "date": "2007-04-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2007-1-r-news-referees-2006/",
    "title": "R News Referees 2006",
    "description": "\"R News Referees 2006\" published in R News.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2007-04-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2006-5-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Wolfgang Huber",
        "url": {}
      },
      {
        "name": "Paul Murrell",
        "url": {}
      }
    ],
    "date": "2006-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2006-5-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2006-4-bioc/",
    "title": "News from the Bioconductor Project",
    "description": "\"News from the Bioconductor Project\" published in R News.",
    "author": [
      {
        "name": "Seth Falcon",
        "url": {}
      }
    ],
    "date": "2006-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2006-4-core/",
    "title": "Changes in R",
    "description": "\"Changes in R\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2006-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2006-4-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2006-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2006-4-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Paul Murrell",
        "url": {}
      }
    ],
    "date": "2006-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2006-4-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2006-4-foundation/",
    "title": "R Foundation News",
    "description": "\"R Foundation News\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2006-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2006-4-user-2006-the-second-r-user/",
    "title": "useR! 2006, The Second R User Conference",
    "description": "\"useR! 2006, The Second R User Conference\" published in R News.",
    "author": [
      {
        "name": "Balasubramanian Narasimhan",
        "url": {}
      }
    ],
    "date": "2006-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2006-3-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Ron Wehrens",
        "url": {}
      },
      {
        "name": "Paul Murrell",
        "url": {}
      }
    ],
    "date": "2006-08-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2006-3-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2006-3-fitting-doseresponse-curves/",
    "title": "Fitting dose-response curves from bioassays and toxicity testing",
    "description": "\"Fitting dose-response curves from bioassays and toxicity testing\" published in R News.",
    "author": [
      {
        "name": "Johannes Ranke",
        "url": {}
      }
    ],
    "date": "2006-08-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2006-3-fitting-doseresponse-curves/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 428,
    "preview_height": 535
  },
  {
    "path": "news/RN-2006-2-bioc/",
    "title": "News from the Bioconductor Project",
    "description": "\"News from the Bioconductor Project\" published in R News.",
    "author": [
      {
        "name": "Seth Falcon",
        "url": {}
      }
    ],
    "date": "2006-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2006-2-core/",
    "title": "Changes in R",
    "description": "\"Changes in R\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2006-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2006-2-core/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 315,
    "preview_height": 500
  },
  {
    "path": "news/RN-2006-2-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2006-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2006-2-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Paul Murrell",
        "url": {}
      }
    ],
    "date": "2006-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2006-2-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2006-2-forthcoming-events-dsc-2007/",
    "title": "Forthcoming Events: DSC 2007",
    "description": "\"Forthcoming Events: DSC 2007\" published in R News.",
    "author": [
      {
        "name": "Paul Murrell",
        "url": {}
      },
      {
        "name": "Ross Ihaka",
        "url": {}
      },
      {
        "name": "David Scott",
        "url": {}
      },
      {
        "name": "Thomas Yee",
        "url": {}
      }
    ],
    "date": "2006-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2006-2-foundation/",
    "title": "R Foundation News",
    "description": "\"R Foundation News\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2006-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2006-2-resistor-networks-r/",
    "title": "Resistor networks R: Introducing the ResistorArray package",
    "description": "\"Resistor networks R: Introducing the ResistorArray package\" published in R News.",
    "author": [
      {
        "name": "Robin K. S. Hankin",
        "url": {}
      }
    ],
    "date": "2006-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2006-2-the-good-the-bad-and-the/",
    "title": "The good, the bad, and the ugly—Review of Paul Murrell’s new book: “R Graphics”",
    "description": "\"The good, the bad, and the ugly—Review of Paul Murrell’s new book: “R Graphics”\" published in R News.",
    "author": [
      {
        "name": "David Meyer",
        "url": {}
      }
    ],
    "date": "2006-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2006-2-the-good-the-bad-and-the/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 315,
    "preview_height": 500
  },
  {
    "path": "news/RN-2006-1-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Martyn Plummer",
        "url": {}
      },
      {
        "name": "Paul Murrell",
        "url": {}
      }
    ],
    "date": "2006-03-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2006-1-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2006-1-erratum/",
    "title": "Erratum",
    "description": "\"Erratum\" published in R News.",
    "author": [],
    "date": "2006-03-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2005-2-core/",
    "title": "Changes in R",
    "description": "\"Changes in R\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2005-11-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2005-2-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2005-11-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2005-2-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Douglas Bates",
        "url": {}
      }
    ],
    "date": "2005-11-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2005-2-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2005-2-forthcoming-events-user-2006/",
    "title": "Forthcoming Events: useR! 2006",
    "description": "\"Forthcoming Events: useR! 2006\" published in R News.",
    "author": [],
    "date": "2005-11-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2005-2-r-help-desk/",
    "title": "R Help Desk",
    "description": "\"R Help Desk\" published in R News.",
    "author": [
      {
        "name": "Uwe Ligges",
        "url": {}
      },
      {
        "name": "Duncan Murdoch",
        "url": {}
      }
    ],
    "date": "2005-11-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2005-1-book-review-of-julian-j/",
    "title": "Book Review of Julian J. Faraway: Linear Models with R",
    "description": "\"Book Review of Julian J. Faraway: Linear Models with R\" published in R News.",
    "author": [
      {
        "name": "Thomas Yee",
        "url": {}
      }
    ],
    "date": "2005-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2005-1-core/",
    "title": "Changes in R",
    "description": "\"Changes in R\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2005-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2005-1-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2005-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2005-1-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Douglas Bates",
        "url": {}
      }
    ],
    "date": "2005-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2005-1-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2005-1-events/",
    "title": "Events",
    "description": "\"Events\" published in R News.",
    "author": [],
    "date": "2005-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2005-1-foundation/",
    "title": "R Foundation News",
    "description": "\"R Foundation News\" published in R News.",
    "author": [
      {
        "name": "Bettina Grün",
        "url": {}
      }
    ],
    "date": "2005-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2005-1-niche/",
    "title": "Programmer’s Niche",
    "description": "\"Programmer’s Niche\" published in R News.",
    "author": [
      {
        "name": "John Fox",
        "url": {}
      }
    ],
    "date": "2005-05-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2004-2-core/",
    "title": "Changes in R",
    "description": "\"Changes in R\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2004-09-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2004-2-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2004-09-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2004-2-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Thomas Lumley",
        "url": {}
      }
    ],
    "date": "2004-09-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2004-2-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2004-1-core/",
    "title": "Changes in R",
    "description": "\"Changes in R\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2004-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2004-1-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2004-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2004-1-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Thomas Lumley",
        "url": {}
      }
    ],
    "date": "2004-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2004-1-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2004-1-foundation/",
    "title": "R Foundation News",
    "description": "\"R Foundation News\" published in R News.",
    "author": [
      {
        "name": "Bettina Grün",
        "url": {}
      }
    ],
    "date": "2004-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2004-1-niche/",
    "title": "Programmers’ Niche",
    "description": "\"Programmers’ Niche\" published in R News.",
    "author": [
      {
        "name": "Thomas Lumley",
        "url": {}
      }
    ],
    "date": "2004-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2004-1-r-help-desk/",
    "title": "R Help Desk",
    "description": "\"R Help Desk\" published in R News.",
    "author": [
      {
        "name": "Gabor Grothendieck",
        "url": {}
      },
      {
        "name": "Thomas Petzoldt",
        "url": {}
      }
    ],
    "date": "2004-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2004-1-user-2004/",
    "title": "useR! 2004",
    "description": "\"useR! 2004\" published in R News.",
    "author": [
      {
        "name": "John Fox",
        "url": {}
      }
    ],
    "date": "2004-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-3-changes-in-r-181/",
    "title": "Changes in R 1.8.1",
    "description": "\"Changes in R 1.8.1\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2003-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-3-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2003-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-3-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2003-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2003-3-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2003-3-events/",
    "title": "Upcoming Events",
    "description": "\"Upcoming Events\" published in R News.",
    "author": [
      {
        "name": "R core team mem- bers:",
        "url": {}
      }
    ],
    "date": "2003-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2003-3-events/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 184,
    "preview_height": 125
  },
  {
    "path": "news/RN-2003-3-foundation/",
    "title": "R Foundation News",
    "description": "\"R Foundation News\" published in R News.",
    "author": [
      {
        "name": "Bettina Grün",
        "url": {}
      }
    ],
    "date": "2003-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-3-niche/",
    "title": "Programmer’s Niche",
    "description": "\"Programmer’s Niche\" published in R News.",
    "author": [
      {
        "name": "Thomas Lumley",
        "url": {}
      }
    ],
    "date": "2003-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-3-r-help-desk/",
    "title": "R Help Desk",
    "description": "\"R Help Desk\" published in R News.",
    "author": [
      {
        "name": "Uwe Ligges",
        "url": {}
      }
    ],
    "date": "2003-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-3-recent-events/",
    "title": "Recent Events",
    "description": "\"Recent Events\" published in R News.",
    "author": [
      {
        "name": "Krisztina Filep",
        "url": {}
      }
    ],
    "date": "2003-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-2-book-reviews/",
    "title": "Book Reviews",
    "description": "\"Book Reviews\" published in R News.",
    "author": [
      {
        "name": "Bret Larget",
        "url": {}
      }
    ],
    "date": "2003-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-2-changes-in-r-180/",
    "title": "Changes in R 1.8.0",
    "description": "\"Changes in R 1.8.0\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2003-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-2-correction-to-building/",
    "title": "Correction to “Building Microsoft Windows Versions of R and R packages under Intel Linux”",
    "description": "\"Correction to “Building Microsoft Windows Versions of R and R packages under Intel Linux”\" published in R News.",
    "author": [
      {
        "name": "Jun Yan",
        "url": {}
      },
      {
        "name": "A.J. Rossini",
        "url": {}
      }
    ],
    "date": "2003-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-2-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2003-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-2-crossword-solution/",
    "title": "Crossword Solution",
    "description": "\"Crossword Solution\" published in R News.",
    "author": [
      {
        "name": "Barry Rowlingson",
        "url": {}
      }
    ],
    "date": "2003-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-2-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2003-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2003-2-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2003-2-foundation/",
    "title": "R Foundation News",
    "description": "\"R Foundation News\" published in R News.",
    "author": [
      {
        "name": "Bettina Grün",
        "url": {}
      },
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2003-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-2-r-help-desk/",
    "title": "R Help Desk",
    "description": "\"R Help Desk\" published in R News.",
    "author": [
      {
        "name": "Marc Schwartz",
        "url": {}
      }
    ],
    "date": "2003-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-2-recent-events/",
    "title": "Recent Events",
    "description": "\"Recent Events\" published in R News.",
    "author": [
      {
        "name": "Günther Sawitzki",
        "url": {}
      },
      {
        "name": "Friedrich Leisch",
        "url": {}
      },
      {
        "name": "Balasubramanian Narasimhan",
        "url": {}
      },
      {
        "name": "Claus Dethlefsen",
        "url": {}
      }
    ],
    "date": "2003-10-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-1-book-reviews/",
    "title": "Book Reviews",
    "description": "\"Book Reviews\" published in R News.",
    "author": [
      {
        "name": "Kevin Wright",
        "url": {}
      },
      {
        "name": "Andy Liaw",
        "url": {}
      },
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2003-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-1-changes-in-r-170/",
    "title": "Changes in R 1.7.0",
    "description": "\"Changes in R 1.7.0\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2003-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-1-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2003-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-1-crossword/",
    "title": "Crossword",
    "description": "\"Crossword\" published in R News.",
    "author": [
      {
        "name": "Barry Rowlingson",
        "url": {}
      }
    ],
    "date": "2003-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-1-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2003-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2003-1-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2003-1-r-help-desk/",
    "title": "R Help Desk",
    "description": "\"R Help Desk\" published in R News.",
    "author": [
      {
        "name": "R Development Core",
        "url": {}
      }
    ],
    "date": "2003-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2003-1-recent-events/",
    "title": "Recent Events",
    "description": "\"Recent Events\" published in R News.",
    "author": [
      {
        "name": "Torsten Hothorn",
        "url": {}
      }
    ],
    "date": "2003-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2002-3-core/",
    "title": "Changes in R",
    "description": "\"Changes in R\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2002-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2002-3-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2002-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2002-3-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2002-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2002-3-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2002-3-graphical-models-in-r/",
    "title": "gRaphical Models in R",
    "description": "\"gRaphical Models in R\" published in R News.",
    "author": [
      {
        "name": "Steffen L. Lauritzen",
        "url": {}
      }
    ],
    "date": "2002-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2002-3-new-publications/",
    "title": "New Publications",
    "description": "\"New Publications\" published in R News.",
    "author": [],
    "date": "2002-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2002-3-r-help-desk/",
    "title": "R Help Desk",
    "description": "\"R Help Desk\" published in R News.",
    "author": [
      {
        "name": "Uwe Ligges",
        "url": {}
      }
    ],
    "date": "2002-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2002-3-recent-and-upcoming-events/",
    "title": "Recent and Upcoming Events",
    "description": "\"Recent and Upcoming Events\" published in R News.",
    "author": [
      {
        "name": "John Fox",
        "url": {}
      },
      {
        "name": "Karl W. Broman",
        "url": {}
      },
      {
        "name": "Friedrich Leisch",
        "url": {}
      },
      {
        "name": "Stefano Iacus",
        "url": {}
      }
    ],
    "date": "2002-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2002-3-sweave-part-i-mixing-r-and-l/",
    "title": "Sweave, Part I: Mixing R and L",
    "description": "\"Sweave, Part I: Mixing R and L\" published in R News.",
    "author": [
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2002-12-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2002-3-sweave-part-i-mixing-r-and-l/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 1,
    "preview_height": 1
  },
  {
    "path": "news/RN-2002-2-core/",
    "title": "Changes in R",
    "description": "\"Changes in R\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2002-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2002-2-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2002-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2002-2-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2002-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2002-2-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2002-2-events/",
    "title": "Upcoming Events",
    "description": "\"Upcoming Events\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2002-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2002-1-changes-in-r-140/",
    "title": "Changes in R 1.4.0",
    "description": "\"Changes in R 1.4.0\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2002-03-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2002-1-changes-in-r-141/",
    "title": "Changes in R 1.4.1",
    "description": "\"Changes in R 1.4.1\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2002-03-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2002-1-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2002-03-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2002-1-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2002-03-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2002-1-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2001-3-core/",
    "title": "Changes in R",
    "description": "\"Changes in R\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2001-09-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2001-3-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2001-09-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2001-3-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2001-09-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2001-3-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2001-2-core/",
    "title": "Changes in R",
    "description": "\"Changes in R\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2001-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2001-2-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2001-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2001-2-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2001-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2001-2-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2001-2-niche/",
    "title": "Programmer’s Niche",
    "description": "\"Programmer’s Niche\" published in R News.",
    "author": [
      {
        "name": "Bill Venables",
        "url": {}
      }
    ],
    "date": "2001-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2001-2-recent-events/",
    "title": "Recent Events",
    "description": "\"Recent Events\" published in R News.",
    "author": [
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2001-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2001-2-spatial-statistics-in-r/",
    "title": "Spatial Statistics in R",
    "description": "\"Spatial Statistics in R\" published in R News.",
    "author": [
      {
        "name": "Brian D. Ripley",
        "url": {}
      }
    ],
    "date": "2001-06-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2001-2-spatial-statistics-in-r/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 292,
    "preview_height": 163
  },
  {
    "path": "news/RN-2001-1-core/",
    "title": "Changes in R",
    "description": "\"Changes in R\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2001-01-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2001-1-cran/",
    "title": "Changes on CRAN",
    "description": "\"Changes on CRAN\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2001-01-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2001-1-editorial/",
    "title": "Editorial",
    "description": "\"Editorial\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      },
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2001-01-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": "news/RN-2001-1-editorial/preview.png",
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {},
    "preview_width": 101,
    "preview_height": 77
  },
  {
    "path": "news/RN-2001-1-events/",
    "title": "Upcoming Events",
    "description": "\"Upcoming Events\" published in R News.",
    "author": [
      {
        "name": "Kurt Hornik",
        "url": {}
      }
    ],
    "date": "2001-01-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2001-1-r-resources/",
    "title": "R Resources",
    "description": "\"R Resources\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2001-01-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2001-1-what-is-r/",
    "title": "What is R?",
    "description": "\"What is R?\" published in R News.",
    "author": [
      {
        "name": "R Core Team",
        "url": {}
      }
    ],
    "date": "2001-01-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  },
  {
    "path": "news/RN-2001-1-writing-articles-for-r-news/",
    "title": "Writing Articles for R News",
    "description": "\"Writing Articles for R News\" published in R News.",
    "author": [
      {
        "name": "Friedrich Leisch",
        "url": {}
      }
    ],
    "date": "2001-01-01",
    "categories": [],
    "contents": "\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-01-26T11:27:09+00:00",
    "input_file": {}
  }
]
